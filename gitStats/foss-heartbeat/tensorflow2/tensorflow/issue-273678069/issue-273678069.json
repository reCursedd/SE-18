{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14529", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14529/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14529/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14529/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14529", "id": 273678069, "node_id": "MDU6SXNzdWUyNzM2NzgwNjk=", "number": 14529, "title": "[feature request]time out option for tf.Data.from_generator", "user": {"login": "qianyizhang", "id": 12500132, "node_id": "MDQ6VXNlcjEyNTAwMTMy", "avatar_url": "https://avatars0.githubusercontent.com/u/12500132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qianyizhang", "html_url": "https://github.com/qianyizhang", "followers_url": "https://api.github.com/users/qianyizhang/followers", "following_url": "https://api.github.com/users/qianyizhang/following{/other_user}", "gists_url": "https://api.github.com/users/qianyizhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/qianyizhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qianyizhang/subscriptions", "organizations_url": "https://api.github.com/users/qianyizhang/orgs", "repos_url": "https://api.github.com/users/qianyizhang/repos", "events_url": "https://api.github.com/users/qianyizhang/events{/privacy}", "received_events_url": "https://api.github.com/users/qianyizhang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-14T06:08:20Z", "updated_at": "2017-11-15T05:16:58Z", "closed_at": "2017-11-14T19:33:50Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 10/7</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\npip installed tensorflow-gpu binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.40</li>\n<li><strong>Python version</strong>:<br>\n3.5/3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nCUDA8/cuDNN6.0</li>\n<li><strong>GPU model and memory</strong>:<br>\ngtx980m(8g)/Quadro 4000M(8g)</li>\n<li><strong>Exact command to reproduce</strong>:<br>\nfrom_generator</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Unnecessary background:<br>\nI previously using a customized python function to load (one epoch of) images from disc, perform pre-processing and data augmentation and return as generator, and feed into corresponding placeholder via feed_dict. This function worked out fine for 100,000+ steps.</p>\n<p>I recently refactored my codes using tf.Data and put the exact same function into the tf.Data.from_generator function. However, the pipeline would stuck indefinitely every 200 epochs (3,000 steps) or so, just before it should break out from \"except tf.errors.OutOfRangeError:\"; also it's not throwing any exception which could be cached by \"except Exception as e\". However, by manually pressing \"enter\", the program would continue to run while dumping out a full screen of getNext() error messages from previous runs. Unfortunately I can not supply any customized pre-processing functions and data to help you debug this \"bug\", and I am not sure it's reproduce-able with a reduced example, since the occurrence seems rather arbitrary.</p>\n<p><strong>Feature wish:</strong><br>\nI am hoping for a time out feature for the general tf.Data class to break out from bad loops.<br>\nI suppose any customized solution would involve using standalone thread which could interfere with tf threadpool, therefore this feature must be supported in the tf scope.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 10/7\nTensorFlow installed from (source or binary):\npip installed tensorflow-gpu binary\nTensorFlow version (use command below):\n1.40\nPython version:\n3.5/3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nCUDA8/cuDNN6.0\nGPU model and memory:\ngtx980m(8g)/Quadro 4000M(8g)\nExact command to reproduce:\nfrom_generator\n\nDescribe the problem\nUnnecessary background:\nI previously using a customized python function to load (one epoch of) images from disc, perform pre-processing and data augmentation and return as generator, and feed into corresponding placeholder via feed_dict. This function worked out fine for 100,000+ steps.\nI recently refactored my codes using tf.Data and put the exact same function into the tf.Data.from_generator function. However, the pipeline would stuck indefinitely every 200 epochs (3,000 steps) or so, just before it should break out from \"except tf.errors.OutOfRangeError:\"; also it's not throwing any exception which could be cached by \"except Exception as e\". However, by manually pressing \"enter\", the program would continue to run while dumping out a full screen of getNext() error messages from previous runs. Unfortunately I can not supply any customized pre-processing functions and data to help you debug this \"bug\", and I am not sure it's reproduce-able with a reduced example, since the occurrence seems rather arbitrary.\nFeature wish:\nI am hoping for a time out feature for the general tf.Data class to break out from bad loops.\nI suppose any customized solution would involve using standalone thread which could interfere with tf threadpool, therefore this feature must be supported in the tf scope.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10/7\r\n- **TensorFlow installed from (source or binary)**:\r\npip installed tensorflow-gpu binary\r\n- **TensorFlow version (use command below)**:\r\n1.40\r\n- **Python version**: \r\n3.5/3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nCUDA8/cuDNN6.0\r\n- **GPU model and memory**:\r\ngtx980m(8g)/Quadro 4000M(8g)\r\n- **Exact command to reproduce**:\r\nfrom_generator\r\n\r\n### Describe the problem\r\nUnnecessary background:\r\nI previously using a customized python function to load (one epoch of) images from disc, perform pre-processing and data augmentation and return as generator, and feed into corresponding placeholder via feed_dict. This function worked out fine for 100,000+ steps.\r\n\r\nI recently refactored my codes using tf.Data and put the exact same function into the tf.Data.from_generator function. However, the pipeline would stuck indefinitely every 200 epochs (3,000 steps) or so, just before it should break out from \"except tf.errors.OutOfRangeError:\"; also it's not throwing any exception which could be cached by \"except Exception as e\". However, by manually pressing \"enter\", the program would continue to run while dumping out a full screen of getNext() error messages from previous runs. Unfortunately I can not supply any customized pre-processing functions and data to help you debug this \"bug\", and I am not sure it's reproduce-able with a reduced example, since the occurrence seems rather arbitrary.\r\n\r\n**Feature wish:**\r\nI am hoping for a time out feature for the general tf.Data class to break out from bad loops. \r\nI suppose any customized solution would involve using standalone thread which could interfere with tf threadpool, therefore this feature must be supported in the tf scope.\r\n\r\n\r\n"}