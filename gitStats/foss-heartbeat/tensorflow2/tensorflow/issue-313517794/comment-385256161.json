{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385256161", "html_url": "https://github.com/tensorflow/tensorflow/issues/18437#issuecomment-385256161", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18437", "id": 385256161, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTI1NjE2MQ==", "user": {"login": "Wheest", "id": 16022573, "node_id": "MDQ6VXNlcjE2MDIyNTcz", "avatar_url": "https://avatars0.githubusercontent.com/u/16022573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Wheest", "html_url": "https://github.com/Wheest", "followers_url": "https://api.github.com/users/Wheest/followers", "following_url": "https://api.github.com/users/Wheest/following{/other_user}", "gists_url": "https://api.github.com/users/Wheest/gists{/gist_id}", "starred_url": "https://api.github.com/users/Wheest/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Wheest/subscriptions", "organizations_url": "https://api.github.com/users/Wheest/orgs", "repos_url": "https://api.github.com/users/Wheest/repos", "events_url": "https://api.github.com/users/Wheest/events{/privacy}", "received_events_url": "https://api.github.com/users/Wheest/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-29T14:39:44Z", "updated_at": "2018-04-29T14:41:54Z", "author_association": "NONE", "body_html": "<p>I have been having a similar issue.  All of the operations are supported, but conversion to <code>.tflite</code> fails because the input tensor has an input dimension of type <code>None</code> (to allow an arbitrary number of input datapoints)</p>\n<p>From the <a href=\"https://www.tensorflow.org/versions/master/mobile/tflite/devguide\" rel=\"nofollow\">tflite dev guide</a>, you can convert your model to FlatBuf like so:</p>\n<pre><code>import tensorflow as tf\n\nimg = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\nval = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\nout = tf.identity(val, name=\"out\")\n\nwith tf.Session() as sess:\n  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])\n  open(\"converteds_model.tflite\", \"wb\").write(tflite_model)\n</code></pre>\n<p>However, if our input can be of arbitrary size, (e.g. our input <code>x</code> is of shape <code>[None, 784]</code>), then we get <code>Error: TypeError: __int__ returned non-int (type NoneType)</code>.</p>\n<p>I posted a <a href=\"https://stackoverflow.com/questions/50028868/tensorflow-lite-toco-convert-for-arbitrary-sized-input-tensor\" rel=\"nofollow\">SO question</a>, but have no answers yet.</p>\n<p>A M(not)WE could be:</p>\n<pre><code>import tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\ngraph_mnist = tf.Graph()\n\nwith graph_mnist.as_default():\n    with tf.name_scope('data'):\n        inputs = tf.placeholder(tf.float32, [None, 784], name='inputs')\n        targets = tf.placeholder(tf.float32, [None, 10], name='targets')\n    with tf.name_scope('parameters'):\n        weights = tf.Variable(tf.zeros([784, 10]), name='weights')\n        biases = tf.Variable(tf.zeros([10]), name='biases')\n    with tf.name_scope('model'):\n        outputs = tf.matmul(inputs, weights) + biases\n    with tf.name_scope('error'):\n        error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, labels=targets))\n    with tf.name_scope('train'):\n        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(error)\n    with tf.name_scope('accuracy'):\n        accuracy = tf.reduce_mean(tf.cast(\n                tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), tf.float32))\n    with tf.name_scope('init'):\n        init_op = tf.global_variables_initializer()\n\nsess = tf.Session(graph=graph_mnist)\nsess.run(init_op)\n\nfor _ in range(200):\n    batch = mnist.train.next_batch(100)\n    _, batch_error = sess.run(\n        [train_step, error],\n        feed_dict={inputs: batch[0], targets: batch[1]})\n        \n        \ndef get_error_and_accuracy(xx, yy_):\n    err = 0\n    acc = 0\n    err += sess.run(error, feed_dict={inputs: xx, targets: yy_})\n    acc += sess.run(accuracy, feed_dict={inputs: xx, targets: yy_})\n    return err, acc\n\nprint('Train data: Error={0:.2f} Accuracy={1:.2f}'\n    .format(*get_error_and_accuracy(mnist.train.images, mnist.train.labels)))\nprint('Valid data: Error={0:.2f} Accuracy={1:.2f}'\n    .format(*get_error_and_accuracy(mnist.test.images, mnist.test.labels)))\n    \n    \ntflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [inputs], [outputs])\nopen(\"converteds_model.tflite\", \"wb\").write(tflite_model)\n</code></pre>\n<p>How would one convert a model like this to the <code>.tflite</code> format?</p>", "body_text": "I have been having a similar issue.  All of the operations are supported, but conversion to .tflite fails because the input tensor has an input dimension of type None (to allow an arbitrary number of input datapoints)\nFrom the tflite dev guide, you can convert your model to FlatBuf like so:\nimport tensorflow as tf\n\nimg = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\nval = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\nout = tf.identity(val, name=\"out\")\n\nwith tf.Session() as sess:\n  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])\n  open(\"converteds_model.tflite\", \"wb\").write(tflite_model)\n\nHowever, if our input can be of arbitrary size, (e.g. our input x is of shape [None, 784]), then we get Error: TypeError: __int__ returned non-int (type NoneType).\nI posted a SO question, but have no answers yet.\nA M(not)WE could be:\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\ngraph_mnist = tf.Graph()\n\nwith graph_mnist.as_default():\n    with tf.name_scope('data'):\n        inputs = tf.placeholder(tf.float32, [None, 784], name='inputs')\n        targets = tf.placeholder(tf.float32, [None, 10], name='targets')\n    with tf.name_scope('parameters'):\n        weights = tf.Variable(tf.zeros([784, 10]), name='weights')\n        biases = tf.Variable(tf.zeros([10]), name='biases')\n    with tf.name_scope('model'):\n        outputs = tf.matmul(inputs, weights) + biases\n    with tf.name_scope('error'):\n        error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, labels=targets))\n    with tf.name_scope('train'):\n        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(error)\n    with tf.name_scope('accuracy'):\n        accuracy = tf.reduce_mean(tf.cast(\n                tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), tf.float32))\n    with tf.name_scope('init'):\n        init_op = tf.global_variables_initializer()\n\nsess = tf.Session(graph=graph_mnist)\nsess.run(init_op)\n\nfor _ in range(200):\n    batch = mnist.train.next_batch(100)\n    _, batch_error = sess.run(\n        [train_step, error],\n        feed_dict={inputs: batch[0], targets: batch[1]})\n        \n        \ndef get_error_and_accuracy(xx, yy_):\n    err = 0\n    acc = 0\n    err += sess.run(error, feed_dict={inputs: xx, targets: yy_})\n    acc += sess.run(accuracy, feed_dict={inputs: xx, targets: yy_})\n    return err, acc\n\nprint('Train data: Error={0:.2f} Accuracy={1:.2f}'\n    .format(*get_error_and_accuracy(mnist.train.images, mnist.train.labels)))\nprint('Valid data: Error={0:.2f} Accuracy={1:.2f}'\n    .format(*get_error_and_accuracy(mnist.test.images, mnist.test.labels)))\n    \n    \ntflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [inputs], [outputs])\nopen(\"converteds_model.tflite\", \"wb\").write(tflite_model)\n\nHow would one convert a model like this to the .tflite format?", "body": "I have been having a similar issue.  All of the operations are supported, but conversion to `.tflite` fails because the input tensor has an input dimension of type `None` (to allow an arbitrary number of input datapoints)\r\n\r\nFrom the [tflite dev guide](https://www.tensorflow.org/versions/master/mobile/tflite/devguide), you can convert your model to FlatBuf like so:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nimg = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\r\nval = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\r\nout = tf.identity(val, name=\"out\")\r\n\r\nwith tf.Session() as sess:\r\n  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])\r\n  open(\"converteds_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nHowever, if our input can be of arbitrary size, (e.g. our input `x` is of shape `[None, 784]`), then we get `Error: TypeError: __int__ returned non-int (type NoneType)`.\r\n\r\nI posted a [SO question](https://stackoverflow.com/questions/50028868/tensorflow-lite-toco-convert-for-arbitrary-sized-input-tensor), but have no answers yet. \r\n\r\nA M(not)WE could be:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\r\n\r\ngraph_mnist = tf.Graph()\r\n\r\nwith graph_mnist.as_default():\r\n    with tf.name_scope('data'):\r\n        inputs = tf.placeholder(tf.float32, [None, 784], name='inputs')\r\n        targets = tf.placeholder(tf.float32, [None, 10], name='targets')\r\n    with tf.name_scope('parameters'):\r\n        weights = tf.Variable(tf.zeros([784, 10]), name='weights')\r\n        biases = tf.Variable(tf.zeros([10]), name='biases')\r\n    with tf.name_scope('model'):\r\n        outputs = tf.matmul(inputs, weights) + biases\r\n    with tf.name_scope('error'):\r\n        error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, labels=targets))\r\n    with tf.name_scope('train'):\r\n        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(error)\r\n    with tf.name_scope('accuracy'):\r\n        accuracy = tf.reduce_mean(tf.cast(\r\n                tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), tf.float32))\r\n    with tf.name_scope('init'):\r\n        init_op = tf.global_variables_initializer()\r\n\r\nsess = tf.Session(graph=graph_mnist)\r\nsess.run(init_op)\r\n\r\nfor _ in range(200):\r\n    batch = mnist.train.next_batch(100)\r\n    _, batch_error = sess.run(\r\n        [train_step, error],\r\n        feed_dict={inputs: batch[0], targets: batch[1]})\r\n        \r\n        \r\ndef get_error_and_accuracy(xx, yy_):\r\n    err = 0\r\n    acc = 0\r\n    err += sess.run(error, feed_dict={inputs: xx, targets: yy_})\r\n    acc += sess.run(accuracy, feed_dict={inputs: xx, targets: yy_})\r\n    return err, acc\r\n\r\nprint('Train data: Error={0:.2f} Accuracy={1:.2f}'\r\n    .format(*get_error_and_accuracy(mnist.train.images, mnist.train.labels)))\r\nprint('Valid data: Error={0:.2f} Accuracy={1:.2f}'\r\n    .format(*get_error_and_accuracy(mnist.test.images, mnist.test.labels)))\r\n    \r\n    \r\ntflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [inputs], [outputs])\r\nopen(\"converteds_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nHow would one convert a model like this to the `.tflite` format?"}