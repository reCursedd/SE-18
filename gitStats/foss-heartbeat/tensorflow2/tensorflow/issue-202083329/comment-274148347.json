{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/274148347", "html_url": "https://github.com/tensorflow/tensorflow/issues/6974#issuecomment-274148347", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6974", "id": 274148347, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NDE0ODM0Nw==", "user": {"login": "gibiansky", "id": 1865411, "node_id": "MDQ6VXNlcjE4NjU0MTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1865411?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gibiansky", "html_url": "https://github.com/gibiansky", "followers_url": "https://api.github.com/users/gibiansky/followers", "following_url": "https://api.github.com/users/gibiansky/following{/other_user}", "gists_url": "https://api.github.com/users/gibiansky/gists{/gist_id}", "starred_url": "https://api.github.com/users/gibiansky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gibiansky/subscriptions", "organizations_url": "https://api.github.com/users/gibiansky/orgs", "repos_url": "https://api.github.com/users/gibiansky/repos", "events_url": "https://api.github.com/users/gibiansky/events{/privacy}", "received_events_url": "https://api.github.com/users/gibiansky/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-20T18:46:55Z", "updated_at": "2017-01-20T18:48:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I agree that this can be handled more effectively by fixing user code, but it is still an issue that should be fixed and should be causing at most a warning (not a crash).</p>\n<p>The reason this is happening is because we are training in parallel using MPI, and so we have many copies of identical MPI processes that run the same model (but communicate with each other to reduce gradients). If the processes are identical they will each write a log of the things they are doing to each directory. This <em>could</em> be handled by either doing a per-rank log directory or by having only a single rank write logs, and that is how we will handle this for the time being.</p>\n<p>More importantly, the reason this happens in a context like this is incredibly confusing and non-deterministic, and in general this situation is more appropriately dealt with by catching the error rather than by checking for the directory existing up-front; you can have a variety of other situations in which the directory does not initially exist but then gets created, and probably not all of those situations are user errors.</p>", "body_text": "I agree that this can be handled more effectively by fixing user code, but it is still an issue that should be fixed and should be causing at most a warning (not a crash).\nThe reason this is happening is because we are training in parallel using MPI, and so we have many copies of identical MPI processes that run the same model (but communicate with each other to reduce gradients). If the processes are identical they will each write a log of the things they are doing to each directory. This could be handled by either doing a per-rank log directory or by having only a single rank write logs, and that is how we will handle this for the time being.\nMore importantly, the reason this happens in a context like this is incredibly confusing and non-deterministic, and in general this situation is more appropriately dealt with by catching the error rather than by checking for the directory existing up-front; you can have a variety of other situations in which the directory does not initially exist but then gets created, and probably not all of those situations are user errors.", "body": "I agree that this can be handled more effectively by fixing user code, but it is still an issue that should be fixed and should be causing at most a warning (not a crash).\r\n\r\nThe reason this is happening is because we are training in parallel using MPI, and so we have many copies of identical MPI processes that run the same model (but communicate with each other to reduce gradients). If the processes are identical they will each write a log of the things they are doing to each directory. This _could_ be handled by either doing a per-rank log directory or by having only a single rank write logs, and that is how we will handle this for the time being.\r\n\r\nMore importantly, the reason this happens in a context like this is incredibly confusing and non-deterministic, and in general this situation is more appropriately dealt with by catching the error rather than by checking for the directory existing up-front; you can have a variety of other situations in which the directory does not initially exist but then gets created, and probably not all of those situations are user errors."}