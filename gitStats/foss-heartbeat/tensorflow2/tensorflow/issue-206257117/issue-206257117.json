{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7362", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7362/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7362/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7362/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7362", "id": 206257117, "node_id": "MDU6SXNzdWUyMDYyNTcxMTc=", "number": 7362, "title": "Clean up SegmentReduction Ops", "user": {"login": "PhilJd", "id": 16101605, "node_id": "MDQ6VXNlcjE2MTAxNjA1", "avatar_url": "https://avatars2.githubusercontent.com/u/16101605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PhilJd", "html_url": "https://github.com/PhilJd", "followers_url": "https://api.github.com/users/PhilJd/followers", "following_url": "https://api.github.com/users/PhilJd/following{/other_user}", "gists_url": "https://api.github.com/users/PhilJd/gists{/gist_id}", "starred_url": "https://api.github.com/users/PhilJd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PhilJd/subscriptions", "organizations_url": "https://api.github.com/users/PhilJd/orgs", "repos_url": "https://api.github.com/users/PhilJd/repos", "events_url": "https://api.github.com/users/PhilJd/events{/privacy}", "received_events_url": "https://api.github.com/users/PhilJd/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-08T16:51:53Z", "updated_at": "2017-02-09T16:32:28Z", "closed_at": "2017-02-09T16:32:28Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The segment reduction ops are currently inconsistent, they include different ops for sorted/unsorted/ and sparse/dense tensors.<br>\nI guess it would make sense to provide the same reduction ops  for these - I'd be happy to work on this and build on nikste's work.</p>\n<p>For similar previous issues <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15696327\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andydavis1\">@andydavis1</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> were responsible for reviewing, so I link you here.</p>\n<p>Things to possibly consider:</p>\n<ul>\n<li>Replace the sorted segment options by the more general unsorted options. I did a quick, non-extensive benchmark for  unsorted_segment_max vs  segment_max, the processing time is about the same (with the unsorted op even being a bit faster sometimes).<br>\nThe drawback would be, that num_segments needs to be specified or needs to be computed before the reduction.</li>\n<li>Include the feature request \"Extend tf.unsorted_segment_sum to allow 'rejecting' entries\" <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"121665076\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/478\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/478/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/478\">#478</a></li>\n<li>Address the ToDo in UnsortedSegmentMax: <code>// todo: Remove duplicate code in UnsortedSegmentSumFunctor and UnsortedSegmentMaxFunctor.</code><br>\nTo sum up, I'd suggest to replace and extend the currently provided functions</li>\n</ul>\n<pre><code>tf.segment_sum(data, segment_ids, name=None)\ntf.segment_prod(data, segment_ids, name=None)\ntf.segment_min(data, segment_ids, name=None)\ntf.segment_max(data, segment_ids, name=None)\ntf.segment_mean(data, segment_ids, name=None)\ntf.unsorted_segment_sum(data, segment_ids, num_segments, name=None)\ntf.sparse_segment_sum(data, indices, segment_ids, name=None)\ntf.sparse_segment_mean(data, indices, segment_ids, name=None)\ntf.sparse_segment_sqrt_n(data, indices, segment_ids, name=None)\n</code></pre>\n<p>with</p>\n<pre><code># all dense/sparse ops support unsorted segments\ntf.segment_sum(data, segment_ids, num_segements=None, name=None) \ntf.segment_prod(data, segment_ids, num_segements=None, name=None)\ntf.segment_min(data, segment_ids, num_segements=None, name=None)\ntf.segment_max(data, segment_ids, num_segements=None, name=None) \ntf.segment_mean(data, segment_ids, num_segements=None, name=None)\ntf.segment_sqrt_n(data, segment_ids, num_segements=None, name=None)  # new\n\ntf.sparse_segment_sum(data, indices, segment_ids, name=None)\ntf.sparse_segment_prod(data, indices, segment_ids, name=None)  # new\ntf.sparse_segment_min(data, indices, segment_ids, name=None)  # new\ntf.sparse_segment_max(data, indices, segment_ids, name=None)  # new\ntf.sparse_segment_mean(data, indices, segment_ids, name=None)\ntf.sparse_segment_sqrt_n(data, indices, segment_ids, name=None)\n</code></pre>\n<p>(Or <code>tf.unsorted_segment_reduce_op</code> instead of <code>tf.segement_reduceop</code> to not break backward compability)</p>", "body_text": "The segment reduction ops are currently inconsistent, they include different ops for sorted/unsorted/ and sparse/dense tensors.\nI guess it would make sense to provide the same reduction ops  for these - I'd be happy to work on this and build on nikste's work.\nFor similar previous issues @andydavis1, @drpngx were responsible for reviewing, so I link you here.\nThings to possibly consider:\n\nReplace the sorted segment options by the more general unsorted options. I did a quick, non-extensive benchmark for  unsorted_segment_max vs  segment_max, the processing time is about the same (with the unsorted op even being a bit faster sometimes).\nThe drawback would be, that num_segments needs to be specified or needs to be computed before the reduction.\nInclude the feature request \"Extend tf.unsorted_segment_sum to allow 'rejecting' entries\" #478\nAddress the ToDo in UnsortedSegmentMax: // todo: Remove duplicate code in UnsortedSegmentSumFunctor and UnsortedSegmentMaxFunctor.\nTo sum up, I'd suggest to replace and extend the currently provided functions\n\ntf.segment_sum(data, segment_ids, name=None)\ntf.segment_prod(data, segment_ids, name=None)\ntf.segment_min(data, segment_ids, name=None)\ntf.segment_max(data, segment_ids, name=None)\ntf.segment_mean(data, segment_ids, name=None)\ntf.unsorted_segment_sum(data, segment_ids, num_segments, name=None)\ntf.sparse_segment_sum(data, indices, segment_ids, name=None)\ntf.sparse_segment_mean(data, indices, segment_ids, name=None)\ntf.sparse_segment_sqrt_n(data, indices, segment_ids, name=None)\n\nwith\n# all dense/sparse ops support unsorted segments\ntf.segment_sum(data, segment_ids, num_segements=None, name=None) \ntf.segment_prod(data, segment_ids, num_segements=None, name=None)\ntf.segment_min(data, segment_ids, num_segements=None, name=None)\ntf.segment_max(data, segment_ids, num_segements=None, name=None) \ntf.segment_mean(data, segment_ids, num_segements=None, name=None)\ntf.segment_sqrt_n(data, segment_ids, num_segements=None, name=None)  # new\n\ntf.sparse_segment_sum(data, indices, segment_ids, name=None)\ntf.sparse_segment_prod(data, indices, segment_ids, name=None)  # new\ntf.sparse_segment_min(data, indices, segment_ids, name=None)  # new\ntf.sparse_segment_max(data, indices, segment_ids, name=None)  # new\ntf.sparse_segment_mean(data, indices, segment_ids, name=None)\ntf.sparse_segment_sqrt_n(data, indices, segment_ids, name=None)\n\n(Or tf.unsorted_segment_reduce_op instead of tf.segement_reduceop to not break backward compability)", "body": "The segment reduction ops are currently inconsistent, they include different ops for sorted/unsorted/ and sparse/dense tensors.\r\nI guess it would make sense to provide the same reduction ops  for these - I'd be happy to work on this and build on nikste's work.\r\n\r\nFor similar previous issues @andydavis1, @drpngx were responsible for reviewing, so I link you here.\r\n\r\nThings to possibly consider:\r\n- Replace the sorted segment options by the more general unsorted options. I did a quick, non-extensive benchmark for  unsorted_segment_max vs  segment_max, the processing time is about the same (with the unsorted op even being a bit faster sometimes).\r\nThe drawback would be, that num_segments needs to be specified or needs to be computed before the reduction.\r\n- Include the feature request \"Extend tf.unsorted_segment_sum to allow 'rejecting' entries\" #478\r\n- Address the ToDo in UnsortedSegmentMax: `// todo: Remove duplicate code in UnsortedSegmentSumFunctor and UnsortedSegmentMaxFunctor.`\r\nTo sum up, I'd suggest to replace and extend the currently provided functions\r\n```\r\ntf.segment_sum(data, segment_ids, name=None)\r\ntf.segment_prod(data, segment_ids, name=None)\r\ntf.segment_min(data, segment_ids, name=None)\r\ntf.segment_max(data, segment_ids, name=None)\r\ntf.segment_mean(data, segment_ids, name=None)\r\ntf.unsorted_segment_sum(data, segment_ids, num_segments, name=None)\r\ntf.sparse_segment_sum(data, indices, segment_ids, name=None)\r\ntf.sparse_segment_mean(data, indices, segment_ids, name=None)\r\ntf.sparse_segment_sqrt_n(data, indices, segment_ids, name=None)\r\n```\r\nwith \r\n```\r\n# all dense/sparse ops support unsorted segments\r\ntf.segment_sum(data, segment_ids, num_segements=None, name=None) \r\ntf.segment_prod(data, segment_ids, num_segements=None, name=None)\r\ntf.segment_min(data, segment_ids, num_segements=None, name=None)\r\ntf.segment_max(data, segment_ids, num_segements=None, name=None) \r\ntf.segment_mean(data, segment_ids, num_segements=None, name=None)\r\ntf.segment_sqrt_n(data, segment_ids, num_segements=None, name=None)  # new\r\n\r\ntf.sparse_segment_sum(data, indices, segment_ids, name=None)\r\ntf.sparse_segment_prod(data, indices, segment_ids, name=None)  # new\r\ntf.sparse_segment_min(data, indices, segment_ids, name=None)  # new\r\ntf.sparse_segment_max(data, indices, segment_ids, name=None)  # new\r\ntf.sparse_segment_mean(data, indices, segment_ids, name=None)\r\ntf.sparse_segment_sqrt_n(data, indices, segment_ids, name=None)\r\n```\r\n\r\n(Or `tf.unsorted_segment_reduce_op` instead of `tf.segement_reduceop` to not break backward compability)"}