{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269328436", "html_url": "https://github.com/tensorflow/tensorflow/issues/6519#issuecomment-269328436", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6519", "id": 269328436, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTMyODQzNg==", "user": {"login": "mxmxlwlw", "id": 7105367, "node_id": "MDQ6VXNlcjcxMDUzNjc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7105367?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mxmxlwlw", "html_url": "https://github.com/mxmxlwlw", "followers_url": "https://api.github.com/users/mxmxlwlw/followers", "following_url": "https://api.github.com/users/mxmxlwlw/following{/other_user}", "gists_url": "https://api.github.com/users/mxmxlwlw/gists{/gist_id}", "starred_url": "https://api.github.com/users/mxmxlwlw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mxmxlwlw/subscriptions", "organizations_url": "https://api.github.com/users/mxmxlwlw/orgs", "repos_url": "https://api.github.com/users/mxmxlwlw/repos", "events_url": "https://api.github.com/users/mxmxlwlw/events{/privacy}", "received_events_url": "https://api.github.com/users/mxmxlwlw/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-27T13:48:28Z", "updated_at": "2016-12-27T13:48:28Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2375962\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/inflation\">@inflation</a> I noticed that slim.learning.train has a parameter summary_writer. So I passed the tf.summary.FileWriter to it, and the warning didn't show again. However, the log still did't come up. I think the error may be in other place of my code.<br>\nHere's my code:</p>\n<p>import pickle<br>\nimport re<br>\nimport random<br>\nimport numpy as np<br>\nimport tensorflow as tf<br>\nfrom vgg_preprocessing import preprocess_image<br>\nslim = tf.contrib.slim<br>\n_R_MEAN = 123.68<br>\n_G_MEAN = 116.78<br>\n_B_MEAN = 103.94<br>\ndef vgg16Net(inputs,<br>\nnum_classes=1000,<br>\nis_training=True,<br>\ndropout_keep_prob=0.5,<br>\nspatial_squeeze=True,<br>\nscope='vgg_16'):<br>\nwith tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:<br>\nend_points_collection = sc.name + '_end_points'<br>\n# Collect outputs for conv2d, fully_connected and max_pool2d<br>\nwith slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],<br>\noutputs_collections=end_points_collection):<br>\nnet = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')<br>\nnet = slim.max_pool2d(net, [2, 2], scope='pool1')<br>\nnet = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')<br>\nnet = slim.max_pool2d(net, [2, 2], scope='pool2')<br>\nnet = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')<br>\nnet = slim.max_pool2d(net, [2, 2], scope='pool3')<br>\nnet = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')<br>\nnet = slim.max_pool2d(net, [2, 2], scope='pool4')<br>\nnet = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')<br>\nnet = slim.max_pool2d(net, [2, 2], scope='pool5')<br>\n# Use conv2d instead of fully_connected layers.<br>\nnet = slim.conv2d(net, 4096, [7, 10], padding='VALID', scope='fc6')<br>\nnet = slim.dropout(net, dropout_keep_prob, is_training=is_training,<br>\nscope='dropout6')<br>\nnet = slim.conv2d(net, 4096, [1, 1], scope='fc7')<br>\nnet = slim.dropout(net, dropout_keep_prob, is_training=is_training,<br>\nscope='dropout7')<br>\nnet = slim.conv2d(net, num_classes, [1, 1],<br>\nactivation_fn=None,<br>\nnormalizer_fn=None,<br>\nscope='fc8')<br>\n# Convert end_points_collection into a end_point dict.<br>\nend_points = slim.utils.convert_collection_to_dict(end_points_collection)<br>\nif spatial_squeeze:<br>\nnet = tf.squeeze(net, [1, 2], name='fc8/squeezed')<br>\nend_points[sc.name + '/fc8'] = net<br>\nreturn net, end_points</p>\n<p>def getsamples():<br>\nrootpath = 'C:\\Users\\mx\\Desktop\\nextLevel\\UCF-101'<br>\nwith open('res.pickle', 'rb') as f:<br>\npathdict = pickle.load(f)<br>\nwith open('trainlist01.txt', 'r') as f:<br>\nlines=f.readlines()<br>\nsamples_all=[]<br>\nlabels_all=[]<br>\nfor line in lines:<br>\n[videogroup, video, label]=re.split('/| |\\n', line)[0:3]<br>\nsamples = [rootpath + '\\' + videogroup + '\\' + video[:-4] + '\\' + i for i in pathdict[videogroup][video]]<br>\nsamples_all.extend(samples)<br>\nlabels_all.extend([label]*len(samples))<br>\nreturn samples_all, labels_all</p>\n<p>samples_all, labels_all = getsamples()</p>\n<p>labels_one_hot_all = np.zeros((len(labels_all), 101))<br>\nindex_offset = np.arange(len(labels_all))*101<br>\nind = index_offset + np.array(labels_all, np.int32) - 1<br>\nlabels_one_hot_all.flat[ind]=1<br>\n#samples_all = tf.constant(samples_all)<br>\n#labels_all = tf.constant(labels_all)<br>\n[sample, label] = tf.train.slice_input_producer([samples_all, labels_one_hot_all])<br>\nimagecontent = tf.read_file(sample)<br>\nimage = tf.image.decode_jpeg(imagecontent, channels=3)<br>\nimage = tf.cast(image, dtype = tf.float32)<br>\nchannels = tf.split(2, 3, image)<br>\nchannels[0] -= _R_MEAN<br>\nchannels[1] -= _G_MEAN<br>\nchannels[2] -= _B_MEAN<br>\nimage=tf.concat(2, channels)<br>\nimage=tf.reshape(image, [240, 320, 3])<br>\nimages, labels = tf.train.batch([image, label], 16, 4, 64)<br>\nnet, end = vgg16Net(images, num_classes = 101, is_training=True)</p>\n<p>slim.losses.softmax_cross_entropy(net, labels)<br>\ntotal_loss = slim.losses.get_total_loss()<br>\nlearning_rate = 0.001<br>\noptimizer=slim.train.GradientDescentOptimizer(learning_rate)<br>\ntrain_var = slim.get_variables_to_restore(exclude = ['vgg_16/conv1', 'vgg_16/conv2', 'vgg_16/conv2', 'vgg_16/conv3', 'vgg_16/conv4', 'vgg_16/conv5']);<br>\ntrain_op=slim.learning.create_train_op(total_loss, optimizer, variables_to_train = train_var)<br>\nmodel_store_dir = './log/'<br>\ninit_var = slim.get_variables_to_restore(exclude = ['vgg_16/fc6', 'vgg_16/fc7', 'vgg_16/fc8'])<br>\ninit_fn = slim.assign_from_checkpoint_fn('./vgg_16.ckpt', init_var)</p>\n<p>summaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))<br>\nfor end_point in end:<br>\nx=end[end_point]<br>\nsummaries.add(tf.summary.histogram('activations/' + end_point, x))<br>\nsummaries.add(tf.summary.scalar('sparsity/' + end_point, tf.nn.zero_fraction(x)))</p>\n<p>for loss in tf.get_collection(tf.GraphKeys.LOSSES):<br>\nsummaries.add(tf.summary.scalar('losses/%s' % loss.op.name, loss))</p>\n<p>for variable in slim.get_model_variables():<br>\nsummaries.add(tf.summary.histogram(variable.op.name, variable))</p>\n<p>summaries.add(tf.summary.scalar('learning_rate', learning_rate))</p>\n<p>summaries.add(tf.summary.scalar('total_loss', total_loss))</p>\n<p>#summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES))</p>\n<p>summary_op = tf.summary.merge(list(summaries))</p>\n<p>summary_writer = tf.summary.FileWriter(model_store_dir)<br>\nslim.learning.train(train_op,<br>\nmodel_store_dir,<br>\ninit_fn = init_fn,<br>\nsummary_op=summary_op,<br>\nsummary_writer=summary_writer,<br>\nnumber_of_steps=100000,<br>\nsave_summaries_secs=300,<br>\nsave_interval_secs=600)</p>", "body_text": "@inflation I noticed that slim.learning.train has a parameter summary_writer. So I passed the tf.summary.FileWriter to it, and the warning didn't show again. However, the log still did't come up. I think the error may be in other place of my code.\nHere's my code:\nimport pickle\nimport re\nimport random\nimport numpy as np\nimport tensorflow as tf\nfrom vgg_preprocessing import preprocess_image\nslim = tf.contrib.slim\n_R_MEAN = 123.68\n_G_MEAN = 116.78\n_B_MEAN = 103.94\ndef vgg16Net(inputs,\nnum_classes=1000,\nis_training=True,\ndropout_keep_prob=0.5,\nspatial_squeeze=True,\nscope='vgg_16'):\nwith tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\nend_points_collection = sc.name + '_end_points'\n# Collect outputs for conv2d, fully_connected and max_pool2d\nwith slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\noutputs_collections=end_points_collection):\nnet = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\nnet = slim.max_pool2d(net, [2, 2], scope='pool1')\nnet = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\nnet = slim.max_pool2d(net, [2, 2], scope='pool2')\nnet = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\nnet = slim.max_pool2d(net, [2, 2], scope='pool3')\nnet = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\nnet = slim.max_pool2d(net, [2, 2], scope='pool4')\nnet = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\nnet = slim.max_pool2d(net, [2, 2], scope='pool5')\n# Use conv2d instead of fully_connected layers.\nnet = slim.conv2d(net, 4096, [7, 10], padding='VALID', scope='fc6')\nnet = slim.dropout(net, dropout_keep_prob, is_training=is_training,\nscope='dropout6')\nnet = slim.conv2d(net, 4096, [1, 1], scope='fc7')\nnet = slim.dropout(net, dropout_keep_prob, is_training=is_training,\nscope='dropout7')\nnet = slim.conv2d(net, num_classes, [1, 1],\nactivation_fn=None,\nnormalizer_fn=None,\nscope='fc8')\n# Convert end_points_collection into a end_point dict.\nend_points = slim.utils.convert_collection_to_dict(end_points_collection)\nif spatial_squeeze:\nnet = tf.squeeze(net, [1, 2], name='fc8/squeezed')\nend_points[sc.name + '/fc8'] = net\nreturn net, end_points\ndef getsamples():\nrootpath = 'C:\\Users\\mx\\Desktop\\nextLevel\\UCF-101'\nwith open('res.pickle', 'rb') as f:\npathdict = pickle.load(f)\nwith open('trainlist01.txt', 'r') as f:\nlines=f.readlines()\nsamples_all=[]\nlabels_all=[]\nfor line in lines:\n[videogroup, video, label]=re.split('/| |\\n', line)[0:3]\nsamples = [rootpath + '\\' + videogroup + '\\' + video[:-4] + '\\' + i for i in pathdict[videogroup][video]]\nsamples_all.extend(samples)\nlabels_all.extend([label]*len(samples))\nreturn samples_all, labels_all\nsamples_all, labels_all = getsamples()\nlabels_one_hot_all = np.zeros((len(labels_all), 101))\nindex_offset = np.arange(len(labels_all))*101\nind = index_offset + np.array(labels_all, np.int32) - 1\nlabels_one_hot_all.flat[ind]=1\n#samples_all = tf.constant(samples_all)\n#labels_all = tf.constant(labels_all)\n[sample, label] = tf.train.slice_input_producer([samples_all, labels_one_hot_all])\nimagecontent = tf.read_file(sample)\nimage = tf.image.decode_jpeg(imagecontent, channels=3)\nimage = tf.cast(image, dtype = tf.float32)\nchannels = tf.split(2, 3, image)\nchannels[0] -= _R_MEAN\nchannels[1] -= _G_MEAN\nchannels[2] -= _B_MEAN\nimage=tf.concat(2, channels)\nimage=tf.reshape(image, [240, 320, 3])\nimages, labels = tf.train.batch([image, label], 16, 4, 64)\nnet, end = vgg16Net(images, num_classes = 101, is_training=True)\nslim.losses.softmax_cross_entropy(net, labels)\ntotal_loss = slim.losses.get_total_loss()\nlearning_rate = 0.001\noptimizer=slim.train.GradientDescentOptimizer(learning_rate)\ntrain_var = slim.get_variables_to_restore(exclude = ['vgg_16/conv1', 'vgg_16/conv2', 'vgg_16/conv2', 'vgg_16/conv3', 'vgg_16/conv4', 'vgg_16/conv5']);\ntrain_op=slim.learning.create_train_op(total_loss, optimizer, variables_to_train = train_var)\nmodel_store_dir = './log/'\ninit_var = slim.get_variables_to_restore(exclude = ['vgg_16/fc6', 'vgg_16/fc7', 'vgg_16/fc8'])\ninit_fn = slim.assign_from_checkpoint_fn('./vgg_16.ckpt', init_var)\nsummaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))\nfor end_point in end:\nx=end[end_point]\nsummaries.add(tf.summary.histogram('activations/' + end_point, x))\nsummaries.add(tf.summary.scalar('sparsity/' + end_point, tf.nn.zero_fraction(x)))\nfor loss in tf.get_collection(tf.GraphKeys.LOSSES):\nsummaries.add(tf.summary.scalar('losses/%s' % loss.op.name, loss))\nfor variable in slim.get_model_variables():\nsummaries.add(tf.summary.histogram(variable.op.name, variable))\nsummaries.add(tf.summary.scalar('learning_rate', learning_rate))\nsummaries.add(tf.summary.scalar('total_loss', total_loss))\n#summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES))\nsummary_op = tf.summary.merge(list(summaries))\nsummary_writer = tf.summary.FileWriter(model_store_dir)\nslim.learning.train(train_op,\nmodel_store_dir,\ninit_fn = init_fn,\nsummary_op=summary_op,\nsummary_writer=summary_writer,\nnumber_of_steps=100000,\nsave_summaries_secs=300,\nsave_interval_secs=600)", "body": "@inflation I noticed that slim.learning.train has a parameter summary_writer. So I passed the tf.summary.FileWriter to it, and the warning didn't show again. However, the log still did't come up. I think the error may be in other place of my code.\r\nHere's my code:\r\n\r\nimport pickle\r\nimport re\r\nimport random\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom vgg_preprocessing import preprocess_image\r\nslim = tf.contrib.slim\r\n_R_MEAN = 123.68\r\n_G_MEAN = 116.78\r\n_B_MEAN = 103.94\r\ndef vgg16Net(inputs,\r\n           num_classes=1000,\r\n           is_training=True,\r\n           dropout_keep_prob=0.5,\r\n           spatial_squeeze=True,\r\n           scope='vgg_16'):\r\n    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\r\n        end_points_collection = sc.name + '_end_points'\r\n        # Collect outputs for conv2d, fully_connected and max_pool2d\r\n        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\r\n                            outputs_collections=end_points_collection):\r\n          net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool1')\r\n          net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool2')\r\n          net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool3')\r\n          net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool4')\r\n          net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool5')\r\n          # Use conv2d instead of fully_connected layers.\r\n          net = slim.conv2d(net, 4096, [7, 10], padding='VALID', scope='fc6')\r\n          net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\r\n                             scope='dropout6')\r\n          net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\r\n          net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\r\n                             scope='dropout7')\r\n          net = slim.conv2d(net, num_classes, [1, 1],\r\n                            activation_fn=None,\r\n                            normalizer_fn=None,\r\n                            scope='fc8')\r\n          # Convert end_points_collection into a end_point dict.\r\n          end_points = slim.utils.convert_collection_to_dict(end_points_collection)\r\n          if spatial_squeeze:\r\n            net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\r\n            end_points[sc.name + '/fc8'] = net\r\n          return net, end_points\r\n\r\ndef getsamples():\r\n    rootpath = 'C:\\\\Users\\\\mx\\\\Desktop\\\\nextLevel\\\\UCF-101'\r\n    with open('res.pickle', 'rb') as f:\r\n        pathdict = pickle.load(f)\r\n    with open('trainlist01.txt', 'r') as f:\r\n        lines=f.readlines()\r\n    samples_all=[]\r\n    labels_all=[]\r\n    for line in lines:\r\n        [videogroup, video, label]=re.split('/| |\\n', line)[0:3]\r\n        samples = [rootpath + '\\\\' + videogroup + '\\\\' + video[:-4] + '\\\\' + i for i in pathdict[videogroup][video]]\r\n        samples_all.extend(samples)\r\n        labels_all.extend([label]*len(samples))\r\n    return samples_all, labels_all\r\n\r\nsamples_all, labels_all = getsamples()\r\n\r\nlabels_one_hot_all = np.zeros((len(labels_all), 101))\r\nindex_offset = np.arange(len(labels_all))*101\r\nind = index_offset + np.array(labels_all, np.int32) - 1\r\nlabels_one_hot_all.flat[ind]=1\r\n#samples_all = tf.constant(samples_all)\r\n#labels_all = tf.constant(labels_all)\r\n[sample, label] = tf.train.slice_input_producer([samples_all, labels_one_hot_all])\r\nimagecontent = tf.read_file(sample)\r\nimage = tf.image.decode_jpeg(imagecontent, channels=3)\r\nimage = tf.cast(image, dtype = tf.float32)\r\nchannels = tf.split(2, 3, image)\r\nchannels[0] -= _R_MEAN\r\nchannels[1] -= _G_MEAN\r\nchannels[2] -= _B_MEAN\r\nimage=tf.concat(2, channels)\r\nimage=tf.reshape(image, [240, 320, 3])\r\nimages, labels = tf.train.batch([image, label], 16, 4, 64)\r\nnet, end = vgg16Net(images, num_classes = 101, is_training=True)\r\n\r\nslim.losses.softmax_cross_entropy(net, labels)\r\ntotal_loss = slim.losses.get_total_loss()\r\nlearning_rate = 0.001\r\noptimizer=slim.train.GradientDescentOptimizer(learning_rate)\r\ntrain_var = slim.get_variables_to_restore(exclude = ['vgg_16/conv1', 'vgg_16/conv2', 'vgg_16/conv2', 'vgg_16/conv3', 'vgg_16/conv4', 'vgg_16/conv5']);\r\ntrain_op=slim.learning.create_train_op(total_loss, optimizer, variables_to_train = train_var)\r\nmodel_store_dir = './log/'\r\ninit_var = slim.get_variables_to_restore(exclude = ['vgg_16/fc6', 'vgg_16/fc7', 'vgg_16/fc8'])\r\ninit_fn = slim.assign_from_checkpoint_fn('./vgg_16.ckpt', init_var)\r\n\r\nsummaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))\r\nfor end_point in end:\r\n    x=end[end_point]\r\n    summaries.add(tf.summary.histogram('activations/' + end_point, x))\r\n    summaries.add(tf.summary.scalar('sparsity/' + end_point, tf.nn.zero_fraction(x)))\r\n\r\nfor loss in tf.get_collection(tf.GraphKeys.LOSSES):\r\n    summaries.add(tf.summary.scalar('losses/%s' % loss.op.name, loss))\r\n\r\nfor variable in slim.get_model_variables():\r\n    summaries.add(tf.summary.histogram(variable.op.name, variable))\r\n\r\nsummaries.add(tf.summary.scalar('learning_rate', learning_rate))\r\n\r\nsummaries.add(tf.summary.scalar('total_loss', total_loss))\r\n\r\n#summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES))\r\n\r\nsummary_op = tf.summary.merge(list(summaries))\r\n\r\nsummary_writer = tf.summary.FileWriter(model_store_dir)\r\nslim.learning.train(train_op, \r\n    model_store_dir, \r\n    init_fn = init_fn,\r\n    summary_op=summary_op,\r\n    summary_writer=summary_writer,\r\n    number_of_steps=100000,\r\n    save_summaries_secs=300, \r\n    save_interval_secs=600)\r\n"}