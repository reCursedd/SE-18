{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294087892", "html_url": "https://github.com/tensorflow/tensorflow/issues/9072#issuecomment-294087892", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9072", "id": 294087892, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDA4Nzg5Mg==", "user": {"login": "udnaan", "id": 7927822, "node_id": "MDQ6VXNlcjc5Mjc4MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/7927822?v=4", "gravatar_id": "", "url": "https://api.github.com/users/udnaan", "html_url": "https://github.com/udnaan", "followers_url": "https://api.github.com/users/udnaan/followers", "following_url": "https://api.github.com/users/udnaan/following{/other_user}", "gists_url": "https://api.github.com/users/udnaan/gists{/gist_id}", "starred_url": "https://api.github.com/users/udnaan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/udnaan/subscriptions", "organizations_url": "https://api.github.com/users/udnaan/orgs", "repos_url": "https://api.github.com/users/udnaan/repos", "events_url": "https://api.github.com/users/udnaan/events{/privacy}", "received_events_url": "https://api.github.com/users/udnaan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-14T04:36:48Z", "updated_at": "2017-04-14T04:36:48Z", "author_association": "NONE", "body_html": "<p>Same here. Here is the ./configure output</p>\n<pre><code>Please specify the location of python. [Default is /usr/local/bin/python]: /usr/local/bin/python3\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] y\nGoogle Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]\nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] y\nXLA JIT support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages]\n\nUsing python library path: /usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\nDo you wish to build TensorFlow with OpenCL support? [y/N]\nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N] y\nClang will be used as CUDA compiler\nPlease specify which clang should be used as device and host compiler. [Default is /usr/bin/clang]:\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify the cuDNN version you want to use. [Leave empty to use system default]: 5\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: 6.1\n............\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\nConfiguration finished\n</code></pre>", "body_text": "Same here. Here is the ./configure output\nPlease specify the location of python. [Default is /usr/local/bin/python]: /usr/local/bin/python3\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] y\nGoogle Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]\nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] y\nXLA JIT support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages]\n\nUsing python library path: /usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\nDo you wish to build TensorFlow with OpenCL support? [y/N]\nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N] y\nClang will be used as CUDA compiler\nPlease specify which clang should be used as device and host compiler. [Default is /usr/bin/clang]:\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify the cuDNN version you want to use. [Leave empty to use system default]: 5\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: 6.1\n............\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\nConfiguration finished", "body": "Same here. Here is the ./configure output\r\n```\r\nPlease specify the location of python. [Default is /usr/local/bin/python]: /usr/local/bin/python3\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] y\r\nGoogle Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]\r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] y\r\nXLA JIT support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages]\r\n\r\nUsing python library path: /usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nDo you want to use clang as CUDA compiler? [y/N] y\r\nClang will be used as CUDA compiler\r\nPlease specify which clang should be used as device and host compiler. [Default is /usr/bin/clang]:\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify the cuDNN version you want to use. [Leave empty to use system default]: 5\r\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.1\r\n............\r\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\r\nConfiguration finished\r\n```"}