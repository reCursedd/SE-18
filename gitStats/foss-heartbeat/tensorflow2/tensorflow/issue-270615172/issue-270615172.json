{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14181", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14181/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14181/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14181/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14181", "id": 270615172, "node_id": "MDU6SXNzdWUyNzA2MTUxNzI=", "number": 14181, "title": "Tensorflow or python having memory cleanup issues when using multiple models in iterative loop", "user": {"login": "JulianStier", "id": 564436, "node_id": "MDQ6VXNlcjU2NDQzNg==", "avatar_url": "https://avatars2.githubusercontent.com/u/564436?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JulianStier", "html_url": "https://github.com/JulianStier", "followers_url": "https://api.github.com/users/JulianStier/followers", "following_url": "https://api.github.com/users/JulianStier/following{/other_user}", "gists_url": "https://api.github.com/users/JulianStier/gists{/gist_id}", "starred_url": "https://api.github.com/users/JulianStier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JulianStier/subscriptions", "organizations_url": "https://api.github.com/users/JulianStier/orgs", "repos_url": "https://api.github.com/users/JulianStier/repos", "events_url": "https://api.github.com/users/JulianStier/events{/privacy}", "received_events_url": "https://api.github.com/users/JulianStier/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2017-11-02T11:11:28Z", "updated_at": "2018-01-26T01:19:36Z", "closed_at": "2018-01-26T01:19:36Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>: yes</li>\n<li><strong>OS Platform and Distribution</strong>: Linux Ubuntu 17.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version</strong>: v1.3.0-rc2-20-g0787eee 1.3.0</li>\n<li><strong>Python version</strong>: Python 3.6.1 :: Anaconda 4.4.0 (64-bit)</li>\n<li><strong>CUDA/cuDNN version</strong>: none</li>\n<li><strong>GPU model and memory</strong>: none</li>\n</ul>\n<p>== cat /etc/issue ===============================================<br>\nLinux Bragi 4.10.0-37-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115969727\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/41\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/41/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/41\">#41</a>-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"17.04 (Zesty Zapus)\"<br>\nVERSION_ID=\"17.04\"<br>\nVERSION_CODENAME=zesty</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 6.3.0-12ubuntu2) 6.3.0 20170406<br>\nCopyright (C) 2016 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux Bragi 4.10.0-37-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115969727\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/41\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/41/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/41\">#41</a>-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy (1.12.1)<br>\nnumpydoc (0.6.0)<br>\nprotobuf (3.4.0)<br>\ntensorflow (1.3.0)<br>\ntensorflow-tensorboard (0.1.8)</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.3.0<br>\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee<br>\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH is unset<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\n./tf_env_collect.sh: line 105: nvidia-smi: command not found</p>\n<h3>Describe the problem</h3>\n<p>I am working on a tensorflow model which takes pretty much RAM. It is executed iteratively to process given tasks.</p>\n<p>However, with increasing time the whole process starts consuming more and more RAM although it should clean it up. This sounds like as if I'd keep data of one graph over the iterations, but I am almost sure that the graphs are cleanly separated.</p>\n<h2>Problem</h2>\n<p>I reduced the code to the following:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nreps = 30\nfor i in range(reps):\n    with tf.Graph().as_default() as graph:\n        with tf.Session(graph=graph) as sess:\n            tf.constant(np.random.random((1000,1000,200,1)))\n</code></pre>\n<p>I have 32GB RAM available, working on a ubuntu 17.04 with CPU Tensorflow 1.3. This will give following error message after about the 25th or 27th iteration:</p>\n<blockquote>\n<p>terminate called after throwing an instance of 'std::bad_alloc'<br>\nwhat():  std::bad_alloc</p>\n</blockquote>\n<p>Giving the process some time after each iteration results in no improvement:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport time\n\nreps = 30\nfor i in range(reps):\n    with tf.Graph().as_default() as graph:\n        with tf.Session(graph=graph) as sess:\n            tf.constant(np.random.random((1000,1000,200,1)))\n    time.sleep(1)\n</code></pre>\n<p>However, it works if I force garbage collection invocation after each repetition:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport gc\n\nreps = 30\nfor i in range(reps):\n    with tf.Graph().as_default() as graph:\n        with tf.Session(graph=graph) as sess:\n            tf.constant(np.random.random((1000,1000,200,1)))\n    gc.collect()\n</code></pre>\n<h2>Question</h2>\n<p>Now I wonder why I need to force garbage collection to run even though tensorflow should have closed the session and de-referenced the graph object.</p>\n<p>Back to my original model I am not sure, yet, if the gc invocation actually helps. The memory usage grows pretty intense, especially when I am about to persist the model to disk.</p>\n<p>Thanks for any insights.</p>", "body_text": "System information\n\nHave I written custom code: yes\nOS Platform and Distribution: Linux Ubuntu 17.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version: v1.3.0-rc2-20-g0787eee 1.3.0\nPython version: Python 3.6.1 :: Anaconda 4.4.0 (64-bit)\nCUDA/cuDNN version: none\nGPU model and memory: none\n\n== cat /etc/issue ===============================================\nLinux Bragi 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"17.04 (Zesty Zapus)\"\nVERSION_ID=\"17.04\"\nVERSION_CODENAME=zesty\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 6.3.0-12ubuntu2) 6.3.0 20170406\nCopyright (C) 2016 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux Bragi 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy (1.12.1)\nnumpydoc (0.6.0)\nprotobuf (3.4.0)\ntensorflow (1.3.0)\ntensorflow-tensorboard (0.1.8)\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.3.0\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\n./tf_env_collect.sh: line 105: nvidia-smi: command not found\nDescribe the problem\nI am working on a tensorflow model which takes pretty much RAM. It is executed iteratively to process given tasks.\nHowever, with increasing time the whole process starts consuming more and more RAM although it should clean it up. This sounds like as if I'd keep data of one graph over the iterations, but I am almost sure that the graphs are cleanly separated.\nProblem\nI reduced the code to the following:\nimport tensorflow as tf\nimport numpy as np\n\nreps = 30\nfor i in range(reps):\n    with tf.Graph().as_default() as graph:\n        with tf.Session(graph=graph) as sess:\n            tf.constant(np.random.random((1000,1000,200,1)))\n\nI have 32GB RAM available, working on a ubuntu 17.04 with CPU Tensorflow 1.3. This will give following error message after about the 25th or 27th iteration:\n\nterminate called after throwing an instance of 'std::bad_alloc'\nwhat():  std::bad_alloc\n\nGiving the process some time after each iteration results in no improvement:\nimport tensorflow as tf\nimport numpy as np\nimport time\n\nreps = 30\nfor i in range(reps):\n    with tf.Graph().as_default() as graph:\n        with tf.Session(graph=graph) as sess:\n            tf.constant(np.random.random((1000,1000,200,1)))\n    time.sleep(1)\n\nHowever, it works if I force garbage collection invocation after each repetition:\nimport tensorflow as tf\nimport numpy as np\nimport gc\n\nreps = 30\nfor i in range(reps):\n    with tf.Graph().as_default() as graph:\n        with tf.Session(graph=graph) as sess:\n            tf.constant(np.random.random((1000,1000,200,1)))\n    gc.collect()\n\nQuestion\nNow I wonder why I need to force garbage collection to run even though tensorflow should have closed the session and de-referenced the graph object.\nBack to my original model I am not sure, yet, if the gc invocation actually helps. The memory usage grows pretty intense, especially when I am about to persist the model to disk.\nThanks for any insights.", "body": "### System information\r\n- **Have I written custom code**: yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 17.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: Python 3.6.1 :: Anaconda 4.4.0 (64-bit)\r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n\r\n== cat /etc/issue ===============================================\r\nLinux Bragi 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"17.04 (Zesty Zapus)\"\r\nVERSION_ID=\"17.04\"\r\nVERSION_CODENAME=zesty\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 6.3.0-12ubuntu2) 6.3.0 20170406\r\nCopyright (C) 2016 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux Bragi 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.1)\r\nnumpydoc (0.6.0)\r\nprotobuf (3.4.0)\r\ntensorflow (1.3.0)\r\ntensorflow-tensorboard (0.1.8)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\r\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n\r\n### Describe the problem\r\nI am working on a tensorflow model which takes pretty much RAM. It is executed iteratively to process given tasks.\r\n\r\nHowever, with increasing time the whole process starts consuming more and more RAM although it should clean it up. This sounds like as if I'd keep data of one graph over the iterations, but I am almost sure that the graphs are cleanly separated.\r\n\r\nProblem\r\n-------\r\nI reduced the code to the following:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n\r\n    reps = 30\r\n    for i in range(reps):\r\n        with tf.Graph().as_default() as graph:\r\n            with tf.Session(graph=graph) as sess:\r\n                tf.constant(np.random.random((1000,1000,200,1)))\r\n\r\nI have 32GB RAM available, working on a ubuntu 17.04 with CPU Tensorflow 1.3. This will give following error message after about the 25th or 27th iteration:\r\n\r\n> terminate called after throwing an instance of 'std::bad_alloc'\r\n  what():  std::bad_alloc\r\n\r\nGiving the process some time after each iteration results in no improvement:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    import time\r\n\r\n    reps = 30\r\n    for i in range(reps):\r\n        with tf.Graph().as_default() as graph:\r\n            with tf.Session(graph=graph) as sess:\r\n                tf.constant(np.random.random((1000,1000,200,1)))\r\n        time.sleep(1)\r\n\r\nHowever, it works if I force garbage collection invocation after each repetition:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    import gc\r\n\r\n    reps = 30\r\n    for i in range(reps):\r\n        with tf.Graph().as_default() as graph:\r\n            with tf.Session(graph=graph) as sess:\r\n                tf.constant(np.random.random((1000,1000,200,1)))\r\n        gc.collect()\r\n\r\nQuestion\r\n--------\r\nNow I wonder why I need to force garbage collection to run even though tensorflow should have closed the session and de-referenced the graph object.\r\n\r\nBack to my original model I am not sure, yet, if the gc invocation actually helps. The memory usage grows pretty intense, especially when I am about to persist the model to disk.\r\n\r\nThanks for any insights.\r\n"}