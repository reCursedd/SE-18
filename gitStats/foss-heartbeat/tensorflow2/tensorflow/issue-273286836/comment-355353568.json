{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/355353568", "html_url": "https://github.com/tensorflow/tensorflow/issues/14506#issuecomment-355353568", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14506", "id": 355353568, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTM1MzU2OA==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-04T18:00:25Z", "updated_at": "2018-01-04T18:00:25Z", "author_association": "MEMBER", "body_html": "<p>Now that we can compile <code>tf.while_loop</code>s with a fixed upper bound on the <em>max</em> number of iterations we can easily change <code>dynamic_rnn</code> to iterate only over the valid input data.  This change is pretty trivial (i.e. one line) and in progress but we wanted to test it separately since we don't want to break and existing users.</p>\n<p><code>dynamic_rnn</code>s wlth <strong>padded</strong> input data then have performance that is proportional to the max sequence length in the minibatch.  The <em>memory</em> usage for gradients will still be proportional to the padded input size, but this should't usually matter too much in most cases.</p>\n<p>Bidirectional rnns should also be doable, but we need to implement a translation of the <code>ReverseSequence</code> op for XLA and that turns out to be a bit ugly ;-)</p>", "body_text": "Now that we can compile tf.while_loops with a fixed upper bound on the max number of iterations we can easily change dynamic_rnn to iterate only over the valid input data.  This change is pretty trivial (i.e. one line) and in progress but we wanted to test it separately since we don't want to break and existing users.\ndynamic_rnns wlth padded input data then have performance that is proportional to the max sequence length in the minibatch.  The memory usage for gradients will still be proportional to the padded input size, but this should't usually matter too much in most cases.\nBidirectional rnns should also be doable, but we need to implement a translation of the ReverseSequence op for XLA and that turns out to be a bit ugly ;-)", "body": "Now that we can compile `tf.while_loop`s with a fixed upper bound on the *max* number of iterations we can easily change `dynamic_rnn` to iterate only over the valid input data.  This change is pretty trivial (i.e. one line) and in progress but we wanted to test it separately since we don't want to break and existing users.\r\n\r\n`dynamic_rnn`s wlth **padded** input data then have performance that is proportional to the max sequence length in the minibatch.  The _memory_ usage for gradients will still be proportional to the padded input size, but this should't usually matter too much in most cases.\r\n\r\nBidirectional rnns should also be doable, but we need to implement a translation of the `ReverseSequence` op for XLA and that turns out to be a bit ugly ;-)"}