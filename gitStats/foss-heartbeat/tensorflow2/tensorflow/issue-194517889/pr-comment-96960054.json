{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/96960054", "pull_request_review_id": 17533815, "id": 96960054, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk2OTYwMDU0", "diff_hunk": "@@ -0,0 +1,1455 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#include <math.h>\n+#include <stdio.h>\n+#include <algorithm>\n+\n+#if GOOGLE_CUDA\n+#define EIGEN_USE_GPU\n+\n+#include \"./layer_norm_fused_op.h\"\n+#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n+#if !defined(_MSC_VER)\n+#define UNROLL _Pragma(\"unroll\")\n+#else\n+#define UNROLL\n+#endif\n+\n+#if !defined(__CUDA_ARCH__) || __CUDA_ARCH__ >= 600\n+#else\n+__device__ double atomicAdd(double* a, double b) { return b; }\n+#endif\n+\n+#define MAX_GRID_SIZE 480\n+inline int get_num_blocks(const int n_slices, const int slice_per_block) {\n+  const int _num_blocks = n_slices / slice_per_block;\n+  if (_num_blocks * slice_per_block == n_slices)\n+    return _num_blocks;\n+  else\n+    return _num_blocks + 1;\n+}\n+\n+inline int get_block_size(const int slice_size, int& block_size, int& mult) {\n+  const int _warp_size = 32;\n+  int _block_size = _warp_size;\n+  int _mult = slice_size / _block_size;\n+  mult = _mult * _block_size >= slice_size ? _mult : _mult + 1;\n+  while (mult > 5) {\n+    _block_size += _warp_size;\n+    _mult = slice_size / _block_size;\n+    mult = _mult * _block_size >= slice_size ? _mult : _mult + 1;\n+  }\n+  block_size = _block_size;\n+  return 0;\n+}\n+\n+template <typename T>\n+__global__ void fillZeros(T* __restrict__ output, const int n_inputs) {\n+  for (int thread_id = threadIdx.x + blockDim.x * blockIdx.x;\n+       thread_id < n_inputs; thread_id += blockDim.x * gridDim.x)\n+    output[thread_id] = static_cast<T>(0.0f);\n+}\n+\n+template <typename T>\n+__device__ __inline__ void warpSum(T& val1, T& val2) {\n+  val1 += __shfl_xor(val1, 16);\n+  val2 += __shfl_xor(val2, 16);\n+  val1 += __shfl_xor(val1, 8);\n+  val2 += __shfl_xor(val2, 8);\n+  val1 += __shfl_xor(val1, 4);\n+  val2 += __shfl_xor(val2, 4);\n+  val1 += __shfl_xor(val1, 2);\n+  val2 += __shfl_xor(val2, 2);\n+  val1 += __shfl_xor(val1, 1);\n+  val2 += __shfl_xor(val2, 1);\n+}\n+\n+template <typename T>\n+__device__ __inline__ T get_value(const T* index, const int bound_check,\n+                                  const int up_bound) {\n+  if (bound_check < up_bound)\n+    return __ldg(index);\n+  else\n+    return static_cast<T>(0.0f);\n+}\n+\n+namespace tensorflow {\n+\n+namespace {\n+\n+typedef Eigen::GpuDevice GPUDevice;\n+\n+template <typename T, int mult>\n+__global__ void LayerNormGPUKernel(const LayerNormFusedArgs args,", "path": "tensorflow/contrib/layers/kernels/layer_norm_fused_op_gpu.cu.cc", "position": null, "original_position": 96, "commit_id": "c956265da134875e8e79bc12cc2223deaceea87c", "original_commit_id": "6fd112700dabe27bb85c3d35eca59c971d7ff985", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "body": "We also need a python or C++ benchmarks so the efficiency of this kernel for typical sizes. ", "created_at": "2017-01-19T21:17:37Z", "updated_at": "2017-03-09T00:28:35Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/6205#discussion_r96960054", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6205", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/96960054"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/6205#discussion_r96960054"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6205"}}, "body_html": "<p>We also need a python or C++ benchmarks so the efficiency of this kernel for typical sizes.</p>", "body_text": "We also need a python or C++ benchmarks so the efficiency of this kernel for typical sizes."}