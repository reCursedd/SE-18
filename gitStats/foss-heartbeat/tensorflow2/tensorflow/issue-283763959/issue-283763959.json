{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15538", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15538/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15538/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15538/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15538", "id": 283763959, "node_id": "MDU6SXNzdWUyODM3NjM5NTk=", "number": 15538, "title": "[solved]session->Create(graph_def) No OpKernel was registered to support Op 'RandomUniform'", "user": {"login": "eigen2017", "id": 33959526, "node_id": "MDQ6VXNlcjMzOTU5NTI2", "avatar_url": "https://avatars3.githubusercontent.com/u/33959526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eigen2017", "html_url": "https://github.com/eigen2017", "followers_url": "https://api.github.com/users/eigen2017/followers", "following_url": "https://api.github.com/users/eigen2017/following{/other_user}", "gists_url": "https://api.github.com/users/eigen2017/gists{/gist_id}", "starred_url": "https://api.github.com/users/eigen2017/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eigen2017/subscriptions", "organizations_url": "https://api.github.com/users/eigen2017/orgs", "repos_url": "https://api.github.com/users/eigen2017/repos", "events_url": "https://api.github.com/users/eigen2017/events{/privacy}", "received_events_url": "https://api.github.com/users/eigen2017/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-12-21T03:35:22Z", "updated_at": "2017-12-22T03:13:54Z", "closed_at": "2017-12-21T18:43:29Z", "author_association": "NONE", "body_html": "<p>issue: crashes when loading pb file in C++ program:</p>\n<blockquote>\n<pre><code>Session * session;\nGraphDef graph_def;\nSessionOptions opts;\nTF_CHECK_OK(ReadBinaryProto(Env::Default(), heartPrintPbPathFile, &amp;graph_def));\nTF_CHECK_OK(NewSession(opts, &amp;session));\nTF_CHECK_OK(session-&gt;Create(graph_def));\n</code></pre>\n</blockquote>\n<p>os: linux<br>\ntrain: python<br>\ninference: C++ interface</p>\n<p>runtime error on inference part:</p>\n<blockquote>\n<p>Non-OK-status: session-&gt;Create(graph_def) status: Invalid argument: No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered devices: [CPU], Registered kernels:<br>\n</p>\n<p>[[Node: rnn_net/rnn/dropout_63/random_uniform/RandomUniform = RandomUniform<a href=\"rnn_net/rnn/dropout_63/Shape\">T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0</a>]]</p>\n</blockquote>\n<p>python train code:</p>\n<blockquote>\n<pre><code>    with tf.variable_scope(\"rnn_net\") as scope:\n        cell = []\n        for i in range(num_layers):\n            cell.append(tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple=True))\n\n        cell = tf.nn.rnn_cell.MultiRNNCell(cell)\n\n        cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = self.keep_prob)\n\n        initial_state = cell.zero_state(batch_size, tf.float32)\n\n        input_list = tf.unstack(conv_output, axis=1)\n\n        rnn_output, _ = tf.nn.static_rnn(cell, input_list, dtype=tf.float32)\n        self.rnn_output = rnn_output[-1]\n        print \"rnn output shape: \"\n        print self.rnn_output.get_shape()\n</code></pre>\n</blockquote>\n<p>hint one : i found that if i delete this line:<br>\ncell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = self.keep_prob)<br>\nthen the trained pb file can be loaded normally.</p>\n<p>hint two: beside rnn part, i also have cnn part in the network, and the dropout in cnn works just fine:</p>\n<blockquote>\n<pre><code>    with tf.variable_scope(\"conv_net\") as scope:\n        filters = [15, 11, 7, 5]\n        kernel_size = [64, 64, 32, 32]\n        input_layer = tf.reshape(self.x, [-1, seq_len, 1])\n        conv1_1 = tf.layers.conv1d(inputs=input_layer, filters=filters[0], kernel_size=kernel_size[0], padding=\"same\", activation=tf.nn.tanh, name='conv1_1')\n        conv1_2 = tf.layers.conv1d(inputs=conv1_1, filters=filters[1], kernel_size=kernel_size[1], padding=\"same\", activation=tf.nn.tanh)\n        pool1 = tf.layers.max_pooling1d(inputs=conv1_2, pool_size=4, strides=4)\n\n        bn1 = batch_norm(pool1, self.is_train, scope='bn1')\n        dropout1 = tf.layers.dropout(inputs=bn1, rate=(1 - self.keep_prob))\n\n        conv2_1 = tf.layers.conv1d(inputs=dropout1, filters=filters[2], kernel_size=kernel_size[2], padding=\"same\", activation=tf.nn.tanh, name='conv2_1')\n        conv2_2 = tf.layers.conv1d(inputs=conv2_1, filters=filters[3], kernel_size=kernel_size[3], padding=\"same\", activation=tf.nn.tanh)\n        pool2 = tf.layers.max_pooling1d(inputs=conv2_2, pool_size=4, strides=4)\n\n        bn2 = batch_norm(pool2, self.is_train, scope='bn2')\n        dropout2 = tf.layers.dropout(inputs=bn2, rate=(1 - self.keep_prob))\n\n        conv3_1 = tf.layers.conv1d(inputs=dropout2, filters=filters[2], kernel_size=kernel_size[2], padding=\"same\", activation=tf.nn.tanh)\n        conv3_2 = tf.layers.conv1d(inputs=conv3_1, filters=filters[3], kernel_size=kernel_size[3], padding=\"same\", activation=tf.nn.tanh)\n        pool3 = tf.layers.max_pooling1d(inputs=conv2_2, pool_size=2, strides=2)\n\n        conv_output = pool3\n</code></pre>\n</blockquote>", "body_text": "issue: crashes when loading pb file in C++ program:\n\nSession * session;\nGraphDef graph_def;\nSessionOptions opts;\nTF_CHECK_OK(ReadBinaryProto(Env::Default(), heartPrintPbPathFile, &graph_def));\nTF_CHECK_OK(NewSession(opts, &session));\nTF_CHECK_OK(session->Create(graph_def));\n\n\nos: linux\ntrain: python\ninference: C++ interface\nruntime error on inference part:\n\nNon-OK-status: session->Create(graph_def) status: Invalid argument: No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered devices: [CPU], Registered kernels:\n\n[[Node: rnn_net/rnn/dropout_63/random_uniform/RandomUniform = RandomUniformT=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0]]\n\npython train code:\n\n    with tf.variable_scope(\"rnn_net\") as scope:\n        cell = []\n        for i in range(num_layers):\n            cell.append(tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple=True))\n\n        cell = tf.nn.rnn_cell.MultiRNNCell(cell)\n\n        cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = self.keep_prob)\n\n        initial_state = cell.zero_state(batch_size, tf.float32)\n\n        input_list = tf.unstack(conv_output, axis=1)\n\n        rnn_output, _ = tf.nn.static_rnn(cell, input_list, dtype=tf.float32)\n        self.rnn_output = rnn_output[-1]\n        print \"rnn output shape: \"\n        print self.rnn_output.get_shape()\n\n\nhint one : i found that if i delete this line:\ncell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = self.keep_prob)\nthen the trained pb file can be loaded normally.\nhint two: beside rnn part, i also have cnn part in the network, and the dropout in cnn works just fine:\n\n    with tf.variable_scope(\"conv_net\") as scope:\n        filters = [15, 11, 7, 5]\n        kernel_size = [64, 64, 32, 32]\n        input_layer = tf.reshape(self.x, [-1, seq_len, 1])\n        conv1_1 = tf.layers.conv1d(inputs=input_layer, filters=filters[0], kernel_size=kernel_size[0], padding=\"same\", activation=tf.nn.tanh, name='conv1_1')\n        conv1_2 = tf.layers.conv1d(inputs=conv1_1, filters=filters[1], kernel_size=kernel_size[1], padding=\"same\", activation=tf.nn.tanh)\n        pool1 = tf.layers.max_pooling1d(inputs=conv1_2, pool_size=4, strides=4)\n\n        bn1 = batch_norm(pool1, self.is_train, scope='bn1')\n        dropout1 = tf.layers.dropout(inputs=bn1, rate=(1 - self.keep_prob))\n\n        conv2_1 = tf.layers.conv1d(inputs=dropout1, filters=filters[2], kernel_size=kernel_size[2], padding=\"same\", activation=tf.nn.tanh, name='conv2_1')\n        conv2_2 = tf.layers.conv1d(inputs=conv2_1, filters=filters[3], kernel_size=kernel_size[3], padding=\"same\", activation=tf.nn.tanh)\n        pool2 = tf.layers.max_pooling1d(inputs=conv2_2, pool_size=4, strides=4)\n\n        bn2 = batch_norm(pool2, self.is_train, scope='bn2')\n        dropout2 = tf.layers.dropout(inputs=bn2, rate=(1 - self.keep_prob))\n\n        conv3_1 = tf.layers.conv1d(inputs=dropout2, filters=filters[2], kernel_size=kernel_size[2], padding=\"same\", activation=tf.nn.tanh)\n        conv3_2 = tf.layers.conv1d(inputs=conv3_1, filters=filters[3], kernel_size=kernel_size[3], padding=\"same\", activation=tf.nn.tanh)\n        pool3 = tf.layers.max_pooling1d(inputs=conv2_2, pool_size=2, strides=2)\n\n        conv_output = pool3", "body": "issue: crashes when loading pb file in C++ program:\r\n\r\n>     Session * session;\r\n>     GraphDef graph_def;\r\n>     SessionOptions opts;\r\n>     TF_CHECK_OK(ReadBinaryProto(Env::Default(), heartPrintPbPathFile, &graph_def));\r\n>     TF_CHECK_OK(NewSession(opts, &session));\r\n>     TF_CHECK_OK(session->Create(graph_def));\r\n> \r\n\r\nos: linux\r\ntrain: python\r\ninference: C++ interface\r\n\r\nruntime error on inference part:\r\n\r\n> Non-OK-status: session->Create(graph_def) status: Invalid argument: No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n>   <no registered kernels>\r\n> \r\n> \t [[Node: rnn_net/rnn/dropout_63/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0](rnn_net/rnn/dropout_63/Shape)]]\r\n\r\npython train code:\r\n\r\n>         with tf.variable_scope(\"rnn_net\") as scope:\r\n>             cell = []\r\n>             for i in range(num_layers):\r\n>                 cell.append(tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple=True))\r\n> \r\n>             cell = tf.nn.rnn_cell.MultiRNNCell(cell)\r\n> \r\n>             cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = self.keep_prob)\r\n> \r\n>             initial_state = cell.zero_state(batch_size, tf.float32)\r\n> \r\n>             input_list = tf.unstack(conv_output, axis=1)\r\n> \r\n>             rnn_output, _ = tf.nn.static_rnn(cell, input_list, dtype=tf.float32)\r\n>             self.rnn_output = rnn_output[-1]\r\n>             print \"rnn output shape: \"\r\n>             print self.rnn_output.get_shape()\r\n\r\nhint one : i found that if i delete this line:\r\ncell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = self.keep_prob)\r\nthen the trained pb file can be loaded normally.\r\n\r\nhint two: beside rnn part, i also have cnn part in the network, and the dropout in cnn works just fine:\r\n\r\n>         with tf.variable_scope(\"conv_net\") as scope:\r\n>             filters = [15, 11, 7, 5]\r\n>             kernel_size = [64, 64, 32, 32]\r\n>             input_layer = tf.reshape(self.x, [-1, seq_len, 1])\r\n>             conv1_1 = tf.layers.conv1d(inputs=input_layer, filters=filters[0], kernel_size=kernel_size[0], padding=\"same\", activation=tf.nn.tanh, name='conv1_1')\r\n>             conv1_2 = tf.layers.conv1d(inputs=conv1_1, filters=filters[1], kernel_size=kernel_size[1], padding=\"same\", activation=tf.nn.tanh)\r\n>             pool1 = tf.layers.max_pooling1d(inputs=conv1_2, pool_size=4, strides=4)\r\n> \r\n>             bn1 = batch_norm(pool1, self.is_train, scope='bn1')\r\n>             dropout1 = tf.layers.dropout(inputs=bn1, rate=(1 - self.keep_prob))\r\n> \r\n>             conv2_1 = tf.layers.conv1d(inputs=dropout1, filters=filters[2], kernel_size=kernel_size[2], padding=\"same\", activation=tf.nn.tanh, name='conv2_1')\r\n>             conv2_2 = tf.layers.conv1d(inputs=conv2_1, filters=filters[3], kernel_size=kernel_size[3], padding=\"same\", activation=tf.nn.tanh)\r\n>             pool2 = tf.layers.max_pooling1d(inputs=conv2_2, pool_size=4, strides=4)\r\n> \r\n>             bn2 = batch_norm(pool2, self.is_train, scope='bn2')\r\n>             dropout2 = tf.layers.dropout(inputs=bn2, rate=(1 - self.keep_prob))\r\n> \r\n>             conv3_1 = tf.layers.conv1d(inputs=dropout2, filters=filters[2], kernel_size=kernel_size[2], padding=\"same\", activation=tf.nn.tanh)\r\n>             conv3_2 = tf.layers.conv1d(inputs=conv3_1, filters=filters[3], kernel_size=kernel_size[3], padding=\"same\", activation=tf.nn.tanh)\r\n>             pool3 = tf.layers.max_pooling1d(inputs=conv2_2, pool_size=2, strides=2)\r\n> \r\n>             conv_output = pool3\r\n\r\n"}