{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/196764875", "pull_request_review_id": 130378668, "id": 196764875, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5Njc2NDg3NQ==", "diff_hunk": "@@ -143,6 +143,68 @@ public void importGraphDef(byte[] graphDef, String prefix) throws IllegalArgumen\n     }\n   }\n \n+  /**\n+   * Adds operations to compute the partial derivatives of sum of {@code y}s w.r.t {@code x}s,\n+   * i.e., {@code d(y_1 + y_2 + ...)/dx_1, d(y_1 + y_2 + ...)/dx_2...}\n+   * <p> \n+   * {@code dx} are used as initial gradients (which represent the symbolic partial\n+   * derivatives of some loss function {@code L} w.r.t. {@code y}).\n+   * {@code dx} must be null or have size of {@code y}.\n+   * <p>\n+   * If {@code dx} is null, the implementation will use dx of {@code OnesLike} for all\n+   * shapes in {@code y}.\n+   * \n+   * @param y\n+   * @param x\n+   * @param dx\n+   * @return the partial derivatives {@code dy} with the size of {@code x}\n+   */\n+  public Output<?>[] addGradients(Output<?>[] y, Output<?>[] x, Output<?>[] dx) {", "path": "tensorflow/java/src/main/java/org/tensorflow/Graph.java", "position": null, "original_position": 20, "commit_id": "b7baff70bbdc2c785bda47c9eb06584ae46fd3b3", "original_commit_id": "2e14dbb32358c59af7fe23405210a319e96ae94c", "user": {"login": "karllessard", "id": 10109534, "node_id": "MDQ6VXNlcjEwMTA5NTM0", "avatar_url": "https://avatars3.githubusercontent.com/u/10109534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karllessard", "html_url": "https://github.com/karllessard", "followers_url": "https://api.github.com/users/karllessard/followers", "following_url": "https://api.github.com/users/karllessard/following{/other_user}", "gists_url": "https://api.github.com/users/karllessard/gists{/gist_id}", "starred_url": "https://api.github.com/users/karllessard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karllessard/subscriptions", "organizations_url": "https://api.github.com/users/karllessard/orgs", "repos_url": "https://api.github.com/users/karllessard/repos", "events_url": "https://api.github.com/users/karllessard/events{/privacy}", "received_events_url": "https://api.github.com/users/karllessard/received_events", "type": "User", "site_admin": false}, "body": "Sounds very good to me. Would it matter if we do that modification only in the `Op` class? I kind of see that this kind of interface optimization is the responsibility of the Ops API layer while the core classes focuses more on the implementation details.\r\n\r\nI also worked on another `Op` that adds gradients nodes to the graph and immediately apply the descent on the input tensors instead of doing this manually in `n` steps, should I also go ahead with this one (perhaps in another PR)?", "created_at": "2018-06-20T12:55:03Z", "updated_at": "2018-06-28T03:08:41Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20133#discussion_r196764875", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20133", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/196764875"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20133#discussion_r196764875"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20133"}}, "body_html": "<p>Sounds very good to me. Would it matter if we do that modification only in the <code>Op</code> class? I kind of see that this kind of interface optimization is the responsibility of the Ops API layer while the core classes focuses more on the implementation details.</p>\n<p>I also worked on another <code>Op</code> that adds gradients nodes to the graph and immediately apply the descent on the input tensors instead of doing this manually in <code>n</code> steps, should I also go ahead with this one (perhaps in another PR)?</p>", "body_text": "Sounds very good to me. Would it matter if we do that modification only in the Op class? I kind of see that this kind of interface optimization is the responsibility of the Ops API layer while the core classes focuses more on the implementation details.\nI also worked on another Op that adds gradients nodes to the graph and immediately apply the descent on the input tensors instead of doing this manually in n steps, should I also go ahead with this one (perhaps in another PR)?", "in_reply_to_id": 196647261}