{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/312427633", "html_url": "https://github.com/tensorflow/tensorflow/issues/11196#issuecomment-312427633", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11196", "id": 312427633, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjQyNzYzMw==", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-01T11:47:22Z", "updated_at": "2017-07-02T17:18:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Currently distributed TensorFlow is not as performant as single-process multi-device setup. If you are not running your job over multiple machines, you could consider using a intra process parameter server (which typically only uses CPU and host RAM as there is not much work to do for PS).</p>\n<p>Nevertheless, we are preparing a patch on interprocess device DMA for distributed runtime. But currently our design only consider the use case that cross the physical machine boundary through an RDMA-capable network interface card (rNIC). Could you explain a little bit more about your use case? Why do you want to run distributed TF on a single node? I am assuming it's not for testing as you mentioned DMA and thus only a performance-wise matter.</p>\n<p>If your use case is valid, we might consider adding a shared-memory based transport. This isn't as efficient as GPU p2p (I don't know how to do that across process boundary), but certainly faster than current gRPC runtime as it doesn't go through the socket and loopback network stack. Alternatively, if you do have RDMA capable network, you could try the <code>grpc+verbs</code> or MPI based runtime which enable ordinary interprocess RDMA.</p>", "body_text": "Currently distributed TensorFlow is not as performant as single-process multi-device setup. If you are not running your job over multiple machines, you could consider using a intra process parameter server (which typically only uses CPU and host RAM as there is not much work to do for PS).\nNevertheless, we are preparing a patch on interprocess device DMA for distributed runtime. But currently our design only consider the use case that cross the physical machine boundary through an RDMA-capable network interface card (rNIC). Could you explain a little bit more about your use case? Why do you want to run distributed TF on a single node? I am assuming it's not for testing as you mentioned DMA and thus only a performance-wise matter.\nIf your use case is valid, we might consider adding a shared-memory based transport. This isn't as efficient as GPU p2p (I don't know how to do that across process boundary), but certainly faster than current gRPC runtime as it doesn't go through the socket and loopback network stack. Alternatively, if you do have RDMA capable network, you could try the grpc+verbs or MPI based runtime which enable ordinary interprocess RDMA.", "body": "Currently distributed TensorFlow is not as performant as single-process multi-device setup. If you are not running your job over multiple machines, you could consider using a intra process parameter server (which typically only uses CPU and host RAM as there is not much work to do for PS).\r\n\r\nNevertheless, we are preparing a patch on interprocess device DMA for distributed runtime. But currently our design only consider the use case that cross the physical machine boundary through an RDMA-capable network interface card (rNIC). Could you explain a little bit more about your use case? Why do you want to run distributed TF on a single node? I am assuming it's not for testing as you mentioned DMA and thus only a performance-wise matter.\r\n\r\nIf your use case is valid, we might consider adding a shared-memory based transport. This isn't as efficient as GPU p2p (I don't know how to do that across process boundary), but certainly faster than current gRPC runtime as it doesn't go through the socket and loopback network stack. Alternatively, if you do have RDMA capable network, you could try the `grpc+verbs` or MPI based runtime which enable ordinary interprocess RDMA."}