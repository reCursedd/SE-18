{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259032683", "html_url": "https://github.com/tensorflow/tensorflow/issues/4705#issuecomment-259032683", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4705", "id": 259032683, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTAzMjY4Mw==", "user": {"login": "davidzchen", "id": 5283042, "node_id": "MDQ6VXNlcjUyODMwNDI=", "avatar_url": "https://avatars1.githubusercontent.com/u/5283042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidzchen", "html_url": "https://github.com/davidzchen", "followers_url": "https://api.github.com/users/davidzchen/followers", "following_url": "https://api.github.com/users/davidzchen/following{/other_user}", "gists_url": "https://api.github.com/users/davidzchen/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidzchen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidzchen/subscriptions", "organizations_url": "https://api.github.com/users/davidzchen/orgs", "repos_url": "https://api.github.com/users/davidzchen/repos", "events_url": "https://api.github.com/users/davidzchen/events{/privacy}", "received_events_url": "https://api.github.com/users/davidzchen/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-08T03:05:06Z", "updated_at": "2016-11-08T03:05:06Z", "author_association": "MEMBER", "body_html": "<p>+cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3721087\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/damienmg\">@damienmg</a></p>\n<p>Sorry for the late reply.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=260360\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/darrengarvey\">@darrengarvey</a> Currently, the way the settings get propagated from <code>configure</code> to <code>cuda_configure()</code> is that the <code>configure</code> script exports a bunch of environment variables and then runs <code>bazel fetch //...</code> before it exits. When this <code>bazel fetch</code> invocation is run, it picks up the environment variables and sets up the <code>@local_config_cuda</code> workspace according to those settings. Then, when you run <code>bazel build</code>, because all of the external repositories have already been fetched, then TF will be built with <code>@local_config_cuda</code> set up based on the settings given to the <code>configure</code> script.</p>\n<p>When the Bazel server is killed in this case, this is equivalent to running the <code>configure</code> script without it running <code>bazel fetch</code> and then running <code>bazel fetch</code> or <code>bazel build</code> without any of the settings from the <code>configure</code> script, which results in <code>@local_config_cuda</code> set up without GPU support.</p>\n<p>The eventual fix for this is to move the remaining CUDA configuration logic currently in the <code>configure</code> script into the <code>cuda_configure()</code> rule so that it will attempt to detect GPU support and the CUDA toolchain and runtime by default. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3721087\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/damienmg\">@damienmg</a> is working on <a href=\"https://bazel-review.googlesource.com/c/6697/3/site/designs/_posts/2016-10-18-repository-invalidation.md\" rel=\"nofollow\">improvements to Skylark remote repositories</a> to both improve its caching invalidation strategy and enable passing environment variables to workspace rules via command line options. This way, we will be able to make <code>cuda_configure()</code> work more similar to the way the Autotools configure invocation works, where it will run its detection logic by default, but users will be able to override whether to build with GPU support or provide a custom CUDA installation directory via command line flags.</p>", "body_text": "+cc @damienmg\nSorry for the late reply.\n@darrengarvey Currently, the way the settings get propagated from configure to cuda_configure() is that the configure script exports a bunch of environment variables and then runs bazel fetch //... before it exits. When this bazel fetch invocation is run, it picks up the environment variables and sets up the @local_config_cuda workspace according to those settings. Then, when you run bazel build, because all of the external repositories have already been fetched, then TF will be built with @local_config_cuda set up based on the settings given to the configure script.\nWhen the Bazel server is killed in this case, this is equivalent to running the configure script without it running bazel fetch and then running bazel fetch or bazel build without any of the settings from the configure script, which results in @local_config_cuda set up without GPU support.\nThe eventual fix for this is to move the remaining CUDA configuration logic currently in the configure script into the cuda_configure() rule so that it will attempt to detect GPU support and the CUDA toolchain and runtime by default. @damienmg is working on improvements to Skylark remote repositories to both improve its caching invalidation strategy and enable passing environment variables to workspace rules via command line options. This way, we will be able to make cuda_configure() work more similar to the way the Autotools configure invocation works, where it will run its detection logic by default, but users will be able to override whether to build with GPU support or provide a custom CUDA installation directory via command line flags.", "body": "+cc @damienmg \n\nSorry for the late reply.\n\n@darrengarvey Currently, the way the settings get propagated from `configure` to `cuda_configure()` is that the `configure` script exports a bunch of environment variables and then runs `bazel fetch //...` before it exits. When this `bazel fetch` invocation is run, it picks up the environment variables and sets up the `@local_config_cuda` workspace according to those settings. Then, when you run `bazel build`, because all of the external repositories have already been fetched, then TF will be built with `@local_config_cuda` set up based on the settings given to the `configure` script.\n\nWhen the Bazel server is killed in this case, this is equivalent to running the `configure` script without it running `bazel fetch` and then running `bazel fetch` or `bazel build` without any of the settings from the `configure` script, which results in `@local_config_cuda` set up without GPU support.\n\nThe eventual fix for this is to move the remaining CUDA configuration logic currently in the `configure` script into the `cuda_configure()` rule so that it will attempt to detect GPU support and the CUDA toolchain and runtime by default. @damienmg is working on [improvements to Skylark remote repositories](https://bazel-review.googlesource.com/c/6697/3/site/designs/_posts/2016-10-18-repository-invalidation.md) to both improve its caching invalidation strategy and enable passing environment variables to workspace rules via command line options. This way, we will be able to make `cuda_configure()` work more similar to the way the Autotools configure invocation works, where it will run its detection logic by default, but users will be able to override whether to build with GPU support or provide a custom CUDA installation directory via command line flags.\n"}