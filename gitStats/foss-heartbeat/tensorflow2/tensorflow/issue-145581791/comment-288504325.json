{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288504325", "html_url": "https://github.com/tensorflow/tensorflow/issues/1763#issuecomment-288504325", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1763", "id": 288504325, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODUwNDMyNQ==", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-22T18:58:22Z", "updated_at": "2017-03-22T18:59:24Z", "author_association": "NONE", "body_html": "<p>But by the same argument, to make the behavior predictable and non-magical, you now have to guarantee transparency into types all the way along the chain. I don't see how that'd be feasible from API design standpoint, short of requiring dtype specifications for all ops so that they assert if they see the type they didn't expect. That seems onerous.</p>\n<p>As things are today, <em>any</em> op that converts image dtype without range rescaling will <em>silently</em> mess up the assumption that convert_image_dtype() will do your rescaling for you. And they all can't really do range rescaling automatically upon dtype conversion, because they don't know they are processing image data per se.</p>\n<p>Besides, how many people deal with HDR vs just plain JPEG? I bet not very many. And it's incredibly easy right now for the majority of TF users to get screwed by this. I bet most people don't even know about this unintended, but likely behavior, hence my extended comment above.</p>\n<p>I guess another, easier recommendation for folks who care about correctness of their computations would be to convert to float32 right after <code>decode_*()</code> op. But that will further slow down data augmentation, which is already quite a bit slower than e.g. Torch/PyTorch.</p>", "body_text": "But by the same argument, to make the behavior predictable and non-magical, you now have to guarantee transparency into types all the way along the chain. I don't see how that'd be feasible from API design standpoint, short of requiring dtype specifications for all ops so that they assert if they see the type they didn't expect. That seems onerous.\nAs things are today, any op that converts image dtype without range rescaling will silently mess up the assumption that convert_image_dtype() will do your rescaling for you. And they all can't really do range rescaling automatically upon dtype conversion, because they don't know they are processing image data per se.\nBesides, how many people deal with HDR vs just plain JPEG? I bet not very many. And it's incredibly easy right now for the majority of TF users to get screwed by this. I bet most people don't even know about this unintended, but likely behavior, hence my extended comment above.\nI guess another, easier recommendation for folks who care about correctness of their computations would be to convert to float32 right after decode_*() op. But that will further slow down data augmentation, which is already quite a bit slower than e.g. Torch/PyTorch.", "body": "But by the same argument, to make the behavior predictable and non-magical, you now have to guarantee transparency into types all the way along the chain. I don't see how that'd be feasible from API design standpoint, short of requiring dtype specifications for all ops so that they assert if they see the type they didn't expect. That seems onerous.\r\n\r\nAs things are today, _any_ op that converts image dtype without range rescaling will _silently_ mess up the assumption that convert_image_dtype() will do your rescaling for you. And they all can't really do range rescaling automatically upon dtype conversion, because they don't know they are processing image data per se.\r\n\r\nBesides, how many people deal with HDR vs just plain JPEG? I bet not very many. And it's incredibly easy right now for the majority of TF users to get screwed by this. I bet most people don't even know about this unintended, but likely behavior, hence my extended comment above.\r\n\r\nI guess another, easier recommendation for folks who care about correctness of their computations would be to convert to float32 right after `decode_*()` op. But that will further slow down data augmentation, which is already quite a bit slower than e.g. Torch/PyTorch."}