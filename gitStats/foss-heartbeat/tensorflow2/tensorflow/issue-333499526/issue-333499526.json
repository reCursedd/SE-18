{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20110", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20110/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20110/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20110/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20110", "id": 333499526, "node_id": "MDU6SXNzdWUzMzM0OTk1MjY=", "number": 20110, "title": "operators not supported by tflite: CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile.", "user": {"login": "walkerlala", "id": 11005974, "node_id": "MDQ6VXNlcjExMDA1OTc0", "avatar_url": "https://avatars0.githubusercontent.com/u/11005974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/walkerlala", "html_url": "https://github.com/walkerlala", "followers_url": "https://api.github.com/users/walkerlala/followers", "following_url": "https://api.github.com/users/walkerlala/following{/other_user}", "gists_url": "https://api.github.com/users/walkerlala/gists{/gist_id}", "starred_url": "https://api.github.com/users/walkerlala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/walkerlala/subscriptions", "organizations_url": "https://api.github.com/users/walkerlala/orgs", "repos_url": "https://api.github.com/users/walkerlala/repos", "events_url": "https://api.github.com/users/walkerlala/events{/privacy}", "received_events_url": "https://api.github.com/users/walkerlala/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2018-06-19T02:40:30Z", "updated_at": "2018-09-13T17:16:20Z", "closed_at": "2018-09-13T17:16:20Z", "author_association": "NONE", "body_html": "<p>This is a feature request issue.</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n</ul>\n<p>Yes</p>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n</ul>\n<p>CentOS 7</p>\n<ul>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n</ul>\n<p>From <code>pip install tensorflow-gpu==1.6</code></p>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n</ul>\n<p>tensorflow-gpu-1.6</p>\n<ul>\n<li><strong>Python version</strong>:</li>\n</ul>\n<p>Python 2.7.5</p>\n<ul>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>: None</p>\n</li>\n<li>\n<p><strong>GCC/Compiler version (if compiling from source)</strong>: None</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:</p>\n</li>\n</ul>\n<p>CUDA: 9.0</p>\n<ul>\n<li><strong>GPU model and memory</strong>:</li>\n</ul>\n<p>NVIDIA GTX 1080Ti, 11178MiB</p>\n<ul>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>toco --input_file=/tmp/mymodels/model_frozen.pb --output_file=/tmp/mymodels/converted_model.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shape=1,320,320,3 --input_array=input_images --output_array=output_num_array --inference_type=FLOAT --input_data_type=FLOAT\n</code></pre>\n<h3>Describe the problem</h3>\n<p>I want to convert a trained model, which works on my GPU workstation, to a tflite model to work on Android phone. But I found that there are lots of operation not supported (see also the log below): <strong>CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile</strong>. Do I need to provide customized operator for that (that is a lot of job...)? Or do newer version of toco support that? By the way, <code>toco</code> seems to not supported batch normalization either, see <a href=\"https://github.com/tensorflow/tensorflow/issues/15336\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/15336/hovercard\">this issue</a>.</p>\n<h3>Source code / logs</h3>\n<p>After running the command above,</p>\n<pre><code>2018-06-19 10:17:59.783022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform\n2018-06-19 10:17:59.920127: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Pow\n2018-06-19 10:17:59.964930: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 306 operators, 577 arrays (0 quantized)\n2018-06-19 10:17:59.971329: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 306 operators, 577 arrays (0 quantized)\n2018-06-19 10:18:02.355631: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 216 operators, 476 arrays (0 quantized)\n2018-06-19 10:18:02.360368: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 216 operators, 476 arrays (0 quantized)\n2018-06-19 10:18:02.364625: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 78643200 bytes, theoretical optimal value: 78643200 bytes.\n2018-06-19 10:18:02.365858: F tensorflow/contrib/lite/toco/tflite/export.cc:304] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile.\nAborted (core dumped)\n</code></pre>", "body_text": "This is a feature request issue.\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nYes\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n\nCentOS 7\n\nTensorFlow installed from (source or binary):\n\nFrom pip install tensorflow-gpu==1.6\n\nTensorFlow version (use command below):\n\ntensorflow-gpu-1.6\n\nPython version:\n\nPython 2.7.5\n\n\nBazel version (if compiling from source): None\n\n\nGCC/Compiler version (if compiling from source): None\n\n\nCUDA/cuDNN version:\n\n\nCUDA: 9.0\n\nGPU model and memory:\n\nNVIDIA GTX 1080Ti, 11178MiB\n\nExact command to reproduce:\n\ntoco --input_file=/tmp/mymodels/model_frozen.pb --output_file=/tmp/mymodels/converted_model.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shape=1,320,320,3 --input_array=input_images --output_array=output_num_array --inference_type=FLOAT --input_data_type=FLOAT\n\nDescribe the problem\nI want to convert a trained model, which works on my GPU workstation, to a tflite model to work on Android phone. But I found that there are lots of operation not supported (see also the log below): CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile. Do I need to provide customized operator for that (that is a lot of job...)? Or do newer version of toco support that? By the way, toco seems to not supported batch normalization either, see this issue.\nSource code / logs\nAfter running the command above,\n2018-06-19 10:17:59.783022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform\n2018-06-19 10:17:59.920127: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Pow\n2018-06-19 10:17:59.964930: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 306 operators, 577 arrays (0 quantized)\n2018-06-19 10:17:59.971329: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 306 operators, 577 arrays (0 quantized)\n2018-06-19 10:18:02.355631: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 216 operators, 476 arrays (0 quantized)\n2018-06-19 10:18:02.360368: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 216 operators, 476 arrays (0 quantized)\n2018-06-19 10:18:02.364625: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 78643200 bytes, theoretical optimal value: 78643200 bytes.\n2018-06-19 10:18:02.365858: F tensorflow/contrib/lite/toco/tflite/export.cc:304] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile.\nAborted (core dumped)", "body": "This is a feature request issue.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nYes\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nCentOS 7\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nFrom `pip install tensorflow-gpu==1.6`\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\ntensorflow-gpu-1.6\r\n\r\n- **Python version**:\r\n\r\nPython 2.7.5\r\n \r\n- **Bazel version (if compiling from source)**: None\r\n\r\n- **GCC/Compiler version (if compiling from source)**: None\r\n\r\n- **CUDA/cuDNN version**:  \r\n\r\nCUDA: 9.0 \r\n\r\n- **GPU model and memory**:\r\n\r\nNVIDIA GTX 1080Ti, 11178MiB\r\n\r\n- **Exact command to reproduce**:\r\n\r\n```\r\ntoco --input_file=/tmp/mymodels/model_frozen.pb --output_file=/tmp/mymodels/converted_model.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shape=1,320,320,3 --input_array=input_images --output_array=output_num_array --inference_type=FLOAT --input_data_type=FLOAT\r\n```\r\n\r\n### Describe the problem\r\n\r\nI want to convert a trained model, which works on my GPU workstation, to a tflite model to work on Android phone. But I found that there are lots of operation not supported (see also the log below): **CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile**. Do I need to provide customized operator for that (that is a lot of job...)? Or do newer version of toco support that? By the way, `toco` seems to not supported batch normalization either, see [this issue](https://github.com/tensorflow/tensorflow/issues/15336).\r\n\r\n### Source code / logs\r\n\r\nAfter running the command above, \r\n\r\n```\r\n2018-06-19 10:17:59.783022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform\r\n2018-06-19 10:17:59.920127: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Pow\r\n2018-06-19 10:17:59.964930: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 306 operators, 577 arrays (0 quantized)\r\n2018-06-19 10:17:59.971329: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 306 operators, 577 arrays (0 quantized)\r\n2018-06-19 10:18:02.355631: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 216 operators, 476 arrays (0 quantized)\r\n2018-06-19 10:18:02.360368: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 216 operators, 476 arrays (0 quantized)\r\n2018-06-19 10:18:02.364625: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 78643200 bytes, theoretical optimal value: 78643200 bytes.\r\n2018-06-19 10:18:02.365858: F tensorflow/contrib/lite/toco/tflite/export.cc:304] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile.\r\nAborted (core dumped)\r\n```"}