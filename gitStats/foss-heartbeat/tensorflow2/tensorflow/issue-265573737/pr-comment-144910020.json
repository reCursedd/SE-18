{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/144910020", "pull_request_review_id": 69625841, "id": 144910020, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NDkxMDAyMA==", "diff_hunk": "@@ -0,0 +1,123 @@\n+/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#if GOOGLE_CUDA\n+\n+#define EIGEN_USE_GPU\n+\n+#include \"tensorflow/core/kernels/histogram_op.h\"\n+#include \"external/cub_archive/cub/device/device_histogram.cuh\"\n+#include \"external/cub_archive/cub/iterator/counting_input_iterator.cuh\"\n+#include \"external/cub_archive/cub/iterator/transform_input_iterator.cuh\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/platform/types.h\"\n+#include \"tensorflow/core/util/cuda_kernel_helper.h\"\n+#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n+namespace tensorflow {\n+\n+typedef Eigen::GpuDevice GPUDevice;\n+\n+namespace functor {\n+\n+// TODO(yongtang) int64 of atomicAdd is not supported yet.\n+template <typename T, typename Tout>\n+struct HistogramFixedWidthFunctor<GPUDevice, T, Tout> {\n+  static Status Compute(OpKernelContext* context,\n+                        const typename TTypes<T, 1>::ConstTensor& values,\n+                        const typename TTypes<T, 1>::ConstTensor& value_range,\n+                        int32 nbins, typename TTypes<Tout, 1>::Tensor& out) {\n+    tensorflow::AllocatorAttributes pinned_allocator;\n+    pinned_allocator.set_on_host(true);\n+    pinned_allocator.set_gpu_compatible(true);\n+\n+    Tensor levels_tensor;\n+    TF_RETURN_IF_ERROR(context->allocate_temp(\n+        DataTypeToEnum<T>::value, TensorShape({nbins + 1}), &levels_tensor,\n+        pinned_allocator));\n+    auto levels = levels_tensor.flat<T>();\n+\n+    const double step = static_cast<double>(value_range(1) - value_range(0)) /\n+                        static_cast<double>(nbins);\n+    double curr = static_cast<double>(value_range(0)) + step;\n+    levels(0) = std::numeric_limits<T>::lowest();\n+    for (int i = 1; i < nbins; i++) {\n+      levels(i) = T(curr);\n+      curr += step;\n+    }\n+    levels(nbins) = std::numeric_limits<T>::max();\n+\n+    size_t temp_storage_bytes = 0;\n+    const T* d_samples = values.data();\n+    Tout* d_histogram = out.data();\n+    int num_levels = levels.size();\n+    T* d_levels = levels.data();\n+    int num_samples = values.size();\n+    const cudaStream_t& stream = GetCudaStream(context);\n+\n+    auto err = cub::DeviceHistogram::HistogramRange(", "path": "tensorflow/core/kernels/histogram_op_gpu.cu.cc", "position": null, "original_position": 74, "commit_id": "0569ad5fe063b58a5671eb6df6e0fa932386ba87", "original_commit_id": "5368cf0595e0593510da753b85995ae4c967b0c2", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "Comment that this call is to get size of temp storage.", "created_at": "2017-10-16T17:15:20Z", "updated_at": "2017-10-16T19:57:54Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13731#discussion_r144910020", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13731", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/144910020"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13731#discussion_r144910020"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13731"}}, "body_html": "<p>Comment that this call is to get size of temp storage.</p>", "body_text": "Comment that this call is to get size of temp storage."}