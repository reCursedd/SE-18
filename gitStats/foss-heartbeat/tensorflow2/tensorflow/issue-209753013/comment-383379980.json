{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/383379980", "html_url": "https://github.com/tensorflow/tensorflow/issues/7817#issuecomment-383379980", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7817", "id": 383379980, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MzM3OTk4MA==", "user": {"login": "ghamarian", "id": 17321904, "node_id": "MDQ6VXNlcjE3MzIxOTA0", "avatar_url": "https://avatars0.githubusercontent.com/u/17321904?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghamarian", "html_url": "https://github.com/ghamarian", "followers_url": "https://api.github.com/users/ghamarian/followers", "following_url": "https://api.github.com/users/ghamarian/following{/other_user}", "gists_url": "https://api.github.com/users/ghamarian/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghamarian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghamarian/subscriptions", "organizations_url": "https://api.github.com/users/ghamarian/orgs", "repos_url": "https://api.github.com/users/ghamarian/repos", "events_url": "https://api.github.com/users/ghamarian/events{/privacy}", "received_events_url": "https://api.github.com/users/ghamarian/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-22T13:01:40Z", "updated_at": "2018-04-22T13:01:40Z", "author_association": "NONE", "body_html": "<p>I don't know if it is still relevant, but reading through the discussion I do not find the reason or the solution to the problem. I have a very simple network (no operations almost) and I use:<br>\ntf.train.shuffle_batch(decoded, capacity=batch_size * 50,<br>\nbatch_size=batch_size,<br>\nnum_threads=6,<br>\nmin_after_dequeue=batch_size * 10,<br>\nallow_smaller_final_batch=True)</p>\n<p>As my performance drops as I increase the batch_size almost linearly, i.e., increasing batch_size 4 times, it takes 4 times as much.</p>", "body_text": "I don't know if it is still relevant, but reading through the discussion I do not find the reason or the solution to the problem. I have a very simple network (no operations almost) and I use:\ntf.train.shuffle_batch(decoded, capacity=batch_size * 50,\nbatch_size=batch_size,\nnum_threads=6,\nmin_after_dequeue=batch_size * 10,\nallow_smaller_final_batch=True)\nAs my performance drops as I increase the batch_size almost linearly, i.e., increasing batch_size 4 times, it takes 4 times as much.", "body": "I don't know if it is still relevant, but reading through the discussion I do not find the reason or the solution to the problem. I have a very simple network (no operations almost) and I use:\r\ntf.train.shuffle_batch(decoded, capacity=batch_size * 50,\r\n                                 batch_size=batch_size,\r\n                                 num_threads=6,\r\n                                 min_after_dequeue=batch_size * 10,\r\n                                 allow_smaller_final_batch=True)\r\n\r\nAs my performance drops as I increase the batch_size almost linearly, i.e., increasing batch_size 4 times, it takes 4 times as much. "}