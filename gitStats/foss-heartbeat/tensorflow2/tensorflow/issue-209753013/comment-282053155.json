{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/282053155", "html_url": "https://github.com/tensorflow/tensorflow/issues/7817#issuecomment-282053155", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7817", "id": 282053155, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MjA1MzE1NQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-23T16:59:59Z", "updated_at": "2017-02-23T17:03:28Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I troubleshooted similar issue <a href=\"http://stackoverflow.com/questions/39840323/benchmark-of-howto-reading-data/39842628#39842628\" rel=\"nofollow\">here</a> and it was caused by Python thread scheduler choosing a bad strategy. Essentially Python would schedule computation thread that issues a single enqueue call, then this thread would block and have to be pre-empted. Python doesn't support parallel execution of Python code and pre-emption is slow so this part is a performance hit. Eventually it pre-empts dequeue (main) thread to schedule enqueue thread, which does a single enqueue call before Python decides to give execution back to main thread. This back-and-forth dance introduced 10x slowdown in the pipeline.</p>\n<p>One solution is to make sure that you never have queue starvation, for instance, by making enqueue part faster (ie by using enqueue many as here <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"161912688\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3009\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3009/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/3009\">#3009</a> ), making dequeue part slower (ie, add more computation to <code>train_op</code> until it becomes slow enough to be bottleneck), and by letting queue runners add some things to the queue (make queue larger and add <code>time.sleep(1)</code> right after <code>start_queue_runners</code>)</p>", "body_text": "I troubleshooted similar issue here and it was caused by Python thread scheduler choosing a bad strategy. Essentially Python would schedule computation thread that issues a single enqueue call, then this thread would block and have to be pre-empted. Python doesn't support parallel execution of Python code and pre-emption is slow so this part is a performance hit. Eventually it pre-empts dequeue (main) thread to schedule enqueue thread, which does a single enqueue call before Python decides to give execution back to main thread. This back-and-forth dance introduced 10x slowdown in the pipeline.\nOne solution is to make sure that you never have queue starvation, for instance, by making enqueue part faster (ie by using enqueue many as here #3009 ), making dequeue part slower (ie, add more computation to train_op until it becomes slow enough to be bottleneck), and by letting queue runners add some things to the queue (make queue larger and add time.sleep(1) right after start_queue_runners)", "body": "I troubleshooted similar issue [here](http://stackoverflow.com/questions/39840323/benchmark-of-howto-reading-data/39842628#39842628) and it was caused by Python thread scheduler choosing a bad strategy. Essentially Python would schedule computation thread that issues a single enqueue call, then this thread would block and have to be pre-empted. Python doesn't support parallel execution of Python code and pre-emption is slow so this part is a performance hit. Eventually it pre-empts dequeue (main) thread to schedule enqueue thread, which does a single enqueue call before Python decides to give execution back to main thread. This back-and-forth dance introduced 10x slowdown in the pipeline.\r\n\r\nOne solution is to make sure that you never have queue starvation, for instance, by making enqueue part faster (ie by using enqueue many as here https://github.com/tensorflow/tensorflow/issues/3009 ), making dequeue part slower (ie, add more computation to `train_op` until it becomes slow enough to be bottleneck), and by letting queue runners add some things to the queue (make queue larger and add `time.sleep(1)` right after `start_queue_runners`) "}