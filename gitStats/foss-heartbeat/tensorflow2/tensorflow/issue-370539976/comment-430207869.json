{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/430207869", "html_url": "https://github.com/tensorflow/tensorflow/issues/23020#issuecomment-430207869", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23020", "id": 430207869, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDIwNzg2OQ==", "user": {"login": "sevensix6", "id": 33054583, "node_id": "MDQ6VXNlcjMzMDU0NTgz", "avatar_url": "https://avatars2.githubusercontent.com/u/33054583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sevensix6", "html_url": "https://github.com/sevensix6", "followers_url": "https://api.github.com/users/sevensix6/followers", "following_url": "https://api.github.com/users/sevensix6/following{/other_user}", "gists_url": "https://api.github.com/users/sevensix6/gists{/gist_id}", "starred_url": "https://api.github.com/users/sevensix6/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sevensix6/subscriptions", "organizations_url": "https://api.github.com/users/sevensix6/orgs", "repos_url": "https://api.github.com/users/sevensix6/repos", "events_url": "https://api.github.com/users/sevensix6/events{/privacy}", "received_events_url": "https://api.github.com/users/sevensix6/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-16T11:52:03Z", "updated_at": "2018-10-16T11:52:03Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>Did you by any chance use the \"optimize_for_inference\" script? I recently got a similar error when using this script. What worked for me was to just freeze the model and not run the optimize_for_inference script.</p>\n</blockquote>\n<p>Thanks for your reply, but I don't use the script, so the problem maybe wrong pb model in freezing process? I also try to load the model by MetaGraphDef class to load \"*.meta\" file, but occurs \"Invalid argument: No Opkernel was registered to support Op 'PyFunc' with these attrs. Registered devices: [CPU], Registered kernels\", which confused me...</p>", "body_text": "Did you by any chance use the \"optimize_for_inference\" script? I recently got a similar error when using this script. What worked for me was to just freeze the model and not run the optimize_for_inference script.\n\nThanks for your reply, but I don't use the script, so the problem maybe wrong pb model in freezing process? I also try to load the model by MetaGraphDef class to load \"*.meta\" file, but occurs \"Invalid argument: No Opkernel was registered to support Op 'PyFunc' with these attrs. Registered devices: [CPU], Registered kernels\", which confused me...", "body": "> Did you by any chance use the \"optimize_for_inference\" script? I recently got a similar error when using this script. What worked for me was to just freeze the model and not run the optimize_for_inference script.\r\n\r\nThanks for your reply, but I don't use the script, so the problem maybe wrong pb model in freezing process? I also try to load the model by MetaGraphDef class to load \"*.meta\" file, but occurs \"Invalid argument: No Opkernel was registered to support Op 'PyFunc' with these attrs. Registered devices: [CPU], Registered kernels\", which confused me..."}