{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16774", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16774/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16774/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16774/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16774", "id": 294437476, "node_id": "MDU6SXNzdWUyOTQ0Mzc0NzY=", "number": 16774, "title": "Missing functionality in Keras TensorBoard callback ", "user": {"login": "Hvass-Labs", "id": 13588114, "node_id": "MDQ6VXNlcjEzNTg4MTE0", "avatar_url": "https://avatars2.githubusercontent.com/u/13588114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hvass-Labs", "html_url": "https://github.com/Hvass-Labs", "followers_url": "https://api.github.com/users/Hvass-Labs/followers", "following_url": "https://api.github.com/users/Hvass-Labs/following{/other_user}", "gists_url": "https://api.github.com/users/Hvass-Labs/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hvass-Labs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hvass-Labs/subscriptions", "organizations_url": "https://api.github.com/users/Hvass-Labs/orgs", "repos_url": "https://api.github.com/users/Hvass-Labs/repos", "events_url": "https://api.github.com/users/Hvass-Labs/events{/privacy}", "received_events_url": "https://api.github.com/users/Hvass-Labs/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-02-05T15:40:29Z", "updated_at": "2018-09-28T22:06:34Z", "closed_at": "2018-09-28T22:06:34Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary.</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5.0 (Keras 2.1.2-tf)</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0 / 7.0</li>\n<li><strong>GPU model and memory</strong>: GTX 1070 8GB</li>\n<li><strong>Exact command to reproduce</strong>: NA</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The TensorBoard-callback in Keras supports the writing of embeddings to the log, but this is not supported in the TensorFlow version of Keras, even though the doc-string of the TensorFlow version actually lists these parameters.</p>\n<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/579125e87af201ae6b6fa872b6dc3f3ecb400de9/tensorflow/python/keras/_impl/keras/callbacks.py#L643-L651\">tensorflow/tensorflow/python/keras/_impl/keras/callbacks.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 643 to 651\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/579125e87af201ae6b6fa872b6dc3f3ecb400de9\">579125e</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L643\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"643\"></td>\n          <td id=\"LC643\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">      embeddings_freq: frequency (in epochs) at which selected embedding</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L644\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"644\"></td>\n          <td id=\"LC644\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">          layers will be saved.</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L645\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"645\"></td>\n          <td id=\"LC645\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">      embeddings_layer_names: a list of names of layers to keep eye on. If</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L646\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"646\"></td>\n          <td id=\"LC646\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">          None or empty list all the embedding layer will be watched.</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L647\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"647\"></td>\n          <td id=\"LC647\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">      embeddings_metadata: a dictionary which maps layer name to a file name</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L648\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"648\"></td>\n          <td id=\"LC648\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">          in which metadata for this embedding layer is saved. See the</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L649\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"649\"></td>\n          <td id=\"LC649\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">          [details](https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L650\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"650\"></td>\n          <td id=\"LC650\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">          about metadata files format. In case if the same metadata file is</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L651\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"651\"></td>\n          <td id=\"LC651\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">          used for all embedding layers, string can be passed.</span> </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>But these are missing from the <code>__init__</code>:</p>\n<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/579125e87af201ae6b6fa872b6dc3f3ecb400de9/tensorflow/python/keras/_impl/keras/callbacks.py#L656-L662\">tensorflow/tensorflow/python/keras/_impl/keras/callbacks.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 656 to 662\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/579125e87af201ae6b6fa872b6dc3f3ecb400de9\">579125e</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L656\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"656\"></td>\n          <td id=\"LC656\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L657\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"657\"></td>\n          <td id=\"LC657\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">              <span class=\"pl-smi\">log_dir</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>./logs<span class=\"pl-pds\">'</span></span>, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L658\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"658\"></td>\n          <td id=\"LC658\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">              <span class=\"pl-smi\">histogram_freq</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L659\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"659\"></td>\n          <td id=\"LC659\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">              <span class=\"pl-smi\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L660\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"660\"></td>\n          <td id=\"LC660\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">              <span class=\"pl-smi\">write_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L661\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"661\"></td>\n          <td id=\"LC661\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">              <span class=\"pl-smi\">write_grads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L662\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"662\"></td>\n          <td id=\"LC662\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">              <span class=\"pl-smi\">write_images</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>): </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>This is the original Keras implementation which has e.g. <code>embeddings_freq</code>:</p>\n<p><a href=\"https://github.com/keras-team/keras/blob/ad00676b80556a6354180a1bfa3009d4db316d3e/keras/callbacks.py#L642-L650\">https://github.com/keras-team/keras/blob/ad00676b80556a6354180a1bfa3009d4db316d3e/keras/callbacks.py#L642-L650</a></p>\n<p>There seems to be a difference between the original Keras implementation and the version in TensorFlow. I am wondering if these are somehow developed in parallel so it is actually not the original Keras that is included with TensorFlow?</p>\n<p>Thanks!</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Binary.\nTensorFlow version (use command below): 1.5.0 (Keras 2.1.2-tf)\nPython version: 3.6\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source): NA\nCUDA/cuDNN version: 9.0 / 7.0\nGPU model and memory: GTX 1070 8GB\nExact command to reproduce: NA\n\nDescribe the problem\nThe TensorBoard-callback in Keras supports the writing of embeddings to the log, but this is not supported in the TensorFlow version of Keras, even though the doc-string of the TensorFlow version actually lists these parameters.\n\n  \n    \n      tensorflow/tensorflow/python/keras/_impl/keras/callbacks.py\n    \n    \n        Lines 643 to 651\n      in\n      579125e\n    \n    \n    \n    \n\n        \n          \n                 embeddings_freq: frequency (in epochs) at which selected embedding \n        \n\n        \n          \n                     layers will be saved. \n        \n\n        \n          \n                 embeddings_layer_names: a list of names of layers to keep eye on. If \n        \n\n        \n          \n                     None or empty list all the embedding layer will be watched. \n        \n\n        \n          \n                 embeddings_metadata: a dictionary which maps layer name to a file name \n        \n\n        \n          \n                     in which metadata for this embedding layer is saved. See the \n        \n\n        \n          \n                     [details](https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional) \n        \n\n        \n          \n                     about metadata files format. In case if the same metadata file is \n        \n\n        \n          \n                     used for all embedding layers, string can be passed. \n        \n    \n  \n\n\nBut these are missing from the __init__:\n\n  \n    \n      tensorflow/tensorflow/python/keras/_impl/keras/callbacks.py\n    \n    \n        Lines 656 to 662\n      in\n      579125e\n    \n    \n    \n    \n\n        \n          \n           def __init__(self, \n        \n\n        \n          \n                        log_dir='./logs', \n        \n\n        \n          \n                        histogram_freq=0, \n        \n\n        \n          \n                        batch_size=32, \n        \n\n        \n          \n                        write_graph=True, \n        \n\n        \n          \n                        write_grads=False, \n        \n\n        \n          \n                        write_images=False): \n        \n    \n  \n\n\nThis is the original Keras implementation which has e.g. embeddings_freq:\nhttps://github.com/keras-team/keras/blob/ad00676b80556a6354180a1bfa3009d4db316d3e/keras/callbacks.py#L642-L650\nThere seems to be a difference between the original Keras implementation and the version in TensorFlow. I am wondering if these are somehow developed in parallel so it is actually not the original Keras that is included with TensorFlow?\nThanks!", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary.\r\n- **TensorFlow version (use command below)**: 1.5.0 (Keras 2.1.2-tf)\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: 9.0 / 7.0\r\n- **GPU model and memory**: GTX 1070 8GB\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\n\r\nThe TensorBoard-callback in Keras supports the writing of embeddings to the log, but this is not supported in the TensorFlow version of Keras, even though the doc-string of the TensorFlow version actually lists these parameters.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/579125e87af201ae6b6fa872b6dc3f3ecb400de9/tensorflow/python/keras/_impl/keras/callbacks.py#L643-L651\r\n\r\nBut these are missing from the `__init__`:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/579125e87af201ae6b6fa872b6dc3f3ecb400de9/tensorflow/python/keras/_impl/keras/callbacks.py#L656-L662\r\n\r\nThis is the original Keras implementation which has e.g. `embeddings_freq`:\r\n\r\nhttps://github.com/keras-team/keras/blob/ad00676b80556a6354180a1bfa3009d4db316d3e/keras/callbacks.py#L642-L650\r\n\r\nThere seems to be a difference between the original Keras implementation and the version in TensorFlow. I am wondering if these are somehow developed in parallel so it is actually not the original Keras that is included with TensorFlow?\r\n\r\nThanks!"}