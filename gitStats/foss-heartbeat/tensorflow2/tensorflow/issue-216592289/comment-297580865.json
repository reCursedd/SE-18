{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/297580865", "html_url": "https://github.com/tensorflow/tensorflow/pull/8673#issuecomment-297580865", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8673", "id": 297580865, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NzU4MDg2NQ==", "user": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-27T00:50:44Z", "updated_at": "2017-04-27T00:50:44Z", "author_association": "MEMBER", "body_html": "<p>Sorry for the slow response on this one, that's my fault. We've been having some internal debate about the best way to support these kind of fused ops, since this is coming up more often. I like your proposal to create a general fused conv op that can have multiple implementations. I ended up doing something similar for fusing ResizeBilinear and MirrorPad into Conv2D:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/nn_ops.cc#L732\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/nn_ops.cc#L732</a></p>\n<p>Ideally I'd love to see a version where the channel order was an attribute, even if the standard order was unimplemented for these cases. It would also be great if we could add a transform to automatically spot this pattern and replace it in graphs, the way I did here for the resize fusion:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#fuse_convolutions\">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#fuse_convolutions</a></p>\n<p>As a start though, would you be willing to put together a FusedConv2DWithBiasAndActivation op proposal? Apologies again for taking so long to get back on this.</p>", "body_text": "Sorry for the slow response on this one, that's my fault. We've been having some internal debate about the best way to support these kind of fused ops, since this is coming up more often. I like your proposal to create a general fused conv op that can have multiple implementations. I ended up doing something similar for fusing ResizeBilinear and MirrorPad into Conv2D:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/nn_ops.cc#L732\nIdeally I'd love to see a version where the channel order was an attribute, even if the standard order was unimplemented for these cases. It would also be great if we could add a transform to automatically spot this pattern and replace it in graphs, the way I did here for the resize fusion:\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#fuse_convolutions\nAs a start though, would you be willing to put together a FusedConv2DWithBiasAndActivation op proposal? Apologies again for taking so long to get back on this.", "body": "Sorry for the slow response on this one, that's my fault. We've been having some internal debate about the best way to support these kind of fused ops, since this is coming up more often. I like your proposal to create a general fused conv op that can have multiple implementations. I ended up doing something similar for fusing ResizeBilinear and MirrorPad into Conv2D:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/nn_ops.cc#L732\r\n\r\nIdeally I'd love to see a version where the channel order was an attribute, even if the standard order was unimplemented for these cases. It would also be great if we could add a transform to automatically spot this pattern and replace it in graphs, the way I did here for the resize fusion:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#fuse_convolutions\r\n\r\nAs a start though, would you be willing to put together a FusedConv2DWithBiasAndActivation op proposal? Apologies again for taking so long to get back on this."}