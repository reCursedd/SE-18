{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6788", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6788/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6788/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6788/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6788", "id": 200078121, "node_id": "MDU6SXNzdWUyMDAwNzgxMjE=", "number": 6788, "title": "Tf-slim: Unable to read dataset using slim.data_set_provider.DataSetProvider when images are not in JPEG.", "user": {"login": "kwotsin", "id": 11178344, "node_id": "MDQ6VXNlcjExMTc4MzQ0", "avatar_url": "https://avatars2.githubusercontent.com/u/11178344?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kwotsin", "html_url": "https://github.com/kwotsin", "followers_url": "https://api.github.com/users/kwotsin/followers", "following_url": "https://api.github.com/users/kwotsin/following{/other_user}", "gists_url": "https://api.github.com/users/kwotsin/gists{/gist_id}", "starred_url": "https://api.github.com/users/kwotsin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kwotsin/subscriptions", "organizations_url": "https://api.github.com/users/kwotsin/orgs", "repos_url": "https://api.github.com/users/kwotsin/repos", "events_url": "https://api.github.com/users/kwotsin/events{/privacy}", "received_events_url": "https://api.github.com/users/kwotsin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-01-11T12:15:58Z", "updated_at": "2017-01-19T01:50:27Z", "closed_at": "2017-01-19T01:50:27Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>Couldn't find relevant threads as there aren't many tf-slim questions.</p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\n<strong>Ubuntu 16.04</strong></p>\n<p>Installed version of CUDA and cuDNN:<br>\n<strong>8.00</strong></p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.<br>\n<strong>0.11</strong></li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Basically I have directory of subdirectories, with each subdirectory containing png images of a certain class. Editing the tf-slim download_and_convert_flowers.py to suit my images, I created a set of tfrecord files (train and validation both included) and stored it in a directory.</p>\n<p>Following which, I used the 'get_split' function from dataset_utils in <a href=\"https://github.com/tensorflow/models/blob/master/slim/datasets/dataset_utils.py\">https://github.com/tensorflow/models/blob/master/slim/datasets/dataset_utils.py</a><br>\nto create a DataSet class from reading the tfrecord files of a certain type (either train or validation. I indicated 'train'). So now I have a DataSet class to read.</p>\n<p>The problem comes when I try to use a batch loading function to actually start reading the DataSet object for extracting images and creating a batch:</p>\n<pre><code>def load_batch(dataset, batch_size=32, height=299, width=299, is_training=False):\n    \"\"\"Loads a single batch of data.\n    \n    Args:\n      dataset: The dataset to load.\n      batch_size: The number of images in the batch.\n      height: The size of each image after preprocessing.\n      width: The size of each image after preprocessing.\n      is_training: Whether or not we're currently training or evaluating.\n    \n    Returns:\n      images: A Tensor of size [batch_size, height, width, 3], image samples that have been preprocessed.\n      images_raw: A Tensor of size [batch_size, height, width, 3], image samples that can be used for visualization.\n      labels: A Tensor of size [batch_size], whose values range between 0 and dataset.num_classes.\n    \"\"\"\n    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n        dataset)\n        # common_queue_capacity=32)\n        # common_queue_min=8)\n    image_raw, label = data_provider.get(['image', 'label'])\n    \n    # Preprocess image for usage by Inception.\n    image = inception_preprocessing.preprocess_image(image_raw, height, width, is_training=is_training)\n    \n    # Preprocess the image for display purposes.\n    image_raw = tf.expand_dims(image_raw, 0)\n    image_raw = tf.image.resize_images(image_raw, [height, width])\n    image_raw = tf.squeeze(image_raw)\n\n    # Batch it up.\n    images, images_raw, labels = tf.train.batch(\n          [image, image_raw, label],\n          batch_size=batch_size,\n          num_threads=1,\n          capacity=2 * batch_size)\n    \n    return images, images_raw, labels\n</code></pre>\n<p>The problem comes from <code>slim.dataset_data_provider.DatasetDataProvider</code> as I couldn't read the dataset at all.</p>\n<p>Here is my error traceback:</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: GeForce GTX 860M\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.0195\npciBusID 0000:01:00.0\nTotal memory: 3.95GiB\nFree memory: 3.60GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1898 get requests, put_count=1100 evicted_count=1000 eviction_rate=0.909091 and unsatisfied allocation rate=1\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\nINFO:tensorflow:Starting Session.\nINFO:tensorflow:Starting Queues.\nINFO:tensorflow:global_step/sec: 0\nNot a JPEG file: starts with 0x89 0x50\nNot a JPEG file: starts with 0x89 0x50\nINFO:tensorflow:Error reported to Coordinator: &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt;, Invalid JPEG data, size 26498\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\n\nCaused by op u'case/If_0/DecodeJpeg', defined at:\n  File \"code.py\", line 148, in &lt;module&gt;\n    images, images_raw, labels = load_batch(dataset, height = image_size, batch_size = batch_size, width = image_size, is_training = True)\n  File \"code.py\", line 27, in load_batch\n    dataset)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\n    tensors = dataset.decoder.decode(data, items)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\n    image = self._decode(image_buffer, image_format)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 324, in _decode\n    }, default=decode_jpg, exclusive=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2886, in case\n    case_seq = _build_case()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2868, in _build_case\n    name=\"If_%d\" % i)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1710, in cond\n    orig_res, res_t = context_t.BuildCondBranch(fn1)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1613, in BuildCondBranch\n    r = fn()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 317, in decode_jpg\n    return image_ops.decode_jpeg(image_buffer, self._channels)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 283, in decode_jpeg\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Invalid JPEG data, size 26498\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\n\nW tensorflow/core/framework/op_kernel.cc:968] Out of range: FIFOQueue '_0_batch/fifo_queue' is closed and has insufficient elements (requested 3, current size 0)\n\t [[Node: batch = QueueDequeueMany[_class=[\"loc:@batch/fifo_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\nW tensorflow/core/framework/op_kernel.cc:968] Out of range: FIFOQueue '_0_batch/fifo_queue' is closed and has insufficient elements (requested 3, current size 0)\n\t [[Node: batch = QueueDequeueMany[_class=[\"loc:@batch/fifo_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\nTraceback (most recent call last):\n  File \"code.py\", line 171, in &lt;module&gt;\n    number_of_steps = 10)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 780, in train\n    raise\n  File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 969, in managed_session\n    self.stop(close_summary_writer=close_summary_writer)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 797, in stop\n    stop_grace_period_secs=self._stop_grace_secs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 386, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner.py\", line 225, in _run\n    sess.run(enqueue_op)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Invalid JPEG data, size 26498\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\n\nCaused by op u'case/If_0/DecodeJpeg', defined at:\n  File \"code.py\", line 148, in &lt;module&gt;\n    images, images_raw, labels = load_batch(dataset, height = image_size, batch_size = batch_size, width = image_size, is_training = True)\n  File \"code.py\", line 27, in load_batch\n    dataset)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\n    tensors = dataset.decoder.decode(data, items)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\n    image = self._decode(image_buffer, image_format)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 324, in _decode\n    }, default=decode_jpg, exclusive=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2886, in case\n    case_seq = _build_case()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2868, in _build_case\n    name=\"If_%d\" % i)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1710, in cond\n    orig_res, res_t = context_t.BuildCondBranch(fn1)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1613, in BuildCondBranch\n    r = fn()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 317, in decode_jpg\n    return image_ops.decode_jpeg(image_buffer, self._channels)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 283, in decode_jpeg\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Invalid JPEG data, size 26498\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\n</code></pre>\n<p>Upon inspection, I have checked that a likely error comes from the line <code>  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item image = self._decode(image_buffer, image_format)</code></p>\n<p>in tfexample_decoder.py, the image_format, if not indicated, will be a JPEG image by default unless there are 4 channels (RGBA) in the images. But since my images are grayscale, a JPEG decoder is used by default. Yet, I have no way to specify the image format as 'png' specifically unless the source code is changed. How should I go about this, or am I mistaken about the error I have arrived at?</p>\n<p>I have previously successfully run the code (many of which are referenced from the tf-slim walkthrough ipynb file), but the images I used were in jpeg.</p>\n<p>Any help is very much appreciated. Thank you for your time.</p>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nCouldn't find relevant threads as there aren't many tf-slim questions.\nEnvironment info\nOperating System:\nUbuntu 16.04\nInstalled version of CUDA and cuDNN:\n8.00\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n0.11\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nBasically I have directory of subdirectories, with each subdirectory containing png images of a certain class. Editing the tf-slim download_and_convert_flowers.py to suit my images, I created a set of tfrecord files (train and validation both included) and stored it in a directory.\nFollowing which, I used the 'get_split' function from dataset_utils in https://github.com/tensorflow/models/blob/master/slim/datasets/dataset_utils.py\nto create a DataSet class from reading the tfrecord files of a certain type (either train or validation. I indicated 'train'). So now I have a DataSet class to read.\nThe problem comes when I try to use a batch loading function to actually start reading the DataSet object for extracting images and creating a batch:\ndef load_batch(dataset, batch_size=32, height=299, width=299, is_training=False):\n    \"\"\"Loads a single batch of data.\n    \n    Args:\n      dataset: The dataset to load.\n      batch_size: The number of images in the batch.\n      height: The size of each image after preprocessing.\n      width: The size of each image after preprocessing.\n      is_training: Whether or not we're currently training or evaluating.\n    \n    Returns:\n      images: A Tensor of size [batch_size, height, width, 3], image samples that have been preprocessed.\n      images_raw: A Tensor of size [batch_size, height, width, 3], image samples that can be used for visualization.\n      labels: A Tensor of size [batch_size], whose values range between 0 and dataset.num_classes.\n    \"\"\"\n    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n        dataset)\n        # common_queue_capacity=32)\n        # common_queue_min=8)\n    image_raw, label = data_provider.get(['image', 'label'])\n    \n    # Preprocess image for usage by Inception.\n    image = inception_preprocessing.preprocess_image(image_raw, height, width, is_training=is_training)\n    \n    # Preprocess the image for display purposes.\n    image_raw = tf.expand_dims(image_raw, 0)\n    image_raw = tf.image.resize_images(image_raw, [height, width])\n    image_raw = tf.squeeze(image_raw)\n\n    # Batch it up.\n    images, images_raw, labels = tf.train.batch(\n          [image, image_raw, label],\n          batch_size=batch_size,\n          num_threads=1,\n          capacity=2 * batch_size)\n    \n    return images, images_raw, labels\n\nThe problem comes from slim.dataset_data_provider.DatasetDataProvider as I couldn't read the dataset at all.\nHere is my error traceback:\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: GeForce GTX 860M\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.0195\npciBusID 0000:01:00.0\nTotal memory: 3.95GiB\nFree memory: 3.60GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1898 get requests, put_count=1100 evicted_count=1000 eviction_rate=0.909091 and unsatisfied allocation rate=1\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\nINFO:tensorflow:Starting Session.\nINFO:tensorflow:Starting Queues.\nINFO:tensorflow:global_step/sec: 0\nNot a JPEG file: starts with 0x89 0x50\nNot a JPEG file: starts with 0x89 0x50\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.InvalidArgumentError'>, Invalid JPEG data, size 26498\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\n\nCaused by op u'case/If_0/DecodeJpeg', defined at:\n  File \"code.py\", line 148, in <module>\n    images, images_raw, labels = load_batch(dataset, height = image_size, batch_size = batch_size, width = image_size, is_training = True)\n  File \"code.py\", line 27, in load_batch\n    dataset)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\n    tensors = dataset.decoder.decode(data, items)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\n    image = self._decode(image_buffer, image_format)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 324, in _decode\n    }, default=decode_jpg, exclusive=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2886, in case\n    case_seq = _build_case()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2868, in _build_case\n    name=\"If_%d\" % i)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1710, in cond\n    orig_res, res_t = context_t.BuildCondBranch(fn1)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1613, in BuildCondBranch\n    r = fn()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 317, in decode_jpg\n    return image_ops.decode_jpeg(image_buffer, self._channels)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 283, in decode_jpeg\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Invalid JPEG data, size 26498\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\n\nW tensorflow/core/framework/op_kernel.cc:968] Out of range: FIFOQueue '_0_batch/fifo_queue' is closed and has insufficient elements (requested 3, current size 0)\n\t [[Node: batch = QueueDequeueMany[_class=[\"loc:@batch/fifo_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\nW tensorflow/core/framework/op_kernel.cc:968] Out of range: FIFOQueue '_0_batch/fifo_queue' is closed and has insufficient elements (requested 3, current size 0)\n\t [[Node: batch = QueueDequeueMany[_class=[\"loc:@batch/fifo_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\nTraceback (most recent call last):\n  File \"code.py\", line 171, in <module>\n    number_of_steps = 10)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 780, in train\n    raise\n  File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 969, in managed_session\n    self.stop(close_summary_writer=close_summary_writer)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 797, in stop\n    stop_grace_period_secs=self._stop_grace_secs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 386, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner.py\", line 225, in _run\n    sess.run(enqueue_op)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Invalid JPEG data, size 26498\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\n\nCaused by op u'case/If_0/DecodeJpeg', defined at:\n  File \"code.py\", line 148, in <module>\n    images, images_raw, labels = load_batch(dataset, height = image_size, batch_size = batch_size, width = image_size, is_training = True)\n  File \"code.py\", line 27, in load_batch\n    dataset)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\n    tensors = dataset.decoder.decode(data, items)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\n    image = self._decode(image_buffer, image_format)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 324, in _decode\n    }, default=decode_jpg, exclusive=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2886, in case\n    case_seq = _build_case()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2868, in _build_case\n    name=\"If_%d\" % i)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1710, in cond\n    orig_res, res_t = context_t.BuildCondBranch(fn1)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1613, in BuildCondBranch\n    r = fn()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 317, in decode_jpg\n    return image_ops.decode_jpeg(image_buffer, self._channels)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 283, in decode_jpeg\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Invalid JPEG data, size 26498\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\n\nUpon inspection, I have checked that a likely error comes from the line   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item image = self._decode(image_buffer, image_format)\nin tfexample_decoder.py, the image_format, if not indicated, will be a JPEG image by default unless there are 4 channels (RGBA) in the images. But since my images are grayscale, a JPEG decoder is used by default. Yet, I have no way to specify the image format as 'png' specifically unless the source code is changed. How should I go about this, or am I mistaken about the error I have arrived at?\nI have previously successfully run the code (many of which are referenced from the tf-slim walkthrough ipynb file), but the images I used were in jpeg.\nAny help is very much appreciated. Thank you for your time.", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nCouldn't find relevant threads as there aren't many tf-slim questions.\r\n\r\n### Environment info\r\nOperating System:\r\n**Ubuntu 16.04**\r\n\r\nInstalled version of CUDA and cuDNN: \r\n**8.00**\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n**0.11**\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nBasically I have directory of subdirectories, with each subdirectory containing png images of a certain class. Editing the tf-slim download_and_convert_flowers.py to suit my images, I created a set of tfrecord files (train and validation both included) and stored it in a directory.\r\n\r\nFollowing which, I used the 'get_split' function from dataset_utils in https://github.com/tensorflow/models/blob/master/slim/datasets/dataset_utils.py\r\nto create a DataSet class from reading the tfrecord files of a certain type (either train or validation. I indicated 'train'). So now I have a DataSet class to read.\r\n\r\nThe problem comes when I try to use a batch loading function to actually start reading the DataSet object for extracting images and creating a batch:\r\n\r\n```\r\ndef load_batch(dataset, batch_size=32, height=299, width=299, is_training=False):\r\n    \"\"\"Loads a single batch of data.\r\n    \r\n    Args:\r\n      dataset: The dataset to load.\r\n      batch_size: The number of images in the batch.\r\n      height: The size of each image after preprocessing.\r\n      width: The size of each image after preprocessing.\r\n      is_training: Whether or not we're currently training or evaluating.\r\n    \r\n    Returns:\r\n      images: A Tensor of size [batch_size, height, width, 3], image samples that have been preprocessed.\r\n      images_raw: A Tensor of size [batch_size, height, width, 3], image samples that can be used for visualization.\r\n      labels: A Tensor of size [batch_size], whose values range between 0 and dataset.num_classes.\r\n    \"\"\"\r\n    data_provider = slim.dataset_data_provider.DatasetDataProvider(\r\n        dataset)\r\n        # common_queue_capacity=32)\r\n        # common_queue_min=8)\r\n    image_raw, label = data_provider.get(['image', 'label'])\r\n    \r\n    # Preprocess image for usage by Inception.\r\n    image = inception_preprocessing.preprocess_image(image_raw, height, width, is_training=is_training)\r\n    \r\n    # Preprocess the image for display purposes.\r\n    image_raw = tf.expand_dims(image_raw, 0)\r\n    image_raw = tf.image.resize_images(image_raw, [height, width])\r\n    image_raw = tf.squeeze(image_raw)\r\n\r\n    # Batch it up.\r\n    images, images_raw, labels = tf.train.batch(\r\n          [image, image_raw, label],\r\n          batch_size=batch_size,\r\n          num_threads=1,\r\n          capacity=2 * batch_size)\r\n    \r\n    return images, images_raw, labels\r\n```\r\nThe problem comes from `slim.dataset_data_provider.DatasetDataProvider` as I couldn't read the dataset at all.\r\n\r\nHere is my error traceback:\r\n\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \r\nname: GeForce GTX 860M\r\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.0195\r\npciBusID 0000:01:00.0\r\nTotal memory: 3.95GiB\r\nFree memory: 3.60GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0)\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1898 get requests, put_count=1100 evicted_count=1000 eviction_rate=0.909091 and unsatisfied allocation rate=1\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\r\nINFO:tensorflow:Starting Session.\r\nINFO:tensorflow:Starting Queues.\r\nINFO:tensorflow:global_step/sec: 0\r\nNot a JPEG file: starts with 0x89 0x50\r\nNot a JPEG file: starts with 0x89 0x50\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.InvalidArgumentError'>, Invalid JPEG data, size 26498\r\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\r\n\r\nCaused by op u'case/If_0/DecodeJpeg', defined at:\r\n  File \"code.py\", line 148, in <module>\r\n    images, images_raw, labels = load_batch(dataset, height = image_size, batch_size = batch_size, width = image_size, is_training = True)\r\n  File \"code.py\", line 27, in load_batch\r\n    dataset)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\r\n    tensors = dataset.decoder.decode(data, items)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\r\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\r\n    image = self._decode(image_buffer, image_format)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 324, in _decode\r\n    }, default=decode_jpg, exclusive=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2886, in case\r\n    case_seq = _build_case()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2868, in _build_case\r\n    name=\"If_%d\" % i)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1710, in cond\r\n    orig_res, res_t = context_t.BuildCondBranch(fn1)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1613, in BuildCondBranch\r\n    r = fn()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 317, in decode_jpg\r\n    return image_ops.decode_jpeg(image_buffer, self._channels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 283, in decode_jpeg\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Invalid JPEG data, size 26498\r\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\r\n\r\nW tensorflow/core/framework/op_kernel.cc:968] Out of range: FIFOQueue '_0_batch/fifo_queue' is closed and has insufficient elements (requested 3, current size 0)\r\n\t [[Node: batch = QueueDequeueMany[_class=[\"loc:@batch/fifo_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\r\nW tensorflow/core/framework/op_kernel.cc:968] Out of range: FIFOQueue '_0_batch/fifo_queue' is closed and has insufficient elements (requested 3, current size 0)\r\n\t [[Node: batch = QueueDequeueMany[_class=[\"loc:@batch/fifo_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\r\nTraceback (most recent call last):\r\n  File \"code.py\", line 171, in <module>\r\n    number_of_steps = 10)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 780, in train\r\n    raise\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 969, in managed_session\r\n    self.stop(close_summary_writer=close_summary_writer)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 797, in stop\r\n    stop_grace_period_secs=self._stop_grace_secs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 386, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner.py\", line 225, in _run\r\n    sess.run(enqueue_op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 717, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 915, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 985, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors.InvalidArgumentError: Invalid JPEG data, size 26498\r\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\r\n\r\nCaused by op u'case/If_0/DecodeJpeg', defined at:\r\n  File \"code.py\", line 148, in <module>\r\n    images, images_raw, labels = load_batch(dataset, height = image_size, batch_size = batch_size, width = image_size, is_training = True)\r\n  File \"code.py\", line 27, in load_batch\r\n    dataset)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\r\n    tensors = dataset.decoder.decode(data, items)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\r\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\r\n    image = self._decode(image_buffer, image_format)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 324, in _decode\r\n    }, default=decode_jpg, exclusive=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2886, in case\r\n    case_seq = _build_case()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2868, in _build_case\r\n    name=\"If_%d\" % i)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1710, in cond\r\n    orig_res, res_t = context_t.BuildCondBranch(fn1)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1613, in BuildCondBranch\r\n    r = fn()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 317, in decode_jpg\r\n    return image_ops.decode_jpeg(image_buffer, self._channels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 283, in decode_jpeg\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Invalid JPEG data, size 26498\r\n\t [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge/_7825)]]\r\n```\r\nUpon inspection, I have checked that a likely error comes from the line ```  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\r\n    image = self._decode(image_buffer, image_format)```\r\n\r\nin tfexample_decoder.py, the image_format, if not indicated, will be a JPEG image by default unless there are 4 channels (RGBA) in the images. But since my images are grayscale, a JPEG decoder is used by default. Yet, I have no way to specify the image format as 'png' specifically unless the source code is changed. How should I go about this, or am I mistaken about the error I have arrived at?\r\n\r\nI have previously successfully run the code (many of which are referenced from the tf-slim walkthrough ipynb file), but the images I used were in jpeg. \r\n\r\nAny help is very much appreciated. Thank you for your time."}