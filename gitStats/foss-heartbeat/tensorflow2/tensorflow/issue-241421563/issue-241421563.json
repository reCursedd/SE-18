{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11366", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11366/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11366/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11366/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11366", "id": 241421563, "node_id": "MDU6SXNzdWUyNDE0MjE1NjM=", "number": 11366, "title": "Problems with AOT-Compiled Inception V3 model (runtime crash / nonsense output)", "user": {"login": "andrew-anki", "id": 5142143, "node_id": "MDQ6VXNlcjUxNDIxNDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5142143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrew-anki", "html_url": "https://github.com/andrew-anki", "followers_url": "https://api.github.com/users/andrew-anki/followers", "following_url": "https://api.github.com/users/andrew-anki/following{/other_user}", "gists_url": "https://api.github.com/users/andrew-anki/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrew-anki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrew-anki/subscriptions", "organizations_url": "https://api.github.com/users/andrew-anki/orgs", "repos_url": "https://api.github.com/users/andrew-anki/repos", "events_url": "https://api.github.com/users/andrew-anki/events{/privacy}", "received_events_url": "https://api.github.com/users/andrew-anki/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2017-07-08T03:29:11Z", "updated_at": "2018-03-31T21:19:49Z", "closed_at": "2018-03-31T21:19:49Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Mac OS X 10.12.5</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: ('v1.2.0-rc2-21-g12f033d', '1.2.0')</li>\n<li><strong>Python version</strong>: 2.7.13</li>\n<li><strong>Bazel version (if compiling from source)</strong>: bazel release 0.5.1-homebrew</li>\n<li><strong>CUDA/cuDNN version</strong>: n/a (CPU only build)</li>\n<li><strong>GPU model and memory</strong>: n/a</li>\n<li><strong>Exact command to reproduce</strong>: See description below.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I've successfully built the AOT compiler and all its tests pass fine. I'm trying to do the analogous thing as in the matmul example to build an AOT-compiled library for a frozen Inception V3 graph: specifically, <code>inception_v3_2016_08_28_frozen.pb</code>, which I hope to incorporate into my larger C++ project.</p>\n<p>The bazel build goes fine, and I get a (large) library and header file. I can successfully compile and link that into my larger project. When I <code>Run()</code> it, however, I get a <code>EXC_BAD_ACCESS</code> on this line of disassembly:</p>\n<pre><code>0x10143f55f &lt;+143&gt;: movq   (%rax), %rax\n</code></pre>\n<p>with this stack trace from a call to <code>Run()</code>:</p>\n<pre><code>#0\t0x000000010143f55f in Eigen::TensorEvaluator&lt;Eigen::TensorContractionOp&lt;Eigen::array&lt;Eigen::IndexPair&lt;long long&gt;, 1ul&gt; const, Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;long long, 2&gt; const, Eigen::TensorImagePatchOp&lt;-1l, -1l, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, long&gt;, 16, Eigen::MakePointer&gt; const&gt; const&gt; const, Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;long long, 2&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, long&gt;, 16, Eigen::MakePointer&gt; const&gt; const&gt; const, Eigen::ThreadPoolDevice&gt;::Context&lt;Eigen::internal::gemm_pack_lhs&lt;float, long, Eigen::internal::TensorContractionSubMapper&lt;float, long, 1, Eigen::TensorEvaluator&lt;Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;long long, 2&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, long&gt;, 16, Eigen::MakePointer&gt; const&gt; const, Eigen::ThreadPoolDevice&gt;, Eigen::array&lt;long, 1ul&gt;, Eigen::array&lt;long, 1ul&gt;, 4, true, false, 0, Eigen::MakePointer&gt;, 8, 4, 0, false, false&gt;, Eigen::internal::gemm_pack_rhs&lt;float, long, Eigen::internal::TensorContractionSubMapper&lt;float, long, 0, Eigen::TensorEvaluator&lt;Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;long long, 2&gt; const, Eigen::TensorImagePatchOp&lt;-1l, -1l, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, long&gt;, 16, Eigen::MakePointer&gt; const&gt; const&gt; const, Eigen::ThreadPoolDevice&gt;, Eigen::array&lt;long, 1ul&gt;, Eigen::array&lt;long, 1ul&gt;, 4, true, false, 0, Eigen::MakePointer&gt;, 4, 0, false, false&gt;, Eigen::internal::gebp_kernel&lt;float, float, long, Eigen::internal::blas_data_mapper&lt;float, long, 0, 0&gt;, 8, 4, false, false&gt;, Eigen::internal::TensorContractionInputMapper&lt;float, long, 1, Eigen::TensorEvaluator&lt;Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;long long, 2&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, long&gt;, 16, Eigen::MakePointer&gt; const&gt; const, Eigen::ThreadPoolDevice&gt;, Eigen::array&lt;long, 1ul&gt;, Eigen::array&lt;long, 1ul&gt;, 4, true, false, 0, Eigen::MakePointer&gt;, Eigen::internal::TensorContractionInputMapper&lt;float, long, 0, Eigen::TensorEvaluator&lt;Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;long long, 2&gt; const, Eigen::TensorImagePatchOp&lt;-1l, -1l, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, long&gt;, 16, Eigen::MakePointer&gt; const&gt; const&gt; const, Eigen::ThreadPoolDevice&gt;, Eigen::array&lt;long, 1ul&gt;, Eigen::array&lt;long, 1ul&gt;, 4, true, false, 0, Eigen::MakePointer&gt;, Eigen::internal::blas_data_mapper&lt;float, long, 0, 0&gt; &gt;::enqueue_packing_helper(long, long, long, bool) ()\n#7\t0x00000001012ff70b in __tensorflow_aot_test__aot_test ()\n</code></pre>\n<p>Furthermore, when I write my own simple binary, separate from my larger project, along the lines of the matmul test example for AOT, I can build and run it without the above crash, but no matter what input I feed in, I get the same output: the 1001-element results vector is all zeros except entry 429, which is exactly 1.0. My guess was that the image data I'm feeding in was somehow garbage, but I've verified (?) that I can read in the same binary blob of pre-processed image data in Matlab and it looks reasonable. (Pre-processing here includes resizing the image to the required size (299x299), dividing each element by 255, and storing as floats.)</p>\n<p>Is something going wrong in AOT-compiling the graph here, or am I doing something wrong or missing something totally stupid? Is there something used in the Inception architecture that's not supported? Should I be trying with another frozen graph? Note that I'm on the <code>r1.2</code> branch, but may try switching to master next to see if it's something that's been changed/fixed since <code>r1.2</code>. See below for source.</p>\n<h3>Source code / logs</h3>\n<p><code>BUILD</code> file for my <code>aot_test</code> library and a simple binary to run it:</p>\n<pre><code>load(\"//tensorflow/compiler/aot:tfcompile.bzl\", \"tf_library\")\n\ntf_library(\n    name = \"aot_test\",\n    cpp_class = \"TF_TestAOT\",\n    graph = \"inception_v3_2016_08_28_frozen.pb\",\n    config = \"aot_test.config.pbtxt\",\n)\n\ncc_binary(\n    name = \"my_binary\",\n    srcs = [\n        \"my_binary.cc\", \n    ],\n    deps = [\n        \":aot_test\",  \n        \"//third_party/eigen3\",\n    ],\n    # I've tried with or without this\n    #linkopts = [\n    #      \"-lpthread\",\n    #]\n)\n</code></pre>\n<p>Contents of <code>aot_test.config.pbtxt</code> referenced above:</p>\n<pre><code>feed {\n  id { node_name: \"input\" }\n  shape {\n    dim { size: 1   }\n    dim { size: 299 }\n    dim { size: 299 }\n    dim { size: 3   }\n  }\n}\n\nfetch {\n  id { node_name: \"InceptionV3/Predictions/Reshape_1\" }\n}\n</code></pre>\n<p>Contents of <code>my_binary.cc</code> referenced above:</p>\n<pre><code>#define EIGEN_USE_THREADS\n#define EIGEN_USE_CUSTOM_THREAD_POOL\n\n#include &lt;cstdlib&gt;\n#include &lt;iostream&gt;\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/aot_test/aot_test.h\" // generated\n\nint main(int argc, char** argv) {\n  Eigen::ThreadPool tp(1);  // Size the thread pool as appropriate. (I've tried various options here)\n  Eigen::ThreadPoolDevice device(&amp;tp, tp.NumThreads());\n\n  TF_TestAOT test;\n  test.set_thread_pool(&amp;device);\n\n  // Set up args and run the computation. \n  // Printing out the data shows it is valid. I've also tried random input data and multiple images.\n  FILE* file = fopen(\"/tmp/img_norm.bin\", \"rb\");\n  const size_t n = fread(test.arg0_data(), sizeof(float), 299*299*3, file); \n  fclose(file);\n  std::cout &lt;&lt; \"Read \" &lt;&lt; n &lt;&lt; \" floats\" &lt;&lt; std::endl;\n  \n  test.Run();\n\n  std::cout &lt;&lt; \"Status: \" &lt;&lt; test.error_msg() &lt;&lt; std::endl;\n  \n  // Check result\n  const float* output_data = test.result0_data();\n  float maxScore = -1.f;\n  int maxIndex = -1;\n  for(int i=0; i&lt;1001; ++i)\n  {\n     // If I print this, i'll see all zeros except entry 429, which is one\n    //std::cout &lt;&lt; \"Score[\" &lt;&lt; i &lt;&lt; \"]=\" &lt;&lt; output_data[i] &lt;&lt; std::endl;\n    if(output_data[i] &gt; maxScore)\n    {\n      maxScore = output_data[i];\n      maxIndex = i;\n    }\n  }\n\n  std::cout &lt;&lt; \"Max score = \" &lt;&lt; maxScore &lt;&lt; \" at index \" &lt;&lt; maxIndex &lt;&lt; std::endl;\n\n  return 0;\n}\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.12.5\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): ('v1.2.0-rc2-21-g12f033d', '1.2.0')\nPython version: 2.7.13\nBazel version (if compiling from source): bazel release 0.5.1-homebrew\nCUDA/cuDNN version: n/a (CPU only build)\nGPU model and memory: n/a\nExact command to reproduce: See description below.\n\nDescribe the problem\nI've successfully built the AOT compiler and all its tests pass fine. I'm trying to do the analogous thing as in the matmul example to build an AOT-compiled library for a frozen Inception V3 graph: specifically, inception_v3_2016_08_28_frozen.pb, which I hope to incorporate into my larger C++ project.\nThe bazel build goes fine, and I get a (large) library and header file. I can successfully compile and link that into my larger project. When I Run() it, however, I get a EXC_BAD_ACCESS on this line of disassembly:\n0x10143f55f <+143>: movq   (%rax), %rax\n\nwith this stack trace from a call to Run():\n#0\t0x000000010143f55f in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 8, 4, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool) ()\n#7\t0x00000001012ff70b in __tensorflow_aot_test__aot_test ()\n\nFurthermore, when I write my own simple binary, separate from my larger project, along the lines of the matmul test example for AOT, I can build and run it without the above crash, but no matter what input I feed in, I get the same output: the 1001-element results vector is all zeros except entry 429, which is exactly 1.0. My guess was that the image data I'm feeding in was somehow garbage, but I've verified (?) that I can read in the same binary blob of pre-processed image data in Matlab and it looks reasonable. (Pre-processing here includes resizing the image to the required size (299x299), dividing each element by 255, and storing as floats.)\nIs something going wrong in AOT-compiling the graph here, or am I doing something wrong or missing something totally stupid? Is there something used in the Inception architecture that's not supported? Should I be trying with another frozen graph? Note that I'm on the r1.2 branch, but may try switching to master next to see if it's something that's been changed/fixed since r1.2. See below for source.\nSource code / logs\nBUILD file for my aot_test library and a simple binary to run it:\nload(\"//tensorflow/compiler/aot:tfcompile.bzl\", \"tf_library\")\n\ntf_library(\n    name = \"aot_test\",\n    cpp_class = \"TF_TestAOT\",\n    graph = \"inception_v3_2016_08_28_frozen.pb\",\n    config = \"aot_test.config.pbtxt\",\n)\n\ncc_binary(\n    name = \"my_binary\",\n    srcs = [\n        \"my_binary.cc\", \n    ],\n    deps = [\n        \":aot_test\",  \n        \"//third_party/eigen3\",\n    ],\n    # I've tried with or without this\n    #linkopts = [\n    #      \"-lpthread\",\n    #]\n)\n\nContents of aot_test.config.pbtxt referenced above:\nfeed {\n  id { node_name: \"input\" }\n  shape {\n    dim { size: 1   }\n    dim { size: 299 }\n    dim { size: 299 }\n    dim { size: 3   }\n  }\n}\n\nfetch {\n  id { node_name: \"InceptionV3/Predictions/Reshape_1\" }\n}\n\nContents of my_binary.cc referenced above:\n#define EIGEN_USE_THREADS\n#define EIGEN_USE_CUSTOM_THREAD_POOL\n\n#include <cstdlib>\n#include <iostream>\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/aot_test/aot_test.h\" // generated\n\nint main(int argc, char** argv) {\n  Eigen::ThreadPool tp(1);  // Size the thread pool as appropriate. (I've tried various options here)\n  Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());\n\n  TF_TestAOT test;\n  test.set_thread_pool(&device);\n\n  // Set up args and run the computation. \n  // Printing out the data shows it is valid. I've also tried random input data and multiple images.\n  FILE* file = fopen(\"/tmp/img_norm.bin\", \"rb\");\n  const size_t n = fread(test.arg0_data(), sizeof(float), 299*299*3, file); \n  fclose(file);\n  std::cout << \"Read \" << n << \" floats\" << std::endl;\n  \n  test.Run();\n\n  std::cout << \"Status: \" << test.error_msg() << std::endl;\n  \n  // Check result\n  const float* output_data = test.result0_data();\n  float maxScore = -1.f;\n  int maxIndex = -1;\n  for(int i=0; i<1001; ++i)\n  {\n     // If I print this, i'll see all zeros except entry 429, which is one\n    //std::cout << \"Score[\" << i << \"]=\" << output_data[i] << std::endl;\n    if(output_data[i] > maxScore)\n    {\n      maxScore = output_data[i];\n      maxIndex = i;\n    }\n  }\n\n  std::cout << \"Max score = \" << maxScore << \" at index \" << maxIndex << std::endl;\n\n  return 0;\n}", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.5\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**: bazel release 0.5.1-homebrew\r\n- **CUDA/cuDNN version**: n/a (CPU only build)\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: See description below.\r\n\r\n### Describe the problem\r\nI've successfully built the AOT compiler and all its tests pass fine. I'm trying to do the analogous thing as in the matmul example to build an AOT-compiled library for a frozen Inception V3 graph: specifically, `inception_v3_2016_08_28_frozen.pb`, which I hope to incorporate into my larger C++ project.\r\n\r\nThe bazel build goes fine, and I get a (large) library and header file. I can successfully compile and link that into my larger project. When I `Run()` it, however, I get a `EXC_BAD_ACCESS` on this line of disassembly:\r\n```\r\n0x10143f55f <+143>: movq   (%rax), %rax\r\n```\r\nwith this stack trace from a call to `Run()`:\r\n```\r\n#0\t0x000000010143f55f in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 8, 4, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool) ()\r\n#7\t0x00000001012ff70b in __tensorflow_aot_test__aot_test ()\r\n```\r\n\r\nFurthermore, when I write my own simple binary, separate from my larger project, along the lines of the matmul test example for AOT, I can build and run it without the above crash, but no matter what input I feed in, I get the same output: the 1001-element results vector is all zeros except entry 429, which is exactly 1.0. My guess was that the image data I'm feeding in was somehow garbage, but I've verified (?) that I can read in the same binary blob of pre-processed image data in Matlab and it looks reasonable. (Pre-processing here includes resizing the image to the required size (299x299), dividing each element by 255, and storing as floats.)\r\n\r\nIs something going wrong in AOT-compiling the graph here, or am I doing something wrong or missing something totally stupid? Is there something used in the Inception architecture that's not supported? Should I be trying with another frozen graph? Note that I'm on the `r1.2` branch, but may try switching to master next to see if it's something that's been changed/fixed since `r1.2`. See below for source. \r\n\r\n### Source code / logs\r\n\r\n`BUILD` file for my `aot_test` library and a simple binary to run it:\r\n```\r\nload(\"//tensorflow/compiler/aot:tfcompile.bzl\", \"tf_library\")\r\n\r\ntf_library(\r\n    name = \"aot_test\",\r\n    cpp_class = \"TF_TestAOT\",\r\n    graph = \"inception_v3_2016_08_28_frozen.pb\",\r\n    config = \"aot_test.config.pbtxt\",\r\n)\r\n\r\ncc_binary(\r\n    name = \"my_binary\",\r\n    srcs = [\r\n        \"my_binary.cc\", \r\n    ],\r\n    deps = [\r\n        \":aot_test\",  \r\n        \"//third_party/eigen3\",\r\n    ],\r\n    # I've tried with or without this\r\n    #linkopts = [\r\n    #      \"-lpthread\",\r\n    #]\r\n)\r\n```\r\n\r\nContents of `aot_test.config.pbtxt` referenced above:\r\n```\r\nfeed {\r\n  id { node_name: \"input\" }\r\n  shape {\r\n    dim { size: 1   }\r\n    dim { size: 299 }\r\n    dim { size: 299 }\r\n    dim { size: 3   }\r\n  }\r\n}\r\n\r\nfetch {\r\n  id { node_name: \"InceptionV3/Predictions/Reshape_1\" }\r\n}\r\n```\r\n\r\nContents of `my_binary.cc` referenced above:\r\n```\r\n#define EIGEN_USE_THREADS\r\n#define EIGEN_USE_CUSTOM_THREAD_POOL\r\n\r\n#include <cstdlib>\r\n#include <iostream>\r\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\r\n#include \"tensorflow/aot_test/aot_test.h\" // generated\r\n\r\nint main(int argc, char** argv) {\r\n  Eigen::ThreadPool tp(1);  // Size the thread pool as appropriate. (I've tried various options here)\r\n  Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());\r\n\r\n  TF_TestAOT test;\r\n  test.set_thread_pool(&device);\r\n\r\n  // Set up args and run the computation. \r\n  // Printing out the data shows it is valid. I've also tried random input data and multiple images.\r\n  FILE* file = fopen(\"/tmp/img_norm.bin\", \"rb\");\r\n  const size_t n = fread(test.arg0_data(), sizeof(float), 299*299*3, file); \r\n  fclose(file);\r\n  std::cout << \"Read \" << n << \" floats\" << std::endl;\r\n  \r\n  test.Run();\r\n\r\n  std::cout << \"Status: \" << test.error_msg() << std::endl;\r\n  \r\n  // Check result\r\n  const float* output_data = test.result0_data();\r\n  float maxScore = -1.f;\r\n  int maxIndex = -1;\r\n  for(int i=0; i<1001; ++i)\r\n  {\r\n     // If I print this, i'll see all zeros except entry 429, which is one\r\n    //std::cout << \"Score[\" << i << \"]=\" << output_data[i] << std::endl;\r\n    if(output_data[i] > maxScore)\r\n    {\r\n      maxScore = output_data[i];\r\n      maxIndex = i;\r\n    }\r\n  }\r\n\r\n  std::cout << \"Max score = \" << maxScore << \" at index \" << maxIndex << std::endl;\r\n\r\n  return 0;\r\n}\r\n```\r\n\r\n"}