{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/239878316", "html_url": "https://github.com/tensorflow/tensorflow/issues/3815#issuecomment-239878316", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3815", "id": 239878316, "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTg3ODMxNg==", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-15T18:03:29Z", "updated_at": "2016-08-15T18:03:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This bug was introduced by me when rewriting the prod gradient to deal with zeros in the input.<br>\nThe code doesn't handle the case where <code>reduction_indices</code> is a scalar.</p>\n<p>To fix this we should</p>\n<ul>\n<li>Add a line to the gradient that reshapes the <code>reduction_indices</code> to a rank 1 tensor: <code>tf.reshape(reduction_indices, [-1])</code></li>\n<li>Add a test case that computes the gradient with a scalar reduction index parameter.</li>\n<li>Maybe add a bit of text to the documentation of the reduction ops that mentions that both scalars and rank tensors can be passed in? I couldn't find any mention of this being possible except for the examples.</li>\n</ul>", "body_text": "This bug was introduced by me when rewriting the prod gradient to deal with zeros in the input.\nThe code doesn't handle the case where reduction_indices is a scalar.\nTo fix this we should\n\nAdd a line to the gradient that reshapes the reduction_indices to a rank 1 tensor: tf.reshape(reduction_indices, [-1])\nAdd a test case that computes the gradient with a scalar reduction index parameter.\nMaybe add a bit of text to the documentation of the reduction ops that mentions that both scalars and rank tensors can be passed in? I couldn't find any mention of this being possible except for the examples.", "body": "This bug was introduced by me when rewriting the prod gradient to deal with zeros in the input.\nThe code doesn't handle the case where `reduction_indices` is a scalar.\n\nTo fix this we should\n- Add a line to the gradient that reshapes the `reduction_indices` to a rank 1 tensor: `tf.reshape(reduction_indices, [-1])`\n- Add a test case that computes the gradient with a scalar reduction index parameter.\n- Maybe add a bit of text to the documentation of the reduction ops that mentions that both scalars and rank tensors can be passed in? I couldn't find any mention of this being possible except for the examples.\n"}