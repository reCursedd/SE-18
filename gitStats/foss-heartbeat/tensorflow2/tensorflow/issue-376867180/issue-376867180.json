{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23458", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23458/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23458/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23458/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23458", "id": 376867180, "node_id": "MDU6SXNzdWUzNzY4NjcxODA=", "number": 23458, "title": "XLA creates CUDA contexts on GPUs not in gpu_options.visible_device_list", "user": {"login": "nluehr", "id": 1873655, "node_id": "MDQ6VXNlcjE4NzM2NTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1873655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nluehr", "html_url": "https://github.com/nluehr", "followers_url": "https://api.github.com/users/nluehr/followers", "following_url": "https://api.github.com/users/nluehr/following{/other_user}", "gists_url": "https://api.github.com/users/nluehr/gists{/gist_id}", "starred_url": "https://api.github.com/users/nluehr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nluehr/subscriptions", "organizations_url": "https://api.github.com/users/nluehr/orgs", "repos_url": "https://api.github.com/users/nluehr/repos", "events_url": "https://api.github.com/users/nluehr/events{/privacy}", "received_events_url": "https://api.github.com/users/nluehr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-11-02T15:52:28Z", "updated_at": "2018-11-23T16:19:40Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A</li>\n<li>TensorFlow installed from (source or binary): Source</li>\n<li>TensorFlow version (use command below): 1.12.0-rc2</li>\n<li>Python version: 3.5</li>\n<li>Bazel version (if compiling from source): 0.15.0</li>\n<li>GCC/Compiler version (if compiling from source): 5.4.0</li>\n<li>CUDA/cuDNN version: CUDA 10.0, cuDNN 7.4</li>\n<li>GPU model and memory: 8xV100 32GB</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nWhen XLA is enabled, CUDA contexts are created on every device visible to the CUDA driver (excluding devices with CUDA_VISIBLE_DEVICES works, but gpu_options.visible_device_list in ConfigProto does not).</p>\n<p><strong>Describe the expected behavior</strong><br>\nWhen gpu_options.visible_device_list is specified, CUDA contexts should only be created on the devices listed.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nTo reproduce, run the following on a multi-gpu system and check nvidia-smi during the 20 second sleep.</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport time\n\nconfig = tf.ConfigProto()\nconfig.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\nconfig.gpu_options.visible_device_list=\"0\"\n\ninput = tf.placeholder(tf.float32, [1000])\ndata = np.random.rand(1000).astype('float32')\noutput = tf.nn.softmax(tf.nn.relu(input))\n\nwith tf.Session(config=config) as sess:\n  res = sess.run(output, feed_dict={input: data})\n  print(\"Session executed, check devices with nvidia-smi\")\n  time.sleep(20)\n  print(\"Exiting\")\n</code></pre>\n<p><strong>Other info / logs</strong></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.12.0-rc2\nPython version: 3.5\nBazel version (if compiling from source): 0.15.0\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: CUDA 10.0, cuDNN 7.4\nGPU model and memory: 8xV100 32GB\n\nDescribe the current behavior\nWhen XLA is enabled, CUDA contexts are created on every device visible to the CUDA driver (excluding devices with CUDA_VISIBLE_DEVICES works, but gpu_options.visible_device_list in ConfigProto does not).\nDescribe the expected behavior\nWhen gpu_options.visible_device_list is specified, CUDA contexts should only be created on the devices listed.\nCode to reproduce the issue\nTo reproduce, run the following on a multi-gpu system and check nvidia-smi during the 20 second sleep.\nimport tensorflow as tf\nimport numpy as np\nimport time\n\nconfig = tf.ConfigProto()\nconfig.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\nconfig.gpu_options.visible_device_list=\"0\"\n\ninput = tf.placeholder(tf.float32, [1000])\ndata = np.random.rand(1000).astype('float32')\noutput = tf.nn.softmax(tf.nn.relu(input))\n\nwith tf.Session(config=config) as sess:\n  res = sess.run(output, feed_dict={input: data})\n  print(\"Session executed, check devices with nvidia-smi\")\n  time.sleep(20)\n  print(\"Exiting\")\n\nOther info / logs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 1.12.0-rc2\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): 0.15.0\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: CUDA 10.0, cuDNN 7.4\r\n- GPU model and memory: 8xV100 32GB\r\n\r\n**Describe the current behavior**\r\nWhen XLA is enabled, CUDA contexts are created on every device visible to the CUDA driver (excluding devices with CUDA_VISIBLE_DEVICES works, but gpu_options.visible_device_list in ConfigProto does not).\r\n\r\n**Describe the expected behavior**\r\nWhen gpu_options.visible_device_list is specified, CUDA contexts should only be created on the devices listed.\r\n\r\n**Code to reproduce the issue**\r\nTo reproduce, run the following on a multi-gpu system and check nvidia-smi during the 20 second sleep.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\r\nconfig.gpu_options.visible_device_list=\"0\"\r\n\r\ninput = tf.placeholder(tf.float32, [1000])\r\ndata = np.random.rand(1000).astype('float32')\r\noutput = tf.nn.softmax(tf.nn.relu(input))\r\n\r\nwith tf.Session(config=config) as sess:\r\n  res = sess.run(output, feed_dict={input: data})\r\n  print(\"Session executed, check devices with nvidia-smi\")\r\n  time.sleep(20)\r\n  print(\"Exiting\")\r\n```\r\n\r\n**Other info / logs**\r\n\r\n"}