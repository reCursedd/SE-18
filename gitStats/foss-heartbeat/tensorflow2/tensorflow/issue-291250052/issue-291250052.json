{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16369", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16369/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16369/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16369/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16369", "id": 291250052, "node_id": "MDU6SXNzdWUyOTEyNTAwNTI=", "number": 16369, "title": "Unittesting Models with Tensorflow - How to clear the existing graph ?", "user": {"login": "DEKHTIARJonathan", "id": 10923599, "node_id": "MDQ6VXNlcjEwOTIzNTk5", "avatar_url": "https://avatars2.githubusercontent.com/u/10923599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DEKHTIARJonathan", "html_url": "https://github.com/DEKHTIARJonathan", "followers_url": "https://api.github.com/users/DEKHTIARJonathan/followers", "following_url": "https://api.github.com/users/DEKHTIARJonathan/following{/other_user}", "gists_url": "https://api.github.com/users/DEKHTIARJonathan/gists{/gist_id}", "starred_url": "https://api.github.com/users/DEKHTIARJonathan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DEKHTIARJonathan/subscriptions", "organizations_url": "https://api.github.com/users/DEKHTIARJonathan/orgs", "repos_url": "https://api.github.com/users/DEKHTIARJonathan/repos", "events_url": "https://api.github.com/users/DEKHTIARJonathan/events{/privacy}", "received_events_url": "https://api.github.com/users/DEKHTIARJonathan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-01-24T15:28:36Z", "updated_at": "2018-11-11T12:49:24Z", "closed_at": "2018-01-25T07:03:15Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello dear tensorflowers,</p>\n<p>I have already asked the question of <a href=\"https://stackoverflow.com/questions/48421308/tensorflow-and-unittests-layer-already-defined\" rel=\"nofollow\">StackOverflow</a>, however it seams like nobody can answer my question.</p>\n<p>So I hope you will forgive me about reposting it here:</p>\n<p>I am developing unittests for a product I implemented with TF.</p>\n<p>Each part of the model is tested separately then all together in different conditions.</p>\n<p>Let's take the example of a simple GAN, I have the following tests:</p>\n<ul>\n<li><strong>GeneratorTest</strong> Class: With all tests concerning G inside</li>\n<li><strong>DiscriminatorTest</strong> Class: With all tests concerning D inside</li>\n<li><strong>GAN_Train_Test</strong> Class: G and D connected all together: 1 training step is tested.</li>\n<li><strong>GAN_Inference_Test</strong> Class: G and D connecteed all together: 1 inference run is tested.</li>\n</ul>\n<hr>\n<p>When the files are executed independently, everything is working nicely and fine. Tests are all fine.</p>\n<p>Problems start occuring when I try to create one file to launch them all from one master file.</p>\n<p><strong>master_test_launcher.py:</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> unittest\n<span class=\"pl-k\">import</span> time\n    \n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n    \n<span class=\"pl-k\">from</span> tests.test_generator <span class=\"pl-k\">import</span> GeneratorTest\n<span class=\"pl-k\">from</span> tests.test_discriminator <span class=\"pl-k\">import</span> DiscriminatorTest\n<span class=\"pl-k\">from</span> tests.test_anovae_model <span class=\"pl-k\">import</span> <span class=\"pl-c1\">GAN_Train_Test</span>\n<span class=\"pl-k\">from</span> tests.test_inference <span class=\"pl-k\">import</span> <span class=\"pl-c1\">GAN_Inference_Test</span>\n    \nrunner <span class=\"pl-k\">=</span> unittest.TextTestRunner(<span class=\"pl-v\">verbosity</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n    \n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n   tf.logging.set_verbosity(tf.logging.<span class=\"pl-c1\">DEBUG</span>)\n    \n    <span class=\"pl-k\">for</span> test <span class=\"pl-k\">in</span> [GeneratorTest, DiscriminatorTest, <span class=\"pl-c1\">GAN_Train_Test</span>, <span class=\"pl-c1\">GAN_Inference_Test</span>]:\n        tf.logging.debug(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Running tests for: <span class=\"pl-c1\">%s</span> ...<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> test.<span class=\"pl-c1\">__str__</span>())\n    \n        tf.reset_default_graph()\n    \n        time.sleep(<span class=\"pl-c1\">2</span>)\n    \n        test_suite <span class=\"pl-k\">=</span> unittest.TestSuite()\n        test_suite.addTest(unittest.makeSuite(test))\n    \n        runner.run(test_suite)</pre></div>\n<p>I repeatedly obtain the same error when I run the tests related to G and D connected together:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">Exception</span>: Layer <span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder/input<span class=\"pl-pds\">'</span></span> already exists, please choice other <span class=\"pl-s\"><span class=\"pl-pds\">'</span>name<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">or</span> reuse this layer\nHint : Use different name <span class=\"pl-k\">for</span> different <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Layer<span class=\"pl-pds\">'</span></span> (The name <span class=\"pl-k\">is</span> used to control parameter sharing)</pre></div>\n<p>The error is quite simple to understand, each test file is independant and thus create its own session and graph. While testing only G or D, there is no problem because they have different name_scope/variable_scope. However, when testing the whole model <em>Layers</em> already have been defined by previous tests and thus leading to issue.</p>\n<p>I would like to find a way to completely drop the graph and reset the whole TF state as <strong>brand new and clean</strong>. However, everything I try seem to  fail.</p>\n<p>I would like to avoid creating a new graph for each test, leaving the old one in memory (could lead to very high amount of memory waste after a few tests).</p>\n<p>So my question is easy: ** How can I reset the whole TF state and internal vars as \"clean\" as if you relaunch a new python shell ? By some black-magic I can't find any way doing it (after looking for it for hours).</p>\n<p>For information here are the things I tried and which failed:</p>\n<ul>\n<li>tf.reset_default_graph()</li>\n<li>cleaning everything in graph collections</li>\n<li>creating a new graph + new session before executing each Test File: A graph is still built somewhere containing my Layers and I can't manage to find it.</li>\n<li>reading the TF code and trying to find any <strong>exit</strong> or close function which I didn't find</li>\n</ul>\n<p>Thanks a lot,</p>\n<p>Jonathan D.</p>", "body_text": "Hello dear tensorflowers,\nI have already asked the question of StackOverflow, however it seams like nobody can answer my question.\nSo I hope you will forgive me about reposting it here:\nI am developing unittests for a product I implemented with TF.\nEach part of the model is tested separately then all together in different conditions.\nLet's take the example of a simple GAN, I have the following tests:\n\nGeneratorTest Class: With all tests concerning G inside\nDiscriminatorTest Class: With all tests concerning D inside\nGAN_Train_Test Class: G and D connected all together: 1 training step is tested.\nGAN_Inference_Test Class: G and D connecteed all together: 1 inference run is tested.\n\n\nWhen the files are executed independently, everything is working nicely and fine. Tests are all fine.\nProblems start occuring when I try to create one file to launch them all from one master file.\nmaster_test_launcher.py:\nimport unittest\nimport time\n    \nimport tensorflow as tf\n    \nfrom tests.test_generator import GeneratorTest\nfrom tests.test_discriminator import DiscriminatorTest\nfrom tests.test_anovae_model import GAN_Train_Test\nfrom tests.test_inference import GAN_Inference_Test\n    \nrunner = unittest.TextTestRunner(verbosity=2)\n    \nif __name__ == '__main__':\n   tf.logging.set_verbosity(tf.logging.DEBUG)\n    \n    for test in [GeneratorTest, DiscriminatorTest, GAN_Train_Test, GAN_Inference_Test]:\n        tf.logging.debug(\"Running tests for: %s ...\" % test.__str__())\n    \n        tf.reset_default_graph()\n    \n        time.sleep(2)\n    \n        test_suite = unittest.TestSuite()\n        test_suite.addTest(unittest.makeSuite(test))\n    \n        runner.run(test_suite)\nI repeatedly obtain the same error when I run the tests related to G and D connected together:\nException: Layer 'encoder/input' already exists, please choice other 'name' or reuse this layer\nHint : Use different name for different 'Layer' (The name is used to control parameter sharing)\nThe error is quite simple to understand, each test file is independant and thus create its own session and graph. While testing only G or D, there is no problem because they have different name_scope/variable_scope. However, when testing the whole model Layers already have been defined by previous tests and thus leading to issue.\nI would like to find a way to completely drop the graph and reset the whole TF state as brand new and clean. However, everything I try seem to  fail.\nI would like to avoid creating a new graph for each test, leaving the old one in memory (could lead to very high amount of memory waste after a few tests).\nSo my question is easy: ** How can I reset the whole TF state and internal vars as \"clean\" as if you relaunch a new python shell ? By some black-magic I can't find any way doing it (after looking for it for hours).\nFor information here are the things I tried and which failed:\n\ntf.reset_default_graph()\ncleaning everything in graph collections\ncreating a new graph + new session before executing each Test File: A graph is still built somewhere containing my Layers and I can't manage to find it.\nreading the TF code and trying to find any exit or close function which I didn't find\n\nThanks a lot,\nJonathan D.", "body": "Hello dear tensorflowers,\r\n\r\nI have already asked the question of [StackOverflow](https://stackoverflow.com/questions/48421308/tensorflow-and-unittests-layer-already-defined), however it seams like nobody can answer my question.\r\n\r\nSo I hope you will forgive me about reposting it here:\r\n\r\nI am developing unittests for a product I implemented with TF.\r\n\r\nEach part of the model is tested separately then all together in different conditions.\r\n\r\nLet's take the example of a simple GAN, I have the following tests:\r\n\r\n - **GeneratorTest** Class: With all tests concerning G inside\r\n - **DiscriminatorTest** Class: With all tests concerning D inside\r\n - **GAN_Train_Test** Class: G and D connected all together: 1 training step is tested.\r\n - **GAN_Inference_Test** Class: G and D connecteed all together: 1 inference run is tested.\r\n\r\n------------\r\n\r\nWhen the files are executed independently, everything is working nicely and fine. Tests are all fine.\r\n\r\nProblems start occuring when I try to create one file to launch them all from one master file.\r\n\r\n**master_test_launcher.py:**\r\n\r\n```python\r\nimport unittest\r\nimport time\r\n    \r\nimport tensorflow as tf\r\n    \r\nfrom tests.test_generator import GeneratorTest\r\nfrom tests.test_discriminator import DiscriminatorTest\r\nfrom tests.test_anovae_model import GAN_Train_Test\r\nfrom tests.test_inference import GAN_Inference_Test\r\n    \r\nrunner = unittest.TextTestRunner(verbosity=2)\r\n    \r\nif __name__ == '__main__':\r\n   tf.logging.set_verbosity(tf.logging.DEBUG)\r\n    \r\n    for test in [GeneratorTest, DiscriminatorTest, GAN_Train_Test, GAN_Inference_Test]:\r\n        tf.logging.debug(\"Running tests for: %s ...\" % test.__str__())\r\n    \r\n        tf.reset_default_graph()\r\n    \r\n        time.sleep(2)\r\n    \r\n        test_suite = unittest.TestSuite()\r\n        test_suite.addTest(unittest.makeSuite(test))\r\n    \r\n        runner.run(test_suite)\r\n```\r\n\r\nI repeatedly obtain the same error when I run the tests related to G and D connected together: \r\n\r\n```python\r\nException: Layer 'encoder/input' already exists, please choice other 'name' or reuse this layer\r\nHint : Use different name for different 'Layer' (The name is used to control parameter sharing)\r\n```\r\n\r\nThe error is quite simple to understand, each test file is independant and thus create its own session and graph. While testing only G or D, there is no problem because they have different name_scope/variable_scope. However, when testing the whole model *Layers* already have been defined by previous tests and thus leading to issue.\r\n\r\nI would like to find a way to completely drop the graph and reset the whole TF state as **brand new and clean**. However, everything I try seem to  fail.\r\n\r\nI would like to avoid creating a new graph for each test, leaving the old one in memory (could lead to very high amount of memory waste after a few tests).\r\n\r\n\r\nSo my question is easy: ** How can I reset the whole TF state and internal vars as \"clean\" as if you relaunch a new python shell ? By some black-magic I can't find any way doing it (after looking for it for hours).\r\n\r\nFor information here are the things I tried and which failed:\r\n- tf.reset_default_graph()\r\n- cleaning everything in graph collections\r\n- creating a new graph + new session before executing each Test File: A graph is still built somewhere containing my Layers and I can't manage to find it.\r\n- reading the TF code and trying to find any __exit__ or close function which I didn't find\r\n\r\nThanks a lot,\r\n\r\nJonathan D."}