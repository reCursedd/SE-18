{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20358", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20358/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20358/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20358/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20358", "id": 336368182, "node_id": "MDU6SXNzdWUzMzYzNjgxODI=", "number": 20358, "title": "Highlevel API do not well support float64 due to tf.feature_column.input_layer", "user": {"login": "bewantbe", "id": 4962979, "node_id": "MDQ6VXNlcjQ5NjI5Nzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/4962979?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bewantbe", "html_url": "https://github.com/bewantbe", "followers_url": "https://api.github.com/users/bewantbe/followers", "following_url": "https://api.github.com/users/bewantbe/following{/other_user}", "gists_url": "https://api.github.com/users/bewantbe/gists{/gist_id}", "starred_url": "https://api.github.com/users/bewantbe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bewantbe/subscriptions", "organizations_url": "https://api.github.com/users/bewantbe/orgs", "repos_url": "https://api.github.com/users/bewantbe/repos", "events_url": "https://api.github.com/users/bewantbe/events{/privacy}", "received_events_url": "https://api.github.com/users/bewantbe/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-06-27T20:04:07Z", "updated_at": "2018-11-14T19:21:30Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes. See the end.</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Debian 9.4.</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource.</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\n1.9.0-rc1</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\n3.5.3</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\n0.11.1</p>\n</li>\n<li>\n<p><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\n6.3.0</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nNA (cpu only build)</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:<br>\nNA (cpu only build)</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\nSee the python script in the end. Just run it like:<br>\n<code>python3 test_tf_float64.py</code></p>\n</li>\n</ul>\n<h3>The problem</h3>\n<p>The function <code>tf.feature_column.input_layer</code> return tensor in dtype=float32 for input dtype=float64.</p>\n<p>I know this is a <a href=\"https://github.com/tensorflow/tensorflow/blob/v1.9.0-rc1/tensorflow/python/feature_column/feature_column.py#L270\">documented</a> behavior, but this breaks things:</p>\n<ol>\n<li>\n<p>When the training data is in float64 precision, the user is (I am) expecting a float64 output, especially when the DNN written in high level API is used as a regressor. However, it returns float32, see the script in the end.</p>\n</li>\n<li>\n<p>When building a custom estimator using high level API, seems that the input layer has to be created by <code>tf.feature_column.input_layer</code>. See the guide <a href=\"https://www.tensorflow.org/get_started/custom_estimators#define_the_input_layer\" rel=\"nofollow\">here</a>. This forbid the user from creating a network with dtype=float64 precision.</p>\n</li>\n</ol>\n<p>One may argue that dtype=float32 is already more than enough for DNN. But e.g. when doing theoretical work, the extra precision is desired.</p>\n<p>A possible fix is:</p>\n<p>Change line <a href=\"https://github.com/tensorflow/tensorflow/blob/v1.9.0-rc1/tensorflow/python/feature_column/feature_column.py#L2347\">2347</a> of function <code>_transform_feature</code> in file <code>tensorflow/python/feature_column/feature_column.py</code>, from</p>\n<div class=\"highlight highlight-source-python\"><pre> <span class=\"pl-k\">return</span> math_ops.to_float(input_tensor)</pre></div>\n<p>to</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> input_tensor.dtype.is_floating:\n      <span class=\"pl-k\">return</span> math_ops.to_float(input_tensor)\n    <span class=\"pl-k\">return</span> input_tensor</pre></div>\n<p>Note: this fix could breaks old code that has float32 assumption...</p>\n<p>If this is considered as non-bug, then consider this as a feature request that make it possible to pass dtype=float64 through.</p>\n<h3>Source code</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Test tensorflow high level API.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> dtype=float64 will be silently transformed to float32.</span>\n\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">load_data</span>(<span class=\"pl-smi\">dtype</span>):\n    l <span class=\"pl-k\">=</span> <span class=\"pl-c1\">7</span>\n    x1 <span class=\"pl-k\">=</span> np.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>, l, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype)\n    z1 <span class=\"pl-k\">=</span> np.sin(x1)\n    <span class=\"pl-k\">return</span> ({<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>:x1}, {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>z<span class=\"pl-pds\">'</span></span>:z1})\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train_input_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">batch_size</span>):\n    dataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices((features, labels[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>z<span class=\"pl-pds\">'</span></span>]))\n    dataset <span class=\"pl-k\">=</span> dataset.repeat().batch(batch_size)\n    <span class=\"pl-k\">return</span> dataset\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">eval_input_fn</span>(<span class=\"pl-smi\">features</span>):\n    dataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices(features)\n    dataset <span class=\"pl-k\">=</span> dataset.batch(<span class=\"pl-c1\">1</span>)\n    <span class=\"pl-k\">return</span> dataset\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">argv</span>):\n    dtype <span class=\"pl-k\">=</span> np.float64   <span class=\"pl-c\"><span class=\"pl-c\">#</span> specifies the data type</span>\n\n    batch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">7</span>\n    n_steps <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n\n    (train_x, train_y) <span class=\"pl-k\">=</span> load_data(dtype)\n    my_feature_columns <span class=\"pl-k\">=</span> [\n        tf.feature_column.numeric_column(\n            <span class=\"pl-v\">key</span>   <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>,\n            <span class=\"pl-v\">shape</span> <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">1</span>,),\n            <span class=\"pl-v\">dtype</span> <span class=\"pl-k\">=</span> tf.as_dtype(train_x[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>].dtype))\n    ]\n\n    regressor <span class=\"pl-k\">=</span> tf.estimator.DNNRegressor(   <span class=\"pl-c\"><span class=\"pl-c\">#</span> or any other regressors</span>\n        <span class=\"pl-v\">hidden_units</span>    <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">3</span>],\n        <span class=\"pl-v\">feature_columns</span> <span class=\"pl-k\">=</span> my_feature_columns)\n\n    regressor.train(\n        <span class=\"pl-v\">input_fn</span> <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span>:train_input_fn(train_x, train_y, batch_size),\n        <span class=\"pl-v\">steps</span>    <span class=\"pl-k\">=</span> n_steps)\n\n    predict_x <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>: np.array([<span class=\"pl-c1\">0.1</span>, <span class=\"pl-c1\">0.2</span>])}\n\n    predictions <span class=\"pl-k\">=</span> regressor.predict(\n        <span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span>:eval_input_fn(predict_x))\n\n    <span class=\"pl-c1\">print</span>([i <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> predictions]) <span class=\"pl-c\"><span class=\"pl-c\">#</span> outputs are float32 instead of float64</span>\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    tf.app.run(main)</pre></div>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes. See the end.\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Debian 9.4.\n\n\nTensorFlow installed from (source or binary):\nsource.\n\n\nTensorFlow version (use command below):\n1.9.0-rc1\n\n\nPython version:\n3.5.3\n\n\nBazel version (if compiling from source):\n0.11.1\n\n\nGCC/Compiler version (if compiling from source):\n6.3.0\n\n\nCUDA/cuDNN version:\nNA (cpu only build)\n\n\nGPU model and memory:\nNA (cpu only build)\n\n\nExact command to reproduce:\nSee the python script in the end. Just run it like:\npython3 test_tf_float64.py\n\n\nThe problem\nThe function tf.feature_column.input_layer return tensor in dtype=float32 for input dtype=float64.\nI know this is a documented behavior, but this breaks things:\n\n\nWhen the training data is in float64 precision, the user is (I am) expecting a float64 output, especially when the DNN written in high level API is used as a regressor. However, it returns float32, see the script in the end.\n\n\nWhen building a custom estimator using high level API, seems that the input layer has to be created by tf.feature_column.input_layer. See the guide here. This forbid the user from creating a network with dtype=float64 precision.\n\n\nOne may argue that dtype=float32 is already more than enough for DNN. But e.g. when doing theoretical work, the extra precision is desired.\nA possible fix is:\nChange line 2347 of function _transform_feature in file tensorflow/python/feature_column/feature_column.py, from\n return math_ops.to_float(input_tensor)\nto\n    if not input_tensor.dtype.is_floating:\n      return math_ops.to_float(input_tensor)\n    return input_tensor\nNote: this fix could breaks old code that has float32 assumption...\nIf this is considered as non-bug, then consider this as a feature request that make it possible to pass dtype=float64 through.\nSource code\n# Test tensorflow high level API.\n# dtype=float64 will be silently transformed to float32.\n\nimport sys\nimport numpy as np\nimport tensorflow as tf\n\ndef load_data(dtype):\n    l = 7\n    x1 = np.linspace(-1.0, 1.0, l, dtype=dtype)\n    z1 = np.sin(x1)\n    return ({'x':x1}, {'z':z1})\n\ndef train_input_fn(features, labels, batch_size):\n    dataset = tf.data.Dataset.from_tensor_slices((features, labels['z']))\n    dataset = dataset.repeat().batch(batch_size)\n    return dataset\n\ndef eval_input_fn(features):\n    dataset = tf.data.Dataset.from_tensor_slices(features)\n    dataset = dataset.batch(1)\n    return dataset\n\ndef main(argv):\n    dtype = np.float64   # specifies the data type\n\n    batch_size = 7\n    n_steps = 1\n\n    (train_x, train_y) = load_data(dtype)\n    my_feature_columns = [\n        tf.feature_column.numeric_column(\n            key   = 'x',\n            shape = (1,),\n            dtype = tf.as_dtype(train_x['x'].dtype))\n    ]\n\n    regressor = tf.estimator.DNNRegressor(   # or any other regressors\n        hidden_units    = [3],\n        feature_columns = my_feature_columns)\n\n    regressor.train(\n        input_fn = lambda:train_input_fn(train_x, train_y, batch_size),\n        steps    = n_steps)\n\n    predict_x = {'x': np.array([0.1, 0.2])}\n\n    predictions = regressor.predict(\n        input_fn=lambda:eval_input_fn(predict_x))\n\n    print([i for i in predictions]) # outputs are float32 instead of float64\n\nif __name__ == '__main__':\n    tf.app.run(main)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes. See the end.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Debian 9.4.\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nsource.\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.9.0-rc1\r\n\r\n- **Python version**: \r\n3.5.3\r\n\r\n- **Bazel version (if compiling from source)**:\r\n0.11.1\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\n6.3.0\r\n\r\n- **CUDA/cuDNN version**:\r\nNA (cpu only build)\r\n\r\n- **GPU model and memory**:\r\nNA (cpu only build)\r\n\r\n- **Exact command to reproduce**:\r\nSee the python script in the end. Just run it like:\r\n`python3 test_tf_float64.py`\r\n\r\n### The problem\r\nThe function `tf.feature_column.input_layer` return tensor in dtype=float32 for input dtype=float64.\r\n\r\nI know this is a [documented](https://github.com/tensorflow/tensorflow/blob/v1.9.0-rc1/tensorflow/python/feature_column/feature_column.py#L270) behavior, but this breaks things:\r\n\r\n1. When the training data is in float64 precision, the user is (I am) expecting a float64 output, especially when the DNN written in high level API is used as a regressor. However, it returns float32, see the script in the end.\r\n\r\n2. When building a custom estimator using high level API, seems that the input layer has to be created by `tf.feature_column.input_layer`. See the guide [here](https://www.tensorflow.org/get_started/custom_estimators#define_the_input_layer). This forbid the user from creating a network with dtype=float64 precision.\r\n\r\nOne may argue that dtype=float32 is already more than enough for DNN. But e.g. when doing theoretical work, the extra precision is desired.\r\n\r\nA possible fix is:\r\n\r\nChange line [2347](https://github.com/tensorflow/tensorflow/blob/v1.9.0-rc1/tensorflow/python/feature_column/feature_column.py#L2347) of function `_transform_feature` in file `tensorflow/python/feature_column/feature_column.py`, from\r\n\r\n```python3\r\n return math_ops.to_float(input_tensor)\r\n```\r\n\r\nto\r\n\r\n```python3\r\n    if not input_tensor.dtype.is_floating:\r\n      return math_ops.to_float(input_tensor)\r\n    return input_tensor\r\n```\r\n\r\nNote: this fix could breaks old code that has float32 assumption...\r\n\r\nIf this is considered as non-bug, then consider this as a feature request that make it possible to pass dtype=float64 through.\r\n\r\n### Source code\r\n```python3\r\n# Test tensorflow high level API.\r\n# dtype=float64 will be silently transformed to float32.\r\n\r\nimport sys\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef load_data(dtype):\r\n    l = 7\r\n    x1 = np.linspace(-1.0, 1.0, l, dtype=dtype)\r\n    z1 = np.sin(x1)\r\n    return ({'x':x1}, {'z':z1})\r\n\r\ndef train_input_fn(features, labels, batch_size):\r\n    dataset = tf.data.Dataset.from_tensor_slices((features, labels['z']))\r\n    dataset = dataset.repeat().batch(batch_size)\r\n    return dataset\r\n\r\ndef eval_input_fn(features):\r\n    dataset = tf.data.Dataset.from_tensor_slices(features)\r\n    dataset = dataset.batch(1)\r\n    return dataset\r\n\r\ndef main(argv):\r\n    dtype = np.float64   # specifies the data type\r\n\r\n    batch_size = 7\r\n    n_steps = 1\r\n\r\n    (train_x, train_y) = load_data(dtype)\r\n    my_feature_columns = [\r\n        tf.feature_column.numeric_column(\r\n            key   = 'x',\r\n            shape = (1,),\r\n            dtype = tf.as_dtype(train_x['x'].dtype))\r\n    ]\r\n\r\n    regressor = tf.estimator.DNNRegressor(   # or any other regressors\r\n        hidden_units    = [3],\r\n        feature_columns = my_feature_columns)\r\n\r\n    regressor.train(\r\n        input_fn = lambda:train_input_fn(train_x, train_y, batch_size),\r\n        steps    = n_steps)\r\n\r\n    predict_x = {'x': np.array([0.1, 0.2])}\r\n\r\n    predictions = regressor.predict(\r\n        input_fn=lambda:eval_input_fn(predict_x))\r\n\r\n    print([i for i in predictions]) # outputs are float32 instead of float64\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run(main)\r\n```"}