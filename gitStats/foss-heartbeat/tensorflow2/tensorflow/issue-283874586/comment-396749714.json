{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/396749714", "html_url": "https://github.com/tensorflow/tensorflow/issues/15554#issuecomment-396749714", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15554", "id": 396749714, "node_id": "MDEyOklzc3VlQ29tbWVudDM5Njc0OTcxNA==", "user": {"login": "aiff22", "id": 11368196, "node_id": "MDQ6VXNlcjExMzY4MTk2", "avatar_url": "https://avatars3.githubusercontent.com/u/11368196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aiff22", "html_url": "https://github.com/aiff22", "followers_url": "https://api.github.com/users/aiff22/followers", "following_url": "https://api.github.com/users/aiff22/following{/other_user}", "gists_url": "https://api.github.com/users/aiff22/gists{/gist_id}", "starred_url": "https://api.github.com/users/aiff22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aiff22/subscriptions", "organizations_url": "https://api.github.com/users/aiff22/orgs", "repos_url": "https://api.github.com/users/aiff22/repos", "events_url": "https://api.github.com/users/aiff22/events{/privacy}", "received_events_url": "https://api.github.com/users/aiff22/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-12T22:05:09Z", "updated_at": "2018-06-12T22:05:09Z", "author_association": "NONE", "body_html": "<p>We are recently doing phone ai benchmarking and checking the support of NNAPI on various android devices. The situation is now quite sad: in brief, only Huawei phones with Kirin's 970 NPU have drivers for it, while other devices are still lacking them. In general, the situation with TFLite/NNAPI is even more curious:</p>\n<ol>\n<li>TF Lite is ~1.5-2 times slower and consumes ~1.5-2 times more RAM than TF Mobile.</li>\n<li>If drivers for NNAPI are not available, this slows TFLite down by another 1.5-2 times.</li>\n<li>NNAPI supports only a subset of TF Lite operations, therefore the majority of models will crush after running with nnapi acceleration - even Inception-v1 and MobileNets are currently not supported, not to mention more complicated models.</li>\n</ol>\n<p>We are trying to keep track of the situation and are publishing the current performance of tflite/tfmobile on various devices on our webpage: <a href=\"http://ai-benchmark.com/ranking\" rel=\"nofollow\">http://ai-benchmark.com/ranking</a>. The phones supporting nnapi are denoted by green (currently it's only huawei), and as soon as new devices with acceleration support are released they will be added to this rating (btw, you can also find the running time and memory requirements for several classification and image-to-image translation networks on this page). If you need to check whether your phone supports nnapi, you can also run the app on it and at the end you will either get a message that it is supported, or a warning that it lacks the drivers.</p>\n<p>Hope this helps.</p>", "body_text": "We are recently doing phone ai benchmarking and checking the support of NNAPI on various android devices. The situation is now quite sad: in brief, only Huawei phones with Kirin's 970 NPU have drivers for it, while other devices are still lacking them. In general, the situation with TFLite/NNAPI is even more curious:\n\nTF Lite is ~1.5-2 times slower and consumes ~1.5-2 times more RAM than TF Mobile.\nIf drivers for NNAPI are not available, this slows TFLite down by another 1.5-2 times.\nNNAPI supports only a subset of TF Lite operations, therefore the majority of models will crush after running with nnapi acceleration - even Inception-v1 and MobileNets are currently not supported, not to mention more complicated models.\n\nWe are trying to keep track of the situation and are publishing the current performance of tflite/tfmobile on various devices on our webpage: http://ai-benchmark.com/ranking. The phones supporting nnapi are denoted by green (currently it's only huawei), and as soon as new devices with acceleration support are released they will be added to this rating (btw, you can also find the running time and memory requirements for several classification and image-to-image translation networks on this page). If you need to check whether your phone supports nnapi, you can also run the app on it and at the end you will either get a message that it is supported, or a warning that it lacks the drivers.\nHope this helps.", "body": "We are recently doing phone ai benchmarking and checking the support of NNAPI on various android devices. The situation is now quite sad: in brief, only Huawei phones with Kirin's 970 NPU have drivers for it, while other devices are still lacking them. In general, the situation with TFLite/NNAPI is even more curious:\r\n\r\n1) TF Lite is ~1.5-2 times slower and consumes ~1.5-2 times more RAM than TF Mobile.\r\n2) If drivers for NNAPI are not available, this slows TFLite down by another 1.5-2 times.\r\n3) NNAPI supports only a subset of TF Lite operations, therefore the majority of models will crush after running with nnapi acceleration - even Inception-v1 and MobileNets are currently not supported, not to mention more complicated models.\r\n\r\nWe are trying to keep track of the situation and are publishing the current performance of tflite/tfmobile on various devices on our webpage: http://ai-benchmark.com/ranking. The phones supporting nnapi are denoted by green (currently it's only huawei), and as soon as new devices with acceleration support are released they will be added to this rating (btw, you can also find the running time and memory requirements for several classification and image-to-image translation networks on this page). If you need to check whether your phone supports nnapi, you can also run the app on it and at the end you will either get a message that it is supported, or a warning that it lacks the drivers.\r\n\r\nHope this helps."}