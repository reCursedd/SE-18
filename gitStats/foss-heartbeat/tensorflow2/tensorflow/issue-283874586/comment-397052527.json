{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397052527", "html_url": "https://github.com/tensorflow/tensorflow/issues/15554#issuecomment-397052527", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15554", "id": 397052527, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzA1MjUyNw==", "user": {"login": "aiff22", "id": 11368196, "node_id": "MDQ6VXNlcjExMzY4MTk2", "avatar_url": "https://avatars3.githubusercontent.com/u/11368196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aiff22", "html_url": "https://github.com/aiff22", "followers_url": "https://api.github.com/users/aiff22/followers", "following_url": "https://api.github.com/users/aiff22/following{/other_user}", "gists_url": "https://api.github.com/users/aiff22/gists{/gist_id}", "starred_url": "https://api.github.com/users/aiff22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aiff22/subscriptions", "organizations_url": "https://api.github.com/users/aiff22/orgs", "repos_url": "https://api.github.com/users/aiff22/repos", "events_url": "https://api.github.com/users/aiff22/events{/privacy}", "received_events_url": "https://api.github.com/users/aiff22/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-13T19:11:29Z", "updated_at": "2018-06-19T15:04:10Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1162712\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/shashishekhar\">@shashishekhar</a></p>\n<p>Thank you for a fast reply. Yes, we are using Java API (with ByteBuffer), setting #threads wasn't available just recently, so it was set to some default number. We will try to play around it now and will let you know whether this will lead to better performance. However, most likely this won't solve the issue with RAM, and we guess that those two might be connected to each other.</p>\n<p>We benchmarked several models, including Inception-v1/v3, Inception-ResNet-v1, SRCNN, ResNet, VGG-19, ICNet and some other architectures (including both image classification and image-to-image translation nets). The difference between inference times for TFMobile/TFLite/TFLite+NNAPI was quite stable among all networks. In particular, this also applies for SRCNN that consists of two ops: conv and relu, and thus can be considered as a simplest baseline.</p>", "body_text": "@shashishekhar\nThank you for a fast reply. Yes, we are using Java API (with ByteBuffer), setting #threads wasn't available just recently, so it was set to some default number. We will try to play around it now and will let you know whether this will lead to better performance. However, most likely this won't solve the issue with RAM, and we guess that those two might be connected to each other.\nWe benchmarked several models, including Inception-v1/v3, Inception-ResNet-v1, SRCNN, ResNet, VGG-19, ICNet and some other architectures (including both image classification and image-to-image translation nets). The difference between inference times for TFMobile/TFLite/TFLite+NNAPI was quite stable among all networks. In particular, this also applies for SRCNN that consists of two ops: conv and relu, and thus can be considered as a simplest baseline.", "body": "@shashishekhar \r\n\r\nThank you for a fast reply. Yes, we are using Java API (with ByteBuffer), setting #threads wasn't available just recently, so it was set to some default number. We will try to play around it now and will let you know whether this will lead to better performance. However, most likely this won't solve the issue with RAM, and we guess that those two might be connected to each other.\r\n\r\nWe benchmarked several models, including Inception-v1/v3, Inception-ResNet-v1, SRCNN, ResNet, VGG-19, ICNet and some other architectures (including both image classification and image-to-image translation nets). The difference between inference times for TFMobile/TFLite/TFLite+NNAPI was quite stable among all networks. In particular, this also applies for SRCNN that consists of two ops: conv and relu, and thus can be considered as a simplest baseline."}