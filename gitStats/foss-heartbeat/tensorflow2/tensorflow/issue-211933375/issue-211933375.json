{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8093", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8093/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8093/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8093/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8093", "id": 211933375, "node_id": "MDU6SXNzdWUyMTE5MzMzNzU=", "number": 8093, "title": "CentOS - failed call to cuInit: CUresult(-1)", "user": {"login": "botev", "id": 1889878, "node_id": "MDQ6VXNlcjE4ODk4Nzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1889878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/botev", "html_url": "https://github.com/botev", "followers_url": "https://api.github.com/users/botev/followers", "following_url": "https://api.github.com/users/botev/following{/other_user}", "gists_url": "https://api.github.com/users/botev/gists{/gist_id}", "starred_url": "https://api.github.com/users/botev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/botev/subscriptions", "organizations_url": "https://api.github.com/users/botev/orgs", "repos_url": "https://api.github.com/users/botev/repos", "events_url": "https://api.github.com/users/botev/events{/privacy}", "received_events_url": "https://api.github.com/users/botev/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-03-05T06:13:21Z", "updated_at": "2017-03-10T07:51:40Z", "closed_at": "2017-03-10T07:51:40Z", "author_association": "NONE", "body_html": "<p>So, again me - I'm on centOS on a cluster. Have used <a href=\"http://stackoverflow.com/questions/33655731/error-while-importing-tensorflow-in-python2-7-in-ubuntu-12-04-glibc-2-17-not-f\" rel=\"nofollow\">this</a> hack for bypassing and using a different GLIBC. Now, however, there seems to be some weird issue with Tensorflow not wanting to run my GPU by failing something on the CUDA side.<br>\nSome general info:</p>\n<pre><code>LSB Version:    :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch\nDistributor ID: CentOS\nDescription:    CentOS release 6.5 (Final)\nRelease:        6.5\nCodename:       Final\nCUDA version: 8.0\nCUDNN version: 5.1\nPython version: 3.6.0\nLD_LIBRARY_PATH=/share/apps/barber/system/lib/:/share/apps/barber/system/lib64/:/opt/gridengine/lib/linux-x64:/opt/openmpi/lib/:/share/apps/barber/cuda/lib64/:/share/apps/barber/cuda/nvvm/lib64/:/share/apps/barber/cuda/extras/CUPTI/lib64:/share/apps/barber/cudnn/lib64/:/share/apps/barber/arrayfire-3/lib/:/share/apps/python-3.6.0-shared/lib/\n</code></pre>\n<p>The actual error I get from my code is (first 2 lines are printed by me):</p>\n<pre><code>Running tool: tensorflow\n/gpu:0\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could spe\ned up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could s\npeed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could s\npeed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could spee\nd up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could spe\ned up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could spee\nd up CPU computations.\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUresult(-1)\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: tesla2.local\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: tesla2.local\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.48  Sat Sep  3 18:21:08 PD\nT 2016\nGCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)\n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 367.48.0\nTraceback (most recent call last):\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1022, in _do_call\n    return fn(*args)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1000, in _run_fn\n    self._extend_graph()\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1049, in _extend_graph\n    self._session, graph_def.SerializeToString(), status)\n  File \"/share/apps/python-3.6.0-shared/lib/python3.6/contextlib.py\", line 89, in __exit__\n    next(self.gen)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit d\nevice specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:\n0\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\nadd_grad/Shape_1)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"bench.py\", line 23, in &lt;module&gt;\n    execute_all(**vars(parser.parse_args()))\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 40, in execute_all\n    wide=w, depth=d, batch=b)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 123, in single_experiment\n    f(model, device, temp_folder, **kwargs)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 80, in execute_experiment\n    session.run(init)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 767, in run\n    run_metadata_ptr)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 965, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\n    target_list, options, run_metadata)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit d\nevice specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:\n0\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\nadd_grad/Shape_1)]]\n\nCaused by op 'gradients/ff_1/add_grad/BroadcastGradientArgs', defined at:\n  File \"bench.py\", line 23, in &lt;module&gt;\n    execute_all(**vars(parser.parse_args()))\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 40, in execute_all\n    wide=w, depth=d, batch=b)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 123, in single_experiment\n    f(model, device, temp_folder, **kwargs)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 75, in execute_experiment\n    x_in, y_in, inference, train, cost = build_model(batch)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/ff.py\", line 21, in build_ff_net\n    train = optimizer.minimize(cost)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 288, in minimize\n    grad_loss=grad_loss)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 354, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\n    in_grads = grad_fn(op, *out_grads)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 586, in _AddGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 411, in _broadcast_gradient_args\n    name=name)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'ff_1/add', defined at:\n  File \"bench.py\", line 23, in &lt;module&gt;\n    execute_all(**vars(parser.parse_args()))\n[elided 2 identical lines from previous traceback]\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 75, in execute_experiment\n    x_in, y_in, inference, train, cost = build_model(batch)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/ff.py\", line 14, in build_ff_net\n    h = net.dense_layer(h, shape=(arch_specs[i-1], arch_specs[i]), nonlinearity=\"tanh\")\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/net.py\", line 40, in dense_layer\n    return f(tf.matmul(x_in, w) + tf.reshape(b, [1, -1]))\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 73, in add\n    result = _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit device specific\nation '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\nadd_grad/Shape_1)]]\n</code></pre>\n<p>One thing slightly suspicious is that it is picking up the default GCC (4.4) rather than the local user one (4.9), however I don't see how this relates to CUDA.</p>\n<p>However, the second error about <code>libcuda</code> version not found has been reported before in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175664993\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4267\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4267/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4267\">#4267</a>, while a similar issue seems to be <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"160420647\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2882\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2882/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2882\">#2882</a>. At this stage, there is not much I can really say why this is happening.</p>\n<p>Also for reference, both Theano and Pytorch worked out of the box, no errors, no complaints directly linking to both CUDA and CuDNN, so this is not a CUDA installation issue. Potentially the fact I use a separate GLIBC might be an issue, but again I don't see why myself.</p>\n<p>PS: This potentially could be some problem of the alternative GLIBC not detecting the GPUs, which to be more general than tensorflow, but I will need to talk with the system admin.</p>", "body_text": "So, again me - I'm on centOS on a cluster. Have used this hack for bypassing and using a different GLIBC. Now, however, there seems to be some weird issue with Tensorflow not wanting to run my GPU by failing something on the CUDA side.\nSome general info:\nLSB Version:    :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch\nDistributor ID: CentOS\nDescription:    CentOS release 6.5 (Final)\nRelease:        6.5\nCodename:       Final\nCUDA version: 8.0\nCUDNN version: 5.1\nPython version: 3.6.0\nLD_LIBRARY_PATH=/share/apps/barber/system/lib/:/share/apps/barber/system/lib64/:/opt/gridengine/lib/linux-x64:/opt/openmpi/lib/:/share/apps/barber/cuda/lib64/:/share/apps/barber/cuda/nvvm/lib64/:/share/apps/barber/cuda/extras/CUPTI/lib64:/share/apps/barber/cudnn/lib64/:/share/apps/barber/arrayfire-3/lib/:/share/apps/python-3.6.0-shared/lib/\n\nThe actual error I get from my code is (first 2 lines are printed by me):\nRunning tool: tensorflow\n/gpu:0\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could spe\ned up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could s\npeed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could s\npeed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could spee\nd up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could spe\ned up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could spee\nd up CPU computations.\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUresult(-1)\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: tesla2.local\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: tesla2.local\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.48  Sat Sep  3 18:21:08 PD\nT 2016\nGCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)\n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 367.48.0\nTraceback (most recent call last):\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1022, in _do_call\n    return fn(*args)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1000, in _run_fn\n    self._extend_graph()\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1049, in _extend_graph\n    self._session, graph_def.SerializeToString(), status)\n  File \"/share/apps/python-3.6.0-shared/lib/python3.6/contextlib.py\", line 89, in __exit__\n    next(self.gen)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit d\nevice specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:\n0\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\nadd_grad/Shape_1)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"bench.py\", line 23, in <module>\n    execute_all(**vars(parser.parse_args()))\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 40, in execute_all\n    wide=w, depth=d, batch=b)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 123, in single_experiment\n    f(model, device, temp_folder, **kwargs)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 80, in execute_experiment\n    session.run(init)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 767, in run\n    run_metadata_ptr)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 965, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\n    target_list, options, run_metadata)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit d\nevice specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:\n0\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\nadd_grad/Shape_1)]]\n\nCaused by op 'gradients/ff_1/add_grad/BroadcastGradientArgs', defined at:\n  File \"bench.py\", line 23, in <module>\n    execute_all(**vars(parser.parse_args()))\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 40, in execute_all\n    wide=w, depth=d, batch=b)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 123, in single_experiment\n    f(model, device, temp_folder, **kwargs)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 75, in execute_experiment\n    x_in, y_in, inference, train, cost = build_model(batch)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/ff.py\", line 21, in build_ff_net\n    train = optimizer.minimize(cost)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 288, in minimize\n    grad_loss=grad_loss)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 354, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\n    in_grads = grad_fn(op, *out_grads)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 586, in _AddGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 411, in _broadcast_gradient_args\n    name=name)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'ff_1/add', defined at:\n  File \"bench.py\", line 23, in <module>\n    execute_all(**vars(parser.parse_args()))\n[elided 2 identical lines from previous traceback]\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 75, in execute_experiment\n    x_in, y_in, inference, train, cost = build_model(batch)\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/ff.py\", line 14, in build_ff_net\n    h = net.dense_layer(h, shape=(arch_specs[i-1], arch_specs[i]), nonlinearity=\"tanh\")\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/net.py\", line 40, in dense_layer\n    return f(tf.matmul(x_in, w) + tf.reshape(b, [1, -1]))\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 73, in add\n    result = _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit device specific\nation '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\nadd_grad/Shape_1)]]\n\nOne thing slightly suspicious is that it is picking up the default GCC (4.4) rather than the local user one (4.9), however I don't see how this relates to CUDA.\nHowever, the second error about libcuda version not found has been reported before in #4267, while a similar issue seems to be #2882. At this stage, there is not much I can really say why this is happening.\nAlso for reference, both Theano and Pytorch worked out of the box, no errors, no complaints directly linking to both CUDA and CuDNN, so this is not a CUDA installation issue. Potentially the fact I use a separate GLIBC might be an issue, but again I don't see why myself.\nPS: This potentially could be some problem of the alternative GLIBC not detecting the GPUs, which to be more general than tensorflow, but I will need to talk with the system admin.", "body": "So, again me - I'm on centOS on a cluster. Have used [this](http://stackoverflow.com/questions/33655731/error-while-importing-tensorflow-in-python2-7-in-ubuntu-12-04-glibc-2-17-not-f) hack for bypassing and using a different GLIBC. Now, however, there seems to be some weird issue with Tensorflow not wanting to run my GPU by failing something on the CUDA side. \r\nSome general info:\r\n```\r\nLSB Version:    :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch\r\nDistributor ID: CentOS\r\nDescription:    CentOS release 6.5 (Final)\r\nRelease:        6.5\r\nCodename:       Final\r\nCUDA version: 8.0\r\nCUDNN version: 5.1\r\nPython version: 3.6.0\r\nLD_LIBRARY_PATH=/share/apps/barber/system/lib/:/share/apps/barber/system/lib64/:/opt/gridengine/lib/linux-x64:/opt/openmpi/lib/:/share/apps/barber/cuda/lib64/:/share/apps/barber/cuda/nvvm/lib64/:/share/apps/barber/cuda/extras/CUPTI/lib64:/share/apps/barber/cudnn/lib64/:/share/apps/barber/arrayfire-3/lib/:/share/apps/python-3.6.0-shared/lib/\r\n```\r\nThe actual error I get from my code is (first 2 lines are printed by me):\r\n```\r\nRunning tool: tensorflow\r\n/gpu:0\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could spe\r\ned up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could s\r\npeed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could s\r\npeed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could spee\r\nd up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could spe\r\ned up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could spee\r\nd up CPU computations.\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUresult(-1)\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: tesla2.local\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: tesla2.local\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.48  Sat Sep  3 18:21:08 PD\r\nT 2016\r\nGCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)\r\n\"\"\"\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 367.48.0\r\nTraceback (most recent call last):\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1022, in _do_call\r\n    return fn(*args)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1000, in _run_fn\r\n    self._extend_graph()\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1049, in _extend_graph\r\n    self._session, graph_def.SerializeToString(), status)\r\n  File \"/share/apps/python-3.6.0-shared/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n    next(self.gen)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit d\r\nevice specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:\r\n0\r\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\r\nadd_grad/Shape_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"bench.py\", line 23, in <module>\r\n    execute_all(**vars(parser.parse_args()))\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 40, in execute_all\r\n    wide=w, depth=d, batch=b)\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 123, in single_experiment\r\n    f(model, device, temp_folder, **kwargs)\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 80, in execute_experiment\r\n    session.run(init)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit d\r\nevice specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:\r\n0\r\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\r\nadd_grad/Shape_1)]]\r\n\r\nCaused by op 'gradients/ff_1/add_grad/BroadcastGradientArgs', defined at:\r\n  File \"bench.py\", line 23, in <module>\r\n    execute_all(**vars(parser.parse_args()))\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 40, in execute_all\r\n    wide=w, depth=d, batch=b)\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/executor.py\", line 123, in single_experiment\r\n    f(model, device, temp_folder, **kwargs)\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 75, in execute_experiment\r\n    x_in, y_in, inference, train, cost = build_model(batch)\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/ff.py\", line 21, in build_ff_net\r\n    train = optimizer.minimize(cost)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 288, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 354, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\r\n    in_grads = grad_fn(op, *out_grads)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 586, in _AddGrad\r\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 411, in _broadcast_gradient_args\r\n    name=name)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\n...which was originally created as op 'ff_1/add', defined at:\r\n  File \"bench.py\", line 23, in <module>\r\n    execute_all(**vars(parser.parse_args()))\r\n[elided 2 identical lines from previous traceback]\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/executor.py\", line 75, in execute_experiment\r\n    x_in, y_in, inference, train, cost = build_model(batch)\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/ff.py\", line 14, in build_ff_net\r\n    h = net.dense_layer(h, shape=(arch_specs[i-1], arch_specs[i]), nonlinearity=\"tanh\")\r\n  File \"/home/abotev/work/python/deep-bench/deep_bench/frameworks/tensorflow/net.py\", line 40, in dense_layer\r\n    return f(tf.matmul(x_in, w) + tf.reshape(b, [1, -1]))\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 73, in add\r\n    result = _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/share/apps/barber/system/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'gradients/ff_1/add_grad/BroadcastGradientArgs': Could not satisfy explicit device specific\r\nation '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\r\n         [[Node: gradients/ff_1/add_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/device:GPU:0\"](gradients/ff_1/add_grad/Shape, gradients/ff_1/\r\nadd_grad/Shape_1)]]\r\n```\r\nOne thing slightly suspicious is that it is picking up the default GCC (4.4) rather than the local user one (4.9), however I don't see how this relates to CUDA. \r\n\r\nHowever, the second error about `libcuda` version not found has been reported before in #4267, while a similar issue seems to be #2882. At this stage, there is not much I can really say why this is happening.\r\n\r\nAlso for reference, both Theano and Pytorch worked out of the box, no errors, no complaints directly linking to both CUDA and CuDNN, so this is not a CUDA installation issue. Potentially the fact I use a separate GLIBC might be an issue, but again I don't see why myself. \r\n\r\nPS: This potentially could be some problem of the alternative GLIBC not detecting the GPUs, which to be more general than tensorflow, but I will need to talk with the system admin.\r\n"}