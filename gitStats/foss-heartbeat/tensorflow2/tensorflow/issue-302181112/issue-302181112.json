{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17427", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17427/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17427/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17427/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17427", "id": 302181112, "node_id": "MDU6SXNzdWUzMDIxODExMTI=", "number": 17427, "title": "Feature Request: Train Using Multiple GPUs with Tensorflow in a Tower-like Fashion for tensorflow 1.4", "user": {"login": "selcouthlyBlue", "id": 13268675, "node_id": "MDQ6VXNlcjEzMjY4Njc1", "avatar_url": "https://avatars2.githubusercontent.com/u/13268675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/selcouthlyBlue", "html_url": "https://github.com/selcouthlyBlue", "followers_url": "https://api.github.com/users/selcouthlyBlue/followers", "following_url": "https://api.github.com/users/selcouthlyBlue/following{/other_user}", "gists_url": "https://api.github.com/users/selcouthlyBlue/gists{/gist_id}", "starred_url": "https://api.github.com/users/selcouthlyBlue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/selcouthlyBlue/subscriptions", "organizations_url": "https://api.github.com/users/selcouthlyBlue/orgs", "repos_url": "https://api.github.com/users/selcouthlyBlue/repos", "events_url": "https://api.github.com/users/selcouthlyBlue/events{/privacy}", "received_events_url": "https://api.github.com/users/selcouthlyBlue/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2018-03-05T05:59:45Z", "updated_at": "2018-04-04T08:44:12Z", "closed_at": "2018-04-04T08:44:12Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nN/A</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 8.1</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nBinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.4</li>\n<li><strong>Python version</strong>:<br>\n3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\nN/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\nN/A</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n8.0</li>\n<li><strong>GPU model and memory</strong>:<br>\n2 NVIDIA GeForce GTX 1070 (8 GB each)<br>\n-<strong>Exact command to reproduce</strong>:<br>\nN/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I tried training my model with a large batch size that is supposed to be enough just for two GPUs but I encounter out of memory errors. I'm using the Estimator API and I was wondering if it handles multi-gpu training like in this <a href=\"https://www.tensorflow.org/tutorials/deep_cnn#training_a_model_using_multiple_gpu_cards\" rel=\"nofollow\">example</a> using the cifar_10 dataset. If it doesn't, it would be nice to have the Estimator API handle multi-gpu training such that we can use larger batch sizes.</p>\n<h3>Source code / logs</h3>\n<p>Here's the architecture of the model I trained.</p>\n<pre><code>{\n  \"network\":[\n    {\"layer_type\": \"input_layer\", \"name\": \"inputs\", \"shape\": [-1, 168, 168, 1]},\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\n    {\"layer_type\": \"conv2d\", \"num_filters\": 16, \"kernel_size\": [3, 3]},\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\n    {\"layer_type\": \"conv2d\", \"num_filters\": 32, \"kernel_size\": [3, 3]},\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5},\n    {\"layer_type\": \"conv2d\", \"num_filters\": 64, \"kernel_size\": [3, 3]},\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5},\n    {\"layer_type\": \"collapse_to_rnn_dims\"},\n    {\"layer_type\": \"birnn\", \"num_hidden\": 128, \"cell_type\": \"LSTM\"},\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5}\n  ],\n  \"output_layer\": \"ctc_decoder\",\n  \"loss\": \"ctc\",\n  \"metrics\": [\"label_error_rate\"],\n  \"learning_rate\": 0.001,\n  \"optimizer\": \"adam\"\n}\n</code></pre>\n<p>The image dimensions are 168x168 px and the working batch size is 240 which I would like to double.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nN/A\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 8.1\nTensorFlow installed from (source or binary):\nBinary\nTensorFlow version (use command below):\n1.4\nPython version:\n3.6\nBazel version (if compiling from source):\nN/A\nGCC/Compiler version (if compiling from source):\nN/A\nCUDA/cuDNN version:\n8.0\nGPU model and memory:\n2 NVIDIA GeForce GTX 1070 (8 GB each)\n-Exact command to reproduce:\nN/A\n\nDescribe the problem\nI tried training my model with a large batch size that is supposed to be enough just for two GPUs but I encounter out of memory errors. I'm using the Estimator API and I was wondering if it handles multi-gpu training like in this example using the cifar_10 dataset. If it doesn't, it would be nice to have the Estimator API handle multi-gpu training such that we can use larger batch sizes.\nSource code / logs\nHere's the architecture of the model I trained.\n{\n  \"network\":[\n    {\"layer_type\": \"input_layer\", \"name\": \"inputs\", \"shape\": [-1, 168, 168, 1]},\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\n    {\"layer_type\": \"conv2d\", \"num_filters\": 16, \"kernel_size\": [3, 3]},\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\n    {\"layer_type\": \"conv2d\", \"num_filters\": 32, \"kernel_size\": [3, 3]},\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5},\n    {\"layer_type\": \"conv2d\", \"num_filters\": 64, \"kernel_size\": [3, 3]},\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5},\n    {\"layer_type\": \"collapse_to_rnn_dims\"},\n    {\"layer_type\": \"birnn\", \"num_hidden\": 128, \"cell_type\": \"LSTM\"},\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5}\n  ],\n  \"output_layer\": \"ctc_decoder\",\n  \"loss\": \"ctc\",\n  \"metrics\": [\"label_error_rate\"],\n  \"learning_rate\": 0.001,\n  \"optimizer\": \"adam\"\n}\n\nThe image dimensions are 168x168 px and the working batch size is 240 which I would like to double.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nN/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 8.1\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.4\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\n8.0\r\n- **GPU model and memory**:\r\n2 NVIDIA GeForce GTX 1070 (8 GB each)\r\n-**Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\nI tried training my model with a large batch size that is supposed to be enough just for two GPUs but I encounter out of memory errors. I'm using the Estimator API and I was wondering if it handles multi-gpu training like in this [example](https://www.tensorflow.org/tutorials/deep_cnn#training_a_model_using_multiple_gpu_cards) using the cifar_10 dataset. If it doesn't, it would be nice to have the Estimator API handle multi-gpu training such that we can use larger batch sizes.\r\n\r\n### Source code / logs\r\nHere's the architecture of the model I trained.\r\n\r\n```\r\n{\r\n  \"network\":[\r\n    {\"layer_type\": \"input_layer\", \"name\": \"inputs\", \"shape\": [-1, 168, 168, 1]},\r\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\r\n    {\"layer_type\": \"conv2d\", \"num_filters\": 16, \"kernel_size\": [3, 3]},\r\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\r\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\r\n    {\"layer_type\": \"conv2d\", \"num_filters\": 32, \"kernel_size\": [3, 3]},\r\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\r\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\r\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5},\r\n    {\"layer_type\": \"conv2d\", \"num_filters\": 64, \"kernel_size\": [3, 3]},\r\n    {\"layer_type\": \"max_pool2d\", \"pool_size\": [2, 2]},\r\n    {\"layer_type\": \"l2_normalize\", \"axis\": [1, 2]},\r\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5},\r\n    {\"layer_type\": \"collapse_to_rnn_dims\"},\r\n    {\"layer_type\": \"birnn\", \"num_hidden\": 128, \"cell_type\": \"LSTM\"},\r\n    {\"layer_type\": \"dropout\", \"keep_prob\": 0.5}\r\n  ],\r\n  \"output_layer\": \"ctc_decoder\",\r\n  \"loss\": \"ctc\",\r\n  \"metrics\": [\"label_error_rate\"],\r\n  \"learning_rate\": 0.001,\r\n  \"optimizer\": \"adam\"\r\n}\r\n```\r\n\r\nThe image dimensions are 168x168 px and the working batch size is 240 which I would like to double.\r\n"}