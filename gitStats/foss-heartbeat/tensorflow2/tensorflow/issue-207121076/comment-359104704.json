{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/359104704", "html_url": "https://github.com/tensorflow/tensorflow/issues/7456#issuecomment-359104704", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7456", "id": 359104704, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTEwNDcwNA==", "user": {"login": "milanfeind", "id": 8996449, "node_id": "MDQ6VXNlcjg5OTY0NDk=", "avatar_url": "https://avatars0.githubusercontent.com/u/8996449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/milanfeind", "html_url": "https://github.com/milanfeind", "followers_url": "https://api.github.com/users/milanfeind/followers", "following_url": "https://api.github.com/users/milanfeind/following{/other_user}", "gists_url": "https://api.github.com/users/milanfeind/gists{/gist_id}", "starred_url": "https://api.github.com/users/milanfeind/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/milanfeind/subscriptions", "organizations_url": "https://api.github.com/users/milanfeind/orgs", "repos_url": "https://api.github.com/users/milanfeind/repos", "events_url": "https://api.github.com/users/milanfeind/events{/privacy}", "received_events_url": "https://api.github.com/users/milanfeind/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-19T22:16:08Z", "updated_at": "2018-01-19T22:33:39Z", "author_association": "NONE", "body_html": "<p>Is there any news? I have a similar problem as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=24216379\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/YiMX\">@YiMX</a>  with 8 Tesla P100.<br>\nI pass the simpleP2P test. I use TensorFlow 1.4.1 and Cuda 8.0.</p>\n<p>Here are two of the error messages (shortened) I get,</p>\n<p>with <code>tf.add_check_numerics_ops()</code>:</p>\n<pre><code>...\nInvalidArgumentError (see above for traceback): tower_0/local3/L2Loss:0 : \nTensor had Inf values\n[[Node: CheckNumerics_173 = CheckNumerics[T=DT_FLOAT, \nmessage=\"tower_0/local3/L2Loss:0\", \n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]\n(tower_0/local3/L2Loss/_209, ^CheckNumerics_172)]]\n</code></pre>\n<p>and with <code>tf.check_numerics()</code> :</p>\n<pre><code>...\nInvalidArgumentError (see above for traceback): NaN: average_gradients(expanded_g) : \nTensor had Inf and NaN values\n [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, \nmessage=\"NaN: average_gradients(expanded_g)\", \n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ExpandDims_30)]]\n[[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, \nclient_terminated=false, \nrecv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", \nsend_device=\"/job:localhost/replica:0/task:0/device:GPU:6\", \nsend_device_incarnation=1, \ntensor_name=\"edge_4923_tower_6/total_loss\",\n _device=\"/job:localhost/replica:0/task:0/device:GPU:6\"](tower_6/total_loss)]]\n</code></pre>\n<p>The output from simpleP2P:</p>\n<pre><code>`[./simpleP2P] - Starting...\nChecking for multiple GPUs...\nCUDA-capable device count: 8\n&gt; GPU0 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n&gt; GPU1 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n&gt; GPU2 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n&gt; GPU3 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n&gt; GPU4 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n&gt; GPU5 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n&gt; GPU6 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n&gt; GPU7 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n\nChecking GPU(s) for support of peer to peer memory access...\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU0) -&gt; Tesla P100-PCIE-16GB (GPU1) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU0) -&gt; Tesla P100-PCIE-16GB (GPU2) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU0) -&gt; Tesla P100-PCIE-16GB (GPU3) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU0) -&gt; Tesla P100-PCIE-16GB (GPU4) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU0) -&gt; Tesla P100-PCIE-16GB (GPU5) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU0) -&gt; Tesla P100-PCIE-16GB (GPU6) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU0) -&gt; Tesla P100-PCIE-16GB (GPU7) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU1) -&gt; Tesla P100-PCIE-16GB (GPU0) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU1) -&gt; Tesla P100-PCIE-16GB (GPU2) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU1) -&gt; Tesla P100-PCIE-16GB (GPU3) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU1) -&gt; Tesla P100-PCIE-16GB (GPU4) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU1) -&gt; Tesla P100-PCIE-16GB (GPU5) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU1) -&gt; Tesla P100-PCIE-16GB (GPU6) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU1) -&gt; Tesla P100-PCIE-16GB (GPU7) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU2) -&gt; Tesla P100-PCIE-16GB (GPU0) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU2) -&gt; Tesla P100-PCIE-16GB (GPU1) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU2) -&gt; Tesla P100-PCIE-16GB (GPU3) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU2) -&gt; Tesla P100-PCIE-16GB (GPU4) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU2) -&gt; Tesla P100-PCIE-16GB (GPU5) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU2) -&gt; Tesla P100-PCIE-16GB (GPU6) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU2) -&gt; Tesla P100-PCIE-16GB (GPU7) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU3) -&gt; Tesla P100-PCIE-16GB (GPU0) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU3) -&gt; Tesla P100-PCIE-16GB (GPU1) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU3) -&gt; Tesla P100-PCIE-16GB (GPU2) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU3) -&gt; Tesla P100-PCIE-16GB (GPU4) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU3) -&gt; Tesla P100-PCIE-16GB (GPU5) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU3) -&gt; Tesla P100-PCIE-16GB (GPU6) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU3) -&gt; Tesla P100-PCIE-16GB (GPU7) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU4) -&gt; Tesla P100-PCIE-16GB (GPU0) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU4) -&gt; Tesla P100-PCIE-16GB (GPU1) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU4) -&gt; Tesla P100-PCIE-16GB (GPU2) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU4) -&gt; Tesla P100-PCIE-16GB (GPU3) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU4) -&gt; Tesla P100-PCIE-16GB (GPU5) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU4) -&gt; Tesla P100-PCIE-16GB (GPU6) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU4) -&gt; Tesla P100-PCIE-16GB (GPU7) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU5) -&gt; Tesla P100-PCIE-16GB (GPU0) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU5) -&gt; Tesla P100-PCIE-16GB (GPU1) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU5) -&gt; Tesla P100-PCIE-16GB (GPU2) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU5) -&gt; Tesla P100-PCIE-16GB (GPU3) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU5) -&gt; Tesla P100-PCIE-16GB (GPU4) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU5) -&gt; Tesla P100-PCIE-16GB (GPU6) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU5) -&gt; Tesla P100-PCIE-16GB (GPU7) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU6) -&gt; Tesla P100-PCIE-16GB (GPU0) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU6) -&gt; Tesla P100-PCIE-16GB (GPU1) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU6) -&gt; Tesla P100-PCIE-16GB (GPU2) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU6) -&gt; Tesla P100-PCIE-16GB (GPU3) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU6) -&gt; Tesla P100-PCIE-16GB (GPU4) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU6) -&gt; Tesla P100-PCIE-16GB (GPU5) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU6) -&gt; Tesla P100-PCIE-16GB (GPU7) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU7) -&gt; Tesla P100-PCIE-16GB (GPU0) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU7) -&gt; Tesla P100-PCIE-16GB (GPU1) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU7) -&gt; Tesla P100-PCIE-16GB (GPU2) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU7) -&gt; Tesla P100-PCIE-16GB (GPU3) : No\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU7) -&gt; Tesla P100-PCIE-16GB (GPU4) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU7) -&gt; Tesla P100-PCIE-16GB (GPU5) : Yes\n&gt; Peer access from Tesla P100-PCIE-16GB (GPU7) -&gt; Tesla P100-PCIE-16GB (GPU6) : Yes\nEnabling peer access between GPU0 and GPU1...\nChecking GPU0 and GPU1 for UVA capabilities...\n&gt; Tesla P100-PCIE-16GB (GPU0) supports UVA: Yes\n&gt; Tesla P100-PCIE-16GB (GPU1) supports UVA: Yes\nBoth GPUs can support UVA, enabling...\nAllocating buffers (64MB on GPU0, GPU1 and CPU Host)...\nCreating event handles...\ncudaMemcpyPeer / cudaMemcpy between GPU0 and GPU1: 12.16GB/s\nPreparing host buffer and memcpy to GPU0...\nRun kernel on GPU1, taking source data from GPU0 and writing to GPU1...\nRun kernel on GPU0, taking source data from GPU1 and writing to GPU0...\nCopy data back to host from GPU0 and verify results...\nDisabling peer access...\nShutting down...\nTest passed\n</code></pre>", "body_text": "Is there any news? I have a similar problem as @YiMX  with 8 Tesla P100.\nI pass the simpleP2P test. I use TensorFlow 1.4.1 and Cuda 8.0.\nHere are two of the error messages (shortened) I get,\nwith tf.add_check_numerics_ops():\n...\nInvalidArgumentError (see above for traceback): tower_0/local3/L2Loss:0 : \nTensor had Inf values\n[[Node: CheckNumerics_173 = CheckNumerics[T=DT_FLOAT, \nmessage=\"tower_0/local3/L2Loss:0\", \n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]\n(tower_0/local3/L2Loss/_209, ^CheckNumerics_172)]]\n\nand with tf.check_numerics() :\n...\nInvalidArgumentError (see above for traceback): NaN: average_gradients(expanded_g) : \nTensor had Inf and NaN values\n [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, \nmessage=\"NaN: average_gradients(expanded_g)\", \n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ExpandDims_30)]]\n[[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, \nclient_terminated=false, \nrecv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", \nsend_device=\"/job:localhost/replica:0/task:0/device:GPU:6\", \nsend_device_incarnation=1, \ntensor_name=\"edge_4923_tower_6/total_loss\",\n _device=\"/job:localhost/replica:0/task:0/device:GPU:6\"](tower_6/total_loss)]]\n\nThe output from simpleP2P:\n`[./simpleP2P] - Starting...\nChecking for multiple GPUs...\nCUDA-capable device count: 8\n> GPU0 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n> GPU1 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n> GPU2 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n> GPU3 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n> GPU4 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n> GPU5 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n> GPU6 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n> GPU7 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\n\nChecking GPU(s) for support of peer to peer memory access...\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU1) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU2) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU3) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU4) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU5) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU6) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU7) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU0) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU2) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU3) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU4) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU5) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU6) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU7) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU0) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU1) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU3) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU4) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU5) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU6) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU7) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU0) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU1) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU2) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU4) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU5) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU6) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU7) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU0) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU1) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU2) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU3) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU5) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU6) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU7) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU0) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU1) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU2) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU3) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU4) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU6) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU7) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU0) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU1) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU2) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU3) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU4) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU5) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU7) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU0) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU1) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU2) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU3) : No\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU4) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU5) : Yes\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU6) : Yes\nEnabling peer access between GPU0 and GPU1...\nChecking GPU0 and GPU1 for UVA capabilities...\n> Tesla P100-PCIE-16GB (GPU0) supports UVA: Yes\n> Tesla P100-PCIE-16GB (GPU1) supports UVA: Yes\nBoth GPUs can support UVA, enabling...\nAllocating buffers (64MB on GPU0, GPU1 and CPU Host)...\nCreating event handles...\ncudaMemcpyPeer / cudaMemcpy between GPU0 and GPU1: 12.16GB/s\nPreparing host buffer and memcpy to GPU0...\nRun kernel on GPU1, taking source data from GPU0 and writing to GPU1...\nRun kernel on GPU0, taking source data from GPU1 and writing to GPU0...\nCopy data back to host from GPU0 and verify results...\nDisabling peer access...\nShutting down...\nTest passed", "body": "Is there any news? I have a similar problem as @YiMX  with 8 Tesla P100. \r\nI pass the simpleP2P test. I use TensorFlow 1.4.1 and Cuda 8.0.\r\n\r\nHere are two of the error messages (shortened) I get,\r\n\r\nwith `tf.add_check_numerics_ops()`:\r\n```\r\n...\r\nInvalidArgumentError (see above for traceback): tower_0/local3/L2Loss:0 : \r\nTensor had Inf values\r\n[[Node: CheckNumerics_173 = CheckNumerics[T=DT_FLOAT, \r\nmessage=\"tower_0/local3/L2Loss:0\", \r\n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]\r\n(tower_0/local3/L2Loss/_209, ^CheckNumerics_172)]]\r\n```\r\nand with `tf.check_numerics()` :\r\n```\r\n...\r\nInvalidArgumentError (see above for traceback): NaN: average_gradients(expanded_g) : \r\nTensor had Inf and NaN values\r\n [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, \r\nmessage=\"NaN: average_gradients(expanded_g)\", \r\n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ExpandDims_30)]]\r\n[[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, \r\nclient_terminated=false, \r\nrecv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", \r\nsend_device=\"/job:localhost/replica:0/task:0/device:GPU:6\", \r\nsend_device_incarnation=1, \r\ntensor_name=\"edge_4923_tower_6/total_loss\",\r\n _device=\"/job:localhost/replica:0/task:0/device:GPU:6\"](tower_6/total_loss)]]\r\n```\r\n\r\nThe output from simpleP2P:\r\n```\r\n`[./simpleP2P] - Starting...\r\nChecking for multiple GPUs...\r\nCUDA-capable device count: 8\r\n> GPU0 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\r\n> GPU1 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\r\n> GPU2 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\r\n> GPU3 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\r\n> GPU4 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\r\n> GPU5 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\r\n> GPU6 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\r\n> GPU7 = \"Tesla P100-PCIE-16GB\" IS  capable of Peer-to-Peer (P2P)\r\n\r\nChecking GPU(s) for support of peer to peer memory access...\r\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU1) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU2) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU3) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU4) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU5) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU6) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU0) -> Tesla P100-PCIE-16GB (GPU7) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU0) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU2) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU3) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU4) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU5) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU6) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU1) -> Tesla P100-PCIE-16GB (GPU7) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU0) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU1) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU3) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU4) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU5) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU6) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU2) -> Tesla P100-PCIE-16GB (GPU7) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU0) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU1) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU2) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU4) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU5) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU6) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU3) -> Tesla P100-PCIE-16GB (GPU7) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU0) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU1) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU2) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU3) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU5) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU6) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU4) -> Tesla P100-PCIE-16GB (GPU7) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU0) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU1) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU2) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU3) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU4) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU6) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU5) -> Tesla P100-PCIE-16GB (GPU7) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU0) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU1) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU2) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU3) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU4) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU5) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU6) -> Tesla P100-PCIE-16GB (GPU7) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU0) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU1) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU2) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU3) : No\r\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU4) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU5) : Yes\r\n> Peer access from Tesla P100-PCIE-16GB (GPU7) -> Tesla P100-PCIE-16GB (GPU6) : Yes\r\nEnabling peer access between GPU0 and GPU1...\r\nChecking GPU0 and GPU1 for UVA capabilities...\r\n> Tesla P100-PCIE-16GB (GPU0) supports UVA: Yes\r\n> Tesla P100-PCIE-16GB (GPU1) supports UVA: Yes\r\nBoth GPUs can support UVA, enabling...\r\nAllocating buffers (64MB on GPU0, GPU1 and CPU Host)...\r\nCreating event handles...\r\ncudaMemcpyPeer / cudaMemcpy between GPU0 and GPU1: 12.16GB/s\r\nPreparing host buffer and memcpy to GPU0...\r\nRun kernel on GPU1, taking source data from GPU0 and writing to GPU1...\r\nRun kernel on GPU0, taking source data from GPU1 and writing to GPU0...\r\nCopy data back to host from GPU0 and verify results...\r\nDisabling peer access...\r\nShutting down...\r\nTest passed\r\n```"}