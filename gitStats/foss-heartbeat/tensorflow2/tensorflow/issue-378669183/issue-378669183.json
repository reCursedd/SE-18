{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23598", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23598/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23598/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23598/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23598", "id": 378669183, "node_id": "MDU6SXNzdWUzNzg2NjkxODM=", "number": 23598, "title": "Wrong output of AveragePool operation, for a quantization TF lite model ", "user": {"login": "MissyDu", "id": 44862377, "node_id": "MDQ6VXNlcjQ0ODYyMzc3", "avatar_url": "https://avatars3.githubusercontent.com/u/44862377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MissyDu", "html_url": "https://github.com/MissyDu", "followers_url": "https://api.github.com/users/MissyDu/followers", "following_url": "https://api.github.com/users/MissyDu/following{/other_user}", "gists_url": "https://api.github.com/users/MissyDu/gists{/gist_id}", "starred_url": "https://api.github.com/users/MissyDu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MissyDu/subscriptions", "organizations_url": "https://api.github.com/users/MissyDu/orgs", "repos_url": "https://api.github.com/users/MissyDu/repos", "events_url": "https://api.github.com/users/MissyDu/events{/privacy}", "received_events_url": "https://api.github.com/users/MissyDu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "liyunlu0618", "id": 9705880, "node_id": "MDQ6VXNlcjk3MDU4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9705880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liyunlu0618", "html_url": "https://github.com/liyunlu0618", "followers_url": "https://api.github.com/users/liyunlu0618/followers", "following_url": "https://api.github.com/users/liyunlu0618/following{/other_user}", "gists_url": "https://api.github.com/users/liyunlu0618/gists{/gist_id}", "starred_url": "https://api.github.com/users/liyunlu0618/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liyunlu0618/subscriptions", "organizations_url": "https://api.github.com/users/liyunlu0618/orgs", "repos_url": "https://api.github.com/users/liyunlu0618/repos", "events_url": "https://api.github.com/users/liyunlu0618/events{/privacy}", "received_events_url": "https://api.github.com/users/liyunlu0618/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "liyunlu0618", "id": 9705880, "node_id": "MDQ6VXNlcjk3MDU4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9705880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liyunlu0618", "html_url": "https://github.com/liyunlu0618", "followers_url": "https://api.github.com/users/liyunlu0618/followers", "following_url": "https://api.github.com/users/liyunlu0618/following{/other_user}", "gists_url": "https://api.github.com/users/liyunlu0618/gists{/gist_id}", "starred_url": "https://api.github.com/users/liyunlu0618/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liyunlu0618/subscriptions", "organizations_url": "https://api.github.com/users/liyunlu0618/orgs", "repos_url": "https://api.github.com/users/liyunlu0618/repos", "events_url": "https://api.github.com/users/liyunlu0618/events{/privacy}", "received_events_url": "https://api.github.com/users/liyunlu0618/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-11-08T10:30:47Z", "updated_at": "2018-11-21T19:40:58Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>step1: Train a TF model to be a quantization one by adding Fake Node.<br>\nstep2: Convert the quantization TF model to be a TF Lite model with command:<br>\n<code> ./bazel-bin/tensorflow/contrib/lite/toco/toco  --output_file=~/deeplab_mobilenetv2_quantized.tflite   --input_file=~/frozen_inference_graph.pb   --inference_type=QUANTIZED_UINT8  --input_arrays=Placeholder  --output_arrays=ResizeBilinear_2  --mean_values=0  --std_dev_values=1  --input_shapes=1,513,513,3</code></p>\n<p>step3. Run the quantization TF lite model on an Android phone.</p>\n<p>I find, for thethe output of model,  there is a big difference between TF and quantization TF lite .</p>\n<p>So, I compared the output of maily operations of model, one by one. And I find that:<br>\n1&gt; For conv operataion, the output difference are less than 1.<br>\n2&gt; But for a AveragePool operation,the output of TF lite seem to be completely wrong. After debug, I find the kernel implementation is running by calling the interface <code>TF_LITE_AVERAGE_POOL(optimized_ops)</code>(in file: tensorflow/lite/kernels/pooling.cc).</p>\n<p>But when I use <code>TF_LITE_AVERAGE_POOL(reference_ops)</code> to replace it by modifying the \"pooling.cc\" in the \"AverageEvalQuantized(...const uint8* input_data...)\" as:<br>\n<code> if (kernel_type == kReference) {</code><br>\n<code>TF_LITE_AVERAGE_POOL(reference_ops);</code><br>\n<code>} else {</code><br>\n<code> //TF_LITE_AVERAGE_POOL(optimized_ops);</code><br>\n<code>TF_LITE_AVERAGE_POOL(reference_ops) ;</code><br>\n<code>}</code><br>\nAfter build and run, find that the difference are also less than 1.</p>\n<p>In all, the issue is:<br>\nThe output of AveragePool operation seem to be wrong when use the interface  <code>TF_LITE_AVERAGE_POOL(optimized_ops)</code>.</p>\n<p>Would you like to enlighten me whether I make some mistakes when I use AveragePool.</p>\n<p>And would you like to do a test for AveragePool operation with:<br>\ninput size: 1x33x33x320 (NxHxWxC)<br>\ninput data type: int8, range at 100~255<br>\npool_params-&gt;stride_width = 33;<br>\npool_params-&gt;stride_height = 33;<br>\npool_params-&gt;filter_height = 33;<br>\npool_params-&gt;filter_width = 33;<br>\npool_params-&gt;activation = kTfLiteActNone;<br>\npool_params-&gt;padding = kTfLitePaddingValid;</p>\n<p>System info for your reference:</p>\n<ul>\n<li>OS Platform: Linux Ubuntu 16.04</li>\n<li>Mobile device:XiaoMi Note</li>\n<li>TensorFlow version: commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/d1e9a1ed54cae9b0b10ab89c06d6d7f9b53af3a1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/d1e9a1ed54cae9b0b10ab89c06d6d7f9b53af3a1\"><tt>d1e9a1e</tt></a></li>\n<li>Python version:2.7.6</li>\n<li>Bazel version:0.15.0</li>\n</ul>", "body_text": "Hello,\nstep1: Train a TF model to be a quantization one by adding Fake Node.\nstep2: Convert the quantization TF model to be a TF Lite model with command:\n ./bazel-bin/tensorflow/contrib/lite/toco/toco  --output_file=~/deeplab_mobilenetv2_quantized.tflite   --input_file=~/frozen_inference_graph.pb   --inference_type=QUANTIZED_UINT8  --input_arrays=Placeholder  --output_arrays=ResizeBilinear_2  --mean_values=0  --std_dev_values=1  --input_shapes=1,513,513,3\nstep3. Run the quantization TF lite model on an Android phone.\nI find, for thethe output of model,  there is a big difference between TF and quantization TF lite .\nSo, I compared the output of maily operations of model, one by one. And I find that:\n1> For conv operataion, the output difference are less than 1.\n2> But for a AveragePool operation,the output of TF lite seem to be completely wrong. After debug, I find the kernel implementation is running by calling the interface TF_LITE_AVERAGE_POOL(optimized_ops)(in file: tensorflow/lite/kernels/pooling.cc).\nBut when I use TF_LITE_AVERAGE_POOL(reference_ops) to replace it by modifying the \"pooling.cc\" in the \"AverageEvalQuantized(...const uint8* input_data...)\" as:\n if (kernel_type == kReference) {\nTF_LITE_AVERAGE_POOL(reference_ops);\n} else {\n //TF_LITE_AVERAGE_POOL(optimized_ops);\nTF_LITE_AVERAGE_POOL(reference_ops) ;\n}\nAfter build and run, find that the difference are also less than 1.\nIn all, the issue is:\nThe output of AveragePool operation seem to be wrong when use the interface  TF_LITE_AVERAGE_POOL(optimized_ops).\nWould you like to enlighten me whether I make some mistakes when I use AveragePool.\nAnd would you like to do a test for AveragePool operation with:\ninput size: 1x33x33x320 (NxHxWxC)\ninput data type: int8, range at 100~255\npool_params->stride_width = 33;\npool_params->stride_height = 33;\npool_params->filter_height = 33;\npool_params->filter_width = 33;\npool_params->activation = kTfLiteActNone;\npool_params->padding = kTfLitePaddingValid;\nSystem info for your reference:\n\nOS Platform: Linux Ubuntu 16.04\nMobile device:XiaoMi Note\nTensorFlow version: commit d1e9a1e\nPython version:2.7.6\nBazel version:0.15.0", "body": "Hello, \r\n\r\nstep1: Train a TF model to be a quantization one by adding Fake Node.\r\nstep2: Convert the quantization TF model to be a TF Lite model with command: \r\n` ./bazel-bin/tensorflow/contrib/lite/toco/toco \r\n        --output_file=~/deeplab_mobilenetv2_quantized.tflite  \r\n        --input_file=~/frozen_inference_graph.pb  \r\n        --inference_type=QUANTIZED_UINT8 \r\n        --input_arrays=Placeholder \r\n        --output_arrays=ResizeBilinear_2 \r\n        --mean_values=0 \r\n        --std_dev_values=1 \r\n        --input_shapes=1,513,513,3`\r\n         \r\nstep3. Run the quantization TF lite model on an Android phone.\r\n\r\nI find, for thethe output of model,  there is a big difference between TF and quantization TF lite .\r\n\r\nSo, I compared the output of maily operations of model, one by one. And I find that:\r\n1> For conv operataion, the output difference are less than 1.\r\n2> But for a AveragePool operation,the output of TF lite seem to be completely wrong. After debug, I find the kernel implementation is running by calling the interface `TF_LITE_AVERAGE_POOL(optimized_ops)`(in file: tensorflow/lite/kernels/pooling.cc).\r\n\r\nBut when I use `TF_LITE_AVERAGE_POOL(reference_ops)` to replace it by modifying the \"pooling.cc\" in the \"AverageEvalQuantized(...const uint8* input_data...)\" as: \r\n     ` if (kernel_type == kReference) {`\r\n          `TF_LITE_AVERAGE_POOL(reference_ops);`\r\n     `} else {`\r\n         ` //TF_LITE_AVERAGE_POOL(optimized_ops);`\r\n         `TF_LITE_AVERAGE_POOL(reference_ops) ;`\r\n       `}`\r\nAfter build and run, find that the difference are also less than 1.\r\n\r\nIn all, the issue is:\r\nThe output of AveragePool operation seem to be wrong when use the interface  `TF_LITE_AVERAGE_POOL(optimized_ops)`.\r\n\r\nWould you like to enlighten me whether I make some mistakes when I use AveragePool.\r\n\r\nAnd would you like to do a test for AveragePool operation with:\r\n   input size: 1x33x33x320 (NxHxWxC)\r\n   input data type: int8, range at 100~255\r\n   pool_params->stride_width = 33;\r\n   pool_params->stride_height = 33;\r\n   pool_params->filter_height = 33;\r\n   pool_params->filter_width = 33;\r\n   pool_params->activation = kTfLiteActNone;\r\n   pool_params->padding = kTfLitePaddingValid;\r\n\r\nSystem info for your reference:\r\n   - OS Platform: Linux Ubuntu 16.04\r\n   - Mobile device:XiaoMi Note\r\n   - TensorFlow version: commit d1e9a1ed54cae9b0b10ab89c06d6d7f9b53af3a1\r\n   - Python version:2.7.6\r\n   - Bazel version:0.15.0\r\n"}