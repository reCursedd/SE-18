{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13552", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13552/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13552/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13552/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13552", "id": 263649388, "node_id": "MDU6SXNzdWUyNjM2NDkzODg=", "number": 13552, "title": "how to restore the certain variable_scope Variables into another certain variable_scope?", "user": {"login": "FesianXu", "id": 12878858, "node_id": "MDQ6VXNlcjEyODc4ODU4", "avatar_url": "https://avatars3.githubusercontent.com/u/12878858?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FesianXu", "html_url": "https://github.com/FesianXu", "followers_url": "https://api.github.com/users/FesianXu/followers", "following_url": "https://api.github.com/users/FesianXu/following{/other_user}", "gists_url": "https://api.github.com/users/FesianXu/gists{/gist_id}", "starred_url": "https://api.github.com/users/FesianXu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FesianXu/subscriptions", "organizations_url": "https://api.github.com/users/FesianXu/orgs", "repos_url": "https://api.github.com/users/FesianXu/repos", "events_url": "https://api.github.com/users/FesianXu/events{/privacy}", "received_events_url": "https://api.github.com/users/FesianXu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-10-07T15:29:50Z", "updated_at": "2018-07-13T05:30:58Z", "closed_at": "2017-10-07T18:10:17Z", "author_association": "NONE", "body_html": "<p>Now I have trained a model A and I need two model A instances because one of them just is fixed and untrainable for outputting and another is trainable for next network. I design two variable_scope <strong>A_train</strong> and <strong>A_untrain</strong>, I pre-trained A model in variable_scope <strong>A_untrain</strong> and restore the model also in this scope, code like:</p>\n<div class=\"highlight highlight-source-python\"><pre>saver_untrain <span class=\"pl-k\">=</span> tf.train.Saver(tf.get_collection(\n                                   tf.GraphKeys.<span class=\"pl-c1\">GLOBAL_VARIABLES</span>,\n                                   <span class=\"pl-s\"><span class=\"pl-pds\">'</span>A_untrain<span class=\"pl-pds\">'</span></span>))\nsaver_path <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>~/models/model.ckpt<span class=\"pl-pds\">'</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> here pre-train model A</span>\nsaver_untrain.save(sess, saver_path)</pre></div>\n<p>Now I need to restore the same model A parameters into the same model in scope <strong>A_train</strong>, but I cannot follow the previous code because the ckpt files restore the params like <code>A_untrain/input_w1</code> instread of <code>A_train/input_w1</code>. I want to know if there is a solution to my problem OR a better solution to make two instances which one is trainable and another is untrainable. Thanks a lot.</p>\n<p><strong>EDIT_1</strong>: I know I can realize my need use code like:</p>\n<p>saver_train = tf.train.Saver({'A_untrain/input_w1': A_train.input_w1})<br>\nbut it will be unpractical when my variables amount is large, so I need to use the variable_scope to restore instead of the specific variables' names.</p>", "body_text": "Now I have trained a model A and I need two model A instances because one of them just is fixed and untrainable for outputting and another is trainable for next network. I design two variable_scope A_train and A_untrain, I pre-trained A model in variable_scope A_untrain and restore the model also in this scope, code like:\nsaver_untrain = tf.train.Saver(tf.get_collection(\n                                   tf.GraphKeys.GLOBAL_VARIABLES,\n                                   'A_untrain'))\nsaver_path = '~/models/model.ckpt'\n# here pre-train model A\nsaver_untrain.save(sess, saver_path)\nNow I need to restore the same model A parameters into the same model in scope A_train, but I cannot follow the previous code because the ckpt files restore the params like A_untrain/input_w1 instread of A_train/input_w1. I want to know if there is a solution to my problem OR a better solution to make two instances which one is trainable and another is untrainable. Thanks a lot.\nEDIT_1: I know I can realize my need use code like:\nsaver_train = tf.train.Saver({'A_untrain/input_w1': A_train.input_w1})\nbut it will be unpractical when my variables amount is large, so I need to use the variable_scope to restore instead of the specific variables' names.", "body": "Now I have trained a model A and I need two model A instances because one of them just is fixed and untrainable for outputting and another is trainable for next network. I design two variable_scope **A_train** and **A_untrain**, I pre-trained A model in variable_scope **A_untrain** and restore the model also in this scope, code like:\r\n```python\r\nsaver_untrain = tf.train.Saver(tf.get_collection(\r\n                                   tf.GraphKeys.GLOBAL_VARIABLES,\r\n                                   'A_untrain'))\r\nsaver_path = '~/models/model.ckpt'\r\n# here pre-train model A\r\nsaver_untrain.save(sess, saver_path)\r\n```\r\nNow I need to restore the same model A parameters into the same model in scope **A_train**, but I cannot follow the previous code because the ckpt files restore the params like `A_untrain/input_w1` instread of `A_train/input_w1`. I want to know if there is a solution to my problem OR a better solution to make two instances which one is trainable and another is untrainable. Thanks a lot.\r\n\r\n**EDIT_1**: I know I can realize my need use code like:\r\n\r\nsaver_train = tf.train.Saver({'A_untrain/input_w1': A_train.input_w1})\r\nbut it will be unpractical when my variables amount is large, so I need to use the variable_scope to restore instead of the specific variables' names."}