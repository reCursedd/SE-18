{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/330669070", "html_url": "https://github.com/tensorflow/tensorflow/issues/13160#issuecomment-330669070", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13160", "id": 330669070, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDY2OTA3MA==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-19T20:49:07Z", "updated_at": "2017-09-19T21:59:47Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Marking the node as recomputable is not enough to save memory. You also have to specify when the recomputation happens.</p>\n<p>TensorFlow scheduling logic (in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/executor.cc\">executor.cc</a>) schedules nodes to evaluate soon as they are ready, so TensorFlow will happily recompute the node right away and hold it in memory which won't save you any memory.</p>\n<p>Fun example -- something like <code>functools.reduce(tf.matmul, [tf.random_uniform((k,k))]*n)</code> needs O(n) memory in TensorFlow because by the time the first <code>matmul</code> is done, it will eval all the <code>random_uniform</code> nodes.</p>\n<p>You can implement this recomputation on client level by inserting control dependencies to force a memory efficient order (like <a href=\"https://github.com/yaroslavvb/stuff/tree/master/linearize\">here</a>), and duplicating nodes you want to be recomputed (using tf.contrib.graph_editor like <a href=\"https://github.com/yaroslavvb/stuff/blob/master/simple_rewiring.ipynb\">here</a> or rewriting the graph in C++ API like <a href=\"https://github.com/tensorflow/tensorflow/blob/cd4c17e63125da5e0047c3bdd05b483e86cc6759/tensorflow/core/grappler/optimizers/memory_optimizer.cc#L44\">here</a>).</p>\n<p>I do agree that current methods are quite awkward</p>", "body_text": "Marking the node as recomputable is not enough to save memory. You also have to specify when the recomputation happens.\nTensorFlow scheduling logic (in executor.cc) schedules nodes to evaluate soon as they are ready, so TensorFlow will happily recompute the node right away and hold it in memory which won't save you any memory.\nFun example -- something like functools.reduce(tf.matmul, [tf.random_uniform((k,k))]*n) needs O(n) memory in TensorFlow because by the time the first matmul is done, it will eval all the random_uniform nodes.\nYou can implement this recomputation on client level by inserting control dependencies to force a memory efficient order (like here), and duplicating nodes you want to be recomputed (using tf.contrib.graph_editor like here or rewriting the graph in C++ API like here).\nI do agree that current methods are quite awkward", "body": "Marking the node as recomputable is not enough to save memory. You also have to specify when the recomputation happens.\r\n\r\nTensorFlow scheduling logic (in [executor.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/executor.cc)) schedules nodes to evaluate soon as they are ready, so TensorFlow will happily recompute the node right away and hold it in memory which won't save you any memory.\r\n\r\nFun example -- something like `functools.reduce(tf.matmul, [tf.random_uniform((k,k))]*n)` needs O(n) memory in TensorFlow because by the time the first `matmul` is done, it will eval all the `random_uniform` nodes.\r\n\r\nYou can implement this recomputation on client level by inserting control dependencies to force a memory efficient order (like [here](https://github.com/yaroslavvb/stuff/tree/master/linearize)), and duplicating nodes you want to be recomputed (using tf.contrib.graph_editor like [here](https://github.com/yaroslavvb/stuff/blob/master/simple_rewiring.ipynb) or rewriting the graph in C++ API like [here](https://github.com/tensorflow/tensorflow/blob/cd4c17e63125da5e0047c3bdd05b483e86cc6759/tensorflow/core/grappler/optimizers/memory_optimizer.cc#L44)).\r\n\r\nI do agree that current methods are quite awkward"}