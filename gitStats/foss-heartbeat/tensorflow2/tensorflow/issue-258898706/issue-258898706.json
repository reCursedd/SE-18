{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13160", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13160/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13160/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13160/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13160", "id": 258898706, "node_id": "MDU6SXNzdWUyNTg4OTg3MDY=", "number": 13160, "title": "[feature request]recomputable operation annotation", "user": {"login": "llvim", "id": 7426917, "node_id": "MDQ6VXNlcjc0MjY5MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/7426917?v=4", "gravatar_id": "", "url": "https://api.github.com/users/llvim", "html_url": "https://github.com/llvim", "followers_url": "https://api.github.com/users/llvim/followers", "following_url": "https://api.github.com/users/llvim/following{/other_user}", "gists_url": "https://api.github.com/users/llvim/gists{/gist_id}", "starred_url": "https://api.github.com/users/llvim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/llvim/subscriptions", "organizations_url": "https://api.github.com/users/llvim/orgs", "repos_url": "https://api.github.com/users/llvim/repos", "events_url": "https://api.github.com/users/llvim/events{/privacy}", "received_events_url": "https://api.github.com/users/llvim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "josh11b", "id": 15258583, "node_id": "MDQ6VXNlcjE1MjU4NTgz", "avatar_url": "https://avatars0.githubusercontent.com/u/15258583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josh11b", "html_url": "https://github.com/josh11b", "followers_url": "https://api.github.com/users/josh11b/followers", "following_url": "https://api.github.com/users/josh11b/following{/other_user}", "gists_url": "https://api.github.com/users/josh11b/gists{/gist_id}", "starred_url": "https://api.github.com/users/josh11b/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josh11b/subscriptions", "organizations_url": "https://api.github.com/users/josh11b/orgs", "repos_url": "https://api.github.com/users/josh11b/repos", "events_url": "https://api.github.com/users/josh11b/events{/privacy}", "received_events_url": "https://api.github.com/users/josh11b/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "josh11b", "id": 15258583, "node_id": "MDQ6VXNlcjE1MjU4NTgz", "avatar_url": "https://avatars0.githubusercontent.com/u/15258583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josh11b", "html_url": "https://github.com/josh11b", "followers_url": "https://api.github.com/users/josh11b/followers", "following_url": "https://api.github.com/users/josh11b/following{/other_user}", "gists_url": "https://api.github.com/users/josh11b/gists{/gist_id}", "starred_url": "https://api.github.com/users/josh11b/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josh11b/subscriptions", "organizations_url": "https://api.github.com/users/josh11b/orgs", "repos_url": "https://api.github.com/users/josh11b/repos", "events_url": "https://api.github.com/users/josh11b/events{/privacy}", "received_events_url": "https://api.github.com/users/josh11b/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2017-09-19T17:17:57Z", "updated_at": "2018-02-03T00:30:28Z", "closed_at": "2018-02-03T00:30:28Z", "author_association": "NONE", "body_html": "<p>'Training Deep Nets with Sublinear Memory Cost' and 'Memory-Efficient Implementation of DenseNets' indicate that use drop intermediate feature map and recompute it if needed can save memory(while add computation burden),</p>\n<p>so we need some mechanism to annotate some op's inputs  <code>recomputable</code> , and drop this input memory after op finish(set input's reference count to 0), when need this op again, recompute it.</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> tf.get_varible(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>,<span class=\"pl-c1\">10</span>])\nb <span class=\"pl-k\">=</span> tf.get_varible(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>,<span class=\"pl-c1\">10</span>])\nc <span class=\"pl-k\">=</span> tf.get_varible(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>,<span class=\"pl-c1\">10</span>])\nd <span class=\"pl-k\">=</span> a<span class=\"pl-k\">*</span>b\nd_recomputable <span class=\"pl-k\">=</span> tf.recomputable(d)\ne <span class=\"pl-k\">=</span> d_recomputable<span class=\"pl-k\">+</span>c</pre></div>\n<p>relate issue</p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"148266318\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1934\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1934/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1934\">#1934</a></li>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"256532521\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/12948\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/12948/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/12948\">#12948</a></li>\n</ul>\n<p>in short, normal reference add reference count, recomputable reference do not add reference count</p>", "body_text": "'Training Deep Nets with Sublinear Memory Cost' and 'Memory-Efficient Implementation of DenseNets' indicate that use drop intermediate feature map and recompute it if needed can save memory(while add computation burden),\nso we need some mechanism to annotate some op's inputs  recomputable , and drop this input memory after op finish(set input's reference count to 0), when need this op again, recompute it.\na = tf.get_varible(shape=[None,10])\nb = tf.get_varible(shape=[None,10])\nc = tf.get_varible(shape=[None,10])\nd = a*b\nd_recomputable = tf.recomputable(d)\ne = d_recomputable+c\nrelate issue\n\n#1934\n#12948\n\nin short, normal reference add reference count, recomputable reference do not add reference count", "body": "'Training Deep Nets with Sublinear Memory Cost' and 'Memory-Efficient Implementation of DenseNets' indicate that use drop intermediate feature map and recompute it if needed can save memory(while add computation burden),\r\n\r\nso we need some mechanism to annotate some op's inputs  `recomputable` , and drop this input memory after op finish(set input's reference count to 0), when need this op again, recompute it.\r\n\r\n```python\r\na = tf.get_varible(shape=[None,10])\r\nb = tf.get_varible(shape=[None,10])\r\nc = tf.get_varible(shape=[None,10])\r\nd = a*b\r\nd_recomputable = tf.recomputable(d)\r\ne = d_recomputable+c\r\n```\r\nrelate issue \r\n- https://github.com/tensorflow/tensorflow/issues/1934\r\n- https://github.com/tensorflow/tensorflow/issues/12948\r\n\r\nin short, normal reference add reference count, recomputable reference do not add reference count\r\n"}