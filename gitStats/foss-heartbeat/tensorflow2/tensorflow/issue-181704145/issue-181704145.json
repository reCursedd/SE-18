{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4823", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4823/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4823/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4823/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4823", "id": 181704145, "node_id": "MDU6SXNzdWUxODE3MDQxNDU=", "number": 4823, "title": "Tensorflow not using GPU (according to TensorBoard)", "user": {"login": "seeb0h", "id": 4989990, "node_id": "MDQ6VXNlcjQ5ODk5OTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/4989990?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seeb0h", "html_url": "https://github.com/seeb0h", "followers_url": "https://api.github.com/users/seeb0h/followers", "following_url": "https://api.github.com/users/seeb0h/following{/other_user}", "gists_url": "https://api.github.com/users/seeb0h/gists{/gist_id}", "starred_url": "https://api.github.com/users/seeb0h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seeb0h/subscriptions", "organizations_url": "https://api.github.com/users/seeb0h/orgs", "repos_url": "https://api.github.com/users/seeb0h/repos", "events_url": "https://api.github.com/users/seeb0h/events{/privacy}", "received_events_url": "https://api.github.com/users/seeb0h/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-10-07T15:49:32Z", "updated_at": "2018-03-06T19:30:56Z", "closed_at": "2016-10-10T14:43:31Z", "author_association": "NONE", "body_html": "<p>GTX 1070, ubuntu 16.04.</p>\n<p>I am retraining <a href=\"https://github.com/tensorflow/models/tree/master/inception\">inception</a> model on my own data. Everything is fine until the final command :</p>\n<pre><code>bazel-bin/inception/flowers_train \\\n  --config=cuda \\\n  --train_dir=\"${TRAIN_DIR}\" \\\n  --data_dir=\"${OUTPUT_DIRECTORY}\" \\\n  --pretrained_model_checkpoint_path=\"${MODEL_PATH}\" \\\n  --fine_tune=True \\\n  --initial_learning_rate=0.001 \\\n  --input_queue_memory_factor=1\n</code></pre>\n<p>According to the logs, <strong>Tensorflow seems to be using the GPU</strong> :</p>\n<pre><code>I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties:\nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7715\npciBusID 0000:03:00.0\nTotal memory: 7.92GiB\nFree memory: 7.77GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1070, pci bus id: 0000:03:00.0)\n</code></pre>\n<p>But when I am checking the learning in TensorBoard, <strong>the net is using mainly the CPU</strong> (blue /device:CPU:0, green /device:GPU:0):</p>\n<p>TensorBoard graph:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4989990/19196523/33a2e6c2-8cb6-11e6-85b1-1f35950657e3.png\"><img src=\"https://cloud.githubusercontent.com/assets/4989990/19196523/33a2e6c2-8cb6-11e6-85b1-1f35950657e3.png\" alt=\"graph\" style=\"max-width:100%;\"></a></p>\n<p>I have tried this two TensorFlow setups :</p>\n<ol>\n<li>\n<p>Install from the source (<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/3b75eb34ea2c4982fb80843be089f02d430faade/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/3b75eb34ea2c4982fb80843be089f02d430faade\"><tt>3b75eb3</tt></a>) with nvidia-367 drivers, CUDA8 8.0, cuDNN<br>\nv5,    source from the master (16/10/06 - r11?). compiled for GPU<br>\nuse:</p>\n<pre><code>bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nbazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu    \nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n</code></pre>\n</li>\n<li>\n<p>docker GPU image of Tensorflow on a PC with a GTX<br>\n1070 8Go</p>\n<pre><code>nvidia-docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow:latest-gpu /bin/bash\n</code></pre>\n</li>\n</ol>\n<p>According to the doc Cuda &gt;=7.0 can be used when installed from sources.</p>\n<blockquote>\n<p>The GPU version works best with Cuda Toolkit 7.5 and cuDNN v5. Other versions are supported (Cuda toolkit &gt;= 7.0 and cuDNN &gt;= v3) only when installing from sources</p>\n</blockquote>\n<p>And the dockerfile begins with <code>FROM nvidia/cuda:7.5-cudnn5-devel</code>. So it is not using cuda and cudnn of the host system</p>", "body_text": "GTX 1070, ubuntu 16.04.\nI am retraining inception model on my own data. Everything is fine until the final command :\nbazel-bin/inception/flowers_train \\\n  --config=cuda \\\n  --train_dir=\"${TRAIN_DIR}\" \\\n  --data_dir=\"${OUTPUT_DIRECTORY}\" \\\n  --pretrained_model_checkpoint_path=\"${MODEL_PATH}\" \\\n  --fine_tune=True \\\n  --initial_learning_rate=0.001 \\\n  --input_queue_memory_factor=1\n\nAccording to the logs, Tensorflow seems to be using the GPU :\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties:\nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7715\npciBusID 0000:03:00.0\nTotal memory: 7.92GiB\nFree memory: 7.77GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:03:00.0)\n\nBut when I am checking the learning in TensorBoard, the net is using mainly the CPU (blue /device:CPU:0, green /device:GPU:0):\nTensorBoard graph:\n\nI have tried this two TensorFlow setups :\n\n\nInstall from the source (3b75eb3) with nvidia-367 drivers, CUDA8 8.0, cuDNN\nv5,    source from the master (16/10/06 - r11?). compiled for GPU\nuse:\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nbazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu    \nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\n\n\ndocker GPU image of Tensorflow on a PC with a GTX\n1070 8Go\nnvidia-docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow:latest-gpu /bin/bash\n\n\n\nAccording to the doc Cuda >=7.0 can be used when installed from sources.\n\nThe GPU version works best with Cuda Toolkit 7.5 and cuDNN v5. Other versions are supported (Cuda toolkit >= 7.0 and cuDNN >= v3) only when installing from sources\n\nAnd the dockerfile begins with FROM nvidia/cuda:7.5-cudnn5-devel. So it is not using cuda and cudnn of the host system", "body": "GTX 1070, ubuntu 16.04.\n\nI am retraining [inception](https://github.com/tensorflow/models/tree/master/inception) model on my own data. Everything is fine until the final command :\n\n```\nbazel-bin/inception/flowers_train \\\n  --config=cuda \\\n  --train_dir=\"${TRAIN_DIR}\" \\\n  --data_dir=\"${OUTPUT_DIRECTORY}\" \\\n  --pretrained_model_checkpoint_path=\"${MODEL_PATH}\" \\\n  --fine_tune=True \\\n  --initial_learning_rate=0.001 \\\n  --input_queue_memory_factor=1\n```\n\nAccording to the logs, **Tensorflow seems to be using the GPU** :\n\n```\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties:\nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7715\npciBusID 0000:03:00.0\nTotal memory: 7.92GiB\nFree memory: 7.77GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:03:00.0)\n```\n\nBut when I am checking the learning in TensorBoard, **the net is using mainly the CPU** (blue /device:CPU:0, green /device:GPU:0):\n\nTensorBoard graph:\n\n![graph](https://cloud.githubusercontent.com/assets/4989990/19196523/33a2e6c2-8cb6-11e6-85b1-1f35950657e3.png)\n\nI have tried this two TensorFlow setups :\n1. Install from the source (3b75eb34ea2c4982fb80843be089f02d430faade) with nvidia-367 drivers, CUDA8 8.0, cuDNN\n   v5,    source from the master (16/10/06 - r11?). compiled for GPU\n   use:\n   \n   ```\n   bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n   bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu    \n   bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n   ```\n2. docker GPU image of Tensorflow on a PC with a GTX\n   1070 8Go\n   \n   ```\n   nvidia-docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow:latest-gpu /bin/bash\n   ```\n\nAccording to the doc Cuda >=7.0 can be used when installed from sources. \n\n> The GPU version works best with Cuda Toolkit 7.5 and cuDNN v5. Other versions are supported (Cuda toolkit >= 7.0 and cuDNN >= v3) only when installing from sources\n\nAnd the dockerfile begins with `FROM nvidia/cuda:7.5-cudnn5-devel`. So it is not using cuda and cudnn of the host system\n"}