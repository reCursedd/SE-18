{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/284221149", "html_url": "https://github.com/tensorflow/tensorflow/issues/7956#issuecomment-284221149", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7956", "id": 284221149, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NDIyMTE0OQ==", "user": {"login": "langmore", "id": 178152, "node_id": "MDQ6VXNlcjE3ODE1Mg==", "avatar_url": "https://avatars2.githubusercontent.com/u/178152?v=4", "gravatar_id": "", "url": "https://api.github.com/users/langmore", "html_url": "https://github.com/langmore", "followers_url": "https://api.github.com/users/langmore/followers", "following_url": "https://api.github.com/users/langmore/following{/other_user}", "gists_url": "https://api.github.com/users/langmore/gists{/gist_id}", "starred_url": "https://api.github.com/users/langmore/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/langmore/subscriptions", "organizations_url": "https://api.github.com/users/langmore/orgs", "repos_url": "https://api.github.com/users/langmore/repos", "events_url": "https://api.github.com/users/langmore/events{/privacy}", "received_events_url": "https://api.github.com/users/langmore/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-05T11:17:11Z", "updated_at": "2017-03-05T11:17:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2409854\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/akuz\">@akuz</a> , I agree that your original suggestion does provide an alternative method to compute the log_prob on the space of probabilities by intercepting an intermediate step of computation of an input.</p>\n<p>So.... we can't call this <code>log_prob</code> since it isn't one.  akuz's original suggestion of <code>log_prob_with_logits(x)</code> would work (although I think the <code>alpha</code> in the formula should be <code>alpha - 1</code>).  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> I think the options are:</p>\n<ol>\n<li>Do nothing, let users build their own (<code>Dirichlet._log_unnormalized_prob</code> will help BTW)</li>\n<li>Write a helper function, e.g. <code>dirichlet_log_prob_with_logits(dirichlet_dist, logits)</code>.</li>\n<li>Create a <code>Dirichlet.log_prob_with_logits(logits)</code> method.</li>\n</ol>\n<p>BTW, the dimensionality restriction on SoftmaxCentered is that it works for batch scalars and vectors (event_ndims = 0 or 1), not batch matrices (event_ndims = 2).  So it would work well for a Tensor of shape [2, 3, 4, 5], representing a shape [2, 3, 4] batch of length [5] logits.  But, it seems this is not what you need.</p>", "body_text": "@akuz , I agree that your original suggestion does provide an alternative method to compute the log_prob on the space of probabilities by intercepting an intermediate step of computation of an input.\nSo.... we can't call this log_prob since it isn't one.  akuz's original suggestion of log_prob_with_logits(x) would work (although I think the alpha in the formula should be alpha - 1).  @ebrevdo I think the options are:\n\nDo nothing, let users build their own (Dirichlet._log_unnormalized_prob will help BTW)\nWrite a helper function, e.g. dirichlet_log_prob_with_logits(dirichlet_dist, logits).\nCreate a Dirichlet.log_prob_with_logits(logits) method.\n\nBTW, the dimensionality restriction on SoftmaxCentered is that it works for batch scalars and vectors (event_ndims = 0 or 1), not batch matrices (event_ndims = 2).  So it would work well for a Tensor of shape [2, 3, 4, 5], representing a shape [2, 3, 4] batch of length [5] logits.  But, it seems this is not what you need.", "body": "@akuz , I agree that your original suggestion does provide an alternative method to compute the log_prob on the space of probabilities by intercepting an intermediate step of computation of an input.\r\n\r\nSo.... we can't call this `log_prob` since it isn't one.  akuz's original suggestion of `log_prob_with_logits(x)` would work (although I think the `alpha` in the formula should be `alpha - 1`).  @ebrevdo I think the options are:\r\n\r\n1. Do nothing, let users build their own (`Dirichlet._log_unnormalized_prob` will help BTW)\r\n1. Write a helper function, e.g. `dirichlet_log_prob_with_logits(dirichlet_dist, logits)`.\r\n1. Create a `Dirichlet.log_prob_with_logits(logits)` method.\r\n\r\nBTW, the dimensionality restriction on SoftmaxCentered is that it works for batch scalars and vectors (event_ndims = 0 or 1), not batch matrices (event_ndims = 2).  So it would work well for a Tensor of shape [2, 3, 4, 5], representing a shape [2, 3, 4] batch of length [5] logits.  But, it seems this is not what you need."}