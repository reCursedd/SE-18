{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/396011295", "html_url": "https://github.com/tensorflow/tensorflow/issues/3332#issuecomment-396011295", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3332", "id": 396011295, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjAxMTI5NQ==", "user": {"login": "lubomir1", "id": 21107748, "node_id": "MDQ6VXNlcjIxMTA3NzQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/21107748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lubomir1", "html_url": "https://github.com/lubomir1", "followers_url": "https://api.github.com/users/lubomir1/followers", "following_url": "https://api.github.com/users/lubomir1/following{/other_user}", "gists_url": "https://api.github.com/users/lubomir1/gists{/gist_id}", "starred_url": "https://api.github.com/users/lubomir1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lubomir1/subscriptions", "organizations_url": "https://api.github.com/users/lubomir1/orgs", "repos_url": "https://api.github.com/users/lubomir1/repos", "events_url": "https://api.github.com/users/lubomir1/events{/privacy}", "received_events_url": "https://api.github.com/users/lubomir1/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-10T01:07:47Z", "updated_at": "2018-06-10T01:07:47Z", "author_association": "NONE", "body_html": "<p>Please add support for group convolutions! Caffe and PyTorch have had an efficient implementation for nearly two years, and the current state of the art models leverage groups. Even though one can use depthwise_conv2d_native followed by a sum, this is a very slow and memory-demanding way to implement it, even with the latest CuDNN optimization.</p>\n<p>I tried a group convolution with 256 channels and 32 groups, 3x3 kernel and in PyTorch it ran x2 the speed of full convolution (groups==1), whereas if I do it in tf with depthwise_conv2d_native it is 5 times slower relative to full convolution -- so PyTorch is 10 times faster in this case, which is very common in ResNeXt style architectures. I am using the latest TF build and have enabled the CuDNN support for it with a kernel label map.</p>", "body_text": "Please add support for group convolutions! Caffe and PyTorch have had an efficient implementation for nearly two years, and the current state of the art models leverage groups. Even though one can use depthwise_conv2d_native followed by a sum, this is a very slow and memory-demanding way to implement it, even with the latest CuDNN optimization.\nI tried a group convolution with 256 channels and 32 groups, 3x3 kernel and in PyTorch it ran x2 the speed of full convolution (groups==1), whereas if I do it in tf with depthwise_conv2d_native it is 5 times slower relative to full convolution -- so PyTorch is 10 times faster in this case, which is very common in ResNeXt style architectures. I am using the latest TF build and have enabled the CuDNN support for it with a kernel label map.", "body": "Please add support for group convolutions! Caffe and PyTorch have had an efficient implementation for nearly two years, and the current state of the art models leverage groups. Even though one can use depthwise_conv2d_native followed by a sum, this is a very slow and memory-demanding way to implement it, even with the latest CuDNN optimization.\r\n\r\nI tried a group convolution with 256 channels and 32 groups, 3x3 kernel and in PyTorch it ran x2 the speed of full convolution (groups==1), whereas if I do it in tf with depthwise_conv2d_native it is 5 times slower relative to full convolution -- so PyTorch is 10 times faster in this case, which is very common in ResNeXt style architectures. I am using the latest TF build and have enabled the CuDNN support for it with a kernel label map.\r\n"}