{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/406245906", "html_url": "https://github.com/tensorflow/tensorflow/issues/3332#issuecomment-406245906", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3332", "id": 406245906, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNjI0NTkwNg==", "user": {"login": "Timen", "id": 567392, "node_id": "MDQ6VXNlcjU2NzM5Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/567392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Timen", "html_url": "https://github.com/Timen", "followers_url": "https://api.github.com/users/Timen/followers", "following_url": "https://api.github.com/users/Timen/following{/other_user}", "gists_url": "https://api.github.com/users/Timen/gists{/gist_id}", "starred_url": "https://api.github.com/users/Timen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Timen/subscriptions", "organizations_url": "https://api.github.com/users/Timen/orgs", "repos_url": "https://api.github.com/users/Timen/repos", "events_url": "https://api.github.com/users/Timen/events{/privacy}", "received_events_url": "https://api.github.com/users/Timen/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-19T11:35:15Z", "updated_at": "2018-07-19T11:41:50Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I implemented a basic version of grouped convolutions(note these are different than depthwise convolutions) using normal convolutions and splitting the input tensor and weights tensor. The implementation is compatible with slim and accepts the slim argscope.</p>\n<p>It can be found here: <a href=\"https://github.com/Timen/squeezenext-tensorflow/blob/master/tensorflow_extentions/grouped_convolution.py\">https://github.com/Timen/squeezenext-tensorflow/blob/master/tensorflow_extentions/grouped_convolution.py</a></p>\n<p>It mainly relies on this function to split the inputs and filters and applies convolutions to each subset:</p>\n<pre><code>def grouped_convolution2D(inputs, filters, padding, num_groups,\n                          strides=None,\n                          dilation_rate=None):\n    \"\"\"\n    Performs a grouped convolution by applying a normal convolution to each of the seperate groups\n    :param inputs:\n        Input of the shape [&lt;batch_size&gt;,H,W,inC]\n    :param filters:\n        [H,W,inC/num_groups,outC]\n    :param padding:\n        What padding to use\n    :param num_groups:\n        Number of seperate groups\n    :param strides:\n        Stride\n    :param dilation_rate:\n        Dilation rate\n    :return:\n        Output of shape [&lt;batch_size&gt;,H/stride,W/stride,outC]\n    \"\"\"\n    # Split input and outputs along their last dimension\n    input_list = tf.split(inputs, num_groups, axis=-1)\n    filter_list = tf.split(filters, num_groups, axis=-1)\n    output_list = []\n\n    # Perform a normal convolution on each split of the input and filters\n    for conv_idx, (input_tensor, filter_tensor) in enumerate(zip(input_list, filter_list)):\n        output_list.append(tf.nn.convolution(\n            input_tensor,\n            filter_tensor,\n            padding,\n            strides=strides,\n            dilation_rate=dilation_rate,\n            name=\"grouped_convolution\" + \"_{}\".format(conv_idx)\n        ))\n    # Concatenate ouptputs along their last dimentsion\n    outputs = tf.concat(output_list, axis=-1)\n\n    return outputs\n</code></pre>", "body_text": "I implemented a basic version of grouped convolutions(note these are different than depthwise convolutions) using normal convolutions and splitting the input tensor and weights tensor. The implementation is compatible with slim and accepts the slim argscope.\nIt can be found here: https://github.com/Timen/squeezenext-tensorflow/blob/master/tensorflow_extentions/grouped_convolution.py\nIt mainly relies on this function to split the inputs and filters and applies convolutions to each subset:\ndef grouped_convolution2D(inputs, filters, padding, num_groups,\n                          strides=None,\n                          dilation_rate=None):\n    \"\"\"\n    Performs a grouped convolution by applying a normal convolution to each of the seperate groups\n    :param inputs:\n        Input of the shape [<batch_size>,H,W,inC]\n    :param filters:\n        [H,W,inC/num_groups,outC]\n    :param padding:\n        What padding to use\n    :param num_groups:\n        Number of seperate groups\n    :param strides:\n        Stride\n    :param dilation_rate:\n        Dilation rate\n    :return:\n        Output of shape [<batch_size>,H/stride,W/stride,outC]\n    \"\"\"\n    # Split input and outputs along their last dimension\n    input_list = tf.split(inputs, num_groups, axis=-1)\n    filter_list = tf.split(filters, num_groups, axis=-1)\n    output_list = []\n\n    # Perform a normal convolution on each split of the input and filters\n    for conv_idx, (input_tensor, filter_tensor) in enumerate(zip(input_list, filter_list)):\n        output_list.append(tf.nn.convolution(\n            input_tensor,\n            filter_tensor,\n            padding,\n            strides=strides,\n            dilation_rate=dilation_rate,\n            name=\"grouped_convolution\" + \"_{}\".format(conv_idx)\n        ))\n    # Concatenate ouptputs along their last dimentsion\n    outputs = tf.concat(output_list, axis=-1)\n\n    return outputs", "body": "I implemented a basic version of grouped convolutions(note these are different than depthwise convolutions) using normal convolutions and splitting the input tensor and weights tensor. The implementation is compatible with slim and accepts the slim argscope. \r\n\r\nIt can be found here: [https://github.com/Timen/squeezenext-tensorflow/blob/master/tensorflow_extentions/grouped_convolution.py](https://github.com/Timen/squeezenext-tensorflow/blob/master/tensorflow_extentions/grouped_convolution.py)\r\n\r\nIt mainly relies on this function to split the inputs and filters and applies convolutions to each subset:\r\n```\r\ndef grouped_convolution2D(inputs, filters, padding, num_groups,\r\n                          strides=None,\r\n                          dilation_rate=None):\r\n    \"\"\"\r\n    Performs a grouped convolution by applying a normal convolution to each of the seperate groups\r\n    :param inputs:\r\n        Input of the shape [<batch_size>,H,W,inC]\r\n    :param filters:\r\n        [H,W,inC/num_groups,outC]\r\n    :param padding:\r\n        What padding to use\r\n    :param num_groups:\r\n        Number of seperate groups\r\n    :param strides:\r\n        Stride\r\n    :param dilation_rate:\r\n        Dilation rate\r\n    :return:\r\n        Output of shape [<batch_size>,H/stride,W/stride,outC]\r\n    \"\"\"\r\n    # Split input and outputs along their last dimension\r\n    input_list = tf.split(inputs, num_groups, axis=-1)\r\n    filter_list = tf.split(filters, num_groups, axis=-1)\r\n    output_list = []\r\n\r\n    # Perform a normal convolution on each split of the input and filters\r\n    for conv_idx, (input_tensor, filter_tensor) in enumerate(zip(input_list, filter_list)):\r\n        output_list.append(tf.nn.convolution(\r\n            input_tensor,\r\n            filter_tensor,\r\n            padding,\r\n            strides=strides,\r\n            dilation_rate=dilation_rate,\r\n            name=\"grouped_convolution\" + \"_{}\".format(conv_idx)\r\n        ))\r\n    # Concatenate ouptputs along their last dimentsion\r\n    outputs = tf.concat(output_list, axis=-1)\r\n\r\n    return outputs\r\n```"}