{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/359639716", "html_url": "https://github.com/tensorflow/tensorflow/issues/3332#issuecomment-359639716", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3332", "id": 359639716, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTYzOTcxNg==", "user": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-23T01:31:19Z", "updated_at": "2018-01-23T01:31:19Z", "author_association": "MEMBER", "body_html": "<p>The API change is fine, but merging a PR that simply iteratively applies <code>Conv2D</code> would result in extremely slow runtime, which would then be misleading. One of the main motivations for using convolution groups is that they should be faster than regular convolutions (separable convolution being the fastest), and in this case we would actually be much slower than regular convolution, by a large factor.</p>\n<p>In my opinion this change only makes sense if we release a kernel that implements it with decent performance.</p>", "body_text": "The API change is fine, but merging a PR that simply iteratively applies Conv2D would result in extremely slow runtime, which would then be misleading. One of the main motivations for using convolution groups is that they should be faster than regular convolutions (separable convolution being the fastest), and in this case we would actually be much slower than regular convolution, by a large factor.\nIn my opinion this change only makes sense if we release a kernel that implements it with decent performance.", "body": "The API change is fine, but merging a PR that simply iteratively applies `Conv2D` would result in extremely slow runtime, which would then be misleading. One of the main motivations for using convolution groups is that they should be faster than regular convolutions (separable convolution being the fastest), and in this case we would actually be much slower than regular convolution, by a large factor. \r\n\r\nIn my opinion this change only makes sense if we release a kernel that implements it with decent performance."}