{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/233036597", "html_url": "https://github.com/tensorflow/tensorflow/issues/3332#issuecomment-233036597", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3332", "id": 233036597, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMzAzNjU5Nw==", "user": {"login": "fculinovic", "id": 9268051, "node_id": "MDQ6VXNlcjkyNjgwNTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/9268051?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fculinovic", "html_url": "https://github.com/fculinovic", "followers_url": "https://api.github.com/users/fculinovic/followers", "following_url": "https://api.github.com/users/fculinovic/following{/other_user}", "gists_url": "https://api.github.com/users/fculinovic/gists{/gist_id}", "starred_url": "https://api.github.com/users/fculinovic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fculinovic/subscriptions", "organizations_url": "https://api.github.com/users/fculinovic/orgs", "repos_url": "https://api.github.com/users/fculinovic/repos", "events_url": "https://api.github.com/users/fculinovic/events{/privacy}", "received_events_url": "https://api.github.com/users/fculinovic/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-15T18:51:09Z", "updated_at": "2016-07-15T18:54:54Z", "author_association": "NONE", "body_html": "<p>What I would basically like to do is use convolution on an input of size (batch_size, 55, 55, 96) such that 1 kernel is shared for the whole input UP TO depth 48, and a different kernel from depth 48. Each convolution should therefore give a result of depth 128 because of the defined weights. Then when the results are concatenated depthwise they would give the depth of 256 such as defined in [(http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf)].</p>\n<p>Currently the implementation of depthwise_conv2d in tensorflow allows for only applying a different filter of depth 1 to each input channel, while I would like to apply a filter of depth 48 to 48 input channels, and then again a different filter of depth 48 for the next 48 input channels.</p>\n<p>Such convolution (splitting the input into 2 groups by depth) is used in AlexNet/CaffeNet and it would be great if such a function would be implemented in TensorFlow.</p>\n<p>My current code is:</p>\n<pre><code>kernel = variable_with_weight_decay('weights', [5, 5, 96, 128],\n                                    stddev=1e-2, wd=1e-6)\n\nconv_grp1 = tf.nn.conv2d(pool1[:, :, :, :48], kernel[:, :, :48, :], [1, 1, 1, 1], padding='SAME')\nconv_grp2 = tf.nn.conv2d(pool1[:, :, :, 48:], kernel[:, :, 48:, :], [1, 1, 1, 1], padding='SAME')\n\nbiases = variable_on_device('biases', [256], tf.constant_initializer(1.))\n\nbias_grp1 = tf.nn.bias_add(conv_grp1, biases[:128])\nbias_grp2 = tf.nn.bias_add(conv_grp2, biases[128:])\n\nconv2_grp1 = tf.nn.relu(bias_grp1, name=scope.name)\nconv2_grp2 = tf.nn.relu(bias_grp2, name=scope.name)\n\nconv2 = tf.concat(3, [conv2_grp1, conv2_grp2])\n</code></pre>\n<p>This code IS working as intended, but it would be nice if I would be able to use convolution like this without explicitly defining 2 groups, but just by definining them in the convolution function.</p>", "body_text": "What I would basically like to do is use convolution on an input of size (batch_size, 55, 55, 96) such that 1 kernel is shared for the whole input UP TO depth 48, and a different kernel from depth 48. Each convolution should therefore give a result of depth 128 because of the defined weights. Then when the results are concatenated depthwise they would give the depth of 256 such as defined in [(http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf)].\nCurrently the implementation of depthwise_conv2d in tensorflow allows for only applying a different filter of depth 1 to each input channel, while I would like to apply a filter of depth 48 to 48 input channels, and then again a different filter of depth 48 for the next 48 input channels.\nSuch convolution (splitting the input into 2 groups by depth) is used in AlexNet/CaffeNet and it would be great if such a function would be implemented in TensorFlow.\nMy current code is:\nkernel = variable_with_weight_decay('weights', [5, 5, 96, 128],\n                                    stddev=1e-2, wd=1e-6)\n\nconv_grp1 = tf.nn.conv2d(pool1[:, :, :, :48], kernel[:, :, :48, :], [1, 1, 1, 1], padding='SAME')\nconv_grp2 = tf.nn.conv2d(pool1[:, :, :, 48:], kernel[:, :, 48:, :], [1, 1, 1, 1], padding='SAME')\n\nbiases = variable_on_device('biases', [256], tf.constant_initializer(1.))\n\nbias_grp1 = tf.nn.bias_add(conv_grp1, biases[:128])\nbias_grp2 = tf.nn.bias_add(conv_grp2, biases[128:])\n\nconv2_grp1 = tf.nn.relu(bias_grp1, name=scope.name)\nconv2_grp2 = tf.nn.relu(bias_grp2, name=scope.name)\n\nconv2 = tf.concat(3, [conv2_grp1, conv2_grp2])\n\nThis code IS working as intended, but it would be nice if I would be able to use convolution like this without explicitly defining 2 groups, but just by definining them in the convolution function.", "body": "What I would basically like to do is use convolution on an input of size (batch_size, 55, 55, 96) such that 1 kernel is shared for the whole input UP TO depth 48, and a different kernel from depth 48. Each convolution should therefore give a result of depth 128 because of the defined weights. Then when the results are concatenated depthwise they would give the depth of 256 such as defined in [(http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf)].\n\nCurrently the implementation of depthwise_conv2d in tensorflow allows for only applying a different filter of depth 1 to each input channel, while I would like to apply a filter of depth 48 to 48 input channels, and then again a different filter of depth 48 for the next 48 input channels.\n\nSuch convolution (splitting the input into 2 groups by depth) is used in AlexNet/CaffeNet and it would be great if such a function would be implemented in TensorFlow.\n\nMy current code is:\n\n```\nkernel = variable_with_weight_decay('weights', [5, 5, 96, 128],\n                                    stddev=1e-2, wd=1e-6)\n\nconv_grp1 = tf.nn.conv2d(pool1[:, :, :, :48], kernel[:, :, :48, :], [1, 1, 1, 1], padding='SAME')\nconv_grp2 = tf.nn.conv2d(pool1[:, :, :, 48:], kernel[:, :, 48:, :], [1, 1, 1, 1], padding='SAME')\n\nbiases = variable_on_device('biases', [256], tf.constant_initializer(1.))\n\nbias_grp1 = tf.nn.bias_add(conv_grp1, biases[:128])\nbias_grp2 = tf.nn.bias_add(conv_grp2, biases[128:])\n\nconv2_grp1 = tf.nn.relu(bias_grp1, name=scope.name)\nconv2_grp2 = tf.nn.relu(bias_grp2, name=scope.name)\n\nconv2 = tf.concat(3, [conv2_grp1, conv2_grp2])\n```\n\nThis code IS working as intended, but it would be nice if I would be able to use convolution like this without explicitly defining 2 groups, but just by definining them in the convolution function.\n"}