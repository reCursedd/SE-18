{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/318800072", "html_url": "https://github.com/tensorflow/tensorflow/issues/4105#issuecomment-318800072", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4105", "id": 318800072, "node_id": "MDEyOklzc3VlQ29tbWVudDMxODgwMDA3Mg==", "user": {"login": "TensorTom", "id": 14287229, "node_id": "MDQ6VXNlcjE0Mjg3MjI5", "avatar_url": "https://avatars2.githubusercontent.com/u/14287229?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TensorTom", "html_url": "https://github.com/TensorTom", "followers_url": "https://api.github.com/users/TensorTom/followers", "following_url": "https://api.github.com/users/TensorTom/following{/other_user}", "gists_url": "https://api.github.com/users/TensorTom/gists{/gist_id}", "starred_url": "https://api.github.com/users/TensorTom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TensorTom/subscriptions", "organizations_url": "https://api.github.com/users/TensorTom/orgs", "repos_url": "https://api.github.com/users/TensorTom/repos", "events_url": "https://api.github.com/users/TensorTom/events{/privacy}", "received_events_url": "https://api.github.com/users/TensorTom/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-29T03:14:22Z", "updated_at": "2017-07-29T03:14:22Z", "author_association": "NONE", "body_html": "<p>This is happening for me too. I already have TF installed and working for GPU via the runfile but I wanted to compile it for optimizations. I get:</p>\n<pre><code>ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\n                _create_local_cuda_repository(repository_ctx)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\n                _host_compiler_includes(repository_ctx, cc)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\n                get_cxx_inc_directories(repository_ctx, cc)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\n                set(includes_cpp)\ndepsets cannot contain mutable items\nWARNING: Target pattern parsing failed.\nERROR: no such package '@local_config_cuda//crosstool': Traceback (most recent call last):\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\n                _create_local_cuda_repository(repository_ctx)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\n                _host_compiler_includes(repository_ctx, cc)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\n                get_cxx_inc_directories(repository_ctx, cc)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\n                set(includes_cpp)\ndepsets cannot contain mutable items\nINFO: Elapsed time: 4.869s\nFAILED: Build did NOT complete successfully (3 packages loaded)\n    currently loading: tensorflow/tools/pip_package\n</code></pre>\n<p>Steps to reproduce:</p>\n<pre><code>git clone --recurse-submodules https://github.com/tensorflow/tensorflow\ncd tensorflow\n$ ./configure\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\nPlease specify the location of python. [Default is /home/user/.pyenv/versions/3.6.2/bin/python]: \nFound possible Python library paths:\n/home/user/.pyenv/versions/3.6.2/lib/python3.6/site-packages\nPlease input the desired Python library path to use.  Default is /home/user/.pyenv/versions/3.6.2/lib/python3.6/site-packages\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: y\njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]: n\nNo Hadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: y\nXLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL support? [y/N]: n\nNo OpenCL support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0\n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: \nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0]:/usr/lib/x86_64-linux-gnu \nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\nDo you want to use clang as CUDA compiler? [y/N]: n\nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nDo you wish to build TensorFlow with MPI support? [y/N]: n\nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nAdd \"--config=mkl\" to your bazel command to build with MKL support.\nPlease note that MKL on MacOS or windows is still not supported.\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\nConfiguration finished\n$ bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package\n</code></pre>\n<p>If you notice that I've done something wrong, please let me know. I saw someone before mention something about <code>LD_LIBRARY_PATH</code> which I have set to <code>/usr/local/cuda-8.0/lib64</code>. I figured it was fine since as I said, I already have TF installed and running from the runfile download. I would like to be able to compile from source though.</p>", "body_text": "This is happening for me too. I already have TF installed and working for GPU via the runfile but I wanted to compile it for optimizations. I get:\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\n                _create_local_cuda_repository(repository_ctx)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\n                _host_compiler_includes(repository_ctx, cc)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\n                get_cxx_inc_directories(repository_ctx, cc)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\n                set(includes_cpp)\ndepsets cannot contain mutable items\nWARNING: Target pattern parsing failed.\nERROR: no such package '@local_config_cuda//crosstool': Traceback (most recent call last):\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\n                _create_local_cuda_repository(repository_ctx)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\n                _host_compiler_includes(repository_ctx, cc)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\n                get_cxx_inc_directories(repository_ctx, cc)\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\n                set(includes_cpp)\ndepsets cannot contain mutable items\nINFO: Elapsed time: 4.869s\nFAILED: Build did NOT complete successfully (3 packages loaded)\n    currently loading: tensorflow/tools/pip_package\n\nSteps to reproduce:\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow\ncd tensorflow\n$ ./configure\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\nPlease specify the location of python. [Default is /home/user/.pyenv/versions/3.6.2/bin/python]: \nFound possible Python library paths:\n/home/user/.pyenv/versions/3.6.2/lib/python3.6/site-packages\nPlease input the desired Python library path to use.  Default is /home/user/.pyenv/versions/3.6.2/lib/python3.6/site-packages\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: y\njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]: n\nNo Hadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: y\nXLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL support? [y/N]: n\nNo OpenCL support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0\n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: \nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0]:/usr/lib/x86_64-linux-gnu \nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\nDo you want to use clang as CUDA compiler? [y/N]: n\nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nDo you wish to build TensorFlow with MPI support? [y/N]: n\nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nAdd \"--config=mkl\" to your bazel command to build with MKL support.\nPlease note that MKL on MacOS or windows is still not supported.\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\nConfiguration finished\n$ bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package\n\nIf you notice that I've done something wrong, please let me know. I saw someone before mention something about LD_LIBRARY_PATH which I have set to /usr/local/cuda-8.0/lib64. I figured it was fine since as I said, I already have TF installed and running from the runfile download. I would like to be able to compile from source though.", "body": "This is happening for me too. I already have TF installed and working for GPU via the runfile but I wanted to compile it for optimizations. I get:\r\n\r\n```\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\r\n                _host_compiler_includes(repository_ctx, cc)\r\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\r\n                get_cxx_inc_directories(repository_ctx, cc)\r\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\r\n                set(includes_cpp)\r\ndepsets cannot contain mutable items\r\nWARNING: Target pattern parsing failed.\r\nERROR: no such package '@local_config_cuda//crosstool': Traceback (most recent call last):\r\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\r\n                _host_compiler_includes(repository_ctx, cc)\r\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\r\n                get_cxx_inc_directories(repository_ctx, cc)\r\n        File \"/home/user/bin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\r\n                set(includes_cpp)\r\ndepsets cannot contain mutable items\r\nINFO: Elapsed time: 4.869s\r\nFAILED: Build did NOT complete successfully (3 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n```\r\n\r\nSteps to reproduce:\r\n\r\n```\r\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow\r\ncd tensorflow\r\n$ ./configure\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nPlease specify the location of python. [Default is /home/user/.pyenv/versions/3.6.2/bin/python]: \r\nFound possible Python library paths:\r\n/home/user/.pyenv/versions/3.6.2/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is /home/user/.pyenv/versions/3.6.2/lib/python3.6/site-packages\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: y\r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]: n\r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]: n\r\nNo Hadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]: n\r\nNo OpenCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0\r\n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: \r\nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0]:/usr/lib/x86_64-linux-gnu \r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\r\nDo you want to use clang as CUDA compiler? [y/N]: n\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\nAdd \"--config=mkl\" to your bazel command to build with MKL support.\r\nPlease note that MKL on MacOS or windows is still not supported.\r\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\r\nConfiguration finished\r\n$ bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nIf you notice that I've done something wrong, please let me know. I saw someone before mention something about `LD_LIBRARY_PATH` which I have set to `/usr/local/cuda-8.0/lib64`. I figured it was fine since as I said, I already have TF installed and running from the runfile download. I would like to be able to compile from source though. "}