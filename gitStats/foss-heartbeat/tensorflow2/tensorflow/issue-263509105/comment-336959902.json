{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/336959902", "html_url": "https://github.com/tensorflow/tensorflow/issues/13530#issuecomment-336959902", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13530", "id": 336959902, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjk1OTkwMg==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-16T17:25:22Z", "updated_at": "2017-10-16T17:25:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=26335535\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mellvinbaker\">@mellvinbaker</a> Looking at your example code, I noticed that the <code>batch_size</code> is 200000 (i.e. the full size of the <code>DataFrame</code>). Is that what you'd typically use in your application?</p>\n<p>Given that the <code>pandas_input_fn()</code> is based on a <code>FeedingQueueRunner</code>, it would have to feed 200000 elements to build such a batch. At ~20us per feed, I'm not surprised that it stalls for a noticeable amount of time.</p>", "body_text": "@mellvinbaker Looking at your example code, I noticed that the batch_size is 200000 (i.e. the full size of the DataFrame). Is that what you'd typically use in your application?\nGiven that the pandas_input_fn() is based on a FeedingQueueRunner, it would have to feed 200000 elements to build such a batch. At ~20us per feed, I'm not surprised that it stalls for a noticeable amount of time.", "body": "@mellvinbaker Looking at your example code, I noticed that the `batch_size` is 200000 (i.e. the full size of the `DataFrame`). Is that what you'd typically use in your application?\r\n\r\nGiven that the `pandas_input_fn()` is based on a `FeedingQueueRunner`, it would have to feed 200000 elements to build such a batch. At ~20us per feed, I'm not surprised that it stalls for a noticeable amount of time.\r\n"}