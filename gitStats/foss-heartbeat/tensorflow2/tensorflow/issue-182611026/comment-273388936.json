{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/273388936", "html_url": "https://github.com/tensorflow/tensorflow/issues/4920#issuecomment-273388936", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4920", "id": 273388936, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MzM4ODkzNg==", "user": {"login": "ZhimingZhou", "id": 11959472, "node_id": "MDQ6VXNlcjExOTU5NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/11959472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhimingZhou", "html_url": "https://github.com/ZhimingZhou", "followers_url": "https://api.github.com/users/ZhimingZhou/followers", "following_url": "https://api.github.com/users/ZhimingZhou/following{/other_user}", "gists_url": "https://api.github.com/users/ZhimingZhou/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhimingZhou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhimingZhou/subscriptions", "organizations_url": "https://api.github.com/users/ZhimingZhou/orgs", "repos_url": "https://api.github.com/users/ZhimingZhou/repos", "events_url": "https://api.github.com/users/ZhimingZhou/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhimingZhou/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-18T05:44:31Z", "updated_at": "2017-01-18T05:45:48Z", "author_association": "NONE", "body_html": "<p>Hi, here is a example:</p>\n<pre><code># testing variable order init\n\nimport tensorflow as tf\n\n\ndef initialize_all_variables(sess=None):\n    \"\"\"Initializes all uninitialized variables in correct order. Initializers\n    are only run for uninitialized variables, so it's safe to run this multiple\n    times.\n    Args:\n        sess: session to use. Use default session if None.\n    \"\"\"\n\n    from tensorflow.contrib import graph_editor as ge\n    def make_initializer(var):\n        def f():\n            return tf.assign(var, var.initial_value).op\n\n        return f\n\n    def make_noop():\n        return tf.no_op()\n\n    def make_safe_initializer(var):\n        \"\"\"Returns initializer op that only runs for uninitialized ops.\"\"\"\n        return tf.cond(tf.is_variable_initialized(var), make_noop, make_initializer(var), name=\"safe_init_\" + var.op.name).op\n\n    if not sess:\n        sess = tf.get_default_session()\n    g = tf.get_default_graph()\n\n    safe_initializers = {}\n    for v in tf.all_variables():\n        safe_initializers[v.op.name] = make_safe_initializer(v)\n\n    # initializers access variable vaue through read-only value cached in\n    # &lt;varname&gt;/read, so add control dependency to trigger safe_initializer\n    # on read access\n    for v in tf.all_variables():\n        var_name = v.op.name\n        var_cache = g.get_operation_by_name(var_name + \"/read\")\n        ge.reroute.add_control_inputs(var_cache, [safe_initializers[var_name]])\n\n    sess.run(tf.group(*safe_initializers.values()))\n\n    # remove initializer dependencies to avoid slowing down future variable reads\n    for v in tf.all_variables():\n        var_name = v.op.name\n        var_cache = g.get_operation_by_name(var_name + \"/read\")\n        ge.reroute.remove_control_inputs(var_cache, [safe_initializers[var_name]])\n\n\n################################################################################\n# Tests\n################################################################################\n\ndef my_test():\n\n    def linear_wn(input, output_size, stddev=0.05):\n\n        def linear_wn_initializer_g(v, init_scale=1.0):\n            v_norm = tf.nn.l2_normalize(v, [0])\n            x_init = tf.matmul(input, v_norm)\n            m_init, v_init = tf.nn.moments(x_init, [0])\n            scale_init = init_scale / tf.sqrt(v_init + 1e-10)\n            scale_init = tf.Print(scale_init, [0], 'linear ini running')\n            return scale_init\n\n        def linear_wn_initializer_b(v, init_scale=1.0):\n            v_norm = tf.nn.l2_normalize(v, [0])\n            x_init = tf.matmul(input, v_norm)\n            m_init, v_init = tf.nn.moments(x_init, [0])\n            scale_init = init_scale / tf.sqrt(v_init + 1e-10)\n            return -m_init * scale_init\n\n        if len(input.get_shape()) &gt; 2:\n            input = tf.reshape(input, [input.get_shape().as_list()[0], -1])\n\n        v = tf.get_variable('v', [input.get_shape().as_list()[1], output_size], initializer=tf.truncated_normal_initializer(stddev=stddev), trainable=True)\n        g = tf.get_variable('g', dtype=tf.float32, initializer=linear_wn_initializer_g(v.initialized_value()), trainable=True)\n        b = tf.get_variable('b', dtype=tf.float32, initializer=linear_wn_initializer_b(v.initialized_value()), trainable=True)\n\n        x = tf.matmul(input, v)\n        scaler = g / tf.sqrt(tf.reduce_sum(tf.square(v), [0]))\n        x = tf.reshape(scaler, [1, output_size]) * x + tf.reshape(b, [1, output_size])\n\n        return x\n\n    input = tf.get_variable('input', [1, 100], initializer=tf.truncated_normal_initializer(stddev=1.0), trainable=True)\n    output = linear_wn(input, 10)\n\n    sess = tf.InteractiveSession()\n    initialize_all_variables(sess)\n\n    opt = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(output)\n\n    while True:\n        sess.run([opt])\n\nif __name__ == '__main__':\n    my_test()\n\nprint(\"Tests passed\")\n</code></pre>\n<p>It will output:</p>\n<pre><code>I tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\n................\n</code></pre>", "body_text": "Hi, here is a example:\n# testing variable order init\n\nimport tensorflow as tf\n\n\ndef initialize_all_variables(sess=None):\n    \"\"\"Initializes all uninitialized variables in correct order. Initializers\n    are only run for uninitialized variables, so it's safe to run this multiple\n    times.\n    Args:\n        sess: session to use. Use default session if None.\n    \"\"\"\n\n    from tensorflow.contrib import graph_editor as ge\n    def make_initializer(var):\n        def f():\n            return tf.assign(var, var.initial_value).op\n\n        return f\n\n    def make_noop():\n        return tf.no_op()\n\n    def make_safe_initializer(var):\n        \"\"\"Returns initializer op that only runs for uninitialized ops.\"\"\"\n        return tf.cond(tf.is_variable_initialized(var), make_noop, make_initializer(var), name=\"safe_init_\" + var.op.name).op\n\n    if not sess:\n        sess = tf.get_default_session()\n    g = tf.get_default_graph()\n\n    safe_initializers = {}\n    for v in tf.all_variables():\n        safe_initializers[v.op.name] = make_safe_initializer(v)\n\n    # initializers access variable vaue through read-only value cached in\n    # <varname>/read, so add control dependency to trigger safe_initializer\n    # on read access\n    for v in tf.all_variables():\n        var_name = v.op.name\n        var_cache = g.get_operation_by_name(var_name + \"/read\")\n        ge.reroute.add_control_inputs(var_cache, [safe_initializers[var_name]])\n\n    sess.run(tf.group(*safe_initializers.values()))\n\n    # remove initializer dependencies to avoid slowing down future variable reads\n    for v in tf.all_variables():\n        var_name = v.op.name\n        var_cache = g.get_operation_by_name(var_name + \"/read\")\n        ge.reroute.remove_control_inputs(var_cache, [safe_initializers[var_name]])\n\n\n################################################################################\n# Tests\n################################################################################\n\ndef my_test():\n\n    def linear_wn(input, output_size, stddev=0.05):\n\n        def linear_wn_initializer_g(v, init_scale=1.0):\n            v_norm = tf.nn.l2_normalize(v, [0])\n            x_init = tf.matmul(input, v_norm)\n            m_init, v_init = tf.nn.moments(x_init, [0])\n            scale_init = init_scale / tf.sqrt(v_init + 1e-10)\n            scale_init = tf.Print(scale_init, [0], 'linear ini running')\n            return scale_init\n\n        def linear_wn_initializer_b(v, init_scale=1.0):\n            v_norm = tf.nn.l2_normalize(v, [0])\n            x_init = tf.matmul(input, v_norm)\n            m_init, v_init = tf.nn.moments(x_init, [0])\n            scale_init = init_scale / tf.sqrt(v_init + 1e-10)\n            return -m_init * scale_init\n\n        if len(input.get_shape()) > 2:\n            input = tf.reshape(input, [input.get_shape().as_list()[0], -1])\n\n        v = tf.get_variable('v', [input.get_shape().as_list()[1], output_size], initializer=tf.truncated_normal_initializer(stddev=stddev), trainable=True)\n        g = tf.get_variable('g', dtype=tf.float32, initializer=linear_wn_initializer_g(v.initialized_value()), trainable=True)\n        b = tf.get_variable('b', dtype=tf.float32, initializer=linear_wn_initializer_b(v.initialized_value()), trainable=True)\n\n        x = tf.matmul(input, v)\n        scaler = g / tf.sqrt(tf.reduce_sum(tf.square(v), [0]))\n        x = tf.reshape(scaler, [1, output_size]) * x + tf.reshape(b, [1, output_size])\n\n        return x\n\n    input = tf.get_variable('input', [1, 100], initializer=tf.truncated_normal_initializer(stddev=1.0), trainable=True)\n    output = linear_wn(input, 10)\n\n    sess = tf.InteractiveSession()\n    initialize_all_variables(sess)\n\n    opt = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(output)\n\n    while True:\n        sess.run([opt])\n\nif __name__ == '__main__':\n    my_test()\n\nprint(\"Tests passed\")\n\nIt will output:\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\n................", "body": "Hi, here is a example:\r\n\r\n```\r\n# testing variable order init\r\n\r\nimport tensorflow as tf\r\n\r\n\r\ndef initialize_all_variables(sess=None):\r\n    \"\"\"Initializes all uninitialized variables in correct order. Initializers\r\n    are only run for uninitialized variables, so it's safe to run this multiple\r\n    times.\r\n    Args:\r\n        sess: session to use. Use default session if None.\r\n    \"\"\"\r\n\r\n    from tensorflow.contrib import graph_editor as ge\r\n    def make_initializer(var):\r\n        def f():\r\n            return tf.assign(var, var.initial_value).op\r\n\r\n        return f\r\n\r\n    def make_noop():\r\n        return tf.no_op()\r\n\r\n    def make_safe_initializer(var):\r\n        \"\"\"Returns initializer op that only runs for uninitialized ops.\"\"\"\r\n        return tf.cond(tf.is_variable_initialized(var), make_noop, make_initializer(var), name=\"safe_init_\" + var.op.name).op\r\n\r\n    if not sess:\r\n        sess = tf.get_default_session()\r\n    g = tf.get_default_graph()\r\n\r\n    safe_initializers = {}\r\n    for v in tf.all_variables():\r\n        safe_initializers[v.op.name] = make_safe_initializer(v)\r\n\r\n    # initializers access variable vaue through read-only value cached in\r\n    # <varname>/read, so add control dependency to trigger safe_initializer\r\n    # on read access\r\n    for v in tf.all_variables():\r\n        var_name = v.op.name\r\n        var_cache = g.get_operation_by_name(var_name + \"/read\")\r\n        ge.reroute.add_control_inputs(var_cache, [safe_initializers[var_name]])\r\n\r\n    sess.run(tf.group(*safe_initializers.values()))\r\n\r\n    # remove initializer dependencies to avoid slowing down future variable reads\r\n    for v in tf.all_variables():\r\n        var_name = v.op.name\r\n        var_cache = g.get_operation_by_name(var_name + \"/read\")\r\n        ge.reroute.remove_control_inputs(var_cache, [safe_initializers[var_name]])\r\n\r\n\r\n################################################################################\r\n# Tests\r\n################################################################################\r\n\r\ndef my_test():\r\n\r\n    def linear_wn(input, output_size, stddev=0.05):\r\n\r\n        def linear_wn_initializer_g(v, init_scale=1.0):\r\n            v_norm = tf.nn.l2_normalize(v, [0])\r\n            x_init = tf.matmul(input, v_norm)\r\n            m_init, v_init = tf.nn.moments(x_init, [0])\r\n            scale_init = init_scale / tf.sqrt(v_init + 1e-10)\r\n            scale_init = tf.Print(scale_init, [0], 'linear ini running')\r\n            return scale_init\r\n\r\n        def linear_wn_initializer_b(v, init_scale=1.0):\r\n            v_norm = tf.nn.l2_normalize(v, [0])\r\n            x_init = tf.matmul(input, v_norm)\r\n            m_init, v_init = tf.nn.moments(x_init, [0])\r\n            scale_init = init_scale / tf.sqrt(v_init + 1e-10)\r\n            return -m_init * scale_init\r\n\r\n        if len(input.get_shape()) > 2:\r\n            input = tf.reshape(input, [input.get_shape().as_list()[0], -1])\r\n\r\n        v = tf.get_variable('v', [input.get_shape().as_list()[1], output_size], initializer=tf.truncated_normal_initializer(stddev=stddev), trainable=True)\r\n        g = tf.get_variable('g', dtype=tf.float32, initializer=linear_wn_initializer_g(v.initialized_value()), trainable=True)\r\n        b = tf.get_variable('b', dtype=tf.float32, initializer=linear_wn_initializer_b(v.initialized_value()), trainable=True)\r\n\r\n        x = tf.matmul(input, v)\r\n        scaler = g / tf.sqrt(tf.reduce_sum(tf.square(v), [0]))\r\n        x = tf.reshape(scaler, [1, output_size]) * x + tf.reshape(b, [1, output_size])\r\n\r\n        return x\r\n\r\n    input = tf.get_variable('input', [1, 100], initializer=tf.truncated_normal_initializer(stddev=1.0), trainable=True)\r\n    output = linear_wn(input, 10)\r\n\r\n    sess = tf.InteractiveSession()\r\n    initialize_all_variables(sess)\r\n\r\n    opt = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(output)\r\n\r\n    while True:\r\n        sess.run([opt])\r\n\r\nif __name__ == '__main__':\r\n    my_test()\r\n\r\nprint(\"Tests passed\")\r\n```\r\n\r\nIt will output:\r\n\r\n```\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\nI tensorflow/core/kernels/logging_ops.cc:79] linear ini running[0]\r\n................\r\n```"}