{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/226909367", "html_url": "https://github.com/tensorflow/tensorflow/issues/2928#issuecomment-226909367", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2928", "id": 226909367, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjkwOTM2Nw==", "user": {"login": "chasep255", "id": 15787797, "node_id": "MDQ6VXNlcjE1Nzg3Nzk3", "avatar_url": "https://avatars3.githubusercontent.com/u/15787797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chasep255", "html_url": "https://github.com/chasep255", "followers_url": "https://api.github.com/users/chasep255/followers", "following_url": "https://api.github.com/users/chasep255/following{/other_user}", "gists_url": "https://api.github.com/users/chasep255/gists{/gist_id}", "starred_url": "https://api.github.com/users/chasep255/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chasep255/subscriptions", "organizations_url": "https://api.github.com/users/chasep255/orgs", "repos_url": "https://api.github.com/users/chasep255/repos", "events_url": "https://api.github.com/users/chasep255/events{/privacy}", "received_events_url": "https://api.github.com/users/chasep255/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-18T00:18:09Z", "updated_at": "2016-06-18T00:18:09Z", "author_association": "NONE", "body_html": "<p>It is not a runtime decision.  t is the time step.  Here is a more complete section.  I already fixed the issue by just defining a batch size so I don't have the original code.</p>\n<p>Here is what is looks like now.  See how t is just the loop variable.</p>\n<pre><code>with tf.variable_scope('decoder') as scope:\n    W_attn = tf.get_variable('W_attn', (TIME_STEPS, TIME_STEPS), tf.float32, tf.truncated_normal_initializer(1.0 / TIME_STEPS, 0.01))\n    W_sm = tf.get_variable('W_softmax', (decoder_gru_size, 128), tf.float32, tf.truncated_normal_initializer(0.0, 1 / np.sqrt(decoder_gru_size)))\n    b_sm = tf.get_variable('b_softmax', 128, tf.float32, tf.truncated_normal_initializer(0.0, 0.01))\n    decoder_outputs = [None] * TIME_STEPS\n    state = tf.zeros((BATCH_SIZE, decoder_multi_rnn.state_size), tf.float32)\n    for t in range(TIME_STEPS):\n        w = tf.reshape(W_attn[t, :], (1, TIME_STEPS, 1))\n        rnn_input = tf.reduce_sum(w * decoder_input, 1)\n        last = tf.cond(is_training, lambda: getTimeStep(expected_output, t - 1), lambda: decoder_outputs[t - 1]) if t else tf.zeros((BATCH_SIZE, 128))\n        rnn_input = tf.concat(1, (rnn_input, last))\n        rnn_output, state = decoder_multi_rnn(rnn_input, state)\n        decoder_outputs[t] = tf.nn.softmax(tf.matmul(rnn_output, W_sm) + b_sm)\n        scope.reuse_variables()\n    output_tensor = tf.concat(1, [tf.reshape(t, (-1, 1, 128)) for t in decoder_outputs])\n</code></pre>", "body_text": "It is not a runtime decision.  t is the time step.  Here is a more complete section.  I already fixed the issue by just defining a batch size so I don't have the original code.\nHere is what is looks like now.  See how t is just the loop variable.\nwith tf.variable_scope('decoder') as scope:\n    W_attn = tf.get_variable('W_attn', (TIME_STEPS, TIME_STEPS), tf.float32, tf.truncated_normal_initializer(1.0 / TIME_STEPS, 0.01))\n    W_sm = tf.get_variable('W_softmax', (decoder_gru_size, 128), tf.float32, tf.truncated_normal_initializer(0.0, 1 / np.sqrt(decoder_gru_size)))\n    b_sm = tf.get_variable('b_softmax', 128, tf.float32, tf.truncated_normal_initializer(0.0, 0.01))\n    decoder_outputs = [None] * TIME_STEPS\n    state = tf.zeros((BATCH_SIZE, decoder_multi_rnn.state_size), tf.float32)\n    for t in range(TIME_STEPS):\n        w = tf.reshape(W_attn[t, :], (1, TIME_STEPS, 1))\n        rnn_input = tf.reduce_sum(w * decoder_input, 1)\n        last = tf.cond(is_training, lambda: getTimeStep(expected_output, t - 1), lambda: decoder_outputs[t - 1]) if t else tf.zeros((BATCH_SIZE, 128))\n        rnn_input = tf.concat(1, (rnn_input, last))\n        rnn_output, state = decoder_multi_rnn(rnn_input, state)\n        decoder_outputs[t] = tf.nn.softmax(tf.matmul(rnn_output, W_sm) + b_sm)\n        scope.reuse_variables()\n    output_tensor = tf.concat(1, [tf.reshape(t, (-1, 1, 128)) for t in decoder_outputs])", "body": "It is not a runtime decision.  t is the time step.  Here is a more complete section.  I already fixed the issue by just defining a batch size so I don't have the original code.\n\nHere is what is looks like now.  See how t is just the loop variable.  \n\n```\nwith tf.variable_scope('decoder') as scope:\n    W_attn = tf.get_variable('W_attn', (TIME_STEPS, TIME_STEPS), tf.float32, tf.truncated_normal_initializer(1.0 / TIME_STEPS, 0.01))\n    W_sm = tf.get_variable('W_softmax', (decoder_gru_size, 128), tf.float32, tf.truncated_normal_initializer(0.0, 1 / np.sqrt(decoder_gru_size)))\n    b_sm = tf.get_variable('b_softmax', 128, tf.float32, tf.truncated_normal_initializer(0.0, 0.01))\n    decoder_outputs = [None] * TIME_STEPS\n    state = tf.zeros((BATCH_SIZE, decoder_multi_rnn.state_size), tf.float32)\n    for t in range(TIME_STEPS):\n        w = tf.reshape(W_attn[t, :], (1, TIME_STEPS, 1))\n        rnn_input = tf.reduce_sum(w * decoder_input, 1)\n        last = tf.cond(is_training, lambda: getTimeStep(expected_output, t - 1), lambda: decoder_outputs[t - 1]) if t else tf.zeros((BATCH_SIZE, 128))\n        rnn_input = tf.concat(1, (rnn_input, last))\n        rnn_output, state = decoder_multi_rnn(rnn_input, state)\n        decoder_outputs[t] = tf.nn.softmax(tf.matmul(rnn_output, W_sm) + b_sm)\n        scope.reuse_variables()\n    output_tensor = tf.concat(1, [tf.reshape(t, (-1, 1, 128)) for t in decoder_outputs])\n```\n"}