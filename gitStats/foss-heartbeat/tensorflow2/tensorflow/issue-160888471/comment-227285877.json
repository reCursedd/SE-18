{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227285877", "html_url": "https://github.com/tensorflow/tensorflow/issues/2928#issuecomment-227285877", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2928", "id": 227285877, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzI4NTg3Nw==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-20T22:12:36Z", "updated_at": "2016-06-20T22:12:36Z", "author_association": "MEMBER", "body_html": "<p>Glad you managed to get it working.  I think your initial post has some confusion between the statically known shapes of ops/tensors in the graph, and the dynamically computed shapes of tensors evaluated when the graph is executed  (via session.run, feeding in placeholders) ?</p>\n<p>e.g. The input_tensor is a placeholder with partially specified shape.  We don't know until the input is fed what the actual batch size is (and it may vary from run to run).  You then take the <em>dynamic</em> shape of the input (using a tf.shape op in the graph)  and slice off the first element.</p>\n<pre><code>input_tensor = tf.placeholder(tf.float32, (None, TIME_STEPS, 128), 'input_tensor')\nshape_of_input_tensor = tf.shape(input_tensor)\nbatch_size = shape_of_input_tensor[0]\n</code></pre>\n<p>If we examine 'shape_of_input_tensor' we see that it is a vector whose value which cannot be computed until the input is fed into the graph.</p>\n<pre><code>&gt;&gt;&gt; print shape_of_input_tensor\nTensor(\"Shape_3:0\", shape=(3,), dtype=int32)\n</code></pre>\n<p>Note that batch_size is actually the output of a dynamic 'Slice' operation</p>\n<pre><code>&gt;&gt;&gt; print batch_size\nTensor(\"Squeeze_2:0\", shape=(), dtype=int32)\n&gt;&gt;&gt; print batch_size.op                                                                                                                                                        \nname: \"Squeeze\"\nop: \"Squeeze\"\ninput: \"Slice\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\nattr {\n  key: \"squeeze_dims\"\n  value {\n    list {\n      i: 0\n    }\n  }\n}\n</code></pre>\n<p>In contrast, 'state.get_shape()' is a static property of the graph and so cannot know the batch size until the placeholder is fed at runtime.  See here:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L329\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L329</a></p>\n<p>I couldn't reproduce further without know what 'encoder_multi_rnn.state_size' returns.  It clearly can't be a simple integer:</p>\n<pre><code>&gt;&gt;&gt; STATE_SIZE=27\n&gt;&gt;&gt; state = tf.zeros((batch_size, STATE_SIZE), tf.float32)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 622, in zeros\n    shape = ops.convert_to_tensor(shape, name=\"shape\")\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py\", line 179, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py\", line 162, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 332, in make_tensor_proto\n    _AssertCompatible(values, dtype)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in _AssertCompatible\n    raise TypeError(\"List of Tensors when single Tensor expected\")\nTypeError: List of Tensors when single Tensor expected\n</code></pre>\n<p>Note that the args of tf.zeros are passed through <a href=\"https://www.tensorflow.org/versions/r0.9/api_docs/python/framework.html#convert_to_tensor\" rel=\"nofollow\">tf.convert_to_tensor</a>:</p>\n<p>Without the entire original program, it's hard to follow why shape inference of last_shape (all the way through your encoder) was not working.</p>\n<p>Could you provide a simple repro test case?  Failing that I propose we close this issue.</p>", "body_text": "Glad you managed to get it working.  I think your initial post has some confusion between the statically known shapes of ops/tensors in the graph, and the dynamically computed shapes of tensors evaluated when the graph is executed  (via session.run, feeding in placeholders) ?\ne.g. The input_tensor is a placeholder with partially specified shape.  We don't know until the input is fed what the actual batch size is (and it may vary from run to run).  You then take the dynamic shape of the input (using a tf.shape op in the graph)  and slice off the first element.\ninput_tensor = tf.placeholder(tf.float32, (None, TIME_STEPS, 128), 'input_tensor')\nshape_of_input_tensor = tf.shape(input_tensor)\nbatch_size = shape_of_input_tensor[0]\n\nIf we examine 'shape_of_input_tensor' we see that it is a vector whose value which cannot be computed until the input is fed into the graph.\n>>> print shape_of_input_tensor\nTensor(\"Shape_3:0\", shape=(3,), dtype=int32)\n\nNote that batch_size is actually the output of a dynamic 'Slice' operation\n>>> print batch_size\nTensor(\"Squeeze_2:0\", shape=(), dtype=int32)\n>>> print batch_size.op                                                                                                                                                        \nname: \"Squeeze\"\nop: \"Squeeze\"\ninput: \"Slice\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\nattr {\n  key: \"squeeze_dims\"\n  value {\n    list {\n      i: 0\n    }\n  }\n}\n\nIn contrast, 'state.get_shape()' is a static property of the graph and so cannot know the batch size until the placeholder is fed at runtime.  See here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L329\nI couldn't reproduce further without know what 'encoder_multi_rnn.state_size' returns.  It clearly can't be a simple integer:\n>>> STATE_SIZE=27\n>>> state = tf.zeros((batch_size, STATE_SIZE), tf.float32)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 622, in zeros\n    shape = ops.convert_to_tensor(shape, name=\"shape\")\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py\", line 179, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py\", line 162, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 332, in make_tensor_proto\n    _AssertCompatible(values, dtype)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in _AssertCompatible\n    raise TypeError(\"List of Tensors when single Tensor expected\")\nTypeError: List of Tensors when single Tensor expected\n\nNote that the args of tf.zeros are passed through tf.convert_to_tensor:\nWithout the entire original program, it's hard to follow why shape inference of last_shape (all the way through your encoder) was not working.\nCould you provide a simple repro test case?  Failing that I propose we close this issue.", "body": "Glad you managed to get it working.  I think your initial post has some confusion between the statically known shapes of ops/tensors in the graph, and the dynamically computed shapes of tensors evaluated when the graph is executed  (via session.run, feeding in placeholders) ?\n\ne.g. The input_tensor is a placeholder with partially specified shape.  We don't know until the input is fed what the actual batch size is (and it may vary from run to run).  You then take the _dynamic_ shape of the input (using a tf.shape op in the graph)  and slice off the first element.  \n\n```\ninput_tensor = tf.placeholder(tf.float32, (None, TIME_STEPS, 128), 'input_tensor')\nshape_of_input_tensor = tf.shape(input_tensor)\nbatch_size = shape_of_input_tensor[0]\n```\n\nIf we examine 'shape_of_input_tensor' we see that it is a vector whose value which cannot be computed until the input is fed into the graph.\n\n```\n>>> print shape_of_input_tensor\nTensor(\"Shape_3:0\", shape=(3,), dtype=int32)\n```\n\nNote that batch_size is actually the output of a dynamic 'Slice' operation \n\n```\n>>> print batch_size\nTensor(\"Squeeze_2:0\", shape=(), dtype=int32)\n>>> print batch_size.op                                                                                                                                                        \nname: \"Squeeze\"\nop: \"Squeeze\"\ninput: \"Slice\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\nattr {\n  key: \"squeeze_dims\"\n  value {\n    list {\n      i: 0\n    }\n  }\n}\n```\n\nIn contrast, 'state.get_shape()' is a static property of the graph and so cannot know the batch size until the placeholder is fed at runtime.  See here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L329\n\nI couldn't reproduce further without know what 'encoder_multi_rnn.state_size' returns.  It clearly can't be a simple integer:\n\n```\n>>> STATE_SIZE=27\n>>> state = tf.zeros((batch_size, STATE_SIZE), tf.float32)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 622, in zeros\n    shape = ops.convert_to_tensor(shape, name=\"shape\")\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py\", line 179, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py\", line 162, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 332, in make_tensor_proto\n    _AssertCompatible(values, dtype)\n  File \"/usr/local/google/home/pbar/tensorflow.virtualenv/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in _AssertCompatible\n    raise TypeError(\"List of Tensors when single Tensor expected\")\nTypeError: List of Tensors when single Tensor expected\n```\n\nNote that the args of tf.zeros are passed through [tf.convert_to_tensor](https://www.tensorflow.org/versions/r0.9/api_docs/python/framework.html#convert_to_tensor):\n\nWithout the entire original program, it's hard to follow why shape inference of last_shape (all the way through your encoder) was not working.  \n\nCould you provide a simple repro test case?  Failing that I propose we close this issue.\n"}