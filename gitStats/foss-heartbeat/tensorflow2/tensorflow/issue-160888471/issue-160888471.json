{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2928", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2928/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2928/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2928/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2928", "id": 160888471, "node_id": "MDU6SXNzdWUxNjA4ODg0NzE=", "number": 2928, "title": "Zeros function not correctly determining shape.", "user": {"login": "chasep255", "id": 15787797, "node_id": "MDQ6VXNlcjE1Nzg3Nzk3", "avatar_url": "https://avatars3.githubusercontent.com/u/15787797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chasep255", "html_url": "https://github.com/chasep255", "followers_url": "https://api.github.com/users/chasep255/followers", "following_url": "https://api.github.com/users/chasep255/following{/other_user}", "gists_url": "https://api.github.com/users/chasep255/gists{/gist_id}", "starred_url": "https://api.github.com/users/chasep255/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chasep255/subscriptions", "organizations_url": "https://api.github.com/users/chasep255/orgs", "repos_url": "https://api.github.com/users/chasep255/repos", "events_url": "https://api.github.com/users/chasep255/events{/privacy}", "received_events_url": "https://api.github.com/users/chasep255/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-06-17T13:30:42Z", "updated_at": "2016-07-09T03:33:08Z", "closed_at": "2016-07-09T03:33:08Z", "author_association": "NONE", "body_html": "<p>I want to have dynamic batch sizes so I defined my input tensors as follows.</p>\n<p><code>input_tensor = tf.placeholder(tf.float32, (None, TIME_STEPS, 128), 'input_tensor')</code></p>\n<p>I then calculate the batch size.</p>\n<p><code>batch_size = tf.shape(input_tensor)[0]</code></p>\n<p>I can use this to determine the initial state for my RNNs as follows...</p>\n<pre><code>initial_state = state = tf.zeros((batch_size, encoder_multi_rnn.state_size), tf.float32)\n...\nforward_outputs[t], state = encoder_multi_rnn(getTimeStep(input_tensor, t), state)\n</code></pre>\n<p>This seems to work fine when I evaluate tf.shape(initial_state) in my sess.run() it prints what appears to be the correct value.  However, when do the following it prints (?, ?).  I think the second dimension should not be a ?</p>\n<pre><code>    state = tf.zeros((batch_size, encoder_multi_rnn.state_size), tf.float32)\n    print(state.get_shape())\n</code></pre>\n<p>This is not causing an issue and my code compiles fine.  However this is causing an issue when I try to feed the output of the last time step of my sequence generating decoder back into the input of the MultiRNN.  On the first time step I feed it zeros since no output has yet to be produced.</p>\n<pre><code>    rnn_input = tf.reduce_sum(w * decoder_input, 1)\n    last_out = decoder_outputs[t - 1] if t else tf.zeros((batch_size, 128))\n    rnn_input = tf.concat(1, (rnn_input, last_out))\n</code></pre>\n<p>I get this error when concat is called.  ValueError: Linear expects shape[1] of arguments: [[None, None], [None, 1024]]</p>\n<p>When I print last_out.get_shape() I get (?, ?) again.  In this case I think it should be (?, 128) since the last dimension is clearly defined.</p>", "body_text": "I want to have dynamic batch sizes so I defined my input tensors as follows.\ninput_tensor = tf.placeholder(tf.float32, (None, TIME_STEPS, 128), 'input_tensor')\nI then calculate the batch size.\nbatch_size = tf.shape(input_tensor)[0]\nI can use this to determine the initial state for my RNNs as follows...\ninitial_state = state = tf.zeros((batch_size, encoder_multi_rnn.state_size), tf.float32)\n...\nforward_outputs[t], state = encoder_multi_rnn(getTimeStep(input_tensor, t), state)\n\nThis seems to work fine when I evaluate tf.shape(initial_state) in my sess.run() it prints what appears to be the correct value.  However, when do the following it prints (?, ?).  I think the second dimension should not be a ?\n    state = tf.zeros((batch_size, encoder_multi_rnn.state_size), tf.float32)\n    print(state.get_shape())\n\nThis is not causing an issue and my code compiles fine.  However this is causing an issue when I try to feed the output of the last time step of my sequence generating decoder back into the input of the MultiRNN.  On the first time step I feed it zeros since no output has yet to be produced.\n    rnn_input = tf.reduce_sum(w * decoder_input, 1)\n    last_out = decoder_outputs[t - 1] if t else tf.zeros((batch_size, 128))\n    rnn_input = tf.concat(1, (rnn_input, last_out))\n\nI get this error when concat is called.  ValueError: Linear expects shape[1] of arguments: [[None, None], [None, 1024]]\nWhen I print last_out.get_shape() I get (?, ?) again.  In this case I think it should be (?, 128) since the last dimension is clearly defined.", "body": "I want to have dynamic batch sizes so I defined my input tensors as follows.\n\n`input_tensor = tf.placeholder(tf.float32, (None, TIME_STEPS, 128), 'input_tensor')`\n\nI then calculate the batch size.\n\n`batch_size = tf.shape(input_tensor)[0]`\n\nI can use this to determine the initial state for my RNNs as follows...\n\n```\ninitial_state = state = tf.zeros((batch_size, encoder_multi_rnn.state_size), tf.float32)\n...\nforward_outputs[t], state = encoder_multi_rnn(getTimeStep(input_tensor, t), state)\n```\n\nThis seems to work fine when I evaluate tf.shape(initial_state) in my sess.run() it prints what appears to be the correct value.  However, when do the following it prints (?, ?).  I think the second dimension should not be a ?\n\n```\n    state = tf.zeros((batch_size, encoder_multi_rnn.state_size), tf.float32)\n    print(state.get_shape())\n```\n\nThis is not causing an issue and my code compiles fine.  However this is causing an issue when I try to feed the output of the last time step of my sequence generating decoder back into the input of the MultiRNN.  On the first time step I feed it zeros since no output has yet to be produced.\n\n```\n    rnn_input = tf.reduce_sum(w * decoder_input, 1)\n    last_out = decoder_outputs[t - 1] if t else tf.zeros((batch_size, 128))\n    rnn_input = tf.concat(1, (rnn_input, last_out))\n```\n\nI get this error when concat is called.  ValueError: Linear expects shape[1] of arguments: [[None, None], [None, 1024]]\n\nWhen I print last_out.get_shape() I get (?, ?) again.  In this case I think it should be (?, 128) since the last dimension is clearly defined.  \n"}