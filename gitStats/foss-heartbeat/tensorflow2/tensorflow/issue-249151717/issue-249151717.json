{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12157", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12157/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12157/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12157/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12157", "id": 249151717, "node_id": "MDU6SXNzdWUyNDkxNTE3MTc=", "number": 12157, "title": "Bug - Restoring a graph created by tensorflow.python.tools.optimize_for_inference has errors with RNN models", "user": {"login": "Sycor4x", "id": 17602932, "node_id": "MDQ6VXNlcjE3NjAyOTMy", "avatar_url": "https://avatars3.githubusercontent.com/u/17602932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sycor4x", "html_url": "https://github.com/Sycor4x", "followers_url": "https://api.github.com/users/Sycor4x/followers", "following_url": "https://api.github.com/users/Sycor4x/following{/other_user}", "gists_url": "https://api.github.com/users/Sycor4x/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sycor4x/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sycor4x/subscriptions", "organizations_url": "https://api.github.com/users/Sycor4x/orgs", "repos_url": "https://api.github.com/users/Sycor4x/repos", "events_url": "https://api.github.com/users/Sycor4x/events{/privacy}", "received_events_url": "https://api.github.com/users/Sycor4x/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2017-08-09T20:29:07Z", "updated_at": "2018-02-08T09:29:58Z", "closed_at": "2018-01-30T00:08:03Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes, below</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04.1</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: tensorflow-gpu (1.1.0)</li>\n<li><strong>Python version</strong>: 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61</li>\n<li><strong>GPU model and memory</strong>: Tesla K80 24GB</li>\n<li><strong>Exact command to reproduce</strong>: see below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I believe I've found a bug. The freeze and optimize scripts appear to have bugs related to the proper function of RNNs. Creating a simple RNN, running the freeze script and the optimize script, and then attempting to restore and use the optimized graph creates a puzzling series of errors.</p>\n<ol>\n<li>\n<p>After running freeze and optimize, the placeholder for sequence lengths has datatype <code>float32</code>, instead of <code>tf.int32</code>, even though the placeholder specifies that it is <code>tf.int32</code>. This breaks evaluating an instance of GRUCell, which expects length to be of type <code>tf.int32</code>.</p>\n</li>\n<li>\n<p>If I add a <code>tf.to_int32()</code> to coerce the sequence length placeholder to type <code>tf.int32</code>, then we obtain a different error, which appears to pertain to the internal operation of the <code>tf.nn.dynamic_rnn()</code> function.</p>\n</li>\n</ol>\n<h3>Source code / logs</h3>\n<p>The code is divided into 2 user-created scripts (and 2 TF-provided scripts are employed along the way). The first of my scripts defines a model and saves it, and is called \"optimize_graph_minimal.py\". Then the freeze and optimize scripts are run. The second of my scripts attempts to restore the model to a new Python session, and this appears to be buggy.</p>\n<h4>This is the code I used to create and save the graph.</h4>\n<pre><code>import numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.rnn as rnn\n\nclass tf_rnn_model(object):\n    def __init__(self, seq_length=10, num_units=2):\n        self.seq_length = seq_length\n        self.num_units = num_units\n        self.graph_context = tf.Graph()\n        self.graph_specification()\n\n    def graph_specification(self):\n        with self.graph_context.as_default():\n            self.X = tf.placeholder(dtype=tf.float32, shape=[None, self.seq_length, 2], name=\"X\")\n            self.X_length = tf.placeholder(dtype=tf.int32, shape=[None], name=\"X_length\")\n\n            cell = rnn.GRUCell(self.num_units)\n            Y, rnn_state = tf.nn.dynamic_rnn(cell=cell,\n                                             inputs=self.X,\n                                             sequence_length=self.X_length,\n                                             dtype=tf.float32,\n                                             swap_memory=False)\n\n            self.Y = tf.identity(Y, name=\"Y\")\n            self.saver = tf.train.Saver()\n\n        return None\n\n    def restore_optimized_graph(self, graph_def_optimized):\n        with tf.gfile.GFile(graph_def_optimized, 'rb') as f:\n            graph_def_optimized = tf.GraphDef()\n            graph_def_optimized.ParseFromString(f.read())\n\n        self.Y, = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\n        self.X = self.graph_context.get_tensor_by_name(\"import/X:0\")\n        self.X_length = self.graph_context.get_tensor_by_name(\"import/X_length:0\")\n        tf.global_variables_initializer().run()\n\n        return None\n\nmodel = tf_rnn_model()\nwith tf.Session(graph=model.graph_context) as sess:\n    sess.run(tf.global_variables_initializer())\n    inputs = np.arange(20).reshape([1, 10, 2])\n    out = sess.run(fetches=[model.Y], feed_dict={model.X: inputs, model.X_length: [10]})\n    print(out)\n\n    tf.train.write_graph(sess.graph_def, \".\", \"toy_graph.pb\")\n    model.saver.save(sess, save_path=\"toy_saved\")\n\n    print(\"These are some helpful things to know for the script.\")\n    print(\"saver.as_saver_def()= %s\" % model.saver.as_saver_def())\n</code></pre>\n<h2>Freeze and optimize scripts are executed here.</h2>\n<pre><code>python -m tensorflow.python.tools.freeze_graph \\\n--input_graph toy_graph.pb \\\n--input_checkpoint toy_saved \\\n--output_graph graph_frozen.pb \\\n--output_node_names=Y \\\n--filename_tensor_name=save/Const:0 \\\n--restore_op_name=save/restore_all\n\npython -m tensorflow.python.tools.optimize_for_inference \\\n--input graph_frozen.pb \\\n--output graph_optimized.pb \\\n--input_names=X,X_length \\\n--output_names=Y\n</code></pre>\n<h4>Attempt to restore and <code>run</code> using this script in a new Python session.</h4>\n<pre><code># This line just imports the model class from the previous Python script because this is a new Python session.\nfrom optimize_graph_minimal import tf_rnn_model\nimport numpy as np\nimport tensorflow as tf\n\nmodel = tf_rnn_model()\n\nwith tf.Session(graph=model.graph_context) as sess:\n    model.restore_optimized_graph(\"graph_optimized.pb\")\n    inputs = np.arange(20).reshape([1, 10, 2])\n    out = sess.run(fetches=[model.Y], feed_dict={model.X: inputs, model.X_length: [10]})\n    print(out)\n</code></pre>\n<h4>The following errors are produced.</h4>\n<ol>\n<li>Without explicitly coercing the sequence length placeholder using <code>tf.to_int32()</code>, we get an error indicating that the sequence length tensor is of type <code>float32</code> but must be type <code>int32</code>.</li>\n</ol>\n<pre><code>Traceback (most recent call last):\n  File \"tf_minimal/optimize_restore_graph.py\", line 14, in &lt;module&gt;\n    model.restore_optimized_graph(\"graph_optimized.pb\")\n  File \"optimize_graph_minimal.py\", line 44, in restore_optimized_graph\n    self.Y = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\n  File \"python2.7/site-packages/tensorflow/python/framework/importer.py\", line 388, in import_graph_def\n    node, 'Input tensor %r %s' % (input_name, te)))\nValueError: graph_def is invalid at node u'rnn/Shape_1': Input tensor 'X_length:0' Cannot convert a tensor of type float32 to an input of type int32.\n</code></pre>\n<ol start=\"2\">\n<li>If we change the graph specification to use an explicit coercion to int32 type<br>\n<code>self.X_length = tf.to_int32(tf.placeholder(dtype=tf.int32, shape=[None], name=\"X_length\"))</code><br>\nthen we get this error instead.</li>\n</ol>\n<pre><code>2017-08-09 19:19:10.910686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\nTraceback (most recent call last):\n  File \"optimize_restore_graph.py\", line 14, in &lt;module&gt;\n    model.restore_optimized_graph(\"graph_optimized.pb\")\n  File \"optimize_graph_minimal.py\", line 44, in restore_optimized_graph\n    self.Y = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\n  File \"python2.7/site-packages/tensorflow/python/framework/importer.py\", line 362, in import_graph_def\n    % (input_name,)))\nValueError: graph_def is invalid at node u'rnn/while/gru_cell/gates/gates/concat/axis': More inputs specified ('rnn/while/Switch:1') than the op expects..\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, below\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.1\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): tensorflow-gpu (1.1.0)\nPython version: 2.7.12\nBazel version (if compiling from source): NA\nCUDA/cuDNN version:\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\nGPU model and memory: Tesla K80 24GB\nExact command to reproduce: see below\n\nDescribe the problem\nI believe I've found a bug. The freeze and optimize scripts appear to have bugs related to the proper function of RNNs. Creating a simple RNN, running the freeze script and the optimize script, and then attempting to restore and use the optimized graph creates a puzzling series of errors.\n\n\nAfter running freeze and optimize, the placeholder for sequence lengths has datatype float32, instead of tf.int32, even though the placeholder specifies that it is tf.int32. This breaks evaluating an instance of GRUCell, which expects length to be of type tf.int32.\n\n\nIf I add a tf.to_int32() to coerce the sequence length placeholder to type tf.int32, then we obtain a different error, which appears to pertain to the internal operation of the tf.nn.dynamic_rnn() function.\n\n\nSource code / logs\nThe code is divided into 2 user-created scripts (and 2 TF-provided scripts are employed along the way). The first of my scripts defines a model and saves it, and is called \"optimize_graph_minimal.py\". Then the freeze and optimize scripts are run. The second of my scripts attempts to restore the model to a new Python session, and this appears to be buggy.\nThis is the code I used to create and save the graph.\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.rnn as rnn\n\nclass tf_rnn_model(object):\n    def __init__(self, seq_length=10, num_units=2):\n        self.seq_length = seq_length\n        self.num_units = num_units\n        self.graph_context = tf.Graph()\n        self.graph_specification()\n\n    def graph_specification(self):\n        with self.graph_context.as_default():\n            self.X = tf.placeholder(dtype=tf.float32, shape=[None, self.seq_length, 2], name=\"X\")\n            self.X_length = tf.placeholder(dtype=tf.int32, shape=[None], name=\"X_length\")\n\n            cell = rnn.GRUCell(self.num_units)\n            Y, rnn_state = tf.nn.dynamic_rnn(cell=cell,\n                                             inputs=self.X,\n                                             sequence_length=self.X_length,\n                                             dtype=tf.float32,\n                                             swap_memory=False)\n\n            self.Y = tf.identity(Y, name=\"Y\")\n            self.saver = tf.train.Saver()\n\n        return None\n\n    def restore_optimized_graph(self, graph_def_optimized):\n        with tf.gfile.GFile(graph_def_optimized, 'rb') as f:\n            graph_def_optimized = tf.GraphDef()\n            graph_def_optimized.ParseFromString(f.read())\n\n        self.Y, = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\n        self.X = self.graph_context.get_tensor_by_name(\"import/X:0\")\n        self.X_length = self.graph_context.get_tensor_by_name(\"import/X_length:0\")\n        tf.global_variables_initializer().run()\n\n        return None\n\nmodel = tf_rnn_model()\nwith tf.Session(graph=model.graph_context) as sess:\n    sess.run(tf.global_variables_initializer())\n    inputs = np.arange(20).reshape([1, 10, 2])\n    out = sess.run(fetches=[model.Y], feed_dict={model.X: inputs, model.X_length: [10]})\n    print(out)\n\n    tf.train.write_graph(sess.graph_def, \".\", \"toy_graph.pb\")\n    model.saver.save(sess, save_path=\"toy_saved\")\n\n    print(\"These are some helpful things to know for the script.\")\n    print(\"saver.as_saver_def()= %s\" % model.saver.as_saver_def())\n\nFreeze and optimize scripts are executed here.\npython -m tensorflow.python.tools.freeze_graph \\\n--input_graph toy_graph.pb \\\n--input_checkpoint toy_saved \\\n--output_graph graph_frozen.pb \\\n--output_node_names=Y \\\n--filename_tensor_name=save/Const:0 \\\n--restore_op_name=save/restore_all\n\npython -m tensorflow.python.tools.optimize_for_inference \\\n--input graph_frozen.pb \\\n--output graph_optimized.pb \\\n--input_names=X,X_length \\\n--output_names=Y\n\nAttempt to restore and run using this script in a new Python session.\n# This line just imports the model class from the previous Python script because this is a new Python session.\nfrom optimize_graph_minimal import tf_rnn_model\nimport numpy as np\nimport tensorflow as tf\n\nmodel = tf_rnn_model()\n\nwith tf.Session(graph=model.graph_context) as sess:\n    model.restore_optimized_graph(\"graph_optimized.pb\")\n    inputs = np.arange(20).reshape([1, 10, 2])\n    out = sess.run(fetches=[model.Y], feed_dict={model.X: inputs, model.X_length: [10]})\n    print(out)\n\nThe following errors are produced.\n\nWithout explicitly coercing the sequence length placeholder using tf.to_int32(), we get an error indicating that the sequence length tensor is of type float32 but must be type int32.\n\nTraceback (most recent call last):\n  File \"tf_minimal/optimize_restore_graph.py\", line 14, in <module>\n    model.restore_optimized_graph(\"graph_optimized.pb\")\n  File \"optimize_graph_minimal.py\", line 44, in restore_optimized_graph\n    self.Y = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\n  File \"python2.7/site-packages/tensorflow/python/framework/importer.py\", line 388, in import_graph_def\n    node, 'Input tensor %r %s' % (input_name, te)))\nValueError: graph_def is invalid at node u'rnn/Shape_1': Input tensor 'X_length:0' Cannot convert a tensor of type float32 to an input of type int32.\n\n\nIf we change the graph specification to use an explicit coercion to int32 type\nself.X_length = tf.to_int32(tf.placeholder(dtype=tf.int32, shape=[None], name=\"X_length\"))\nthen we get this error instead.\n\n2017-08-09 19:19:10.910686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\nTraceback (most recent call last):\n  File \"optimize_restore_graph.py\", line 14, in <module>\n    model.restore_optimized_graph(\"graph_optimized.pb\")\n  File \"optimize_graph_minimal.py\", line 44, in restore_optimized_graph\n    self.Y = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\n  File \"python2.7/site-packages/tensorflow/python/framework/importer.py\", line 362, in import_graph_def\n    % (input_name,)))\nValueError: graph_def is invalid at node u'rnn/while/gru_cell/gates/gates/concat/axis': More inputs specified ('rnn/while/Switch:1') than the op expects..", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.1\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: tensorflow-gpu (1.1.0)\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**:\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n- **GPU model and memory**: Tesla K80 24GB\r\n- **Exact command to reproduce**: see below\r\n\r\n### Describe the problem\r\nI believe I've found a bug. The freeze and optimize scripts appear to have bugs related to the proper function of RNNs. Creating a simple RNN, running the freeze script and the optimize script, and then attempting to restore and use the optimized graph creates a puzzling series of errors.\r\n\r\n1. After running freeze and optimize, the placeholder for sequence lengths has datatype `float32`, instead of `tf.int32`, even though the placeholder specifies that it is `tf.int32`. This breaks evaluating an instance of GRUCell, which expects length to be of type `tf.int32`.\r\n\r\n2. If I add a `tf.to_int32()` to coerce the sequence length placeholder to type `tf.int32`, then we obtain a different error, which appears to pertain to the internal operation of the `tf.nn.dynamic_rnn()` function.\r\n\r\n### Source code / logs\r\nThe code is divided into 2 user-created scripts (and 2 TF-provided scripts are employed along the way). The first of my scripts defines a model and saves it, and is called \"optimize_graph_minimal.py\". Then the freeze and optimize scripts are run. The second of my scripts attempts to restore the model to a new Python session, and this appears to be buggy.\r\n\r\n#### This is the code I used to create and save the graph.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.rnn as rnn\r\n\r\nclass tf_rnn_model(object):\r\n    def __init__(self, seq_length=10, num_units=2):\r\n        self.seq_length = seq_length\r\n        self.num_units = num_units\r\n        self.graph_context = tf.Graph()\r\n        self.graph_specification()\r\n\r\n    def graph_specification(self):\r\n        with self.graph_context.as_default():\r\n            self.X = tf.placeholder(dtype=tf.float32, shape=[None, self.seq_length, 2], name=\"X\")\r\n            self.X_length = tf.placeholder(dtype=tf.int32, shape=[None], name=\"X_length\")\r\n\r\n            cell = rnn.GRUCell(self.num_units)\r\n            Y, rnn_state = tf.nn.dynamic_rnn(cell=cell,\r\n                                             inputs=self.X,\r\n                                             sequence_length=self.X_length,\r\n                                             dtype=tf.float32,\r\n                                             swap_memory=False)\r\n\r\n            self.Y = tf.identity(Y, name=\"Y\")\r\n            self.saver = tf.train.Saver()\r\n\r\n        return None\r\n\r\n    def restore_optimized_graph(self, graph_def_optimized):\r\n        with tf.gfile.GFile(graph_def_optimized, 'rb') as f:\r\n            graph_def_optimized = tf.GraphDef()\r\n            graph_def_optimized.ParseFromString(f.read())\r\n\r\n        self.Y, = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\r\n        self.X = self.graph_context.get_tensor_by_name(\"import/X:0\")\r\n        self.X_length = self.graph_context.get_tensor_by_name(\"import/X_length:0\")\r\n        tf.global_variables_initializer().run()\r\n\r\n        return None\r\n\r\nmodel = tf_rnn_model()\r\nwith tf.Session(graph=model.graph_context) as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    inputs = np.arange(20).reshape([1, 10, 2])\r\n    out = sess.run(fetches=[model.Y], feed_dict={model.X: inputs, model.X_length: [10]})\r\n    print(out)\r\n\r\n    tf.train.write_graph(sess.graph_def, \".\", \"toy_graph.pb\")\r\n    model.saver.save(sess, save_path=\"toy_saved\")\r\n\r\n    print(\"These are some helpful things to know for the script.\")\r\n    print(\"saver.as_saver_def()= %s\" % model.saver.as_saver_def())\r\n```\r\n\r\n## Freeze and optimize scripts are executed here.\r\n\r\n```\r\npython -m tensorflow.python.tools.freeze_graph \\\r\n--input_graph toy_graph.pb \\\r\n--input_checkpoint toy_saved \\\r\n--output_graph graph_frozen.pb \\\r\n--output_node_names=Y \\\r\n--filename_tensor_name=save/Const:0 \\\r\n--restore_op_name=save/restore_all\r\n\r\npython -m tensorflow.python.tools.optimize_for_inference \\\r\n--input graph_frozen.pb \\\r\n--output graph_optimized.pb \\\r\n--input_names=X,X_length \\\r\n--output_names=Y\r\n```\r\n\r\n#### Attempt to restore and `run` using this script in a new Python session.\r\n\r\n```\r\n# This line just imports the model class from the previous Python script because this is a new Python session.\r\nfrom optimize_graph_minimal import tf_rnn_model\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nmodel = tf_rnn_model()\r\n\r\nwith tf.Session(graph=model.graph_context) as sess:\r\n    model.restore_optimized_graph(\"graph_optimized.pb\")\r\n    inputs = np.arange(20).reshape([1, 10, 2])\r\n    out = sess.run(fetches=[model.Y], feed_dict={model.X: inputs, model.X_length: [10]})\r\n    print(out)\r\n```\r\n#### The following errors are produced.\r\n\r\n1. Without explicitly coercing the sequence length placeholder using `tf.to_int32()`, we get an error indicating that the sequence length tensor is of type `float32` but must be type `int32`.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"tf_minimal/optimize_restore_graph.py\", line 14, in <module>\r\n    model.restore_optimized_graph(\"graph_optimized.pb\")\r\n  File \"optimize_graph_minimal.py\", line 44, in restore_optimized_graph\r\n    self.Y = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\r\n  File \"python2.7/site-packages/tensorflow/python/framework/importer.py\", line 388, in import_graph_def\r\n    node, 'Input tensor %r %s' % (input_name, te)))\r\nValueError: graph_def is invalid at node u'rnn/Shape_1': Input tensor 'X_length:0' Cannot convert a tensor of type float32 to an input of type int32.\r\n```\r\n\r\n2. If we change the graph specification to use an explicit coercion to int32 type\r\n`self.X_length = tf.to_int32(tf.placeholder(dtype=tf.int32, shape=[None], name=\"X_length\"))`\r\nthen we get this error instead.\r\n\r\n```\r\n2017-08-09 19:19:10.910686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\r\nTraceback (most recent call last):\r\n  File \"optimize_restore_graph.py\", line 14, in <module>\r\n    model.restore_optimized_graph(\"graph_optimized.pb\")\r\n  File \"optimize_graph_minimal.py\", line 44, in restore_optimized_graph\r\n    self.Y = tf.import_graph_def(graph_def_optimized, return_elements=[\"Y:0\"])\r\n  File \"python2.7/site-packages/tensorflow/python/framework/importer.py\", line 362, in import_graph_def\r\n    % (input_name,)))\r\nValueError: graph_def is invalid at node u'rnn/while/gru_cell/gates/gates/concat/axis': More inputs specified ('rnn/while/Switch:1') than the op expects..\r\n```"}