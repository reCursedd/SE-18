{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9829", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9829/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9829/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9829/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9829", "id": 227890401, "node_id": "MDU6SXNzdWUyMjc4OTA0MDE=", "number": 9829, "title": "Kernel Restarting The kernel appears to have died. It will restart automatically (Jupyter-Tensorflow)", "user": {"login": "dineshgit", "id": 20434896, "node_id": "MDQ6VXNlcjIwNDM0ODk2", "avatar_url": "https://avatars1.githubusercontent.com/u/20434896?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dineshgit", "html_url": "https://github.com/dineshgit", "followers_url": "https://api.github.com/users/dineshgit/followers", "following_url": "https://api.github.com/users/dineshgit/following{/other_user}", "gists_url": "https://api.github.com/users/dineshgit/gists{/gist_id}", "starred_url": "https://api.github.com/users/dineshgit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dineshgit/subscriptions", "organizations_url": "https://api.github.com/users/dineshgit/orgs", "repos_url": "https://api.github.com/users/dineshgit/repos", "events_url": "https://api.github.com/users/dineshgit/events{/privacy}", "received_events_url": "https://api.github.com/users/dineshgit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-05-11T06:27:37Z", "updated_at": "2018-09-15T11:06:46Z", "closed_at": "2017-05-11T20:13:40Z", "author_association": "NONE", "body_html": "<p>I am facing a huge problem where the jupyter kernel keeps dying. This is my first experience of kernel ending on Jupyter. I'm using Tensorflow to fit a CNN model (the total input datasize is only 9.8MB)</p>\n<p>I did not have this issue in my previous run on the same code (however I did have errors where it said \"dst tensor is not initialized\". That was when I made the dataset really small to attempt to fit it. Could someone please kindly help ?</p>\n<p>This is the code:</p>\n<p>import tensorflow as tf<br>\nimport numpy as np</p>\n<p>IMG_PX_SIZE = 50<br>\nHM_SLICES = 20</p>\n<p>n_classes = 2</p>\n<p>x = tf.placeholder('float')<br>\ny = tf.placeholder('float')</p>\n<p>keep_rate = 0.8<br>\nkeep_prob = tf.placeholder(tf.float32)</p>\n<p>def conv3d(x, W):<br>\nreturn tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')</p>\n<p>def maxpool3d(x):<br>\nreturn tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')</p>\n<p>def convolutional_neural_network(x):<br>\nweights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,1,32])),<br>\n'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),<br>\n'W_fc':tf.Variable(tf.random_normal([62720  ,1024])),<br>\n'out':tf.Variable(tf.random_normal([1024, n_classes]))}</p>\n<pre><code>biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n           'b_conv2':tf.Variable(tf.random_normal([64])),\n           'b_fc':tf.Variable(tf.random_normal([1024])),\n           'out':tf.Variable(tf.random_normal([n_classes]))}\n\nx = tf.reshape(x, shape=[-1, IMG_PX_SIZE, IMG_PX_SIZE, HM_SLICES, 1])\n\nconv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\nconv1 = maxpool3d(conv1)\n\nconv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\nconv2 = maxpool3d(conv2)\n\nfc = tf.reshape(conv2,[-1, 62720  ])\nfc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\nfc = tf.nn.dropout(fc, keep_rate)\n\noutput = tf.matmul(fc, weights['out']) + biases['out']\n\nreturn output\n</code></pre>\n<p>def train_neural_network(x):</p>\n<pre><code>much_data = np.load('muchdata_sampled-50-50-20.npy')\ntrain_data = much_data[:100]\nvalidation_data = much_data[-100:]\n\nprediction = convolutional_neural_network(x)\ncost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\noptimizer = tf.train.AdamOptimizer().minimize(cost)\n\nhm_epochs = 3\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for epoch in range(hm_epochs):\n        epoch_loss = 0\n        for data in train_data:\n            X = data[0]\n            Y = data[1]\n            _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\n            epoch_loss += c\n\n        print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n\n    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n\n    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n    print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n</code></pre>\n<p>train_neural_network(x)</p>\n<p>(My System information)</p>\n<p>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):</p>\n<ul>\n<li>Yes</li>\n</ul>\n<p>OS Platform and Distribution:</p>\n<ul>\n<li>OS = Windows 10</li>\n</ul>\n<p>TensorFlow installed from (source or binary):<br>\n*Installed from Source</p>\n<p>TensorFlow version (use command below):<br>\n*When I ran =&gt; python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"<br>\n*I get only this result =&gt; b'unknown' 1.0.0</p>\n<p>CUDA/cuDNN version:<br>\n*cuda_8.0.61_win10<br>\n*cuDNN v5.1 (Jan 20, 2017), for CUDA 8.0</p>\n<p>GPU model and memory:<br>\n*GeForce GTX 1050 graphics card<br>\n*RAM 32GB</p>", "body_text": "I am facing a huge problem where the jupyter kernel keeps dying. This is my first experience of kernel ending on Jupyter. I'm using Tensorflow to fit a CNN model (the total input datasize is only 9.8MB)\nI did not have this issue in my previous run on the same code (however I did have errors where it said \"dst tensor is not initialized\". That was when I made the dataset really small to attempt to fit it. Could someone please kindly help ?\nThis is the code:\nimport tensorflow as tf\nimport numpy as np\nIMG_PX_SIZE = 50\nHM_SLICES = 20\nn_classes = 2\nx = tf.placeholder('float')\ny = tf.placeholder('float')\nkeep_rate = 0.8\nkeep_prob = tf.placeholder(tf.float32)\ndef conv3d(x, W):\nreturn tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\ndef maxpool3d(x):\nreturn tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\ndef convolutional_neural_network(x):\nweights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,1,32])),\n'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\n'W_fc':tf.Variable(tf.random_normal([62720  ,1024])),\n'out':tf.Variable(tf.random_normal([1024, n_classes]))}\nbiases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n           'b_conv2':tf.Variable(tf.random_normal([64])),\n           'b_fc':tf.Variable(tf.random_normal([1024])),\n           'out':tf.Variable(tf.random_normal([n_classes]))}\n\nx = tf.reshape(x, shape=[-1, IMG_PX_SIZE, IMG_PX_SIZE, HM_SLICES, 1])\n\nconv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\nconv1 = maxpool3d(conv1)\n\nconv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\nconv2 = maxpool3d(conv2)\n\nfc = tf.reshape(conv2,[-1, 62720  ])\nfc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\nfc = tf.nn.dropout(fc, keep_rate)\n\noutput = tf.matmul(fc, weights['out']) + biases['out']\n\nreturn output\n\ndef train_neural_network(x):\nmuch_data = np.load('muchdata_sampled-50-50-20.npy')\ntrain_data = much_data[:100]\nvalidation_data = much_data[-100:]\n\nprediction = convolutional_neural_network(x)\ncost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\noptimizer = tf.train.AdamOptimizer().minimize(cost)\n\nhm_epochs = 3\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for epoch in range(hm_epochs):\n        epoch_loss = 0\n        for data in train_data:\n            X = data[0]\n            Y = data[1]\n            _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\n            epoch_loss += c\n\n        print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n\n    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n\n    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n    print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n\ntrain_neural_network(x)\n(My System information)\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nYes\n\nOS Platform and Distribution:\n\nOS = Windows 10\n\nTensorFlow installed from (source or binary):\n*Installed from Source\nTensorFlow version (use command below):\n*When I ran => python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n*I get only this result => b'unknown' 1.0.0\nCUDA/cuDNN version:\n*cuda_8.0.61_win10\n*cuDNN v5.1 (Jan 20, 2017), for CUDA 8.0\nGPU model and memory:\n*GeForce GTX 1050 graphics card\n*RAM 32GB", "body": "I am facing a huge problem where the jupyter kernel keeps dying. This is my first experience of kernel ending on Jupyter. I'm using Tensorflow to fit a CNN model (the total input datasize is only 9.8MB)\r\n\r\nI did not have this issue in my previous run on the same code (however I did have errors where it said \"dst tensor is not initialized\". That was when I made the dataset really small to attempt to fit it. Could someone please kindly help ?\r\n\r\nThis is the code:\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nIMG_PX_SIZE = 50\r\nHM_SLICES = 20\r\n\r\nn_classes = 2\r\n\r\nx = tf.placeholder('float')\r\ny = tf.placeholder('float')\r\n\r\nkeep_rate = 0.8\r\nkeep_prob = tf.placeholder(tf.float32)\r\n\r\ndef conv3d(x, W):\r\n    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\r\n\r\ndef maxpool3d(x):\r\n    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\r\n\r\ndef convolutional_neural_network(x):\r\n    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,1,32])),\r\n               'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\r\n               'W_fc':tf.Variable(tf.random_normal([62720  ,1024])),\r\n               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\r\n\r\n    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\r\n               'b_conv2':tf.Variable(tf.random_normal([64])),\r\n               'b_fc':tf.Variable(tf.random_normal([1024])),\r\n               'out':tf.Variable(tf.random_normal([n_classes]))}\r\n\r\n    x = tf.reshape(x, shape=[-1, IMG_PX_SIZE, IMG_PX_SIZE, HM_SLICES, 1])\r\n\r\n    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\r\n    conv1 = maxpool3d(conv1)\r\n    \r\n    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\r\n    conv2 = maxpool3d(conv2)\r\n\r\n    fc = tf.reshape(conv2,[-1, 62720  ])\r\n    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\r\n    fc = tf.nn.dropout(fc, keep_rate)\r\n\r\n    output = tf.matmul(fc, weights['out']) + biases['out']\r\n\r\n    return output\r\n\r\n def train_neural_network(x):\r\n    \r\n    much_data = np.load('muchdata_sampled-50-50-20.npy')\r\n    train_data = much_data[:100]\r\n    validation_data = much_data[-100:]\r\n    \r\n    prediction = convolutional_neural_network(x)\r\n    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\r\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\r\n    \r\n    hm_epochs = 3\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n        for epoch in range(hm_epochs):\r\n            epoch_loss = 0\r\n            for data in train_data:\r\n                X = data[0]\r\n                Y = data[1]\r\n                _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\r\n                epoch_loss += c\r\n\r\n            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\r\n\r\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\r\n\r\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\r\n        print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\r\n\r\n train_neural_network(x)\r\n\r\n\r\n\r\n(My System information)\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n* Yes\r\n\r\nOS Platform and Distribution:\r\n* OS = Windows 10\r\n\r\nTensorFlow installed from (source or binary):\r\n*Installed from Source\r\n\r\nTensorFlow version (use command below):\r\n*When I ran => python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n*I get only this result => b'unknown' 1.0.0\r\n\r\nCUDA/cuDNN version:\r\n*cuda_8.0.61_win10\r\n*cuDNN v5.1 (Jan 20, 2017), for CUDA 8.0\r\n\r\nGPU model and memory:\r\n*GeForce GTX 1050 graphics card\r\n*RAM 32GB"}