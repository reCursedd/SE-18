{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291868368", "html_url": "https://github.com/tensorflow/tensorflow/issues/550#issuecomment-291868368", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/550", "id": 291868368, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTg2ODM2OA==", "user": {"login": "blester125", "id": 10950530, "node_id": "MDQ6VXNlcjEwOTUwNTMw", "avatar_url": "https://avatars3.githubusercontent.com/u/10950530?v=4", "gravatar_id": "", "url": "https://api.github.com/users/blester125", "html_url": "https://github.com/blester125", "followers_url": "https://api.github.com/users/blester125/followers", "following_url": "https://api.github.com/users/blester125/following{/other_user}", "gists_url": "https://api.github.com/users/blester125/gists{/gist_id}", "starred_url": "https://api.github.com/users/blester125/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/blester125/subscriptions", "organizations_url": "https://api.github.com/users/blester125/orgs", "repos_url": "https://api.github.com/users/blester125/repos", "events_url": "https://api.github.com/users/blester125/events{/privacy}", "received_events_url": "https://api.github.com/users/blester125/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-05T13:53:41Z", "updated_at": "2017-04-05T14:36:35Z", "author_association": "NONE", "body_html": "<p>I am very confused about my results. My network has only trained for 56,600 steps but my perplexities are far lower than many that are reported here. For example by bucket perplexities are 3.92, 2.77, 2.97, 3.91 and the total perplexity is something around 2.15</p>\n<p>I started the model training with</p>\n<p>python translate.py<br>\n--data_dir [your_data_directory] --train_dir [checkpoints_directory]<br>\n--en_vocab_size=40000 --fr_vocab_size=40000</p>\n<p>using tensorflow 1.0 and python 3.5</p>\n<p>Also when I try to translate things directly from the training set I often get nothing but _UNK's, for example:</p>\n<blockquote>\n<p>What is light ?<br>\n_UNK _UNK ?</p>\n</blockquote>\n<p>The model also seems to really into the words spectrom\u00e9trie and TORONTO</p>\n<blockquote>\n<p>Who is the president of the United States ?<br>\nLa _UNK _UNK spectrom\u00e9trie _UNK ?<br>\nThe hills are alive with the sound of music .<br>\nLe _UNK est TORONTO la bonne forme TORONTO la musique .</p>\n</blockquote>\n<p>There is also some strange stuff in my vocab files for example<br>\n\"The\" appears in the vocab file as \"\u2028\u2028The\" where there are two boxes before it in the atom text editor and then I copy pasted it there there seem to be two invisable character that eat key presses as you try to arrow key over them. The same thing goes for \"the\" but there is only one box</p>", "body_text": "I am very confused about my results. My network has only trained for 56,600 steps but my perplexities are far lower than many that are reported here. For example by bucket perplexities are 3.92, 2.77, 2.97, 3.91 and the total perplexity is something around 2.15\nI started the model training with\npython translate.py\n--data_dir [your_data_directory] --train_dir [checkpoints_directory]\n--en_vocab_size=40000 --fr_vocab_size=40000\nusing tensorflow 1.0 and python 3.5\nAlso when I try to translate things directly from the training set I often get nothing but _UNK's, for example:\n\nWhat is light ?\n_UNK _UNK ?\n\nThe model also seems to really into the words spectrom\u00e9trie and TORONTO\n\nWho is the president of the United States ?\nLa _UNK _UNK spectrom\u00e9trie _UNK ?\nThe hills are alive with the sound of music .\nLe _UNK est TORONTO la bonne forme TORONTO la musique .\n\nThere is also some strange stuff in my vocab files for example\n\"The\" appears in the vocab file as \"\u2028\u2028The\" where there are two boxes before it in the atom text editor and then I copy pasted it there there seem to be two invisable character that eat key presses as you try to arrow key over them. The same thing goes for \"the\" but there is only one box", "body": "I am very confused about my results. My network has only trained for 56,600 steps but my perplexities are far lower than many that are reported here. For example by bucket perplexities are 3.92, 2.77, 2.97, 3.91 and the total perplexity is something around 2.15\r\n\r\nI started the model training with\r\n\r\npython translate.py\r\n  --data_dir [your_data_directory] --train_dir [checkpoints_directory]\r\n  --en_vocab_size=40000 --fr_vocab_size=40000\r\n\r\nusing tensorflow 1.0 and python 3.5\r\n\r\nAlso when I try to translate things directly from the training set I often get nothing but _UNK's, for example:\r\n\r\n> What is light ?\r\n_UNK _UNK ?\r\n\r\nThe model also seems to really into the words spectrom\u00e9trie and TORONTO\r\n\r\n> Who is the president of the United States ?\r\nLa _UNK _UNK spectrom\u00e9trie _UNK ?\r\n> The hills are alive with the sound of music .\r\nLe _UNK est TORONTO la bonne forme TORONTO la musique .\r\n\r\nThere is also some strange stuff in my vocab files for example \r\n\"The\" appears in the vocab file as \"\u2028\u2028The\" where there are two boxes before it in the atom text editor and then I copy pasted it there there seem to be two invisable character that eat key presses as you try to arrow key over them. The same thing goes for \"the\" but there is only one box"}