{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/173473745", "html_url": "https://github.com/tensorflow/tensorflow/issues/550#issuecomment-173473745", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/550", "id": 173473745, "node_id": "MDEyOklzc3VlQ29tbWVudDE3MzQ3Mzc0NQ==", "user": {"login": "juesato", "id": 5617616, "node_id": "MDQ6VXNlcjU2MTc2MTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/5617616?v=4", "gravatar_id": "", "url": "https://api.github.com/users/juesato", "html_url": "https://github.com/juesato", "followers_url": "https://api.github.com/users/juesato/followers", "following_url": "https://api.github.com/users/juesato/following{/other_user}", "gists_url": "https://api.github.com/users/juesato/gists{/gist_id}", "starred_url": "https://api.github.com/users/juesato/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/juesato/subscriptions", "organizations_url": "https://api.github.com/users/juesato/orgs", "repos_url": "https://api.github.com/users/juesato/repos", "events_url": "https://api.github.com/users/juesato/events{/privacy}", "received_events_url": "https://api.github.com/users/juesato/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-21T06:31:30Z", "updated_at": "2016-01-21T06:31:30Z", "author_association": "NONE", "body_html": "<p>The basically problem I'm observing is that while the model learns to translate \"Who is the president of the United States?\" it doesn't translate other very basic sentences well. Even though I had perplexity &lt;5, basic translations such as \"What is my name?\" and \"How are you doing today?\" would not be translated well, and often have many OOV tokens (I haven't limited max vocab size at all). My concern is if perplexity isn't a good measure, for example, the model can game the cost function by frequently predicting OOV.</p>\n<p>I would post samples, but I'm out of the country without my computer - I'll be able to do this in a week.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=684901\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lukaszkaiser\">@lukaszkaiser</a> could you post a few more sample translations? If your model seems robust, then maybe it's just a peculiarity on my end, but right now, I'm not convinced perplexity &lt;5 means much.</p>\n<p>Thank you for looking into this, really appreciate it.</p>", "body_text": "The basically problem I'm observing is that while the model learns to translate \"Who is the president of the United States?\" it doesn't translate other very basic sentences well. Even though I had perplexity <5, basic translations such as \"What is my name?\" and \"How are you doing today?\" would not be translated well, and often have many OOV tokens (I haven't limited max vocab size at all). My concern is if perplexity isn't a good measure, for example, the model can game the cost function by frequently predicting OOV.\nI would post samples, but I'm out of the country without my computer - I'll be able to do this in a week.\n@lukaszkaiser could you post a few more sample translations? If your model seems robust, then maybe it's just a peculiarity on my end, but right now, I'm not convinced perplexity <5 means much.\nThank you for looking into this, really appreciate it.", "body": "The basically problem I'm observing is that while the model learns to translate \"Who is the president of the United States?\" it doesn't translate other very basic sentences well. Even though I had perplexity <5, basic translations such as \"What is my name?\" and \"How are you doing today?\" would not be translated well, and often have many OOV tokens (I haven't limited max vocab size at all). My concern is if perplexity isn't a good measure, for example, the model can game the cost function by frequently predicting OOV.\n\nI would post samples, but I'm out of the country without my computer - I'll be able to do this in a week.\n\n@lukaszkaiser could you post a few more sample translations? If your model seems robust, then maybe it's just a peculiarity on my end, but right now, I'm not convinced perplexity <5 means much. \n\nThank you for looking into this, really appreciate it.\n"}