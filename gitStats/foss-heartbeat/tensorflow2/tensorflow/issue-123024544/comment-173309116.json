{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/173309116", "html_url": "https://github.com/tensorflow/tensorflow/issues/550#issuecomment-173309116", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/550", "id": 173309116, "node_id": "MDEyOklzc3VlQ29tbWVudDE3MzMwOTExNg==", "user": {"login": "markusdr", "id": 1832155, "node_id": "MDQ6VXNlcjE4MzIxNTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1832155?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markusdr", "html_url": "https://github.com/markusdr", "followers_url": "https://api.github.com/users/markusdr/followers", "following_url": "https://api.github.com/users/markusdr/following{/other_user}", "gists_url": "https://api.github.com/users/markusdr/gists{/gist_id}", "starred_url": "https://api.github.com/users/markusdr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markusdr/subscriptions", "organizations_url": "https://api.github.com/users/markusdr/orgs", "repos_url": "https://api.github.com/users/markusdr/repos", "events_url": "https://api.github.com/users/markusdr/events{/privacy}", "received_events_url": "https://api.github.com/users/markusdr/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-20T18:08:05Z", "updated_at": "2016-01-20T18:08:05Z", "author_association": "NONE", "body_html": "<p>It would also be helpful to output BLEU scores on the dev data set at each checkpoint.</p>\n<p>Someone should train on the same data as this <a href=\"http://www.statmt.org/moses/?n=moses.baseline\" rel=\"nofollow\">Moses baseline</a> and compare the final BLEU scores when decoding the test set (23.5 with Moses). That would be a great comparison point and sanity check; it should also train fast as the data is not that large. (Use the same tokenizer as given there instead of the tutorial tokenizer in data_utils.py).<br>\nI've tried it myself, but a model of size 1024 with 3 layers doesn't fit in my 3GB GPU memory, and I haven't figured out yet how to get reasonable performance with a smaller model.</p>", "body_text": "It would also be helpful to output BLEU scores on the dev data set at each checkpoint.\nSomeone should train on the same data as this Moses baseline and compare the final BLEU scores when decoding the test set (23.5 with Moses). That would be a great comparison point and sanity check; it should also train fast as the data is not that large. (Use the same tokenizer as given there instead of the tutorial tokenizer in data_utils.py).\nI've tried it myself, but a model of size 1024 with 3 layers doesn't fit in my 3GB GPU memory, and I haven't figured out yet how to get reasonable performance with a smaller model.", "body": "It would also be helpful to output BLEU scores on the dev data set at each checkpoint.\n\nSomeone should train on the same data as this [Moses baseline](http://www.statmt.org/moses/?n=moses.baseline) and compare the final BLEU scores when decoding the test set (23.5 with Moses). That would be a great comparison point and sanity check; it should also train fast as the data is not that large. (Use the same tokenizer as given there instead of the tutorial tokenizer in data_utils.py). \nI've tried it myself, but a model of size 1024 with 3 layers doesn't fit in my 3GB GPU memory, and I haven't figured out yet how to get reasonable performance with a smaller model.\n"}