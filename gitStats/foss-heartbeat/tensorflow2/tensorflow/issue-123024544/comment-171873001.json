{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/171873001", "html_url": "https://github.com/tensorflow/tensorflow/issues/550#issuecomment-171873001", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/550", "id": 171873001, "node_id": "MDEyOklzc3VlQ29tbWVudDE3MTg3MzAwMQ==", "user": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-15T05:06:44Z", "updated_at": "2016-01-15T05:06:44Z", "author_association": "MEMBER", "body_html": "<p>To get reasonable translations you need to train a reasonably large network (say 3 layers with 1K nodes) for at least a few hundred thousand steps. Indeed, the perplexity numbers are just a guide to what's happening, but you can get decodings from the binary as well (or even add your own BLEU score computation using the same function). Did you try to re-run the tutorial setting? That was one decoding I got when training the tutorial before first release:</p>\n<pre><code>Reading model parameters from /tmp/translate.ckpt-340000\n&gt;  Who is the president of the United States?\n Qui est le pr\u00e9sident des \u00c9tats-Unis \n</code></pre>\n<p>We should be able to get at least something like this, if not, there might be some new bug to correct. I'll start a run to check it, but it usually takes about a week to get to this point, so please, post here if you get some numbers earlier.</p>", "body_text": "To get reasonable translations you need to train a reasonably large network (say 3 layers with 1K nodes) for at least a few hundred thousand steps. Indeed, the perplexity numbers are just a guide to what's happening, but you can get decodings from the binary as well (or even add your own BLEU score computation using the same function). Did you try to re-run the tutorial setting? That was one decoding I got when training the tutorial before first release:\nReading model parameters from /tmp/translate.ckpt-340000\n>  Who is the president of the United States?\n Qui est le pr\u00e9sident des \u00c9tats-Unis \n\nWe should be able to get at least something like this, if not, there might be some new bug to correct. I'll start a run to check it, but it usually takes about a week to get to this point, so please, post here if you get some numbers earlier.", "body": "To get reasonable translations you need to train a reasonably large network (say 3 layers with 1K nodes) for at least a few hundred thousand steps. Indeed, the perplexity numbers are just a guide to what's happening, but you can get decodings from the binary as well (or even add your own BLEU score computation using the same function). Did you try to re-run the tutorial setting? That was one decoding I got when training the tutorial before first release:\n\n```\nReading model parameters from /tmp/translate.ckpt-340000\n>  Who is the president of the United States?\n Qui est le pr\u00e9sident des \u00c9tats-Unis \n```\n\nWe should be able to get at least something like this, if not, there might be some new bug to correct. I'll start a run to check it, but it usually takes about a week to get to this point, so please, post here if you get some numbers earlier.\n"}