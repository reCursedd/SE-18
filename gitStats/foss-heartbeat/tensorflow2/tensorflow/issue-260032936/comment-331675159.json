{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/331675159", "html_url": "https://github.com/tensorflow/tensorflow/issues/13262#issuecomment-331675159", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13262", "id": 331675159, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMTY3NTE1OQ==", "user": {"login": "vishalbhalla", "id": 10245689, "node_id": "MDQ6VXNlcjEwMjQ1Njg5", "avatar_url": "https://avatars0.githubusercontent.com/u/10245689?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishalbhalla", "html_url": "https://github.com/vishalbhalla", "followers_url": "https://api.github.com/users/vishalbhalla/followers", "following_url": "https://api.github.com/users/vishalbhalla/following{/other_user}", "gists_url": "https://api.github.com/users/vishalbhalla/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishalbhalla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishalbhalla/subscriptions", "organizations_url": "https://api.github.com/users/vishalbhalla/orgs", "repos_url": "https://api.github.com/users/vishalbhalla/repos", "events_url": "https://api.github.com/users/vishalbhalla/events{/privacy}", "received_events_url": "https://api.github.com/users/vishalbhalla/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-23T23:01:18Z", "updated_at": "2017-09-23T23:01:18Z", "author_association": "NONE", "body_html": "<p>Hi Adam,</p>\n<p>I researched on stackoverflow forums but couldn't find anything relevant for mini-batches over unsupervised data. Hence, I posted here after a friend's suggestion. My apologies for the same.</p>\n<p>'f' is my whole dataset say text data of N points with dimension D<br>\nU is cluster centroid with K clusters again of dimension D</p>\n<p>I define my variables as below:</p>\n<pre><code>F = tf.Variable(f.astype(np.float32), name='F') \nU = tf.Variable(u.astype(np.float32), name='U')\nFMod = tf.reshape(F, [N/K, K, D], name='FMod')\nUMod = tf.reshape(U, [1, K, D], name='UMod')\n</code></pre>\n<p>Then I define a custom loss or objective function as 'objective'</p>\n<p>Next I use an optimizer</p>\n<pre><code>optimizer = tf.train.AdamOptimizer(learning_rate)\ntrain_W = optimizer.minimize(objective, var_list=[F, U])\n</code></pre>\n<p>Finally, I evaluate the variable as</p>\n<pre><code>with tf.Session() as sess:\n                \n    # Initialize all the variables\n    sess.run(init_op)\n\n    for n in range(noEpochs):\n\n        objval1 = sess.run([train_W, objective])\n\t\t\n</code></pre>\n<p>The thing I am stuck at - is to iterate over batches of my data 'f' which is ultimately used in the optimizer train_W. If I have a for loop over these mini-batches, I will assign a new variable train_W for each of these iterations. How can I pass this value so that it can be used in the next mini-batch?</p>\n<p>The full code can be found at this link: <a href=\"https://github.com/vishalbhalla/semi-supervised-clustering/blob/master/semi-supervised-clustering/code/Semi-supervised%20Clustering.ipynb\">Semi-supervised Clustering</a></p>", "body_text": "Hi Adam,\nI researched on stackoverflow forums but couldn't find anything relevant for mini-batches over unsupervised data. Hence, I posted here after a friend's suggestion. My apologies for the same.\n'f' is my whole dataset say text data of N points with dimension D\nU is cluster centroid with K clusters again of dimension D\nI define my variables as below:\nF = tf.Variable(f.astype(np.float32), name='F') \nU = tf.Variable(u.astype(np.float32), name='U')\nFMod = tf.reshape(F, [N/K, K, D], name='FMod')\nUMod = tf.reshape(U, [1, K, D], name='UMod')\n\nThen I define a custom loss or objective function as 'objective'\nNext I use an optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntrain_W = optimizer.minimize(objective, var_list=[F, U])\n\nFinally, I evaluate the variable as\nwith tf.Session() as sess:\n                \n    # Initialize all the variables\n    sess.run(init_op)\n\n    for n in range(noEpochs):\n\n        objval1 = sess.run([train_W, objective])\n\t\t\n\nThe thing I am stuck at - is to iterate over batches of my data 'f' which is ultimately used in the optimizer train_W. If I have a for loop over these mini-batches, I will assign a new variable train_W for each of these iterations. How can I pass this value so that it can be used in the next mini-batch?\nThe full code can be found at this link: Semi-supervised Clustering", "body": "Hi Adam,\r\n\r\nI researched on stackoverflow forums but couldn't find anything relevant for mini-batches over unsupervised data. Hence, I posted here after a friend's suggestion. My apologies for the same.\r\n\r\n'f' is my whole dataset say text data of N points with dimension D\r\nU is cluster centroid with K clusters again of dimension D\r\n\r\nI define my variables as below:\r\n```\r\nF = tf.Variable(f.astype(np.float32), name='F') \r\nU = tf.Variable(u.astype(np.float32), name='U')\r\nFMod = tf.reshape(F, [N/K, K, D], name='FMod')\r\nUMod = tf.reshape(U, [1, K, D], name='UMod')\r\n```\r\n\r\nThen I define a custom loss or objective function as 'objective'\r\n\r\nNext I use an optimizer\r\n```\r\noptimizer = tf.train.AdamOptimizer(learning_rate)\r\ntrain_W = optimizer.minimize(objective, var_list=[F, U])\r\n```\r\n\r\nFinally, I evaluate the variable as\r\n```\r\nwith tf.Session() as sess:\r\n                \r\n    # Initialize all the variables\r\n    sess.run(init_op)\r\n\r\n    for n in range(noEpochs):\r\n\r\n        objval1 = sess.run([train_W, objective])\r\n\t\t\r\n```\r\n\r\nThe thing I am stuck at - is to iterate over batches of my data 'f' which is ultimately used in the optimizer train_W. If I have a for loop over these mini-batches, I will assign a new variable train_W for each of these iterations. How can I pass this value so that it can be used in the next mini-batch?\r\n \r\nThe full code can be found at this link: [Semi-supervised Clustering](https://github.com/vishalbhalla/semi-supervised-clustering/blob/master/semi-supervised-clustering/code/Semi-supervised%20Clustering.ipynb)\r\n"}