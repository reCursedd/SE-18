{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3912", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3912/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3912/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3912/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3912", "id": 172037623, "node_id": "MDU6SXNzdWUxNzIwMzc2MjM=", "number": 3912, "title": "Tensorflow Data Corruption after Training", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-08-19T01:41:59Z", "updated_at": "2016-09-23T18:12:12Z", "closed_at": "2016-09-23T18:12:12Z", "author_association": "NONE", "body_html": "<p>GitHub issues are for bugs / installation problems / feature requests.<br>\nFor general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>Environment info</h3>\n<p>Operating System: Mac OSX El Capitan</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.</li>\n</ol>\n<p>The latest tensorflow.</p>\n<ol>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<p>0.10.0rc0</p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>\n<p>In order to reproduce, I have used the main function:</p>\n<p>import Input<br>\nimport Process</p>\n<p>import time<br>\nimport numpy as np<br>\nimport os</p>\n<p>import tensorflow as tf<br>\nfrom datetime import datetime</p>\n<p>FLAGS = tf.app.flags.FLAGS</p>\n<p>def train():</p>\n<pre><code>with tf.Session() as sess:\n\n    images, labels = Process.inputs()\n\n    forward_propgation_results = Process.forward_propagation(images)\n\n    cost, train_loss = Process.error(forward_propgation_results, labels)\n\n    image_summary_t = tf.image_summary(images.name, images, max_images = 2)\n\n    summary_op = tf.merge_all_summaries()\n\n    init = tf.initialize_all_variables()\n\n    saver = tf.train.Saver()\n\n    sess.run(init)\n\n    saver = tf.train.Saver(tf.all_variables())\n\n    tf.train.start_queue_runners(sess = sess)\n\n    train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"\n\n    summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n\n    for step in range(100):\n        start_time = time.time()\n        print(sess.run([train_loss, cost]))\n        duration = time.time() - start_time\n        if step % 1 == 0:\n            num_examples_per_step = FLAGS.batch_size\n            examples_per_sec = num_examples_per_step / duration\n            sec_per_batch = float(duration)\n\n            format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')\n            print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))\n\n            summary_str = sess.run(summary_op)\n            summary_writer.add_summary(summary_str, step)\n\n\n            if step % 2 == 0:\n                checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')\n                saver.save(sess, checkpoint_path, global_step = step)\n</code></pre>\n<p>def main(argv = None):<br>\ntrain()</p>\n<p>if <strong>name</strong> == '<strong>main</strong>':<br>\ntf.app.run()</p>\n</li>\n</ol>\n<p>Then the computation graph seems normal while running but after a few minutes after, the displayed images (in a similar to cifar10 format) shifts and turns into weird unrecognizable colors and the training loss which is normally descending normally is now displayed chaotically. This is all sudden after a few reloads a few minutes after training. I am absolutely sure there is nothing wrong with my hard drive.</p>\n<h3>What have you tried?</h3>\n<ol>\n<li>I have tried retraining.</li>\n</ol>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).</p>", "body_text": "GitHub issues are for bugs / installation problems / feature requests.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nEnvironment info\nOperating System: Mac OSX El Capitan\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\n\nThe latest tensorflow.\n\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\n0.10.0rc0\nSteps to reproduce\n\n\nIn order to reproduce, I have used the main function:\nimport Input\nimport Process\nimport time\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom datetime import datetime\nFLAGS = tf.app.flags.FLAGS\ndef train():\nwith tf.Session() as sess:\n\n    images, labels = Process.inputs()\n\n    forward_propgation_results = Process.forward_propagation(images)\n\n    cost, train_loss = Process.error(forward_propgation_results, labels)\n\n    image_summary_t = tf.image_summary(images.name, images, max_images = 2)\n\n    summary_op = tf.merge_all_summaries()\n\n    init = tf.initialize_all_variables()\n\n    saver = tf.train.Saver()\n\n    sess.run(init)\n\n    saver = tf.train.Saver(tf.all_variables())\n\n    tf.train.start_queue_runners(sess = sess)\n\n    train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"\n\n    summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n\n    for step in range(100):\n        start_time = time.time()\n        print(sess.run([train_loss, cost]))\n        duration = time.time() - start_time\n        if step % 1 == 0:\n            num_examples_per_step = FLAGS.batch_size\n            examples_per_sec = num_examples_per_step / duration\n            sec_per_batch = float(duration)\n\n            format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')\n            print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))\n\n            summary_str = sess.run(summary_op)\n            summary_writer.add_summary(summary_str, step)\n\n\n            if step % 2 == 0:\n                checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')\n                saver.save(sess, checkpoint_path, global_step = step)\n\ndef main(argv = None):\ntrain()\nif name == 'main':\ntf.app.run()\n\n\nThen the computation graph seems normal while running but after a few minutes after, the displayed images (in a similar to cifar10 format) shifts and turns into weird unrecognizable colors and the training loss which is normally descending normally is now displayed chaotically. This is all sudden after a few reloads a few minutes after training. I am absolutely sure there is nothing wrong with my hard drive.\nWhat have you tried?\n\nI have tried retraining.\n\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Mac OSX El Capitan\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n\nThe latest tensorflow.\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n0.10.0rc0\n### Steps to reproduce\n1. In order to reproduce, I have used the main function:\n   \n   import Input\n   import Process\n   \n   import time\n   import numpy as np\n   import os\n   \n   import tensorflow as tf\n   from datetime import datetime\n   \n   FLAGS = tf.app.flags.FLAGS\n   \n   def train():\n   \n   ```\n   with tf.Session() as sess:\n   \n       images, labels = Process.inputs()\n   \n       forward_propgation_results = Process.forward_propagation(images)\n   \n       cost, train_loss = Process.error(forward_propgation_results, labels)\n   \n       image_summary_t = tf.image_summary(images.name, images, max_images = 2)\n   \n       summary_op = tf.merge_all_summaries()\n   \n       init = tf.initialize_all_variables()\n   \n       saver = tf.train.Saver()\n   \n       sess.run(init)\n   \n       saver = tf.train.Saver(tf.all_variables())\n   \n       tf.train.start_queue_runners(sess = sess)\n   \n       train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"\n   \n       summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n   \n       for step in range(100):\n           start_time = time.time()\n           print(sess.run([train_loss, cost]))\n           duration = time.time() - start_time\n           if step % 1 == 0:\n               num_examples_per_step = FLAGS.batch_size\n               examples_per_sec = num_examples_per_step / duration\n               sec_per_batch = float(duration)\n   \n               format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')\n               print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))\n   \n               summary_str = sess.run(summary_op)\n               summary_writer.add_summary(summary_str, step)\n   \n   \n               if step % 2 == 0:\n                   checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')\n                   saver.save(sess, checkpoint_path, global_step = step)\n   ```\n   \n   def main(argv = None):\n       train()\n   \n   if **name** == '**main**':\n     tf.app.run()\n\nThen the computation graph seems normal while running but after a few minutes after, the displayed images (in a similar to cifar10 format) shifts and turns into weird unrecognizable colors and the training loss which is normally descending normally is now displayed chaotically. This is all sudden after a few reloads a few minutes after training. I am absolutely sure there is nothing wrong with my hard drive.\n### What have you tried?\n1. I have tried retraining.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n"}