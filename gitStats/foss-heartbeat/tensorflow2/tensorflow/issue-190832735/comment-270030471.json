{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/270030471", "html_url": "https://github.com/tensorflow/tensorflow/issues/5757#issuecomment-270030471", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5757", "id": 270030471, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MDAzMDQ3MQ==", "user": {"login": "vade", "id": 65011, "node_id": "MDQ6VXNlcjY1MDEx", "avatar_url": "https://avatars1.githubusercontent.com/u/65011?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vade", "html_url": "https://github.com/vade", "followers_url": "https://api.github.com/users/vade/followers", "following_url": "https://api.github.com/users/vade/following{/other_user}", "gists_url": "https://api.github.com/users/vade/gists{/gist_id}", "starred_url": "https://api.github.com/users/vade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vade/subscriptions", "organizations_url": "https://api.github.com/users/vade/orgs", "repos_url": "https://api.github.com/users/vade/repos", "events_url": "https://api.github.com/users/vade/events{/privacy}", "received_events_url": "https://api.github.com/users/vade/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-02T23:11:34Z", "updated_at": "2017-01-02T23:11:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi All.</p>\n<p>Looking at the new graph transform tool as documented here:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#optimizing-for-deployment\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#optimizing-for-deployment</a></p>\n<p>It appears that the quantize_nodes pass has the same issue as discussed in this bug. I understand this is because 8 bit quantized operations on the X86/ 64 platform have likely not been optimized, but I'm just putting a public notice that transform graph tool does not fix the problem.</p>\n<p>Thanks for all the work everyone, transform graph is very helpful in managing model size for deployment! Id love to eek some more speed from CPU builds on desktop if possible :) I understand that is likely not a priority use case however.</p>\n<p>Thanks again!</p>", "body_text": "Hi All.\nLooking at the new graph transform tool as documented here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#optimizing-for-deployment\nIt appears that the quantize_nodes pass has the same issue as discussed in this bug. I understand this is because 8 bit quantized operations on the X86/ 64 platform have likely not been optimized, but I'm just putting a public notice that transform graph tool does not fix the problem.\nThanks for all the work everyone, transform graph is very helpful in managing model size for deployment! Id love to eek some more speed from CPU builds on desktop if possible :) I understand that is likely not a priority use case however.\nThanks again!", "body": "Hi All. \r\n\r\nLooking at the new graph transform tool as documented here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#optimizing-for-deployment\r\n\r\nIt appears that the quantize_nodes pass has the same issue as discussed in this bug. I understand this is because 8 bit quantized operations on the X86/ 64 platform have likely not been optimized, but I'm just putting a public notice that transform graph tool does not fix the problem.\r\n\r\nThanks for all the work everyone, transform graph is very helpful in managing model size for deployment! Id love to eek some more speed from CPU builds on desktop if possible :) I understand that is likely not a priority use case however.\r\n\r\nThanks again!"}