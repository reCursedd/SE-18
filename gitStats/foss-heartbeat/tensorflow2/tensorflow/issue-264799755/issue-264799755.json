{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13651", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13651/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13651/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13651/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13651", "id": 264799755, "node_id": "MDU6SXNzdWUyNjQ3OTk3NTU=", "number": 13651, "title": "Android -- No OpKernel was registered to support Op 'SparseToDense' with these attrs", "user": {"login": "selcouthlyBlue", "id": 13268675, "node_id": "MDQ6VXNlcjEzMjY4Njc1", "avatar_url": "https://avatars2.githubusercontent.com/u/13268675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/selcouthlyBlue", "html_url": "https://github.com/selcouthlyBlue", "followers_url": "https://api.github.com/users/selcouthlyBlue/followers", "following_url": "https://api.github.com/users/selcouthlyBlue/following{/other_user}", "gists_url": "https://api.github.com/users/selcouthlyBlue/gists{/gist_id}", "starred_url": "https://api.github.com/users/selcouthlyBlue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/selcouthlyBlue/subscriptions", "organizations_url": "https://api.github.com/users/selcouthlyBlue/orgs", "repos_url": "https://api.github.com/users/selcouthlyBlue/repos", "events_url": "https://api.github.com/users/selcouthlyBlue/events{/privacy}", "received_events_url": "https://api.github.com/users/selcouthlyBlue/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-10-12T03:05:14Z", "updated_at": "2017-11-08T01:21:00Z", "closed_at": "2017-11-06T04:21:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I am trying to load a graph inside Android that I generated and frozen. I keep getting this error whenever I try to run it:</p>\n<pre><code>Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support\nOp 'SparseToDense' with these attrs.  Registered devices: [CPU], Registered kernels:\ndevice='CPU'; T in [DT_STRING]; Tindices in [DT_INT64]\ndevice='CPU'; T in [DT_STRING]; Tindices in [DT_INT32]\ndevice='CPU'; T in [DT_BOOL]; Tindices in [DT_INT64]\ndevice='CPU'; T in [DT_BOOL]; Tindices in [DT_INT32]\ndevice='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]\ndevice='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]\ndevice='CPU'; T in [DT_INT32]; Tindices in [DT_INT64]\ndevice='CPU'; T in [DT_INT32]; Tindices in [DT_INT32]\n                                                                                            \n[[Node: output = SparseToDense[T=DT_INT64, Tindices=DT_INT64, validate_indices=true](CTCBeamSearchDecoder, CTCBeamSearchDecoder:2, CTCBeamSearchDecoder:1, output/default_value)]]\n</code></pre>\n<p>I also optimized the graph for inference. When I try to load it onto Android, I get this error:</p>\n<pre><code>java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef expected inputs '' do not match 1 inputs \nspecified; Op&lt;name=Const; signature= -&gt; output:dtype; attr=value:tensor; attr=dtype:type&gt;; \nNodeDef: stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/add/y = Const[dtype=DT_INT32, \nvalue=Tensor&lt;type: int32 shape: [] values: 1&gt;](stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/Switch:1)\n</code></pre>\n<p>Steps to get the frozen graph and optimized graph:</p>\n<ol>\n<li>Clone this <a href=\"https://github.com/selcouthlyBlue/bi_lstm_ocr\">repository</a>:</li>\n<li>Run dummy_train.py producing the .pbtxt and checkpoint files</li>\n<li>Run dummy_freeze_and_save.py producing the frozen and optimized graphs frozen_bi_lstm_ctc_ocr.pb and optimized_frozen_bi_lstm_ctc_ocr.pb, respectively.</li>\n</ol>\n<p>Files in the mentioned repository relevant to the problem:</p>\n<ul>\n<li><a href=\"https://github.com/selcouthlyBlue/bi_lstm_ocr/blob/master/main/TFStackedBidirectionalLstmNetwork.py\">The Bidirectional LSTM Network</a> (contains the network specs and training code)</li>\n<li><a href=\"https://github.com/selcouthlyBlue/bi_lstm_ocr/blob/master/main/utils.py\">The utilities file</a> (containing the graph freezing and optimization codes)</li>\n<li><a href=\"https://github.com/selcouthlyBlue/bi_lstm_ocr/tree/master/test_files/configs\">The dummy configs</a> in the test files (just to train the model for 1 epoch)</li>\n</ul>\n<p>Here is the Java part related to the problem:</p>\n<pre><code>public String recognizeHandwritingFrom(Bitmap bitmap) {\n     bitmap = Bitmap.createScaledBitmap(bitmap, 1024, 128,, true);\n     int[] intValues = new int[bitmap.getWidth() * bitmap.getHeight()];\n     bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\n     float[] floatValues = new float[bitmap.getWidth() * bitmap.getHeight()];\n     for (int i = 0; i &lt; intValues.length; ++i) {\n         final int val = intValues[i];\n         floatValues[i] = (((val &gt;&gt; 16) &amp; 0xFF));\n     }\n     float[] result = new float[80];\n\n     long[] INPUT_SIZE = new long[]{1, bitmap.getHeight(), bitmap.getWidth()};\n     String[] inputs = new String[]{\"input\", \"seq_len_input\"};\n     inferenceInterface.feed(inputs[0], floatValues, INPUT_SIZE);\n     inferenceInterface.feed(inputs[1], new int[]{bitmap.getWidth()}, 1);\n\n     String[] outputs = new String[]{\"output\"};\n     inferenceInterface.run(outputs);\n     inferenceInterface.fetch(outputs[0], result);\n\n     return result.toString();\n }\n</code></pre>\n<p>I'm using</p>\n<ul>\n<li>Python 3.5.3 :: Anaconda custom (64-bit)</li>\n<li>The python tensorflow build is downloaded using Anaconda. Tensorflow version is 1.2.1</li>\n<li>The compiled tensorflow for IOS is from this <a href=\"https://ci.tensorflow.org/view/Nightly/job/nightly-android/44/artifact/\" rel=\"nofollow\">nightly build</a>.</li>\n</ul>\n<p>I would be really grateful if anyone has an idea on why Android seems to not be able to find <code>SparseToDense</code> as this is the only thing I have to fix to make it work.</p>\n<p>If you would like to run the android application as well, you can clone this <a href=\"https://github.com/selcouthlyBlue/mem2speech\">repository</a>. Just get the files from the nightly build and place them inside app/libs folder following this structure:</p>\n<pre><code>libs\n|____arm64-v8a\n| |____libtensorflow_inference.so\n|____armeabi-v7a\n| |____libtensorflow_inference.so\n|____libandroid_tensorflow_inference_java.jar\n|____x86\n| |____libtensorflow_inference.so\n|____x86_64\n| |____libtensorflow_inference.so\n</code></pre>", "body_text": "I am trying to load a graph inside Android that I generated and frozen. I keep getting this error whenever I try to run it:\nCaused by: java.lang.IllegalArgumentException: No OpKernel was registered to support\nOp 'SparseToDense' with these attrs.  Registered devices: [CPU], Registered kernels:\ndevice='CPU'; T in [DT_STRING]; Tindices in [DT_INT64]\ndevice='CPU'; T in [DT_STRING]; Tindices in [DT_INT32]\ndevice='CPU'; T in [DT_BOOL]; Tindices in [DT_INT64]\ndevice='CPU'; T in [DT_BOOL]; Tindices in [DT_INT32]\ndevice='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]\ndevice='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]\ndevice='CPU'; T in [DT_INT32]; Tindices in [DT_INT64]\ndevice='CPU'; T in [DT_INT32]; Tindices in [DT_INT32]\n                                                                                            \n[[Node: output = SparseToDense[T=DT_INT64, Tindices=DT_INT64, validate_indices=true](CTCBeamSearchDecoder, CTCBeamSearchDecoder:2, CTCBeamSearchDecoder:1, output/default_value)]]\n\nI also optimized the graph for inference. When I try to load it onto Android, I get this error:\njava.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef expected inputs '' do not match 1 inputs \nspecified; Op<name=Const; signature= -> output:dtype; attr=value:tensor; attr=dtype:type>; \nNodeDef: stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/add/y = Const[dtype=DT_INT32, \nvalue=Tensor<type: int32 shape: [] values: 1>](stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/Switch:1)\n\nSteps to get the frozen graph and optimized graph:\n\nClone this repository:\nRun dummy_train.py producing the .pbtxt and checkpoint files\nRun dummy_freeze_and_save.py producing the frozen and optimized graphs frozen_bi_lstm_ctc_ocr.pb and optimized_frozen_bi_lstm_ctc_ocr.pb, respectively.\n\nFiles in the mentioned repository relevant to the problem:\n\nThe Bidirectional LSTM Network (contains the network specs and training code)\nThe utilities file (containing the graph freezing and optimization codes)\nThe dummy configs in the test files (just to train the model for 1 epoch)\n\nHere is the Java part related to the problem:\npublic String recognizeHandwritingFrom(Bitmap bitmap) {\n     bitmap = Bitmap.createScaledBitmap(bitmap, 1024, 128,, true);\n     int[] intValues = new int[bitmap.getWidth() * bitmap.getHeight()];\n     bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\n     float[] floatValues = new float[bitmap.getWidth() * bitmap.getHeight()];\n     for (int i = 0; i < intValues.length; ++i) {\n         final int val = intValues[i];\n         floatValues[i] = (((val >> 16) & 0xFF));\n     }\n     float[] result = new float[80];\n\n     long[] INPUT_SIZE = new long[]{1, bitmap.getHeight(), bitmap.getWidth()};\n     String[] inputs = new String[]{\"input\", \"seq_len_input\"};\n     inferenceInterface.feed(inputs[0], floatValues, INPUT_SIZE);\n     inferenceInterface.feed(inputs[1], new int[]{bitmap.getWidth()}, 1);\n\n     String[] outputs = new String[]{\"output\"};\n     inferenceInterface.run(outputs);\n     inferenceInterface.fetch(outputs[0], result);\n\n     return result.toString();\n }\n\nI'm using\n\nPython 3.5.3 :: Anaconda custom (64-bit)\nThe python tensorflow build is downloaded using Anaconda. Tensorflow version is 1.2.1\nThe compiled tensorflow for IOS is from this nightly build.\n\nI would be really grateful if anyone has an idea on why Android seems to not be able to find SparseToDense as this is the only thing I have to fix to make it work.\nIf you would like to run the android application as well, you can clone this repository. Just get the files from the nightly build and place them inside app/libs folder following this structure:\nlibs\n|____arm64-v8a\n| |____libtensorflow_inference.so\n|____armeabi-v7a\n| |____libtensorflow_inference.so\n|____libandroid_tensorflow_inference_java.jar\n|____x86\n| |____libtensorflow_inference.so\n|____x86_64\n| |____libtensorflow_inference.so", "body": "I am trying to load a graph inside Android that I generated and frozen. I keep getting this error whenever I try to run it:\r\n\r\n```\r\nCaused by: java.lang.IllegalArgumentException: No OpKernel was registered to support\r\nOp 'SparseToDense' with these attrs.  Registered devices: [CPU], Registered kernels:\r\ndevice='CPU'; T in [DT_STRING]; Tindices in [DT_INT64]\r\ndevice='CPU'; T in [DT_STRING]; Tindices in [DT_INT32]\r\ndevice='CPU'; T in [DT_BOOL]; Tindices in [DT_INT64]\r\ndevice='CPU'; T in [DT_BOOL]; Tindices in [DT_INT32]\r\ndevice='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]\r\ndevice='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]\r\ndevice='CPU'; T in [DT_INT32]; Tindices in [DT_INT64]\r\ndevice='CPU'; T in [DT_INT32]; Tindices in [DT_INT32]\r\n                                                                                            \r\n[[Node: output = SparseToDense[T=DT_INT64, Tindices=DT_INT64, validate_indices=true](CTCBeamSearchDecoder, CTCBeamSearchDecoder:2, CTCBeamSearchDecoder:1, output/default_value)]]\r\n```\r\n\r\nI also optimized the graph for inference. When I try to load it onto Android, I get this error:\r\n\r\n```\r\njava.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef expected inputs '' do not match 1 inputs \r\nspecified; Op<name=Const; signature= -> output:dtype; attr=value:tensor; attr=dtype:type>; \r\nNodeDef: stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/add/y = Const[dtype=DT_INT32, \r\nvalue=Tensor<type: int32 shape: [] values: 1>](stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/Switch:1)\r\n```\r\n\r\nSteps to get the frozen graph and optimized graph:\r\n1. Clone this [repository](https://github.com/selcouthlyBlue/bi_lstm_ocr):\r\n2. Run dummy_train.py producing the .pbtxt and checkpoint files\r\n3. Run dummy_freeze_and_save.py producing the frozen and optimized graphs frozen_bi_lstm_ctc_ocr.pb and optimized_frozen_bi_lstm_ctc_ocr.pb, respectively.\r\n\r\nFiles in the mentioned repository relevant to the problem:\r\n- [The Bidirectional LSTM Network](https://github.com/selcouthlyBlue/bi_lstm_ocr/blob/master/main/TFStackedBidirectionalLstmNetwork.py) (contains the network specs and training code)\r\n- [The utilities file](https://github.com/selcouthlyBlue/bi_lstm_ocr/blob/master/main/utils.py) (containing the graph freezing and optimization codes)\r\n- [The dummy configs](https://github.com/selcouthlyBlue/bi_lstm_ocr/tree/master/test_files/configs) in the test files (just to train the model for 1 epoch)\r\n\r\nHere is the Java part related to the problem:\r\n\r\n   ```\r\n public String recognizeHandwritingFrom(Bitmap bitmap) {\r\n        bitmap = Bitmap.createScaledBitmap(bitmap, 1024, 128,, true);\r\n        int[] intValues = new int[bitmap.getWidth() * bitmap.getHeight()];\r\n        bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\r\n        float[] floatValues = new float[bitmap.getWidth() * bitmap.getHeight()];\r\n        for (int i = 0; i < intValues.length; ++i) {\r\n            final int val = intValues[i];\r\n            floatValues[i] = (((val >> 16) & 0xFF));\r\n        }\r\n        float[] result = new float[80];\r\n\r\n        long[] INPUT_SIZE = new long[]{1, bitmap.getHeight(), bitmap.getWidth()};\r\n        String[] inputs = new String[]{\"input\", \"seq_len_input\"};\r\n        inferenceInterface.feed(inputs[0], floatValues, INPUT_SIZE);\r\n        inferenceInterface.feed(inputs[1], new int[]{bitmap.getWidth()}, 1);\r\n\r\n        String[] outputs = new String[]{\"output\"};\r\n        inferenceInterface.run(outputs);\r\n        inferenceInterface.fetch(outputs[0], result);\r\n\r\n        return result.toString();\r\n    }\r\n```\r\nI'm using \r\n\r\n- Python 3.5.3 :: Anaconda custom (64-bit)\r\n- The python tensorflow build is downloaded using Anaconda. Tensorflow version is 1.2.1\r\n- The compiled tensorflow for IOS is from this [nightly build](https://ci.tensorflow.org/view/Nightly/job/nightly-android/44/artifact/).\r\n\r\nI would be really grateful if anyone has an idea on why Android seems to not be able to find `SparseToDense` as this is the only thing I have to fix to make it work.\r\n\r\nIf you would like to run the android application as well, you can clone this [repository](https://github.com/selcouthlyBlue/mem2speech). Just get the files from the nightly build and place them inside app/libs folder following this structure:\r\n\r\n```\r\nlibs\r\n|____arm64-v8a\r\n| |____libtensorflow_inference.so\r\n|____armeabi-v7a\r\n| |____libtensorflow_inference.so\r\n|____libandroid_tensorflow_inference_java.jar\r\n|____x86\r\n| |____libtensorflow_inference.so\r\n|____x86_64\r\n| |____libtensorflow_inference.so\r\n```"}