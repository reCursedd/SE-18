{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13905", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13905/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13905/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13905/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/13905", "id": 267479508, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQ4MDAyMDI0", "number": 13905, "title": "Add a GPU kernel for tf.dynamic_partition.", "user": {"login": "codrut3", "id": 10788581, "node_id": "MDQ6VXNlcjEwNzg4NTgx", "avatar_url": "https://avatars1.githubusercontent.com/u/10788581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codrut3", "html_url": "https://github.com/codrut3", "followers_url": "https://api.github.com/users/codrut3/followers", "following_url": "https://api.github.com/users/codrut3/following{/other_user}", "gists_url": "https://api.github.com/users/codrut3/gists{/gist_id}", "starred_url": "https://api.github.com/users/codrut3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codrut3/subscriptions", "organizations_url": "https://api.github.com/users/codrut3/orgs", "repos_url": "https://api.github.com/users/codrut3/repos", "events_url": "https://api.github.com/users/codrut3/events{/privacy}", "received_events_url": "https://api.github.com/users/codrut3/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2017-10-22T16:42:10Z", "updated_at": "2017-11-10T19:07:43Z", "closed_at": "2017-11-05T06:33:32Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13905", "html_url": "https://github.com/tensorflow/tensorflow/pull/13905", "diff_url": "https://github.com/tensorflow/tensorflow/pull/13905.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/13905.patch"}, "body_html": "<p>This PR partially addresses issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"192464124\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5965\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5965/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5965\">#5965</a>.<br>\nThe implementation follows closely the outline proposed by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2533174\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ekelsen\">@ekelsen</a> in the comments:</p>\n<ul>\n<li>use cub to radix-sort the information in partitions,</li>\n<li>compute the dimension of the output and allocate it,</li>\n<li>use tf.gather to move data to the correct output tensor.</li>\n</ul>\n<p>I wrote a benchmark test to compare it to the CPU implementation. The speedup is substantial:</p>\n<pre><code>Benchmark                          Time(ns) Iterations\n------------------------------------------------------\nBM_cpu_dynpart_float_2/1         2124112900        100\t 15.8M items/s\nBM_cpu_dynpart_float_2/256         28420220        100\t 1180.7M items/s\nBM_cpu_dynpart_float_100/1       1944110960        100\t 17.3M items/s\nBM_cpu_dynpart_float_100/256       48420780        100\t 693.0M items/s\nBM_cpu_dynpart_double_2/1         976543960        100\t 17.2M items/s\nBM_cpu_dynpart_double_2/256        24370610        100\t 688.4M items/s\nBM_cpu_dynpart_double_100/1       905003160        100\t 18.5M items/s\nBM_cpu_dynpart_double_100/256      50220970        100\t 334.1M items/s\nBM_cpu_dynpart_complex64_2/1     1065424130        100\t 15.7M items/s\nBM_cpu_dynpart_complex64_2/256     24578800        100\t 682.6M items/s\nBM_cpu_dynpart_complex64_100/1    991734960        100\t 16.9M items/s\nBM_cpu_dynpart_complex64_100/256   50632520        100\t 331.4M items/s\n\nBM_gpu_dynpart_float_2/1           57177980        100\t 586.8M items/s\nBM_gpu_dynpart_float_2/256          5857340        100\t 5728.6M items/s\nBM_gpu_dynpart_float_100/1         66666680        100\t 503.3M items/s\nBM_gpu_dynpart_float_100/256        6203580        100\t 5408.9M items/s\nBM_gpu_dynpart_double_2/1          30886780        100\t 543.2M items/s\nBM_gpu_dynpart_double_2/256         3717482        164\t 4513.1M items/s\nBM_gpu_dynpart_double_100/1        37068810        100\t 452.6M items/s\nBM_gpu_dynpart_double_100/256       4507507        142\t 3722.1M items/s\nBM_gpu_dynpart_complex64_2/1       32092400        100\t 522.8M items/s\nBM_gpu_dynpart_complex64_2/256      3940877        154\t 4257.2M items/s\nBM_gpu_dynpart_complex64_100/1     38496700        100\t 435.8M items/s\nBM_gpu_dynpart_complex64_100/256    5081670        100\t 3301.5M  #items/s\n</code></pre>\n<p>The gpu version runs 4.8 - 37 times faster, with the biggest gain obtained for 1D data.<br>\nThe benchmark tests used a 128MD data buffer, either 1D or with 256 columns, and num_partitions was either 2 or 100.</p>\n<p>The drawback to the implementation is that it requires some additional device memory.<br>\nIf I is the size of the input, O the size of the output, N the size of partitions, and P the number of partitions, the total memory cost is roughly<br>\nI + P + max(5N, O + N),<br>\nso about 4N additional memory is needed in the worst-case.<br>\nMost of it comes from using cub::RadixSort.</p>\n<p>However, N is large only if data is 1D, and this additional memory cost becomes prohibitive only for gigantic 1D vectors (&gt;= 512MB), which I don't think is a common use case.</p>", "body_text": "This PR partially addresses issue #5965.\nThe implementation follows closely the outline proposed by @ekelsen in the comments:\n\nuse cub to radix-sort the information in partitions,\ncompute the dimension of the output and allocate it,\nuse tf.gather to move data to the correct output tensor.\n\nI wrote a benchmark test to compare it to the CPU implementation. The speedup is substantial:\nBenchmark                          Time(ns) Iterations\n------------------------------------------------------\nBM_cpu_dynpart_float_2/1         2124112900        100\t 15.8M items/s\nBM_cpu_dynpart_float_2/256         28420220        100\t 1180.7M items/s\nBM_cpu_dynpart_float_100/1       1944110960        100\t 17.3M items/s\nBM_cpu_dynpart_float_100/256       48420780        100\t 693.0M items/s\nBM_cpu_dynpart_double_2/1         976543960        100\t 17.2M items/s\nBM_cpu_dynpart_double_2/256        24370610        100\t 688.4M items/s\nBM_cpu_dynpart_double_100/1       905003160        100\t 18.5M items/s\nBM_cpu_dynpart_double_100/256      50220970        100\t 334.1M items/s\nBM_cpu_dynpart_complex64_2/1     1065424130        100\t 15.7M items/s\nBM_cpu_dynpart_complex64_2/256     24578800        100\t 682.6M items/s\nBM_cpu_dynpart_complex64_100/1    991734960        100\t 16.9M items/s\nBM_cpu_dynpart_complex64_100/256   50632520        100\t 331.4M items/s\n\nBM_gpu_dynpart_float_2/1           57177980        100\t 586.8M items/s\nBM_gpu_dynpart_float_2/256          5857340        100\t 5728.6M items/s\nBM_gpu_dynpart_float_100/1         66666680        100\t 503.3M items/s\nBM_gpu_dynpart_float_100/256        6203580        100\t 5408.9M items/s\nBM_gpu_dynpart_double_2/1          30886780        100\t 543.2M items/s\nBM_gpu_dynpart_double_2/256         3717482        164\t 4513.1M items/s\nBM_gpu_dynpart_double_100/1        37068810        100\t 452.6M items/s\nBM_gpu_dynpart_double_100/256       4507507        142\t 3722.1M items/s\nBM_gpu_dynpart_complex64_2/1       32092400        100\t 522.8M items/s\nBM_gpu_dynpart_complex64_2/256      3940877        154\t 4257.2M items/s\nBM_gpu_dynpart_complex64_100/1     38496700        100\t 435.8M items/s\nBM_gpu_dynpart_complex64_100/256    5081670        100\t 3301.5M  #items/s\n\nThe gpu version runs 4.8 - 37 times faster, with the biggest gain obtained for 1D data.\nThe benchmark tests used a 128MD data buffer, either 1D or with 256 columns, and num_partitions was either 2 or 100.\nThe drawback to the implementation is that it requires some additional device memory.\nIf I is the size of the input, O the size of the output, N the size of partitions, and P the number of partitions, the total memory cost is roughly\nI + P + max(5N, O + N),\nso about 4N additional memory is needed in the worst-case.\nMost of it comes from using cub::RadixSort.\nHowever, N is large only if data is 1D, and this additional memory cost becomes prohibitive only for gigantic 1D vectors (>= 512MB), which I don't think is a common use case.", "body": "This PR partially addresses issue #5965.\r\nThe implementation follows closely the outline proposed by @ekelsen in the comments:\r\n- use cub to radix-sort the information in partitions,\r\n- compute the dimension of the output and allocate it,\r\n- use tf.gather to move data to the correct output tensor.\r\n\r\nI wrote a benchmark test to compare it to the CPU implementation. The speedup is substantial:\r\n\r\n```\r\nBenchmark                          Time(ns) Iterations\r\n------------------------------------------------------\r\nBM_cpu_dynpart_float_2/1         2124112900        100\t 15.8M items/s\r\nBM_cpu_dynpart_float_2/256         28420220        100\t 1180.7M items/s\r\nBM_cpu_dynpart_float_100/1       1944110960        100\t 17.3M items/s\r\nBM_cpu_dynpart_float_100/256       48420780        100\t 693.0M items/s\r\nBM_cpu_dynpart_double_2/1         976543960        100\t 17.2M items/s\r\nBM_cpu_dynpart_double_2/256        24370610        100\t 688.4M items/s\r\nBM_cpu_dynpart_double_100/1       905003160        100\t 18.5M items/s\r\nBM_cpu_dynpart_double_100/256      50220970        100\t 334.1M items/s\r\nBM_cpu_dynpart_complex64_2/1     1065424130        100\t 15.7M items/s\r\nBM_cpu_dynpart_complex64_2/256     24578800        100\t 682.6M items/s\r\nBM_cpu_dynpart_complex64_100/1    991734960        100\t 16.9M items/s\r\nBM_cpu_dynpart_complex64_100/256   50632520        100\t 331.4M items/s\r\n\r\nBM_gpu_dynpart_float_2/1           57177980        100\t 586.8M items/s\r\nBM_gpu_dynpart_float_2/256          5857340        100\t 5728.6M items/s\r\nBM_gpu_dynpart_float_100/1         66666680        100\t 503.3M items/s\r\nBM_gpu_dynpart_float_100/256        6203580        100\t 5408.9M items/s\r\nBM_gpu_dynpart_double_2/1          30886780        100\t 543.2M items/s\r\nBM_gpu_dynpart_double_2/256         3717482        164\t 4513.1M items/s\r\nBM_gpu_dynpart_double_100/1        37068810        100\t 452.6M items/s\r\nBM_gpu_dynpart_double_100/256       4507507        142\t 3722.1M items/s\r\nBM_gpu_dynpart_complex64_2/1       32092400        100\t 522.8M items/s\r\nBM_gpu_dynpart_complex64_2/256      3940877        154\t 4257.2M items/s\r\nBM_gpu_dynpart_complex64_100/1     38496700        100\t 435.8M items/s\r\nBM_gpu_dynpart_complex64_100/256    5081670        100\t 3301.5M  #items/s\r\n```\r\n\r\nThe gpu version runs 4.8 - 37 times faster, with the biggest gain obtained for 1D data.\r\nThe benchmark tests used a 128MD data buffer, either 1D or with 256 columns, and num_partitions was either 2 or 100.\r\n\r\nThe drawback to the implementation is that it requires some additional device memory.\r\nIf I is the size of the input, O the size of the output, N the size of partitions, and P the number of partitions, the total memory cost is roughly\r\nI + P + max(5N, O + N),\r\nso about 4N additional memory is needed in the worst-case.\r\nMost of it comes from using cub::RadixSort.\r\n\r\nHowever, N is large only if data is 1D, and this additional memory cost becomes prohibitive only for gigantic 1D vectors (>= 512MB), which I don't think is a common use case."}