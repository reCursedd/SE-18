{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/324436356", "html_url": "https://github.com/tensorflow/tensorflow/issues/12375#issuecomment-324436356", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12375", "id": 324436356, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDQzNjM1Ng==", "user": {"login": "eaplatanios", "id": 1294940, "node_id": "MDQ6VXNlcjEyOTQ5NDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1294940?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eaplatanios", "html_url": "https://github.com/eaplatanios", "followers_url": "https://api.github.com/users/eaplatanios/followers", "following_url": "https://api.github.com/users/eaplatanios/following{/other_user}", "gists_url": "https://api.github.com/users/eaplatanios/gists{/gist_id}", "starred_url": "https://api.github.com/users/eaplatanios/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eaplatanios/subscriptions", "organizations_url": "https://api.github.com/users/eaplatanios/orgs", "repos_url": "https://api.github.com/users/eaplatanios/repos", "events_url": "https://api.github.com/users/eaplatanios/events{/privacy}", "received_events_url": "https://api.github.com/users/eaplatanios/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-23T19:20:14Z", "updated_at": "2017-08-23T19:20:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5061\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alextp\">@alextp</a> Also, a small comment about efficiency: currently eager execution also performs shape inference. Wouldn't it be better to avoid running shape inference completely when executing an op eagerly, since the shape will be known when the execution finishes?</p>", "body_text": "@alextp Also, a small comment about efficiency: currently eager execution also performs shape inference. Wouldn't it be better to avoid running shape inference completely when executing an op eagerly, since the shape will be known when the execution finishes?", "body": "@alextp Also, a small comment about efficiency: currently eager execution also performs shape inference. Wouldn't it be better to avoid running shape inference completely when executing an op eagerly, since the shape will be known when the execution finishes?"}