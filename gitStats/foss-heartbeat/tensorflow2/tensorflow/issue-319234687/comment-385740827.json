{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385740827", "html_url": "https://github.com/tensorflow/tensorflow/issues/19002#issuecomment-385740827", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19002", "id": 385740827, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTc0MDgyNw==", "user": {"login": "glhfgg1024", "id": 30264480, "node_id": "MDQ6VXNlcjMwMjY0NDgw", "avatar_url": "https://avatars3.githubusercontent.com/u/30264480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/glhfgg1024", "html_url": "https://github.com/glhfgg1024", "followers_url": "https://api.github.com/users/glhfgg1024/followers", "following_url": "https://api.github.com/users/glhfgg1024/following{/other_user}", "gists_url": "https://api.github.com/users/glhfgg1024/gists{/gist_id}", "starred_url": "https://api.github.com/users/glhfgg1024/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/glhfgg1024/subscriptions", "organizations_url": "https://api.github.com/users/glhfgg1024/orgs", "repos_url": "https://api.github.com/users/glhfgg1024/repos", "events_url": "https://api.github.com/users/glhfgg1024/events{/privacy}", "received_events_url": "https://api.github.com/users/glhfgg1024/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-01T17:58:10Z", "updated_at": "2018-05-01T17:58:10Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> , the TensorFlow version is <code>1.6.0</code>. The <code>dataset_input_from_tfrecords</code> is:</p>\n<pre><code>def dataset_input_from_tfrecords(filenames, batch_size=1, num_epochs=1, shuffle=True, image_mean=None):\n# filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filenames)\n\n# Use `tf.parse_single_example()` to extract data from a `tf.Example`\n# protocol buffer, and perform any additional per-record preprocessing.\ndef parser(record):\n    keys_to_features = {\n        'image_raw': tf.FixedLenFeature([], tf.string),\n        'label': tf.FixedLenFeature([], tf.int64),\n    }\n    parsed = tf.parse_single_example(record, keys_to_features)\n    \n    # Perform additional preprocessing on the parsed data.\n    image = tf.cast(tf.decode_raw(parsed['image_raw'], tf.uint8), tf.float32) / 128 - 1.0\n    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n    label = tf.cast(parsed['label'], tf.int64)\n    \n    if image_mean != None:\n        image -= image_mean\n    \n    return image, label\n\n# Use `Dataset.map()` to build a pair of a feature dictionary and a label \n# tensor for each example.\ndataset = dataset.map(parser)\nif shuffle:\n    dataset = dataset.shuffle(buffer_size=1024)\ndataset = dataset.batch(batch_size)\n# dataset = dataset.padded_batch(batch_size, padded_shapes=([HEIGHT, WIDTH, 3], []))\n# dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\ndataset = dataset.repeat(num_epochs)\niterator = dataset.make_one_shot_iterator()\n\nfeatures, labels = iterator.get_next()\nreturn features, labels\n</code></pre>", "body_text": "Hi @mrry , the TensorFlow version is 1.6.0. The dataset_input_from_tfrecords is:\ndef dataset_input_from_tfrecords(filenames, batch_size=1, num_epochs=1, shuffle=True, image_mean=None):\n# filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filenames)\n\n# Use `tf.parse_single_example()` to extract data from a `tf.Example`\n# protocol buffer, and perform any additional per-record preprocessing.\ndef parser(record):\n    keys_to_features = {\n        'image_raw': tf.FixedLenFeature([], tf.string),\n        'label': tf.FixedLenFeature([], tf.int64),\n    }\n    parsed = tf.parse_single_example(record, keys_to_features)\n    \n    # Perform additional preprocessing on the parsed data.\n    image = tf.cast(tf.decode_raw(parsed['image_raw'], tf.uint8), tf.float32) / 128 - 1.0\n    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n    label = tf.cast(parsed['label'], tf.int64)\n    \n    if image_mean != None:\n        image -= image_mean\n    \n    return image, label\n\n# Use `Dataset.map()` to build a pair of a feature dictionary and a label \n# tensor for each example.\ndataset = dataset.map(parser)\nif shuffle:\n    dataset = dataset.shuffle(buffer_size=1024)\ndataset = dataset.batch(batch_size)\n# dataset = dataset.padded_batch(batch_size, padded_shapes=([HEIGHT, WIDTH, 3], []))\n# dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\ndataset = dataset.repeat(num_epochs)\niterator = dataset.make_one_shot_iterator()\n\nfeatures, labels = iterator.get_next()\nreturn features, labels", "body": "Hi @mrry , the TensorFlow version is `1.6.0`. The `dataset_input_from_tfrecords` is:\r\n\r\n    def dataset_input_from_tfrecords(filenames, batch_size=1, num_epochs=1, shuffle=True, image_mean=None):\r\n    # filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\r\n    dataset = tf.data.TFRecordDataset(filenames)\r\n    \r\n    # Use `tf.parse_single_example()` to extract data from a `tf.Example`\r\n    # protocol buffer, and perform any additional per-record preprocessing.\r\n    def parser(record):\r\n        keys_to_features = {\r\n            'image_raw': tf.FixedLenFeature([], tf.string),\r\n            'label': tf.FixedLenFeature([], tf.int64),\r\n        }\r\n        parsed = tf.parse_single_example(record, keys_to_features)\r\n        \r\n        # Perform additional preprocessing on the parsed data.\r\n        image = tf.cast(tf.decode_raw(parsed['image_raw'], tf.uint8), tf.float32) / 128 - 1.0\r\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\r\n        label = tf.cast(parsed['label'], tf.int64)\r\n        \r\n        if image_mean != None:\r\n            image -= image_mean\r\n        \r\n        return image, label\r\n    \r\n    # Use `Dataset.map()` to build a pair of a feature dictionary and a label \r\n    # tensor for each example.\r\n    dataset = dataset.map(parser)\r\n    if shuffle:\r\n        dataset = dataset.shuffle(buffer_size=1024)\r\n    dataset = dataset.batch(batch_size)\r\n    # dataset = dataset.padded_batch(batch_size, padded_shapes=([HEIGHT, WIDTH, 3], []))\r\n    # dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n    dataset = dataset.repeat(num_epochs)\r\n    iterator = dataset.make_one_shot_iterator()\r\n    \r\n    features, labels = iterator.get_next()\r\n    return features, labels"}