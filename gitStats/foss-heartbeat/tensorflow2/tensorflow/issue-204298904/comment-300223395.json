{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300223395", "html_url": "https://github.com/tensorflow/tensorflow/issues/7162#issuecomment-300223395", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7162", "id": 300223395, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDIyMzM5NQ==", "user": {"login": "lissyx", "id": 1645737, "node_id": "MDQ6VXNlcjE2NDU3Mzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1645737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lissyx", "html_url": "https://github.com/lissyx", "followers_url": "https://api.github.com/users/lissyx/followers", "following_url": "https://api.github.com/users/lissyx/following{/other_user}", "gists_url": "https://api.github.com/users/lissyx/gists{/gist_id}", "starred_url": "https://api.github.com/users/lissyx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lissyx/subscriptions", "organizations_url": "https://api.github.com/users/lissyx/orgs", "repos_url": "https://api.github.com/users/lissyx/repos", "events_url": "https://api.github.com/users/lissyx/events{/privacy}", "received_events_url": "https://api.github.com/users/lissyx/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-09T16:33:53Z", "updated_at": "2017-05-09T16:33:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Looks like this fixes the problem on our network as well. I just tested applying the documented transforms for \"8 bits calculations\", and the resulting file does indeed work.</p>\n<p>More precisely, <code>add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics) fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'</code> produced a network where our \"output_node\" is removed.</p>\n<p>But <code>add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\")  fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'</code> produces a network where we can do inference.</p>", "body_text": "Looks like this fixes the problem on our network as well. I just tested applying the documented transforms for \"8 bits calculations\", and the resulting file does indeed work.\nMore precisely, add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics) fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order' produced a network where our \"output_node\" is removed.\nBut add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\")  fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order' produces a network where we can do inference.", "body": "Looks like this fixes the problem on our network as well. I just tested applying the documented transforms for \"8 bits calculations\", and the resulting file does indeed work.\r\n\r\nMore precisely, `add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics) fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'` produced a network where our \"output_node\" is removed.\r\n\r\nBut `add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\")  fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'` produces a network where we can do inference."}