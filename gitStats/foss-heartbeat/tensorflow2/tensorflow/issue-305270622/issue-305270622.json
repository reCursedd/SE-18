{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17717", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17717/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17717/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17717/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17717", "id": 305270622, "node_id": "MDU6SXNzdWUzMDUyNzA2MjI=", "number": 17717, "title": "Add working example of distributed tensorflow using Estimator API for K-Means", "user": {"login": "avigyan1009", "id": 16451347, "node_id": "MDQ6VXNlcjE2NDUxMzQ3", "avatar_url": "https://avatars0.githubusercontent.com/u/16451347?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avigyan1009", "html_url": "https://github.com/avigyan1009", "followers_url": "https://api.github.com/users/avigyan1009/followers", "following_url": "https://api.github.com/users/avigyan1009/following{/other_user}", "gists_url": "https://api.github.com/users/avigyan1009/gists{/gist_id}", "starred_url": "https://api.github.com/users/avigyan1009/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avigyan1009/subscriptions", "organizations_url": "https://api.github.com/users/avigyan1009/orgs", "repos_url": "https://api.github.com/users/avigyan1009/repos", "events_url": "https://api.github.com/users/avigyan1009/events{/privacy}", "received_events_url": "https://api.github.com/users/avigyan1009/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-03-14T18:06:41Z", "updated_at": "2018-08-30T22:52:40Z", "closed_at": "2018-08-30T22:52:40Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Redhat</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N.A.</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N.A.</li>\n<li><strong>CUDA/cuDNN version</strong>: N.A.</li>\n<li><strong>GPU model and memory</strong>: N.A.</li>\n<li><strong>Exact command to reproduce</strong>: N.A.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am using standard library-provided k-means with Estimator API for distributed tensorflow. I have a cluster of three machine and I have updated the TF_CONFIG env. variable on all three machine. I am using HDFS to store the model directory so that all machine can access that it, but when I execute the python file from the master machine, the gRPC server gets created and then \"PS server and Worker server waiting for response from master\"  message is repeated after every 10 seconds or so.</p>\n<p>If sample code for using this Estimator-API based K-Means would had been present, it would have helped better</p>\n<h3>Source code / logs</h3>\n<p>import tensorflow as tf<br>\nimport numpy as np<br>\nimport pandas as pd<br>\nk = 5<br>\nn = 100<br>\nvariables = 2<br>\npoints = np.random.uniform(0, 1000, [n, variables])<br>\ninput_fn=lambda: tf.train.limit_epochs(tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)<br>\nkmeans=tf.contrib.factorization.KMeansClustering(num_clusters=k, use_mini_batch=False,model_dir=\"my_hdfs_path\")</p>\n<p>train_spec = tf.estimator.TrainSpec(input_fn=input_fn, max_steps=100)<br>\neval_spec = tf.estimator.EvalSpec(input_fn=input_fn)</p>\n<p>tf.estimator.train_and_evaluate(kmeans, train_spec, eval_spec)<br>\nlist(kmeans.predict(input_fn=input_fn))</p>\n<h3>TF_CONFIG:</h3>\n<p>{ \"cluster\":{ \"chief\":[ \"master:22220\" ], \"ps\":[ \"slave02:22220\" ], \"worker\":[ \"slave01:22220\" ] }, \"task\":{  \"type\":\"chief\", \"index\":0, } }</p>\n<p>Error message:<br>\nCreateSession still waiting for response from worker: /job:ps/replica:0/task:0<br>\nCreateSession still waiting for response from worker: /job:worker/replica:0/task:0</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Redhat\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): 1.5\nPython version: 3.6\nBazel version (if compiling from source): N.A.\nGCC/Compiler version (if compiling from source): N.A.\nCUDA/cuDNN version: N.A.\nGPU model and memory: N.A.\nExact command to reproduce: N.A.\n\nDescribe the problem\nI am using standard library-provided k-means with Estimator API for distributed tensorflow. I have a cluster of three machine and I have updated the TF_CONFIG env. variable on all three machine. I am using HDFS to store the model directory so that all machine can access that it, but when I execute the python file from the master machine, the gRPC server gets created and then \"PS server and Worker server waiting for response from master\"  message is repeated after every 10 seconds or so.\nIf sample code for using this Estimator-API based K-Means would had been present, it would have helped better\nSource code / logs\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nk = 5\nn = 100\nvariables = 2\npoints = np.random.uniform(0, 1000, [n, variables])\ninput_fn=lambda: tf.train.limit_epochs(tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)\nkmeans=tf.contrib.factorization.KMeansClustering(num_clusters=k, use_mini_batch=False,model_dir=\"my_hdfs_path\")\ntrain_spec = tf.estimator.TrainSpec(input_fn=input_fn, max_steps=100)\neval_spec = tf.estimator.EvalSpec(input_fn=input_fn)\ntf.estimator.train_and_evaluate(kmeans, train_spec, eval_spec)\nlist(kmeans.predict(input_fn=input_fn))\nTF_CONFIG:\n{ \"cluster\":{ \"chief\":[ \"master:22220\" ], \"ps\":[ \"slave02:22220\" ], \"worker\":[ \"slave01:22220\" ] }, \"task\":{  \"type\":\"chief\", \"index\":0, } }\nError message:\nCreateSession still waiting for response from worker: /job:ps/replica:0/task:0\nCreateSession still waiting for response from worker: /job:worker/replica:0/task:0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Redhat\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N.A.\r\n- **GCC/Compiler version (if compiling from source)**: N.A.\r\n- **CUDA/cuDNN version**: N.A.\r\n- **GPU model and memory**: N.A.\r\n- **Exact command to reproduce**: N.A.\r\n\r\n### Describe the problem\r\nI am using standard library-provided k-means with Estimator API for distributed tensorflow. I have a cluster of three machine and I have updated the TF_CONFIG env. variable on all three machine. I am using HDFS to store the model directory so that all machine can access that it, but when I execute the python file from the master machine, the gRPC server gets created and then \"PS server and Worker server waiting for response from master\"  message is repeated after every 10 seconds or so.  \r\n\r\nIf sample code for using this Estimator-API based K-Means would had been present, it would have helped better\r\n\r\n### Source code / logs\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\nk = 5\r\nn = 100\r\nvariables = 2\r\npoints = np.random.uniform(0, 1000, [n, variables])\r\ninput_fn=lambda: tf.train.limit_epochs(tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)\r\nkmeans=tf.contrib.factorization.KMeansClustering(num_clusters=k, use_mini_batch=False,model_dir=\"my_hdfs_path\")\r\n\r\ntrain_spec = tf.estimator.TrainSpec(input_fn=input_fn, max_steps=100)\r\neval_spec = tf.estimator.EvalSpec(input_fn=input_fn)\r\n\r\ntf.estimator.train_and_evaluate(kmeans, train_spec, eval_spec)\r\nlist(kmeans.predict(input_fn=input_fn))\r\n\r\n### TF_CONFIG:\r\n{ \"cluster\":{ \"chief\":[ \"master:22220\" ], \"ps\":[ \"slave02:22220\" ], \"worker\":[ \"slave01:22220\" ] }, \"task\":{  \"type\":\"chief\", \"index\":0, } }\r\n\r\nError message:\r\nCreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\nCreateSession still waiting for response from worker: /job:worker/replica:0/task:0"}