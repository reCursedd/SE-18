{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/317340420", "html_url": "https://github.com/tensorflow/tensorflow/issues/11692#issuecomment-317340420", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11692", "id": 317340420, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzM0MDQyMA==", "user": {"login": "meijun", "id": 22214696, "node_id": "MDQ6VXNlcjIyMjE0Njk2", "avatar_url": "https://avatars0.githubusercontent.com/u/22214696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meijun", "html_url": "https://github.com/meijun", "followers_url": "https://api.github.com/users/meijun/followers", "following_url": "https://api.github.com/users/meijun/following{/other_user}", "gists_url": "https://api.github.com/users/meijun/gists{/gist_id}", "starred_url": "https://api.github.com/users/meijun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meijun/subscriptions", "organizations_url": "https://api.github.com/users/meijun/orgs", "repos_url": "https://api.github.com/users/meijun/repos", "events_url": "https://api.github.com/users/meijun/events{/privacy}", "received_events_url": "https://api.github.com/users/meijun/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-24T07:25:19Z", "updated_at": "2017-08-03T18:01:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The tf.reduce_logsumexp source code currently is:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">reduce_logsumexp</span>(<span class=\"pl-smi\">input_tensor</span>,\n                     <span class=\"pl-smi\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                     <span class=\"pl-smi\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                     <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                     <span class=\"pl-smi\">reduction_indices</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>TF 1.2.0 source code<span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-k\">with</span> ops.name_scope(name, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ReduceLogSumExp<span class=\"pl-pds\">\"</span></span>, [input_tensor]) <span class=\"pl-k\">as</span> name:\n    my_max <span class=\"pl-k\">=</span> array_ops.stop_gradient(\n        reduce_max(\n            input_tensor,\n            <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span>axis,\n            <span class=\"pl-v\">reduction_indices</span><span class=\"pl-k\">=</span>reduction_indices,\n            <span class=\"pl-v\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n    result <span class=\"pl-k\">=</span> gen_math_ops.log(\n        reduce_sum(\n            gen_math_ops.exp(input_tensor <span class=\"pl-k\">-</span> my_max),\n            axis,\n            <span class=\"pl-v\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n            <span class=\"pl-v\">reduction_indices</span><span class=\"pl-k\">=</span>reduction_indices)) <span class=\"pl-k\">+</span> my_max\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> keep_dims:\n      <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(axis, <span class=\"pl-c1\">int</span>):\n        axis <span class=\"pl-k\">=</span> [axis]\n      result <span class=\"pl-k\">=</span> array_ops.squeeze(result, axis)\n    <span class=\"pl-k\">return</span> result</pre></div>\n<p>I have written my own tf_reduce_logsumexp to fix the bug:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">tf_reduce_logsumexp</span>(<span class=\"pl-smi\">input_tensor</span>,\n                        <span class=\"pl-smi\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                        <span class=\"pl-smi\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                        <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                        <span class=\"pl-smi\">reduction_indices</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Fix tf.reduce_logsumexp<span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> tf.name_scope(name, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tf_ReduceLogSumExp<span class=\"pl-pds\">\"</span></span>, [input_tensor]) <span class=\"pl-k\">as</span> name:\n        raw_max <span class=\"pl-k\">=</span> tf.reduce_max(\n            input_tensor,\n            <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span>axis,\n            <span class=\"pl-v\">reduction_indices</span><span class=\"pl-k\">=</span>reduction_indices,\n            <span class=\"pl-v\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n        my_max <span class=\"pl-k\">=</span> tf.stop_gradient(\n            tf.where(\n                tf.is_finite(raw_max),\n                raw_max,\n                tf.zeros_like(raw_max)))\n        result <span class=\"pl-k\">=</span> tf.log(\n            tf.reduce_sum(\n                tf.exp(input_tensor <span class=\"pl-k\">-</span> my_max),\n                axis,\n                <span class=\"pl-v\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                <span class=\"pl-v\">reduction_indices</span><span class=\"pl-k\">=</span>reduction_indices)) <span class=\"pl-k\">+</span> my_max\n        <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> keep_dims:\n            <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(axis, <span class=\"pl-c1\">int</span>):\n                axis <span class=\"pl-k\">=</span> [axis]\n            result <span class=\"pl-k\">=</span> tf.squeeze(result, axis)\n        <span class=\"pl-k\">return</span> result</pre></div>", "body_text": "The tf.reduce_logsumexp source code currently is:\ndef reduce_logsumexp(input_tensor,\n                     axis=None,\n                     keep_dims=False,\n                     name=None,\n                     reduction_indices=None):\n  \"\"\"TF 1.2.0 source code\"\"\"\n  with ops.name_scope(name, \"ReduceLogSumExp\", [input_tensor]) as name:\n    my_max = array_ops.stop_gradient(\n        reduce_max(\n            input_tensor,\n            axis=axis,\n            reduction_indices=reduction_indices,\n            keep_dims=True))\n    result = gen_math_ops.log(\n        reduce_sum(\n            gen_math_ops.exp(input_tensor - my_max),\n            axis,\n            keep_dims=True,\n            reduction_indices=reduction_indices)) + my_max\n    if not keep_dims:\n      if isinstance(axis, int):\n        axis = [axis]\n      result = array_ops.squeeze(result, axis)\n    return result\nI have written my own tf_reduce_logsumexp to fix the bug:\ndef tf_reduce_logsumexp(input_tensor,\n                        axis=None,\n                        keep_dims=False,\n                        name=None,\n                        reduction_indices=None):\n    \"\"\"Fix tf.reduce_logsumexp\"\"\"\n    with tf.name_scope(name, \"tf_ReduceLogSumExp\", [input_tensor]) as name:\n        raw_max = tf.reduce_max(\n            input_tensor,\n            axis=axis,\n            reduction_indices=reduction_indices,\n            keep_dims=True)\n        my_max = tf.stop_gradient(\n            tf.where(\n                tf.is_finite(raw_max),\n                raw_max,\n                tf.zeros_like(raw_max)))\n        result = tf.log(\n            tf.reduce_sum(\n                tf.exp(input_tensor - my_max),\n                axis,\n                keep_dims=True,\n                reduction_indices=reduction_indices)) + my_max\n        if not keep_dims:\n            if isinstance(axis, int):\n                axis = [axis]\n            result = tf.squeeze(result, axis)\n        return result", "body": "The tf.reduce_logsumexp source code currently is:\r\n```python\r\ndef reduce_logsumexp(input_tensor,\r\n                     axis=None,\r\n                     keep_dims=False,\r\n                     name=None,\r\n                     reduction_indices=None):\r\n  \"\"\"TF 1.2.0 source code\"\"\"\r\n  with ops.name_scope(name, \"ReduceLogSumExp\", [input_tensor]) as name:\r\n    my_max = array_ops.stop_gradient(\r\n        reduce_max(\r\n            input_tensor,\r\n            axis=axis,\r\n            reduction_indices=reduction_indices,\r\n            keep_dims=True))\r\n    result = gen_math_ops.log(\r\n        reduce_sum(\r\n            gen_math_ops.exp(input_tensor - my_max),\r\n            axis,\r\n            keep_dims=True,\r\n            reduction_indices=reduction_indices)) + my_max\r\n    if not keep_dims:\r\n      if isinstance(axis, int):\r\n        axis = [axis]\r\n      result = array_ops.squeeze(result, axis)\r\n    return result\r\n```\r\n\r\nI have written my own tf_reduce_logsumexp to fix the bug:\r\n```python\r\ndef tf_reduce_logsumexp(input_tensor,\r\n                        axis=None,\r\n                        keep_dims=False,\r\n                        name=None,\r\n                        reduction_indices=None):\r\n    \"\"\"Fix tf.reduce_logsumexp\"\"\"\r\n    with tf.name_scope(name, \"tf_ReduceLogSumExp\", [input_tensor]) as name:\r\n        raw_max = tf.reduce_max(\r\n            input_tensor,\r\n            axis=axis,\r\n            reduction_indices=reduction_indices,\r\n            keep_dims=True)\r\n        my_max = tf.stop_gradient(\r\n            tf.where(\r\n                tf.is_finite(raw_max),\r\n                raw_max,\r\n                tf.zeros_like(raw_max)))\r\n        result = tf.log(\r\n            tf.reduce_sum(\r\n                tf.exp(input_tensor - my_max),\r\n                axis,\r\n                keep_dims=True,\r\n                reduction_indices=reduction_indices)) + my_max\r\n        if not keep_dims:\r\n            if isinstance(axis, int):\r\n                axis = [axis]\r\n            result = tf.squeeze(result, axis)\r\n        return result\r\n```\r\n"}