{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/267881864", "html_url": "https://github.com/tensorflow/tensorflow/issues/6019#issuecomment-267881864", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6019", "id": 267881864, "node_id": "MDEyOklzc3VlQ29tbWVudDI2Nzg4MTg2NA==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-19T04:54:22Z", "updated_at": "2016-12-19T04:54:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I took a <a href=\"https://github.com/yaroslavvb/notebooks/blob/master/mnist-memory.ipynb\">closer look</a> at your memory usage and the main source of memory usage is the activation in your first conv layer.</p>\n<p>Your convolution has 32 filters, so activations for first conv layer takes 4x28x28x32 = 100k per example. This is followed by broadcasting add which makes it 200k total. To run this over whole dataset you need 60k x 200k = 12GB of RAM</p>", "body_text": "I took a closer look at your memory usage and the main source of memory usage is the activation in your first conv layer.\nYour convolution has 32 filters, so activations for first conv layer takes 4x28x28x32 = 100k per example. This is followed by broadcasting add which makes it 200k total. To run this over whole dataset you need 60k x 200k = 12GB of RAM", "body": "I took a [closer look](https://github.com/yaroslavvb/notebooks/blob/master/mnist-memory.ipynb) at your memory usage and the main source of memory usage is the activation in your first conv layer.\r\n\r\nYour convolution has 32 filters, so activations for first conv layer takes 4x28x28x32 = 100k per example. This is followed by broadcasting add which makes it 200k total. To run this over whole dataset you need 60k x 200k = 12GB of RAM\r\n\r\n"}