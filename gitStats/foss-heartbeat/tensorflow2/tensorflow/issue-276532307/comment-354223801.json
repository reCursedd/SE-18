{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/354223801", "html_url": "https://github.com/tensorflow/tensorflow/issues/14857#issuecomment-354223801", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14857", "id": 354223801, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDIyMzgwMQ==", "user": {"login": "chaos5958", "id": 15246011, "node_id": "MDQ6VXNlcjE1MjQ2MDEx", "avatar_url": "https://avatars2.githubusercontent.com/u/15246011?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chaos5958", "html_url": "https://github.com/chaos5958", "followers_url": "https://api.github.com/users/chaos5958/followers", "following_url": "https://api.github.com/users/chaos5958/following{/other_user}", "gists_url": "https://api.github.com/users/chaos5958/gists{/gist_id}", "starred_url": "https://api.github.com/users/chaos5958/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chaos5958/subscriptions", "organizations_url": "https://api.github.com/users/chaos5958/orgs", "repos_url": "https://api.github.com/users/chaos5958/repos", "events_url": "https://api.github.com/users/chaos5958/events{/privacy}", "received_events_url": "https://api.github.com/users/chaos5958/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-28T03:51:37Z", "updated_at": "2017-12-28T03:54:36Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=14304858\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xtudbxk\">@xtudbxk</a></p>\n<p>I understand shuffling filenames could handle this problem.<br>\nHowever, Tensorflow recommends \"TFRecord\" and \"Dataset AP\" to build an input pipeline.<br>\nTherefore, if I construct as below (TFRecord--tf.data), how can I shuffle whole dataset if a TFRecord file is too large to fit on own device memory?<br>\nI think I observe repeating loss pattern on Tensorboard due to only partially random dataset.</p>\n<p>Summary: I want to shuffle whole 'tf.data.TFRecordDataset' every epoch.</p>\n<p><code>dataset = tf.data.TFRecordDataset(filenames)</code><br>\n<code>dataset = dataset.map(parser, self.nMapThread)</code><br>\n<code>dataset = dataset.shuffle(buffer_size=10000)</code><br>\n<code>dataset = dataset.batch(batchsize)</code><br>\n<code>iterator = dataset.make_initializable_iterator()</code><br>\n<code>hr_image, lr_bicubic_image = iterator.get_next()</code></p>", "body_text": "@xtudbxk\nI understand shuffling filenames could handle this problem.\nHowever, Tensorflow recommends \"TFRecord\" and \"Dataset AP\" to build an input pipeline.\nTherefore, if I construct as below (TFRecord--tf.data), how can I shuffle whole dataset if a TFRecord file is too large to fit on own device memory?\nI think I observe repeating loss pattern on Tensorboard due to only partially random dataset.\nSummary: I want to shuffle whole 'tf.data.TFRecordDataset' every epoch.\ndataset = tf.data.TFRecordDataset(filenames)\ndataset = dataset.map(parser, self.nMapThread)\ndataset = dataset.shuffle(buffer_size=10000)\ndataset = dataset.batch(batchsize)\niterator = dataset.make_initializable_iterator()\nhr_image, lr_bicubic_image = iterator.get_next()", "body": "@xtudbxk             \r\n\r\nI understand shuffling filenames could handle this problem.\r\nHowever, Tensorflow recommends \"TFRecord\" and \"Dataset AP\" to build an input pipeline.\r\nTherefore, if I construct as below (TFRecord--tf.data), how can I shuffle whole dataset if a TFRecord file is too large to fit on own device memory?\r\nI think I observe repeating loss pattern on Tensorboard due to only partially random dataset. \r\n\r\nSummary: I want to shuffle whole 'tf.data.TFRecordDataset' every epoch.\r\n\r\n`dataset = tf.data.TFRecordDataset(filenames)`\r\n`dataset = dataset.map(parser, self.nMapThread)`\r\n`dataset = dataset.shuffle(buffer_size=10000)`\r\n`dataset = dataset.batch(batchsize)`\r\n`iterator = dataset.make_initializable_iterator()`\r\n`hr_image, lr_bicubic_image = iterator.get_next()`\r\n"}