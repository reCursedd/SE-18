{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347261151", "html_url": "https://github.com/tensorflow/tensorflow/issues/14857#issuecomment-347261151", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14857", "id": 347261151, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzI2MTE1MQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-27T17:36:49Z", "updated_at": "2017-11-27T17:36:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The <code>Dataset.shuffle()</code> implementation is designed for data that could be shuffled in memory; we're considering whether to add support for external-memory shuffles, but this is in the early stages. In case it works for you, here's the usual approach we use when the data are too large to fit in memory:</p>\n<ol>\n<li>Randomly shuffle the entire data once using a MapReduce/Spark/Beam/etc. job to create a set of roughly equal-sized files (\"shards\").</li>\n<li>In each epoch:\n<ol>\n<li>Randomly shuffle the list of shard filenames, using <code>Dataset.list_files(...).shuffle(num_shards)</code>.</li>\n<li>Use <code>dataset.interleave(lambda filename: tf.data.TextLineDataset(filename), cycle_length=N)</code> to mix together records from <code>N</code> different shards.</li>\n<li>Use <code>dataset.shuffle(B)</code> to shuffle the resulting dataset. Setting <code>B</code> might require some experimentation, but you will probably want to set it to some value larger than the number of records in a single shard.</li>\n</ol>\n</li>\n</ol>", "body_text": "The Dataset.shuffle() implementation is designed for data that could be shuffled in memory; we're considering whether to add support for external-memory shuffles, but this is in the early stages. In case it works for you, here's the usual approach we use when the data are too large to fit in memory:\n\nRandomly shuffle the entire data once using a MapReduce/Spark/Beam/etc. job to create a set of roughly equal-sized files (\"shards\").\nIn each epoch:\n\nRandomly shuffle the list of shard filenames, using Dataset.list_files(...).shuffle(num_shards).\nUse dataset.interleave(lambda filename: tf.data.TextLineDataset(filename), cycle_length=N) to mix together records from N different shards.\nUse dataset.shuffle(B) to shuffle the resulting dataset. Setting B might require some experimentation, but you will probably want to set it to some value larger than the number of records in a single shard.", "body": "The `Dataset.shuffle()` implementation is designed for data that could be shuffled in memory; we're considering whether to add support for external-memory shuffles, but this is in the early stages. In case it works for you, here's the usual approach we use when the data are too large to fit in memory:\r\n\r\n1. Randomly shuffle the entire data once using a MapReduce/Spark/Beam/etc. job to create a set of roughly equal-sized files (\"shards\").\r\n2. In each epoch:\r\n     1. Randomly shuffle the list of shard filenames, using `Dataset.list_files(...).shuffle(num_shards)`.\r\n     2. Use `dataset.interleave(lambda filename: tf.data.TextLineDataset(filename), cycle_length=N)` to mix together records from `N` different shards.\r\n     3. Use `dataset.shuffle(B)` to shuffle the resulting dataset. Setting `B` might require some experimentation, but you will probably want to set it to some value larger than the number of records in a single shard."}