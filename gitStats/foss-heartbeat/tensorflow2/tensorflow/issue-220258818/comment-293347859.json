{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/293347859", "html_url": "https://github.com/tensorflow/tensorflow/issues/9047#issuecomment-293347859", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9047", "id": 293347859, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MzM0Nzg1OQ==", "user": {"login": "taion", "id": 3112159, "node_id": "MDQ6VXNlcjMxMTIxNTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/3112159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taion", "html_url": "https://github.com/taion", "followers_url": "https://api.github.com/users/taion/followers", "following_url": "https://api.github.com/users/taion/following{/other_user}", "gists_url": "https://api.github.com/users/taion/gists{/gist_id}", "starred_url": "https://api.github.com/users/taion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taion/subscriptions", "organizations_url": "https://api.github.com/users/taion/orgs", "repos_url": "https://api.github.com/users/taion/repos", "events_url": "https://api.github.com/users/taion/events{/privacy}", "received_events_url": "https://api.github.com/users/taion/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-11T18:00:53Z", "updated_at": "2017-04-11T18:00:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Just checked a few other packages \u2013</p>\n<ul>\n<li>Keras uses the same incorrect formulation as here: <a href=\"https://github.com/fchollet/keras/blob/7f58b6fbe702c1936e88a878002ee6e9c469bc77/keras/optimizers.py#L389-L400\">https://github.com/fchollet/keras/blob/7f58b6fbe702c1936e88a878002ee6e9c469bc77/keras/optimizers.py#L389-L400</a></li>\n<li>PyTorch uses the same incorrect formulation as here: <a href=\"https://github.com/pytorch/pytorch/blob/f17cfe42936310a2e3fd573e1f4dec8c684d4003/torch/optim/adam.py#L68-L72\">https://github.com/pytorch/pytorch/blob/f17cfe42936310a2e3fd573e1f4dec8c684d4003/torch/optim/adam.py#L68-L72</a></li>\n<li>Lasagne uses the correct implementation, but in the unoptimized form: <a href=\"https://github.com/Lasagne/Lasagne/blob/45bb5689f0b2edb7114608e88305e8074d29bbe7/lasagne/updates.py#L620-L622\">https://github.com/Lasagne/Lasagne/blob/45bb5689f0b2edb7114608e88305e8074d29bbe7/lasagne/updates.py#L620-L622</a></li>\n</ul>\n<p>I mean, I don't know. The correct version seems unlikely to cause issues for the on-label case, or people using Lasagne would have had problems.</p>\n<p>I don't really want to train an InceptionNet from scratch to see what this does for the off-label case; I will just note that when I tried using a larger epsilon a while ago, my model seemed to not train at all even when I used a higher learning rate, which would suggest that the current implementation makes things worse in the off-label case of using a higher epsilon.</p>", "body_text": "Just checked a few other packages \u2013\n\nKeras uses the same incorrect formulation as here: https://github.com/fchollet/keras/blob/7f58b6fbe702c1936e88a878002ee6e9c469bc77/keras/optimizers.py#L389-L400\nPyTorch uses the same incorrect formulation as here: https://github.com/pytorch/pytorch/blob/f17cfe42936310a2e3fd573e1f4dec8c684d4003/torch/optim/adam.py#L68-L72\nLasagne uses the correct implementation, but in the unoptimized form: https://github.com/Lasagne/Lasagne/blob/45bb5689f0b2edb7114608e88305e8074d29bbe7/lasagne/updates.py#L620-L622\n\nI mean, I don't know. The correct version seems unlikely to cause issues for the on-label case, or people using Lasagne would have had problems.\nI don't really want to train an InceptionNet from scratch to see what this does for the off-label case; I will just note that when I tried using a larger epsilon a while ago, my model seemed to not train at all even when I used a higher learning rate, which would suggest that the current implementation makes things worse in the off-label case of using a higher epsilon.", "body": "Just checked a few other packages \u2013\r\n\r\n- Keras uses the same incorrect formulation as here: https://github.com/fchollet/keras/blob/7f58b6fbe702c1936e88a878002ee6e9c469bc77/keras/optimizers.py#L389-L400\r\n- PyTorch uses the same incorrect formulation as here: https://github.com/pytorch/pytorch/blob/f17cfe42936310a2e3fd573e1f4dec8c684d4003/torch/optim/adam.py#L68-L72\r\n- Lasagne uses the correct implementation, but in the unoptimized form: https://github.com/Lasagne/Lasagne/blob/45bb5689f0b2edb7114608e88305e8074d29bbe7/lasagne/updates.py#L620-L622\r\n\r\nI mean, I don't know. The correct version seems unlikely to cause issues for the on-label case, or people using Lasagne would have had problems.\r\n\r\nI don't really want to train an InceptionNet from scratch to see what this does for the off-label case; I will just note that when I tried using a larger epsilon a while ago, my model seemed to not train at all even when I used a higher learning rate, which would suggest that the current implementation makes things worse in the off-label case of using a higher epsilon."}