{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16900", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16900/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16900/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16900/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16900", "id": 296013784, "node_id": "MDU6SXNzdWUyOTYwMTM3ODQ=", "number": 16900, "title": "Restoring a model trained with tf.estimator and feeding input through feed_dict", "user": {"login": "deepaksuresh", "id": 9796812, "node_id": "MDQ6VXNlcjk3OTY4MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/9796812?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepaksuresh", "html_url": "https://github.com/deepaksuresh", "followers_url": "https://api.github.com/users/deepaksuresh/followers", "following_url": "https://api.github.com/users/deepaksuresh/following{/other_user}", "gists_url": "https://api.github.com/users/deepaksuresh/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepaksuresh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepaksuresh/subscriptions", "organizations_url": "https://api.github.com/users/deepaksuresh/orgs", "repos_url": "https://api.github.com/users/deepaksuresh/repos", "events_url": "https://api.github.com/users/deepaksuresh/events{/privacy}", "received_events_url": "https://api.github.com/users/deepaksuresh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-09T21:13:31Z", "updated_at": "2018-09-07T12:21:54Z", "closed_at": "2018-02-09T23:08:42Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nNo</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nbinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.5</li>\n<li><strong>Python version</strong>:<br>\n3.6.2</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n9.0/7.0</li>\n<li><strong>GPU model and memory</strong>:<br>\nNVIDIA 1050 4 GB</li>\n</ul>\n<p>I trained a resnet with tf.estimator, the model was saved during the training process. The saved files consist of <code>.data</code>, <code>.index</code> and <code>.meta</code>. I'd like to load this model back and get predictions for new images. The data was fed to the model during training using <code>tf.data.Dataset</code>.  I have closely followed the resnet implementation given <a href=\"https://github.com/deepaksuresh/models/blob/master/official/resnet/resnet.py\">here</a>.</p>\n<p>I would like to restore the model and feed inputs to the nodes using a feed_dict.<br>\n<strong>My attempt</strong><br>\n#rebuild input pipeline<br>\nimages, labels = input_fn(data_dir, batch_size=32, num_epochs=1)</p>\n<pre><code>  #rebuild graph\n  prediction= imagenet_model_fn(images,labels,{'batch_size':32,'data_format':'channels_first','resnet_size':18},mode = tf.estimator.ModeKeys.EVAL).predictions \n\n  saver  = tf.train.Saver()\n  with tf.Session() as sess:\n    ckpt = tf.train.get_checkpoint_state(r'./model')\n    saver.restore(sess, ckpt.model_checkpoint_path)\n    while True:\n    try:\n        pred,im= sess.run([prediction,images])\n        print(pred)\n    except tf.errors.OutOfRangeError:\n      break\n</code></pre>\n<p>I fed a dataset which was evaluated on the same model using <code>classifier.evaluate</code>, but the above method gives wrong predictions. The model gives same class and probability, 1.0, for all images.</p>\n<p>The code I used for training and building the model is as below:</p>\n<p>Specification for parsing the dataset:</p>\n<pre><code>def parse_record(raw_record, is_training):\n  keys_to_features = {\n      'image/encoded':\n          tf.FixedLenFeature((), tf.string, default_value=''),\n      'image/class/label':\n          tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\n  }\n  parsed = tf.parse_single_example(raw_record, keys_to_features)\n  image = tf.image.decode_image(\n      tf.reshape(parsed['image/encoded'], shape=[]),3)\n  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n  label = tf.cast(\n      tf.reshape(parsed['image/class/label'], shape=[]),\n      dtype=tf.int32)\n  return image, tf.one_hot(label,2)\n</code></pre>\n<p>The following function parses the data and creates batches for training</p>\n<pre><code>def input_fn(is_training, data_dir, batch_size, num_epochs=1):\n  dataset = tf.data.Dataset.from_tensor_slices(\n      filenames(is_training, data_dir))\n  if is_training:\n     dataset = dataset.shuffle(buffer_size=_FILE_SHUFFLE_BUFFER)\n  dataset = dataset.flat_map(tf.data.TFRecordDataset)\n  dataset = dataset.map(lambda value: parse_record(value, is_training),\n                        num_parallel_calls=5)\n  dataset = dataset.prefetch(batch_size)\n  if is_training:\n      dataset = dataset.shuffle(buffer_size=_SHUFFLE_BUFFER)\n  dataset = dataset.repeat(num_epochs)\n  dataset = dataset.batch(batch_size)\n\n  iterator = dataset.make_one_shot_iterator()\n  images, labels = iterator.get_next()\n  return images, labels\n</code></pre>\n<p>A classifier is created as below for training on train set and evaluation on validation set</p>\n<pre><code>classifier = tf.estimator.Estimator(\n      model_fn=model_function, model_dir=flags.model_dir, config=run_config,\n      params={\n          'resnet_size': flags.resnet_size,\n          'data_format': flags.data_format,\n          'batch_size': flags.batch_size,\n      })\n\n    #Training cycle\n     classifier.train(\n         input_fn=lambda: input_function(\n             training_phase=True, flags.data_dir, flags.batch_size, flags.epochs_per_eval),\n         hooks=[logging_hook])\n    # Evaluate the model \n    eval_results = classifier.evaluate(input_fn=lambda: input_function(\n        training_phase=False, flags.data_dir, flags.batch_size))\n</code></pre>\n<p>This is how I tried to load and get predictions from the model.<br>\nI'd like to feed images through a <code>feed_dict</code> so that I can see the model's performance on individual images.<br>\nWhat is the right way to restore a saved model and perform inference on it. I want to feed images directly without using <code>tf.data.Dataset</code>.  I had opened a <a href=\"https://stackoverflow.com/questions/48679622/restoring-a-model-trained-with-tf-estimator-and-feeding-input-through-feed-dict\" rel=\"nofollow\">question </a>on stackoverflow, but didn't get any response. I'm wondering if there really is a feature that can help with restoring a model trained with <code>tf.estimator</code> and feeding images through a <code>feed_dict</code>.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nNo\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 10\nTensorFlow installed from (source or binary):\nbinary\nTensorFlow version (use command below):\n1.5\nPython version:\n3.6.2\nCUDA/cuDNN version:\n9.0/7.0\nGPU model and memory:\nNVIDIA 1050 4 GB\n\nI trained a resnet with tf.estimator, the model was saved during the training process. The saved files consist of .data, .index and .meta. I'd like to load this model back and get predictions for new images. The data was fed to the model during training using tf.data.Dataset.  I have closely followed the resnet implementation given here.\nI would like to restore the model and feed inputs to the nodes using a feed_dict.\nMy attempt\n#rebuild input pipeline\nimages, labels = input_fn(data_dir, batch_size=32, num_epochs=1)\n  #rebuild graph\n  prediction= imagenet_model_fn(images,labels,{'batch_size':32,'data_format':'channels_first','resnet_size':18},mode = tf.estimator.ModeKeys.EVAL).predictions \n\n  saver  = tf.train.Saver()\n  with tf.Session() as sess:\n    ckpt = tf.train.get_checkpoint_state(r'./model')\n    saver.restore(sess, ckpt.model_checkpoint_path)\n    while True:\n    try:\n        pred,im= sess.run([prediction,images])\n        print(pred)\n    except tf.errors.OutOfRangeError:\n      break\n\nI fed a dataset which was evaluated on the same model using classifier.evaluate, but the above method gives wrong predictions. The model gives same class and probability, 1.0, for all images.\nThe code I used for training and building the model is as below:\nSpecification for parsing the dataset:\ndef parse_record(raw_record, is_training):\n  keys_to_features = {\n      'image/encoded':\n          tf.FixedLenFeature((), tf.string, default_value=''),\n      'image/class/label':\n          tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\n  }\n  parsed = tf.parse_single_example(raw_record, keys_to_features)\n  image = tf.image.decode_image(\n      tf.reshape(parsed['image/encoded'], shape=[]),3)\n  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n  label = tf.cast(\n      tf.reshape(parsed['image/class/label'], shape=[]),\n      dtype=tf.int32)\n  return image, tf.one_hot(label,2)\n\nThe following function parses the data and creates batches for training\ndef input_fn(is_training, data_dir, batch_size, num_epochs=1):\n  dataset = tf.data.Dataset.from_tensor_slices(\n      filenames(is_training, data_dir))\n  if is_training:\n     dataset = dataset.shuffle(buffer_size=_FILE_SHUFFLE_BUFFER)\n  dataset = dataset.flat_map(tf.data.TFRecordDataset)\n  dataset = dataset.map(lambda value: parse_record(value, is_training),\n                        num_parallel_calls=5)\n  dataset = dataset.prefetch(batch_size)\n  if is_training:\n      dataset = dataset.shuffle(buffer_size=_SHUFFLE_BUFFER)\n  dataset = dataset.repeat(num_epochs)\n  dataset = dataset.batch(batch_size)\n\n  iterator = dataset.make_one_shot_iterator()\n  images, labels = iterator.get_next()\n  return images, labels\n\nA classifier is created as below for training on train set and evaluation on validation set\nclassifier = tf.estimator.Estimator(\n      model_fn=model_function, model_dir=flags.model_dir, config=run_config,\n      params={\n          'resnet_size': flags.resnet_size,\n          'data_format': flags.data_format,\n          'batch_size': flags.batch_size,\n      })\n\n    #Training cycle\n     classifier.train(\n         input_fn=lambda: input_function(\n             training_phase=True, flags.data_dir, flags.batch_size, flags.epochs_per_eval),\n         hooks=[logging_hook])\n    # Evaluate the model \n    eval_results = classifier.evaluate(input_fn=lambda: input_function(\n        training_phase=False, flags.data_dir, flags.batch_size))\n\nThis is how I tried to load and get predictions from the model.\nI'd like to feed images through a feed_dict so that I can see the model's performance on individual images.\nWhat is the right way to restore a saved model and perform inference on it. I want to feed images directly without using tf.data.Dataset.  I had opened a question on stackoverflow, but didn't get any response. I'm wondering if there really is a feature that can help with restoring a model trained with tf.estimator and feeding images through a feed_dict.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.5\r\n- **Python version**: \r\n3.6.2\r\n- **CUDA/cuDNN version**:\r\n9.0/7.0\r\n- **GPU model and memory**:\r\nNVIDIA 1050 4 GB\r\n\r\nI trained a resnet with tf.estimator, the model was saved during the training process. The saved files consist of `.data`, `.index` and `.meta`. I'd like to load this model back and get predictions for new images. The data was fed to the model during training using `tf.data.Dataset`.  I have closely followed the resnet implementation given [here][1].\r\n\r\nI would like to restore the model and feed inputs to the nodes using a feed_dict. \r\n**My attempt**\r\n      #rebuild input pipeline\r\n      images, labels = input_fn(data_dir, batch_size=32, num_epochs=1)\r\n        \r\n      #rebuild graph\r\n      prediction= imagenet_model_fn(images,labels,{'batch_size':32,'data_format':'channels_first','resnet_size':18},mode = tf.estimator.ModeKeys.EVAL).predictions \r\n    \r\n      saver  = tf.train.Saver()\r\n      with tf.Session() as sess:\r\n        ckpt = tf.train.get_checkpoint_state(r'./model')\r\n        saver.restore(sess, ckpt.model_checkpoint_path)\r\n        while True:\r\n        try:\r\n            pred,im= sess.run([prediction,images])\r\n            print(pred)\r\n        except tf.errors.OutOfRangeError:\r\n          break\r\n\r\nI fed a dataset which was evaluated on the same model using `classifier.evaluate`, but the above method gives wrong predictions. The model gives same class and probability, 1.0, for all images.\r\n\r\nThe code I used for training and building the model is as below:\r\n\r\nSpecification for parsing the dataset:\r\n\r\n    def parse_record(raw_record, is_training):\r\n      keys_to_features = {\r\n          'image/encoded':\r\n              tf.FixedLenFeature((), tf.string, default_value=''),\r\n          'image/class/label':\r\n              tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\r\n      }\r\n      parsed = tf.parse_single_example(raw_record, keys_to_features)\r\n      image = tf.image.decode_image(\r\n          tf.reshape(parsed['image/encoded'], shape=[]),3)\r\n      image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n      label = tf.cast(\r\n          tf.reshape(parsed['image/class/label'], shape=[]),\r\n          dtype=tf.int32)\r\n      return image, tf.one_hot(label,2)\r\n\r\nThe following function parses the data and creates batches for training\r\n\r\n    def input_fn(is_training, data_dir, batch_size, num_epochs=1):\r\n      dataset = tf.data.Dataset.from_tensor_slices(\r\n          filenames(is_training, data_dir))\r\n      if is_training:\r\n         dataset = dataset.shuffle(buffer_size=_FILE_SHUFFLE_BUFFER)\r\n      dataset = dataset.flat_map(tf.data.TFRecordDataset)\r\n      dataset = dataset.map(lambda value: parse_record(value, is_training),\r\n                            num_parallel_calls=5)\r\n      dataset = dataset.prefetch(batch_size)\r\n      if is_training:\r\n          dataset = dataset.shuffle(buffer_size=_SHUFFLE_BUFFER)\r\n      dataset = dataset.repeat(num_epochs)\r\n      dataset = dataset.batch(batch_size)\r\n    \r\n      iterator = dataset.make_one_shot_iterator()\r\n      images, labels = iterator.get_next()\r\n      return images, labels\r\n\r\nA classifier is created as below for training on train set and evaluation on validation set\r\n\r\n    classifier = tf.estimator.Estimator(\r\n          model_fn=model_function, model_dir=flags.model_dir, config=run_config,\r\n          params={\r\n              'resnet_size': flags.resnet_size,\r\n              'data_format': flags.data_format,\r\n              'batch_size': flags.batch_size,\r\n          })\r\n    \r\n        #Training cycle\r\n         classifier.train(\r\n             input_fn=lambda: input_function(\r\n                 training_phase=True, flags.data_dir, flags.batch_size, flags.epochs_per_eval),\r\n             hooks=[logging_hook])\r\n        # Evaluate the model \r\n        eval_results = classifier.evaluate(input_fn=lambda: input_function(\r\n            training_phase=False, flags.data_dir, flags.batch_size))\r\n\r\nThis is how I tried to load and get predictions from the model.\r\nI'd like to feed images through a `feed_dict` so that I can see the model's performance on individual images.\r\nWhat is the right way to restore a saved model and perform inference on it. I want to feed images directly without using `tf.data.Dataset`.  I had opened a [question ](https://stackoverflow.com/questions/48679622/restoring-a-model-trained-with-tf-estimator-and-feeding-input-through-feed-dict)on stackoverflow, but didn't get any response. I'm wondering if there really is a feature that can help with restoring a model trained with `tf.estimator` and feeding images through a `feed_dict`. \r\n\r\n\r\n  [1]: https://github.com/deepaksuresh/models/blob/master/official/resnet/resnet.py\r\n\r\n"}