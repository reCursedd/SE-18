{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/170221530", "pull_request_review_id": 98873982, "id": 170221530, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MDIyMTUzMA==", "diff_hunk": "@@ -47,6 +48,38 @@ Status SoftmaxGrad(const Scope& scope, const Operation& op,\n }\n REGISTER_GRADIENT_OP(\"Softmax\", SoftmaxGrad);\n \n+Status SoftmaxCrossEntropyWithLogitsGrad(const Scope& scope,\n+                                          const Operation& op,\n+                                          const std::vector<Output>&\n+                                          grad_inputs,\n+                                          std::vector<Output>* grad_outputs) {\n+  // Softmax gradient with cross entropy logits function\n+  // We multiply the backprop for cost with the gradients - op.output[1]\n+  // There is no gradient for labels\n+\n+  auto softmaxGrad = op.output(1);\n+  auto gradLoss = grad_inputs[0];\n+  auto gradGrad = grad_inputs[1];\n+\n+  auto tempGrad = Mul(scope, gradLoss, softmaxGrad);\n+\n+  // TODO: Check if this sufficient, need a check for null ?\n+  if (gradGrad.op().output_type(0) != 0) {\n+\t  auto logits = op.input(0);\n+\t  auto softmax = ops::Softmax(scope, logits);\n+\t  auto prod = ops::MatMul(scope, gradGrad, softmax);", "path": "tensorflow/cc/gradients/nn_grad.cc", "position": null, "original_position": 31, "commit_id": "4d98d2b592b7990968be33e10064d06ca35f40c9", "original_commit_id": "ace35ecca311c15724584b80b2cf0a35cbfd7eb6", "user": {"login": "nietras", "id": 10798831, "node_id": "MDQ6VXNlcjEwNzk4ODMx", "avatar_url": "https://avatars1.githubusercontent.com/u/10798831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nietras", "html_url": "https://github.com/nietras", "followers_url": "https://api.github.com/users/nietras/followers", "following_url": "https://api.github.com/users/nietras/following{/other_user}", "gists_url": "https://api.github.com/users/nietras/gists{/gist_id}", "starred_url": "https://api.github.com/users/nietras/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nietras/subscriptions", "organizations_url": "https://api.github.com/users/nietras/orgs", "repos_url": "https://api.github.com/users/nietras/repos", "events_url": "https://api.github.com/users/nietras/events{/privacy}", "received_events_url": "https://api.github.com/users/nietras/received_events", "type": "User", "site_admin": false}, "body": "In python `MatMul` is:\r\n```python\r\nmath_ops.matmul(grad_grad[:, None, :],\r\n                        softmax[:, :, None]), axis=1)\r\n```\r\nwhich I am not sure why it does? What is the effect of this? ", "created_at": "2018-02-23T10:49:50Z", "updated_at": "2018-07-12T20:46:25Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/14727#discussion_r170221530", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14727", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/170221530"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/14727#discussion_r170221530"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14727"}}, "body_html": "<p>In python <code>MatMul</code> is:</p>\n<div class=\"highlight highlight-source-python\"><pre>math_ops.matmul(grad_grad[:, <span class=\"pl-c1\">None</span>, :],\n                        softmax[:, :, <span class=\"pl-c1\">None</span>]), axis<span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)</pre></div>\n<p>which I am not sure why it does? What is the effect of this?</p>", "body_text": "In python MatMul is:\nmath_ops.matmul(grad_grad[:, None, :],\n                        softmax[:, :, None]), axis=1)\nwhich I am not sure why it does? What is the effect of this?"}