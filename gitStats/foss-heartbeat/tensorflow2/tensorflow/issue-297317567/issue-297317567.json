{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17028", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17028/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17028/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17028/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17028", "id": 297317567, "node_id": "MDU6SXNzdWUyOTczMTc1Njc=", "number": 17028, "title": "MLP prediction is 3~4x slower than theano/pytorch", "user": {"login": "JiaweiZhuang", "id": 25473287, "node_id": "MDQ6VXNlcjI1NDczMjg3", "avatar_url": "https://avatars1.githubusercontent.com/u/25473287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JiaweiZhuang", "html_url": "https://github.com/JiaweiZhuang", "followers_url": "https://api.github.com/users/JiaweiZhuang/followers", "following_url": "https://api.github.com/users/JiaweiZhuang/following{/other_user}", "gists_url": "https://api.github.com/users/JiaweiZhuang/gists{/gist_id}", "starred_url": "https://api.github.com/users/JiaweiZhuang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JiaweiZhuang/subscriptions", "organizations_url": "https://api.github.com/users/JiaweiZhuang/orgs", "repos_url": "https://api.github.com/users/JiaweiZhuang/repos", "events_url": "https://api.github.com/users/JiaweiZhuang/events{/privacy}", "received_events_url": "https://api.github.com/users/JiaweiZhuang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-02-15T03:12:21Z", "updated_at": "2018-02-19T20:56:33Z", "closed_at": "2018-02-19T20:56:33Z", "author_association": "NONE", "body_html": "<p>(Moving from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"297174086\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/keras-team/keras/issues/9388\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/9388/hovercard\" href=\"https://github.com/keras-team/keras/issues/9388\">keras-team/keras#9388</a>)<br>\nFor a simple 2-hidden-layer MLP, TF is 3~4x slower than pytorch and theano. This is only for <strong>prediction</strong>, not training, and it is only on <strong>CPU</strong>. Please see this <a href=\"https://gist.github.com/JiaweiZhuang/c3350f7a89db3d5a98c6a2c0228ceea9/eb4eec9056b02b1ac2e0e039f646347c02885309\">GitHub gist</a> for timing.</p>\n<p>For reproducibility, the test was done on AWS EC2 c5.large. Two different builds were tested and showed similar results. One is the pre-built <a href=\"https://aws.amazon.com/machine-learning/amis/\" rel=\"nofollow\">AWS deep learning AMI</a> (ami-e07e779a). Another is installing conda on a fresh Ubuntu machine and then installing TF with <code>pip</code>.</p>\n<p>My questions are:</p>\n<ol>\n<li>Is this performance difference expected? I assume that TF shouldn't be that slow.</li>\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a> suggested that the TF installation was broken. If so, what's the correct way to install TensorFlow to ensure good performance? I also tried <a href=\"https://www.tensorflow.org/install/install_linux\" rel=\"nofollow\">other installation methods on the official docs</a>, as such native Python and pip, but didn't get better performance.</li>\n</ol>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>: Almost all built-in functions</li>\n<li><strong>OS Platform and Distribution</strong>: Linux Ubuntu 16.04<br>\nTest env 1: AWS deep learning AMI Ubuntu Version (ami-e07e779a)<br>\nTest env 2: AWS base Ubuntu AMI (ami-66506c1c)</li>\n<li><strong>TensorFlow installed from</strong>:<br>\nTest env 1: TensorFlow/Keras/PyTorch are all provided by that AMI.<br>\nTest env 2: Installed from binary, i.e. <code>pip install tensorflow</code> and <code>pip install keras</code>. PyTorch was installed by <code>conda install pytorch</code>.</li>\n<li><strong>TensorFlow version</strong>: 1.5.0</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version</strong>: N/A (from binary)</li>\n<li><strong>CUDA/cuDNN version</strong>: CPU-only</li>\n<li><strong>GPU model and memory</strong>: CPU-only</li>\n<li><strong>Exact command to reproduce</strong>: Please follow this <a href=\"https://gist.github.com/JiaweiZhuang/c3350f7a89db3d5a98c6a2c0228ceea9/eb4eec9056b02b1ac2e0e039f646347c02885309\">GitHub gist</a>.</li>\n</ul>", "body_text": "(Moving from keras-team/keras#9388)\nFor a simple 2-hidden-layer MLP, TF is 3~4x slower than pytorch and theano. This is only for prediction, not training, and it is only on CPU. Please see this GitHub gist for timing.\nFor reproducibility, the test was done on AWS EC2 c5.large. Two different builds were tested and showed similar results. One is the pre-built AWS deep learning AMI (ami-e07e779a). Another is installing conda on a fresh Ubuntu machine and then installing TF with pip.\nMy questions are:\n\nIs this performance difference expected? I assume that TF shouldn't be that slow.\n@fchollet suggested that the TF installation was broken. If so, what's the correct way to install TensorFlow to ensure good performance? I also tried other installation methods on the official docs, as such native Python and pip, but didn't get better performance.\n\nSystem information\n\nHave I written custom code: Almost all built-in functions\nOS Platform and Distribution: Linux Ubuntu 16.04\nTest env 1: AWS deep learning AMI Ubuntu Version (ami-e07e779a)\nTest env 2: AWS base Ubuntu AMI (ami-66506c1c)\nTensorFlow installed from:\nTest env 1: TensorFlow/Keras/PyTorch are all provided by that AMI.\nTest env 2: Installed from binary, i.e. pip install tensorflow and pip install keras. PyTorch was installed by conda install pytorch.\nTensorFlow version: 1.5.0\nPython version: 3.6\nBazel version: N/A (from binary)\nCUDA/cuDNN version: CPU-only\nGPU model and memory: CPU-only\nExact command to reproduce: Please follow this GitHub gist.", "body": "(Moving from keras-team/keras#9388)\r\nFor a simple 2-hidden-layer MLP, TF is 3~4x slower than pytorch and theano. This is only for **prediction**, not training, and it is only on **CPU**. Please see this [GitHub gist](https://gist.github.com/JiaweiZhuang/c3350f7a89db3d5a98c6a2c0228ceea9/eb4eec9056b02b1ac2e0e039f646347c02885309) for timing.\r\n\r\nFor reproducibility, the test was done on AWS EC2 c5.large. Two different builds were tested and showed similar results. One is the pre-built [AWS deep learning AMI](https://aws.amazon.com/machine-learning/amis/) (ami-e07e779a). Another is installing conda on a fresh Ubuntu machine and then installing TF with `pip`.\r\n\r\nMy questions are:\r\n1. Is this performance difference expected? I assume that TF shouldn't be that slow. \r\n2. @fchollet suggested that the TF installation was broken. If so, what's the correct way to install TensorFlow to ensure good performance? I also tried [other installation methods on the official docs](https://www.tensorflow.org/install/install_linux), as such native Python and pip, but didn't get better performance.\r\n\r\n### System information\r\n- **Have I written custom code**: Almost all built-in functions\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04 \r\nTest env 1: AWS deep learning AMI Ubuntu Version (ami-e07e779a)\r\nTest env 2: AWS base Ubuntu AMI (ami-66506c1c)\r\n- **TensorFlow installed from**: \r\nTest env 1: TensorFlow/Keras/PyTorch are all provided by that AMI.\r\nTest env 2: Installed from binary, i.e. `pip install tensorflow` and `pip install keras`. PyTorch was installed by `conda install pytorch`.\r\n- **TensorFlow version**: 1.5.0\r\n- **Python version**: 3.6\r\n- **Bazel version**: N/A (from binary)\r\n- **CUDA/cuDNN version**: CPU-only\r\n- **GPU model and memory**: CPU-only\r\n- **Exact command to reproduce**: Please follow this [GitHub gist](https://gist.github.com/JiaweiZhuang/c3350f7a89db3d5a98c6a2c0228ceea9/eb4eec9056b02b1ac2e0e039f646347c02885309)."}