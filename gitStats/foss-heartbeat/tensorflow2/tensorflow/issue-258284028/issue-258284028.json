{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13095", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13095/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13095/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13095/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13095", "id": 258284028, "node_id": "MDU6SXNzdWUyNTgyODQwMjg=", "number": 13095, "title": "About the issue: Ran out of GPU memory!", "user": {"login": "segatecm", "id": 6448025, "node_id": "MDQ6VXNlcjY0NDgwMjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6448025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/segatecm", "html_url": "https://github.com/segatecm", "followers_url": "https://api.github.com/users/segatecm/followers", "following_url": "https://api.github.com/users/segatecm/following{/other_user}", "gists_url": "https://api.github.com/users/segatecm/gists{/gist_id}", "starred_url": "https://api.github.com/users/segatecm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/segatecm/subscriptions", "organizations_url": "https://api.github.com/users/segatecm/orgs", "repos_url": "https://api.github.com/users/segatecm/repos", "events_url": "https://api.github.com/users/segatecm/events{/privacy}", "received_events_url": "https://api.github.com/users/segatecm/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-17T06:50:45Z", "updated_at": "2017-09-19T13:54:46Z", "closed_at": "2017-09-17T17:49:15Z", "author_association": "NONE", "body_html": "<p>HI every one, I wrote my first tensorflow code, it is a classic CNN. And when I run it on Ubuntu16. it report error!</p>\n<p>2017-09-17 05:16:34.243946: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-09-17 05:16:34.243983: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-09-17 05:16:34.244007: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-09-17 05:16:34.244017: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-09-17 05:16:34.244023: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-09-17 05:16:35.679378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:<br>\nname: Tesla P100-SXM2-16GB<br>\nmajor: 6 minor: 0 memoryClockRate (GHz) 1.4805<br>\npciBusID 0000:89:00.0<br>\nTotal memory: 15.89GiB<br>\nFree memory: 15.61GiB<br>\n2017-09-17 05:16:36.490317: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xab5bff0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.<br>\n2017-09-17 05:16:36.492491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:<br>\nname: Tesla P100-SXM2-16GB<br>\nmajor: 6 minor: 0 memoryClockRate (GHz) 1.4805<br>\npciBusID 0000:8a:00.0<br>\nTotal memory: 15.89GiB<br>\nFree memory: 15.61GiB<br>\n2017-09-17 05:16:36.496233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1<br>\n2017-09-17 05:16:36.496258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y<br>\n2017-09-17 05:16:36.496267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y<br>\n2017-09-17 05:16:36.496282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:89:00.0)<br>\n2017-09-17 05:16:36.496353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:8a:00.0)<br>\nstep 0, train accuracy 0<br>\nstep 100, train accuracy 0.845555<br>\nstep 200, train accuracy 0.80391<br>\nstep 300, train accuracy 0.913599<br>\nstep 400, train accuracy 0.893777<br>\nstep 500, train accuracy 0.918844<br>\nstep 600, train accuracy 0.937555<br>\n2017-09-17 05:16:41.502931: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes<br>\n2017-09-17 05:16:41.503008: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes<br>\n2017-09-17 05:16:41.503035: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes<br>\n2017-09-17 05:16:41.503060: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes<br>\n2017-09-17 05:16:41.503223: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr<br>\n2017-09-17 05:16:41.503268: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr<br>\nTraceback (most recent call last):<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1327, in _do_call<br>\nreturn fn(*args)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1306, in _run_fn<br>\nstatus, run_metadata)<br>\nFile \"/usr/lib/python3.5/contextlib.py\", line 66, in <strong>exit</strong><br>\nnext(self.gen)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status<br>\npywrap_tensorflow.TF_GetCode(status))<br>\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Ran out of GPU memory when allocating 0 bytes for<br>\n[[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"check_cnn.py\", line 228, in <br>\nTrainNetwork()<br>\nFile \"check_cnn.py\", line 147, in TrainNetwork<br>\nsess.run(train_step, feed_dict = {x: xs, y_: ys, keep_prob: 0.5})<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 895, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run<br>\nfeed_dict_tensor, options, run_metadata)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run<br>\noptions, run_metadata)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1340, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Ran out of GPU memory when allocating 0 bytes for<br>\n[[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]</p>\n<p>Caused by op 'SoftmaxCrossEntropyWithLogits', defined at:<br>\nFile \"check_cnn.py\", line 228, in <br>\nTrainNetwork()<br>\nFile \"check_cnn.py\", line 128, in TrainNetwork<br>\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = Ylogits, labels = y_)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1597, in softmax_cross_entropy_with_logits<br>\nprecise_logits, labels, name=name)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2385, in _softmax_cross_entropy_with_logits<br>\nfeatures=features, labels=labels, name=name)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in <strong>init</strong><br>\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access</p>\n<p>ResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 0 bytes for<br>\n[[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]</p>\n<p>The system is ubuntu16, tensorflow 1.2, CUDA 8, cudnn 6.<br>\nthe machine is:</p>\n<p>Sun Sep 17 06:30:45 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Tesla P100-SXM2...  On   | 0000:89:00.0     Off |                    0 |<br>\n| N/A   39C    P0    34W / 300W |      0MiB / 16276MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  Tesla P100-SXM2...  On   | 0000:8A:00.0     Off |                    0 |<br>\n| N/A   38C    P0    32W / 300W |      0MiB / 16276MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID  Type  Process name                               Usage      |<br>\n|=============================================================================|<br>\n|  No running processes found                                                 |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>So please help me for this, thanks!</p>", "body_text": "HI every one, I wrote my first tensorflow code, it is a classic CNN. And when I run it on Ubuntu16. it report error!\n2017-09-17 05:16:34.243946: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-17 05:16:34.243983: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-17 05:16:34.244007: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-17 05:16:34.244017: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-17 05:16:34.244023: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-17 05:16:35.679378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\nname: Tesla P100-SXM2-16GB\nmajor: 6 minor: 0 memoryClockRate (GHz) 1.4805\npciBusID 0000:89:00.0\nTotal memory: 15.89GiB\nFree memory: 15.61GiB\n2017-09-17 05:16:36.490317: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xab5bff0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n2017-09-17 05:16:36.492491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:\nname: Tesla P100-SXM2-16GB\nmajor: 6 minor: 0 memoryClockRate (GHz) 1.4805\npciBusID 0000:8a:00.0\nTotal memory: 15.89GiB\nFree memory: 15.61GiB\n2017-09-17 05:16:36.496233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1\n2017-09-17 05:16:36.496258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y\n2017-09-17 05:16:36.496267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y\n2017-09-17 05:16:36.496282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:89:00.0)\n2017-09-17 05:16:36.496353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:8a:00.0)\nstep 0, train accuracy 0\nstep 100, train accuracy 0.845555\nstep 200, train accuracy 0.80391\nstep 300, train accuracy 0.913599\nstep 400, train accuracy 0.893777\nstep 500, train accuracy 0.918844\nstep 600, train accuracy 0.937555\n2017-09-17 05:16:41.502931: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\n2017-09-17 05:16:41.503008: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n2017-09-17 05:16:41.503035: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\n2017-09-17 05:16:41.503060: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n2017-09-17 05:16:41.503223: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\n2017-09-17 05:16:41.503268: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\nTraceback (most recent call last):\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\nreturn fn(*args)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1306, in _run_fn\nstatus, run_metadata)\nFile \"/usr/lib/python3.5/contextlib.py\", line 66, in exit\nnext(self.gen)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\npywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Ran out of GPU memory when allocating 0 bytes for\n[[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"check_cnn.py\", line 228, in \nTrainNetwork()\nFile \"check_cnn.py\", line 147, in TrainNetwork\nsess.run(train_step, feed_dict = {x: xs, y_: ys, keep_prob: 0.5})\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 895, in run\nrun_metadata_ptr)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run\nfeed_dict_tensor, options, run_metadata)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\noptions, run_metadata)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Ran out of GPU memory when allocating 0 bytes for\n[[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]\nCaused by op 'SoftmaxCrossEntropyWithLogits', defined at:\nFile \"check_cnn.py\", line 228, in \nTrainNetwork()\nFile \"check_cnn.py\", line 128, in TrainNetwork\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = Ylogits, labels = y_)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1597, in softmax_cross_entropy_with_logits\nprecise_logits, labels, name=name)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2385, in _softmax_cross_entropy_with_logits\nfeatures=features, labels=labels, name=name)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\nop_def=op_def)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in init\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 0 bytes for\n[[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]\nThe system is ubuntu16, tensorflow 1.2, CUDA 8, cudnn 6.\nthe machine is:\nSun Sep 17 06:30:45 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla P100-SXM2...  On   | 0000:89:00.0     Off |                    0 |\n| N/A   39C    P0    34W / 300W |      0MiB / 16276MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla P100-SXM2...  On   | 0000:8A:00.0     Off |                    0 |\n| N/A   38C    P0    32W / 300W |      0MiB / 16276MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\nSo please help me for this, thanks!", "body": "HI every one, I wrote my first tensorflow code, it is a classic CNN. And when I run it on Ubuntu16. it report error!\r\n\r\n2017-09-17 05:16:34.243946: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-17 05:16:34.243983: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-17 05:16:34.244007: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-17 05:16:34.244017: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-17 05:16:34.244023: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-17 05:16:35.679378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \r\nname: Tesla P100-SXM2-16GB\r\nmajor: 6 minor: 0 memoryClockRate (GHz) 1.4805\r\npciBusID 0000:89:00.0\r\nTotal memory: 15.89GiB\r\nFree memory: 15.61GiB\r\n2017-09-17 05:16:36.490317: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xab5bff0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\r\n2017-09-17 05:16:36.492491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: \r\nname: Tesla P100-SXM2-16GB\r\nmajor: 6 minor: 0 memoryClockRate (GHz) 1.4805\r\npciBusID 0000:8a:00.0\r\nTotal memory: 15.89GiB\r\nFree memory: 15.61GiB\r\n2017-09-17 05:16:36.496233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 \r\n2017-09-17 05:16:36.496258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y \r\n2017-09-17 05:16:36.496267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y \r\n2017-09-17 05:16:36.496282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:89:00.0)\r\n2017-09-17 05:16:36.496353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:8a:00.0)\r\nstep 0, train accuracy 0\r\nstep 100, train accuracy 0.845555\r\nstep 200, train accuracy 0.80391\r\nstep 300, train accuracy 0.913599\r\nstep 400, train accuracy 0.893777\r\nstep 500, train accuracy 0.918844\r\nstep 600, train accuracy 0.937555\r\n2017-09-17 05:16:41.502931: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\r\n2017-09-17 05:16:41.503008: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2017-09-17 05:16:41.503035: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\r\n2017-09-17 05:16:41.503060: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2017-09-17 05:16:41.503223: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\r\n2017-09-17 05:16:41.503268: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1306, in _run_fn\r\n    status, run_metadata)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Ran out of GPU memory when allocating 0 bytes for \r\n\t [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"check_cnn.py\", line 228, in <module>\r\n    TrainNetwork()\r\n  File \"check_cnn.py\", line 147, in TrainNetwork\r\n    sess.run(train_step, feed_dict = {x: xs, y_: ys, keep_prob: 0.5})\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Ran out of GPU memory when allocating 0 bytes for \r\n\t [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]\r\n\r\nCaused by op 'SoftmaxCrossEntropyWithLogits', defined at:\r\n  File \"check_cnn.py\", line 228, in <module>\r\n    TrainNetwork()\r\n  File \"check_cnn.py\", line 128, in TrainNetwork\r\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = Ylogits, labels = y_)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1597, in softmax_cross_entropy_with_logits\r\n    precise_logits, labels, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2385, in _softmax_cross_entropy_with_logits\r\n    features=features, labels=labels, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): Ran out of GPU memory when allocating 0 bytes for \r\n\t [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape_2, Reshape_3)]]\r\n\r\nThe system is ubuntu16, tensorflow 1.2, CUDA 8, cudnn 6.\r\nthe machine is:\r\n\r\nSun Sep 17 06:30:45 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla P100-SXM2...  On   | 0000:89:00.0     Off |                    0 |\r\n| N/A   39C    P0    34W / 300W |      0MiB / 16276MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla P100-SXM2...  On   | 0000:8A:00.0     Off |                    0 |\r\n| N/A   38C    P0    32W / 300W |      0MiB / 16276MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\nSo please help me for this, thanks!"}