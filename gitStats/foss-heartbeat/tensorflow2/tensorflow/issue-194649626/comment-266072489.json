{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/266072489", "html_url": "https://github.com/tensorflow/tensorflow/issues/6216#issuecomment-266072489", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6216", "id": 266072489, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NjA3MjQ4OQ==", "user": {"login": "ericyue", "id": 918889, "node_id": "MDQ6VXNlcjkxODg4OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/918889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ericyue", "html_url": "https://github.com/ericyue", "followers_url": "https://api.github.com/users/ericyue/followers", "following_url": "https://api.github.com/users/ericyue/following{/other_user}", "gists_url": "https://api.github.com/users/ericyue/gists{/gist_id}", "starred_url": "https://api.github.com/users/ericyue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ericyue/subscriptions", "organizations_url": "https://api.github.com/users/ericyue/orgs", "repos_url": "https://api.github.com/users/ericyue/repos", "events_url": "https://api.github.com/users/ericyue/events{/privacy}", "received_events_url": "https://api.github.com/users/ericyue/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-09T17:31:52Z", "updated_at": "2016-12-09T17:32:21Z", "author_association": "NONE", "body_html": "<p>thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a>  .  I recently submit a lot issue to tensorflow , many of them replied \"ask on stackoverflow\", but currently,  a question about tensorflow in the stackoverflow barely be answered :( , so .....</p>\n<p>where to find some docs about the inner process about distributed tensorflow? I have read the tutorial , but not help.</p>\n<p>the example a provide is not the current version in my code. I updated</p>\n<pre><code>    with sv.managed_session(server.target) as sess:\n\n        if mode == \"train\" or mode == \"train_from_scratch\":\n\n            while not sv.should_stop():\n                # Get coordinator and run queues to read data\n                coord = tf.train.Coordinator()\n                threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n\n                start_time = datetime.datetime.now()\n\n                try:\n                    while not coord.should_stop():\n                        _, loss_value, step = sess.run([train_op, loss, global_step])\n                        if step % steps_to_validate == 0:\n                            accuracy_value, auc_value, summary_value = sess.run(\n                                [accuracy, auc_op, summary_op])\n                            end_time = datetime.datetime.now()\n                            print(\"[{}] Task: {}, Step: {}, loss: {}, accuracy: {}, auc: {}\".format(\n                                end_time - start_time,\n                                FLAGS.task_index,\n                                step, loss_value, accuracy_value,\n                                auc_value))\n\n                            #if FLAGS.task_index == 0:\n                            #  writer.add_summary(summary_value, step)\n                            #  saver.save(sess, checkpoint_file, global_step=step)\n                            start_time = end_time\n                except tf.errors.OutOfRangeError:\n                    print(\"Done training after reading all data\")\n                finally:\n                    coord.request_stop()\n                    print(\"coord stopped\")\n\n                # Wait for threads to exit\n                coord.join(threads)\n</code></pre>", "body_text": "thanks @yaroslavvb  .  I recently submit a lot issue to tensorflow , many of them replied \"ask on stackoverflow\", but currently,  a question about tensorflow in the stackoverflow barely be answered :( , so .....\nwhere to find some docs about the inner process about distributed tensorflow? I have read the tutorial , but not help.\nthe example a provide is not the current version in my code. I updated\n    with sv.managed_session(server.target) as sess:\n\n        if mode == \"train\" or mode == \"train_from_scratch\":\n\n            while not sv.should_stop():\n                # Get coordinator and run queues to read data\n                coord = tf.train.Coordinator()\n                threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n\n                start_time = datetime.datetime.now()\n\n                try:\n                    while not coord.should_stop():\n                        _, loss_value, step = sess.run([train_op, loss, global_step])\n                        if step % steps_to_validate == 0:\n                            accuracy_value, auc_value, summary_value = sess.run(\n                                [accuracy, auc_op, summary_op])\n                            end_time = datetime.datetime.now()\n                            print(\"[{}] Task: {}, Step: {}, loss: {}, accuracy: {}, auc: {}\".format(\n                                end_time - start_time,\n                                FLAGS.task_index,\n                                step, loss_value, accuracy_value,\n                                auc_value))\n\n                            #if FLAGS.task_index == 0:\n                            #  writer.add_summary(summary_value, step)\n                            #  saver.save(sess, checkpoint_file, global_step=step)\n                            start_time = end_time\n                except tf.errors.OutOfRangeError:\n                    print(\"Done training after reading all data\")\n                finally:\n                    coord.request_stop()\n                    print(\"coord stopped\")\n\n                # Wait for threads to exit\n                coord.join(threads)", "body": "thanks @yaroslavvb  .  I recently submit a lot issue to tensorflow , many of them replied \"ask on stackoverflow\", but currently,  a question about tensorflow in the stackoverflow barely be answered :( , so .....\r\n\r\nwhere to find some docs about the inner process about distributed tensorflow? I have read the tutorial , but not help.\r\n\r\nthe example a provide is not the current version in my code. I updated \r\n```\r\n    with sv.managed_session(server.target) as sess:\r\n\r\n        if mode == \"train\" or mode == \"train_from_scratch\":\r\n\r\n            while not sv.should_stop():\r\n                # Get coordinator and run queues to read data\r\n                coord = tf.train.Coordinator()\r\n                threads = tf.train.start_queue_runners(coord=coord, sess=sess)\r\n\r\n                start_time = datetime.datetime.now()\r\n\r\n                try:\r\n                    while not coord.should_stop():\r\n                        _, loss_value, step = sess.run([train_op, loss, global_step])\r\n                        if step % steps_to_validate == 0:\r\n                            accuracy_value, auc_value, summary_value = sess.run(\r\n                                [accuracy, auc_op, summary_op])\r\n                            end_time = datetime.datetime.now()\r\n                            print(\"[{}] Task: {}, Step: {}, loss: {}, accuracy: {}, auc: {}\".format(\r\n                                end_time - start_time,\r\n                                FLAGS.task_index,\r\n                                step, loss_value, accuracy_value,\r\n                                auc_value))\r\n\r\n                            #if FLAGS.task_index == 0:\r\n                            #  writer.add_summary(summary_value, step)\r\n                            #  saver.save(sess, checkpoint_file, global_step=step)\r\n                            start_time = end_time\r\n                except tf.errors.OutOfRangeError:\r\n                    print(\"Done training after reading all data\")\r\n                finally:\r\n                    coord.request_stop()\r\n                    print(\"coord stopped\")\r\n\r\n                # Wait for threads to exit\r\n                coord.join(threads)\r\n```"}