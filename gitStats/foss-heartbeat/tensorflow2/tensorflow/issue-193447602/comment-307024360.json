{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/307024360", "html_url": "https://github.com/tensorflow/tensorflow/issues/6084#issuecomment-307024360", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6084", "id": 307024360, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzAyNDM2MA==", "user": {"login": "aihamtaleb", "id": 5914133, "node_id": "MDQ6VXNlcjU5MTQxMzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5914133?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aihamtaleb", "html_url": "https://github.com/aihamtaleb", "followers_url": "https://api.github.com/users/aihamtaleb/followers", "following_url": "https://api.github.com/users/aihamtaleb/following{/other_user}", "gists_url": "https://api.github.com/users/aihamtaleb/gists{/gist_id}", "starred_url": "https://api.github.com/users/aihamtaleb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aihamtaleb/subscriptions", "organizations_url": "https://api.github.com/users/aihamtaleb/orgs", "repos_url": "https://api.github.com/users/aihamtaleb/repos", "events_url": "https://api.github.com/users/aihamtaleb/events{/privacy}", "received_events_url": "https://api.github.com/users/aihamtaleb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-08T07:36:56Z", "updated_at": "2017-06-08T07:36:56Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=26853612\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pronot\">@pronot</a> Well, I didn't need the name of the corresponding tensor. For the model in this file: <a href=\"https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py\">https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py</a></p>\n<p>I did the following:</p>\n<ul>\n<li>I constructed inception_v3 model only until the avg_pool layer. (Line 320). And then returned the net. This operation is the one that gives you the 2048 vector for each image. Because all consequent operations are related to the actual classification.</li>\n<li>Then, you just have to call this function and pass a list of images as its inputs. However, you have to consider performing the same image preprocessing steps that were performed before the training procedure. I.e. you have to create Tf-records out of your test images list.</li>\n<li>After creating the tf-records for your test set, convert it to a tensor. And just pass it as a parameter to the function inception_v3 you created in the first step.</li>\n<li>Then you just have to evaluate the bottleneck tensor using a default session.</li>\n</ul>\n<p>Actually, the flow of inference from the bottleneck layer I followed is very similar to the evaluation of inception shown in this file:<br>\n<a href=\"https://github.com/tensorflow/models/blob/master/inception/inception/inception_eval.py\">https://github.com/tensorflow/models/blob/master/inception/inception/inception_eval.py</a><br>\nBut instead of constructing the full graph, I constructed until the bottleneck (avg_pool).</p>\n<p>Please let me know if you need more elaboration, and/or code snippets.</p>", "body_text": "@pronot Well, I didn't need the name of the corresponding tensor. For the model in this file: https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py\nI did the following:\n\nI constructed inception_v3 model only until the avg_pool layer. (Line 320). And then returned the net. This operation is the one that gives you the 2048 vector for each image. Because all consequent operations are related to the actual classification.\nThen, you just have to call this function and pass a list of images as its inputs. However, you have to consider performing the same image preprocessing steps that were performed before the training procedure. I.e. you have to create Tf-records out of your test images list.\nAfter creating the tf-records for your test set, convert it to a tensor. And just pass it as a parameter to the function inception_v3 you created in the first step.\nThen you just have to evaluate the bottleneck tensor using a default session.\n\nActually, the flow of inference from the bottleneck layer I followed is very similar to the evaluation of inception shown in this file:\nhttps://github.com/tensorflow/models/blob/master/inception/inception/inception_eval.py\nBut instead of constructing the full graph, I constructed until the bottleneck (avg_pool).\nPlease let me know if you need more elaboration, and/or code snippets.", "body": "@pronot Well, I didn't need the name of the corresponding tensor. For the model in this file: https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py \r\n\r\nI did the following:\r\n\r\n- I constructed inception_v3 model only until the avg_pool layer. (Line 320). And then returned the net. This operation is the one that gives you the 2048 vector for each image. Because all consequent operations are related to the actual classification.\r\n- Then, you just have to call this function and pass a list of images as its inputs. However, you have to consider performing the same image preprocessing steps that were performed before the training procedure. I.e. you have to create Tf-records out of your test images list.\r\n- After creating the tf-records for your test set, convert it to a tensor. And just pass it as a parameter to the function inception_v3 you created in the first step.\r\n- Then you just have to evaluate the bottleneck tensor using a default session.\r\n\r\nActually, the flow of inference from the bottleneck layer I followed is very similar to the evaluation of inception shown in this file: \r\nhttps://github.com/tensorflow/models/blob/master/inception/inception/inception_eval.py\r\nBut instead of constructing the full graph, I constructed until the bottleneck (avg_pool).\r\n\r\nPlease let me know if you need more elaboration, and/or code snippets. "}