{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4847", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4847/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4847/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4847/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4847", "id": 181844612, "node_id": "MDU6SXNzdWUxODE4NDQ2MTI=", "number": 4847, "title": "input tensor lost in --mode eightbit quantization", "user": {"login": "tachim", "id": 11812, "node_id": "MDQ6VXNlcjExODEy", "avatar_url": "https://avatars1.githubusercontent.com/u/11812?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tachim", "html_url": "https://github.com/tachim", "followers_url": "https://api.github.com/users/tachim/followers", "following_url": "https://api.github.com/users/tachim/following{/other_user}", "gists_url": "https://api.github.com/users/tachim/gists{/gist_id}", "starred_url": "https://api.github.com/users/tachim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tachim/subscriptions", "organizations_url": "https://api.github.com/users/tachim/orgs", "repos_url": "https://api.github.com/users/tachim/repos", "events_url": "https://api.github.com/users/tachim/events{/privacy}", "received_events_url": "https://api.github.com/users/tachim/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2016-10-08T19:36:53Z", "updated_at": "2017-06-16T20:56:04Z", "closed_at": "2017-06-16T20:56:04Z", "author_association": "NONE", "body_html": "<p>Quantizing with --mode eightbit somehow loses the input tensor, whereas other methods like weights_rounded don't. If I do this:</p>\n<p><code>python quantize_graph.py --input ~/proc/frozen_inference_optimized.pb --output ~/proc/frozen_inference_optimized_quantized.pb --output_node_names on_logits --mode eightbit</code></p>\n<p>the following error pops up in the iOS tensorflow runtime:</p>\n<p><code>Running model failed:Not found: FeedInputs: unable to find feed output preprocess/centered_bgr</code></p>\n<p>Here <code>preprocess/centered_bgr</code> is the node I want to use as the input. If instead I use something like <code>--mode weights_rounded</code> no error is raised and the network functions as expected.</p>\n<h3>Environment info</h3>\n<p>Operating System: ubuntu / iOS</p>\n<p>Installed version of CUDA and cuDNN:</p>\n<pre><code>root@0f1fd91e29a1:~/w/tensorflow/tensorflow/contrib/quantization/tools# ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -&gt; libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n</code></pre>\n<p>Commit I'm using: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/8915f0f8072c406ae3fe0dff888f51b4cad02d7d/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/8915f0f8072c406ae3fe0dff888f51b4cad02d7d\"><tt>8915f0f</tt></a>. bazel version 0.3.0.</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=161459\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/petewarden\">@petewarden</a></p>", "body_text": "Quantizing with --mode eightbit somehow loses the input tensor, whereas other methods like weights_rounded don't. If I do this:\npython quantize_graph.py --input ~/proc/frozen_inference_optimized.pb --output ~/proc/frozen_inference_optimized_quantized.pb --output_node_names on_logits --mode eightbit\nthe following error pops up in the iOS tensorflow runtime:\nRunning model failed:Not found: FeedInputs: unable to find feed output preprocess/centered_bgr\nHere preprocess/centered_bgr is the node I want to use as the input. If instead I use something like --mode weights_rounded no error is raised and the network functions as expected.\nEnvironment info\nOperating System: ubuntu / iOS\nInstalled version of CUDA and cuDNN:\nroot@0f1fd91e29a1:~/w/tensorflow/tensorflow/contrib/quantization/tools# ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n\nCommit I'm using: 8915f0f. bazel version 0.3.0.\ncc @petewarden", "body": "Quantizing with --mode eightbit somehow loses the input tensor, whereas other methods like weights_rounded don't. If I do this:\n\n`python quantize_graph.py --input ~/proc/frozen_inference_optimized.pb --output ~/proc/frozen_inference_optimized_quantized.pb --output_node_names on_logits --mode eightbit`\n\nthe following error pops up in the iOS tensorflow runtime:\n\n`Running model failed:Not found: FeedInputs: unable to find feed output preprocess/centered_bgr`\n\nHere `preprocess/centered_bgr` is the node I want to use as the input. If instead I use something like `--mode weights_rounded` no error is raised and the network functions as expected.\n### Environment info\n\nOperating System: ubuntu / iOS\n\nInstalled version of CUDA and cuDNN: \n\n```\nroot@0f1fd91e29a1:~/w/tensorflow/tensorflow/contrib/quantization/tools# ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n```\n\nCommit I'm using: 8915f0f8072c406ae3fe0dff888f51b4cad02d7d. bazel version 0.3.0.\n\ncc @petewarden \n"}