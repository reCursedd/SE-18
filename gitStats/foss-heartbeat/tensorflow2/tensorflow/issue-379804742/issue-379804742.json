{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23687", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23687/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23687/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23687/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23687", "id": 379804742, "node_id": "MDU6SXNzdWUzNzk4MDQ3NDI=", "number": 23687, "title": "scatter_max doesn't work with MirroredStrategy since v1.11.0", "user": {"login": "ZhouYuChen", "id": 3125695, "node_id": "MDQ6VXNlcjMxMjU2OTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/3125695?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhouYuChen", "html_url": "https://github.com/ZhouYuChen", "followers_url": "https://api.github.com/users/ZhouYuChen/followers", "following_url": "https://api.github.com/users/ZhouYuChen/following{/other_user}", "gists_url": "https://api.github.com/users/ZhouYuChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhouYuChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhouYuChen/subscriptions", "organizations_url": "https://api.github.com/users/ZhouYuChen/orgs", "repos_url": "https://api.github.com/users/ZhouYuChen/repos", "events_url": "https://api.github.com/users/ZhouYuChen/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhouYuChen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 996845227, "node_id": "MDU6TGFiZWw5OTY4NDUyMjc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:dist-strat", "name": "comp:dist-strat", "color": "0052cc", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-11-12T14:36:11Z", "updated_at": "2018-11-23T11:06:56Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code: yes</li>\n<li>OS Platform and Distribution: Linux Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A</li>\n<li>TensorFlow installed from: binary</li>\n<li>TensorFlow version: tensorflow-gpu v1.12.0-0-ga6d8ffae09, v1.11.0-0-gc19e29306c</li>\n<li>Python version: python 2.7.12</li>\n<li>Bazel version: N/A</li>\n<li>GCC/Compiler version: N/A</li>\n<li>CUDA/cuDNN version: CUDA 9.0 / cuDNN 7.1.4.18-1+cuda9.0</li>\n<li>GPU model and memory: (GeForce GTX 1080Ti / 11172MiB) x 2</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nscatter_max does not work with MirroredStrategy since v1.11.0.</p>\n<p><strong>Describe the expected behavior</strong><br>\nscatter_max can work with MirroredStrategy in tensorflow-gpu 1.10.0</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import, division, print_function\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> os, sys\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">model_func</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>, <span class=\"pl-smi\">params</span>):\n    tmp_var <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    a<span class=\"pl-k\">=</span>tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.ones(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[]), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">aggregation</span><span class=\"pl-k\">=</span>tf.VariableAggregation.<span class=\"pl-c1\">MEAN</span>)\n    <span class=\"pl-k\">with</span> tf.control_dependencies([tmp_var.initializer]):\n        y <span class=\"pl-k\">=</span> tf.stop_gradient(tf.scatter_max(tmp_var, [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>], tf.random_uniform([<span class=\"pl-c1\">2</span>])))\n        loss <span class=\"pl-k\">=</span> tf.reduce_sum(y <span class=\"pl-k\">*</span> a)\n    opt <span class=\"pl-k\">=</span> tf.train.AdamOptimizer().minimize(loss, tf.train.get_global_step())\n    <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>opt)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">input_fn</span>():\n    features <span class=\"pl-k\">=</span>  tf.data.Dataset.from_tensors([[<span class=\"pl-c1\">0</span>.]]).repeat()\n    labels <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensors(<span class=\"pl-c1\">0</span>.).repeat()\n    <span class=\"pl-k\">return</span> tf.data.Dataset.zip((features, labels))\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">argv</span>):\n    os.environ[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>CUDA_VISIBLE_DEVICES<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>0,1<span class=\"pl-pds\">\"</span></span>\n    run_config <span class=\"pl-k\">=</span> tf.estimator.RunConfig(\n        <span class=\"pl-v\">train_distribute</span><span class=\"pl-k\">=</span>tf.contrib.distribute.MirroredStrategy(<span class=\"pl-v\">num_gpus</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>),\n        <span class=\"pl-v\">session_config</span><span class=\"pl-k\">=</span>tf.ConfigProto(\n            <span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n            <span class=\"pl-v\">gpu_options</span><span class=\"pl-k\">=</span>tf.GPUOptions(<span class=\"pl-v\">force_gpu_compatible</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n    )\n    model <span class=\"pl-k\">=</span> tf.estimator.Estimator(<span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>model_func, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>run_config)\n\n    model.train(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>input_fn, <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>)\n\ntf.logging.set_verbosity(tf.logging.<span class=\"pl-c1\">INFO</span>)\ntf.app.run(<span class=\"pl-v\">argv</span><span class=\"pl-k\">=</span>[sys.argv[<span class=\"pl-c1\">0</span>]])</pre></div>\n<p><strong>Other info / logs</strong></p>\n<p>error logs from up code running in v1.12.0</p>\n<pre><code>INFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:Not using Distribute Coordinator.\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpiGysT0\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': gpu_options {\n  force_gpu_compatible: true\n}\nallow_soft_placement: true\n, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': &lt;tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f7bc01ee910&gt;, '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7bc01ee890&gt;, '_model_dir': '/tmp/tmpiGysT0', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': '', '_distribute_coordinator_mode': None}\nWARNING:tensorflow:Estimator's model_fn (&lt;function model_func at 0x7f7bc5e48578&gt;) includes params argument, but params are not passed to Estimator.\n2018-11-12 06:18:54.074313: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-11-12 06:18:55.364237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:03:00.0\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\n2018-11-12 06:18:55.511370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:04:00.0\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\n2018-11-12 06:18:55.512283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n2018-11-12 06:18:55.949305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-12 06:18:55.949341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n2018-11-12 06:18:55.949347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \n2018-11-12 06:18:55.949351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \n2018-11-12 06:18:55.949765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 10400 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n2018-11-12 06:18:55.950082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:1 with 10400 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\nINFO:tensorflow:Configured nccl all-reduce.\n2018-11-12 06:18:55.968070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n2018-11-12 06:18:55.968135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-12 06:18:55.968145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n2018-11-12 06:18:55.968150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \n2018-11-12 06:18:55.968155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \n2018-11-12 06:18:55.968526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10400 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n2018-11-12 06:18:55.968672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10400 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Error reported to Coordinator: \nTraceback (most recent call last):\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/tmp/model_test.py\", line 9, in model_func\n    y = tf.stop_gradient(tf.scatter_max(tmp_var, [0, 1], tf.random_uniform([2])))\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 719, in scatter_max\n    use_locking=use_locking, name=name)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\n    assert not as_ref\nAssertionError\nTraceback (most recent call last):\n  File \"/tmp/model_test.py\", line 33, in &lt;module&gt;\n    tf.app.run(argv=[sys.argv[0]])\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"/tmp/model_test.py\", line 30, in main\n    model.train(input_fn=input_fn, steps=100)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1205, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1316, in _train_model_distributed\n    self.config)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/distribute.py\", line 721, in call_for_each_tower\n    return self._call_for_each_tower(fn, *args, **kwargs)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 556, in _call_for_each_tower\n    return _call_for_each_tower(self, fn, *args, **kwargs)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 183, in _call_for_each_tower\n    coord.join(threads)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/tmp/model_test.py\", line 9, in model_func\n    y = tf.stop_gradient(tf.scatter_max(tmp_var, [0, 1], tf.random_uniform([2])))\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 719, in scatter_max\n    use_locking=use_locking, name=name)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\n    assert not as_ref\nAssertionError\n</code></pre>", "body_text": "System information\n\nHave I written custom code: yes\nOS Platform and Distribution: Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from: binary\nTensorFlow version: tensorflow-gpu v1.12.0-0-ga6d8ffae09, v1.11.0-0-gc19e29306c\nPython version: python 2.7.12\nBazel version: N/A\nGCC/Compiler version: N/A\nCUDA/cuDNN version: CUDA 9.0 / cuDNN 7.1.4.18-1+cuda9.0\nGPU model and memory: (GeForce GTX 1080Ti / 11172MiB) x 2\n\nDescribe the current behavior\nscatter_max does not work with MirroredStrategy since v1.11.0.\nDescribe the expected behavior\nscatter_max can work with MirroredStrategy in tensorflow-gpu 1.10.0\nCode to reproduce the issue\nfrom __future__ import absolute_import, division, print_function\nimport tensorflow as tf\nimport os, sys\n\ndef model_func(features, labels, mode, params):\n    tmp_var = tf.Variable(tf.zeros(shape=[2]), trainable=False)\n    a=tf.get_variable('a', initializer=tf.ones(shape=[]), trainable=True, aggregation=tf.VariableAggregation.MEAN)\n    with tf.control_dependencies([tmp_var.initializer]):\n        y = tf.stop_gradient(tf.scatter_max(tmp_var, [0, 1], tf.random_uniform([2])))\n        loss = tf.reduce_sum(y * a)\n    opt = tf.train.AdamOptimizer().minimize(loss, tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=opt)\n\ndef input_fn():\n    features =  tf.data.Dataset.from_tensors([[0.]]).repeat()\n    labels = tf.data.Dataset.from_tensors(0.).repeat()\n    return tf.data.Dataset.zip((features, labels))\n\ndef main(argv):\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n    run_config = tf.estimator.RunConfig(\n        train_distribute=tf.contrib.distribute.MirroredStrategy(num_gpus=2),\n        session_config=tf.ConfigProto(\n            allow_soft_placement=True,\n            gpu_options=tf.GPUOptions(force_gpu_compatible=True))\n    )\n    model = tf.estimator.Estimator(model_fn=model_func, config=run_config)\n\n    model.train(input_fn=input_fn, steps=100)\n\ntf.logging.set_verbosity(tf.logging.INFO)\ntf.app.run(argv=[sys.argv[0]])\nOther info / logs\nerror logs from up code running in v1.12.0\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:Not using Distribute Coordinator.\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpiGysT0\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': gpu_options {\n  force_gpu_compatible: true\n}\nallow_soft_placement: true\n, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f7bc01ee910>, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7bc01ee890>, '_model_dir': '/tmp/tmpiGysT0', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': '', '_distribute_coordinator_mode': None}\nWARNING:tensorflow:Estimator's model_fn (<function model_func at 0x7f7bc5e48578>) includes params argument, but params are not passed to Estimator.\n2018-11-12 06:18:54.074313: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-11-12 06:18:55.364237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:03:00.0\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\n2018-11-12 06:18:55.511370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:04:00.0\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\n2018-11-12 06:18:55.512283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n2018-11-12 06:18:55.949305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-12 06:18:55.949341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n2018-11-12 06:18:55.949347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \n2018-11-12 06:18:55.949351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \n2018-11-12 06:18:55.949765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 10400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n2018-11-12 06:18:55.950082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:1 with 10400 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\nINFO:tensorflow:Configured nccl all-reduce.\n2018-11-12 06:18:55.968070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n2018-11-12 06:18:55.968135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-12 06:18:55.968145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n2018-11-12 06:18:55.968150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \n2018-11-12 06:18:55.968155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \n2018-11-12 06:18:55.968526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n2018-11-12 06:18:55.968672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10400 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Error reported to Coordinator: \nTraceback (most recent call last):\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/tmp/model_test.py\", line 9, in model_func\n    y = tf.stop_gradient(tf.scatter_max(tmp_var, [0, 1], tf.random_uniform([2])))\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 719, in scatter_max\n    use_locking=use_locking, name=name)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\n    assert not as_ref\nAssertionError\nTraceback (most recent call last):\n  File \"/tmp/model_test.py\", line 33, in <module>\n    tf.app.run(argv=[sys.argv[0]])\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"/tmp/model_test.py\", line 30, in main\n    model.train(input_fn=input_fn, steps=100)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1205, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1316, in _train_model_distributed\n    self.config)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/distribute.py\", line 721, in call_for_each_tower\n    return self._call_for_each_tower(fn, *args, **kwargs)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 556, in _call_for_each_tower\n    return _call_for_each_tower(self, fn, *args, **kwargs)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 183, in _call_for_each_tower\n    coord.join(threads)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/tmp/model_test.py\", line 9, in model_func\n    y = tf.stop_gradient(tf.scatter_max(tmp_var, [0, 1], tf.random_uniform([2])))\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 719, in scatter_max\n    use_locking=use_locking, name=name)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\n    assert not as_ref\nAssertionError", "body": "\r\n**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: tensorflow-gpu v1.12.0-0-ga6d8ffae09, v1.11.0-0-gc19e29306c\r\n- Python version: python 2.7.12\r\n- Bazel version: N/A\r\n- GCC/Compiler version: N/A \r\n- CUDA/cuDNN version: CUDA 9.0 / cuDNN 7.1.4.18-1+cuda9.0\r\n- GPU model and memory: (GeForce GTX 1080Ti / 11172MiB) x 2\r\n\r\n**Describe the current behavior**\r\nscatter_max does not work with MirroredStrategy since v1.11.0.\r\n\r\n**Describe the expected behavior**\r\nscatter_max can work with MirroredStrategy in tensorflow-gpu 1.10.0\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nfrom __future__ import absolute_import, division, print_function\r\nimport tensorflow as tf\r\nimport os, sys\r\n\r\ndef model_func(features, labels, mode, params):\r\n    tmp_var = tf.Variable(tf.zeros(shape=[2]), trainable=False)\r\n    a=tf.get_variable('a', initializer=tf.ones(shape=[]), trainable=True, aggregation=tf.VariableAggregation.MEAN)\r\n    with tf.control_dependencies([tmp_var.initializer]):\r\n        y = tf.stop_gradient(tf.scatter_max(tmp_var, [0, 1], tf.random_uniform([2])))\r\n        loss = tf.reduce_sum(y * a)\r\n    opt = tf.train.AdamOptimizer().minimize(loss, tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=opt)\r\n\r\ndef input_fn():\r\n    features =  tf.data.Dataset.from_tensors([[0.]]).repeat()\r\n    labels = tf.data.Dataset.from_tensors(0.).repeat()\r\n    return tf.data.Dataset.zip((features, labels))\r\n\r\ndef main(argv):\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\r\n    run_config = tf.estimator.RunConfig(\r\n        train_distribute=tf.contrib.distribute.MirroredStrategy(num_gpus=2),\r\n        session_config=tf.ConfigProto(\r\n            allow_soft_placement=True,\r\n            gpu_options=tf.GPUOptions(force_gpu_compatible=True))\r\n    )\r\n    model = tf.estimator.Estimator(model_fn=model_func, config=run_config)\r\n\r\n    model.train(input_fn=input_fn, steps=100)\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\ntf.app.run(argv=[sys.argv[0]])\r\n```\r\n\r\n**Other info / logs**\r\n\r\nerror logs from up code running in v1.12.0\r\n```\r\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\r\nINFO:tensorflow:Not using Distribute Coordinator.\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpiGysT0\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': gpu_options {\r\n  force_gpu_compatible: true\r\n}\r\nallow_soft_placement: true\r\n, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f7bc01ee910>, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7bc01ee890>, '_model_dir': '/tmp/tmpiGysT0', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': '', '_distribute_coordinator_mode': None}\r\nWARNING:tensorflow:Estimator's model_fn (<function model_func at 0x7f7bc5e48578>) includes params argument, but params are not passed to Estimator.\r\n2018-11-12 06:18:54.074313: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-11-12 06:18:55.364237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\r\n2018-11-12 06:18:55.511370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\r\n2018-11-12 06:18:55.512283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\r\n2018-11-12 06:18:55.949305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-12 06:18:55.949341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \r\n2018-11-12 06:18:55.949347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \r\n2018-11-12 06:18:55.949351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \r\n2018-11-12 06:18:55.949765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 10400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2018-11-12 06:18:55.950082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:1 with 10400 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\r\nINFO:tensorflow:Configured nccl all-reduce.\r\n2018-11-12 06:18:55.968070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\r\n2018-11-12 06:18:55.968135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-12 06:18:55.968145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \r\n2018-11-12 06:18:55.968150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \r\n2018-11-12 06:18:55.968155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \r\n2018-11-12 06:18:55.968526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2018-11-12 06:18:55.968672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10400 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Error reported to Coordinator: \r\nTraceback (most recent call last):\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\r\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/tmp/model_test.py\", line 9, in model_func\r\n    y = tf.stop_gradient(tf.scatter_max(tmp_var, [0, 1], tf.random_uniform([2])))\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 719, in scatter_max\r\n    use_locking=use_locking, name=name)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\r\n    assert not as_ref\r\nAssertionError\r\nTraceback (most recent call last):\r\n  File \"/tmp/model_test.py\", line 33, in <module>\r\n    tf.app.run(argv=[sys.argv[0]])\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/tmp/model_test.py\", line 30, in main\r\n    model.train(input_fn=input_fn, steps=100)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1205, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1316, in _train_model_distributed\r\n    self.config)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/distribute.py\", line 721, in call_for_each_tower\r\n    return self._call_for_each_tower(fn, *args, **kwargs)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 556, in _call_for_each_tower\r\n    return _call_for_each_tower(self, fn, *args, **kwargs)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 183, in _call_for_each_tower\r\n    coord.join(threads)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\r\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/tmp/model_test.py\", line 9, in model_func\r\n    y = tf.stop_gradient(tf.scatter_max(tmp_var, [0, 1], tf.random_uniform([2])))\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 719, in scatter_max\r\n    use_locking=use_locking, name=name)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/data/tf1.12/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\r\n    assert not as_ref\r\nAssertionError\r\n```"}