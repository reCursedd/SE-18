{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/337257557", "html_url": "https://github.com/tensorflow/tensorflow/issues/8246#issuecomment-337257557", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8246", "id": 337257557, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzI1NzU1Nw==", "user": {"login": "qianyizhang", "id": 12500132, "node_id": "MDQ6VXNlcjEyNTAwMTMy", "avatar_url": "https://avatars0.githubusercontent.com/u/12500132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qianyizhang", "html_url": "https://github.com/qianyizhang", "followers_url": "https://api.github.com/users/qianyizhang/followers", "following_url": "https://api.github.com/users/qianyizhang/following{/other_user}", "gists_url": "https://api.github.com/users/qianyizhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/qianyizhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qianyizhang/subscriptions", "organizations_url": "https://api.github.com/users/qianyizhang/orgs", "repos_url": "https://api.github.com/users/qianyizhang/repos", "events_url": "https://api.github.com/users/qianyizhang/events{/privacy}", "received_events_url": "https://api.github.com/users/qianyizhang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-17T14:51:22Z", "updated_at": "2017-10-17T14:55:31Z", "author_association": "NONE", "body_html": "<p>since the thread is still open, I will paste my solution here</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">np_repeat</span>(<span class=\"pl-smi\">tensor</span>, <span class=\"pl-smi\">repeats</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">    Args:</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    input: A Tensor. 1-D or higher.</span>\n<span class=\"pl-s\">    repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Returns:</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">assert</span> <span class=\"pl-c1\">len</span>(repeats) <span class=\"pl-k\">==</span> tensor.ndim, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>dimension must match<span class=\"pl-pds\">\"</span></span>\n    repeated <span class=\"pl-k\">=</span> tensor\n    <span class=\"pl-k\">for</span> axis, repeat <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(repeats):\n        repeated <span class=\"pl-k\">=</span> np.repeat(repeated, repeat, <span class=\"pl-v\">axis</span> <span class=\"pl-k\">=</span> axis)\n    <span class=\"pl-k\">return</span> repeated\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">tf_repeat</span>(<span class=\"pl-smi\">tensor</span>, <span class=\"pl-smi\">repeats</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">    Args:</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    input: A Tensor. 1-D or higher.</span>\n<span class=\"pl-s\">    repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Returns:</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repeat<span class=\"pl-pds\">\"</span></span>):\n        expanded_tensor <span class=\"pl-k\">=</span> tf.expand_dims(tensor, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n        multiples <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">+</span> repeats\n        tiled_tensor <span class=\"pl-k\">=</span> tf.tile(expanded_tensor, <span class=\"pl-v\">multiples</span> <span class=\"pl-k\">=</span> multiples)\n        repeated_tesnor <span class=\"pl-k\">=</span> tf.reshape(tiled_tensor, tf.shape(tensor) <span class=\"pl-k\">*</span> repeats)\n    <span class=\"pl-k\">return</span> repeated_tesnor\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">repeat_test</span>():\n    shape <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">2</span>]\n    repeat <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">1</span>]\n    tensor <span class=\"pl-k\">=</span> np.random.randn(<span class=\"pl-k\">*</span>shape)\n    np_repeated_tensor <span class=\"pl-k\">=</span> np_repeat(tensor, repeat)\n    tf_tensor <span class=\"pl-k\">=</span> tf.constant(tensor)\n    g <span class=\"pl-k\">=</span> tf.get_default_graph()\n    tf_new <span class=\"pl-k\">=</span> tf_repeat(tf_tensor, repeat)\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>g) <span class=\"pl-k\">as</span> sess:\n        tf_repeated_tensor <span class=\"pl-k\">=</span> tf_new.eval()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>    tf_repeated_tensor = np.array(tf_repeated_tensor)</span>\n    <span class=\"pl-k\">if</span> np.allclose(np_repeated_tensor, tf_repeated_tensor):\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tf_repeat is the same as np_repeat<span class=\"pl-pds\">\"</span></span>)\n    <span class=\"pl-k\">else</span>:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>something wrong<span class=\"pl-pds\">\"</span></span>)</pre></div>", "body_text": "since the thread is still open, I will paste my solution here\ndef np_repeat(tensor, repeats):\n    \"\"\"\n    Args:\n\n    input: A Tensor. 1-D or higher.\n    repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n\n    Returns:\n    \n    A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n    \"\"\"\n    assert len(repeats) == tensor.ndim, \"dimension must match\"\n    repeated = tensor\n    for axis, repeat in enumerate(repeats):\n        repeated = np.repeat(repeated, repeat, axis = axis)\n    return repeated\n\ndef tf_repeat(tensor, repeats):\n    \"\"\"\n    Args:\n\n    input: A Tensor. 1-D or higher.\n    repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n\n    Returns:\n    \n    A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n    \"\"\"\n    with tf.variable_scope(\"repeat\"):\n        expanded_tensor = tf.expand_dims(tensor, -1)\n        multiples = [1] + repeats\n        tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\n        repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\n    return repeated_tesnor\n\ndef repeat_test():\n    shape = [1,3,3,3,2]\n    repeat = [1,2,2,3,1]\n    tensor = np.random.randn(*shape)\n    np_repeated_tensor = np_repeat(tensor, repeat)\n    tf_tensor = tf.constant(tensor)\n    g = tf.get_default_graph()\n    tf_new = tf_repeat(tf_tensor, repeat)\n    with tf.Session(graph=g) as sess:\n        tf_repeated_tensor = tf_new.eval()\n#    tf_repeated_tensor = np.array(tf_repeated_tensor)\n    if np.allclose(np_repeated_tensor, tf_repeated_tensor):\n        print(\"tf_repeat is the same as np_repeat\")\n    else:\n        print(\"something wrong\")", "body": "since the thread is still open, I will paste my solution here\r\n```python\r\ndef np_repeat(tensor, repeats):\r\n    \"\"\"\r\n    Args:\r\n\r\n    input: A Tensor. 1-D or higher.\r\n    repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\r\n\r\n    Returns:\r\n    \r\n    A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\r\n    \"\"\"\r\n    assert len(repeats) == tensor.ndim, \"dimension must match\"\r\n    repeated = tensor\r\n    for axis, repeat in enumerate(repeats):\r\n        repeated = np.repeat(repeated, repeat, axis = axis)\r\n    return repeated\r\n\r\ndef tf_repeat(tensor, repeats):\r\n    \"\"\"\r\n    Args:\r\n\r\n    input: A Tensor. 1-D or higher.\r\n    repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\r\n\r\n    Returns:\r\n    \r\n    A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\r\n    \"\"\"\r\n    with tf.variable_scope(\"repeat\"):\r\n        expanded_tensor = tf.expand_dims(tensor, -1)\r\n        multiples = [1] + repeats\r\n        tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\r\n        repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\r\n    return repeated_tesnor\r\n\r\ndef repeat_test():\r\n    shape = [1,3,3,3,2]\r\n    repeat = [1,2,2,3,1]\r\n    tensor = np.random.randn(*shape)\r\n    np_repeated_tensor = np_repeat(tensor, repeat)\r\n    tf_tensor = tf.constant(tensor)\r\n    g = tf.get_default_graph()\r\n    tf_new = tf_repeat(tf_tensor, repeat)\r\n    with tf.Session(graph=g) as sess:\r\n        tf_repeated_tensor = tf_new.eval()\r\n#    tf_repeated_tensor = np.array(tf_repeated_tensor)\r\n    if np.allclose(np_repeated_tensor, tf_repeated_tensor):\r\n        print(\"tf_repeat is the same as np_repeat\")\r\n    else:\r\n        print(\"something wrong\")\r\n````"}