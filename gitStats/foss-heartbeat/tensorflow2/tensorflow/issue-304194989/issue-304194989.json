{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17632", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17632/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17632/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17632/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17632", "id": 304194989, "node_id": "MDU6SXNzdWUzMDQxOTQ5ODk=", "number": 17632, "title": "got Nan when powered float32 tensors", "user": {"login": "metya", "id": 968934, "node_id": "MDQ6VXNlcjk2ODkzNA==", "avatar_url": "https://avatars3.githubusercontent.com/u/968934?v=4", "gravatar_id": "", "url": "https://api.github.com/users/metya", "html_url": "https://github.com/metya", "followers_url": "https://api.github.com/users/metya/followers", "following_url": "https://api.github.com/users/metya/following{/other_user}", "gists_url": "https://api.github.com/users/metya/gists{/gist_id}", "starred_url": "https://api.github.com/users/metya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/metya/subscriptions", "organizations_url": "https://api.github.com/users/metya/orgs", "repos_url": "https://api.github.com/users/metya/repos", "events_url": "https://api.github.com/users/metya/events{/privacy}", "received_events_url": "https://api.github.com/users/metya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-03-11T21:18:53Z", "updated_at": "2018-03-17T19:48:08Z", "closed_at": "2018-03-17T19:48:08Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>Windows 10 Pro</strong></li>\n<li><strong>TensorFlow installed from (prebuild version here <a href=\"https://github.com/fo40225/tensorflow-windows-wheel\">https://github.com/fo40225/tensorflow-windows-wheel</a>  with avx2)</strong></li>\n<li><strong>TensorFlow version 1.6.0</strong></li>\n<li><strong>Python version 3.6.4</strong>:</li>\n<li><strong>Bazel version (if compiling from source)</strong></li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong></li>\n<li><strong>CUDA 9.1.85/cuDNN 1.7.1 version</strong></li>\n<li><strong>GPU Nvidia MX150 2GB</strong></li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>On my setup tensorflow get nan when I powered tensors with float32 type, but with float64 it's ok.</p>\n<p>But if just product tensors by itself in float32 it's ok too.</p>\n<h3>Source code / logs</h3>\n<h2>Scenario 1</h2>\n<pre><code>X = tf.placeholder('float32')\n\nx = np.linspace(-3, 3)\n\ns = tf.Session()\n\nX_pow2 = tf.pow(X, 2)\nX_pow3 = tf.pow(X, 3)\nX_prod = X*X\n\nprint('X_pow2 =', X_pow2.eval({X:x}, session=s), '\\n')\nprint('X_pow3 =', X_pow3.eval({X:x},session=s),'\\n')\nprint('X_prod =', X_prod.eval({X:x},session=s),'\\n')\n</code></pre>\n<p>I get this</p>\n<pre><code>X_pow2 = [          nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n 3.7484397e-03 3.3735953e-02 9.3710966e-02 1.8367349e-01 3.0362350e-01\n 4.5356098e-01 6.3348603e-01 8.4339863e-01 1.0832988e+00 1.3531864e+00\n 1.6530614e+00 1.9829239e+00 2.3427739e+00 2.7326119e+00 3.1524367e+00\n 3.6022491e+00 4.0820494e+00 4.5918374e+00 5.1316123e+00 5.7013750e+00\n 6.3011241e+00 6.9308624e+00 7.5905871e+00 8.2803001e+00 9.0000000e+00] \n\nX_pow3 = [          nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n 2.2949636e-04 6.1964002e-03 2.8687032e-02 7.8717217e-02 1.6730276e-01\n 3.0545944e-01 5.0420320e-01 7.7454978e-01 1.1275151e+00 1.5741148e+00\n 2.1253648e+00 2.7922804e+00 3.5858786e+00 4.5171747e+00 5.5971832e+00\n 6.8369217e+00 8.2474060e+00 9.8396511e+00 1.1624674e+01 1.3613489e+01\n 1.5817106e+01 1.8246557e+01 2.0912844e+01 2.3826992e+01 2.7000002e+01] \n\nX_prod = [9.0000000e+00 8.2803001e+00 7.5905881e+00 6.9308619e+00 6.3011246e+00\n 5.7013745e+00 5.1316123e+00 4.5918365e+00 4.0820489e+00 3.6022491e+00\n 3.1524365e+00 2.7326117e+00 2.3427739e+00 1.9829239e+00 1.6530612e+00\n 1.3531862e+00 1.0832986e+00 8.4339857e-01 6.3348603e-01 4.5356098e-01\n 3.0362347e-01 1.8367347e-01 9.3710959e-02 3.3735946e-02 3.7484383e-03\n 3.7484383e-03 3.3735946e-02 9.3710959e-02 1.8367347e-01 3.0362347e-01\n 4.5356098e-01 6.3348603e-01 8.4339857e-01 1.0832986e+00 1.3531862e+00\n 1.6530612e+00 1.9829239e+00 2.3427739e+00 2.7326117e+00 3.1524365e+00\n 3.6022491e+00 4.0820489e+00 4.5918365e+00 5.1316123e+00 5.7013745e+00\n 6.3011246e+00 6.9308619e+00 7.5905881e+00 8.2803001e+00 9.0000000e+00] \n\n</code></pre>\n<h2>Scenario 2</h2>\n<pre><code>X = tf.placeholder('float64')\n\nx = np.linspace(-3, 3)\n\ns = tf.Session()\n\nX_pow2 = tf.pow(X, 2)\nX_pow3 = tf.pow(X, 3)\n\nprint('X_pow2 =', X_pow2.eval({X:x}, session=s), '\\n')\nprint('X_pow3 =', X_pow3.eval({X:x},session=s),'\\n')\n</code></pre>\n<p>get this</p>\n<pre><code>X_pow2 = [9.00000000e+00 8.28029988e+00 7.59058726e+00 6.93086214e+00\n 6.30112453e+00 5.70137443e+00 5.13161183e+00 4.59183673e+00\n 4.08204915e+00 3.60224906e+00 3.15243648e+00 2.73261141e+00\n 2.34277384e+00 1.98292378e+00 1.65306122e+00 1.35318617e+00\n 1.08329863e+00 8.43398584e-01 6.33486047e-01 4.53561016e-01\n 3.03623490e-01 1.83673469e-01 9.37109538e-02 3.37359434e-02\n 3.74843815e-03 3.74843815e-03 3.37359434e-02 9.37109538e-02\n 1.83673469e-01 3.03623490e-01 4.53561016e-01 6.33486047e-01\n 8.43398584e-01 1.08329863e+00 1.35318617e+00 1.65306122e+00\n 1.98292378e+00 2.34277384e+00 2.73261141e+00 3.15243648e+00\n 3.60224906e+00 4.08204915e+00 4.59183673e+00 5.13161183e+00\n 5.70137443e+00 6.30112453e+00 6.93086214e+00 7.59058726e+00\n 8.28029988e+00 9.00000000e+00] \n\nX_pow3 = [-2.70000000e+01 -2.38269854e+01 -2.09128424e+01 -1.82465554e+01\n -1.58171085e+01 -1.36134859e+01 -1.16246717e+01 -9.83965015e+00\n -8.24740542e+00 -6.83692169e+00 -5.59718315e+00 -4.51717397e+00\n -3.58587833e+00 -2.79228043e+00 -2.12536443e+00 -1.57411453e+00\n -1.12751490e+00 -7.74549720e-01 -5.04203181e-01 -3.05459460e-01\n -1.67302740e-01 -7.87172012e-02 -2.86870267e-02 -6.19639776e-03\n -2.29496213e-04  2.29496213e-04  6.19639776e-03  2.86870267e-02\n  7.87172012e-02  1.67302740e-01  3.05459460e-01  5.04203181e-01\n  7.74549720e-01  1.12751490e+00  1.57411453e+00  2.12536443e+00\n  2.79228043e+00  3.58587833e+00  4.51717397e+00  5.59718315e+00\n  6.83692169e+00  8.24740542e+00  9.83965015e+00  1.16246717e+01\n  1.36134859e+01  1.58171085e+01  1.82465554e+01  2.09128424e+01\n  2.38269854e+01  2.70000000e+01] \n</code></pre>\n<p>So on more serious or complicated tasks this give unpredictable behavior and optimizers don't optimize, losses get NaN, everything going crazy or just NaN everywhere.</p>\n<p>So I exactly had the same problem on tensorflow version 1.5.0 with CuDNN 7.0.5</p>\n<p>And I can't understand, is it my setup and maybe videocard just bad, or is it really bug?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nWindows 10 Pro\nTensorFlow installed from (prebuild version here https://github.com/fo40225/tensorflow-windows-wheel  with avx2)\nTensorFlow version 1.6.0\nPython version 3.6.4:\nBazel version (if compiling from source)\nGCC/Compiler version (if compiling from source)\nCUDA 9.1.85/cuDNN 1.7.1 version\nGPU Nvidia MX150 2GB\nExact command to reproduce:\n\nDescribe the problem\nOn my setup tensorflow get nan when I powered tensors with float32 type, but with float64 it's ok.\nBut if just product tensors by itself in float32 it's ok too.\nSource code / logs\nScenario 1\nX = tf.placeholder('float32')\n\nx = np.linspace(-3, 3)\n\ns = tf.Session()\n\nX_pow2 = tf.pow(X, 2)\nX_pow3 = tf.pow(X, 3)\nX_prod = X*X\n\nprint('X_pow2 =', X_pow2.eval({X:x}, session=s), '\\n')\nprint('X_pow3 =', X_pow3.eval({X:x},session=s),'\\n')\nprint('X_prod =', X_prod.eval({X:x},session=s),'\\n')\n\nI get this\nX_pow2 = [          nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n 3.7484397e-03 3.3735953e-02 9.3710966e-02 1.8367349e-01 3.0362350e-01\n 4.5356098e-01 6.3348603e-01 8.4339863e-01 1.0832988e+00 1.3531864e+00\n 1.6530614e+00 1.9829239e+00 2.3427739e+00 2.7326119e+00 3.1524367e+00\n 3.6022491e+00 4.0820494e+00 4.5918374e+00 5.1316123e+00 5.7013750e+00\n 6.3011241e+00 6.9308624e+00 7.5905871e+00 8.2803001e+00 9.0000000e+00] \n\nX_pow3 = [          nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n           nan           nan           nan           nan           nan\n 2.2949636e-04 6.1964002e-03 2.8687032e-02 7.8717217e-02 1.6730276e-01\n 3.0545944e-01 5.0420320e-01 7.7454978e-01 1.1275151e+00 1.5741148e+00\n 2.1253648e+00 2.7922804e+00 3.5858786e+00 4.5171747e+00 5.5971832e+00\n 6.8369217e+00 8.2474060e+00 9.8396511e+00 1.1624674e+01 1.3613489e+01\n 1.5817106e+01 1.8246557e+01 2.0912844e+01 2.3826992e+01 2.7000002e+01] \n\nX_prod = [9.0000000e+00 8.2803001e+00 7.5905881e+00 6.9308619e+00 6.3011246e+00\n 5.7013745e+00 5.1316123e+00 4.5918365e+00 4.0820489e+00 3.6022491e+00\n 3.1524365e+00 2.7326117e+00 2.3427739e+00 1.9829239e+00 1.6530612e+00\n 1.3531862e+00 1.0832986e+00 8.4339857e-01 6.3348603e-01 4.5356098e-01\n 3.0362347e-01 1.8367347e-01 9.3710959e-02 3.3735946e-02 3.7484383e-03\n 3.7484383e-03 3.3735946e-02 9.3710959e-02 1.8367347e-01 3.0362347e-01\n 4.5356098e-01 6.3348603e-01 8.4339857e-01 1.0832986e+00 1.3531862e+00\n 1.6530612e+00 1.9829239e+00 2.3427739e+00 2.7326117e+00 3.1524365e+00\n 3.6022491e+00 4.0820489e+00 4.5918365e+00 5.1316123e+00 5.7013745e+00\n 6.3011246e+00 6.9308619e+00 7.5905881e+00 8.2803001e+00 9.0000000e+00] \n\n\nScenario 2\nX = tf.placeholder('float64')\n\nx = np.linspace(-3, 3)\n\ns = tf.Session()\n\nX_pow2 = tf.pow(X, 2)\nX_pow3 = tf.pow(X, 3)\n\nprint('X_pow2 =', X_pow2.eval({X:x}, session=s), '\\n')\nprint('X_pow3 =', X_pow3.eval({X:x},session=s),'\\n')\n\nget this\nX_pow2 = [9.00000000e+00 8.28029988e+00 7.59058726e+00 6.93086214e+00\n 6.30112453e+00 5.70137443e+00 5.13161183e+00 4.59183673e+00\n 4.08204915e+00 3.60224906e+00 3.15243648e+00 2.73261141e+00\n 2.34277384e+00 1.98292378e+00 1.65306122e+00 1.35318617e+00\n 1.08329863e+00 8.43398584e-01 6.33486047e-01 4.53561016e-01\n 3.03623490e-01 1.83673469e-01 9.37109538e-02 3.37359434e-02\n 3.74843815e-03 3.74843815e-03 3.37359434e-02 9.37109538e-02\n 1.83673469e-01 3.03623490e-01 4.53561016e-01 6.33486047e-01\n 8.43398584e-01 1.08329863e+00 1.35318617e+00 1.65306122e+00\n 1.98292378e+00 2.34277384e+00 2.73261141e+00 3.15243648e+00\n 3.60224906e+00 4.08204915e+00 4.59183673e+00 5.13161183e+00\n 5.70137443e+00 6.30112453e+00 6.93086214e+00 7.59058726e+00\n 8.28029988e+00 9.00000000e+00] \n\nX_pow3 = [-2.70000000e+01 -2.38269854e+01 -2.09128424e+01 -1.82465554e+01\n -1.58171085e+01 -1.36134859e+01 -1.16246717e+01 -9.83965015e+00\n -8.24740542e+00 -6.83692169e+00 -5.59718315e+00 -4.51717397e+00\n -3.58587833e+00 -2.79228043e+00 -2.12536443e+00 -1.57411453e+00\n -1.12751490e+00 -7.74549720e-01 -5.04203181e-01 -3.05459460e-01\n -1.67302740e-01 -7.87172012e-02 -2.86870267e-02 -6.19639776e-03\n -2.29496213e-04  2.29496213e-04  6.19639776e-03  2.86870267e-02\n  7.87172012e-02  1.67302740e-01  3.05459460e-01  5.04203181e-01\n  7.74549720e-01  1.12751490e+00  1.57411453e+00  2.12536443e+00\n  2.79228043e+00  3.58587833e+00  4.51717397e+00  5.59718315e+00\n  6.83692169e+00  8.24740542e+00  9.83965015e+00  1.16246717e+01\n  1.36134859e+01  1.58171085e+01  1.82465554e+01  2.09128424e+01\n  2.38269854e+01  2.70000000e+01] \n\nSo on more serious or complicated tasks this give unpredictable behavior and optimizers don't optimize, losses get NaN, everything going crazy or just NaN everywhere.\nSo I exactly had the same problem on tensorflow version 1.5.0 with CuDNN 7.0.5\nAnd I can't understand, is it my setup and maybe videocard just bad, or is it really bug?", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **Windows 10 Pro**\r\n- **TensorFlow installed from (prebuild version here https://github.com/fo40225/tensorflow-windows-wheel  with avx2)**\r\n- **TensorFlow version 1.6.0**\r\n- **Python version 3.6.4**:\r\n- **Bazel version (if compiling from source)**\r\n- **GCC/Compiler version (if compiling from source)**\r\n- **CUDA 9.1.85/cuDNN 1.7.1 version**\r\n- **GPU Nvidia MX150 2GB**\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nOn my setup tensorflow get nan when I powered tensors with float32 type, but with float64 it's ok.\r\n\r\nBut if just product tensors by itself in float32 it's ok too.\r\n\r\n### Source code / logs\r\n\r\n## Scenario 1\r\n```\r\nX = tf.placeholder('float32')\r\n\r\nx = np.linspace(-3, 3)\r\n\r\ns = tf.Session()\r\n\r\nX_pow2 = tf.pow(X, 2)\r\nX_pow3 = tf.pow(X, 3)\r\nX_prod = X*X\r\n\r\nprint('X_pow2 =', X_pow2.eval({X:x}, session=s), '\\n')\r\nprint('X_pow3 =', X_pow3.eval({X:x},session=s),'\\n')\r\nprint('X_prod =', X_prod.eval({X:x},session=s),'\\n')\r\n```\r\n\r\nI get this \r\n\r\n```\r\nX_pow2 = [          nan           nan           nan           nan           nan\r\n           nan           nan           nan           nan           nan\r\n           nan           nan           nan           nan           nan\r\n           nan           nan           nan           nan           nan\r\n           nan           nan           nan           nan           nan\r\n 3.7484397e-03 3.3735953e-02 9.3710966e-02 1.8367349e-01 3.0362350e-01\r\n 4.5356098e-01 6.3348603e-01 8.4339863e-01 1.0832988e+00 1.3531864e+00\r\n 1.6530614e+00 1.9829239e+00 2.3427739e+00 2.7326119e+00 3.1524367e+00\r\n 3.6022491e+00 4.0820494e+00 4.5918374e+00 5.1316123e+00 5.7013750e+00\r\n 6.3011241e+00 6.9308624e+00 7.5905871e+00 8.2803001e+00 9.0000000e+00] \r\n\r\nX_pow3 = [          nan           nan           nan           nan           nan\r\n           nan           nan           nan           nan           nan\r\n           nan           nan           nan           nan           nan\r\n           nan           nan           nan           nan           nan\r\n           nan           nan           nan           nan           nan\r\n 2.2949636e-04 6.1964002e-03 2.8687032e-02 7.8717217e-02 1.6730276e-01\r\n 3.0545944e-01 5.0420320e-01 7.7454978e-01 1.1275151e+00 1.5741148e+00\r\n 2.1253648e+00 2.7922804e+00 3.5858786e+00 4.5171747e+00 5.5971832e+00\r\n 6.8369217e+00 8.2474060e+00 9.8396511e+00 1.1624674e+01 1.3613489e+01\r\n 1.5817106e+01 1.8246557e+01 2.0912844e+01 2.3826992e+01 2.7000002e+01] \r\n\r\nX_prod = [9.0000000e+00 8.2803001e+00 7.5905881e+00 6.9308619e+00 6.3011246e+00\r\n 5.7013745e+00 5.1316123e+00 4.5918365e+00 4.0820489e+00 3.6022491e+00\r\n 3.1524365e+00 2.7326117e+00 2.3427739e+00 1.9829239e+00 1.6530612e+00\r\n 1.3531862e+00 1.0832986e+00 8.4339857e-01 6.3348603e-01 4.5356098e-01\r\n 3.0362347e-01 1.8367347e-01 9.3710959e-02 3.3735946e-02 3.7484383e-03\r\n 3.7484383e-03 3.3735946e-02 9.3710959e-02 1.8367347e-01 3.0362347e-01\r\n 4.5356098e-01 6.3348603e-01 8.4339857e-01 1.0832986e+00 1.3531862e+00\r\n 1.6530612e+00 1.9829239e+00 2.3427739e+00 2.7326117e+00 3.1524365e+00\r\n 3.6022491e+00 4.0820489e+00 4.5918365e+00 5.1316123e+00 5.7013745e+00\r\n 6.3011246e+00 6.9308619e+00 7.5905881e+00 8.2803001e+00 9.0000000e+00] \r\n\r\n```\r\n\r\n## Scenario 2\r\n```\r\nX = tf.placeholder('float64')\r\n\r\nx = np.linspace(-3, 3)\r\n\r\ns = tf.Session()\r\n\r\nX_pow2 = tf.pow(X, 2)\r\nX_pow3 = tf.pow(X, 3)\r\n\r\nprint('X_pow2 =', X_pow2.eval({X:x}, session=s), '\\n')\r\nprint('X_pow3 =', X_pow3.eval({X:x},session=s),'\\n')\r\n```\r\n\r\nget this \r\n\r\n```\r\nX_pow2 = [9.00000000e+00 8.28029988e+00 7.59058726e+00 6.93086214e+00\r\n 6.30112453e+00 5.70137443e+00 5.13161183e+00 4.59183673e+00\r\n 4.08204915e+00 3.60224906e+00 3.15243648e+00 2.73261141e+00\r\n 2.34277384e+00 1.98292378e+00 1.65306122e+00 1.35318617e+00\r\n 1.08329863e+00 8.43398584e-01 6.33486047e-01 4.53561016e-01\r\n 3.03623490e-01 1.83673469e-01 9.37109538e-02 3.37359434e-02\r\n 3.74843815e-03 3.74843815e-03 3.37359434e-02 9.37109538e-02\r\n 1.83673469e-01 3.03623490e-01 4.53561016e-01 6.33486047e-01\r\n 8.43398584e-01 1.08329863e+00 1.35318617e+00 1.65306122e+00\r\n 1.98292378e+00 2.34277384e+00 2.73261141e+00 3.15243648e+00\r\n 3.60224906e+00 4.08204915e+00 4.59183673e+00 5.13161183e+00\r\n 5.70137443e+00 6.30112453e+00 6.93086214e+00 7.59058726e+00\r\n 8.28029988e+00 9.00000000e+00] \r\n\r\nX_pow3 = [-2.70000000e+01 -2.38269854e+01 -2.09128424e+01 -1.82465554e+01\r\n -1.58171085e+01 -1.36134859e+01 -1.16246717e+01 -9.83965015e+00\r\n -8.24740542e+00 -6.83692169e+00 -5.59718315e+00 -4.51717397e+00\r\n -3.58587833e+00 -2.79228043e+00 -2.12536443e+00 -1.57411453e+00\r\n -1.12751490e+00 -7.74549720e-01 -5.04203181e-01 -3.05459460e-01\r\n -1.67302740e-01 -7.87172012e-02 -2.86870267e-02 -6.19639776e-03\r\n -2.29496213e-04  2.29496213e-04  6.19639776e-03  2.86870267e-02\r\n  7.87172012e-02  1.67302740e-01  3.05459460e-01  5.04203181e-01\r\n  7.74549720e-01  1.12751490e+00  1.57411453e+00  2.12536443e+00\r\n  2.79228043e+00  3.58587833e+00  4.51717397e+00  5.59718315e+00\r\n  6.83692169e+00  8.24740542e+00  9.83965015e+00  1.16246717e+01\r\n  1.36134859e+01  1.58171085e+01  1.82465554e+01  2.09128424e+01\r\n  2.38269854e+01  2.70000000e+01] \r\n```\r\n\r\nSo on more serious or complicated tasks this give unpredictable behavior and optimizers don't optimize, losses get NaN, everything going crazy or just NaN everywhere.\r\n\r\nSo I exactly had the same problem on tensorflow version 1.5.0 with CuDNN 7.0.5\r\n\r\nAnd I can't understand, is it my setup and maybe videocard just bad, or is it really bug?"}