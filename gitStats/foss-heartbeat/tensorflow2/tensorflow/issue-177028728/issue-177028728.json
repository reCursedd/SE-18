{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4387", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4387/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4387/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4387/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4387", "id": 177028728, "node_id": "MDU6SXNzdWUxNzcwMjg3Mjg=", "number": 4387, "title": "Significant performance overhead with gpu kernel launches in a while_loop", "user": {"login": "kbrems", "id": 456665, "node_id": "MDQ6VXNlcjQ1NjY2NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/456665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kbrems", "html_url": "https://github.com/kbrems", "followers_url": "https://api.github.com/users/kbrems/followers", "following_url": "https://api.github.com/users/kbrems/following{/other_user}", "gists_url": "https://api.github.com/users/kbrems/gists{/gist_id}", "starred_url": "https://api.github.com/users/kbrems/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kbrems/subscriptions", "organizations_url": "https://api.github.com/users/kbrems/orgs", "repos_url": "https://api.github.com/users/kbrems/repos", "events_url": "https://api.github.com/users/kbrems/events{/privacy}", "received_events_url": "https://api.github.com/users/kbrems/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-09-14T21:39:56Z", "updated_at": "2016-10-06T18:31:46Z", "closed_at": "2016-10-06T18:31:46Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>Environment info</h3>\n<p>Operating System:<br>\nubuntu 14.04<br>\nGeForce GTX TITAN  Driver Version: 367.44</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):<br>\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a<br>\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.7.5<br>\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -&gt; libcudart.so.7.5.18<br>\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18<br>\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a<br>\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so<br>\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so.4<br>\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so.4.0.7<br>\n-rw-r--r-- 1 root root 62025862 Feb 23  2016 /usr/local/cuda/lib64/libcudnn_static.a</p>\n<ol>\n<li>A link to the pip package you installed:<br>\n<a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl</a></li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.<br>\n0.10.0rc0</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>import tensorflow as tf<br>\nfrom tensorflow.python.client import timeline</p>\n<p>start = tf.constant(0, dtype=tf.float64)<br>\nend = tf.constant(100, dtype=tf.float64)<br>\ninit = tf.ones([100], dtype=tf.float64)<br>\nb = tf.ones([100], dtype=tf.float64)</p>\n<p>def condForWhile(i, a):<br>\nreturn tf.less(i, end)</p>\n<p>def bodyForWhile(i, a):<br>\ni = i + 1<br>\na = tf.mul(a, b)<br>\nreturn [i, a]</p>\n<p>_, prod = tf.while_loop(condForWhile, bodyForWhile, [start, init])</p>\n<p>with tf.Session() as sess:<br>\ntf.initialize_all_variables().run()<br>\n# run once to eliminate start-up costs<br>\nsess.run(prod)<br>\n# now run with tracing<br>\nrun_metadata = tf.RunMetadata()<br>\nresult = sess.run(prod,<br>\noptions=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),<br>\nrun_metadata=run_metadata)</p>\n<p>trace = timeline.Timeline(step_stats=run_metadata.step_stats)<br>\ntrace_file = open('/tmp/timeline.tfwhile.json', 'w')<br>\ntrace_file.write(trace.generate_chrome_trace_format(show_dataflow=False, show_memory=False))</p>\n<p>This is a simple app that does a = a * b 100 times in a while_loop using the tf.mul() operator. I am using the timeline feature to profile it. Inspecting the timeline shows that for each iteration, the time in the gpu stream for the multiply is about .003ms, but the time between launches is .3ms-.5ms. This seems like a lot - is that expected?</p>\n<p>Note that my while condition uses floats in the less function. I see the less operation happening on the gpu stream and a memcpyDtoH time for each loop iteration presumably to copy the loop counter back and forth to the gpu, which seems kind of inefficient. If instead I use  type int64 in the loop conditions (start and end), then the gap between kernels goes down to .11 - .17ms and I no longer see the less on the gpu stream or the memcpy.</p>\n<p>Note that in the original case where we discovered this, our gpu operator was much more complicated (and uses floats in the condition) and the time between kernel launches was still relatively constant at around .4ms. In contrast, if I write this same app in straight cuda, and launch the kernel 100 times in cuda, the gap between launches is about .007ms (about 50x improvement). I would expect some overhead in the tensorflow conditional operators, but this really seems like a lot.</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).<br>\nAttaching the timeline traces for the above code for both floats and ints in the conditional.</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/473495/timelines.zip\">timelines.zip</a></p>", "body_text": "Environment info\nOperating System:\nubuntu 14.04\nGeForce GTX TITAN  Driver Version: 367.44\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Feb 23  2016 /usr/local/cuda/lib64/libcudnn_static.a\n\nA link to the pip package you installed:\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n0.10.0rc0\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nimport tensorflow as tf\nfrom tensorflow.python.client import timeline\nstart = tf.constant(0, dtype=tf.float64)\nend = tf.constant(100, dtype=tf.float64)\ninit = tf.ones([100], dtype=tf.float64)\nb = tf.ones([100], dtype=tf.float64)\ndef condForWhile(i, a):\nreturn tf.less(i, end)\ndef bodyForWhile(i, a):\ni = i + 1\na = tf.mul(a, b)\nreturn [i, a]\n_, prod = tf.while_loop(condForWhile, bodyForWhile, [start, init])\nwith tf.Session() as sess:\ntf.initialize_all_variables().run()\n# run once to eliminate start-up costs\nsess.run(prod)\n# now run with tracing\nrun_metadata = tf.RunMetadata()\nresult = sess.run(prod,\noptions=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\nrun_metadata=run_metadata)\ntrace = timeline.Timeline(step_stats=run_metadata.step_stats)\ntrace_file = open('/tmp/timeline.tfwhile.json', 'w')\ntrace_file.write(trace.generate_chrome_trace_format(show_dataflow=False, show_memory=False))\nThis is a simple app that does a = a * b 100 times in a while_loop using the tf.mul() operator. I am using the timeline feature to profile it. Inspecting the timeline shows that for each iteration, the time in the gpu stream for the multiply is about .003ms, but the time between launches is .3ms-.5ms. This seems like a lot - is that expected?\nNote that my while condition uses floats in the less function. I see the less operation happening on the gpu stream and a memcpyDtoH time for each loop iteration presumably to copy the loop counter back and forth to the gpu, which seems kind of inefficient. If instead I use  type int64 in the loop conditions (start and end), then the gap between kernels goes down to .11 - .17ms and I no longer see the less on the gpu stream or the memcpy.\nNote that in the original case where we discovered this, our gpu operator was much more complicated (and uses floats in the condition) and the time between kernel launches was still relatively constant at around .4ms. In contrast, if I write this same app in straight cuda, and launch the kernel 100 times in cuda, the gap between launches is about .007ms (about 50x improvement). I would expect some overhead in the tensorflow conditional operators, but this really seems like a lot.\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\nAttaching the timeline traces for the above code for both floats and ints in the conditional.\ntimelines.zip", "body": "### Environment info\n\nOperating System:\nubuntu 14.04\nGeForce GTX TITAN  Driver Version: 367.44\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 Feb 23  2016 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Feb 23  2016 /usr/local/cuda/lib64/libcudnn_static.a\n1. A link to the pip package you installed:\n   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.10.0rc0\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nimport tensorflow as tf\nfrom tensorflow.python.client import timeline\n\nstart = tf.constant(0, dtype=tf.float64)\nend = tf.constant(100, dtype=tf.float64)\ninit = tf.ones([100], dtype=tf.float64)\nb = tf.ones([100], dtype=tf.float64)\n\ndef condForWhile(i, a):\n    return tf.less(i, end)\n\ndef bodyForWhile(i, a):\n    i = i + 1\n    a = tf.mul(a, b)\n    return [i, a]\n\n_, prod = tf.while_loop(condForWhile, bodyForWhile, [start, init])\n\nwith tf.Session() as sess:\n    tf.initialize_all_variables().run()\n    # run once to eliminate start-up costs\n    sess.run(prod)\n    # now run with tracing\n    run_metadata = tf.RunMetadata()\n    result = sess.run(prod,\n        options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n        run_metadata=run_metadata)\n\ntrace = timeline.Timeline(step_stats=run_metadata.step_stats)\ntrace_file = open('/tmp/timeline.tfwhile.json', 'w')\ntrace_file.write(trace.generate_chrome_trace_format(show_dataflow=False, show_memory=False))\n\nThis is a simple app that does a = a \\* b 100 times in a while_loop using the tf.mul() operator. I am using the timeline feature to profile it. Inspecting the timeline shows that for each iteration, the time in the gpu stream for the multiply is about .003ms, but the time between launches is .3ms-.5ms. This seems like a lot - is that expected? \n\nNote that my while condition uses floats in the less function. I see the less operation happening on the gpu stream and a memcpyDtoH time for each loop iteration presumably to copy the loop counter back and forth to the gpu, which seems kind of inefficient. If instead I use  type int64 in the loop conditions (start and end), then the gap between kernels goes down to .11 - .17ms and I no longer see the less on the gpu stream or the memcpy. \n\nNote that in the original case where we discovered this, our gpu operator was much more complicated (and uses floats in the condition) and the time between kernel launches was still relatively constant at around .4ms. In contrast, if I write this same app in straight cuda, and launch the kernel 100 times in cuda, the gap between launches is about .007ms (about 50x improvement). I would expect some overhead in the tensorflow conditional operators, but this really seems like a lot. \n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\nAttaching the timeline traces for the above code for both floats and ints in the conditional. \n\n[timelines.zip](https://github.com/tensorflow/tensorflow/files/473495/timelines.zip)\n"}