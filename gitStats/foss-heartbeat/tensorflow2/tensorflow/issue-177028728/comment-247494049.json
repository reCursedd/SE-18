{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/247494049", "html_url": "https://github.com/tensorflow/tensorflow/issues/4387#issuecomment-247494049", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4387", "id": 247494049, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NzQ5NDA0OQ==", "user": {"login": "yuanbyu", "id": 2342391, "node_id": "MDQ6VXNlcjIzNDIzOTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/2342391?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuanbyu", "html_url": "https://github.com/yuanbyu", "followers_url": "https://api.github.com/users/yuanbyu/followers", "following_url": "https://api.github.com/users/yuanbyu/following{/other_user}", "gists_url": "https://api.github.com/users/yuanbyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuanbyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuanbyu/subscriptions", "organizations_url": "https://api.github.com/users/yuanbyu/orgs", "repos_url": "https://api.github.com/users/yuanbyu/repos", "events_url": "https://api.github.com/users/yuanbyu/events{/privacy}", "received_events_url": "https://api.github.com/users/yuanbyu/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-16T00:54:20Z", "updated_at": "2016-09-16T00:54:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I modified your code to compare it with static unrolling in TF:</p>\n<pre><code>import google3\nimport tensorflow.google as tf\nimport numpy as np\nimport time\n\ncfg = tf.ConfigProto(graph_options=tf.GraphOptions(\n    optimizer_options=tf.OptimizerOptions(\n        opt_level=tf.OptimizerOptions.L0)))\n\ndim = 100\nstart = tf.constant(0)\nend = tf.placeholder(tf.int32)\ninit = tf.ones([dim], dtype=tf.float64)\nb = tf.ones([dim], dtype=tf.float64)\n\ndef while_run():\n  def condForWhile(i, a):\n    return tf.less(i, end)\n\n  def bodyForWhile(i, a):\n    i = i + 1\n    a = tf.mul(a, b)\n    return [i, a]\n\n  _, prod = tf.while_loop(condForWhile, bodyForWhile, [start, init])\n  with tf.control_dependencies([prod]):\n    result = tf.no_op()\n\n  with tf.Session(config=cfg) as sess:\n    # warm up to eliminate start-up costs\n    sess.run(result, feed_dict={end: 100})\n\n    # time it.\n    t0 = time.time()\n    sess.run(result, feed_dict={end: 10000})\n    print(\"Iterations/second (dynamic):\", 10000.0 / (time.time() - t0))\n\ndef for_run():\n  prod = init\n  for i in xrange(10000):\n    prod = tf.mul(prod, b)\n  with tf.control_dependencies([prod]):\n    result = tf.no_op()\n\n  with tf.Session(config=cfg) as sess:\n    # warm up to eliminate start-up costs\n    sess.run(result)\n\n    # time it.\n    t0 = time.time()\n    sess.run(result)\n    print(\"Iterations/second (static):\", 10000.0 / (time.time() - t0))\n\ndef main(_):\n  for_run()\n  while_run()\n\nif __name__ == '__main__':\n  tf.app.run() \n</code></pre>\n<p>Here are the results. When the loop body is tiny, the run time is dominated by the book keeping overhead of while loop. (We need to run a lot more ops such as tf.add, tf.less, ...) When the loop body has a bit non-trivial computation, they are roughly equal.</p>\n<p>dim = 100:<br>\nIterations/second (static): 183921.174835<br>\nIterations/second (dynamic): 79751.9009581</p>\n<p>dim = 100000:<br>\nIterations/second (static): 69104.7188479<br>\nIterations/second (dynamic): 69447.4082463</p>", "body_text": "I modified your code to compare it with static unrolling in TF:\nimport google3\nimport tensorflow.google as tf\nimport numpy as np\nimport time\n\ncfg = tf.ConfigProto(graph_options=tf.GraphOptions(\n    optimizer_options=tf.OptimizerOptions(\n        opt_level=tf.OptimizerOptions.L0)))\n\ndim = 100\nstart = tf.constant(0)\nend = tf.placeholder(tf.int32)\ninit = tf.ones([dim], dtype=tf.float64)\nb = tf.ones([dim], dtype=tf.float64)\n\ndef while_run():\n  def condForWhile(i, a):\n    return tf.less(i, end)\n\n  def bodyForWhile(i, a):\n    i = i + 1\n    a = tf.mul(a, b)\n    return [i, a]\n\n  _, prod = tf.while_loop(condForWhile, bodyForWhile, [start, init])\n  with tf.control_dependencies([prod]):\n    result = tf.no_op()\n\n  with tf.Session(config=cfg) as sess:\n    # warm up to eliminate start-up costs\n    sess.run(result, feed_dict={end: 100})\n\n    # time it.\n    t0 = time.time()\n    sess.run(result, feed_dict={end: 10000})\n    print(\"Iterations/second (dynamic):\", 10000.0 / (time.time() - t0))\n\ndef for_run():\n  prod = init\n  for i in xrange(10000):\n    prod = tf.mul(prod, b)\n  with tf.control_dependencies([prod]):\n    result = tf.no_op()\n\n  with tf.Session(config=cfg) as sess:\n    # warm up to eliminate start-up costs\n    sess.run(result)\n\n    # time it.\n    t0 = time.time()\n    sess.run(result)\n    print(\"Iterations/second (static):\", 10000.0 / (time.time() - t0))\n\ndef main(_):\n  for_run()\n  while_run()\n\nif __name__ == '__main__':\n  tf.app.run() \n\nHere are the results. When the loop body is tiny, the run time is dominated by the book keeping overhead of while loop. (We need to run a lot more ops such as tf.add, tf.less, ...) When the loop body has a bit non-trivial computation, they are roughly equal.\ndim = 100:\nIterations/second (static): 183921.174835\nIterations/second (dynamic): 79751.9009581\ndim = 100000:\nIterations/second (static): 69104.7188479\nIterations/second (dynamic): 69447.4082463", "body": "I modified your code to compare it with static unrolling in TF:\n\n```\nimport google3\nimport tensorflow.google as tf\nimport numpy as np\nimport time\n\ncfg = tf.ConfigProto(graph_options=tf.GraphOptions(\n    optimizer_options=tf.OptimizerOptions(\n        opt_level=tf.OptimizerOptions.L0)))\n\ndim = 100\nstart = tf.constant(0)\nend = tf.placeholder(tf.int32)\ninit = tf.ones([dim], dtype=tf.float64)\nb = tf.ones([dim], dtype=tf.float64)\n\ndef while_run():\n  def condForWhile(i, a):\n    return tf.less(i, end)\n\n  def bodyForWhile(i, a):\n    i = i + 1\n    a = tf.mul(a, b)\n    return [i, a]\n\n  _, prod = tf.while_loop(condForWhile, bodyForWhile, [start, init])\n  with tf.control_dependencies([prod]):\n    result = tf.no_op()\n\n  with tf.Session(config=cfg) as sess:\n    # warm up to eliminate start-up costs\n    sess.run(result, feed_dict={end: 100})\n\n    # time it.\n    t0 = time.time()\n    sess.run(result, feed_dict={end: 10000})\n    print(\"Iterations/second (dynamic):\", 10000.0 / (time.time() - t0))\n\ndef for_run():\n  prod = init\n  for i in xrange(10000):\n    prod = tf.mul(prod, b)\n  with tf.control_dependencies([prod]):\n    result = tf.no_op()\n\n  with tf.Session(config=cfg) as sess:\n    # warm up to eliminate start-up costs\n    sess.run(result)\n\n    # time it.\n    t0 = time.time()\n    sess.run(result)\n    print(\"Iterations/second (static):\", 10000.0 / (time.time() - t0))\n\ndef main(_):\n  for_run()\n  while_run()\n\nif __name__ == '__main__':\n  tf.app.run() \n```\n\nHere are the results. When the loop body is tiny, the run time is dominated by the book keeping overhead of while loop. (We need to run a lot more ops such as tf.add, tf.less, ...) When the loop body has a bit non-trivial computation, they are roughly equal.\n\ndim = 100:\nIterations/second (static): 183921.174835\nIterations/second (dynamic): 79751.9009581\n\ndim = 100000:\nIterations/second (static): 69104.7188479\nIterations/second (dynamic): 69447.4082463\n"}