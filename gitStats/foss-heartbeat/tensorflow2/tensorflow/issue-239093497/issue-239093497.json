{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11102", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11102/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11102/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11102/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11102", "id": 239093497, "node_id": "MDU6SXNzdWUyMzkwOTM0OTc=", "number": 11102, "title": "using output_layer in seq2seq model?", "user": {"login": "sunxiaoben", "id": 5608481, "node_id": "MDQ6VXNlcjU2MDg0ODE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5608481?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sunxiaoben", "html_url": "https://github.com/sunxiaoben", "followers_url": "https://api.github.com/users/sunxiaoben/followers", "following_url": "https://api.github.com/users/sunxiaoben/following{/other_user}", "gists_url": "https://api.github.com/users/sunxiaoben/gists{/gist_id}", "starred_url": "https://api.github.com/users/sunxiaoben/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sunxiaoben/subscriptions", "organizations_url": "https://api.github.com/users/sunxiaoben/orgs", "repos_url": "https://api.github.com/users/sunxiaoben/repos", "events_url": "https://api.github.com/users/sunxiaoben/events{/privacy}", "received_events_url": "https://api.github.com/users/sunxiaoben/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-06-28T08:45:30Z", "updated_at": "2018-01-17T21:49:31Z", "closed_at": "2017-06-30T18:43:55Z", "author_association": "NONE", "body_html": "<p>Os\uff1aliunx<br>\nversion: v1.2.0</p>\n<p>i am writing a seq2seq model using tensorflow. my problem is</p>\n<p>helper = TrainingHelper(...)<br>\ndecoder = BasicDecoder(...)<br>\ndecoder_outputs, final_state, seq_len  = tf.contrib.seq2seq.dynamic_decode(decoder)<br>\nrnn_out, sample_ids = decoder_outputs</p>\n<p>in traing period, we should calculate the loss:<br>\nloss = tf.contrib.seq2seq.sequence_loss(rnn_out, targets, weights)</p>\n<p>the rnn_out's shape should be (batch_size, seq_len, target_vocab_size), but (batch_size, seq_len, cell_hidden_size)</p>\n<p>how to change the shape ? should i add a output_layer in decoder ?<br>\nif add, how to define a output_layer? i found tf.layers.dense has two params (inputs, units), units may be target_vocab_size, but what about inputs?</p>\n<p>In addition, is the output_layer is same as the beamSearcheDecoder when decoding?</p>", "body_text": "Os\uff1aliunx\nversion: v1.2.0\ni am writing a seq2seq model using tensorflow. my problem is\nhelper = TrainingHelper(...)\ndecoder = BasicDecoder(...)\ndecoder_outputs, final_state, seq_len  = tf.contrib.seq2seq.dynamic_decode(decoder)\nrnn_out, sample_ids = decoder_outputs\nin traing period, we should calculate the loss:\nloss = tf.contrib.seq2seq.sequence_loss(rnn_out, targets, weights)\nthe rnn_out's shape should be (batch_size, seq_len, target_vocab_size), but (batch_size, seq_len, cell_hidden_size)\nhow to change the shape ? should i add a output_layer in decoder ?\nif add, how to define a output_layer? i found tf.layers.dense has two params (inputs, units), units may be target_vocab_size, but what about inputs?\nIn addition, is the output_layer is same as the beamSearcheDecoder when decoding?", "body": "Os\uff1aliunx\r\nversion: v1.2.0\r\n\r\ni am writing a seq2seq model using tensorflow. my problem is \r\n\r\nhelper = TrainingHelper(...)\r\ndecoder = BasicDecoder(...)\r\ndecoder_outputs, final_state, seq_len  = tf.contrib.seq2seq.dynamic_decode(decoder)\r\nrnn_out, sample_ids = decoder_outputs\r\n\r\nin traing period, we should calculate the loss:\r\nloss = tf.contrib.seq2seq.sequence_loss(rnn_out, targets, weights)\r\n\r\nthe rnn_out's shape should be (batch_size, seq_len, target_vocab_size), but (batch_size, seq_len, cell_hidden_size)\r\n\r\nhow to change the shape ? should i add a output_layer in decoder ? \r\nif add, how to define a output_layer? i found tf.layers.dense has two params (inputs, units), units may be target_vocab_size, but what about inputs?\r\n\r\nIn addition, is the output_layer is same as the beamSearcheDecoder when decoding?\r\n\r\n"}