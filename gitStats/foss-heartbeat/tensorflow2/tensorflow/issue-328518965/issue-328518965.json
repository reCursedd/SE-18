{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19690", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19690/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19690/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19690/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19690", "id": 328518965, "node_id": "MDU6SXNzdWUzMjg1MTg5NjU=", "number": 19690, "title": "The tensorflow become dead when I use nccl.all_sum", "user": {"login": "luanyunteng", "id": 9795802, "node_id": "MDQ6VXNlcjk3OTU4MDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/9795802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/luanyunteng", "html_url": "https://github.com/luanyunteng", "followers_url": "https://api.github.com/users/luanyunteng/followers", "following_url": "https://api.github.com/users/luanyunteng/following{/other_user}", "gists_url": "https://api.github.com/users/luanyunteng/gists{/gist_id}", "starred_url": "https://api.github.com/users/luanyunteng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/luanyunteng/subscriptions", "organizations_url": "https://api.github.com/users/luanyunteng/orgs", "repos_url": "https://api.github.com/users/luanyunteng/repos", "events_url": "https://api.github.com/users/luanyunteng/events{/privacy}", "received_events_url": "https://api.github.com/users/luanyunteng/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "chsigg", "id": 7523982, "node_id": "MDQ6VXNlcjc1MjM5ODI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7523982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chsigg", "html_url": "https://github.com/chsigg", "followers_url": "https://api.github.com/users/chsigg/followers", "following_url": "https://api.github.com/users/chsigg/following{/other_user}", "gists_url": "https://api.github.com/users/chsigg/gists{/gist_id}", "starred_url": "https://api.github.com/users/chsigg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chsigg/subscriptions", "organizations_url": "https://api.github.com/users/chsigg/orgs", "repos_url": "https://api.github.com/users/chsigg/repos", "events_url": "https://api.github.com/users/chsigg/events{/privacy}", "received_events_url": "https://api.github.com/users/chsigg/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "chsigg", "id": 7523982, "node_id": "MDQ6VXNlcjc1MjM5ODI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7523982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chsigg", "html_url": "https://github.com/chsigg", "followers_url": "https://api.github.com/users/chsigg/followers", "following_url": "https://api.github.com/users/chsigg/following{/other_user}", "gists_url": "https://api.github.com/users/chsigg/gists{/gist_id}", "starred_url": "https://api.github.com/users/chsigg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chsigg/subscriptions", "organizations_url": "https://api.github.com/users/chsigg/orgs", "repos_url": "https://api.github.com/users/chsigg/repos", "events_url": "https://api.github.com/users/chsigg/events{/privacy}", "received_events_url": "https://api.github.com/users/chsigg/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-06-01T13:25:56Z", "updated_at": "2018-09-26T12:01:22Z", "closed_at": "2018-09-26T12:01:21Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:ubuntu14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:source</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.3.1</li>\n<li><strong>Python version</strong>: python3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>I try to use nccl to transfer data between gpus, but I can not run the programme although my 'print' tell<br>\nme 'Tensor(\"NcclAllReduce_1:0\", shape=(32, 35, 35, 192), dtype=float32, device=/device:GPU:1)<br>\n'</p>\n<h3>Source code / logs</h3>\n<p>this is my code:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef network(x):\n    with tf.device('/gpu:1'):\n        x1 = tf.zeros(shape=[32, 35, 35, 192])\n    with tf.device('/gpu:0'):\n        x0= tf.reshape(x, [-1, 35, 35, 192])\n        #x1 = tf.contrib.nccl.broadcast(x0, ['/gpu:1'])\n        #print(type(x1[1][0]))\n        #return x1\n        #return x1\n        (x_temp, x_temp1) = tf.contrib.nccl.all_sum([x0,x1])\n        print(x_temp1)\n        result = tf.identity(x_temp1)\n        return result\n\ndef main(_):\n    x = np.random.ranf(size=[32, 35, 35, 192])\n    x = x.astype('float32')\n    y_pre = network(x)\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(y_pre)\n\nif __name__ == '__main__':\n    tf.app.run(main=main)\n</code></pre>\n<p>this is my log:<br>\nTensor(\"NcclAllReduce_1:0\", shape=(32, 35, 35, 192), dtype=float32, device=/device:GPU:1)<br>\n2018-06-01 21:16:36.078103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:<br>\nname: GeForce GTX 1080<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 7.92GiB<br>\nFree memory: 7.80GiB<br>\n2018-06-01 21:16:36.197439: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4741160 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.<br>\n2018-06-01 21:16:36.198248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:<br>\nname: GeForce GTX 1080<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335<br>\npciBusID 0000:02:00.0<br>\nTotal memory: 7.92GiB<br>\nFree memory: 7.80GiB<br>\n2018-06-01 21:16:36.323103: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47455a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.<br>\n2018-06-01 21:16:36.323733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties:<br>\nname: GeForce GTX 1080<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335<br>\npciBusID 0000:03:00.0<br>\nTotal memory: 7.92GiB<br>\nFree memory: 7.80GiB<br>\n2018-06-01 21:16:36.456854: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47499e0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.<br>\n2018-06-01 21:16:36.457447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties:<br>\nname: GeForce GTX 1080<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335<br>\npciBusID 0000:04:00.0<br>\nTotal memory: 7.92GiB<br>\nFree memory: 7.80GiB<br>\n2018-06-01 21:16:36.461138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3<br>\n2018-06-01 21:16:36.461152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y Y Y<br>\n2018-06-01 21:16:36.461171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y Y Y<br>\n2018-06-01 21:16:36.461177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   Y Y Y Y<br>\n2018-06-01 21:16:36.461181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   Y Y Y Y<br>\n2018-06-01 21:16:36.461189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)<br>\n2018-06-01 21:16:36.461195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)<br>\n2018-06-01 21:16:36.461201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -&gt; (device: 2, name: GeForce GTX 1080, pci bus id: 0000:03:00.0)<br>\n2018-06-01 21:16:36.461205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -&gt; (device: 3, name: GeForce GTX 1080, pci bus id: 0000:04:00.0)</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu14.04\nTensorFlow installed from (source or binary):source\nTensorFlow version (use command below):1.3.1\nPython version: python3.5\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nI try to use nccl to transfer data between gpus, but I can not run the programme although my 'print' tell\nme 'Tensor(\"NcclAllReduce_1:0\", shape=(32, 35, 35, 192), dtype=float32, device=/device:GPU:1)\n'\nSource code / logs\nthis is my code:\nimport tensorflow as tf\nimport numpy as np\n\ndef network(x):\n    with tf.device('/gpu:1'):\n        x1 = tf.zeros(shape=[32, 35, 35, 192])\n    with tf.device('/gpu:0'):\n        x0= tf.reshape(x, [-1, 35, 35, 192])\n        #x1 = tf.contrib.nccl.broadcast(x0, ['/gpu:1'])\n        #print(type(x1[1][0]))\n        #return x1\n        #return x1\n        (x_temp, x_temp1) = tf.contrib.nccl.all_sum([x0,x1])\n        print(x_temp1)\n        result = tf.identity(x_temp1)\n        return result\n\ndef main(_):\n    x = np.random.ranf(size=[32, 35, 35, 192])\n    x = x.astype('float32')\n    y_pre = network(x)\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(y_pre)\n\nif __name__ == '__main__':\n    tf.app.run(main=main)\n\nthis is my log:\nTensor(\"NcclAllReduce_1:0\", shape=(32, 35, 35, 192), dtype=float32, device=/device:GPU:1)\n2018-06-01 21:16:36.078103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.80GiB\n2018-06-01 21:16:36.197439: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4741160 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n2018-06-01 21:16:36.198248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:\nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:02:00.0\nTotal memory: 7.92GiB\nFree memory: 7.80GiB\n2018-06-01 21:16:36.323103: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47455a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n2018-06-01 21:16:36.323733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties:\nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:03:00.0\nTotal memory: 7.92GiB\nFree memory: 7.80GiB\n2018-06-01 21:16:36.456854: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47499e0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n2018-06-01 21:16:36.457447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties:\nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:04:00.0\nTotal memory: 7.92GiB\nFree memory: 7.80GiB\n2018-06-01 21:16:36.461138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3\n2018-06-01 21:16:36.461152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y Y Y\n2018-06-01 21:16:36.461171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y Y Y\n2018-06-01 21:16:36.461177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   Y Y Y Y\n2018-06-01 21:16:36.461181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   Y Y Y Y\n2018-06-01 21:16:36.461189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n2018-06-01 21:16:36.461195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)\n2018-06-01 21:16:36.461201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:03:00.0)\n2018-06-01 21:16:36.461205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:04:00.0)", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:ubuntu14.04\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:1.3.1\r\n- **Python version**: python3.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nI try to use nccl to transfer data between gpus, but I can not run the programme although my 'print' tell\r\nme 'Tensor(\"NcclAllReduce_1:0\", shape=(32, 35, 35, 192), dtype=float32, device=/device:GPU:1)\r\n'\r\n### Source code / logs\r\nthis is my code:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef network(x):\r\n    with tf.device('/gpu:1'):\r\n        x1 = tf.zeros(shape=[32, 35, 35, 192])\r\n    with tf.device('/gpu:0'):\r\n        x0= tf.reshape(x, [-1, 35, 35, 192])\r\n        #x1 = tf.contrib.nccl.broadcast(x0, ['/gpu:1'])\r\n        #print(type(x1[1][0]))\r\n        #return x1\r\n        #return x1\r\n        (x_temp, x_temp1) = tf.contrib.nccl.all_sum([x0,x1])\r\n        print(x_temp1)\r\n        result = tf.identity(x_temp1)\r\n        return result\r\n\r\ndef main(_):\r\n    x = np.random.ranf(size=[32, 35, 35, 192])\r\n    x = x.astype('float32')\r\n    y_pre = network(x)\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(y_pre)\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run(main=main)\r\n```\r\nthis is my log:\r\nTensor(\"NcclAllReduce_1:0\", shape=(32, 35, 35, 192), dtype=float32, device=/device:GPU:1)\r\n2018-06-01 21:16:36.078103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.80GiB\r\n2018-06-01 21:16:36.197439: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4741160 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\r\n2018-06-01 21:16:36.198248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:\r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\npciBusID 0000:02:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.80GiB\r\n2018-06-01 21:16:36.323103: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47455a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\r\n2018-06-01 21:16:36.323733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties:\r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\npciBusID 0000:03:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.80GiB\r\n2018-06-01 21:16:36.456854: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47499e0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\r\n2018-06-01 21:16:36.457447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties:\r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\npciBusID 0000:04:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.80GiB\r\n2018-06-01 21:16:36.461138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3\r\n2018-06-01 21:16:36.461152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y Y Y\r\n2018-06-01 21:16:36.461171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y Y Y\r\n2018-06-01 21:16:36.461177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   Y Y Y Y\r\n2018-06-01 21:16:36.461181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   Y Y Y Y\r\n2018-06-01 21:16:36.461189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\r\n2018-06-01 21:16:36.461195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)\r\n2018-06-01 21:16:36.461201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:03:00.0)\r\n2018-06-01 21:16:36.461205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:04:00.0)\r\n"}