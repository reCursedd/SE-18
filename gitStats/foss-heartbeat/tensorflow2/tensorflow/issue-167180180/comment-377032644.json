{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/377032644", "html_url": "https://github.com/tensorflow/tensorflow/issues/3476#issuecomment-377032644", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3476", "id": 377032644, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzAzMjY0NA==", "user": {"login": "yurijvolkov", "id": 16668275, "node_id": "MDQ6VXNlcjE2NjY4Mjc1", "avatar_url": "https://avatars1.githubusercontent.com/u/16668275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yurijvolkov", "html_url": "https://github.com/yurijvolkov", "followers_url": "https://api.github.com/users/yurijvolkov/followers", "following_url": "https://api.github.com/users/yurijvolkov/following{/other_user}", "gists_url": "https://api.github.com/users/yurijvolkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/yurijvolkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yurijvolkov/subscriptions", "organizations_url": "https://api.github.com/users/yurijvolkov/orgs", "repos_url": "https://api.github.com/users/yurijvolkov/repos", "events_url": "https://api.github.com/users/yurijvolkov/events{/privacy}", "received_events_url": "https://api.github.com/users/yurijvolkov/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-28T20:53:25Z", "updated_at": "2018-03-28T20:53:25Z", "author_association": "NONE", "body_html": "<p>It seems that this issue was resolved a long time ago. But I stuck on this problem not so long ago and didn't figure out good solution from upward thread.</p>\n<p>So I decided to share solution I found. Possibly it would be useful for somebody.</p>\n<p>After creating cell (e.g. with MultiRNNCell) we can receive zero_state of it cell. Hence we can initialise Tensor with such shape and feed value into it. After that we only need to pass it into RNN directly.<br>\nCode example:</p>\n<p>`<br>\nCode example:</p>\n<pre><code>init_state = cell.zero_state(batch_size[0], tf.float32)\n\ninit_state = tf.identity(init_state, 'init_state') #Actually it works without this line. But it can be useful \n\n_lstm_state_ = tf.contrib.rnn.LSTMStateTuple(init_state[0, 0, :, :], init_state[0,1,:,:])\n\npreds, final_state = tf.nn.dynamic_rnn(cell, x, initial_state=(_lstm_state_,), parallel_iterations=1)\n</code></pre>\n<p>`</p>\n<p>Imo, this solution much scalable (e.g. for adding more layers) than creating placeholder for each LSTM layer parameter.</p>", "body_text": "It seems that this issue was resolved a long time ago. But I stuck on this problem not so long ago and didn't figure out good solution from upward thread.\nSo I decided to share solution I found. Possibly it would be useful for somebody.\nAfter creating cell (e.g. with MultiRNNCell) we can receive zero_state of it cell. Hence we can initialise Tensor with such shape and feed value into it. After that we only need to pass it into RNN directly.\nCode example:\n`\nCode example:\ninit_state = cell.zero_state(batch_size[0], tf.float32)\n\ninit_state = tf.identity(init_state, 'init_state') #Actually it works without this line. But it can be useful \n\n_lstm_state_ = tf.contrib.rnn.LSTMStateTuple(init_state[0, 0, :, :], init_state[0,1,:,:])\n\npreds, final_state = tf.nn.dynamic_rnn(cell, x, initial_state=(_lstm_state_,), parallel_iterations=1)\n\n`\nImo, this solution much scalable (e.g. for adding more layers) than creating placeholder for each LSTM layer parameter.", "body": "It seems that this issue was resolved a long time ago. But I stuck on this problem not so long ago and didn't figure out good solution from upward thread. \r\n\r\nSo I decided to share solution I found. Possibly it would be useful for somebody.\r\n\r\nAfter creating cell (e.g. with MultiRNNCell) we can receive zero_state of it cell. Hence we can initialise Tensor with such shape and feed value into it. After that we only need to pass it into RNN directly.\r\nCode example:\r\n\r\n`\r\nCode example:  \r\n\r\n    init_state = cell.zero_state(batch_size[0], tf.float32)\r\n\r\n    init_state = tf.identity(init_state, 'init_state') #Actually it works without this line. But it can be useful \r\n\r\n    _lstm_state_ = tf.contrib.rnn.LSTMStateTuple(init_state[0, 0, :, :], init_state[0,1,:,:])\r\n\r\n    preds, final_state = tf.nn.dynamic_rnn(cell, x, initial_state=(_lstm_state_,), parallel_iterations=1)\r\n`\r\n\r\nImo, this solution much scalable (e.g. for adding more layers) than creating placeholder for each LSTM layer parameter.\r\n\r\n"}