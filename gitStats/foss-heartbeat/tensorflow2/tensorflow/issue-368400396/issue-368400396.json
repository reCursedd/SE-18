{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22852", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22852/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22852/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22852/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22852", "id": 368400396, "node_id": "MDU6SXNzdWUzNjg0MDAzOTY=", "number": 22852, "title": "TensorFlow C++ API is significantly slower than Python API in inference", "user": {"login": "RothLuo", "id": 16584056, "node_id": "MDQ6VXNlcjE2NTg0MDU2", "avatar_url": "https://avatars1.githubusercontent.com/u/16584056?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RothLuo", "html_url": "https://github.com/RothLuo", "followers_url": "https://api.github.com/users/RothLuo/followers", "following_url": "https://api.github.com/users/RothLuo/following{/other_user}", "gists_url": "https://api.github.com/users/RothLuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/RothLuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RothLuo/subscriptions", "organizations_url": "https://api.github.com/users/RothLuo/orgs", "repos_url": "https://api.github.com/users/RothLuo/repos", "events_url": "https://api.github.com/users/RothLuo/events{/privacy}", "received_events_url": "https://api.github.com/users/RothLuo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-10-09T21:13:01Z", "updated_at": "2018-11-20T18:34:33Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>System information<br>\n***Have I written custom code (as opposed to using a stock example script provided in TensorFlow):<br>\nNo<br>\n***OS Platform and Distribution (e.g., Linux Ubuntu 16.04):<br>\nLinux Kernel 4.4.103, LUbuntu 16.04<br>\n***TensorFlow installed from (source or binary):<br>\nPython API is the official release;  C++ API was complied via Makefile with all available optimization flags (linked as a static library)<br>\n***TensorFlow version (use command below):<br>\n1.10.1<br>\n***Python version:<br>\n2.7<br>\n***CUDA/cuDNN version:<br>\nOnly CPU no GPU<br>\n***Bazel version:<br>\ndid not use Bazel to build<br>\n***GPU model and memory:<br>\ndid not use GPU for inference<br>\n***Mobile device:<br>\nplatform with a RK3399 ARM processor</p>\n<p>Steps to reproduce:</p>\n<ol>\n<li>Trained a MobileNetSSDv1 model via Google Detection API (Python);</li>\n<li>Froze the graph via the official tool provided by Detection API with batch_size = 1, and the input tensor size was [1, 150, 150, 3];</li>\n<li>Used the frozen graph (.pb file) along with TensorFlow Python and C++ API for inference, respectively. All C++ optimization flags on;</li>\n<li>The inference time with Python API was ~200 ms while C++ API takes ~550 ms.</li>\n</ol>\n<p>Any thoughts would be appreciated!</p>", "body_text": "System information\n***Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\nNo\n***OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Kernel 4.4.103, LUbuntu 16.04\n***TensorFlow installed from (source or binary):\nPython API is the official release;  C++ API was complied via Makefile with all available optimization flags (linked as a static library)\n***TensorFlow version (use command below):\n1.10.1\n***Python version:\n2.7\n***CUDA/cuDNN version:\nOnly CPU no GPU\n***Bazel version:\ndid not use Bazel to build\n***GPU model and memory:\ndid not use GPU for inference\n***Mobile device:\nplatform with a RK3399 ARM processor\nSteps to reproduce:\n\nTrained a MobileNetSSDv1 model via Google Detection API (Python);\nFroze the graph via the official tool provided by Detection API with batch_size = 1, and the input tensor size was [1, 150, 150, 3];\nUsed the frozen graph (.pb file) along with TensorFlow Python and C++ API for inference, respectively. All C++ optimization flags on;\nThe inference time with Python API was ~200 ms while C++ API takes ~550 ms.\n\nAny thoughts would be appreciated!", "body": "System information\r\n***Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n***OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Kernel 4.4.103, LUbuntu 16.04\r\n***TensorFlow installed from (source or binary):\r\nPython API is the official release;  C++ API was complied via Makefile with all available optimization flags (linked as a static library)\r\n***TensorFlow version (use command below):\r\n1.10.1\r\n***Python version:\r\n2.7\r\n***CUDA/cuDNN version:\r\nOnly CPU no GPU\r\n***Bazel version:\r\ndid not use Bazel to build \r\n***GPU model and memory:\r\ndid not use GPU for inference \r\n***Mobile device:\r\nplatform with a RK3399 ARM processor\r\n\r\nSteps to reproduce:\r\n1. Trained a MobileNetSSDv1 model via Google Detection API (Python);\r\n2. Froze the graph via the official tool provided by Detection API with batch_size = 1, and the input tensor size was [1, 150, 150, 3];\r\n3. Used the frozen graph (.pb file) along with TensorFlow Python and C++ API for inference, respectively. All C++ optimization flags on;\r\n4. The inference time with Python API was ~200 ms while C++ API takes ~550 ms. \r\n\r\nAny thoughts would be appreciated!"}