{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11730", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11730/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11730/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11730/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11730", "id": 245256966, "node_id": "MDU6SXNzdWUyNDUyNTY5NjY=", "number": 11730, "title": "Using XLA JIT Compilation results in bad_alloc error", "user": {"login": "villanuevab", "id": 3021974, "node_id": "MDQ6VXNlcjMwMjE5NzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/3021974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/villanuevab", "html_url": "https://github.com/villanuevab", "followers_url": "https://api.github.com/users/villanuevab/followers", "following_url": "https://api.github.com/users/villanuevab/following{/other_user}", "gists_url": "https://api.github.com/users/villanuevab/gists{/gist_id}", "starred_url": "https://api.github.com/users/villanuevab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/villanuevab/subscriptions", "organizations_url": "https://api.github.com/users/villanuevab/orgs", "repos_url": "https://api.github.com/users/villanuevab/repos", "events_url": "https://api.github.com/users/villanuevab/events{/privacy}", "received_events_url": "https://api.github.com/users/villanuevab/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-07-25T01:05:27Z", "updated_at": "2017-10-30T01:10:53Z", "closed_at": "2017-10-30T01:10:45Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.0.1-0-ge895d5c-dirty 1.0.1</li>\n<li><strong>Python version</strong>: Python 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: Build label: 0.4.5- (@non-git)</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/5.1</li>\n<li><strong>GPU model and memory</strong>: NVIDIA TX2</li>\n<li><strong>Exact command to reproduce</strong>: <code>python3 script.py</code></li>\n</ul>\n<pre><code># Config to turn on XLA JIT compilation\nconfig = tf.ConfigProto()\nconfig.graph_options.optimizer_options.global_jit_level = \\\n    tf.OptimizerOptions.ON_1\nwith tf.Session(config=config) as sess:\n</code></pre>\n<h3>Describe the problem</h3>\n<p>Bug in XLA JIT compilation. Script works as expected without assigning config with JIT optimizer option.</p>\n<h3>Source code / logs</h3>\n<p>Changing the following code:</p>\n<pre><code>with tf.Session() as sess:\n</code></pre>\n<p>To:</p>\n<pre><code># Config to turn on XLA JIT compilation\nconfig = tf.ConfigProto()\nconfig.graph_options.optimizer_options.global_jit_level = \\\n    tf.OptimizerOptions.ON_1\nwith tf.Session(config=config) as sess:\n</code></pre>\n<p>Results in the following error at runtime:</p>\n<pre><code>nvidia@tegra-ubuntu:~/dev$ python3 script.py\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:873] ARM has no NUMA node, hardcoding to return zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GP10B\nmajor: 6 minor: 2 memoryClockRate (GHz) 1.3005\npciBusID 0000:00:00.0\nTotal memory: 7.67GiB\nFree memory: 4.32GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GP10B, pci bus id: 0000:00:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 4.03G (4323303424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform CUDA. Devices:\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): GP10B, Compute Capability 6.2\nterminate called after throwing an instance of 'std::bad_alloc'\n  what():  std::bad_alloc\nAborted (core dumped)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): v1.0.1-0-ge895d5c-dirty 1.0.1\nPython version: Python 3.5.2\nBazel version (if compiling from source): Build label: 0.4.5- (@non-git)\nCUDA/cuDNN version: 8.0/5.1\nGPU model and memory: NVIDIA TX2\nExact command to reproduce: python3 script.py\n\n# Config to turn on XLA JIT compilation\nconfig = tf.ConfigProto()\nconfig.graph_options.optimizer_options.global_jit_level = \\\n    tf.OptimizerOptions.ON_1\nwith tf.Session(config=config) as sess:\n\nDescribe the problem\nBug in XLA JIT compilation. Script works as expected without assigning config with JIT optimizer option.\nSource code / logs\nChanging the following code:\nwith tf.Session() as sess:\n\nTo:\n# Config to turn on XLA JIT compilation\nconfig = tf.ConfigProto()\nconfig.graph_options.optimizer_options.global_jit_level = \\\n    tf.OptimizerOptions.ON_1\nwith tf.Session(config=config) as sess:\n\nResults in the following error at runtime:\nnvidia@tegra-ubuntu:~/dev$ python3 script.py\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:873] ARM has no NUMA node, hardcoding to return zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GP10B\nmajor: 6 minor: 2 memoryClockRate (GHz) 1.3005\npciBusID 0000:00:00.0\nTotal memory: 7.67GiB\nFree memory: 4.32GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GP10B, pci bus id: 0000:00:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 4.03G (4323303424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform CUDA. Devices:\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): GP10B, Compute Capability 6.2\nterminate called after throwing an instance of 'std::bad_alloc'\n  what():  std::bad_alloc\nAborted (core dumped)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.0.1-0-ge895d5c-dirty 1.0.1\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: Build label: 0.4.5- (@non-git)\r\n- **CUDA/cuDNN version**: 8.0/5.1\r\n- **GPU model and memory**: NVIDIA TX2\r\n- **Exact command to reproduce**: `python3 script.py`\r\n```\r\n# Config to turn on XLA JIT compilation\r\nconfig = tf.ConfigProto()\r\nconfig.graph_options.optimizer_options.global_jit_level = \\\r\n    tf.OptimizerOptions.ON_1\r\nwith tf.Session(config=config) as sess:\r\n```\r\n\r\n### Describe the problem\r\nBug in XLA JIT compilation. Script works as expected without assigning config with JIT optimizer option. \r\n\r\n### Source code / logs\r\nChanging the following code: \r\n```\r\nwith tf.Session() as sess:\r\n```\r\nTo:\r\n```\r\n# Config to turn on XLA JIT compilation\r\nconfig = tf.ConfigProto()\r\nconfig.graph_options.optimizer_options.global_jit_level = \\\r\n    tf.OptimizerOptions.ON_1\r\nwith tf.Session(config=config) as sess:\r\n```\r\nResults in the following error at runtime: \r\n```\r\nnvidia@tegra-ubuntu:~/dev$ python3 script.py\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:873] ARM has no NUMA node, hardcoding to return zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GP10B\r\nmajor: 6 minor: 2 memoryClockRate (GHz) 1.3005\r\npciBusID 0000:00:00.0\r\nTotal memory: 7.67GiB\r\nFree memory: 4.32GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GP10B, pci bus id: 0000:00:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 4.03G (4323303424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\r\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:\r\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\r\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform CUDA. Devices:\r\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): GP10B, Compute Capability 6.2\r\nterminate called after throwing an instance of 'std::bad_alloc'\r\n  what():  std::bad_alloc\r\nAborted (core dumped)\r\n```"}