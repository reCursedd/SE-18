{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18228", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18228/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18228/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18228/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18228", "id": 311087175, "node_id": "MDU6SXNzdWUzMTEwODcxNzU=", "number": 18228, "title": "why the convolution network output changes when i have already fixed the parameters of the convolution and only feed the net with same input?", "user": {"login": "Zealoe", "id": 30797481, "node_id": "MDQ6VXNlcjMwNzk3NDgx", "avatar_url": "https://avatars1.githubusercontent.com/u/30797481?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zealoe", "html_url": "https://github.com/Zealoe", "followers_url": "https://api.github.com/users/Zealoe/followers", "following_url": "https://api.github.com/users/Zealoe/following{/other_user}", "gists_url": "https://api.github.com/users/Zealoe/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zealoe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zealoe/subscriptions", "organizations_url": "https://api.github.com/users/Zealoe/orgs", "repos_url": "https://api.github.com/users/Zealoe/repos", "events_url": "https://api.github.com/users/Zealoe/events{/privacy}", "received_events_url": "https://api.github.com/users/Zealoe/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-04-04T05:08:55Z", "updated_at": "2018-04-04T07:20:10Z", "closed_at": "2018-04-04T07:20:10Z", "author_association": "NONE", "body_html": "<p>Sorry to bother, but i have trouble with the convolution in tensorflow.</p>\n<p>I am working with the network as below, input shape is [1,256,256,33], go through some convs, and after them i add a fully connected layer( not show in this picture). i fix the parameters of the convs, and try to train the fc layer.</p>\n<p>However, i found something weird... the network won't converge at all, so i only feed the network with one same input to test whether the network has any problem and print the output of each layer every iteration.</p>\n<p>and i found that the output of 'conv6' changes, though my net has been fixed.</p>\n<p>but the output of 'conv5_1' doesn't change at all!....</p>\n<p>so i changed the stride of conv6... and when i change the stride of conv6 from 2 to 1, the output of conv6 doesn't change either.... So the net is very weird to me.... the stride of conv6 decides whether it changes?</p>\n<p>Could anyone help me? thanks!!!</p>\n<p>[my network ('is training' is false]</p>\n<div class=\"highlight highlight-source-python\"><pre>    conv1 <span class=\"pl-k\">=</span> conv(data, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv1<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv1_1 <span class=\"pl-k\">=</span> conv(conv1, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv1_1<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv2 <span class=\"pl-k\">=</span> conv(conv1_1, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv2<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv2_1 <span class=\"pl-k\">=</span> conv(conv2, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv2_1<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)    \n    conv3 <span class=\"pl-k\">=</span> conv(conv2_1, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv3<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv3_1 <span class=\"pl-k\">=</span> conv(conv3, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv3_1<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv4 <span class=\"pl-k\">=</span> conv(conv3_1, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">512</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv4<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv4_1 <span class=\"pl-k\">=</span> conv(conv4, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">512</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv4_1<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv5 <span class=\"pl-k\">=</span> conv(conv4_1, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">512</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv5<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv5_1 <span class=\"pl-k\">=</span> conv(conv5, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">512</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv5_1<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n    conv6 <span class=\"pl-k\">=</span> conv(conv5_1, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1024</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv6<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)</pre></div>\n<p>[the conv definition]</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">conv</span>(<span class=\"pl-smi\">inputs</span>,<span class=\"pl-smi\">k_h</span>,<span class=\"pl-smi\">k_w</span>,<span class=\"pl-smi\">c_o</span>,<span class=\"pl-smi\">s_h</span>,<span class=\"pl-smi\">s_w</span>,<span class=\"pl-smi\">name</span>,<span class=\"pl-smi\">relu</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,<span class=\"pl-smi\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>,<span class=\"pl-smi\">group</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,<span class=\"pl-smi\">biased</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,<span class=\"pl-smi\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n\n    c_i <span class=\"pl-k\">=</span> inputs.get_shape()[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\n    convolve <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">i</span>, <span class=\"pl-smi\">k</span>: tf.nn.conv2d(i, k, [<span class=\"pl-c1\">1</span>, s_h, s_w, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span>padding)\n    <span class=\"pl-k\">with</span> tf.variable_scope(name) <span class=\"pl-k\">as</span> scope:\n        \n      <span class=\"pl-k\">if</span> is_training:\n        initializer <span class=\"pl-k\">=</span> slim.xavier_initializer()\n        weights_regularizer <span class=\"pl-k\">=</span> slim.l2_regularizer(<span class=\"pl-c1\">5e-4</span>)\n      <span class=\"pl-k\">else</span>:\n        initializer <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n        weights_regularizer <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n      kernel <span class=\"pl-k\">=</span> make_var(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>weights<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[k_h, k_w, c_i <span class=\"pl-k\">/</span> group, c_o],<span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training,<span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>initializer ,<span class=\"pl-v\">regularizer</span><span class=\"pl-k\">=</span>weights_regularizer)\n\n      output <span class=\"pl-k\">=</span> convolve(inputs, kernel)\n      <span class=\"pl-k\">if</span> biased:\n        biases <span class=\"pl-k\">=</span> make_var(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>biases<span class=\"pl-pds\">'</span></span>, [c_o],<span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)\n        output <span class=\"pl-k\">=</span> tf.nn.bias_add(output, biases)\n      <span class=\"pl-k\">if</span> relu:\n        output<span class=\"pl-k\">=</span> tf.nn.relu(output, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>scope.name)\n      <span class=\"pl-k\">return</span> output</pre></div>\n<p>[make_var definition]</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">make_var</span>( <span class=\"pl-smi\">name</span>, <span class=\"pl-smi\">shape</span>,<span class=\"pl-smi\">is_training</span>, <span class=\"pl-smi\">initializer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,<span class=\"pl-smi\">regularizer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n\n      <span class=\"pl-k\">return</span> tf.get_variable(name, shape,<span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span> initializer,<span class=\"pl-v\">regularizer</span><span class=\"pl-k\">=</span>regularizer,<span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span>is_training)</pre></div>", "body_text": "Sorry to bother, but i have trouble with the convolution in tensorflow.\nI am working with the network as below, input shape is [1,256,256,33], go through some convs, and after them i add a fully connected layer( not show in this picture). i fix the parameters of the convs, and try to train the fc layer.\nHowever, i found something weird... the network won't converge at all, so i only feed the network with one same input to test whether the network has any problem and print the output of each layer every iteration.\nand i found that the output of 'conv6' changes, though my net has been fixed.\nbut the output of 'conv5_1' doesn't change at all!....\nso i changed the stride of conv6... and when i change the stride of conv6 from 2 to 1, the output of conv6 doesn't change either.... So the net is very weird to me.... the stride of conv6 decides whether it changes?\nCould anyone help me? thanks!!!\n[my network ('is training' is false]\n    conv1 = conv(data, 3, 3, 64, 1, 1, name='conv1', is_training=is_training)\n    conv1_1 = conv(conv1, 3, 3, 64, 1, 1, name='conv1_1', is_training=is_training)\n    conv2 = conv(conv1_1, 3, 3, 128, 2, 2, name='conv2', is_training=is_training)\n    conv2_1 = conv(conv2, 3, 3, 128, 1, 1, name='conv2_1', is_training=is_training)    \n    conv3 = conv(conv2_1, 3, 3, 256, 2, 2, name='conv3', is_training=is_training)\n    conv3_1 = conv(conv3, 3, 3, 256, 1, 1, name='conv3_1', is_training=is_training)\n    conv4 = conv(conv3_1, 3, 3, 512, 2, 2, name='conv4', is_training=is_training)\n    conv4_1 = conv(conv4, 3, 3, 512, 1, 1, name='conv4_1', is_training=is_training)\n    conv5 = conv(conv4_1, 3, 3, 512, 2, 2, name='conv5', is_training=is_training)\n    conv5_1 = conv(conv5, 3, 3, 512, 1, 1, name='conv5_1', is_training=is_training)\n    conv6 = conv(conv5_1, 3, 3, 1024, 2, 2, name='conv6', is_training=is_training)\n[the conv definition]\ndef conv(inputs,k_h,k_w,c_o,s_h,s_w,name,relu=True,padding='SAME',group=1,biased=True,is_training=False):\n\n    c_i = inputs.get_shape()[-1]\n    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n    with tf.variable_scope(name) as scope:\n        \n      if is_training:\n        initializer = slim.xavier_initializer()\n        weights_regularizer = slim.l2_regularizer(5e-4)\n      else:\n        initializer = None\n        weights_regularizer = None\n\n      kernel = make_var('weights', shape=[k_h, k_w, c_i / group, c_o],is_training=is_training,initializer=initializer ,regularizer=weights_regularizer)\n\n      output = convolve(inputs, kernel)\n      if biased:\n        biases = make_var('biases', [c_o],is_training=is_training)\n        output = tf.nn.bias_add(output, biases)\n      if relu:\n        output= tf.nn.relu(output, name=scope.name)\n      return output\n[make_var definition]\n    def make_var( name, shape,is_training, initializer=None,regularizer=None):\n\n      return tf.get_variable(name, shape,initializer= initializer,regularizer=regularizer,trainable=is_training)", "body": "Sorry to bother, but i have trouble with the convolution in tensorflow.\r\n\r\nI am working with the network as below, input shape is [1,256,256,33], go through some convs, and after them i add a fully connected layer( not show in this picture). i fix the parameters of the convs, and try to train the fc layer.\r\n\r\nHowever, i found something weird... the network won't converge at all, so i only feed the network with one same input to test whether the network has any problem and print the output of each layer every iteration.\r\n\r\nand i found that the output of 'conv6' changes, though my net has been fixed.\r\n\r\nbut the output of 'conv5_1' doesn't change at all!....\r\n\r\nso i changed the stride of conv6... and when i change the stride of conv6 from 2 to 1, the output of conv6 doesn't change either.... So the net is very weird to me.... the stride of conv6 decides whether it changes?\r\n\r\nCould anyone help me? thanks!!!\r\n\r\n[my network ('is training' is false]\r\n```python\r\n    conv1 = conv(data, 3, 3, 64, 1, 1, name='conv1', is_training=is_training)\r\n    conv1_1 = conv(conv1, 3, 3, 64, 1, 1, name='conv1_1', is_training=is_training)\r\n    conv2 = conv(conv1_1, 3, 3, 128, 2, 2, name='conv2', is_training=is_training)\r\n    conv2_1 = conv(conv2, 3, 3, 128, 1, 1, name='conv2_1', is_training=is_training)    \r\n    conv3 = conv(conv2_1, 3, 3, 256, 2, 2, name='conv3', is_training=is_training)\r\n    conv3_1 = conv(conv3, 3, 3, 256, 1, 1, name='conv3_1', is_training=is_training)\r\n    conv4 = conv(conv3_1, 3, 3, 512, 2, 2, name='conv4', is_training=is_training)\r\n    conv4_1 = conv(conv4, 3, 3, 512, 1, 1, name='conv4_1', is_training=is_training)\r\n    conv5 = conv(conv4_1, 3, 3, 512, 2, 2, name='conv5', is_training=is_training)\r\n    conv5_1 = conv(conv5, 3, 3, 512, 1, 1, name='conv5_1', is_training=is_training)\r\n    conv6 = conv(conv5_1, 3, 3, 1024, 2, 2, name='conv6', is_training=is_training)\r\n```\r\n\r\n[the conv definition]\r\n```python\r\ndef conv(inputs,k_h,k_w,c_o,s_h,s_w,name,relu=True,padding='SAME',group=1,biased=True,is_training=False):\r\n\r\n    c_i = inputs.get_shape()[-1]\r\n    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\r\n    with tf.variable_scope(name) as scope:\r\n        \r\n      if is_training:\r\n        initializer = slim.xavier_initializer()\r\n        weights_regularizer = slim.l2_regularizer(5e-4)\r\n      else:\r\n        initializer = None\r\n        weights_regularizer = None\r\n\r\n      kernel = make_var('weights', shape=[k_h, k_w, c_i / group, c_o],is_training=is_training,initializer=initializer ,regularizer=weights_regularizer)\r\n\r\n      output = convolve(inputs, kernel)\r\n      if biased:\r\n        biases = make_var('biases', [c_o],is_training=is_training)\r\n        output = tf.nn.bias_add(output, biases)\r\n      if relu:\r\n        output= tf.nn.relu(output, name=scope.name)\r\n      return output\r\n```\r\n\r\n[make_var definition]\r\n```python\r\n    def make_var( name, shape,is_training, initializer=None,regularizer=None):\r\n\r\n      return tf.get_variable(name, shape,initializer= initializer,regularizer=regularizer,trainable=is_training)\r\n```"}