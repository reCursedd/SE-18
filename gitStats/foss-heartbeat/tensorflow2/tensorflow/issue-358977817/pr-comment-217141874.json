{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/217141874", "pull_request_review_id": 154785342, "id": 217141874, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNzE0MTg3NA==", "diff_hunk": "@@ -0,0 +1,763 @@\n+# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\n+\"\"\"Ignite Dataset.\"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import socket\n+import struct\n+import ssl\n+import abc\n+\n+from tensorflow.contrib.ignite.python.ops import ignite_op_loader  # pylint: disable=unused-import\n+from tensorflow.contrib.ignite.python.ops import gen_dataset_ops\n+from tensorflow.python.data.ops.dataset_ops import Dataset\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import ops\n+from tensorflow.python.framework import tensor_shape\n+\n+class Readable():\n+  \"\"\"Readable abstract class that exposes methods to do reading-related\n+     operations.\n+  \"\"\"\n+\n+  @abc.abstractmethod\n+  def __init__(self):\n+    pass\n+\n+  def read_byte(self):\n+    \"\"\"Reads and returnes byte.\"\"\"\n+    return self.__read(\"b\", 1)\n+\n+  def read_short(self):\n+    \"\"\"Reads and returns short (2 bytes, little-endian).\"\"\"\n+    return self.__read(\"h\", 2)\n+\n+  def read_int(self):\n+    \"\"\"Reads and returns int (4 bytes, little-endian).\"\"\"\n+    return self.__read(\"i\", 4)\n+\n+  def read_long(self):\n+    \"\"\"Reads and returns long (8 bytes, little-endian).\"\"\"\n+    return self.__read(\"q\", 8)\n+\n+  def skip(self, length):\n+    \"\"\"Skips the specified number of bytes.\"\"\"\n+    self.read_data(length)\n+\n+  @abc.abstractmethod\n+  def read_data(self, length):\n+    \"\"\"Reads the specified number of bytes and returns them as a buffer.\"\"\"\n+    return None\n+\n+  def __read(self, data_type, length):\n+    \"\"\"Reads, unpacks and returns specified type (little-endian).\"\"\"\n+    data_buffer = self.read_data(length)\n+    return struct.unpack(\"<\" + data_type, data_buffer)[0]\n+\n+class DataBuffer(Readable):\n+  \"\"\"DataBuffer class that exposes methods to read data from a byte buffer.\"\"\"\n+\n+  def __init__(self, data_buffer):\n+    \"\"\"Constructs a new instance of DataBuffer based on the specified byte\n+       buffer.\n+\n+    Args:\n+      buffer: Buffer to be read.\n+    \"\"\"\n+    Readable.__init__(self)\n+    self.buffer = data_buffer\n+    self.ptr = 0\n+\n+  def read_data(self, length):\n+    \"\"\"Reads the specified number of bytes and returns them as a buffer.\"\"\"\n+    data_buffer = self.buffer[self.ptr:][:length]\n+    self.ptr += length\n+    return data_buffer\n+\n+class TcpClient(Readable):\n+  \"\"\"TcpClient class that exposes methods to read data from a socket.\"\"\"\n+\n+  def __init__(self, host, port, certfile=None, keyfile=None, password=None):\n+    \"\"\"Constructs a new instance of TcpClient based on the specified host\n+       and port.\n+\n+    Args:\n+      host: Host to be connected.\n+      port: Port to be connected.\n+      certfile: File in PEM format containing the certificate as well as any\n+        number of CA certificates needed to establish the certificate\u2019s\n+        authenticity.\n+      keyfile: File containing the private key (otherwise the private key\n+        will be taken from certfile as well).\n+      password: Password to be used if the private key is encrypted and a\n+        password is necessary.\n+    \"\"\"\n+    Readable.__init__(self)\n+    self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n+\n+    if certfile is not None:\n+      context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n+      context.load_cert_chain(certfile, keyfile, password)\n+      self.sock = context.wrap_socket(self.sock)\n+    else:\n+      if keyfile is not None:\n+        raise Exception(\"SSL is disabled, keyfile must not be specified \\\n+          (to enable SSL specify certfile)\")\n+      if password is not None:\n+        raise Exception(\"SSL is disabled, password must not be specified \\\n+          (to enable SSL specify certfile)\")\n+\n+    self.host = host\n+    self.port = port\n+\n+  def __enter__(self):\n+    \"\"\"Connects to host and port specified in the constructor.\"\"\"\n+    self.sock.connect((self.host, self.port))\n+    return self\n+\n+  def __exit__(self, t, v, traceback):\n+    \"\"\"Disconnects the socket.\"\"\"\n+    self.sock.close()\n+\n+  def write_byte(self, v):\n+    \"\"\"Writes the specified byte.\"\"\"\n+    self.__write(v, \"b\")\n+\n+  def write_short(self, v):\n+    \"\"\"Writes the specified short (2 bytes, little-endian).\"\"\"\n+    self.__write(v, \"h\")\n+\n+  def write_int(self, v):\n+    \"\"\"Writes the specified short (4 bytes, little-endian).\"\"\"\n+    self.__write(v, \"i\")\n+\n+  def write_long(self, v):\n+    \"\"\"Writes the specified int (8 bytes, little-endian).\"\"\"\n+    self.__write(v, \"q\")\n+\n+  def write_string(self, v):\n+    \"\"\"Writes the specified string.\"\"\"\n+    self.sock.sendall(v.encode(\"UTF-8\"))\n+\n+  def read_data(self, length):\n+    \"\"\"Reads the specified number of bytes and returns them as a buffer.\"\"\"\n+    data_buffer = None\n+    rem = length\n+    while rem > 0:\n+      buf = self.sock.recv(rem)\n+      rem = rem - len(buf)\n+      if data_buffer is None:\n+        data_buffer = buf\n+      else:\n+        data_buffer += buf\n+    return data_buffer\n+\n+  def __write(self, value, data_type):\n+    \"\"\"Packs and writes data using the specified type (little-endian).\"\"\"\n+    data_buffer = struct.pack(\"<\" + data_type, value)\n+    self.sock.sendall(data_buffer)\n+\n+class BinaryType():\n+  \"\"\"BinaryType class that encapsulated type id, type name and fields.\"\"\"\n+\n+  def __init__(self, type_id, type_name, fields):\n+    \"\"\"Constructs a new instance of BinaryType.\"\"\"\n+    self.type_id = type_id\n+    self.type_name = type_name\n+    self.fields = fields\n+\n+class BinaryField():\n+  \"\"\"BinaryField class that encapsulated field name, type id and field id.\"\"\"\n+\n+  def __init__(self, field_name, type_id, field_id):\n+    \"\"\"Constructs a new instance of BinaryField.\"\"\"\n+    self.field_name = field_name\n+    self.type_id = type_id\n+    self.field_id = field_id\n+\n+# Binary types defined in Apache Ignite Thin client and supported by\n+# TensorFlow on Apache Ignite, see\n+# https://apacheignite.readme.io/v2.6/docs/binary-client-protocol.\n+types = {\n+    1: (dtypes.uint8, False),\n+    2: (dtypes.int16, False),\n+    3: (dtypes.int32, False),\n+    4: (dtypes.int64, False),\n+    5: (dtypes.float32, False),\n+    6: (dtypes.float64, False),\n+    7: (dtypes.uint16, False),\n+    8: (dtypes.bool, False),\n+    9: (dtypes.string, False),\n+    12: (dtypes.uint8, True),\n+    13: (dtypes.int16, True),\n+    14: (dtypes.int32, True),\n+    15: (dtypes.int64, True),\n+    16: (dtypes.float32, True),\n+    17: (dtypes.float64, True),\n+    18: (dtypes.uint16, True),\n+    19: (dtypes.bool, True),\n+    20: (dtypes.string, True)\n+}\n+\n+class TypeTreeNode():\n+  \"\"\"TypeTreeNode class exposes methods to format object tree structure\n+     data.\n+  \"\"\"\n+  def __init__(self, name, type_id, fields=None, permutation=None):\n+    \"\"\"Constructs a new instance of TypeTreeNode.\n+\n+    Args:\n+      name: Name of the object tree node.\n+      type_id: Type id of the object tree node.\n+      fields: List of fields (children of the object tree node).\n+      permutation: Permutation that should be applied to order object children.\n+    \"\"\"\n+    self.name = name\n+    self.type_id = type_id\n+    self.fields = fields\n+    self.permutation = permutation\n+\n+  def to_output_classes(self):\n+    \"\"\"Formats the tree object the way required in 'output_classes' property of\n+       dataset.\n+    \"\"\"\n+    if self.fields is None:\n+      return ops.Tensor\n+    output_classes = {}\n+    for field in self.fields:\n+      output_classes[field.name] = field.to_output_classes()\n+    return output_classes\n+\n+  def to_output_shapes(self):\n+    \"\"\"Formats the tree object the way required in 'output_shapes' property of\n+       dataset.\n+    \"\"\"\n+    if self.fields is None:\n+      object_type = types[self.type_id]\n+      if object_type is not None:\n+        is_array = object_type[1]\n+        if is_array:\n+          return tensor_shape.TensorShape([None])\n+        return tensor_shape.TensorShape([])\n+      raise Exception(\"Unsupported type [type_id=%d]\" % self.type_id)\n+    output_shapes = {}\n+    for field in self.fields:\n+      output_shapes[field.name] = field.to_output_shapes()\n+    return output_shapes\n+\n+  def to_output_types(self):\n+    \"\"\"Formats the tree object the way required in 'output_types' property of\n+       dataset.\n+    \"\"\"\n+    if self.fields is None:\n+      object_type = types[self.type_id]\n+      if object_type is not None:\n+        return object_type[0]\n+      raise Exception(\"Unsupported type [type_id=%d]\" % self.type_id)\n+    else:\n+      output_types = {}\n+      for field in self.fields:\n+        output_types[field.name] = field.to_output_types()\n+      return output_types\n+\n+  def to_flat(self):\n+    \"\"\"Returns a list of leaf node types.\"\"\"\n+    return self.to_flat_rec([])\n+\n+  def to_permutation(self):\n+    \"\"\"Returns a permutation that should be applied to order object leafs.\"\"\"\n+    correct_order_dict = {}\n+    self.traversal_rec(correct_order_dict, 0)\n+    object_order = []\n+    self.traversal_permutation_rec(object_order)\n+    return [correct_order_dict[o] for o in object_order]\n+\n+  def to_flat_rec(self, flat):\n+    \"\"\"Formats a list of leaf node types.\"\"\"\n+    flat.append(self.type_id)\n+    if self.fields is not None:\n+      for field in self.fields:\n+        field.to_flat_rec(flat)\n+    return flat\n+\n+  def traversal_permutation_rec(self, permutation):\n+    \"\"\"Collects nodes in accordance with permutation.\"\"\"\n+    if self.fields is None:\n+      permutation.append(self)\n+    else:\n+      for idx in self.permutation:\n+        field = self.fields[idx]\n+        field.traversal_permutation_rec(permutation)\n+\n+  def traversal_rec(self, d, i):\n+    \"\"\"Collects nodes in pre-order traversal.\"\"\"\n+    if self.fields is None:\n+      d[self] = i\n+      i += 1\n+    else:\n+      for field in self.fields:\n+        i = field.traversal_rec(d, i)\n+    return i\n+\n+class IgniteClient(TcpClient):\n+  \"\"\"IgniteClient class exposes methods to work with Apache Ignite using Thin\n+     client. This client works with assumption that all object in the cache\n+     have the same structure (homogeneous objects) and the cache contains at\n+     least one object.\n+  \"\"\"\n+  def __init__(self, host, port, username=None, password=None, certfile=None,\\\n+    keyfile=None, cert_password=None):\n+    \"\"\"Constructs a new instance of IgniteClient.\n+\n+    Args:\n+      host: Apache Ignite Thin client host to be connected.\n+      port: Apache Ignite Thin client port to be connected.\n+      username: Apache Ignite Thin Client authentication username.\n+      password: Apache Ignite Thin Client authentication password.\n+      certfile: File in PEM format containing the certificate as well as\n+        any number of CA certificates needed to establish the certificate\u2019s\n+        authenticity.\n+      keyfile: File containing the private key (otherwise the private key\n+        will be taken from certfile as well).\n+      cert_password: Password to be used if the private key is encrypted and a\n+        password is necessary.\n+    \"\"\"\n+    TcpClient.__init__(self, host, port, certfile, keyfile, cert_password)\n+    self.username = username\n+    self.password = password\n+\n+  def handshake(self):\n+    \"\"\"Makes a handshake required to be made after connect before any other\n+       calls.\n+    \"\"\"\n+    msg_len = 8\n+\n+    if self.username is None:\n+      msg_len += 1\n+    else:\n+      msg_len += 5 + len(self.username)\n+\n+    if self.password is None:\n+      msg_len += 1\n+    else:\n+      msg_len += 5 + len(self.password)\n+\n+    self.write_int(msg_len)   # Message length\n+    self.write_byte(1)        # Handshake operation\n+    self.write_short(1)       # Version (1.1.0)\n+    self.write_short(1)\n+    self.write_short(0)\n+    self.write_byte(2)        # Thin client\n+\n+    if self.username is None: # Username\n+      self.write_byte(101)\n+    else:\n+      self.write_byte(9)\n+      self.write_int(len(self.username))\n+      self.write_string(self.username)\n+\n+    if self.password is None: # Password\n+      self.write_byte(101)\n+    else:\n+      self.write_byte(9)\n+      self.write_int(len(self.password))\n+      self.write_string(self.password)\n+\n+    self.read_int()           # Result length\n+    res = self.read_byte()\n+\n+    if res != 1:\n+      serv_ver_major = self.read_short()\n+      serv_ver_minor = self.read_short()\n+      serv_ver_patch = self.read_short()\n+      err_msg = self.__parse_string()\n+      if err_msg is None:\n+        raise Exception(\"Handshake Error [result=%d, version=%d.%d.%d]\" \\\n+            % (res, serv_ver_major, serv_ver_minor, serv_ver_patch))\n+      else:\n+        raise Exception(\"Handshake Error [result=%d, version=%d.%d.%d, \\\n+            message='%s']\" % (\n+                res,\n+                serv_ver_major,\n+                serv_ver_minor,\n+                serv_ver_patch,\n+                err_msg\n+            ))\n+\n+  def get_cache_type(self, cache_name):\n+    \"\"\"Collects type information about objects stored in the specified\n+       cache.\n+    \"\"\"\n+    cache_name_hash = self.__java_hash_code(cache_name)\n+    self.write_int(25)        # Message length\n+    self.write_short(2000)      # Operation code\n+    self.write_long(0)        # Request ID\n+    self.write_int(cache_name_hash) # Cache name\n+    self.write_byte(0)        # Flags\n+    self.write_byte(101)      # Filter (NULL)\n+    self.write_int(1)         # Cursor page size\n+    self.write_int(-1)        # Partition to query\n+    self.write_byte(0)        # Local flag\n+\n+    result_length = self.read_int()\n+    self.read_long()          # Request id\n+    status = self.read_int()\n+\n+    if status != 0:\n+      err_msg = self.__parse_string()\n+      if err_msg is None:\n+        raise Exception(\"Scan Query Error [status=%s]\" % status)\n+      else:\n+        raise Exception(\"Scan Query Error [status=%s, message='%s']\" \\\n+            % (status, err_msg))\n+\n+    self.read_long()          # Cursor id\n+    row_count = self.read_int()\n+\n+    if row_count == 0:\n+      raise Exception(\"Scan Query returned empty result, so it's \\\n+        impossible to derive the cache type\")\n+\n+    payload = DataBuffer(self.read_data(result_length - 25))\n+\n+    self.read_byte()          # Next page\n+\n+    res = TypeTreeNode(\"root\", 0, [\n+        self.__collect_types(\"key\", payload),\n+        self.__collect_types(\"val\", payload)\n+    ], [0, 1])\n+\n+    return res\n+\n+  def __java_hash_code(self, s):\n+    \"\"\"Computes hash code of the specified string using Java code.\"\"\"\n+    h = 0\n+    for c in s:\n+      h = (31 * h + ord(c)) & 0xFFFFFFFF\n+    return ((h + 0x80000000) & 0xFFFFFFFF) - 0x80000000\n+\n+  def __collect_types(self, field_name, data):\n+    \"\"\"Extracts type information from the specified object.\"\"\"\n+    type_id = data.read_byte()\n+\n+    # Byte scalar.\n+    if type_id == 1:\n+      data.skip(1)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Short scalar.\n+    if type_id == 2:\n+      data.skip(2)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Integer scalar.\n+    if type_id == 3:\n+      data.skip(4)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Long scalar.\n+    if type_id == 4:\n+      data.skip(8)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Float scalar.\n+    if type_id == 5:\n+      data.skip(4)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Double scalar.\n+    if type_id == 6:\n+      data.skip(8)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Char scalar.\n+    if type_id == 7:\n+      data.skip(2)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Bool scalar.\n+    if type_id == 8:\n+      data.skip(1)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # String scalar.\n+    if type_id == 9:\n+      length = data.read_int()\n+      data.skip(length)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # UUID scalar.\n+    if type_id == 10:\n+      data.skip(16)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Date scalar.\n+    if type_id == 11:\n+      data.skip(8)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Byte array.\n+    if type_id == 12:\n+      length = data.read_int()\n+      data.skip(length)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Short array.\n+    if type_id == 13:\n+      length = data.read_int()\n+      data.skip(length * 2)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Integer array.\n+    if type_id == 14:\n+      length = data.read_int()\n+      data.skip(length * 4)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Long array.\n+    if type_id == 15:\n+      length = data.read_int()\n+      data.skip(length * 8)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Float array.\n+    if type_id == 16:\n+      length = data.read_int()\n+      data.skip(length * 4)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Double array.\n+    if type_id == 17:\n+      length = data.read_int()\n+      data.skip(length * 8)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Char array.\n+    if type_id == 18:\n+      length = data.read_int()\n+      data.skip(length * 2)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Bool array.\n+    if type_id == 19:\n+      length = data.read_int()\n+      data.skip(length)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # String array.\n+    if type_id == 20:\n+      length = data.read_int()\n+      for _ in range(length):\n+        header = data.read_byte()\n+        if header == 9:\n+          str_length = data.read_int()\n+          data.skip(str_length)\n+        elif header == 101:\n+          pass\n+        else:\n+          raise Exception(\"Unknown binary type when expected string \\\n+            [type_id=%d]\" % header)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # UUID array.\n+    if type_id == 21:\n+      length = data.read_int()\n+      data.skip(length * 16) # TODO: support NULL values.\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Date array.\n+    if type_id == 22:\n+      length = data.read_int()\n+      data.skip(length * 8)\n+      return TypeTreeNode(field_name, type_id)\n+\n+    # Wrapped Binary Object.\n+    if type_id == 27:\n+      length = data.read_int()\n+      inner_data = data.read_data(length)\n+      data.read_int()   # Offset\n+      return self.__collect_types(field_name, DataBuffer(inner_data))\n+\n+    # Complex Object.\n+    if type_id == 103:\n+      data.read_byte()  # Object version\n+      data.read_short() # Object flags\n+      obj_type_id = data.read_int()\n+      data.read_int()   # Object hash code\n+      obj_length = data.read_int()\n+      data.read_int()   # Object schema id\n+      obj_schema_offset = data.read_int()\n+\n+      obj_type = self.__get_type(obj_type_id)\n+      children = []\n+\n+      for obj_field in obj_type.fields:\n+        child = self.__collect_types(obj_field.field_name, data)\n+        children.append(child)\n+\n+      children_sorted = sorted(children, key=lambda child: child.name)\n+      permutation = [children_sorted.index(child) for child in children]\n+      children = children_sorted\n+\n+      data.skip(obj_length - obj_schema_offset)\n+\n+      return TypeTreeNode(field_name, type_id, children, permutation)\n+\n+    raise Exception(\"Unknown binary type [type_id=%d]\" % type_id)\n+\n+  def __get_type(self, type_id):\n+    \"\"\"Queries Apache Ignite information about type by type id.\"\"\"\n+    self.write_int(14)      # Message length\n+    self.write_short(3002)  # Operation code\n+    self.write_long(0)      # Request ID\n+    self.write_int(type_id) # Type ID\n+\n+    self.read_int()         # Result length\n+    self.read_long()        # Request id\n+    status = self.read_int()\n+\n+    if status != 0:\n+      err_msg = self.__parse_string()\n+      if err_msg is None:\n+        raise Exception(\"Get Binary Type Error [status=%d, message='%s']\" \\\n+            % (status, err_msg))\n+      else:\n+        raise Exception(\"Get Binary Type Error [status=%d]\" % status)\n+\n+    binary_type_exists = self.read_byte()\n+\n+    if binary_type_exists == 0:\n+      raise Exception(\"Binary type not found [type_id=%d] \" % type_id)\n+\n+    binary_type_id = self.read_int()\n+    binary_type_name = self.__parse_string()\n+    self.__parse_string()   # Affinity field name\n+\n+    fields = []\n+    for _ in range(self.read_int()):\n+      field_name = self.__parse_string()\n+      field_type_id = self.read_int()\n+      field_id = self.read_int()\n+\n+      field = BinaryField(field_name, field_type_id, field_id)\n+      fields.append(field)\n+\n+    is_enum = self.read_byte()\n+    if is_enum == 1:\n+      raise Exception(\"Enum fields are not supported yet\")\n+\n+    schema_cnt = self.read_int()\n+    for _ in range(schema_cnt):\n+      self.read_int()       # Schema id\n+      field_cnt = self.read_int()\n+      self.skip(field_cnt * 4)\n+\n+    return BinaryType(binary_type_id, binary_type_name, fields)\n+\n+  def __parse_string(self):\n+    \"\"\"Parses string.\"\"\"\n+    header = self.read_byte()\n+    if header == 9:\n+      length = self.read_int()\n+      return self.read_data(length).decode(\"utf-8\")\n+    if header == 101:\n+      return None\n+    raise Exception(\"Unknown binary type when expected string [type_id=%d]\" \\\n+        % header)\n+\n+class IgniteDataset(Dataset):\n+  \"\"\"Apache Ignite is a memory-centric distributed database, caching, and\n+     processing platform for transactional, analytical, and streaming workloads,\n+     delivering in-memory speeds at petabyte scale. This contrib package\n+     contains an integration between Apache Ignite and TensorFlow. The\n+     integration is based on tf.data from TensorFlow side and Binary Client\n+     Protocol from Apache Ignite side. It allows to use Apache Ignite as a\n+     datasource for neural network training, inference and all other\n+     computations supported by TensorFlow. Ignite Dataset is based on Apache\n+     Ignite Binary Client Protocol.\n+  \"\"\"\n+\n+  def __init__(self, cache_name, host=\"localhost\", port=10800, local=False,\\\n+    part=-1, page_size=100, username=None, password=None, certfile=None,\\\n+    keyfile=None, cert_password=None):\n+    \"\"\"Create a IgniteDataset.\n+\n+    Args:\n+      cache_name: Cache name to be used as datasource.\n+      host: Apache Ignite Thin Client host to be connected.\n+      port: Apache Ignite Thin Client port to be connected.\n+      local: Local flag that defines to query only local data.\n+      part: Number of partitions to be queried.\n+      page_size: Apache Ignite Thin Client page size.\n+      username: Apache Ignite Thin Client authentication username.\n+      password: Apache Ignite Thin Client authentication password.\n+      certfile: File in PEM format containing the certificate as well as\n+        any number of CA certificates needed to establish the certificate\u2019s\n+        authenticity.\n+      keyfile: File containing the private key (otherwise the private key\n+        will be taken from certfile as well).\n+      cert_password: Password to be used if the private key is encrypted and a\n+        password is necessary.\n+    \"\"\"\n+    super(IgniteDataset, self).__init__()\n+\n+    with IgniteClient(host, port, username, password, certfile, keyfile,\\\n+        cert_password) as client:\n+      client.handshake()\n+      self.cache_type = client.get_cache_type(cache_name)\n+\n+    self.cache_name = ops.convert_to_tensor(cache_name, dtype=dtypes.string,\\\n+        name=\"cache_name\")\n+    self.host = ops.convert_to_tensor(host, dtype=dtypes.string, name=\"host\")\n+    self.port = ops.convert_to_tensor(port, dtype=dtypes.int32, name=\"port\")\n+    self.local = ops.convert_to_tensor(local, dtype=dtypes.bool, name=\"local\")\n+    self.part = ops.convert_to_tensor(part, dtype=dtypes.int32, name=\"part\")\n+    self.page_size = ops.convert_to_tensor(page_size, dtype=dtypes.int32,\\\n+        name=\"page_size\")\n+    self.username = ops.convert_to_tensor(\"\" if username is None else username,\\\n+        dtype=dtypes.string, name=\"username\")\n+    self.password = ops.convert_to_tensor(\"\" if password is None else password,\\", "path": "tensorflow/contrib/ignite/python/ops/ignite_dataset_ops.py", "position": null, "original_position": 734, "commit_id": "90c68770467701a23d23a85c5d769f6f4fa39f0f", "original_commit_id": "0b6654bc223f4f3807209043dc34ccb07b55474e", "user": {"login": "dmitrievanthony", "id": 1028969, "node_id": "MDQ6VXNlcjEwMjg5Njk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1028969?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dmitrievanthony", "html_url": "https://github.com/dmitrievanthony", "followers_url": "https://api.github.com/users/dmitrievanthony/followers", "following_url": "https://api.github.com/users/dmitrievanthony/following{/other_user}", "gists_url": "https://api.github.com/users/dmitrievanthony/gists{/gist_id}", "starred_url": "https://api.github.com/users/dmitrievanthony/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dmitrievanthony/subscriptions", "organizations_url": "https://api.github.com/users/dmitrievanthony/orgs", "repos_url": "https://api.github.com/users/dmitrievanthony/repos", "events_url": "https://api.github.com/users/dmitrievanthony/events{/privacy}", "received_events_url": "https://api.github.com/users/dmitrievanthony/received_events", "type": "User", "site_admin": false}, "body": "It's not necessary, but it's the simple way to start using.\r\n\r\nWe provide two ways to specify these parameters: via parameters of dataset or via environment variables on the nodes where dataset will be actually instantiated. As far as I understand, in the second case sensitive information won't be included into `GraphDef` and passed via insecure channels.", "created_at": "2018-09-12T18:30:06Z", "updated_at": "2018-09-24T09:16:00Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22210#discussion_r217141874", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22210", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/217141874"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22210#discussion_r217141874"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22210"}}, "body_html": "<p>It's not necessary, but it's the simple way to start using.</p>\n<p>We provide two ways to specify these parameters: via parameters of dataset or via environment variables on the nodes where dataset will be actually instantiated. As far as I understand, in the second case sensitive information won't be included into <code>GraphDef</code> and passed via insecure channels.</p>", "body_text": "It's not necessary, but it's the simple way to start using.\nWe provide two ways to specify these parameters: via parameters of dataset or via environment variables on the nodes where dataset will be actually instantiated. As far as I understand, in the second case sensitive information won't be included into GraphDef and passed via insecure channels.", "in_reply_to_id": 216720596}