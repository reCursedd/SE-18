{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/357868465", "html_url": "https://github.com/tensorflow/tensorflow/issues/14964#issuecomment-357868465", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14964", "id": 357868465, "node_id": "MDEyOklzc3VlQ29tbWVudDM1Nzg2ODQ2NQ==", "user": {"login": "facaiy", "id": 1112263, "node_id": "MDQ6VXNlcjExMTIyNjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1112263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/facaiy", "html_url": "https://github.com/facaiy", "followers_url": "https://api.github.com/users/facaiy/followers", "following_url": "https://api.github.com/users/facaiy/following{/other_user}", "gists_url": "https://api.github.com/users/facaiy/gists{/gist_id}", "starred_url": "https://api.github.com/users/facaiy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/facaiy/subscriptions", "organizations_url": "https://api.github.com/users/facaiy/orgs", "repos_url": "https://api.github.com/users/facaiy/repos", "events_url": "https://api.github.com/users/facaiy/events{/privacy}", "received_events_url": "https://api.github.com/users/facaiy/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-16T06:48:12Z", "updated_at": "2018-01-16T06:54:54Z", "author_association": "MEMBER", "body_html": "<p>Hi, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8024096\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/chaihua483\">@chaihua483</a> . <code>SparseReduceSumSparse</code> behaves the same way with <code>SparseReduceSum</code>, so their gradient implementations are almost same. However, since <code>gather_nd</code> doesn't support <code>SparseTensor</code>, I cannot find an efficient way to gather values from its <code>out_grad[1]</code>.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a>  The only one solution I can think of is to implement the gradient op in C++ side. Is it worthwhile to do that?</p>\n<p>Above all, I suggest you to use <code>SparseReduceSum</code> if you need gradient calculation. Please correct me if I'm wrong.</p>", "body_text": "Hi, @chaihua483 . SparseReduceSumSparse behaves the same way with SparseReduceSum, so their gradient implementations are almost same. However, since gather_nd doesn't support SparseTensor, I cannot find an efficient way to gather values from its out_grad[1].\n@aselle  The only one solution I can think of is to implement the gradient op in C++ side. Is it worthwhile to do that?\nAbove all, I suggest you to use SparseReduceSum if you need gradient calculation. Please correct me if I'm wrong.", "body": "Hi, @chaihua483 . `SparseReduceSumSparse` behaves the same way with `SparseReduceSum`, so their gradient implementations are almost same. However, since `gather_nd` doesn't support `SparseTensor`, I cannot find an efficient way to gather values from its `out_grad[1]`. \r\n\r\n@aselle  The only one solution I can think of is to implement the gradient op in C++ side. Is it worthwhile to do that? \r\n\r\nAbove all, I suggest you to use `SparseReduceSum` if you need gradient calculation. Please correct me if I'm wrong."}