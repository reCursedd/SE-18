{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16721", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16721/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16721/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16721/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16721", "id": 294093564, "node_id": "MDU6SXNzdWUyOTQwOTM1NjQ=", "number": 16721, "title": "Customized loss in keras", "user": {"login": "ymcasky", "id": 6229000, "node_id": "MDQ6VXNlcjYyMjkwMDA=", "avatar_url": "https://avatars0.githubusercontent.com/u/6229000?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymcasky", "html_url": "https://github.com/ymcasky", "followers_url": "https://api.github.com/users/ymcasky/followers", "following_url": "https://api.github.com/users/ymcasky/following{/other_user}", "gists_url": "https://api.github.com/users/ymcasky/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymcasky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymcasky/subscriptions", "organizations_url": "https://api.github.com/users/ymcasky/orgs", "repos_url": "https://api.github.com/users/ymcasky/repos", "events_url": "https://api.github.com/users/ymcasky/events{/privacy}", "received_events_url": "https://api.github.com/users/ymcasky/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-02-03T08:08:05Z", "updated_at": "2018-02-07T02:49:48Z", "closed_at": "2018-02-07T00:25:52Z", "author_association": "NONE", "body_html": "<p>Dear all,</p>\n<p>I can run properly with the following code:</p>\n<h3>System Information</h3>\n<p>Have I written custom code : As following<br>\nOS Platform and Distribution: Linux Ubuntu16.04<br>\nTensorFlow installed from : conda script<br>\nTensorFlow version : '1.4.0'<br>\nBazel version : N/A<br>\nCUDA/cuDNN version : CUDA8.0, cudnn6.0<br>\nGPU model and memory : 1070/8G</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras.backend import categorical_crossentropy\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.layers import  Input\n\nmnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\nimg_size_flat = 28*28\nbatch_size = 64\n\ndef gen(batch_size=32):\n    while True:\n        batch_data, batch_label = mnist_data.train.next_batch(batch_size)\n        yield batch_data, batch_label   \n\n\ninputs = Input(shape=(img_size_flat,))\nx = Dense(128, activation='relu')(inputs)  # fully-connected layer with 128 units and ReLU activation\nx = Dense(128, activation='relu')(x)\npreds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation\nmodel = Model(inputs=inputs, outputs=preds)\n\nmodel.compile(optimizer='rmsprop',\n               loss='categorical_crossentropy',\n               metrics=['accuracy'])\n\n\nmodel.fit_generator(gen(batch_size), steps_per_epoch=len(mnist_data.train.labels)//batch_size, epochs=2)\n</code></pre>\n<p>But if I want to write loss function with my own code like:</p>\n<pre><code>preds_softmax = tf.nn.softmax(preds)\nstep1 = tf.cast(y_true, tf.float32) * tf.log(preds_softmax)\nstep2 = -tf.reduce_sum(step1, reduction_indices=[1])\nloss = tf.reduce_mean(step2)       # loss\n</code></pre>\n<p>Is something like the following code on tensorflow?</p>\n<pre><code>inputs = tf.placeholder(tf.float32, shape=(None, 784))\nx = Dense(128, activation='relu')(inputs) # fully-connected layer with 128 units and ReLU activation\nx = Dense(128, activation='relu')(x)\npreds = Dense(10, activation='softmax')(x) # output layer with 10 units and a softmax activation\n\ny_true = tf.placeholder(tf.float32, shape=(None, 10))\n</code></pre>\n<p>How can I do based on above code(part I)? Thanks for any help!!</p>", "body_text": "Dear all,\nI can run properly with the following code:\nSystem Information\nHave I written custom code : As following\nOS Platform and Distribution: Linux Ubuntu16.04\nTensorFlow installed from : conda script\nTensorFlow version : '1.4.0'\nBazel version : N/A\nCUDA/cuDNN version : CUDA8.0, cudnn6.0\nGPU model and memory : 1070/8G\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras.backend import categorical_crossentropy\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.layers import  Input\n\nmnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\nimg_size_flat = 28*28\nbatch_size = 64\n\ndef gen(batch_size=32):\n    while True:\n        batch_data, batch_label = mnist_data.train.next_batch(batch_size)\n        yield batch_data, batch_label   \n\n\ninputs = Input(shape=(img_size_flat,))\nx = Dense(128, activation='relu')(inputs)  # fully-connected layer with 128 units and ReLU activation\nx = Dense(128, activation='relu')(x)\npreds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation\nmodel = Model(inputs=inputs, outputs=preds)\n\nmodel.compile(optimizer='rmsprop',\n               loss='categorical_crossentropy',\n               metrics=['accuracy'])\n\n\nmodel.fit_generator(gen(batch_size), steps_per_epoch=len(mnist_data.train.labels)//batch_size, epochs=2)\n\nBut if I want to write loss function with my own code like:\npreds_softmax = tf.nn.softmax(preds)\nstep1 = tf.cast(y_true, tf.float32) * tf.log(preds_softmax)\nstep2 = -tf.reduce_sum(step1, reduction_indices=[1])\nloss = tf.reduce_mean(step2)       # loss\n\nIs something like the following code on tensorflow?\ninputs = tf.placeholder(tf.float32, shape=(None, 784))\nx = Dense(128, activation='relu')(inputs) # fully-connected layer with 128 units and ReLU activation\nx = Dense(128, activation='relu')(x)\npreds = Dense(10, activation='softmax')(x) # output layer with 10 units and a softmax activation\n\ny_true = tf.placeholder(tf.float32, shape=(None, 10))\n\nHow can I do based on above code(part I)? Thanks for any help!!", "body": "Dear all,\r\n\r\nI can run properly with the following code:\r\n### System Information ####\r\nHave I written custom code : As following\r\nOS Platform and Distribution: Linux Ubuntu16.04\r\nTensorFlow installed from : conda script\r\nTensorFlow version : '1.4.0'\r\nBazel version : N/A\r\nCUDA/cuDNN version : CUDA8.0, cudnn6.0\r\nGPU model and memory : 1070/8G\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.layers import Dense\r\nfrom tensorflow.python.keras.backend import categorical_crossentropy\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.layers import  Input\r\n\r\nmnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\r\nimg_size_flat = 28*28\r\nbatch_size = 64\r\n\r\ndef gen(batch_size=32):\r\n    while True:\r\n        batch_data, batch_label = mnist_data.train.next_batch(batch_size)\r\n        yield batch_data, batch_label   \r\n\r\n\r\ninputs = Input(shape=(img_size_flat,))\r\nx = Dense(128, activation='relu')(inputs)  # fully-connected layer with 128 units and ReLU activation\r\nx = Dense(128, activation='relu')(x)\r\npreds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation\r\nmodel = Model(inputs=inputs, outputs=preds)\r\n\r\nmodel.compile(optimizer='rmsprop',\r\n               loss='categorical_crossentropy',\r\n               metrics=['accuracy'])\r\n\r\n\r\nmodel.fit_generator(gen(batch_size), steps_per_epoch=len(mnist_data.train.labels)//batch_size, epochs=2)\r\n```\r\n\r\nBut if I want to write loss function with my own code like:\r\n```\r\npreds_softmax = tf.nn.softmax(preds)\r\nstep1 = tf.cast(y_true, tf.float32) * tf.log(preds_softmax)\r\nstep2 = -tf.reduce_sum(step1, reduction_indices=[1])\r\nloss = tf.reduce_mean(step2)       # loss\r\n```\r\n\r\nIs something like the following code on tensorflow?\r\n```\r\ninputs = tf.placeholder(tf.float32, shape=(None, 784))\r\nx = Dense(128, activation='relu')(inputs) # fully-connected layer with 128 units and ReLU activation\r\nx = Dense(128, activation='relu')(x)\r\npreds = Dense(10, activation='softmax')(x) # output layer with 10 units and a softmax activation\r\n\r\ny_true = tf.placeholder(tf.float32, shape=(None, 10))\r\n```\r\n\r\nHow can I do based on above code(part I)? Thanks for any help!!\r\n"}