{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6520", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6520/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6520/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6520/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6520", "id": 197708902, "node_id": "MDU6SXNzdWUxOTc3MDg5MDI=", "number": 6520, "title": "Interesting phenomenon when running cifar10_train.py and cifar10_multi_gpu_train.py", "user": {"login": "shixiazuike", "id": 7998316, "node_id": "MDQ6VXNlcjc5OTgzMTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/7998316?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shixiazuike", "html_url": "https://github.com/shixiazuike", "followers_url": "https://api.github.com/users/shixiazuike/followers", "following_url": "https://api.github.com/users/shixiazuike/following{/other_user}", "gists_url": "https://api.github.com/users/shixiazuike/gists{/gist_id}", "starred_url": "https://api.github.com/users/shixiazuike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shixiazuike/subscriptions", "organizations_url": "https://api.github.com/users/shixiazuike/orgs", "repos_url": "https://api.github.com/users/shixiazuike/repos", "events_url": "https://api.github.com/users/shixiazuike/events{/privacy}", "received_events_url": "https://api.github.com/users/shixiazuike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-12-27T14:15:53Z", "updated_at": "2017-01-17T19:20:38Z", "closed_at": "2017-01-17T19:20:38Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System:</p>\n<div class=\"highlight highlight-source-shell\"><pre> centos 7 </pre></div>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-smi\">$ls</span> -l /usr/local/cuda/lib64/libcud<span class=\"pl-k\">*</span></pre></div>\n<p>here is the result</p>\n<div class=\"highlight highlight-source-shell\"><pre>  548 -rw-r--r-- 1 root root   558720 Dec  7 21:02 /usr/local/cuda/lib64/libcudadevrt.a\n    0 lrwxrwxrwx 1 root root       16 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so -<span class=\"pl-k\">&gt;</span> libcudart.so.8.0\n    0 lrwxrwxrwx 1 root root       19 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0 -<span class=\"pl-k\">&gt;</span> libcudart.so.8.0.44\n  408 -rwxr-xr-x 1 root root   415432 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\n  760 -rw-r--r-- 1 root root   775162 Dec  7 21:02 /usr/local/cuda/lib64/libcudart_static.a\n    0 lrwxrwxrwx 1 root root       13 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so -<span class=\"pl-k\">&gt;</span> libcudnn.so.5\n    0 lrwxrwxrwx 1 root root       17 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so.5 -<span class=\"pl-k\">&gt;</span> libcudnn.so.5.1.5\n77480 -rwxr-xr-x 1 root root 79337624 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n68124 -rw-r--r-- 1 root root 69756172 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn_static.a</pre></div>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:<br>\nI install tensorflow using pip with command from pypi</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>$ pip install tensorflow-gpu </pre></div>\n<ol start=\"2\">\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n0.12.0</pre></div>\n<h3>Phenomenon</h3>\n<h4>Performance of cifar10 model on GPU</h4>\n<p>When running cifar10_train.py, I tried 2000 steps with batch_size 128</p>\n<div class=\"highlight highlight-source-shell\"><pre>python cifar10_train.py --data_dir ../datasets/cifar10 --batch_size 128 --max_steps 2000</pre></div>\n<p>Then elasped time on a Telsa M40 graphics card is</p>\n<div class=\"highlight highlight-source-shell\"><pre>Elasped Time: 167.51s</pre></div>\n<p>Here is the speed running cifar10_multi_gpu_train.py with different number of GPUs on my machine (max_steps=2000, batch_size=128)</p>\n<table>\n<thead>\n<tr>\n<th>System</th>\n<th>Examples per sec</th>\n<th>Step Time (sec/batch)</th>\n<th>Elasped Time (sec)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1 Tesla M40</td>\n<td>1300 ~ 2400</td>\n<td>0.05 ~ 0.10</td>\n<td>157.96</td>\n</tr>\n<tr>\n<td>2 Tesla M40</td>\n<td>2700 ~ 3700</td>\n<td>0.03 ~ 0.04</td>\n<td>164.49</td>\n</tr>\n<tr>\n<td>4 Tesla M40</td>\n<td>3900 ~ 6300</td>\n<td>0,02 ~ 0.03</td>\n<td>231.98</td>\n</tr>\n<tr>\n<td>8 Tesla M40</td>\n<td>3700 ~ 6700</td>\n<td>0.02 ~ 0.04</td>\n<td>431.54</td>\n</tr>\n</tbody>\n</table>\n<p>The performance improves as the number of GPUs increases.</p>\n<h4>Performance when moving distorted_inputs to cpu</h4>\n<p>I made some changes on cifar10_train.py and cifar10_muti_gpu_train.py</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> cifar10_train.py</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train</span>():\n    <span class=\"pl-k\">with</span> tf.Graph().as_default():\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Here is what I modified</span>\n         <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/cpu:0<span class=\"pl-pds\">\"</span></span>):\n            images, labels <span class=\"pl-k\">=</span> cifar10.distorted_inputs()</pre></div>\n<p>I put function distorted_inputs on cpu, and then the performace is much better than before</p>\n<div class=\"highlight highlight-source-shell\"><pre>Elasped Time: 42.92s</pre></div>\n<p>I made the same change on cifar10_multi_gpu_train.py</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> cifar10_multi_gpu_train.py</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">tower_loss</span>(<span class=\"pl-smi\">scope</span>, <span class=\"pl-smi\">images</span>, <span class=\"pl-smi\">labels</span>):\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Get images and labels for CIFAR-10.</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Commented</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span>images, labels = cifar10.distorted_inputs()</span>\n\n  logits <span class=\"pl-k\">=</span> cifar10.inference(images)\n\n  _ <span class=\"pl-k\">=</span> cifar10.loss(logits, labels)\n  losses <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>losses<span class=\"pl-pds\">'</span></span>, scope)\n  total_loss <span class=\"pl-k\">=</span> tf.add_n(losses, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>total_loss<span class=\"pl-pds\">'</span></span>)\n\n  <span class=\"pl-k\">for</span> l <span class=\"pl-k\">in</span> losses <span class=\"pl-k\">+</span> [total_loss]:\n    loss_name <span class=\"pl-k\">=</span> re.sub(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%s</span>_[0-9]*/<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> cifar10.<span class=\"pl-c1\">TOWER_NAME</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>, l.op.name)\n    tf.scalar_summary(loss_name, l)\n\n  <span class=\"pl-k\">return</span> total_loss\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train</span>():\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Train CIFAR-10 for a number of steps.<span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-k\">with</span> tf.Graph().as_default(), tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n    global_step <span class=\"pl-k\">=</span> tf.get_variable(\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>global_step<span class=\"pl-pds\">'</span></span>, [],\n        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-c1\">0</span>), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n    <span class=\"pl-c1\">...</span>build optimizer<span class=\"pl-c1\">...</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Calculate the gradients for each model tower.</span>\n    tower_grads <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">FLAGS</span>.num_gpus):\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> move distorted_inputs to here</span>\n      images, labels <span class=\"pl-k\">=</span> cifar10.distorted_inputs()\n      <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:<span class=\"pl-c1\">%d</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> i):\n          <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%s</span>_<span class=\"pl-c1\">%d</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (cifar10.<span class=\"pl-c1\">TOWER_NAME</span>, i)) <span class=\"pl-k\">as</span> scope:\n               loss <span class=\"pl-k\">=</span> tower_loss(scope, images, labels)</pre></div>\n<p>And then the performance is</p>\n<table>\n<thead>\n<tr>\n<th>System</th>\n<th>Examples per sec</th>\n<th>Step Time (sec/batch)</th>\n<th>Elasped Time (sec)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1 Tesla M40</td>\n<td>6700 ~ 7700</td>\n<td>0.016 ~ 0.019</td>\n<td>42.62</td>\n</tr>\n<tr>\n<td>2 Tesla M40</td>\n<td>6800 ~ 7600</td>\n<td>0.016 ~ 0.018</td>\n<td>78.18</td>\n</tr>\n<tr>\n<td>4 Tesla M40</td>\n<td>7000 ~ 7400</td>\n<td>0,017 ~ 0.018</td>\n<td>154.88</td>\n</tr>\n<tr>\n<td>8 Tesla M40</td>\n<td>6900 ~ 7200</td>\n<td>0,017 ~ 0.018</td>\n<td>309.95</td>\n</tr>\n</tbody>\n</table>\n<p>The performce is much better than the previous table but increaing number of GPUs does not acquire better result.</p>", "body_text": "Environment info\nOperating System:\n centos 7 \nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n$ls -l /usr/local/cuda/lib64/libcud*\nhere is the result\n  548 -rw-r--r-- 1 root root   558720 Dec  7 21:02 /usr/local/cuda/lib64/libcudadevrt.a\n    0 lrwxrwxrwx 1 root root       16 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\n    0 lrwxrwxrwx 1 root root       19 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n  408 -rwxr-xr-x 1 root root   415432 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\n  760 -rw-r--r-- 1 root root   775162 Dec  7 21:02 /usr/local/cuda/lib64/libcudart_static.a\n    0 lrwxrwxrwx 1 root root       13 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\n    0 lrwxrwxrwx 1 root root       17 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n77480 -rwxr-xr-x 1 root root 79337624 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n68124 -rw-r--r-- 1 root root 69756172 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn_static.a\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nI install tensorflow using pip with command from pypi\n\n$ pip install tensorflow-gpu \n\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n0.12.0\nPhenomenon\nPerformance of cifar10 model on GPU\nWhen running cifar10_train.py, I tried 2000 steps with batch_size 128\npython cifar10_train.py --data_dir ../datasets/cifar10 --batch_size 128 --max_steps 2000\nThen elasped time on a Telsa M40 graphics card is\nElasped Time: 167.51s\nHere is the speed running cifar10_multi_gpu_train.py with different number of GPUs on my machine (max_steps=2000, batch_size=128)\n\n\n\nSystem\nExamples per sec\nStep Time (sec/batch)\nElasped Time (sec)\n\n\n\n\n1 Tesla M40\n1300 ~ 2400\n0.05 ~ 0.10\n157.96\n\n\n2 Tesla M40\n2700 ~ 3700\n0.03 ~ 0.04\n164.49\n\n\n4 Tesla M40\n3900 ~ 6300\n0,02 ~ 0.03\n231.98\n\n\n8 Tesla M40\n3700 ~ 6700\n0.02 ~ 0.04\n431.54\n\n\n\nThe performance improves as the number of GPUs increases.\nPerformance when moving distorted_inputs to cpu\nI made some changes on cifar10_train.py and cifar10_muti_gpu_train.py\n# cifar10_train.py\ndef train():\n    with tf.Graph().as_default():\n        # Here is what I modified\n         with tf.device(\"/cpu:0\"):\n            images, labels = cifar10.distorted_inputs()\nI put function distorted_inputs on cpu, and then the performace is much better than before\nElasped Time: 42.92s\nI made the same change on cifar10_multi_gpu_train.py\n# cifar10_multi_gpu_train.py\ndef tower_loss(scope, images, labels):\n  # Get images and labels for CIFAR-10.\n  # Commented\n  #images, labels = cifar10.distorted_inputs()\n\n  logits = cifar10.inference(images)\n\n  _ = cifar10.loss(logits, labels)\n  losses = tf.get_collection('losses', scope)\n  total_loss = tf.add_n(losses, name='total_loss')\n\n  for l in losses + [total_loss]:\n    loss_name = re.sub('%s_[0-9]*/' % cifar10.TOWER_NAME, '', l.op.name)\n    tf.scalar_summary(loss_name, l)\n\n  return total_loss\n\ndef train():\n  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n  with tf.Graph().as_default(), tf.device('/cpu:0'):\n    global_step = tf.get_variable(\n        'global_step', [],\n        initializer=tf.constant_initializer(0), trainable=False)\n\n    ...build optimizer...\n\n    # Calculate the gradients for each model tower.\n    tower_grads = []\n    for i in xrange(FLAGS.num_gpus):\n      # move distorted_inputs to here\n      images, labels = cifar10.distorted_inputs()\n      with tf.device('/gpu:%d' % i):\n          with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:\n               loss = tower_loss(scope, images, labels)\nAnd then the performance is\n\n\n\nSystem\nExamples per sec\nStep Time (sec/batch)\nElasped Time (sec)\n\n\n\n\n1 Tesla M40\n6700 ~ 7700\n0.016 ~ 0.019\n42.62\n\n\n2 Tesla M40\n6800 ~ 7600\n0.016 ~ 0.018\n78.18\n\n\n4 Tesla M40\n7000 ~ 7400\n0,017 ~ 0.018\n154.88\n\n\n8 Tesla M40\n6900 ~ 7200\n0,017 ~ 0.018\n309.95\n\n\n\nThe performce is much better than the previous table but increaing number of GPUs does not acquire better result.", "body": "### Environment info\r\nOperating System:\r\n```bash\r\n centos 7 \r\n```\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```bash\r\n$ls -l /usr/local/cuda/lib64/libcud*\r\n```\r\nhere is the result\r\n```bash\r\n  548 -rw-r--r-- 1 root root   558720 Dec  7 21:02 /usr/local/cuda/lib64/libcudadevrt.a\r\n    0 lrwxrwxrwx 1 root root       16 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\n    0 lrwxrwxrwx 1 root root       19 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n  408 -rwxr-xr-x 1 root root   415432 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n  760 -rw-r--r-- 1 root root   775162 Dec  7 21:02 /usr/local/cuda/lib64/libcudart_static.a\r\n    0 lrwxrwxrwx 1 root root       13 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\n    0 lrwxrwxrwx 1 root root       17 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n77480 -rwxr-xr-x 1 root root 79337624 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n68124 -rw-r--r-- 1 root root 69756172 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\nI install tensorflow using pip with command from pypi\r\n```bash\r\n$ pip install tensorflow-gpu \r\n```\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```bash\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n0.12.0\r\n```\r\n\r\n### Phenomenon\r\n#### Performance of cifar10 model on GPU\r\nWhen running cifar10_train.py, I tried 2000 steps with batch_size 128\r\n```bash\r\npython cifar10_train.py --data_dir ../datasets/cifar10 --batch_size 128 --max_steps 2000\r\n```\r\nThen elasped time on a Telsa M40 graphics card is \r\n```bash\r\nElasped Time: 167.51s\r\n```\r\nHere is the speed running cifar10_multi_gpu_train.py with different number of GPUs on my machine (max_steps=2000, batch_size=128)\r\n\r\n| System           |   Examples per sec   | Step Time (sec/batch)   |    Elasped Time (sec)  |\r\n| -------------    |  -------------------   |---------------------------|------------------------|\r\n| 1 Tesla M40   |   1300 ~ 2400          |  0.05 ~ 0.10                   |   157.96                      |\r\n| 2 Tesla M40   |   2700 ~ 3700          |  0.03 ~ 0.04                   |   164.49                      |\r\n| 4 Tesla M40   |   3900 ~ 6300          |  0,02 ~ 0.03                   |   231.98                      |\r\n| 8 Tesla M40   |   3700 ~ 6700          |  0.02 ~ 0.04                   |   431.54                      |\r\n\r\nThe performance improves as the number of GPUs increases.\r\n\r\n#### Performance when moving distorted_inputs to cpu\r\nI made some changes on cifar10_train.py and cifar10_muti_gpu_train.py\r\n```python\r\n# cifar10_train.py\r\ndef train():\r\n    with tf.Graph().as_default():\r\n        # Here is what I modified\r\n         with tf.device(\"/cpu:0\"):\r\n            images, labels = cifar10.distorted_inputs()\r\n```\r\nI put function distorted_inputs on cpu, and then the performace is much better than before\r\n```bash\r\nElasped Time: 42.92s\r\n```\r\nI made the same change on cifar10_multi_gpu_train.py\r\n```python\r\n# cifar10_multi_gpu_train.py\r\ndef tower_loss(scope, images, labels):\r\n  # Get images and labels for CIFAR-10.\r\n  # Commented\r\n  #images, labels = cifar10.distorted_inputs()\r\n\r\n  logits = cifar10.inference(images)\r\n\r\n  _ = cifar10.loss(logits, labels)\r\n  losses = tf.get_collection('losses', scope)\r\n  total_loss = tf.add_n(losses, name='total_loss')\r\n\r\n  for l in losses + [total_loss]:\r\n    loss_name = re.sub('%s_[0-9]*/' % cifar10.TOWER_NAME, '', l.op.name)\r\n    tf.scalar_summary(loss_name, l)\r\n\r\n  return total_loss\r\n\r\ndef train():\r\n  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\r\n  with tf.Graph().as_default(), tf.device('/cpu:0'):\r\n    global_step = tf.get_variable(\r\n        'global_step', [],\r\n        initializer=tf.constant_initializer(0), trainable=False)\r\n\r\n    ...build optimizer...\r\n\r\n    # Calculate the gradients for each model tower.\r\n    tower_grads = []\r\n    for i in xrange(FLAGS.num_gpus):\r\n      # move distorted_inputs to here\r\n      images, labels = cifar10.distorted_inputs()\r\n      with tf.device('/gpu:%d' % i):\r\n          with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:\r\n               loss = tower_loss(scope, images, labels)\r\n```\r\nAnd then the performance is \r\n\r\n| System           |   Examples per sec   | Step Time (sec/batch)   |    Elasped Time (sec)  |\r\n| -------------    |  -------------------   |---------------------------|------------------------|\r\n| 1 Tesla M40   |   6700 ~ 7700          |  0.016 ~ 0.019               |   42.62                       |\r\n| 2 Tesla M40   |   6800 ~ 7600          |  0.016 ~ 0.018               |   78.18                        |\r\n| 4 Tesla M40   |   7000 ~ 7400          |  0,017 ~ 0.018               |   154.88                      |\r\n| 8 Tesla M40   |   6900 ~ 7200          |  0,017 ~ 0.018               |   309.95                      |\r\n\r\nThe performce is much better than the previous table but increaing number of GPUs does not acquire better result. "}