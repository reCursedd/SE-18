{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/411937804", "html_url": "https://github.com/tensorflow/tensorflow/issues/13610#issuecomment-411937804", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13610", "id": 411937804, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTkzNzgwNA==", "user": {"login": "ed-alertedh", "id": 24605895, "node_id": "MDQ6VXNlcjI0NjA1ODk1", "avatar_url": "https://avatars1.githubusercontent.com/u/24605895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ed-alertedh", "html_url": "https://github.com/ed-alertedh", "followers_url": "https://api.github.com/users/ed-alertedh/followers", "following_url": "https://api.github.com/users/ed-alertedh/following{/other_user}", "gists_url": "https://api.github.com/users/ed-alertedh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ed-alertedh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ed-alertedh/subscriptions", "organizations_url": "https://api.github.com/users/ed-alertedh/orgs", "repos_url": "https://api.github.com/users/ed-alertedh/repos", "events_url": "https://api.github.com/users/ed-alertedh/events{/privacy}", "received_events_url": "https://api.github.com/users/ed-alertedh/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-10T00:20:41Z", "updated_at": "2018-08-10T00:20:41Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=144114\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rohan100jain\">@rohan100jain</a> that looks like a very powerful new iterator! I'm not sure if it's exactly addressing everything discussed in this issue. I think the OP was essentially asking whether they could add more dataset ops after prefetch_to_device.</p>\n<p>Now that all the docs make it fairly clear the Dataset API has been designed as an ETL process I would hazard a guess that you aren't planning to change that architecture to allow further \"T\" steps after the \"L\". Now that I look at it again, the OP's example doesn't really require Dataset.map anyway as they are all ops that can be run on GPU after the input pipeline has loaded the data onto there.</p>\n<p>Also, I haven't tried it yet but the changes to <code>tf.estimator.train_and_evaluate</code> in the latest release sound like they do switching between train and test datasets on a single graph like I wanted to do.</p>", "body_text": "@rohan100jain that looks like a very powerful new iterator! I'm not sure if it's exactly addressing everything discussed in this issue. I think the OP was essentially asking whether they could add more dataset ops after prefetch_to_device.\nNow that all the docs make it fairly clear the Dataset API has been designed as an ETL process I would hazard a guess that you aren't planning to change that architecture to allow further \"T\" steps after the \"L\". Now that I look at it again, the OP's example doesn't really require Dataset.map anyway as they are all ops that can be run on GPU after the input pipeline has loaded the data onto there.\nAlso, I haven't tried it yet but the changes to tf.estimator.train_and_evaluate in the latest release sound like they do switching between train and test datasets on a single graph like I wanted to do.", "body": "@rohan100jain that looks like a very powerful new iterator! I'm not sure if it's exactly addressing everything discussed in this issue. I think the OP was essentially asking whether they could add more dataset ops after prefetch_to_device.\r\n\r\nNow that all the docs make it fairly clear the Dataset API has been designed as an ETL process I would hazard a guess that you aren't planning to change that architecture to allow further \"T\" steps after the \"L\". Now that I look at it again, the OP's example doesn't really require Dataset.map anyway as they are all ops that can be run on GPU after the input pipeline has loaded the data onto there.\r\n\r\nAlso, I haven't tried it yet but the changes to `tf.estimator.train_and_evaluate` in the latest release sound like they do switching between train and test datasets on a single graph like I wanted to do."}