{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/339848949", "html_url": "https://github.com/tensorflow/tensorflow/issues/13610#issuecomment-339848949", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13610", "id": 339848949, "node_id": "MDEyOklzc3VlQ29tbWVudDMzOTg0ODk0OQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-27T01:45:44Z", "updated_at": "2017-10-27T01:45:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1928815\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nirmalthacker\">@nirmalthacker</a>  I posted an answer to your question <a href=\"https://stackoverflow.com/a/46966248/3574081\" rel=\"nofollow\">on Stack Overflow</a>.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=653425\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tongda\">@tongda</a> General cross-device pipelines are still some way off, but <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=144114\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rohan100jain\">@rohan100jain</a> has developed some nice support for staging data automatically to GPU memory, which covers one of the big use cases. In principle you could reuse some of the support for dispatching TensorFlow functions to remote devices in a host-side <code>Dataset.map()</code>, but the partitioning between devices would currently be manual.</p>", "body_text": "@nirmalthacker  I posted an answer to your question on Stack Overflow.\n@tongda General cross-device pipelines are still some way off, but @rohan100jain has developed some nice support for staging data automatically to GPU memory, which covers one of the big use cases. In principle you could reuse some of the support for dispatching TensorFlow functions to remote devices in a host-side Dataset.map(), but the partitioning between devices would currently be manual.", "body": "@nirmalthacker  I posted an answer to your question [on Stack Overflow](https://stackoverflow.com/a/46966248/3574081).\r\n\r\n@tongda General cross-device pipelines are still some way off, but @rohan100jain has developed some nice support for staging data automatically to GPU memory, which covers one of the big use cases. In principle you could reuse some of the support for dispatching TensorFlow functions to remote devices in a host-side `Dataset.map()`, but the partitioning between devices would currently be manual."}