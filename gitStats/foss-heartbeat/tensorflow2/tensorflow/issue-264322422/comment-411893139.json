{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/411893139", "html_url": "https://github.com/tensorflow/tensorflow/issues/13610#issuecomment-411893139", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13610", "id": 411893139, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTg5MzEzOQ==", "user": {"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-09T20:52:23Z", "updated_at": "2018-08-09T20:52:23Z", "author_association": "MEMBER", "body_html": "<p>Hi all,</p>\n<p>Please take a look at MultiDeviceIterator <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/prefetching_ops.py#L628\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/prefetching_ops.py#L628</a></p>\n<p>Currently its exposed via tf.contrib.data but this solves the prefetching to multiple GPU devices use case.</p>\n<p>Sample API usage:</p>\n<p>host_dataset_on_cpu = .....<br>\nmulti_device_iterator = prefetching_ops.MultiDeviceIterator(host_dataset_on_cpu, devices=['/gpu:0', '/gpu:1'])<br>\nelem_on_gpu_0, elem_on_gpu_1 = multi_device_iterator.get_next()</p>\n<p>with tf.Session() as sess:<br>\nsess.run(multi_device_iterator.initializer)<br>\nelem_0 = sess.run(elem_on_gpu_0)<br>\nelem_1 = sess.run(elem_on_gpu_1)</p>\n<p>MultiDeviceIterator deterministically prefetches elements to the different GPU's i.e. elements % 2 == 0 will go to GPU:0 and elements % 2 == 1 will go to GPU:1.</p>\n<p>Closing this issue for now but feel free to open new ones if you see issues.</p>", "body_text": "Hi all,\nPlease take a look at MultiDeviceIterator https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/prefetching_ops.py#L628\nCurrently its exposed via tf.contrib.data but this solves the prefetching to multiple GPU devices use case.\nSample API usage:\nhost_dataset_on_cpu = .....\nmulti_device_iterator = prefetching_ops.MultiDeviceIterator(host_dataset_on_cpu, devices=['/gpu:0', '/gpu:1'])\nelem_on_gpu_0, elem_on_gpu_1 = multi_device_iterator.get_next()\nwith tf.Session() as sess:\nsess.run(multi_device_iterator.initializer)\nelem_0 = sess.run(elem_on_gpu_0)\nelem_1 = sess.run(elem_on_gpu_1)\nMultiDeviceIterator deterministically prefetches elements to the different GPU's i.e. elements % 2 == 0 will go to GPU:0 and elements % 2 == 1 will go to GPU:1.\nClosing this issue for now but feel free to open new ones if you see issues.", "body": "Hi all,\r\n\r\nPlease take a look at MultiDeviceIterator https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/prefetching_ops.py#L628\r\n\r\nCurrently its exposed via tf.contrib.data but this solves the prefetching to multiple GPU devices use case.\r\n\r\nSample API usage:\r\n\r\nhost_dataset_on_cpu = .....\r\nmulti_device_iterator = prefetching_ops.MultiDeviceIterator(host_dataset_on_cpu, devices=['/gpu:0', '/gpu:1'])\r\nelem_on_gpu_0, elem_on_gpu_1 = multi_device_iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n  sess.run(multi_device_iterator.initializer)\r\n  elem_0 = sess.run(elem_on_gpu_0)\r\n  elem_1 = sess.run(elem_on_gpu_1)\r\n\r\nMultiDeviceIterator deterministically prefetches elements to the different GPU's i.e. elements % 2 == 0 will go to GPU:0 and elements % 2 == 1 will go to GPU:1.\r\n\r\nClosing this issue for now but feel free to open new ones if you see issues."}