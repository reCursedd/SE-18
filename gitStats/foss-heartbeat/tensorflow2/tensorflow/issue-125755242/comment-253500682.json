{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/253500682", "html_url": "https://github.com/tensorflow/tensorflow/issues/734#issuecomment-253500682", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/734", "id": 253500682, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MzUwMDY4Mg==", "user": {"login": "joaanna", "id": 13452631, "node_id": "MDQ6VXNlcjEzNDUyNjMx", "avatar_url": "https://avatars2.githubusercontent.com/u/13452631?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joaanna", "html_url": "https://github.com/joaanna", "followers_url": "https://api.github.com/users/joaanna/followers", "following_url": "https://api.github.com/users/joaanna/following{/other_user}", "gists_url": "https://api.github.com/users/joaanna/gists{/gist_id}", "starred_url": "https://api.github.com/users/joaanna/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joaanna/subscriptions", "organizations_url": "https://api.github.com/users/joaanna/orgs", "repos_url": "https://api.github.com/users/joaanna/repos", "events_url": "https://api.github.com/users/joaanna/events{/privacy}", "received_events_url": "https://api.github.com/users/joaanna/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-13T12:36:01Z", "updated_at": "2016-10-13T12:36:01Z", "author_association": "NONE", "body_html": "<p>I have a similar error message, in my case I am able to train let say model A, and the only thing I change in model B are sizes of convolution filters and pooling windows. I am wondering if it can be caused because the matrix operations are too computionally expensive? The error message:<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: Quadro K2000<br>\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.954<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 1.94GiB<br>\nFree memory: 1.83GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Quadro K2000, pci bus id: 0000:01:00.0)<br>\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1110] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_TIMEOUT<br>\nE tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x2f838f0: CUDA_ERROR_LAUNCH_TIMEOUT<br>\nE tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x2f838f0: CUDA_ERROR_LAUNCH_TIMEOUT<br>\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:1251] failed to enqueue convolution on stream: CUDNN_STATUS_EXECUTION_FAILED<br>\nAborted (core dumped)</p>", "body_text": "I have a similar error message, in my case I am able to train let say model A, and the only thing I change in model B are sizes of convolution filters and pooling windows. I am wondering if it can be caused because the matrix operations are too computionally expensive? The error message:\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: Quadro K2000\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.954\npciBusID 0000:01:00.0\nTotal memory: 1.94GiB\nFree memory: 1.83GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro K2000, pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1110] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_TIMEOUT\nE tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x2f838f0: CUDA_ERROR_LAUNCH_TIMEOUT\nE tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x2f838f0: CUDA_ERROR_LAUNCH_TIMEOUT\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:1251] failed to enqueue convolution on stream: CUDNN_STATUS_EXECUTION_FAILED\nAborted (core dumped)", "body": "I have a similar error message, in my case I am able to train let say model A, and the only thing I change in model B are sizes of convolution filters and pooling windows. I am wondering if it can be caused because the matrix operations are too computionally expensive? The error message:\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Quadro K2000\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.954\npciBusID 0000:01:00.0\nTotal memory: 1.94GiB\nFree memory: 1.83GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro K2000, pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1110] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_TIMEOUT\nE tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x2f838f0: CUDA_ERROR_LAUNCH_TIMEOUT\nE tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x2f838f0: CUDA_ERROR_LAUNCH_TIMEOUT\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:1251] failed to enqueue convolution on stream: CUDNN_STATUS_EXECUTION_FAILED\nAborted (core dumped)\n"}