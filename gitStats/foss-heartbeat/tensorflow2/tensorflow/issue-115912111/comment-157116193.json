{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/157116193", "html_url": "https://github.com/tensorflow/tensorflow/issues/7#issuecomment-157116193", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7", "id": 157116193, "node_id": "MDEyOklzc3VlQ29tbWVudDE1NzExNjE5Mw==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-16T17:45:56Z", "updated_at": "2015-11-16T17:45:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yes, to add to what <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15710643\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ludimagister\">@ludimagister</a> says: the conditional op will plug in zeros to the output &amp; state past max(sequence_length), thus reducing the total amount of computation (if not memory).</p>\n<p>I may actually modify this so that instead of plugging in zeros to the state, it just copies the state.  This way the final state will represent the \"final\" state at max(sequence_length).  However, I'm undecided on this.  If you want the final state at time sequence_length, you can concat the state vectors and use transpose() followed by gather() with sequence_length in order to pull out the states you care about.  That's probably what you would want to do, in fact, because if you have batch_size = 2 and sequence_length = [1, 2], then for the first minibatch entry, the state at max(sequence_length) will not equal the state at sequence_length[0].</p>\n<p>An alternative solution is to right-align your inputs so that they always \"end\" on the final time step.  This breaks down the dynamic calculation performed when you pass sequence_length (because it assumes left-aligned inputs).  I may extend this by adding a bool flag like \"right_aligned\" to the rnn call, which assumes that calculation starts at len(inputs) - max(sequence_length), and copies the initial state through appropriately.  But that doesn't exist now.</p>", "body_text": "Yes, to add to what @ludimagister says: the conditional op will plug in zeros to the output & state past max(sequence_length), thus reducing the total amount of computation (if not memory).\nI may actually modify this so that instead of plugging in zeros to the state, it just copies the state.  This way the final state will represent the \"final\" state at max(sequence_length).  However, I'm undecided on this.  If you want the final state at time sequence_length, you can concat the state vectors and use transpose() followed by gather() with sequence_length in order to pull out the states you care about.  That's probably what you would want to do, in fact, because if you have batch_size = 2 and sequence_length = [1, 2], then for the first minibatch entry, the state at max(sequence_length) will not equal the state at sequence_length[0].\nAn alternative solution is to right-align your inputs so that they always \"end\" on the final time step.  This breaks down the dynamic calculation performed when you pass sequence_length (because it assumes left-aligned inputs).  I may extend this by adding a bool flag like \"right_aligned\" to the rnn call, which assumes that calculation starts at len(inputs) - max(sequence_length), and copies the initial state through appropriately.  But that doesn't exist now.", "body": "Yes, to add to what @ludimagister says: the conditional op will plug in zeros to the output & state past max(sequence_length), thus reducing the total amount of computation (if not memory).\n\nI may actually modify this so that instead of plugging in zeros to the state, it just copies the state.  This way the final state will represent the \"final\" state at max(sequence_length).  However, I'm undecided on this.  If you want the final state at time sequence_length, you can concat the state vectors and use transpose() followed by gather() with sequence_length in order to pull out the states you care about.  That's probably what you would want to do, in fact, because if you have batch_size = 2 and sequence_length = [1, 2], then for the first minibatch entry, the state at max(sequence_length) will not equal the state at sequence_length[0].\n\nAn alternative solution is to right-align your inputs so that they always \"end\" on the final time step.  This breaks down the dynamic calculation performed when you pass sequence_length (because it assumes left-aligned inputs).  I may extend this by adding a bool flag like \"right_aligned\" to the rnn call, which assumes that calculation starts at len(inputs) - max(sequence_length), and copies the initial state through appropriately.  But that doesn't exist now.\n"}