{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15802", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15802/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15802/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15802/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15802", "id": 285585041, "node_id": "MDU6SXNzdWUyODU1ODUwNDE=", "number": 15802, "title": "tf.stack eats memory over time", "user": {"login": "scotthuang1989", "id": 5325686, "node_id": "MDQ6VXNlcjUzMjU2ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/5325686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scotthuang1989", "html_url": "https://github.com/scotthuang1989", "followers_url": "https://api.github.com/users/scotthuang1989/followers", "following_url": "https://api.github.com/users/scotthuang1989/following{/other_user}", "gists_url": "https://api.github.com/users/scotthuang1989/gists{/gist_id}", "starred_url": "https://api.github.com/users/scotthuang1989/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scotthuang1989/subscriptions", "organizations_url": "https://api.github.com/users/scotthuang1989/orgs", "repos_url": "https://api.github.com/users/scotthuang1989/repos", "events_url": "https://api.github.com/users/scotthuang1989/events{/privacy}", "received_events_url": "https://api.github.com/users/scotthuang1989/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-03T02:15:52Z", "updated_at": "2018-08-31T00:52:22Z", "closed_at": "2018-01-03T06:27:07Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4.1</li>\n<li><strong>Python version</strong>:  3.5</li>\n<li><strong>CUDA/cuDNN version</strong>: 8</li>\n<li><strong>GPU model and memory</strong>: 1060 + 6GB</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I use tf.stack to stack 2 images. But the memory used by this program increase over time. I use <code>memory_profiler</code> check it. it is caused by tf.stack, here is the minimal re-produce code:</p>\n<pre><code>import tensorflow as tf\nimport glob\nimport gc\nfrom memory_profiler import profile\n\n\n@profile\ndef function_mark():\n  pass\n\n@profile\ndef stack_images():\n  image_file_list = glob.glob(\"car_images/*.jpg\")\n  sess = tf.Session()\n\n  for _ in range(300):\n    # read image\n    image1 = tf.gfile.FastGFile(image_file_list[0], 'rb').read()\n    image2 = tf.gfile.FastGFile(image_file_list[1], 'rb').read()\n    # decode image\n    image1_decode = tf.image.decode_image(image1, channels=3)\n    image2_decode = tf.image.decode_image(image2, channels=3)\n    # stack image\n    image_stack = tf.stack([image1_decode, image2_decode])\n    # run session\n    r_image_stack = sess.run(image_stack)\n    # mark function. so I can check the memory-usage of every loop.\n    function_mark()\n    # force garbage collection, so all the un-reference variable will be freed.\n    del r_image_stack\n    gc.collect()\n</code></pre>\n<p>First, I profile it line by line, here is the result:<br>\n<strong>you can see it very clearly that line 26 take a lot of memory. My image is 800*600 and I only stack 2 image each time, so 1.3G memory consumption is not normal.</strong></p>\n<blockquote>\n<h1>Line #    Mem usage    Increment   Line Contents</h1>\n<pre><code>11    190.0 MiB    190.0 MiB   @profile\n12                             def stack_images():\n13    190.0 MiB      0.0 MiB     image_file_list = glob.glob(\"car_images/*.jpg\")\n14    421.6 MiB    231.7 MiB     sess = tf.Session()\n15\n16   1998.4 MiB      0.0 MiB     for _ in range(300):\n\n17                                 # read image\n18   1992.5 MiB      1.5 MiB       image1 = tf.gfile.FastGFile(image_file_list[0], 'rb').read()\n19   1992.5 MiB      0.0 MiB       image2 = tf.gfile.FastGFile(image_file_list[1], 'rb').read()\n20                                 # decode image\n21   1992.8 MiB     77.6 MiB       image1_decode = tf.image.decode_image(image1, channels=3)\n22   1993.3 MiB    108.6 MiB       image2_decode = tf.image.decode_image(image2, channels=3)\n23                                 # stack image\n24   1993.3 MiB      0.7 MiB       image_stack = tf.stack([image1_decode, image2_decode])\n25                                 # run session\n26   1998.4 MiB   1350.4 MiB       r_image_stack = sess.run(image_stack)\n27                                 # mark function. so I can check the memory-usage of every loop.\n28   1998.4 MiB     29.0 MiB       function_mark()\n29                                 # force garbage collection, so all the un-reference variable will be freed.\n30   1998.4 MiB      0.0 MiB       del r_image_stack\n31   1998.4 MiB      8.9 MiB       gc.collect()\n</code></pre>\n</blockquote>\n<p>Then <strong>I profile it over time.</strong> I use function <code>function_mark</code> to distinguish each loop. So we can see it very clearly that the memory usage of this program is increase over time.<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/5325686/34505710-d25c80b0-f061-11e7-99c6-5db2e990d9aa.png\"><img src=\"https://user-images.githubusercontent.com/5325686/34505710-d25c80b0-f061-11e7-99c6-5db2e990d9aa.png\" alt=\"figure_1\" style=\"max-width:100%;\"></a></p>\n<p>My question is: How should I avoid this problem. because it cause a serious performance regression.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.4.1\nPython version:  3.5\nCUDA/cuDNN version: 8\nGPU model and memory: 1060 + 6GB\n\nDescribe the problem\nI use tf.stack to stack 2 images. But the memory used by this program increase over time. I use memory_profiler check it. it is caused by tf.stack, here is the minimal re-produce code:\nimport tensorflow as tf\nimport glob\nimport gc\nfrom memory_profiler import profile\n\n\n@profile\ndef function_mark():\n  pass\n\n@profile\ndef stack_images():\n  image_file_list = glob.glob(\"car_images/*.jpg\")\n  sess = tf.Session()\n\n  for _ in range(300):\n    # read image\n    image1 = tf.gfile.FastGFile(image_file_list[0], 'rb').read()\n    image2 = tf.gfile.FastGFile(image_file_list[1], 'rb').read()\n    # decode image\n    image1_decode = tf.image.decode_image(image1, channels=3)\n    image2_decode = tf.image.decode_image(image2, channels=3)\n    # stack image\n    image_stack = tf.stack([image1_decode, image2_decode])\n    # run session\n    r_image_stack = sess.run(image_stack)\n    # mark function. so I can check the memory-usage of every loop.\n    function_mark()\n    # force garbage collection, so all the un-reference variable will be freed.\n    del r_image_stack\n    gc.collect()\n\nFirst, I profile it line by line, here is the result:\nyou can see it very clearly that line 26 take a lot of memory. My image is 800*600 and I only stack 2 image each time, so 1.3G memory consumption is not normal.\n\nLine #    Mem usage    Increment   Line Contents\n11    190.0 MiB    190.0 MiB   @profile\n12                             def stack_images():\n13    190.0 MiB      0.0 MiB     image_file_list = glob.glob(\"car_images/*.jpg\")\n14    421.6 MiB    231.7 MiB     sess = tf.Session()\n15\n16   1998.4 MiB      0.0 MiB     for _ in range(300):\n\n17                                 # read image\n18   1992.5 MiB      1.5 MiB       image1 = tf.gfile.FastGFile(image_file_list[0], 'rb').read()\n19   1992.5 MiB      0.0 MiB       image2 = tf.gfile.FastGFile(image_file_list[1], 'rb').read()\n20                                 # decode image\n21   1992.8 MiB     77.6 MiB       image1_decode = tf.image.decode_image(image1, channels=3)\n22   1993.3 MiB    108.6 MiB       image2_decode = tf.image.decode_image(image2, channels=3)\n23                                 # stack image\n24   1993.3 MiB      0.7 MiB       image_stack = tf.stack([image1_decode, image2_decode])\n25                                 # run session\n26   1998.4 MiB   1350.4 MiB       r_image_stack = sess.run(image_stack)\n27                                 # mark function. so I can check the memory-usage of every loop.\n28   1998.4 MiB     29.0 MiB       function_mark()\n29                                 # force garbage collection, so all the un-reference variable will be freed.\n30   1998.4 MiB      0.0 MiB       del r_image_stack\n31   1998.4 MiB      8.9 MiB       gc.collect()\n\n\nThen I profile it over time. I use function function_mark to distinguish each loop. So we can see it very clearly that the memory usage of this program is increase over time.\n\nMy question is: How should I avoid this problem. because it cause a serious performance regression.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**:  3.5\r\n- **CUDA/cuDNN version**: 8\r\n- **GPU model and memory**: 1060 + 6GB\r\n \r\n\r\n### Describe the problem\r\nI use tf.stack to stack 2 images. But the memory used by this program increase over time. I use `memory_profiler` check it. it is caused by tf.stack, here is the minimal re-produce code:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport glob\r\nimport gc\r\nfrom memory_profiler import profile\r\n\r\n\r\n@profile\r\ndef function_mark():\r\n  pass\r\n\r\n@profile\r\ndef stack_images():\r\n  image_file_list = glob.glob(\"car_images/*.jpg\")\r\n  sess = tf.Session()\r\n\r\n  for _ in range(300):\r\n    # read image\r\n    image1 = tf.gfile.FastGFile(image_file_list[0], 'rb').read()\r\n    image2 = tf.gfile.FastGFile(image_file_list[1], 'rb').read()\r\n    # decode image\r\n    image1_decode = tf.image.decode_image(image1, channels=3)\r\n    image2_decode = tf.image.decode_image(image2, channels=3)\r\n    # stack image\r\n    image_stack = tf.stack([image1_decode, image2_decode])\r\n    # run session\r\n    r_image_stack = sess.run(image_stack)\r\n    # mark function. so I can check the memory-usage of every loop.\r\n    function_mark()\r\n    # force garbage collection, so all the un-reference variable will be freed.\r\n    del r_image_stack\r\n    gc.collect()\r\n```\r\n\r\n First, I profile it line by line, here is the result:\r\n**you can see it very clearly that line 26 take a lot of memory. My image is 800*600 and I only stack 2 image each time, so 1.3G memory consumption is not normal.**\r\n\r\n> \r\n> Line #    Mem usage    Increment   Line Contents\r\n> ================================================\r\n>     11    190.0 MiB    190.0 MiB   @profile\r\n>     12                             def stack_images():\r\n>     13    190.0 MiB      0.0 MiB     image_file_list = glob.glob(\"car_images/*.jpg\")\r\n>     14    421.6 MiB    231.7 MiB     sess = tf.Session()\r\n>     15\r\n>     16   1998.4 MiB      0.0 MiB     for _ in range(300):\r\n> \r\n>     17                                 # read image\r\n>     18   1992.5 MiB      1.5 MiB       image1 = tf.gfile.FastGFile(image_file_list[0], 'rb').read()\r\n>     19   1992.5 MiB      0.0 MiB       image2 = tf.gfile.FastGFile(image_file_list[1], 'rb').read()\r\n>     20                                 # decode image\r\n>     21   1992.8 MiB     77.6 MiB       image1_decode = tf.image.decode_image(image1, channels=3)\r\n>     22   1993.3 MiB    108.6 MiB       image2_decode = tf.image.decode_image(image2, channels=3)\r\n>     23                                 # stack image\r\n>     24   1993.3 MiB      0.7 MiB       image_stack = tf.stack([image1_decode, image2_decode])\r\n>     25                                 # run session\r\n>     26   1998.4 MiB   1350.4 MiB       r_image_stack = sess.run(image_stack)\r\n>     27                                 # mark function. so I can check the memory-usage of every loop.\r\n>     28   1998.4 MiB     29.0 MiB       function_mark()\r\n>     29                                 # force garbage collection, so all the un-reference variable will be freed.\r\n>     30   1998.4 MiB      0.0 MiB       del r_image_stack\r\n>     31   1998.4 MiB      8.9 MiB       gc.collect()\r\n\r\nThen **I profile it over time.** I use function `function_mark` to distinguish each loop. So we can see it very clearly that the memory usage of this program is increase over time.\r\n![figure_1](https://user-images.githubusercontent.com/5325686/34505710-d25c80b0-f061-11e7-99c6-5db2e990d9aa.png)\r\n\r\nMy question is: How should I avoid this problem. because it cause a serious performance regression.\r\n"}