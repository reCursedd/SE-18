{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290400477", "html_url": "https://github.com/tensorflow/tensorflow/pull/8728#issuecomment-290400477", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8728", "id": 290400477, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDQwMDQ3Nw==", "user": {"login": "tillahoffmann", "id": 966348, "node_id": "MDQ6VXNlcjk2NjM0OA==", "avatar_url": "https://avatars2.githubusercontent.com/u/966348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tillahoffmann", "html_url": "https://github.com/tillahoffmann", "followers_url": "https://api.github.com/users/tillahoffmann/followers", "following_url": "https://api.github.com/users/tillahoffmann/following{/other_user}", "gists_url": "https://api.github.com/users/tillahoffmann/gists{/gist_id}", "starred_url": "https://api.github.com/users/tillahoffmann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tillahoffmann/subscriptions", "organizations_url": "https://api.github.com/users/tillahoffmann/orgs", "repos_url": "https://api.github.com/users/tillahoffmann/repos", "events_url": "https://api.github.com/users/tillahoffmann/events{/privacy}", "received_events_url": "https://api.github.com/users/tillahoffmann/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-30T12:49:14Z", "updated_at": "2017-03-30T12:49:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Here is a small example on how to learn the mean of a distribution by generating data in two separate processes and consuming the data in a single process.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> consumer.py</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Define parameters</span>\naddresses <span class=\"pl-k\">=</span> [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tcp://localhost:5555<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tcp://localhost:5556<span class=\"pl-pds\">\"</span></span>]\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\nmin_after_dequeue <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1000</span>\nqueue_capacity <span class=\"pl-k\">=</span> min_after_dequeue <span class=\"pl-k\">+</span> <span class=\"pl-c1\">3</span> <span class=\"pl-k\">*</span> batch_size\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a queue to hold the data</span>\n    queue <span class=\"pl-k\">=</span> tf.RandomShuffleQueue(\n        queue_capacity,\n        min_after_dequeue,\n        [tf.float32], \n        [[]],\n        [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>]\n    )\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add zmq ops</span>\n    enqueue_ops <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> address <span class=\"pl-k\">in</span> addresses:\n        raw <span class=\"pl-k\">=</span> tf.poll_zmq(<span class=\"pl-s\"><span class=\"pl-k\">b</span><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>, address, <span class=\"pl-c1\">1000</span>)\n        decoded <span class=\"pl-k\">=</span> tf.decode_raw(raw, tf.float32)\n        enqueue_ops.append(queue.enqueue_many({<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>: decoded}))\n        \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add a queue runner for the enqueue ops</span>\n    qr <span class=\"pl-k\">=</span> tf.train.QueueRunner(queue, enqueue_ops)\n    tf.train.add_queue_runner(qr)\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Get the data</span>\n    data <span class=\"pl-k\">=</span> queue.dequeue_many(batch_size)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Compute the loss</span>\n    mean <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    loss <span class=\"pl-k\">=</span> tf.reduce_mean((data[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">-</span> mean) <span class=\"pl-k\">**</span> <span class=\"pl-c1\">2</span>)\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add optimization op</span>\n    train_op <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(<span class=\"pl-c1\">1</span>).minimize(loss)\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Setup</span>\n    sess <span class=\"pl-k\">=</span> tf.Session()\n    sess.run(tf.global_variables_initializer())\n    tf.train.start_queue_runners(sess)\n    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run the training</span>\nlosses <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">100</span>):\n    _, loss_val <span class=\"pl-k\">=</span> sess.run([train_op, loss])\n    losses.append(loss_val)\n    \n<span class=\"pl-c1\">print</span>(sess.run(mean))</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> producer.py</span>\n<span class=\"pl-k\">import</span> zmq\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Get the port to listen on and define the ground truth mean</span>\nport <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>(sys.argv[<span class=\"pl-c1\">1</span>])\nmean <span class=\"pl-k\">=</span> <span class=\"pl-c1\">15</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a socket and listen</span>\ncontext <span class=\"pl-k\">=</span> zmq.Context()\nsocket <span class=\"pl-k\">=</span> context.socket(zmq.<span class=\"pl-c1\">REP</span>)\nsocket.bind(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tcp://*:<span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> port)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Respond to requests</span>\n<span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n    message <span class=\"pl-k\">=</span> socket.recv()\n    socket.send(np.random.normal(mean, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1000</span>).astype(np.float32).tostring())</pre></div>", "body_text": "Here is a small example on how to learn the mean of a distribution by generating data in two separate processes and consuming the data in a single process.\n# consumer.py\nimport tensorflow as tf\n\n# Define parameters\naddresses = [\"tcp://localhost:5555\", \"tcp://localhost:5556\"]\nbatch_size = 100\nmin_after_dequeue = 1000\nqueue_capacity = min_after_dequeue + 3 * batch_size\n\nwith tf.Graph().as_default():\n    # Create a queue to hold the data\n    queue = tf.RandomShuffleQueue(\n        queue_capacity,\n        min_after_dequeue,\n        [tf.float32], \n        [[]],\n        ['x']\n    )\n    \n    # Add zmq ops\n    enqueue_ops = []\n    for address in addresses:\n        raw = tf.poll_zmq(b\"\", address, 1000)\n        decoded = tf.decode_raw(raw, tf.float32)\n        enqueue_ops.append(queue.enqueue_many({'x': decoded}))\n        \n    # Add a queue runner for the enqueue ops\n    qr = tf.train.QueueRunner(queue, enqueue_ops)\n    tf.train.add_queue_runner(qr)\n    \n    # Get the data\n    data = queue.dequeue_many(batch_size)\n    # Compute the loss\n    mean = tf.Variable(0, dtype=tf.float32)\n    loss = tf.reduce_mean((data['x'] - mean) ** 2)\n    \n    # Add optimization op\n    train_op = tf.train.AdamOptimizer(1).minimize(loss)\n    \n    # Setup\n    sess = tf.Session()\n    sess.run(tf.global_variables_initializer())\n    tf.train.start_queue_runners(sess)\n    \n# Run the training\nlosses = []\nfor _ in range(100):\n    _, loss_val = sess.run([train_op, loss])\n    losses.append(loss_val)\n    \nprint(sess.run(mean))\n# producer.py\nimport zmq\nimport sys\nimport numpy as np\n\n# Get the port to listen on and define the ground truth mean\nport = int(sys.argv[1])\nmean = 15\n\n# Create a socket and listen\ncontext = zmq.Context()\nsocket = context.socket(zmq.REP)\nsocket.bind(\"tcp://*:%d\" % port)\n\n# Respond to requests\nwhile True:\n    message = socket.recv()\n    socket.send(np.random.normal(mean, 1, 1000).astype(np.float32).tostring())", "body": "Here is a small example on how to learn the mean of a distribution by generating data in two separate processes and consuming the data in a single process.\r\n\r\n```python\r\n# consumer.py\r\nimport tensorflow as tf\r\n\r\n# Define parameters\r\naddresses = [\"tcp://localhost:5555\", \"tcp://localhost:5556\"]\r\nbatch_size = 100\r\nmin_after_dequeue = 1000\r\nqueue_capacity = min_after_dequeue + 3 * batch_size\r\n\r\nwith tf.Graph().as_default():\r\n    # Create a queue to hold the data\r\n    queue = tf.RandomShuffleQueue(\r\n        queue_capacity,\r\n        min_after_dequeue,\r\n        [tf.float32], \r\n        [[]],\r\n        ['x']\r\n    )\r\n    \r\n    # Add zmq ops\r\n    enqueue_ops = []\r\n    for address in addresses:\r\n        raw = tf.poll_zmq(b\"\", address, 1000)\r\n        decoded = tf.decode_raw(raw, tf.float32)\r\n        enqueue_ops.append(queue.enqueue_many({'x': decoded}))\r\n        \r\n    # Add a queue runner for the enqueue ops\r\n    qr = tf.train.QueueRunner(queue, enqueue_ops)\r\n    tf.train.add_queue_runner(qr)\r\n    \r\n    # Get the data\r\n    data = queue.dequeue_many(batch_size)\r\n    # Compute the loss\r\n    mean = tf.Variable(0, dtype=tf.float32)\r\n    loss = tf.reduce_mean((data['x'] - mean) ** 2)\r\n    \r\n    # Add optimization op\r\n    train_op = tf.train.AdamOptimizer(1).minimize(loss)\r\n    \r\n    # Setup\r\n    sess = tf.Session()\r\n    sess.run(tf.global_variables_initializer())\r\n    tf.train.start_queue_runners(sess)\r\n    \r\n# Run the training\r\nlosses = []\r\nfor _ in range(100):\r\n    _, loss_val = sess.run([train_op, loss])\r\n    losses.append(loss_val)\r\n    \r\nprint(sess.run(mean))\r\n```\r\n\r\n```python\r\n# producer.py\r\nimport zmq\r\nimport sys\r\nimport numpy as np\r\n\r\n# Get the port to listen on and define the ground truth mean\r\nport = int(sys.argv[1])\r\nmean = 15\r\n\r\n# Create a socket and listen\r\ncontext = zmq.Context()\r\nsocket = context.socket(zmq.REP)\r\nsocket.bind(\"tcp://*:%d\" % port)\r\n\r\n# Respond to requests\r\nwhile True:\r\n    message = socket.recv()\r\n    socket.send(np.random.normal(mean, 1, 1000).astype(np.float32).tostring())\r\n```"}