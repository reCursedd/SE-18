{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/289819038", "html_url": "https://github.com/tensorflow/tensorflow/issues/7278#issuecomment-289819038", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7278", "id": 289819038, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTgxOTAzOA==", "user": {"login": "alexvicegrab", "id": 1575642, "node_id": "MDQ6VXNlcjE1NzU2NDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1575642?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexvicegrab", "html_url": "https://github.com/alexvicegrab", "followers_url": "https://api.github.com/users/alexvicegrab/followers", "following_url": "https://api.github.com/users/alexvicegrab/following{/other_user}", "gists_url": "https://api.github.com/users/alexvicegrab/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexvicegrab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexvicegrab/subscriptions", "organizations_url": "https://api.github.com/users/alexvicegrab/orgs", "repos_url": "https://api.github.com/users/alexvicegrab/repos", "events_url": "https://api.github.com/users/alexvicegrab/events{/privacy}", "received_events_url": "https://api.github.com/users/alexvicegrab/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-28T16:03:40Z", "updated_at": "2017-03-28T16:04:15Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=70511\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/girving\">@girving</a> True, but making a slower version (how much slower?) to some extent defeats the point of implementing separable convolutions, I was hoping to use (or create) a fast version that can take advantage of hardware acceleration, but I'm not sure how to go about it, since I can't seem access the native code of the nn_ops.depthwise_conv2d_native (so as to have an example of how this is implemented in 2D to guide me), unless I've been looking in the wrong places. Otherwise I'd be happy to have a go at trying to implement it :)</p>", "body_text": "@girving True, but making a slower version (how much slower?) to some extent defeats the point of implementing separable convolutions, I was hoping to use (or create) a fast version that can take advantage of hardware acceleration, but I'm not sure how to go about it, since I can't seem access the native code of the nn_ops.depthwise_conv2d_native (so as to have an example of how this is implemented in 2D to guide me), unless I've been looking in the wrong places. Otherwise I'd be happy to have a go at trying to implement it :)", "body": "@girving True, but making a slower version (how much slower?) to some extent defeats the point of implementing separable convolutions, I was hoping to use (or create) a fast version that can take advantage of hardware acceleration, but I'm not sure how to go about it, since I can't seem access the native code of the nn_ops.depthwise_conv2d_native (so as to have an example of how this is implemented in 2D to guide me), unless I've been looking in the wrong places. Otherwise I'd be happy to have a go at trying to implement it :)"}