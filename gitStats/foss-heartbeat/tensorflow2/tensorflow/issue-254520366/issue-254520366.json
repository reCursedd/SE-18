{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12739", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12739/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12739/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12739/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12739", "id": 254520366, "node_id": "MDU6SXNzdWUyNTQ1MjAzNjY=", "number": 12739, "title": "TF 1.3 keras TimeDistributed wrapper issue - rnn() got an unexpected keyword argument 'input_length'", "user": {"login": "KishoreKarunakaran", "id": 10724627, "node_id": "MDQ6VXNlcjEwNzI0NjI3", "avatar_url": "https://avatars3.githubusercontent.com/u/10724627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KishoreKarunakaran", "html_url": "https://github.com/KishoreKarunakaran", "followers_url": "https://api.github.com/users/KishoreKarunakaran/followers", "following_url": "https://api.github.com/users/KishoreKarunakaran/following{/other_user}", "gists_url": "https://api.github.com/users/KishoreKarunakaran/gists{/gist_id}", "starred_url": "https://api.github.com/users/KishoreKarunakaran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KishoreKarunakaran/subscriptions", "organizations_url": "https://api.github.com/users/KishoreKarunakaran/orgs", "repos_url": "https://api.github.com/users/KishoreKarunakaran/repos", "events_url": "https://api.github.com/users/KishoreKarunakaran/events{/privacy}", "received_events_url": "https://api.github.com/users/KishoreKarunakaran/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-09-01T02:39:41Z", "updated_at": "2017-11-08T22:33:02Z", "closed_at": "2017-11-08T22:33:02Z", "author_association": "NONE", "body_html": "<p>When I use TimeDistributed  wrapper from keras I'm getting unexpected keyword argument 'input_length'</p>\n<h1><strong>System Info:</strong></h1>\n<p><strong>Windows 10</strong><br>\n<strong>TF 1.3.0</strong><br>\n<strong>Python 3.5</strong></p>\n<p><strong>Code :</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> json\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> sklearn.model_selection <span class=\"pl-k\">import</span> train_test_split\n<span class=\"pl-k\">from</span> tensorflow.contrib.keras <span class=\"pl-k\">import</span> layers\n<span class=\"pl-k\">from</span> tensorflow.contrib.keras.python.keras.layers.wrappers <span class=\"pl-k\">import</span> TimeDistributed\n<span class=\"pl-k\">from</span> tensorflow.python.estimator.inputs <span class=\"pl-k\">import</span> numpy_io\n\n<span class=\"pl-c1\">MAX_NB_WORDS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">200000</span>\n<span class=\"pl-c1\">MAX_SEQUENCE_LENGTH</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">25</span>\n<span class=\"pl-c1\">EMBEDDING_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">300</span>\n<span class=\"pl-c1\">VALIDATION_SPLIT</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.1</span>\n<span class=\"pl-c1\">TEST_SPLIT</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.1</span>\n<span class=\"pl-c1\">RNG_SEED</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">13371447</span>\n<span class=\"pl-c1\">NB_EPOCHS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">25</span>\n<span class=\"pl-c1\">DROPOUT</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.1</span>\n<span class=\"pl-c1\">BATCH_SIZE</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">32</span>\n\ntf.logging.set_verbosity(tf.logging.<span class=\"pl-c1\">INFO</span>)\n\n<span class=\"pl-c1\">Q1_TRAINING_DATA_FILE</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gen/q1_train.npy<span class=\"pl-pds\">'</span></span>\n<span class=\"pl-c1\">Q2_TRAINING_DATA_FILE</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gen/q2_train.npy<span class=\"pl-pds\">'</span></span>\n<span class=\"pl-c1\">LABEL_TRAINING_DATA_FILE</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gen/label_train.npy<span class=\"pl-pds\">'</span></span>\n<span class=\"pl-c1\">NB_WORDS_DATA_FILE</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gen/nb_words.json<span class=\"pl-pds\">'</span></span>\n<span class=\"pl-k\">with</span> <span class=\"pl-c1\">open</span>(<span class=\"pl-c1\">NB_WORDS_DATA_FILE</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>r<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n    nb_words <span class=\"pl-k\">=</span> json.load(f)[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>nb_words<span class=\"pl-pds\">'</span></span>]\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>, <span class=\"pl-smi\">params</span>):\n    input_data <span class=\"pl-k\">=</span> features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>]\n\n    Q1_Data <span class=\"pl-k\">=</span> input_data[:, <span class=\"pl-c1\">0</span>]\n    Q2_Data <span class=\"pl-k\">=</span> input_data[:, <span class=\"pl-c1\">1</span>]\n\n    q1 <span class=\"pl-k\">=</span> layers.Embedding(nb_words <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">EMBEDDING_DIM</span>, <span class=\"pl-v\">input_length</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">MAX_SEQUENCE_LENGTH</span>)(Q1_Data)\n    q1 <span class=\"pl-k\">=</span> tf.contrib.keras.layers.TimeDistributed(layers.Dense(<span class=\"pl-c1\">EMBEDDING_DIM</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>))(q1)\n    q1 <span class=\"pl-k\">=</span> layers.Lambda(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: tf.reduce_max(x, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>))(q1)\n\n    q2 <span class=\"pl-k\">=</span> layers.Embedding(nb_words <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">EMBEDDING_DIM</span>, <span class=\"pl-v\">input_length</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">MAX_SEQUENCE_LENGTH</span>)(Q2_Data)\n    q2 <span class=\"pl-k\">=</span> tf.contrib.keras.layers.TimeDistributed(layers.Dense(<span class=\"pl-c1\">EMBEDDING_DIM</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>))(q2)\n    q2 <span class=\"pl-k\">=</span> layers.Lambda(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: tf.reduce_max(x, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>))(q2)\n\n    merged <span class=\"pl-k\">=</span> layers.concatenate([q1, q2])\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> merged = layers.Flatten()(merged)</span>\n    merged <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">200</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(merged)\n    merged <span class=\"pl-k\">=</span> tf.layers.dropout(merged, <span class=\"pl-v\">rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">DROPOUT</span>)\n    merged <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">200</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(merged)\n    merged <span class=\"pl-k\">=</span> tf.layers.dropout(merged, <span class=\"pl-v\">rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">DROPOUT</span>)\n    merged <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">200</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(merged)\n    merged <span class=\"pl-k\">=</span> tf.layers.dropout(merged, <span class=\"pl-v\">rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">DROPOUT</span>)\n    merged <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">200</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(merged)\n    merged <span class=\"pl-k\">=</span> tf.layers.dropout(merged, <span class=\"pl-v\">rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">DROPOUT</span>)\n\n    predictions <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">1</span>)(merged)\n\n    predictions <span class=\"pl-k\">=</span> tf.reshape(predictions, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>])\n\n    train_op <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n    eval_metric_ops <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">PREDICT</span>:\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(\n            <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode,\n            <span class=\"pl-v\">predictions</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>duplicate<span class=\"pl-pds\">\"</span></span>: predictions})\n\n    loss <span class=\"pl-k\">=</span> tf.losses.sigmoid_cross_entropy(labels, predictions)\n    optimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer()\n    train_op <span class=\"pl-k\">=</span> optimizer.minimize(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>tf.train.get_global_step())\n\n    eval_metric_ops <span class=\"pl-k\">=</span> {\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>accuracy<span class=\"pl-pds\">\"</span></span>: tf.metrics.accuracy(labels, predictions)\n    }\n\n    <span class=\"pl-c1\">print</span>(predictions)\n\n    <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>train_op, <span class=\"pl-v\">eval_metric_ops</span><span class=\"pl-k\">=</span>eval_metric_ops)\n\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Loading Numpy inputs<span class=\"pl-pds\">'</span></span>)\nq1_data <span class=\"pl-k\">=</span> np.load(<span class=\"pl-c1\">open</span>(<span class=\"pl-c1\">Q1_TRAINING_DATA_FILE</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>))\nq2_data <span class=\"pl-k\">=</span> np.load(<span class=\"pl-c1\">open</span>(<span class=\"pl-c1\">Q2_TRAINING_DATA_FILE</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>))\nlabels <span class=\"pl-k\">=</span> np.load(<span class=\"pl-c1\">open</span>(<span class=\"pl-c1\">LABEL_TRAINING_DATA_FILE</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>))\n\nX <span class=\"pl-k\">=</span> np.stack((q1_data, q2_data), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\ny <span class=\"pl-k\">=</span> labels\nX_train, X_test, y_train, y_test <span class=\"pl-k\">=</span> train_test_split(X, y, <span class=\"pl-v\">test_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">TEST_SPLIT</span>, <span class=\"pl-v\">random_state</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">RNG_SEED</span>)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Preparing Numpy Input_Fn for both train and test<span class=\"pl-pds\">'</span></span>)\ntrain_input_fn <span class=\"pl-k\">=</span> numpy_io.numpy_input_fn(<span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>: X_train}, <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>y_train, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">BATCH_SIZE</span>,\n                                         <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>)\n\ntest_input_fn <span class=\"pl-k\">=</span> numpy_io.numpy_input_fn(<span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>: X_test}, <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>y_test, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\nnn <span class=\"pl-k\">=</span> tf.estimator.Estimator(<span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>model_fn, <span class=\"pl-v\">params</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">model_dir</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>build/<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Training...............<span class=\"pl-pds\">'</span></span>)\nnn.train(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>train_input_fn, <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Training Complete, Evaluating............<span class=\"pl-pds\">'</span></span>)\nev <span class=\"pl-k\">=</span> nn.evaluate(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>test_input_fn)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Loss: <span class=\"pl-c1\">%s</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> ev[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>loss<span class=\"pl-pds\">\"</span></span>])\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Accuracy: <span class=\"pl-c1\">%s</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> ev[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>accuracy<span class=\"pl-pds\">\"</span></span>])\n</pre></div>\n<p><strong>Exception:</strong><br>\nTraceback (most recent call last):<br>\nFile \"D:/PlayGround/Git/Coding2Fun/Blog/DeepLearning/Quora-NLP/model.py\", line 103, in <br>\nnn.train(input_fn=train_input_fn, steps=100)<br>\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train<br>\nloss = self._train_model(input_fn=input_fn, hooks=hooks)<br>\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 630, in _train_model<br>\nmodel_fn_lib.ModeKeys.TRAIN)<br>\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 615, in _call_model_fn<br>\nmodel_fn_results = self._model_fn(features=features, **kwargs)<br>\nFile \"D:/PlayGround/Git/Coding2Fun/Blog/DeepLearning/Quora-NLP/model.py\", line 38, in model_fn<br>\nq1 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q1)<br>\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\engine\\topology.py\", line 396, in <strong>call</strong><br>\noutput = super(Layer, self).<strong>call</strong>(inputs, **kwargs)<br>\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 450, in <strong>call</strong><br>\noutputs = self.call(inputs, *args, **kwargs)<br>\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\layers\\wrappers.py\", line 208, in call<br>\nunroll=False)<br>\n<strong>TypeError: rnn() got an unexpected keyword argument 'input_length'</strong></p>", "body_text": "When I use TimeDistributed  wrapper from keras I'm getting unexpected keyword argument 'input_length'\nSystem Info:\nWindows 10\nTF 1.3.0\nPython 3.5\nCode :\nimport json\n\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.contrib.keras import layers\nfrom tensorflow.contrib.keras.python.keras.layers.wrappers import TimeDistributed\nfrom tensorflow.python.estimator.inputs import numpy_io\n\nMAX_NB_WORDS = 200000\nMAX_SEQUENCE_LENGTH = 25\nEMBEDDING_DIM = 300\nVALIDATION_SPLIT = 0.1\nTEST_SPLIT = 0.1\nRNG_SEED = 13371447\nNB_EPOCHS = 25\nDROPOUT = 0.1\nBATCH_SIZE = 32\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\nQ1_TRAINING_DATA_FILE = 'gen/q1_train.npy'\nQ2_TRAINING_DATA_FILE = 'gen/q2_train.npy'\nLABEL_TRAINING_DATA_FILE = 'gen/label_train.npy'\nNB_WORDS_DATA_FILE = 'gen/nb_words.json'\nwith open(NB_WORDS_DATA_FILE, 'r') as f:\n    nb_words = json.load(f)['nb_words']\n\n\ndef model_fn(features, labels, mode, params):\n    input_data = features['x']\n\n    Q1_Data = input_data[:, 0]\n    Q2_Data = input_data[:, 1]\n\n    q1 = layers.Embedding(nb_words + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(Q1_Data)\n    q1 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q1)\n    q1 = layers.Lambda(lambda x: tf.reduce_max(x, axis=1, keep_dims=False))(q1)\n\n    q2 = layers.Embedding(nb_words + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(Q2_Data)\n    q2 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q2)\n    q2 = layers.Lambda(lambda x: tf.reduce_max(x, axis=1, keep_dims=False))(q2)\n\n    merged = layers.concatenate([q1, q2])\n    # merged = layers.Flatten()(merged)\n    merged = layers.Dense(200, activation='relu')(merged)\n    merged = tf.layers.dropout(merged, rate=DROPOUT)\n    merged = layers.Dense(200, activation='relu')(merged)\n    merged = tf.layers.dropout(merged, rate=DROPOUT)\n    merged = layers.Dense(200, activation='relu')(merged)\n    merged = tf.layers.dropout(merged, rate=DROPOUT)\n    merged = layers.Dense(200, activation='relu')(merged)\n    merged = tf.layers.dropout(merged, rate=DROPOUT)\n\n    predictions = layers.Dense(1)(merged)\n\n    predictions = tf.reshape(predictions, [-1])\n\n    train_op = None\n    eval_metric_ops = None\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(\n            mode=mode,\n            predictions={\"duplicate\": predictions})\n\n    loss = tf.losses.sigmoid_cross_entropy(labels, predictions)\n    optimizer = tf.train.AdamOptimizer()\n    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n\n    eval_metric_ops = {\n        \"accuracy\": tf.metrics.accuracy(labels, predictions)\n    }\n\n    print(predictions)\n\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metric_ops)\n\n\nprint('\\n')\nprint('Loading Numpy inputs')\nq1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\nq2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\nlabels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\n\nX = np.stack((q1_data, q2_data), axis=1)\ny = labels\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n\nprint('\\n')\nprint('Preparing Numpy Input_Fn for both train and test')\ntrain_input_fn = numpy_io.numpy_input_fn(x={'x': X_train}, y=y_train, shuffle=True, batch_size=BATCH_SIZE,\n                                         num_epochs=None)\n\ntest_input_fn = numpy_io.numpy_input_fn(x={'x': X_test}, y=y_test, shuffle=False, batch_size=BATCH_SIZE, num_epochs=1)\n\nnn = tf.estimator.Estimator(model_fn=model_fn, params=None, model_dir='build/')\n\nprint('\\n')\nprint('Training...............')\nnn.train(input_fn=train_input_fn, steps=100)\n\nprint('\\n')\nprint('Training Complete, Evaluating............')\nev = nn.evaluate(input_fn=test_input_fn)\nprint(\"Loss: %s\" % ev[\"loss\"])\nprint(\"Accuracy: %s\" % ev[\"accuracy\"])\n\nException:\nTraceback (most recent call last):\nFile \"D:/PlayGround/Git/Coding2Fun/Blog/DeepLearning/Quora-NLP/model.py\", line 103, in \nnn.train(input_fn=train_input_fn, steps=100)\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\nloss = self._train_model(input_fn=input_fn, hooks=hooks)\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 630, in _train_model\nmodel_fn_lib.ModeKeys.TRAIN)\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 615, in _call_model_fn\nmodel_fn_results = self._model_fn(features=features, **kwargs)\nFile \"D:/PlayGround/Git/Coding2Fun/Blog/DeepLearning/Quora-NLP/model.py\", line 38, in model_fn\nq1 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q1)\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\engine\\topology.py\", line 396, in call\noutput = super(Layer, self).call(inputs, **kwargs)\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 450, in call\noutputs = self.call(inputs, *args, **kwargs)\nFile \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\layers\\wrappers.py\", line 208, in call\nunroll=False)\nTypeError: rnn() got an unexpected keyword argument 'input_length'", "body": "When I use TimeDistributed  wrapper from keras I'm getting unexpected keyword argument 'input_length'\r\n\r\n# **System Info:**\r\n\r\n**Windows 10**\r\n**TF 1.3.0**\r\n**Python 3.5**\r\n\r\n**Code :**\r\n\r\n```python\r\nimport json\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom sklearn.model_selection import train_test_split\r\nfrom tensorflow.contrib.keras import layers\r\nfrom tensorflow.contrib.keras.python.keras.layers.wrappers import TimeDistributed\r\nfrom tensorflow.python.estimator.inputs import numpy_io\r\n\r\nMAX_NB_WORDS = 200000\r\nMAX_SEQUENCE_LENGTH = 25\r\nEMBEDDING_DIM = 300\r\nVALIDATION_SPLIT = 0.1\r\nTEST_SPLIT = 0.1\r\nRNG_SEED = 13371447\r\nNB_EPOCHS = 25\r\nDROPOUT = 0.1\r\nBATCH_SIZE = 32\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\nQ1_TRAINING_DATA_FILE = 'gen/q1_train.npy'\r\nQ2_TRAINING_DATA_FILE = 'gen/q2_train.npy'\r\nLABEL_TRAINING_DATA_FILE = 'gen/label_train.npy'\r\nNB_WORDS_DATA_FILE = 'gen/nb_words.json'\r\nwith open(NB_WORDS_DATA_FILE, 'r') as f:\r\n    nb_words = json.load(f)['nb_words']\r\n\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    input_data = features['x']\r\n\r\n    Q1_Data = input_data[:, 0]\r\n    Q2_Data = input_data[:, 1]\r\n\r\n    q1 = layers.Embedding(nb_words + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(Q1_Data)\r\n    q1 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q1)\r\n    q1 = layers.Lambda(lambda x: tf.reduce_max(x, axis=1, keep_dims=False))(q1)\r\n\r\n    q2 = layers.Embedding(nb_words + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(Q2_Data)\r\n    q2 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q2)\r\n    q2 = layers.Lambda(lambda x: tf.reduce_max(x, axis=1, keep_dims=False))(q2)\r\n\r\n    merged = layers.concatenate([q1, q2])\r\n    # merged = layers.Flatten()(merged)\r\n    merged = layers.Dense(200, activation='relu')(merged)\r\n    merged = tf.layers.dropout(merged, rate=DROPOUT)\r\n    merged = layers.Dense(200, activation='relu')(merged)\r\n    merged = tf.layers.dropout(merged, rate=DROPOUT)\r\n    merged = layers.Dense(200, activation='relu')(merged)\r\n    merged = tf.layers.dropout(merged, rate=DROPOUT)\r\n    merged = layers.Dense(200, activation='relu')(merged)\r\n    merged = tf.layers.dropout(merged, rate=DROPOUT)\r\n\r\n    predictions = layers.Dense(1)(merged)\r\n\r\n    predictions = tf.reshape(predictions, [-1])\r\n\r\n    train_op = None\r\n    eval_metric_ops = None\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            predictions={\"duplicate\": predictions})\r\n\r\n    loss = tf.losses.sigmoid_cross_entropy(labels, predictions)\r\n    optimizer = tf.train.AdamOptimizer()\r\n    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\r\n\r\n    eval_metric_ops = {\r\n        \"accuracy\": tf.metrics.accuracy(labels, predictions)\r\n    }\r\n\r\n    print(predictions)\r\n\r\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metric_ops)\r\n\r\n\r\nprint('\\n')\r\nprint('Loading Numpy inputs')\r\nq1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\r\nq2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\r\nlabels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\r\n\r\nX = np.stack((q1_data, q2_data), axis=1)\r\ny = labels\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\r\n\r\nprint('\\n')\r\nprint('Preparing Numpy Input_Fn for both train and test')\r\ntrain_input_fn = numpy_io.numpy_input_fn(x={'x': X_train}, y=y_train, shuffle=True, batch_size=BATCH_SIZE,\r\n                                         num_epochs=None)\r\n\r\ntest_input_fn = numpy_io.numpy_input_fn(x={'x': X_test}, y=y_test, shuffle=False, batch_size=BATCH_SIZE, num_epochs=1)\r\n\r\nnn = tf.estimator.Estimator(model_fn=model_fn, params=None, model_dir='build/')\r\n\r\nprint('\\n')\r\nprint('Training...............')\r\nnn.train(input_fn=train_input_fn, steps=100)\r\n\r\nprint('\\n')\r\nprint('Training Complete, Evaluating............')\r\nev = nn.evaluate(input_fn=test_input_fn)\r\nprint(\"Loss: %s\" % ev[\"loss\"])\r\nprint(\"Accuracy: %s\" % ev[\"accuracy\"])\r\n\r\n```\r\n\r\n**Exception:**\r\nTraceback (most recent call last):\r\n  File \"D:/PlayGround/Git/Coding2Fun/Blog/DeepLearning/Quora-NLP/model.py\", line 103, in <module>\r\n    nn.train(input_fn=train_input_fn, steps=100)\r\n  File \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 630, in _train_model\r\n    model_fn_lib.ModeKeys.TRAIN)\r\n  File \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 615, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"D:/PlayGround/Git/Coding2Fun/Blog/DeepLearning/Quora-NLP/model.py\", line 38, in model_fn\r\n    q1 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q1)\r\n  File \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\engine\\topology.py\", line 396, in __call__\r\n    output = super(Layer, self).__call__(inputs, **kwargs)\r\n  File \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 450, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"D:\\Programs\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\layers\\wrappers.py\", line 208, in call\r\n    unroll=False)\r\n**TypeError: rnn() got an unexpected keyword argument 'input_length'**"}