{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21224", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21224/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21224/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21224/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21224", "id": 345545477, "node_id": "MDU6SXNzdWUzNDU1NDU0Nzc=", "number": 21224, "title": "tf.while_loop - Eager mode allows a changing input size by default, while Graph mode does not", "user": {"login": "RanFeldesh", "id": 8627404, "node_id": "MDQ6VXNlcjg2Mjc0MDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8627404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RanFeldesh", "html_url": "https://github.com/RanFeldesh", "followers_url": "https://api.github.com/users/RanFeldesh/followers", "following_url": "https://api.github.com/users/RanFeldesh/following{/other_user}", "gists_url": "https://api.github.com/users/RanFeldesh/gists{/gist_id}", "starred_url": "https://api.github.com/users/RanFeldesh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RanFeldesh/subscriptions", "organizations_url": "https://api.github.com/users/RanFeldesh/orgs", "repos_url": "https://api.github.com/users/RanFeldesh/repos", "events_url": "https://api.github.com/users/RanFeldesh/events{/privacy}", "received_events_url": "https://api.github.com/users/RanFeldesh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-07-29T16:52:29Z", "updated_at": "2018-11-14T19:23:47Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: YES</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Window10</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: Unknown</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>: CPU version</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>With tf.while_loop - Eager mode allows a changing input size by default, while Graph mode does not.<br>\nThis seems to me like a consistency issue.<br>\nWhen eager and graph mode are consistent it allows to debug in eager, and when done run as graph. Inconsistency between eager and graph modes requires an extra debugging step in the graph mode.</p>\n<p>The error message in graph mode:<br>\n\"ValueError: Input tensor 'while/Const_1:0' enters the loop with shape (), but has shape (2, 1) after one iteration. To allow the shape to vary across iterations, use the <code>shape_invariants</code> argument of tf.while_loop to specify a less-specific shape.\"<br>\nBut works perfectly in eager mode.</p>\n<h3>Source code / logs</h3>\n<p>*** EAGER (WORKS) ***:<br>\nimport tensorflow as tf<br>\nimport numpy as np<br>\ntf.enable_eager_execution()</p>\n<p>batch = 2<br>\ntime = 3<br>\ninput_depth = 5<br>\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))</p>\n<p>def timestep(t, dns_output):<br>\ndns_output = dns(inpt)<br>\nreturn t+1, dns_output</p>\n<p>dns = tf.layers.Dense(units=1)<br>\n_, dns_output = tf.while_loop(lambda t, dns_output: t &lt; time, timestep, (0, 0))</p>\n<p>print(dns_output)</p>\n<p>***Graph (Error)***:<br>\nimport tensorflow as tf<br>\nimport numpy as np</p>\n<p>batch = 2<br>\ntime = 3<br>\ninput_depth = 5<br>\ndense_units = 1<br>\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))</p>\n<p>def timestep(t, dns_output):<br>\ndns_output = dns(inpt)<br>\nprint(dns_output)<br>\nreturn t+1, dns_output</p>\n<p>dns = tf.layers.Dense(units=dense_units)</p>\n<p>_, dns_output1 = tf.while_loop(lambda t, dns_output: t &lt; time, timestep, (0, 0))</p>\n<p>sess = tf.Session()<br>\nsess.run(tf.global_variables_initializer())<br>\nout = sess.run(dns_output1)<br>\nprint(out)</p>\n<p>***Graph (No Error, works)***:<br>\nimport tensorflow as tf<br>\nimport numpy as np</p>\n<p>batch = 2<br>\ntime = 3<br>\ninput_depth = 5<br>\ndense_units = 1<br>\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))</p>\n<p>def timestep(t, dns_output):<br>\ndns_output = dns(inpt)<br>\nreturn t+1, dns_output</p>\n<p>dns = tf.layers.Dense(units=dense_units)<br>\ndns_output_temp = tf.zeros(shape=[batch, dense_units])<br>\n_, dns_output1 = tf.while_loop(lambda t, dns_output: t &lt; time, timestep, (0, dns_output_temp))</p>\n<p>sess = tf.Session()<br>\nsess.run(tf.global_variables_initializer())<br>\nout = sess.run(dns_output1)<br>\nprint(out)</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window10\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Unknown\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): 1.9\nPython version: 3.6\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source): NA\nCUDA/cuDNN version: NA\nGPU model and memory: CPU version\nExact command to reproduce:\n\nDescribe the problem\nWith tf.while_loop - Eager mode allows a changing input size by default, while Graph mode does not.\nThis seems to me like a consistency issue.\nWhen eager and graph mode are consistent it allows to debug in eager, and when done run as graph. Inconsistency between eager and graph modes requires an extra debugging step in the graph mode.\nThe error message in graph mode:\n\"ValueError: Input tensor 'while/Const_1:0' enters the loop with shape (), but has shape (2, 1) after one iteration. To allow the shape to vary across iterations, use the shape_invariants argument of tf.while_loop to specify a less-specific shape.\"\nBut works perfectly in eager mode.\nSource code / logs\n*** EAGER (WORKS) ***:\nimport tensorflow as tf\nimport numpy as np\ntf.enable_eager_execution()\nbatch = 2\ntime = 3\ninput_depth = 5\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))\ndef timestep(t, dns_output):\ndns_output = dns(inpt)\nreturn t+1, dns_output\ndns = tf.layers.Dense(units=1)\n_, dns_output = tf.while_loop(lambda t, dns_output: t < time, timestep, (0, 0))\nprint(dns_output)\n***Graph (Error)***:\nimport tensorflow as tf\nimport numpy as np\nbatch = 2\ntime = 3\ninput_depth = 5\ndense_units = 1\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))\ndef timestep(t, dns_output):\ndns_output = dns(inpt)\nprint(dns_output)\nreturn t+1, dns_output\ndns = tf.layers.Dense(units=dense_units)\n_, dns_output1 = tf.while_loop(lambda t, dns_output: t < time, timestep, (0, 0))\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nout = sess.run(dns_output1)\nprint(out)\n***Graph (No Error, works)***:\nimport tensorflow as tf\nimport numpy as np\nbatch = 2\ntime = 3\ninput_depth = 5\ndense_units = 1\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))\ndef timestep(t, dns_output):\ndns_output = dns(inpt)\nreturn t+1, dns_output\ndns = tf.layers.Dense(units=dense_units)\ndns_output_temp = tf.zeros(shape=[batch, dense_units])\n_, dns_output1 = tf.while_loop(lambda t, dns_output: t < time, timestep, (0, dns_output_temp))\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nout = sess.run(dns_output1)\nprint(out)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Window10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Unknown\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: CPU version\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWith tf.while_loop - Eager mode allows a changing input size by default, while Graph mode does not.\r\nThis seems to me like a consistency issue.\r\nWhen eager and graph mode are consistent it allows to debug in eager, and when done run as graph. Inconsistency between eager and graph modes requires an extra debugging step in the graph mode. \r\n\r\nThe error message in graph mode:\r\n\"ValueError: Input tensor 'while/Const_1:0' enters the loop with shape (), but has shape (2, 1) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.\"\r\nBut works perfectly in eager mode.\r\n### Source code / logs\r\n*** EAGER (WORKS) ***:\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.enable_eager_execution()\r\n\r\nbatch = 2\r\ntime = 3\r\ninput_depth = 5\r\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))\r\n\r\ndef timestep(t, dns_output):\r\n    dns_output = dns(inpt)\r\n    return t+1, dns_output\r\n\r\n\r\ndns = tf.layers.Dense(units=1)\r\n_, dns_output = tf.while_loop(lambda t, dns_output: t < time, timestep, (0, 0))\r\n\r\nprint(dns_output)\r\n\r\n***Graph (Error)***:\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nbatch = 2\r\ntime = 3\r\ninput_depth = 5\r\ndense_units = 1\r\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))\r\n\r\ndef timestep(t, dns_output):\r\n    dns_output = dns(inpt)\r\n    print(dns_output)\r\n    return t+1, dns_output\r\n\r\n\r\ndns = tf.layers.Dense(units=dense_units)\r\n\r\n_, dns_output1 = tf.while_loop(lambda t, dns_output: t < time, timestep, (0, 0))\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nout = sess.run(dns_output1)\r\nprint(out)\r\n\r\n***Graph (No Error, works)***:\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nbatch = 2\r\ntime = 3\r\ninput_depth = 5\r\ndense_units = 1\r\ninpt = tf.constant(np.random.normal(size=(batch, input_depth)).astype(np.float32))\r\n\r\ndef timestep(t, dns_output):\r\n    dns_output = dns(inpt)\r\n    return t+1, dns_output\r\n\r\n\r\ndns = tf.layers.Dense(units=dense_units)\r\ndns_output_temp = tf.zeros(shape=[batch, dense_units])\r\n_, dns_output1 = tf.while_loop(lambda t, dns_output: t < time, timestep, (0, dns_output_temp))\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nout = sess.run(dns_output1)\r\nprint(out)\r\n"}