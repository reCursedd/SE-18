{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3430", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3430/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3430/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3430/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3430", "id": 166702941, "node_id": "MDU6SXNzdWUxNjY3MDI5NDE=", "number": 3430, "title": "Ignoring gpu device with Cuda multiprocessor count: 7.", "user": {"login": "gaphex", "id": 4992480, "node_id": "MDQ6VXNlcjQ5OTI0ODA=", "avatar_url": "https://avatars3.githubusercontent.com/u/4992480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaphex", "html_url": "https://github.com/gaphex", "followers_url": "https://api.github.com/users/gaphex/followers", "following_url": "https://api.github.com/users/gaphex/following{/other_user}", "gists_url": "https://api.github.com/users/gaphex/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaphex/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaphex/subscriptions", "organizations_url": "https://api.github.com/users/gaphex/orgs", "repos_url": "https://api.github.com/users/gaphex/repos", "events_url": "https://api.github.com/users/gaphex/events{/privacy}", "received_events_url": "https://api.github.com/users/gaphex/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-07-20T23:06:59Z", "updated_at": "2016-07-26T19:22:51Z", "closed_at": "2016-07-26T19:22:50Z", "author_association": "NONE", "body_html": "<p>I am unable to run TF on a GPU, despite the fact that I have 2 CUDA-enabled K4200 NVIDIA QUATTRO (Compute Capability 3.0)</p>\n<h3>Environment info</h3>\n<p>Operating System: linux 14.04 x64</p>\n<p>Installed version of CUDA and cuDNN:</p>\n<ol>\n<li>CUDA 7.5</li>\n<li>cuDNN 4</li>\n</ol>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Ubuntu/Linux 64-bit, GPU enabled, Python 2.7</li>\n<li>TF v0.9.0</li>\n</ol>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Run IPython Notebook</li>\n<li>Run a tensorflow session (I was doing Udacity DL course)</li>\n<li>In IPython log, observe:</li>\n</ol>\n<p>I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: Quadro K4200<br>\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.784<br>\npciBusID 0000:03:00.0<br>\nTotal memory: 4.00GiB<br>\nFree memory: 3.96GiB<br>\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3b717e0<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:<br>\nname: Quadro K4200<br>\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.784<br>\npciBusID 0000:04:00.0<br>\nTotal memory: 4.00GiB<br>\nFree memory: 3.86GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:793] Ignoring gpu device (device: 0, name: Quadro K4200, pci bus id: 0000:03:00.0) with Cuda multiprocessor count: 7. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:793] Ignoring gpu device (device: 1, name: Quadro K4200, pci bus id: 0000:04:00.0) with Cuda multiprocessor count: 7. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.</p>\n<h3>What have you tried?</h3>\n<ol>\n<li>Setting TF_MIN_GPU_MULTIPROCESSOR_COUNT to 4, both locally and system-wide</li>\n</ol>\n<h3>Logs or other output that would be helpful</h3>\n<p>echo $TF_MIN_GPU_MULTIPROCESSOR_COUNT<br>\n4</p>\n<p>Am I missing something? Setting the environment variable seems to have no effect.</p>", "body_text": "I am unable to run TF on a GPU, despite the fact that I have 2 CUDA-enabled K4200 NVIDIA QUATTRO (Compute Capability 3.0)\nEnvironment info\nOperating System: linux 14.04 x64\nInstalled version of CUDA and cuDNN:\n\nCUDA 7.5\ncuDNN 4\n\nIf installed from binary pip package, provide:\n\nUbuntu/Linux 64-bit, GPU enabled, Python 2.7\nTF v0.9.0\n\nSteps to reproduce\n\nRun IPython Notebook\nRun a tensorflow session (I was doing Udacity DL course)\nIn IPython log, observe:\n\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: Quadro K4200\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.784\npciBusID 0000:03:00.0\nTotal memory: 4.00GiB\nFree memory: 3.96GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3b717e0\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:\nname: Quadro K4200\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.784\npciBusID 0000:04:00.0\nTotal memory: 4.00GiB\nFree memory: 3.86GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:793] Ignoring gpu device (device: 0, name: Quadro K4200, pci bus id: 0000:03:00.0) with Cuda multiprocessor count: 7. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:793] Ignoring gpu device (device: 1, name: Quadro K4200, pci bus id: 0000:04:00.0) with Cuda multiprocessor count: 7. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\nWhat have you tried?\n\nSetting TF_MIN_GPU_MULTIPROCESSOR_COUNT to 4, both locally and system-wide\n\nLogs or other output that would be helpful\necho $TF_MIN_GPU_MULTIPROCESSOR_COUNT\n4\nAm I missing something? Setting the environment variable seems to have no effect.", "body": "I am unable to run TF on a GPU, despite the fact that I have 2 CUDA-enabled K4200 NVIDIA QUATTRO (Compute Capability 3.0)\n### Environment info\n\nOperating System: linux 14.04 x64\n\nInstalled version of CUDA and cuDNN: \n1. CUDA 7.5\n2. cuDNN 4\n\nIf installed from binary pip package, provide:\n1. Ubuntu/Linux 64-bit, GPU enabled, Python 2.7\n2. TF v0.9.0\n### Steps to reproduce\n1. Run IPython Notebook\n2. Run a tensorflow session (I was doing Udacity DL course)\n3. In IPython log, observe:\n\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: Quadro K4200\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.784\npciBusID 0000:03:00.0\nTotal memory: 4.00GiB\nFree memory: 3.96GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3b717e0\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:\nname: Quadro K4200\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.784\npciBusID 0000:04:00.0\nTotal memory: 4.00GiB\nFree memory: 3.86GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:793] Ignoring gpu device (device: 0, name: Quadro K4200, pci bus id: 0000:03:00.0) with Cuda multiprocessor count: 7. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:793] Ignoring gpu device (device: 1, name: Quadro K4200, pci bus id: 0000:04:00.0) with Cuda multiprocessor count: 7. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n### What have you tried?\n1. Setting TF_MIN_GPU_MULTIPROCESSOR_COUNT to 4, both locally and system-wide\n### Logs or other output that would be helpful\n\necho $TF_MIN_GPU_MULTIPROCESSOR_COUNT\n4\n\nAm I missing something? Setting the environment variable seems to have no effect.\n"}