{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19573", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19573/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19573/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19573/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19573", "id": 326746091, "node_id": "MDU6SXNzdWUzMjY3NDYwOTE=", "number": 19573, "title": "UnicodeDecodeError from tf.train.import_meta_graph", "user": {"login": "reid-fu", "id": 11605043, "node_id": "MDQ6VXNlcjExNjA1MDQz", "avatar_url": "https://avatars2.githubusercontent.com/u/11605043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reid-fu", "html_url": "https://github.com/reid-fu", "followers_url": "https://api.github.com/users/reid-fu/followers", "following_url": "https://api.github.com/users/reid-fu/following{/other_user}", "gists_url": "https://api.github.com/users/reid-fu/gists{/gist_id}", "starred_url": "https://api.github.com/users/reid-fu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reid-fu/subscriptions", "organizations_url": "https://api.github.com/users/reid-fu/orgs", "repos_url": "https://api.github.com/users/reid-fu/repos", "events_url": "https://api.github.com/users/reid-fu/events{/privacy}", "received_events_url": "https://api.github.com/users/reid-fu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-26T15:25:56Z", "updated_at": "2018-06-22T16:08:49Z", "closed_at": "2018-06-22T16:08:49Z", "author_association": "NONE", "body_html": "<p>I serialized a Tensorflow model with the following code ...</p>\n<pre><code>save_path = self.saver.save(self.session, os.path.join(self.logdir, \"model.ckpt\"), global_step)\nlogging.info(\"Model saved in file: %s\" % save_path)\n</code></pre>\n<p>... and I'm now trying to restore it from scratch in a separate file using the following code:</p>\n<pre><code>saver = tf.train.import_meta_graph(PROJ_DIR + '/logs/default/model.ckpt-54.meta')\nsession = tf.Session()\nsaver.restore(session, PROJ_DIR + '/logs/default/model.ckpt-54')\nprint('Model restored')\n</code></pre>\n<p>When <code>tf.train.import_meta_graph</code> is called, the following exception is thrown:</p>\n<pre><code>[libprotobuf ERROR google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\nTraceback (most recent call last):\n  File \"/home/reid/projects/research/ccg/taggerflow_modified/test/tf_restore.py\", line 4, in &lt;module&gt;\nsaver = tf.train.import_meta_graph(PROJ_DIR + '/logs/default/model.ckpt-54.meta')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1711, in import_meta_graph\nread_meta_graph_file(meta_graph_or_file), clear_devices)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1563, in read_meta_graph_file\ntext_format.Merge(file_content.decode(\"utf-8\"), meta_graph_def)\n  File \"/usr/lib/python2.7/encodings/utf_8.py\", line 16, in decode\nreturn codecs.utf_8_decode(input, errors, True)\nUnicodeDecodeError: 'utf8' codec can't decode byte 0xa7 in position 1: invalid start byte\n</code></pre>\n<p>For reference, here's the first few lines of <code>&lt;PROJ_DIR&gt;/logs/default/model.ckpt-54.meta</code>:</p>\n<pre><code>&lt;A7&gt;:^R&lt;A4&gt;:\n9\n^CAdd^R^F\n^Ax\"^AT^R^F\n^Ay\"^AT^Z^F\n^Az\"^AT\"^Z\n^AT^R^Dtype:^O\n^M2^K^S^A^B^D^F^E^C    ^R^G\n</code></pre>\n<p>I think that Tensorflow is using a different encoding when serializing vs when deserializing. How do we specify the encoding that Tensorflow uses when serializing/deserializing? Or is the solution something different?</p>\n<p>This was originally a Stack Overflow question. Someone asked me to make it a GitHub issue. I'm using version r0.11.</p>", "body_text": "I serialized a Tensorflow model with the following code ...\nsave_path = self.saver.save(self.session, os.path.join(self.logdir, \"model.ckpt\"), global_step)\nlogging.info(\"Model saved in file: %s\" % save_path)\n\n... and I'm now trying to restore it from scratch in a separate file using the following code:\nsaver = tf.train.import_meta_graph(PROJ_DIR + '/logs/default/model.ckpt-54.meta')\nsession = tf.Session()\nsaver.restore(session, PROJ_DIR + '/logs/default/model.ckpt-54')\nprint('Model restored')\n\nWhen tf.train.import_meta_graph is called, the following exception is thrown:\n[libprotobuf ERROR google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\nTraceback (most recent call last):\n  File \"/home/reid/projects/research/ccg/taggerflow_modified/test/tf_restore.py\", line 4, in <module>\nsaver = tf.train.import_meta_graph(PROJ_DIR + '/logs/default/model.ckpt-54.meta')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1711, in import_meta_graph\nread_meta_graph_file(meta_graph_or_file), clear_devices)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1563, in read_meta_graph_file\ntext_format.Merge(file_content.decode(\"utf-8\"), meta_graph_def)\n  File \"/usr/lib/python2.7/encodings/utf_8.py\", line 16, in decode\nreturn codecs.utf_8_decode(input, errors, True)\nUnicodeDecodeError: 'utf8' codec can't decode byte 0xa7 in position 1: invalid start byte\n\nFor reference, here's the first few lines of <PROJ_DIR>/logs/default/model.ckpt-54.meta:\n<A7>:^R<A4>:\n9\n^CAdd^R^F\n^Ax\"^AT^R^F\n^Ay\"^AT^Z^F\n^Az\"^AT\"^Z\n^AT^R^Dtype:^O\n^M2^K^S^A^B^D^F^E^C    ^R^G\n\nI think that Tensorflow is using a different encoding when serializing vs when deserializing. How do we specify the encoding that Tensorflow uses when serializing/deserializing? Or is the solution something different?\nThis was originally a Stack Overflow question. Someone asked me to make it a GitHub issue. I'm using version r0.11.", "body": "I serialized a Tensorflow model with the following code ...\r\n\r\n    save_path = self.saver.save(self.session, os.path.join(self.logdir, \"model.ckpt\"), global_step)\r\n    logging.info(\"Model saved in file: %s\" % save_path)\r\n\r\n... and I'm now trying to restore it from scratch in a separate file using the following code:\r\n\r\n    saver = tf.train.import_meta_graph(PROJ_DIR + '/logs/default/model.ckpt-54.meta')\r\n    session = tf.Session()\r\n    saver.restore(session, PROJ_DIR + '/logs/default/model.ckpt-54')\r\n    print('Model restored')\r\n\r\nWhen `tf.train.import_meta_graph` is called, the following exception is thrown:\r\n\r\n    [libprotobuf ERROR google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\r\n    Traceback (most recent call last):\r\n      File \"/home/reid/projects/research/ccg/taggerflow_modified/test/tf_restore.py\", line 4, in <module>\r\n    saver = tf.train.import_meta_graph(PROJ_DIR + '/logs/default/model.ckpt-54.meta')\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1711, in import_meta_graph\r\n    read_meta_graph_file(meta_graph_or_file), clear_devices)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1563, in read_meta_graph_file\r\n    text_format.Merge(file_content.decode(\"utf-8\"), meta_graph_def)\r\n      File \"/usr/lib/python2.7/encodings/utf_8.py\", line 16, in decode\r\n    return codecs.utf_8_decode(input, errors, True)\r\n    UnicodeDecodeError: 'utf8' codec can't decode byte 0xa7 in position 1: invalid start byte\r\n\r\nFor reference, here's the first few lines of `<PROJ_DIR>/logs/default/model.ckpt-54.meta`:\r\n\r\n    <A7>:^R<A4>:\r\n    9\r\n    ^CAdd^R^F\r\n    ^Ax\"^AT^R^F\r\n    ^Ay\"^AT^Z^F\r\n    ^Az\"^AT\"^Z\r\n    ^AT^R^Dtype:^O\r\n    ^M2^K^S^A^B^D^F^E^C    ^R^G\r\n\r\nI think that Tensorflow is using a different encoding when serializing vs when deserializing. How do we specify the encoding that Tensorflow uses when serializing/deserializing? Or is the solution something different?\r\n\r\nThis was originally a Stack Overflow question. Someone asked me to make it a GitHub issue. I'm using version r0.11."}