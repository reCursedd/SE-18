{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23914", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23914/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23914/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23914/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23914", "id": 383368583, "node_id": "MDU6SXNzdWUzODMzNjg1ODM=", "number": 23914, "title": "Weird behavior of tf.math.reduce_max", "user": {"login": "WindQAQ", "id": 11615393, "node_id": "MDQ6VXNlcjExNjE1Mzkz", "avatar_url": "https://avatars2.githubusercontent.com/u/11615393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WindQAQ", "html_url": "https://github.com/WindQAQ", "followers_url": "https://api.github.com/users/WindQAQ/followers", "following_url": "https://api.github.com/users/WindQAQ/following{/other_user}", "gists_url": "https://api.github.com/users/WindQAQ/gists{/gist_id}", "starred_url": "https://api.github.com/users/WindQAQ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WindQAQ/subscriptions", "organizations_url": "https://api.github.com/users/WindQAQ/orgs", "repos_url": "https://api.github.com/users/WindQAQ/repos", "events_url": "https://api.github.com/users/WindQAQ/events{/privacy}", "received_events_url": "https://api.github.com/users/WindQAQ/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-22T03:34:08Z", "updated_at": "2018-11-22T03:34:08Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0</li>\n<li>Python version: 3.6.6</li>\n<li>Bazel version (if compiling from source): None</li>\n<li>GCC/Compiler version (if compiling from source): None</li>\n<li>CUDA/cuDNN version: 9.0/7</li>\n<li>GPU model and memory: GeForce GTX 1080 Ti, 11G</li>\n</ul>\n<p><strong>Describe the current behavior</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> tf.enable_eager_execution()</span>\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">test_bug</span>():\n    <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> tf.convert_to_tensor(np.ones((<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32))\n    x <span class=\"pl-k\">=</span> tf.layers.conv2d(<span class=\"pl-c1\">input</span>, <span class=\"pl-c1\">1</span>, (<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tanh<span class=\"pl-pds\">\"</span></span>,\n                         <span class=\"pl-v\">kernel_initializer</span><span class=\"pl-k\">=</span>tf.initializers.constant(<span class=\"pl-c1\">2</span>),\n                         <span class=\"pl-v\">use_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    max_out <span class=\"pl-k\">=</span> tf.math.reduce_max(x, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>])\n\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(tf.global_variables_initializer())\n        m <span class=\"pl-k\">=</span> sess.run(max_out)\n        m1, _ <span class=\"pl-k\">=</span> sess.run([max_out, x])\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>m =<span class=\"pl-pds\">'</span></span>, m)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>m1 =<span class=\"pl-pds\">'</span></span>, m1)\n        <span class=\"pl-k\">assert</span> np.allclose(m, m1)\n\ntest_bug()</pre></div>\n<p>I'd suppose that the assertion should pass given above code. However, <code>tf.math.reduce_max</code> looks very strange:</p>\n<pre><code>m = [[2.]]\nm1 = [[0.9640276]]\n</code></pre>\n<p><strong>Describe the expected behavior</strong><br>\n<code>m</code> and <code>m1</code> should have the same value and the assertion should pass.</p>\n<pre><code>m = [[0.9640276]]\nm1 = [[0.9640276]]\n</code></pre>\n<p><strong>Code to reproduce the issue</strong><br>\nListed above.</p>\n<p><strong>Other info / logs</strong><br>\nIf eager execution is enabled, then the value of <code>x</code> and <code>max_out</code> is the same.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\nPython version: 3.6.6\nBazel version (if compiling from source): None\nGCC/Compiler version (if compiling from source): None\nCUDA/cuDNN version: 9.0/7\nGPU model and memory: GeForce GTX 1080 Ti, 11G\n\nDescribe the current behavior\nimport numpy as np\nimport tensorflow as tf\n\n# tf.enable_eager_execution()\n\n\ndef test_bug():\n    input = tf.convert_to_tensor(np.ones((1, 1, 1, 1), dtype=np.float32))\n    x = tf.layers.conv2d(input, 1, (1, 1), activation=\"tanh\",\n                         kernel_initializer=tf.initializers.constant(2),\n                         use_bias=False)\n    max_out = tf.math.reduce_max(x, [1, 2])\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        m = sess.run(max_out)\n        m1, _ = sess.run([max_out, x])\n        print('m =', m)\n        print('m1 =', m1)\n        assert np.allclose(m, m1)\n\ntest_bug()\nI'd suppose that the assertion should pass given above code. However, tf.math.reduce_max looks very strange:\nm = [[2.]]\nm1 = [[0.9640276]]\n\nDescribe the expected behavior\nm and m1 should have the same value and the assertion should pass.\nm = [[0.9640276]]\nm1 = [[0.9640276]]\n\nCode to reproduce the issue\nListed above.\nOther info / logs\nIf eager execution is enabled, then the value of x and max_out is the same.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: 3.6.6\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: 9.0/7\r\n- GPU model and memory: GeForce GTX 1080 Ti, 11G\r\n\r\n**Describe the current behavior**\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# tf.enable_eager_execution()\r\n\r\n\r\ndef test_bug():\r\n    input = tf.convert_to_tensor(np.ones((1, 1, 1, 1), dtype=np.float32))\r\n    x = tf.layers.conv2d(input, 1, (1, 1), activation=\"tanh\",\r\n                         kernel_initializer=tf.initializers.constant(2),\r\n                         use_bias=False)\r\n    max_out = tf.math.reduce_max(x, [1, 2])\r\n\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        m = sess.run(max_out)\r\n        m1, _ = sess.run([max_out, x])\r\n        print('m =', m)\r\n        print('m1 =', m1)\r\n        assert np.allclose(m, m1)\r\n\r\ntest_bug()\r\n```\r\nI'd suppose that the assertion should pass given above code. However, `tf.math.reduce_max` looks very strange:\r\n```\r\nm = [[2.]]\r\nm1 = [[0.9640276]]\r\n```\r\n\r\n**Describe the expected behavior**\r\n`m` and `m1` should have the same value and the assertion should pass.\r\n```\r\nm = [[0.9640276]]\r\nm1 = [[0.9640276]]\r\n```\r\n\r\n**Code to reproduce the issue**\r\nListed above.\r\n\r\n**Other info / logs**\r\nIf eager execution is enabled, then the value of `x` and `max_out` is the same.\r\n"}