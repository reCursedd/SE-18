{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/436829978", "html_url": "https://github.com/tensorflow/tensorflow/pull/21222#issuecomment-436829978", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21222", "id": 436829978, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjgyOTk3OA==", "user": {"login": "MarkPKCollier", "id": 1159632, "node_id": "MDQ6VXNlcjExNTk2MzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1159632?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkPKCollier", "html_url": "https://github.com/MarkPKCollier", "followers_url": "https://api.github.com/users/MarkPKCollier/followers", "following_url": "https://api.github.com/users/MarkPKCollier/following{/other_user}", "gists_url": "https://api.github.com/users/MarkPKCollier/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkPKCollier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkPKCollier/subscriptions", "organizations_url": "https://api.github.com/users/MarkPKCollier/orgs", "repos_url": "https://api.github.com/users/MarkPKCollier/repos", "events_url": "https://api.github.com/users/MarkPKCollier/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkPKCollier/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-08T00:36:11Z", "updated_at": "2018-11-08T00:36:11Z", "author_association": "NONE", "body_html": "<p>I am specifying the initializer (see below).</p>\n<pre><code>def build(self, inputs_shape):\n    ...\n    self._M = self.add_variable(\n        'memory',\n        shape=[self.memory_size, self.memory_vector_dim],\n        initializer=init_ops.constant_initializer(1e-6, dtype=self.dtype),\n        trainable=True)\n    print('Memory Variable (add_variable)', self._M)\n    print('Memory initializer', self._M.initializer)\n    print('Memory initial value', self._M.initial_value)\n</code></pre>\n<p>Output:</p>\n<pre><code>Memory Variable (add_variable) &lt;tf.Variable 'root/rnn/ntm_cell/memory:0' shape=(128, 20) dtype=float32_ref&gt;\nMemory initializer name: \"root/rnn/ntm_cell/memory/Assign\"\nop: \"Assign\"\ninput: \"root/rnn/ntm_cell/memory\"\ninput: \"root/rnn/ntm_cell/memory/Initializer/Const\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"_class\"\n  value {\n    list {\n      s: \"loc:@root/rnn/ntm_cell/memory\"\n    }\n  }\n}\nattr {\n  key: \"use_locking\"\n  value {\n    b: true\n  }\n}\nattr {\n  key: \"validate_shape\"\n  value {\n    b: true\n  }\n}\n\nMemory initial value Tensor(\"root/rnn/ntm_cell/memory/Initializer/Const:0\", shape=(128, 20), dtype=float32)\n</code></pre>\n<pre><code>def build(self, inputs_shape):\n    ...\n    self._M = vs.get_variable('memory',\n      [self.memory_size, self.memory_vector_dim],\n      initializer=init_ops.constant_initializer(1e-6))\n    print('Memory Variable (get_variable)', self._M)\n    print('Memory initializer', self._M.initializer)\n    print('Memory initial value', self._M.initial_value)\n</code></pre>\n<p>Output:</p>\n<pre><code>Memory Variable (get_variable) &lt;tf.Variable 'root/rnn/ntm_cell/memory:0' shape=(128, 20) dtype=float32_ref&gt;\nMemory initializer name: \"root/rnn/ntm_cell/memory/Assign\"\nop: \"Assign\"\ninput: \"root/rnn/ntm_cell/memory\"\ninput: \"root/rnn/ntm_cell/memory/Initializer/Const\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"_class\"\n  value {\n    list {\n      s: \"loc:@root/rnn/ntm_cell/memory\"\n    }\n  }\n}\nattr {\n  key: \"use_locking\"\n  value {\n    b: true\n  }\n}\nattr {\n  key: \"validate_shape\"\n  value {\n    b: true\n  }\n}\n\nMemory initial value Tensor(\"root/rnn/ntm_cell/memory/Initializer/Const:0\", shape=(128, 20), dtype=float32)\n</code></pre>\n<p>As far as I can tell these should be exactly the same - but I consistently get different performance with the two approaches.</p>", "body_text": "I am specifying the initializer (see below).\ndef build(self, inputs_shape):\n    ...\n    self._M = self.add_variable(\n        'memory',\n        shape=[self.memory_size, self.memory_vector_dim],\n        initializer=init_ops.constant_initializer(1e-6, dtype=self.dtype),\n        trainable=True)\n    print('Memory Variable (add_variable)', self._M)\n    print('Memory initializer', self._M.initializer)\n    print('Memory initial value', self._M.initial_value)\n\nOutput:\nMemory Variable (add_variable) <tf.Variable 'root/rnn/ntm_cell/memory:0' shape=(128, 20) dtype=float32_ref>\nMemory initializer name: \"root/rnn/ntm_cell/memory/Assign\"\nop: \"Assign\"\ninput: \"root/rnn/ntm_cell/memory\"\ninput: \"root/rnn/ntm_cell/memory/Initializer/Const\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"_class\"\n  value {\n    list {\n      s: \"loc:@root/rnn/ntm_cell/memory\"\n    }\n  }\n}\nattr {\n  key: \"use_locking\"\n  value {\n    b: true\n  }\n}\nattr {\n  key: \"validate_shape\"\n  value {\n    b: true\n  }\n}\n\nMemory initial value Tensor(\"root/rnn/ntm_cell/memory/Initializer/Const:0\", shape=(128, 20), dtype=float32)\n\ndef build(self, inputs_shape):\n    ...\n    self._M = vs.get_variable('memory',\n      [self.memory_size, self.memory_vector_dim],\n      initializer=init_ops.constant_initializer(1e-6))\n    print('Memory Variable (get_variable)', self._M)\n    print('Memory initializer', self._M.initializer)\n    print('Memory initial value', self._M.initial_value)\n\nOutput:\nMemory Variable (get_variable) <tf.Variable 'root/rnn/ntm_cell/memory:0' shape=(128, 20) dtype=float32_ref>\nMemory initializer name: \"root/rnn/ntm_cell/memory/Assign\"\nop: \"Assign\"\ninput: \"root/rnn/ntm_cell/memory\"\ninput: \"root/rnn/ntm_cell/memory/Initializer/Const\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"_class\"\n  value {\n    list {\n      s: \"loc:@root/rnn/ntm_cell/memory\"\n    }\n  }\n}\nattr {\n  key: \"use_locking\"\n  value {\n    b: true\n  }\n}\nattr {\n  key: \"validate_shape\"\n  value {\n    b: true\n  }\n}\n\nMemory initial value Tensor(\"root/rnn/ntm_cell/memory/Initializer/Const:0\", shape=(128, 20), dtype=float32)\n\nAs far as I can tell these should be exactly the same - but I consistently get different performance with the two approaches.", "body": "I am specifying the initializer (see below).\r\n\r\n```\r\ndef build(self, inputs_shape):\r\n    ...\r\n    self._M = self.add_variable(\r\n        'memory',\r\n        shape=[self.memory_size, self.memory_vector_dim],\r\n        initializer=init_ops.constant_initializer(1e-6, dtype=self.dtype),\r\n        trainable=True)\r\n    print('Memory Variable (add_variable)', self._M)\r\n    print('Memory initializer', self._M.initializer)\r\n    print('Memory initial value', self._M.initial_value)\r\n```\r\nOutput:\r\n```\r\nMemory Variable (add_variable) <tf.Variable 'root/rnn/ntm_cell/memory:0' shape=(128, 20) dtype=float32_ref>\r\nMemory initializer name: \"root/rnn/ntm_cell/memory/Assign\"\r\nop: \"Assign\"\r\ninput: \"root/rnn/ntm_cell/memory\"\r\ninput: \"root/rnn/ntm_cell/memory/Initializer/Const\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"_class\"\r\n  value {\r\n    list {\r\n      s: \"loc:@root/rnn/ntm_cell/memory\"\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"use_locking\"\r\n  value {\r\n    b: true\r\n  }\r\n}\r\nattr {\r\n  key: \"validate_shape\"\r\n  value {\r\n    b: true\r\n  }\r\n}\r\n\r\nMemory initial value Tensor(\"root/rnn/ntm_cell/memory/Initializer/Const:0\", shape=(128, 20), dtype=float32)\r\n```\r\n\r\n```\r\ndef build(self, inputs_shape):\r\n    ...\r\n    self._M = vs.get_variable('memory',\r\n      [self.memory_size, self.memory_vector_dim],\r\n      initializer=init_ops.constant_initializer(1e-6))\r\n    print('Memory Variable (get_variable)', self._M)\r\n    print('Memory initializer', self._M.initializer)\r\n    print('Memory initial value', self._M.initial_value)\r\n```\r\nOutput:\r\n```\r\nMemory Variable (get_variable) <tf.Variable 'root/rnn/ntm_cell/memory:0' shape=(128, 20) dtype=float32_ref>\r\nMemory initializer name: \"root/rnn/ntm_cell/memory/Assign\"\r\nop: \"Assign\"\r\ninput: \"root/rnn/ntm_cell/memory\"\r\ninput: \"root/rnn/ntm_cell/memory/Initializer/Const\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"_class\"\r\n  value {\r\n    list {\r\n      s: \"loc:@root/rnn/ntm_cell/memory\"\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"use_locking\"\r\n  value {\r\n    b: true\r\n  }\r\n}\r\nattr {\r\n  key: \"validate_shape\"\r\n  value {\r\n    b: true\r\n  }\r\n}\r\n\r\nMemory initial value Tensor(\"root/rnn/ntm_cell/memory/Initializer/Const:0\", shape=(128, 20), dtype=float32)\r\n```\r\n\r\nAs far as I can tell these should be exactly the same - but I consistently get different performance with the two approaches. "}