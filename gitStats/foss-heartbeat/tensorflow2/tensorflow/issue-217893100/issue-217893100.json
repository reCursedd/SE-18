{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8804", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8804/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8804/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8804/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8804", "id": 217893100, "node_id": "MDU6SXNzdWUyMTc4OTMxMDA=", "number": 8804, "title": "why use unknown batch_size in BasicDecoder class?", "user": {"login": "zzw922cn", "id": 11649939, "node_id": "MDQ6VXNlcjExNjQ5OTM5", "avatar_url": "https://avatars3.githubusercontent.com/u/11649939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zzw922cn", "html_url": "https://github.com/zzw922cn", "followers_url": "https://api.github.com/users/zzw922cn/followers", "following_url": "https://api.github.com/users/zzw922cn/following{/other_user}", "gists_url": "https://api.github.com/users/zzw922cn/gists{/gist_id}", "starred_url": "https://api.github.com/users/zzw922cn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zzw922cn/subscriptions", "organizations_url": "https://api.github.com/users/zzw922cn/orgs", "repos_url": "https://api.github.com/users/zzw922cn/repos", "events_url": "https://api.github.com/users/zzw922cn/events{/privacy}", "received_events_url": "https://api.github.com/users/zzw922cn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-03-29T14:23:56Z", "updated_at": "2018-11-22T18:51:43Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I found that in the source code:<a href=\"basic_decoder.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py</a></p>\n<div class=\"highlight highlight-source-python\"><pre>  <span class=\"pl-en\">@</span><span class=\"pl-c1\">property</span>\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">batch_size</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>._helper.batch_size\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">_rnn_output_size</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n    size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._cell.output_size\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>._output_layer <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n      <span class=\"pl-k\">return</span> size\n    <span class=\"pl-k\">else</span>:\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> To use layer's compute_output_shape, we need to convert the</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> RNNCell's output_size entries into shapes with an unknown</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> batch size.  We then pass this through the layer's</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> compute_output_shape and read off all but the first (batch)</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> dimensions to get the output size of the rnn with the layer</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> applied to the top.</span>\n      output_shape_with_unknown_batch <span class=\"pl-k\">=</span> nest.map_structure(\n          <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">s</span>: tensor_shape.TensorShape([<span class=\"pl-c1\">None</span>]).concatenate(s),\n          size)\n      layer_output_shape <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._output_layer._compute_output_shape(  <span class=\"pl-c\"><span class=\"pl-c\">#</span> pylint: disable=protected-access</span>\n          output_shape_with_unknown_batch)\n<span class=\"pl-k\">return</span> nest.map_structure(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">s</span>: s[<span class=\"pl-c1\">1</span>:], layer_output_shape)</pre></div>\n<p>As above, since we can get the batch size by calling self._helper.batch_size, why it is set to be None in<br>\n<code>lambda s: tensor_shape.TensorShape([None]).concatenate(s)</code>?  Why the batch size is still unknown? Couldn't we set to be <code>lambda s: tensor_shape.TensorShape([self._helper.batch_size]).concatenate(s)</code>?</p>", "body_text": "I found that in the source code:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py\n  @property\n  def batch_size(self):\n    return self._helper.batch_size\n\n  def _rnn_output_size(self):\n    size = self._cell.output_size\n    if self._output_layer is None:\n      return size\n    else:\n      # To use layer's compute_output_shape, we need to convert the\n      # RNNCell's output_size entries into shapes with an unknown\n      # batch size.  We then pass this through the layer's\n      # compute_output_shape and read off all but the first (batch)\n      # dimensions to get the output size of the rnn with the layer\n      # applied to the top.\n      output_shape_with_unknown_batch = nest.map_structure(\n          lambda s: tensor_shape.TensorShape([None]).concatenate(s),\n          size)\n      layer_output_shape = self._output_layer._compute_output_shape(  # pylint: disable=protected-access\n          output_shape_with_unknown_batch)\nreturn nest.map_structure(lambda s: s[1:], layer_output_shape)\nAs above, since we can get the batch size by calling self._helper.batch_size, why it is set to be None in\nlambda s: tensor_shape.TensorShape([None]).concatenate(s)?  Why the batch size is still unknown? Couldn't we set to be lambda s: tensor_shape.TensorShape([self._helper.batch_size]).concatenate(s)?", "body": "I found that in the source code:[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py](basic_decoder.py)\r\n```python\r\n  @property\r\n  def batch_size(self):\r\n    return self._helper.batch_size\r\n\r\n  def _rnn_output_size(self):\r\n    size = self._cell.output_size\r\n    if self._output_layer is None:\r\n      return size\r\n    else:\r\n      # To use layer's compute_output_shape, we need to convert the\r\n      # RNNCell's output_size entries into shapes with an unknown\r\n      # batch size.  We then pass this through the layer's\r\n      # compute_output_shape and read off all but the first (batch)\r\n      # dimensions to get the output size of the rnn with the layer\r\n      # applied to the top.\r\n      output_shape_with_unknown_batch = nest.map_structure(\r\n          lambda s: tensor_shape.TensorShape([None]).concatenate(s),\r\n          size)\r\n      layer_output_shape = self._output_layer._compute_output_shape(  # pylint: disable=protected-access\r\n          output_shape_with_unknown_batch)\r\nreturn nest.map_structure(lambda s: s[1:], layer_output_shape)\r\n```\r\n\r\nAs above, since we can get the batch size by calling self._helper.batch_size, why it is set to be None in\r\n`lambda s: tensor_shape.TensorShape([None]).concatenate(s)`?  Why the batch size is still unknown? Couldn't we set to be `lambda s: tensor_shape.TensorShape([self._helper.batch_size]).concatenate(s)`?"}