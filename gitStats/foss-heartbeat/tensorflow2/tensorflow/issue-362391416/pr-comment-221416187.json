{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/221416187", "pull_request_review_id": 160066844, "id": 221416187, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMTQxNjE4Nw==", "diff_hunk": "@@ -0,0 +1,305 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#include <queue>\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/partial_tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/kernels/data/dataset.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/core/threadpool.h\"\n+#include \"tensorflow/core/lib/io/buffered_inputstream.h\"\n+#include \"tensorflow/core/lib/io/inputbuffer.h\"\n+#include \"tensorflow/core/lib/io/path.h\"\n+#include \"tensorflow/core/lib/io/random_inputstream.h\"\n+#include \"tensorflow/core/lib/io/record_reader.h\"\n+#include \"tensorflow/core/lib/io/zlib_compression_options.h\"\n+#include \"tensorflow/core/lib/io/zlib_inputstream.h\"\n+#include \"tensorflow/core/platform/env.h\"\n+\n+namespace tensorflow {\n+namespace data {\n+namespace {\n+\n+// See documentation in ../../ops/dataset_ops.cc for a high-level\n+// description of the following op.\n+\n+class MatchingFilesDatasetOp : public DatasetOpKernel {\n+ public:\n+  using DatasetOpKernel::DatasetOpKernel;\n+\n+  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n+    const Tensor* patterns_t;\n+    OP_REQUIRES_OK(ctx, ctx->input(\"patterns\", &patterns_t));\n+    const auto patterns = patterns_t->flat<string>();\n+    size_t num_patterns = static_cast<size_t>(patterns.size());\n+    std::vector<string> pattern_strs;\n+    pattern_strs.reserve(num_patterns);\n+\n+    for (int i = 0; i < num_patterns; i++) {\n+      pattern_strs.push_back(patterns(i));\n+    }\n+\n+    // keep the elements in the ascending order\n+    std::sort(pattern_strs.begin(), pattern_strs.end());\n+    *output = new Dataset(ctx, std::move(pattern_strs));\n+  }\n+\n+ private:\n+  class Dataset : public DatasetBase {\n+   public:\n+    Dataset(OpKernelContext* ctx, std::vector<string> patterns)\n+        : DatasetBase(DatasetContext(ctx)), patterns_(std::move(patterns)) {}\n+\n+    std::unique_ptr<IteratorBase> MakeIteratorInternal(\n+        const string& prefix) const override {\n+      return std::unique_ptr<IteratorBase>(\n+          new Iterator({this, strings::StrCat(prefix, \"::MatchingFiles\")}));\n+    }\n+\n+    const DataTypeVector& output_dtypes() const override {\n+      static DataTypeVector* dtypes = new DataTypeVector({DT_STRING});\n+      return *dtypes;\n+    }\n+\n+    const std::vector<PartialTensorShape>& output_shapes() const override {\n+      static std::vector<PartialTensorShape>* shapes =\n+          new std::vector<PartialTensorShape>({{}});\n+      return *shapes;\n+    }\n+\n+    string DebugString() const override {\n+      return \"MatchingFilesDatasetOp::Dataset\";\n+    }\n+\n+   protected:\n+    Status AsGraphDefInternal(SerializationContext* ctx,\n+                              DatasetGraphDefBuilder* b,\n+                              Node** output) const override {\n+      Node* patterns_node = nullptr;\n+      TF_RETURN_IF_ERROR(b->AddVector(patterns_, &patterns_node));\n+      TF_RETURN_IF_ERROR(b->AddDataset(this, {patterns_node}, output));\n+      return Status::OK();\n+    }\n+\n+   private:\n+    class Iterator : public DatasetIterator<Dataset> {\n+     public:\n+      explicit Iterator(const Params& params)\n+          : DatasetIterator<Dataset>(params) {}\n+\n+      Status GetNextInternal(IteratorContext* ctx,\n+                             std::vector<Tensor>* out_tensors,\n+                             bool* end_of_sequence) override {\n+        mutex_lock l(mu_);\n+        Status ret;\n+\n+        while (!filepath_queue_.empty() ||\n+               current_pattern_index_ < dataset()->patterns_.size()) {\n+          // All the elements in the heap will be the matched filename or the\n+          // potential directory.\n+          if (!filepath_queue_.empty()) {\n+            string cur_file = filepath_queue_.top();\n+            filepath_queue_.pop();\n+\n+            // We can also use isDectory() here. But IsDirectory call can be\n+            // expensive for some FS.\n+            if (ctx->env()->MatchPath(cur_file, current_pattern_)) {\n+              Tensor filepath_tensor(ctx->allocator({}), DT_STRING, {});\n+              filepath_tensor.scalar<string>()() = cur_file;\n+              out_tensors->emplace_back(std::move(filepath_tensor));\n+              *end_of_sequence = false;\n+              return Status::OK();\n+            }\n+\n+            // In this case, cur_file is a directory. Then create a sub-pattern\n+            // to continue the search.\n+            size_t pos = current_pattern_.find_first_of(\"*?[\\\\\");\n+            size_t len = current_pattern_.size() - pos;\n+            string cur_pattern_suffix = current_pattern_.substr(pos, len);\n+            string sub_pattern =\n+                strings::StrCat(cur_file, \"/\", cur_pattern_suffix);\n+            Status s = UpdateIterator(ctx, sub_pattern);\n+            ret.Update(s);\n+          } else {\n+            // search a new pattern\n+            current_pattern_ = dataset()->patterns_[current_pattern_index_];\n+            Status s = UpdateIterator(ctx, current_pattern_);\n+            ret.Update(s);\n+            ++current_pattern_index_;\n+          }\n+        }\n+\n+        *end_of_sequence = true;\n+        return Status::OK();\n+      }\n+\n+     protected:\n+      Status SaveInternal(IteratorStateWriter* writer) override {\n+        mutex_lock l(mu_);\n+        TF_RETURN_IF_ERROR(writer->WriteScalar(\n+            full_name(\"current_pattern_index\"), current_pattern_index_));\n+\n+        TF_RETURN_IF_ERROR(writer->WriteScalar(full_name(\"current_pattern\"),\n+                                               current_pattern_));\n+\n+        if (!filepath_queue_.empty()) {\n+          TF_RETURN_IF_ERROR(writer->WriteScalar(full_name(\"queue_size\"),\n+                                                 filepath_queue_.size()));\n+          for (int i = 0; i < filepath_queue_.size(); ++i) {\n+            TF_RETURN_IF_ERROR(writer->WriteScalar(\n+                full_name(strings::StrCat(\"queue_element_\", i)),\n+                filepath_queue_.top()));\n+            filepath_queue_.pop();\n+          }\n+        }\n+      }\n+\n+      Status RestoreInternal(IteratorContext* ctx,\n+                             IteratorStateReader* reader) override {\n+        mutex_lock l(mu_);\n+        int64 current_pattern_index;\n+        TF_RETURN_IF_ERROR(reader->ReadScalar(\n+            full_name(\"current_pattern_index\"), &current_pattern_index));\n+        current_pattern_index_ = size_t(current_pattern_index);\n+\n+        TF_RETURN_IF_ERROR(reader->ReadScalar(full_name(\"current_pattern\"),\n+                                              &current_pattern_));\n+\n+        int64 queue_size;\n+        TF_RETURN_IF_ERROR(\n+            reader->ReadScalar(full_name(\"queue_size\"), &queue_size));\n+        for (int i = 0; i < queue_size; i++) {\n+          string element;\n+          TF_RETURN_IF_ERROR(reader->ReadScalar(\n+              full_name(strings::StrCat(\"queue_element_\", i)), &element));\n+          filepath_queue_.push(element);\n+        }\n+        return Status::OK();\n+      }\n+\n+     private:\n+      Status UpdateIterator(IteratorContext* ctx, const string& pattern)\n+          EXCLUSIVE_LOCKS_REQUIRED(mu_) {\n+        string fixed_prefix = pattern.substr(0, pattern.find_first_of(\"*?[\\\\\"));\n+        string eval_pattern = pattern;\n+        string dir(io::Dirname(fixed_prefix));\n+\n+        // If dir is empty then we need to fix up fixed_prefix and eval_pattern\n+        // to include . as the top level directory.\n+        if (dir.empty()) {\n+          dir = \".\";\n+          fixed_prefix = io::JoinPath(dir, fixed_prefix);\n+          eval_pattern = io::JoinPath(dir, pattern);\n+        }\n+\n+        FileSystem* fs;\n+        TF_RETURN_IF_ERROR(ctx->env()->GetFileSystemForFile(dir, &fs));\n+\n+        filepath_queue_.push(dir);\n+        Status ret;  // Status to return\n+        // children_dir_status holds is_dir status for children. It can have\n+        // three possible values: OK for true; FAILED_PRECONDITION for false;\n+        // CANCELLED if we don't calculate IsDirectory (we might do that because\n+        // there isn't any point in exploring that child path).\n+\n+        // DFS to find the first element in the iterator.\n+        while (!filepath_queue_.empty()) {\n+          string cur_dir = filepath_queue_.top();\n+          filepath_queue_.pop();\n+          std::vector<string> children;\n+          Status s = fs->GetChildren(cur_dir, &children);\n+          ret.Update(s);\n+\n+          // If cur_dir has no children, there will two possible situations: 1)\n+          // the cur_dir is an empty dir; 2) the cur_dir is actual a file\n+          // instead of a director. For the first one, continue to search the\n+          // heap. For the second one, if the file matches the pattern, add\n+          // it to the heap and finish the search; otherwise, continue the next\n+          // search.\n+          if (children.empty()) {\n+            if (ctx->env()->MatchPath(cur_dir, eval_pattern)) {\n+              filepath_queue_.push(cur_dir);\n+              return ret;\n+            } else {\n+              continue;\n+            }\n+          }\n+\n+          std::map<string, Status> children_dir_status;\n+          // This IsDirectory call can be expensive for some FS. Parallelizing\n+          // it.\n+          ForEach(\n+              ctx, 0, children.size(),\n+              [fs, &cur_dir, &children, &fixed_prefix,\n+               &children_dir_status](int i) {\n+                const string child_path = io::JoinPath(cur_dir, children[i]);\n+                // In case the child_path doesn't start with the fixed_prefix,\n+                // then we don't need to explore this path.\n+                if (!str_util::StartsWith(child_path, fixed_prefix)) {\n+                  children_dir_status[child_path] = Status(\n+                      tensorflow::error::CANCELLED, \"Operation not needed\");\n+                } else {\n+                  children_dir_status[child_path] = fs->IsDirectory(child_path);\n+                }\n+              });\n+\n+          for (const auto& child : children) {\n+            const string child_dir_path = io::JoinPath(cur_dir, child);\n+            const Status child_dir_status = children_dir_status[child];\n+            // If the IsDirectory call was cancelled we bail.\n+            if (child_dir_status.code() == tensorflow::error::CANCELLED) {\n+              continue;\n+            }\n+\n+            if (child_dir_status.ok()) {\n+              // push the child dir for next search\n+              filepath_queue_.push(child_dir_path);\n+            } else {\n+              // This case will be a file: if the file matches the pattern, push\n+              // it to the heap; otherwise, ignore it.\n+              if (ctx->env()->MatchPath(child_dir_path, eval_pattern)) {\n+                filepath_queue_.push(child_dir_path);\n+              }\n+            }\n+          }\n+        }\n+        return ret;\n+      }\n+\n+      static void ForEach(IteratorContext* ctx, int first, int last,\n+                          const std::function<void(int)>& f) {\n+        for (int i = first; i < last; i++) {\n+          (*ctx->runner())([f, i] { std::bind(f, i); });", "path": "tensorflow/core/kernels/data/matching_files_dataset_op.cc", "position": null, "original_position": 285, "commit_id": "0d5b9d20cc3e3062aa4d443bc772bb3aed698d15", "original_commit_id": "3c3f6205ab7ae733487e30916b1e2c493e16fb6c", "user": {"login": "feihugis", "id": 5057740, "node_id": "MDQ6VXNlcjUwNTc3NDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/5057740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/feihugis", "html_url": "https://github.com/feihugis", "followers_url": "https://api.github.com/users/feihugis/followers", "following_url": "https://api.github.com/users/feihugis/following{/other_user}", "gists_url": "https://api.github.com/users/feihugis/gists{/gist_id}", "starred_url": "https://api.github.com/users/feihugis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/feihugis/subscriptions", "organizations_url": "https://api.github.com/users/feihugis/orgs", "repos_url": "https://api.github.com/users/feihugis/repos", "events_url": "https://api.github.com/users/feihugis/events{/privacy}", "received_events_url": "https://api.github.com/users/feihugis/received_events", "type": "User", "site_admin": false}, "body": "Thanks for your suggestion! It helps me get a better understanding of `ctx-runner()`. \r\n\r\nAfter updating the code, I got the following error when running the test:\r\n```\r\n*** Received signal 11 ***\r\n*** BEGIN MANGLED STACK TRACE ***\r\n0   libtensorflow_framework.so          0x0000000109fd7d85 _ZN10tensorflow7testingL17StacktraceHandlerEiP9__siginfoPv + 181\r\n1   libsystem_platform.dylib            0x00007fff6c20ff5a _sigtramp + 26\r\n2   libtensorflow_framework.so          0x0000000109d41020 libtensorflow_framework.so + 32\r\n3   _pywrap_tensorflow_internal.so      0x00000001122d5993 _ZNSt3__110__function6__funcIZN10tensorflow4data12_GLOBAL__N_122MatchingFilesDatasetOp7Dataset8Iterator14UpdateIteratorEPNS3_15IteratorContextERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlvE_NSD_ISI_EEFvvEEclEv + 403\r\n4   libtensorflow_framework.so          0x0000000109fb5fde _ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi + 1342\r\n5   libtensorflow_framework.so          0x0000000109fb598f _ZNSt3__110__function6__funcIZN10tensorflow6thread16EigenEnvironment12CreateThreadENS_8functionIFvvEEEEUlvE_NS_9allocatorIS8_EES6_EclEv + 47\r\n6   libtensorflow_framework.so          0x0000000109fd95b0 _ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEENS_8functionIFvvEEEEEEEEPvSB_ + 48\r\n7   libsystem_pthread.dylib             0x00007fff6c219661 _pthread_body + 340\r\n8   libsystem_pthread.dylib             0x00007fff6c21950d _pthread_body + 0\r\n9   libsystem_pthread.dylib             0x00007fff6c218bf9 thread_start + 13\r\n*** END MANGLED STACK TRACE ***\r\n\r\n*** Begin stack trace ***\r\n        tensorflow::CurrentStackTrace()\r\n        tensorflow::testing::StacktraceHandler(int, __siginfo*, void*)\r\n        _sigtramp\r\n\r\n        std::__1::__function::__func<tensorflow::data::(anonymous namespace)::MatchingFilesDatasetOp::Dataset::Iterator::UpdateIterator(tensorflow::data::IteratorContext*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(), std::__1::allocator<tensorflow::data::(anonymous namespace)::MatchingFilesDatasetOp::Dataset::Iterator::UpdateIterator(tensorflow::data::IteratorContext*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'()>, void ()>::operator()()\r\n        Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int)\r\n        std::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()()\r\n        void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*)\r\n        _pthread_body\r\n        _pthread_body\r\n        thread_start\r\n*** End stack trace ***\r\nAbort trap: 6\r\n```\r\n\r\nIt seems to be caused by `children_dir_status`, which is defined by `std::map<string, Status> children_dir_status;` and not thread-safe.\r\n\r\nIn order to solve this problem, I change the defination of `children_dir_status` to be as below. \r\n```C++\r\nstd::vector<Status> children_dir_status;\r\nchildren_dir_status.resize(children.size());\r\n```\r\nThen the test cases pass without error. I paste the code here for your checking. I'm wondering if my understanding of the error is right?\r\n\r\n```C++\r\n          std::vector<Status> children_dir_status;\r\n          children_dir_status.resize(children.size());\r\n\r\n          // This IsDirectory call can be expensive for some FS. Parallelizing\r\n          // it.\r\n          auto is_directory_fn = [fs, &cur_dir, &children, &fixed_prefix,\r\n              &children_dir_status](int i) {\r\n            const string child_path = io::JoinPath(cur_dir, children[i]);\r\n            // In case the child_path doesn't start with the fixed_prefix, then\r\n            // we don't need to explore this path.\r\n            if (!str_util::StartsWith(child_path, fixed_prefix)) {\r\n              children_dir_status[i] = Status(\r\n                  tensorflow::error::CANCELLED, \"Operation not needed\");\r\n            } else {\r\n              children_dir_status[i] = fs->IsDirectory(child_path);\r\n            }\r\n          };\r\n\r\n          BlockingCounter counter(children.size());\r\n          for (int i = 0; i < children.size(); i++) {\r\n            (*ctx->runner())([&is_directory_fn, &counter, i] {\r\n              is_directory_fn(i);\r\n              counter.DecrementCount();\r\n            });\r\n          }\r\n          counter.Wait();\r\n\r\n          for (int i = 0; i < children.size(); i++) {\r\n            const string child_dir_path = io::JoinPath(cur_dir, children[i]);\r\n            const Status child_dir_status = children_dir_status[i];\r\n            // If the IsDirectory call was cancelled we bail.\r\n            if (child_dir_status.code() == tensorflow::error::CANCELLED) {\r\n              continue;\r\n            }\r\n\r\n            if (child_dir_status.ok()) {\r\n              // push the child dir for next search\r\n              filepath_queue_.push(child_dir_path);\r\n            } else {\r\n              // This case will be a file: if the file matches the pattern, push\r\n              // it to the heap; otherwise, ignore it.\r\n              if (ctx->env()->MatchPath(child_dir_path, eval_pattern)) {\r\n                filepath_queue_.push(child_dir_path);\r\n              }\r\n            }\r\n          }\r\n```\r\n\r\n\r\n", "created_at": "2018-09-29T04:55:56Z", "updated_at": "2018-10-15T21:38:29Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22429#discussion_r221416187", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22429", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/221416187"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22429#discussion_r221416187"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22429"}}, "body_html": "<p>Thanks for your suggestion! It helps me get a better understanding of <code>ctx-runner()</code>.</p>\n<p>After updating the code, I got the following error when running the test:</p>\n<pre><code>*** Received signal 11 ***\n*** BEGIN MANGLED STACK TRACE ***\n0   libtensorflow_framework.so          0x0000000109fd7d85 _ZN10tensorflow7testingL17StacktraceHandlerEiP9__siginfoPv + 181\n1   libsystem_platform.dylib            0x00007fff6c20ff5a _sigtramp + 26\n2   libtensorflow_framework.so          0x0000000109d41020 libtensorflow_framework.so + 32\n3   _pywrap_tensorflow_internal.so      0x00000001122d5993 _ZNSt3__110__function6__funcIZN10tensorflow4data12_GLOBAL__N_122MatchingFilesDatasetOp7Dataset8Iterator14UpdateIteratorEPNS3_15IteratorContextERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlvE_NSD_ISI_EEFvvEEclEv + 403\n4   libtensorflow_framework.so          0x0000000109fb5fde _ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi + 1342\n5   libtensorflow_framework.so          0x0000000109fb598f _ZNSt3__110__function6__funcIZN10tensorflow6thread16EigenEnvironment12CreateThreadENS_8functionIFvvEEEEUlvE_NS_9allocatorIS8_EES6_EclEv + 47\n6   libtensorflow_framework.so          0x0000000109fd95b0 _ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEENS_8functionIFvvEEEEEEEEPvSB_ + 48\n7   libsystem_pthread.dylib             0x00007fff6c219661 _pthread_body + 340\n8   libsystem_pthread.dylib             0x00007fff6c21950d _pthread_body + 0\n9   libsystem_pthread.dylib             0x00007fff6c218bf9 thread_start + 13\n*** END MANGLED STACK TRACE ***\n\n*** Begin stack trace ***\n        tensorflow::CurrentStackTrace()\n        tensorflow::testing::StacktraceHandler(int, __siginfo*, void*)\n        _sigtramp\n\n        std::__1::__function::__func&lt;tensorflow::data::(anonymous namespace)::MatchingFilesDatasetOp::Dataset::Iterator::UpdateIterator(tensorflow::data::IteratorContext*, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)::'lambda'(), std::__1::allocator&lt;tensorflow::data::(anonymous namespace)::MatchingFilesDatasetOp::Dataset::Iterator::UpdateIterator(tensorflow::data::IteratorContext*, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)::'lambda'()&gt;, void ()&gt;::operator()()\n        Eigen::NonBlockingThreadPoolTempl&lt;tensorflow::thread::EigenEnvironment&gt;::WorkerLoop(int)\n        std::__1::__function::__func&lt;tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function&lt;void ()&gt;)::'lambda'(), std::__1::allocator&lt;tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function&lt;void ()&gt;)::'lambda'()&gt;, void ()&gt;::operator()()\n        void* std::__1::__thread_proxy&lt;std::__1::tuple&lt;std::__1::unique_ptr&lt;std::__1::__thread_struct, std::__1::default_delete&lt;std::__1::__thread_struct&gt; &gt;, std::__1::function&lt;void ()&gt; &gt; &gt;(void*)\n        _pthread_body\n        _pthread_body\n        thread_start\n*** End stack trace ***\nAbort trap: 6\n</code></pre>\n<p>It seems to be caused by <code>children_dir_status</code>, which is defined by <code>std::map&lt;string, Status&gt; children_dir_status;</code> and not thread-safe.</p>\n<p>In order to solve this problem, I change the defination of <code>children_dir_status</code> to be as below.</p>\n<div class=\"highlight highlight-source-c++\"><pre>std::vector&lt;Status&gt; children_dir_status;\nchildren_dir_status.resize(children.size());</pre></div>\n<p>Then the test cases pass without error. I paste the code here for your checking. I'm wondering if my understanding of the error is right?</p>\n<div class=\"highlight highlight-source-c++\"><pre>          std::vector&lt;Status&gt; children_dir_status;\n          children_dir_status.resize(children.size());\n\n          <span class=\"pl-c\"><span class=\"pl-c\">//</span> This IsDirectory call can be expensive for some FS. Parallelizing</span>\n          <span class=\"pl-c\"><span class=\"pl-c\">//</span> it.</span>\n          <span class=\"pl-k\">auto</span> is_directory_fn = [fs, &amp;cur_dir, &amp;children, &amp;fixed_prefix,\n              &amp;children_dir_status](<span class=\"pl-k\">int</span> i) {\n            <span class=\"pl-k\">const</span> string child_path = <span class=\"pl-c1\">io::JoinPath</span>(cur_dir, children[i]);\n            <span class=\"pl-c\"><span class=\"pl-c\">//</span> In case the child_path doesn't start with the fixed_prefix, then</span>\n            <span class=\"pl-c\"><span class=\"pl-c\">//</span> we don't need to explore this path.</span>\n            <span class=\"pl-k\">if</span> (!<span class=\"pl-c1\">str_util::StartsWith</span>(child_path, fixed_prefix)) {\n              children_dir_status[i] = <span class=\"pl-c1\">Status</span>(\n                  tensorflow::error::CANCELLED, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Operation not needed<span class=\"pl-pds\">\"</span></span>);\n            } <span class=\"pl-k\">else</span> {\n              children_dir_status[i] = fs-&gt;<span class=\"pl-c1\">IsDirectory</span>(child_path);\n            }\n          };\n\n          BlockingCounter <span class=\"pl-en\">counter</span>(children.size());\n          <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; children.size(); i++) {\n            (*ctx-&gt;<span class=\"pl-c1\">runner</span>())([&amp;is_directory_fn, &amp;counter, i] {\n              <span class=\"pl-c1\">is_directory_fn</span>(i);\n              counter.<span class=\"pl-c1\">DecrementCount</span>();\n            });\n          }\n          counter.Wait();\n\n          <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; children.size(); i++) {\n            <span class=\"pl-k\">const</span> string child_dir_path = <span class=\"pl-c1\">io::JoinPath</span>(cur_dir, children[i]);\n            <span class=\"pl-k\">const</span> Status child_dir_status = children_dir_status[i];\n            <span class=\"pl-c\"><span class=\"pl-c\">//</span> If the IsDirectory call was cancelled we bail.</span>\n            <span class=\"pl-k\">if</span> (child_dir_status.<span class=\"pl-c1\">code</span>() == tensorflow::error::CANCELLED) {\n              <span class=\"pl-k\">continue</span>;\n            }\n\n            <span class=\"pl-k\">if</span> (child_dir_status.<span class=\"pl-c1\">ok</span>()) {\n              <span class=\"pl-c\"><span class=\"pl-c\">//</span> push the child dir for next search</span>\n              filepath_queue_.<span class=\"pl-c1\">push</span>(child_dir_path);\n            } <span class=\"pl-k\">else</span> {\n              <span class=\"pl-c\"><span class=\"pl-c\">//</span> This case will be a file: if the file matches the pattern, push</span>\n              <span class=\"pl-c\"><span class=\"pl-c\">//</span> it to the heap; otherwise, ignore it.</span>\n              <span class=\"pl-k\">if</span> (ctx-&gt;<span class=\"pl-c1\">env</span>()-&gt;<span class=\"pl-c1\">MatchPath</span>(child_dir_path, eval_pattern)) {\n                filepath_queue_.<span class=\"pl-c1\">push</span>(child_dir_path);\n              }\n            }\n          }</pre></div>", "body_text": "Thanks for your suggestion! It helps me get a better understanding of ctx-runner().\nAfter updating the code, I got the following error when running the test:\n*** Received signal 11 ***\n*** BEGIN MANGLED STACK TRACE ***\n0   libtensorflow_framework.so          0x0000000109fd7d85 _ZN10tensorflow7testingL17StacktraceHandlerEiP9__siginfoPv + 181\n1   libsystem_platform.dylib            0x00007fff6c20ff5a _sigtramp + 26\n2   libtensorflow_framework.so          0x0000000109d41020 libtensorflow_framework.so + 32\n3   _pywrap_tensorflow_internal.so      0x00000001122d5993 _ZNSt3__110__function6__funcIZN10tensorflow4data12_GLOBAL__N_122MatchingFilesDatasetOp7Dataset8Iterator14UpdateIteratorEPNS3_15IteratorContextERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlvE_NSD_ISI_EEFvvEEclEv + 403\n4   libtensorflow_framework.so          0x0000000109fb5fde _ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi + 1342\n5   libtensorflow_framework.so          0x0000000109fb598f _ZNSt3__110__function6__funcIZN10tensorflow6thread16EigenEnvironment12CreateThreadENS_8functionIFvvEEEEUlvE_NS_9allocatorIS8_EES6_EclEv + 47\n6   libtensorflow_framework.so          0x0000000109fd95b0 _ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEENS_8functionIFvvEEEEEEEEPvSB_ + 48\n7   libsystem_pthread.dylib             0x00007fff6c219661 _pthread_body + 340\n8   libsystem_pthread.dylib             0x00007fff6c21950d _pthread_body + 0\n9   libsystem_pthread.dylib             0x00007fff6c218bf9 thread_start + 13\n*** END MANGLED STACK TRACE ***\n\n*** Begin stack trace ***\n        tensorflow::CurrentStackTrace()\n        tensorflow::testing::StacktraceHandler(int, __siginfo*, void*)\n        _sigtramp\n\n        std::__1::__function::__func<tensorflow::data::(anonymous namespace)::MatchingFilesDatasetOp::Dataset::Iterator::UpdateIterator(tensorflow::data::IteratorContext*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(), std::__1::allocator<tensorflow::data::(anonymous namespace)::MatchingFilesDatasetOp::Dataset::Iterator::UpdateIterator(tensorflow::data::IteratorContext*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'()>, void ()>::operator()()\n        Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int)\n        std::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()()\n        void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*)\n        _pthread_body\n        _pthread_body\n        thread_start\n*** End stack trace ***\nAbort trap: 6\n\nIt seems to be caused by children_dir_status, which is defined by std::map<string, Status> children_dir_status; and not thread-safe.\nIn order to solve this problem, I change the defination of children_dir_status to be as below.\nstd::vector<Status> children_dir_status;\nchildren_dir_status.resize(children.size());\nThen the test cases pass without error. I paste the code here for your checking. I'm wondering if my understanding of the error is right?\n          std::vector<Status> children_dir_status;\n          children_dir_status.resize(children.size());\n\n          // This IsDirectory call can be expensive for some FS. Parallelizing\n          // it.\n          auto is_directory_fn = [fs, &cur_dir, &children, &fixed_prefix,\n              &children_dir_status](int i) {\n            const string child_path = io::JoinPath(cur_dir, children[i]);\n            // In case the child_path doesn't start with the fixed_prefix, then\n            // we don't need to explore this path.\n            if (!str_util::StartsWith(child_path, fixed_prefix)) {\n              children_dir_status[i] = Status(\n                  tensorflow::error::CANCELLED, \"Operation not needed\");\n            } else {\n              children_dir_status[i] = fs->IsDirectory(child_path);\n            }\n          };\n\n          BlockingCounter counter(children.size());\n          for (int i = 0; i < children.size(); i++) {\n            (*ctx->runner())([&is_directory_fn, &counter, i] {\n              is_directory_fn(i);\n              counter.DecrementCount();\n            });\n          }\n          counter.Wait();\n\n          for (int i = 0; i < children.size(); i++) {\n            const string child_dir_path = io::JoinPath(cur_dir, children[i]);\n            const Status child_dir_status = children_dir_status[i];\n            // If the IsDirectory call was cancelled we bail.\n            if (child_dir_status.code() == tensorflow::error::CANCELLED) {\n              continue;\n            }\n\n            if (child_dir_status.ok()) {\n              // push the child dir for next search\n              filepath_queue_.push(child_dir_path);\n            } else {\n              // This case will be a file: if the file matches the pattern, push\n              // it to the heap; otherwise, ignore it.\n              if (ctx->env()->MatchPath(child_dir_path, eval_pattern)) {\n                filepath_queue_.push(child_dir_path);\n              }\n            }\n          }", "in_reply_to_id": 221327510}