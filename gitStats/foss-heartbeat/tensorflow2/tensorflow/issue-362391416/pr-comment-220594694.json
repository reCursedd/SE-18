{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/220594694", "pull_request_review_id": 159037045, "id": 220594694, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMDU5NDY5NA==", "diff_hunk": "@@ -0,0 +1,267 @@\n+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for the experimental input pipeline ops.\"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+from os import path\n+import shutil\n+import tempfile\n+\n+from tensorflow.python.data.ops import iterator_ops\n+from tensorflow.python.data.ops.dataset_ops import MatchingFilesDataset\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.platform import test\n+from tensorflow.python.util import compat\n+from tensorflow.python.data.ops import dataset_ops\n+from tensorflow.python.ops.gen_io_ops import matching_files\n+from tensorflow.python.framework import errors\n+\n+import os\n+import time\n+from functools import partial\n+\n+\n+try:\n+  import psutil  # pylint: disable=g-import-not-at-top\n+\n+  psutil_import_succeeded = True\n+except ImportError:\n+  psutil_import_succeeded = False\n+\n+\n+def timeit(fn, msg, N=0):\n+  start = time.time()\n+  res = fn()\n+  end = time.time()\n+  runtime = (end - start) * 1000\n+  msg = '{}: time: {:.2f} ms'.format(msg, runtime)\n+  if N:\n+    msg += ' ({:.2f} ms per iteration)'.format(runtime / N)\n+  print(msg)\n+  return res\n+\n+\n+width = 1000\n+depth = 20\n+\n+\n+class MatchingFilesDatasetTest(test.TestCase):\n+\n+  def setUp(self):\n+    self.tmp_dir = tempfile.mkdtemp()\n+\n+  def tearDown(self):\n+    shutil.rmtree(self.tmp_dir, ignore_errors=True)\n+\n+  def _touchTempFiles(self, filenames):\n+    for filename in filenames:\n+      open(path.join(self.tmp_dir, filename), 'a').close()\n+\n+  def testEmptyDirectory(self):\n+    dataset = MatchingFilesDataset(path.join(self.tmp_dir, '*'))\n+    with self.cached_session() as sess:\n+      itr = iterator_ops.Iterator.from_structure(dataset.output_types)\n+      init_op = itr.make_initializer(dataset)\n+      next_element = itr.get_next()\n+      sess.run(init_op)\n+      with self.assertRaises(errors.OutOfRangeError):\n+        sess.run(next_element)\n+\n+  def testSimpleDirectory(self):\n+    filenames = ['a', 'b', 'c']\n+    self._touchTempFiles(filenames)\n+\n+    dataset = MatchingFilesDataset(path.join(self.tmp_dir, '*'))\n+    with self.cached_session() as sess:\n+      itr = iterator_ops.Iterator.from_structure(dataset.output_types)\n+      init_op = itr.make_initializer(dataset)\n+      next_element = itr.get_next()\n+      sess.run(init_op)\n+\n+      full_filenames = []\n+      produced_filenames = []\n+      for filename in filenames:\n+        full_filenames.append(\n+          compat.as_bytes(path.join(self.tmp_dir, filename)))\n+        produced_filenames.append(compat.as_bytes(sess.run(next_element)))\n+      self.assertItemsEqual(full_filenames, produced_filenames)\n+      with self.assertRaises(errors.OutOfRangeError):\n+        sess.run(itr.get_next())\n+\n+  def testSimpleDirectoryInitializer(self):\n+    filenames = ['a', 'b', 'c']\n+    self._touchTempFiles(filenames)\n+\n+    filename_placeholder = array_ops.placeholder(dtypes.string, shape=[])\n+    dataset = MatchingFilesDataset(filename_placeholder)\n+\n+    with self.cached_session() as sess:\n+      itr = iterator_ops.Iterator.from_structure(dataset.output_types)\n+      init_op = itr.make_initializer(dataset)\n+      next_element = itr.get_next()\n+      sess.run(\n+        init_op,\n+        feed_dict={filename_placeholder: path.join(self.tmp_dir, '*')})\n+\n+      full_filenames = []\n+      produced_filenames = []\n+      for filename in filenames:\n+        full_filenames.append(\n+          compat.as_bytes(path.join(self.tmp_dir, filename)))\n+        produced_filenames.append(compat.as_bytes(sess.run(next_element)))\n+\n+      self.assertItemsEqual(full_filenames, produced_filenames)\n+\n+      with self.assertRaises(errors.OutOfRangeError):\n+        sess.run(itr.get_next())\n+\n+  def testFileSuffixes(self):\n+    filenames = ['a.txt', 'b.py', 'c.py', 'd.pyc']\n+    self._touchTempFiles(filenames)\n+\n+    filename_placeholder = array_ops.placeholder(dtypes.string, shape=[])\n+    dataset = MatchingFilesDataset(filename_placeholder)\n+\n+    with self.cached_session() as sess:\n+      itr = iterator_ops.Iterator.from_structure(dataset.output_types)\n+      init_op = itr.make_initializer(dataset)\n+      next_element = itr.get_next()\n+      sess.run(\n+        init_op,\n+        feed_dict={filename_placeholder: path.join(self.tmp_dir, '*.py')})\n+\n+      full_filenames = []\n+      produced_filenames = []\n+      for filename in filenames[1:-1]:\n+        full_filenames.append(\n+          compat.as_bytes(path.join(self.tmp_dir, filename)))\n+        produced_filenames.append(compat.as_bytes(sess.run(next_element)))\n+      self.assertItemsEqual(full_filenames, produced_filenames)\n+\n+      with self.assertRaises(errors.OutOfRangeError):\n+        sess.run(itr.get_next())\n+\n+  def testFileMiddles(self):\n+    filenames = ['a.txt', 'b.py', 'c.pyc']\n+    self._touchTempFiles(filenames)\n+\n+    filename_placeholder = array_ops.placeholder(dtypes.string, shape=[])\n+    dataset = MatchingFilesDataset(filename_placeholder)\n+\n+    with self.cached_session() as sess:\n+      itr = iterator_ops.Iterator.from_structure(dataset.output_types)\n+      init_op = itr.make_initializer(dataset)\n+      next_element = itr.get_next()\n+      sess.run(\n+        init_op,\n+        feed_dict={filename_placeholder: path.join(self.tmp_dir, '*.py*')})\n+\n+      full_filenames = []\n+      produced_filenames = []\n+      for filename in filenames[1:]:\n+        full_filenames.append(\n+          compat.as_bytes(path.join(self.tmp_dir, filename)))\n+        produced_filenames.append(compat.as_bytes(sess.run(next_element)))\n+\n+      self.assertItemsEqual(full_filenames, produced_filenames)\n+\n+      with self.assertRaises(errors.OutOfRangeError):\n+        sess.run(itr.get_next())\n+", "path": "tensorflow/python/data/kernel_tests/matching_files_dataset_op_test.py", "position": null, "original_position": 185, "commit_id": "0d5b9d20cc3e3062aa4d443bc772bb3aed698d15", "original_commit_id": "de453a41d3886afbcb6c1b51caa3bfa61c2d36ef", "user": {"login": "feihugis", "id": 5057740, "node_id": "MDQ6VXNlcjUwNTc3NDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/5057740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/feihugis", "html_url": "https://github.com/feihugis", "followers_url": "https://api.github.com/users/feihugis/followers", "following_url": "https://api.github.com/users/feihugis/following{/other_user}", "gists_url": "https://api.github.com/users/feihugis/gists{/gist_id}", "starred_url": "https://api.github.com/users/feihugis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/feihugis/subscriptions", "organizations_url": "https://api.github.com/users/feihugis/orgs", "repos_url": "https://api.github.com/users/feihugis/repos", "events_url": "https://api.github.com/users/feihugis/events{/privacy}", "received_events_url": "https://api.github.com/users/feihugis/received_events", "type": "User", "site_admin": false}, "body": "Sure, have added a test for files nested in directories. The structure of nested directories is as below:\r\n```\r\n- /tmp_dir/\r\n- /tmp_dir/0\r\n- /tmp_dir/0/a.txt\r\n- /tmp_dir/0/b.py\r\n- /tmp_dir/0/c.pyc\r\n- /tmp_dir/0/0\r\n- /tmp_dir/0/0/a.txt\r\n- /tmp_dir/0/0/b.py\r\n- /tmp_dir/0/0/c.pyc\r\n- /tmp_dir/0/0/1\r\n- /tmp_dir/0/0/1/a.txt\r\n- /tmp_dir/0/0/1/b.py\r\n- /tmp_dir/0/0/1/c.pyc\r\n- /tmp_dir/0/0/1/2\r\n- /tmp_dir/0/0/1/2/a.txt\r\n- /tmp_dir/0/0/1/2/b.py\r\n- /tmp_dir/0/0/1/2/c.pyc\r\n- /tmp_dir/0/0/1/2/3\r\n- /tmp_dir/0/0/1/2/3/a.txt\r\n- /tmp_dir/0/0/1/2/3/b.py\r\n- /tmp_dir/0/0/1/2/3/c.pyc\r\n.\r\n.\r\n.\r\n- /tmp_dir/0/....../depth-1/\r\n- /tmp_dir/0/....../depth-1/a.txt\r\n- /tmp_dir/0/....../depth-1/b.py\r\n- /tmp_dir/0/....../depth-1/c.pyc\r\n.\r\n.\r\n.\r\n- /tmp_dir/width-1\r\n.\r\n.\r\n.\r\n- /tmp_dir/width-1/....../depth-1/\r\n- /tmp_dir/width-1/....../depth-1/a.txt\r\n- /tmp_dir/width-1/....../depth-1/b.py\r\n- /tmp_dir/width-1/....../depth-1/c.pyc\r\n```", "created_at": "2018-09-26T14:46:48Z", "updated_at": "2018-10-15T21:38:29Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22429#discussion_r220594694", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22429", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/220594694"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22429#discussion_r220594694"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22429"}}, "body_html": "<p>Sure, have added a test for files nested in directories. The structure of nested directories is as below:</p>\n<pre><code>- /tmp_dir/\n- /tmp_dir/0\n- /tmp_dir/0/a.txt\n- /tmp_dir/0/b.py\n- /tmp_dir/0/c.pyc\n- /tmp_dir/0/0\n- /tmp_dir/0/0/a.txt\n- /tmp_dir/0/0/b.py\n- /tmp_dir/0/0/c.pyc\n- /tmp_dir/0/0/1\n- /tmp_dir/0/0/1/a.txt\n- /tmp_dir/0/0/1/b.py\n- /tmp_dir/0/0/1/c.pyc\n- /tmp_dir/0/0/1/2\n- /tmp_dir/0/0/1/2/a.txt\n- /tmp_dir/0/0/1/2/b.py\n- /tmp_dir/0/0/1/2/c.pyc\n- /tmp_dir/0/0/1/2/3\n- /tmp_dir/0/0/1/2/3/a.txt\n- /tmp_dir/0/0/1/2/3/b.py\n- /tmp_dir/0/0/1/2/3/c.pyc\n.\n.\n.\n- /tmp_dir/0/....../depth-1/\n- /tmp_dir/0/....../depth-1/a.txt\n- /tmp_dir/0/....../depth-1/b.py\n- /tmp_dir/0/....../depth-1/c.pyc\n.\n.\n.\n- /tmp_dir/width-1\n.\n.\n.\n- /tmp_dir/width-1/....../depth-1/\n- /tmp_dir/width-1/....../depth-1/a.txt\n- /tmp_dir/width-1/....../depth-1/b.py\n- /tmp_dir/width-1/....../depth-1/c.pyc\n</code></pre>", "body_text": "Sure, have added a test for files nested in directories. The structure of nested directories is as below:\n- /tmp_dir/\n- /tmp_dir/0\n- /tmp_dir/0/a.txt\n- /tmp_dir/0/b.py\n- /tmp_dir/0/c.pyc\n- /tmp_dir/0/0\n- /tmp_dir/0/0/a.txt\n- /tmp_dir/0/0/b.py\n- /tmp_dir/0/0/c.pyc\n- /tmp_dir/0/0/1\n- /tmp_dir/0/0/1/a.txt\n- /tmp_dir/0/0/1/b.py\n- /tmp_dir/0/0/1/c.pyc\n- /tmp_dir/0/0/1/2\n- /tmp_dir/0/0/1/2/a.txt\n- /tmp_dir/0/0/1/2/b.py\n- /tmp_dir/0/0/1/2/c.pyc\n- /tmp_dir/0/0/1/2/3\n- /tmp_dir/0/0/1/2/3/a.txt\n- /tmp_dir/0/0/1/2/3/b.py\n- /tmp_dir/0/0/1/2/3/c.pyc\n.\n.\n.\n- /tmp_dir/0/....../depth-1/\n- /tmp_dir/0/....../depth-1/a.txt\n- /tmp_dir/0/....../depth-1/b.py\n- /tmp_dir/0/....../depth-1/c.pyc\n.\n.\n.\n- /tmp_dir/width-1\n.\n.\n.\n- /tmp_dir/width-1/....../depth-1/\n- /tmp_dir/width-1/....../depth-1/a.txt\n- /tmp_dir/width-1/....../depth-1/b.py\n- /tmp_dir/width-1/....../depth-1/c.pyc", "in_reply_to_id": 219970845}