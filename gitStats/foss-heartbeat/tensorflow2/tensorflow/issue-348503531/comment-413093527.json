{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/413093527", "html_url": "https://github.com/tensorflow/tensorflow/issues/21459#issuecomment-413093527", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21459", "id": 413093527, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzA5MzUyNw==", "user": {"login": "jackd", "id": 659115, "node_id": "MDQ6VXNlcjY1OTExNQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/659115?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jackd", "html_url": "https://github.com/jackd", "followers_url": "https://api.github.com/users/jackd/followers", "following_url": "https://api.github.com/users/jackd/following{/other_user}", "gists_url": "https://api.github.com/users/jackd/gists{/gist_id}", "starred_url": "https://api.github.com/users/jackd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jackd/subscriptions", "organizations_url": "https://api.github.com/users/jackd/orgs", "repos_url": "https://api.github.com/users/jackd/repos", "events_url": "https://api.github.com/users/jackd/events{/privacy}", "received_events_url": "https://api.github.com/users/jackd/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-15T04:50:19Z", "updated_at": "2018-08-15T04:50:19Z", "author_association": "NONE", "body_html": "<p>After extensive testing I found my issue was related to the very high value of <code>decay</code> used in batch normalization. Lowering the decay term to <code>0.9</code> resulted in almost immediate consistency between training performance and evaluation performance. The best explanation I have is that update operations were being run, but the decay value so close to 1 (0.997 for my case using mobilenet) meant moving averages weren't keeping up with the changes to the batch statistics as a result of faster training.</p>\n<p>I find this very surprising, but it's the best I've got...</p>", "body_text": "After extensive testing I found my issue was related to the very high value of decay used in batch normalization. Lowering the decay term to 0.9 resulted in almost immediate consistency between training performance and evaluation performance. The best explanation I have is that update operations were being run, but the decay value so close to 1 (0.997 for my case using mobilenet) meant moving averages weren't keeping up with the changes to the batch statistics as a result of faster training.\nI find this very surprising, but it's the best I've got...", "body": "After extensive testing I found my issue was related to the very high value of `decay` used in batch normalization. Lowering the decay term to `0.9` resulted in almost immediate consistency between training performance and evaluation performance. The best explanation I have is that update operations were being run, but the decay value so close to 1 (0.997 for my case using mobilenet) meant moving averages weren't keeping up with the changes to the batch statistics as a result of faster training.\r\n\r\nI find this very surprising, but it's the best I've got..."}