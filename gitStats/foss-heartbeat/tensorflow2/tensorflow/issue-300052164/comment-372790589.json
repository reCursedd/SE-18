{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/372790589", "html_url": "https://github.com/tensorflow/tensorflow/pull/17261#issuecomment-372790589", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17261", "id": 372790589, "node_id": "MDEyOklzc3VlQ29tbWVudDM3Mjc5MDU4OQ==", "user": {"login": "zasdfgbnm", "id": 1032377, "node_id": "MDQ6VXNlcjEwMzIzNzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1032377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zasdfgbnm", "html_url": "https://github.com/zasdfgbnm", "followers_url": "https://api.github.com/users/zasdfgbnm/followers", "following_url": "https://api.github.com/users/zasdfgbnm/following{/other_user}", "gists_url": "https://api.github.com/users/zasdfgbnm/gists{/gist_id}", "starred_url": "https://api.github.com/users/zasdfgbnm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zasdfgbnm/subscriptions", "organizations_url": "https://api.github.com/users/zasdfgbnm/orgs", "repos_url": "https://api.github.com/users/zasdfgbnm/repos", "events_url": "https://api.github.com/users/zasdfgbnm/events{/privacy}", "received_events_url": "https://api.github.com/users/zasdfgbnm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-13T19:32:06Z", "updated_at": "2018-03-13T19:32:06Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19293677\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ispirmustafa\">@ispirmustafa</a> I don't find sensitivity and specificity there either, do I miss something? However, I find <code>streaming_false_negative_rate</code> and <code>streaming_false_positive_rate</code>, which is 1 - (what I want). I'm totally happy with these two functions, so you can close this PR if you want. Thank you!</p>\n<p>By the way, the metric API of tensorflow looks a bit odd to me: we have true positive(TP), true negative(TN), false positive(FP) and false negative(FN). There are various ways to combine these four metrics:<br>\nTP/(TP+FP)<br>\nFP/(TP+FP)<br>\nTP/(TP+FN)<br>\nFN/(TP+FN)<br>\nTN/(TN+FP)<br>\nFP/(TN+FP)<br>\n.....<br>\nThere are a lot of useful functions like above. The set of functions that tensorflow currently have is not complete and it is hard for users to memorize the name of these functions. If further a \"at_threshold\" mode is supported, this doubles the amount. There is also a \"top_k\" version.... Would it be nice if we have user code that looks like:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(...):\n  <span class=\"pl-c1\">......</span>\n  tp <span class=\"pl-k\">=</span> tf.metrics.true_positive(label, prediction)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> an object of type tf.metrics.Metric</span>\n  fn <span class=\"pl-k\">=</span> tf.metrics.false_negative(label, prediction)\n  sensitivity <span class=\"pl-k\">=</span> tp <span class=\"pl-k\">/</span> (tp <span class=\"pl-k\">+</span> fn)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> safe div of two tf.metrics.Metric object</span>\n  <span class=\"pl-c1\">......</span>\n  <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(mode, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">eval_metric_ops</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>dict of string-&gt;tf.metrics.Metric<span class=\"pl-pds\">\"</span></span>})</pre></div>", "body_text": "@ispirmustafa I don't find sensitivity and specificity there either, do I miss something? However, I find streaming_false_negative_rate and streaming_false_positive_rate, which is 1 - (what I want). I'm totally happy with these two functions, so you can close this PR if you want. Thank you!\nBy the way, the metric API of tensorflow looks a bit odd to me: we have true positive(TP), true negative(TN), false positive(FP) and false negative(FN). There are various ways to combine these four metrics:\nTP/(TP+FP)\nFP/(TP+FP)\nTP/(TP+FN)\nFN/(TP+FN)\nTN/(TN+FP)\nFP/(TN+FP)\n.....\nThere are a lot of useful functions like above. The set of functions that tensorflow currently have is not complete and it is hard for users to memorize the name of these functions. If further a \"at_threshold\" mode is supported, this doubles the amount. There is also a \"top_k\" version.... Would it be nice if we have user code that looks like:\ndef model_fn(...):\n  ......\n  tp = tf.metrics.true_positive(label, prediction)  # an object of type tf.metrics.Metric\n  fn = tf.metrics.false_negative(label, prediction)\n  sensitivity = tp / (tp + fn)  # safe div of two tf.metrics.Metric object\n  ......\n  return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops={\"dict of string->tf.metrics.Metric\"})", "body": "@ispirmustafa I don't find sensitivity and specificity there either, do I miss something? However, I find `streaming_false_negative_rate` and `streaming_false_positive_rate`, which is 1 - (what I want). I'm totally happy with these two functions, so you can close this PR if you want. Thank you!\r\n\r\nBy the way, the metric API of tensorflow looks a bit odd to me: we have true positive(TP), true negative(TN), false positive(FP) and false negative(FN). There are various ways to combine these four metrics:\r\nTP/(TP+FP)\r\nFP/(TP+FP)\r\nTP/(TP+FN)\r\nFN/(TP+FN)\r\nTN/(TN+FP)\r\nFP/(TN+FP)\r\n.....\r\nThere are a lot of useful functions like above. The set of functions that tensorflow currently have is not complete and it is hard for users to memorize the name of these functions. If further a \"at_threshold\" mode is supported, this doubles the amount. There is also a \"top_k\" version.... Would it be nice if we have user code that looks like:\r\n```python\r\ndef model_fn(...):\r\n  ......\r\n  tp = tf.metrics.true_positive(label, prediction)  # an object of type tf.metrics.Metric\r\n  fn = tf.metrics.false_negative(label, prediction)\r\n  sensitivity = tp / (tp + fn)  # safe div of two tf.metrics.Metric object\r\n  ......\r\n  return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops={\"dict of string->tf.metrics.Metric\"})\r\n```"}