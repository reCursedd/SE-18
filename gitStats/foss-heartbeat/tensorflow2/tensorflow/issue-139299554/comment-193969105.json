{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/193969105", "html_url": "https://github.com/tensorflow/tensorflow/issues/1432#issuecomment-193969105", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1432", "id": 193969105, "node_id": "MDEyOklzc3VlQ29tbWVudDE5Mzk2OTEwNQ==", "user": {"login": "OlavHN", "id": 324645, "node_id": "MDQ6VXNlcjMyNDY0NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/324645?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OlavHN", "html_url": "https://github.com/OlavHN", "followers_url": "https://api.github.com/users/OlavHN/followers", "following_url": "https://api.github.com/users/OlavHN/following{/other_user}", "gists_url": "https://api.github.com/users/OlavHN/gists{/gist_id}", "starred_url": "https://api.github.com/users/OlavHN/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OlavHN/subscriptions", "organizations_url": "https://api.github.com/users/OlavHN/orgs", "repos_url": "https://api.github.com/users/OlavHN/repos", "events_url": "https://api.github.com/users/OlavHN/events{/privacy}", "received_events_url": "https://api.github.com/users/OlavHN/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-08T21:12:30Z", "updated_at": "2016-03-08T21:12:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Line 134 to <code>with gfile.GFile(data_path, mode=\"rb\") as f:</code></p>\n<p>together with</p>\n<p>Line 140 to <code>tokens = tokenizer(line.decode('latin1')) if tokenizer else basic_tokenizer(line.decode('latin1'))</code></p>\n<p>also seems to solve the issue for python 3.</p>", "body_text": "Line 134 to with gfile.GFile(data_path, mode=\"rb\") as f:\ntogether with\nLine 140 to tokens = tokenizer(line.decode('latin1')) if tokenizer else basic_tokenizer(line.decode('latin1'))\nalso seems to solve the issue for python 3.", "body": "Line 134 to `with gfile.GFile(data_path, mode=\"rb\") as f:`\n\ntogether with\n\nLine 140 to `tokens = tokenizer(line.decode('latin1')) if tokenizer else basic_tokenizer(line.decode('latin1'))`\n\nalso seems to solve the issue for python 3.\n"}