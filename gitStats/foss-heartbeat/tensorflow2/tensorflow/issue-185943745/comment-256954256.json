{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256954256", "html_url": "https://github.com/tensorflow/tensorflow/issues/5263#issuecomment-256954256", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5263", "id": 256954256, "node_id": "MDEyOklzc3VlQ29tbWVudDI1Njk1NDI1Ng==", "user": {"login": "NickShahML", "id": 14891677, "node_id": "MDQ6VXNlcjE0ODkxNjc3", "avatar_url": "https://avatars2.githubusercontent.com/u/14891677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NickShahML", "html_url": "https://github.com/NickShahML", "followers_url": "https://api.github.com/users/NickShahML/followers", "following_url": "https://api.github.com/users/NickShahML/following{/other_user}", "gists_url": "https://api.github.com/users/NickShahML/gists{/gist_id}", "starred_url": "https://api.github.com/users/NickShahML/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NickShahML/subscriptions", "organizations_url": "https://api.github.com/users/NickShahML/orgs", "repos_url": "https://api.github.com/users/NickShahML/repos", "events_url": "https://api.github.com/users/NickShahML/events{/privacy}", "received_events_url": "https://api.github.com/users/NickShahML/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-28T15:40:03Z", "updated_at": "2016-10-28T15:40:21Z", "author_association": "NONE", "body_html": "<p>Sorry, forgot to add that. The error message seems to tell you which tensors have not been initialized. However, this does not tell you which gpu ran out of memory, because tensors can not be initialized on both gpus. You are still left with not knowing which gpu ran out of memory.</p>\n<p>I tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 11.27GiB          [1020/1823]<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats:<br>\nLimit:                 12104795546<br>\nInUse:                 12104599040<br>\nMaxInUse:              12104599040<br>\nNumAllocs:                   50546<br>\nMaxAllocSize:            164069376</p>\n<p>W tensorflow/core/common_runtime/bfc_allocator.cc:270] *********************************************************</p>\n<hr>\n<p>W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 384.0KiB.  See logs<br>\nfor memory state.<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 74370 get requests, put_count=2<br>\n3731 evicted_count=1000 eviction_rate=0.042139 and unsatisfied allocation rate=0.695697<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=10010<br>\nevicted_count=10000 eviction_rate=0.999001 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=20010<br>\nevicted_count=20000 eviction_rate=0.9995 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=30010<br>\nevicted_count=30000 eviction_rate=0.999667 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=40010<br>\nevicted_count=40000 eviction_rate=0.99975 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=50010<br>\nevicted_count=50000 eviction_rate=0.9998 and unsatisfied allocation rate=0<br>\nW tensorflow/core/framework/op_kernel.cc:968] Internal: Dst tensor is not initialized.```<br>\n[[Node: vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/embedding_atte<br>\nntion_decoder/Attention_0_60/attn_stack_layer0/Reshape_2/_91437 = _Recv<a href=\"\">client_terminated=false, recv_device=\"/j<br>\nob:localhost/replica:0/task:0/gpu:1\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnati<br>\non=1, tensor_name=\"edge_356892_vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/<br>\nembedding_attention_decoder/Attention_0_60/attn_stack_layer0/Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:loc<br>\nalhost/replica:0/task:0/gpu:1\"</a>]]<br>\n[[Node: vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/embedding_atte<br>\nntion_decoder/MultiRNNCell_69/Cell1/LayerNormBasicLSTMCell/forget/forget/moments/sufficient_statistics/Shape/_89<br>\n165 = _Recv<a href=\"\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:loca<br>\nlhost/replica:0/task:0/gpu:1\", send_device_incarnation=1, tensor_name=\"edge_525863_vanilla_generator_seq2seq_mod<br>\nel/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/MultiRNNCell_69/Cell1/LayerNormB<br>\nasicLSTMCell/forget/forget/moments/sufficient_statistics/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/r<br>\neplica:0/task:0/cpu:0\"</a>]]</p>", "body_text": "Sorry, forgot to add that. The error message seems to tell you which tensors have not been initialized. However, this does not tell you which gpu ran out of memory, because tensors can not be initialized on both gpus. You are still left with not knowing which gpu ran out of memory.\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 11.27GiB          [1020/1823]\nI tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats:\nLimit:                 12104795546\nInUse:                 12104599040\nMaxInUse:              12104599040\nNumAllocs:                   50546\nMaxAllocSize:            164069376\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] *********************************************************\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 384.0KiB.  See logs\nfor memory state.\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 74370 get requests, put_count=2\n3731 evicted_count=1000 eviction_rate=0.042139 and unsatisfied allocation rate=0.695697\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=10010\nevicted_count=10000 eviction_rate=0.999001 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=20010\nevicted_count=20000 eviction_rate=0.9995 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=30010\nevicted_count=30000 eviction_rate=0.999667 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=40010\nevicted_count=40000 eviction_rate=0.99975 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=50010\nevicted_count=50000 eviction_rate=0.9998 and unsatisfied allocation rate=0\nW tensorflow/core/framework/op_kernel.cc:968] Internal: Dst tensor is not initialized.```\n[[Node: vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/embedding_atte\nntion_decoder/Attention_0_60/attn_stack_layer0/Reshape_2/_91437 = _Recvclient_terminated=false, recv_device=\"/j\nob:localhost/replica:0/task:0/gpu:1\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnati\non=1, tensor_name=\"edge_356892_vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/\nembedding_attention_decoder/Attention_0_60/attn_stack_layer0/Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:loc\nalhost/replica:0/task:0/gpu:1\"]]\n[[Node: vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/embedding_atte\nntion_decoder/MultiRNNCell_69/Cell1/LayerNormBasicLSTMCell/forget/forget/moments/sufficient_statistics/Shape/_89\n165 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:loca\nlhost/replica:0/task:0/gpu:1\", send_device_incarnation=1, tensor_name=\"edge_525863_vanilla_generator_seq2seq_mod\nel/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/MultiRNNCell_69/Cell1/LayerNormB\nasicLSTMCell/forget/forget/moments/sufficient_statistics/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/r\neplica:0/task:0/cpu:0\"]]", "body": "Sorry, forgot to add that. The error message seems to tell you which tensors have not been initialized. However, this does not tell you which gpu ran out of memory, because tensors can not be initialized on both gpus. You are still left with not knowing which gpu ran out of memory. \n\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 11.27GiB          [1020/1823]\nI tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: \nLimit:                 12104795546\nInUse:                 12104599040\nMaxInUse:              12104599040\nNumAllocs:                   50546\nMaxAllocSize:            164069376\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] *********************************************************\n\n---\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 384.0KiB.  See logs \nfor memory state.\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 74370 get requests, put_count=2\n3731 evicted_count=1000 eviction_rate=0.042139 and unsatisfied allocation rate=0.695697\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=10010\n evicted_count=10000 eviction_rate=0.999001 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=20010\n evicted_count=20000 eviction_rate=0.9995 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=30010\n evicted_count=30000 eviction_rate=0.999667 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=40010\n evicted_count=40000 eviction_rate=0.99975 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 0 get requests, put_count=50010\n evicted_count=50000 eviction_rate=0.9998 and unsatisfied allocation rate=0\nW tensorflow/core/framework/op_kernel.cc:968] Internal: Dst tensor is not initialized.```\n[[Node: vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/embedding_atte\nntion_decoder/Attention_0_60/attn_stack_layer0/Reshape_2/_91437 = _Recv[client_terminated=false, recv_device=\"/j\nob:localhost/replica:0/task:0/gpu:1\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnati\non=1, tensor_name=\"edge_356892_vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/\nembedding_attention_decoder/Attention_0_60/attn_stack_layer0/Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:loc\nalhost/replica:0/task:0/gpu:1\"]()]]\n         [[Node: vanilla_generator_seq2seq_model/model_with_buckets/embedding_attention_seq2seq_2/embedding_atte\nntion_decoder/MultiRNNCell_69/Cell1/LayerNormBasicLSTMCell/forget/forget/moments/sufficient_statistics/Shape/_89\n165 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:loca\nlhost/replica:0/task:0/gpu:1\", send_device_incarnation=1, tensor_name=\"edge_525863_vanilla_generator_seq2seq_mod\nel/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/MultiRNNCell_69/Cell1/LayerNormB\nasicLSTMCell/forget/forget/moments/sufficient_statistics/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/r\neplica:0/task:0/cpu:0\"]()]]\n"}