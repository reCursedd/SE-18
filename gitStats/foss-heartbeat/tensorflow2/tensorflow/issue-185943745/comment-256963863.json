{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256963863", "html_url": "https://github.com/tensorflow/tensorflow/issues/5263#issuecomment-256963863", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5263", "id": 256963863, "node_id": "MDEyOklzc3VlQ29tbWVudDI1Njk2Mzg2Mw==", "user": {"login": "NickShahML", "id": 14891677, "node_id": "MDQ6VXNlcjE0ODkxNjc3", "avatar_url": "https://avatars2.githubusercontent.com/u/14891677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NickShahML", "html_url": "https://github.com/NickShahML", "followers_url": "https://api.github.com/users/NickShahML/followers", "following_url": "https://api.github.com/users/NickShahML/following{/other_user}", "gists_url": "https://api.github.com/users/NickShahML/gists{/gist_id}", "starred_url": "https://api.github.com/users/NickShahML/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NickShahML/subscriptions", "organizations_url": "https://api.github.com/users/NickShahML/orgs", "repos_url": "https://api.github.com/users/NickShahML/repos", "events_url": "https://api.github.com/users/NickShahML/events{/privacy}", "received_events_url": "https://api.github.com/users/NickShahML/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-28T16:19:15Z", "updated_at": "2016-10-28T16:19:15Z", "author_association": "NONE", "body_html": "<p>When I run this network on one titan x, it runs with a batch size of 64. I'm attempting to raise the batch size to 96 with two titan x's on board. I feel that this should be easily done as there is double the GPU memory. Even a batch size of 128 should be doable.</p>\n<p>I just placed more of the forward pass on GPU0 in response to your previous message. I'm still getting a memory error. Currently I have:</p>\n<p>GPU0 --&gt; stores all vars and handles forward pass<br>\nGPU1 --&gt; stores all gradients and handles gradient computations</p>\n<p>I will keep trying to change things around, but perhaps I'm approaching this the wrong way. This is turning more into a stack overflow question. Any help is greatly appreciated and I posted the overflow question in regards to this here:</p>\n<p><a href=\"http://stackoverflow.com/questions/39773645/split-rnn-memory-consumption-evenly-between-gpus-in-tensorflow\" rel=\"nofollow\">http://stackoverflow.com/questions/39773645/split-rnn-memory-consumption-evenly-between-gpus-in-tensorflow</a></p>", "body_text": "When I run this network on one titan x, it runs with a batch size of 64. I'm attempting to raise the batch size to 96 with two titan x's on board. I feel that this should be easily done as there is double the GPU memory. Even a batch size of 128 should be doable.\nI just placed more of the forward pass on GPU0 in response to your previous message. I'm still getting a memory error. Currently I have:\nGPU0 --> stores all vars and handles forward pass\nGPU1 --> stores all gradients and handles gradient computations\nI will keep trying to change things around, but perhaps I'm approaching this the wrong way. This is turning more into a stack overflow question. Any help is greatly appreciated and I posted the overflow question in regards to this here:\nhttp://stackoverflow.com/questions/39773645/split-rnn-memory-consumption-evenly-between-gpus-in-tensorflow", "body": "When I run this network on one titan x, it runs with a batch size of 64. I'm attempting to raise the batch size to 96 with two titan x's on board. I feel that this should be easily done as there is double the GPU memory. Even a batch size of 128 should be doable.\n\nI just placed more of the forward pass on GPU0 in response to your previous message. I'm still getting a memory error. Currently I have:\n\nGPU0 --> stores all vars and handles forward pass\nGPU1 --> stores all gradients and handles gradient computations\n\nI will keep trying to change things around, but perhaps I'm approaching this the wrong way. This is turning more into a stack overflow question. Any help is greatly appreciated and I posted the overflow question in regards to this here:\n\nhttp://stackoverflow.com/questions/39773645/split-rnn-memory-consumption-evenly-between-gpus-in-tensorflow\n"}