{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256115990", "html_url": "https://github.com/tensorflow/tensorflow/issues/4709#issuecomment-256115990", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4709", "id": 256115990, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NjExNTk5MA==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-25T18:13:06Z", "updated_at": "2016-10-25T18:13:06Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You can also get raw memory allocator messages in your log like this:<br>\n<a href=\"http://stackoverflow.com/questions/36331419/tensorflow-how-to-measure-how-much-gpu-memory-each-tensor-takes/36505898#36505898\" rel=\"nofollow\">http://stackoverflow.com/questions/36331419/tensorflow-how-to-measure-how-much-gpu-memory-each-tensor-takes/36505898#36505898</a></p>\n<p>On Thu, Oct 20, 2016 at 10:17 AM, Yaroslav Bulatov <a href=\"mailto:yaroslavvb@gmail.com\">yaroslavvb@gmail.com</a><br>\nwrote:</p>\n<blockquote>\n<p>If you print run_metadata, you'll see messages like this:</p>\n<pre><code>  output {\n    tensor_description {\n      dtype: DT_FLOAT\n      shape {\n      }\n      allocation_description {\n        requested_bytes: 4\n        allocator_name: \"cpu\"\n        ptr: 4493467328\n      }\n    }\n  }\n</code></pre>\n<p>That means 4 bytes got allocated</p>\n<p>On Thu, Oct 20, 2016 at 5:17 AM, redst4r <a href=\"mailto:notifications@github.com\">notifications@github.com</a> wrote:</p>\n<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> <a href=\"https://github.com/yaroslavvb\">https://github.com/yaroslavvb</a> : can you elaborate on using<br>\nFULL_TRACING to get memory allocator stats?<br>\nI managed to get the timing information via:</p>\n<p>from tensorflow.python.client import timeline<br>\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)<br>\nrun_metadata = tf.RunMetadata()<br>\nsess.run(some_stuff, options=run_options, run_metadata=run_metadata)</p>\n<h1>for visualization</h1>\n<p>tl = timeline.Timeline(run_metadata.step_stats)<br>\nctf = tl.generate_chrome_trace_format()with open('timeline.json', 'w') as f:<br>\nf.write(ctf)</p>\n<p>But how would I assess the memory allocation from run_metadata?</p>\n<p>\u2014<br>\nYou are receiving this because you were mentioned.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"180467114\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4709\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4709/hovercard?comment_id=255089531&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/4709#issuecomment-255089531\">#4709 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/AABaHAUCSGUxmaSCC8P-Wonypmt8AT3nks5q11vVgaJpZM4KLzWI\">https://github.com/notifications/unsubscribe-auth/AABaHAUCSGUxmaSCC8P-Wonypmt8AT3nks5q11vVgaJpZM4KLzWI</a><br>\n.</p>\n</blockquote>\n</blockquote>", "body_text": "You can also get raw memory allocator messages in your log like this:\nhttp://stackoverflow.com/questions/36331419/tensorflow-how-to-measure-how-much-gpu-memory-each-tensor-takes/36505898#36505898\nOn Thu, Oct 20, 2016 at 10:17 AM, Yaroslav Bulatov yaroslavvb@gmail.com\nwrote:\n\nIf you print run_metadata, you'll see messages like this:\n  output {\n    tensor_description {\n      dtype: DT_FLOAT\n      shape {\n      }\n      allocation_description {\n        requested_bytes: 4\n        allocator_name: \"cpu\"\n        ptr: 4493467328\n      }\n    }\n  }\n\nThat means 4 bytes got allocated\nOn Thu, Oct 20, 2016 at 5:17 AM, redst4r notifications@github.com wrote:\n\n@yaroslavvb https://github.com/yaroslavvb : can you elaborate on using\nFULL_TRACING to get memory allocator stats?\nI managed to get the timing information via:\nfrom tensorflow.python.client import timeline\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\nrun_metadata = tf.RunMetadata()\nsess.run(some_stuff, options=run_options, run_metadata=run_metadata)\nfor visualization\ntl = timeline.Timeline(run_metadata.step_stats)\nctf = tl.generate_chrome_trace_format()with open('timeline.json', 'w') as f:\nf.write(ctf)\nBut how would I assess the memory allocation from run_metadata?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n#4709 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABaHAUCSGUxmaSCC8P-Wonypmt8AT3nks5q11vVgaJpZM4KLzWI\n.", "body": "You can also get raw memory allocator messages in your log like this:\nhttp://stackoverflow.com/questions/36331419/tensorflow-how-to-measure-how-much-gpu-memory-each-tensor-takes/36505898#36505898\n\nOn Thu, Oct 20, 2016 at 10:17 AM, Yaroslav Bulatov yaroslavvb@gmail.com\nwrote:\n\n> If you print run_metadata, you'll see messages like this:\n> \n> ```\n>   output {\n>     tensor_description {\n>       dtype: DT_FLOAT\n>       shape {\n>       }\n>       allocation_description {\n>         requested_bytes: 4\n>         allocator_name: \"cpu\"\n>         ptr: 4493467328\n>       }\n>     }\n>   }\n> ```\n> \n> That means 4 bytes got allocated\n> \n> On Thu, Oct 20, 2016 at 5:17 AM, redst4r notifications@github.com wrote:\n> \n> > @yaroslavvb https://github.com/yaroslavvb : can you elaborate on using\n> > FULL_TRACING to get memory allocator stats?\n> > I managed to get the timing information via:\n> > \n> > from tensorflow.python.client import timeline\n> > run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n> > run_metadata = tf.RunMetadata()\n> > sess.run(some_stuff, options=run_options, run_metadata=run_metadata)\n> > \n> > # for visualization\n> > \n> > tl = timeline.Timeline(run_metadata.step_stats)\n> > ctf = tl.generate_chrome_trace_format()with open('timeline.json', 'w') as f:\n> >     f.write(ctf)\n> > \n> > But how would I assess the memory allocation from run_metadata?\n> > \n> > \u2014\n> > You are receiving this because you were mentioned.\n> > Reply to this email directly, view it on GitHub\n> > https://github.com/tensorflow/tensorflow/issues/4709#issuecomment-255089531,\n> > or mute the thread\n> > https://github.com/notifications/unsubscribe-auth/AABaHAUCSGUxmaSCC8P-Wonypmt8AT3nks5q11vVgaJpZM4KLzWI\n> > .\n"}