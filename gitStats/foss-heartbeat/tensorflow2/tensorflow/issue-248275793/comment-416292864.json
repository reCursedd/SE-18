{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/416292864", "html_url": "https://github.com/tensorflow/tensorflow/issues/12065#issuecomment-416292864", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12065", "id": 416292864, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNjI5Mjg2NA==", "user": {"login": "muggin", "id": 4559861, "node_id": "MDQ6VXNlcjQ1NTk4NjE=", "avatar_url": "https://avatars3.githubusercontent.com/u/4559861?v=4", "gravatar_id": "", "url": "https://api.github.com/users/muggin", "html_url": "https://github.com/muggin", "followers_url": "https://api.github.com/users/muggin/followers", "following_url": "https://api.github.com/users/muggin/following{/other_user}", "gists_url": "https://api.github.com/users/muggin/gists{/gist_id}", "starred_url": "https://api.github.com/users/muggin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/muggin/subscriptions", "organizations_url": "https://api.github.com/users/muggin/orgs", "repos_url": "https://api.github.com/users/muggin/repos", "events_url": "https://api.github.com/users/muggin/events{/privacy}", "received_events_url": "https://api.github.com/users/muggin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-27T16:57:00Z", "updated_at": "2018-08-27T16:59:32Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8748158\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Andreea-G\">@Andreea-G</a> could you please elaborate on this flag <code>end_fn=lambda sample_ids: False</code> in your <code>InferenceHelper</code>? Wouldn't this be equal to setting <code>impute_finished=False</code>?</p>\n<p>I use the following lambda function <code>end_fn=lambda outputs: tf.greater_equal(tf.shape(outputs)[1], self.outputs_len)</code> where <code>self.outputs_len</code> are the true lengths of the target sequences. In this setting, during training, the validation loss doesn't decrease. If I set <code>impute_finished=False</code>, validation loss does decrease. I'm having difficulties in understanding this behavior.</p>", "body_text": "@Andreea-G could you please elaborate on this flag end_fn=lambda sample_ids: False in your InferenceHelper? Wouldn't this be equal to setting impute_finished=False?\nI use the following lambda function end_fn=lambda outputs: tf.greater_equal(tf.shape(outputs)[1], self.outputs_len) where self.outputs_len are the true lengths of the target sequences. In this setting, during training, the validation loss doesn't decrease. If I set impute_finished=False, validation loss does decrease. I'm having difficulties in understanding this behavior.", "body": "@Andreea-G could you please elaborate on this flag `end_fn=lambda sample_ids: False` in your `InferenceHelper`? Wouldn't this be equal to setting `impute_finished=False`?\r\n\r\nI use the following lambda function `end_fn=lambda outputs: tf.greater_equal(tf.shape(outputs)[1], self.outputs_len)` where `self.outputs_len` are the true lengths of the target sequences. In this setting, during training, the validation loss doesn't decrease. If I set `impute_finished=False`, validation loss does decrease. I'm having difficulties in understanding this behavior.\r\n"}