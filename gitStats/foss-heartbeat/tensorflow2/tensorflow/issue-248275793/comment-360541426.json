{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/360541426", "html_url": "https://github.com/tensorflow/tensorflow/issues/12065#issuecomment-360541426", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12065", "id": 360541426, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDU0MTQyNg==", "user": {"login": "RylanSchaeffer", "id": 8942987, "node_id": "MDQ6VXNlcjg5NDI5ODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/8942987?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RylanSchaeffer", "html_url": "https://github.com/RylanSchaeffer", "followers_url": "https://api.github.com/users/RylanSchaeffer/followers", "following_url": "https://api.github.com/users/RylanSchaeffer/following{/other_user}", "gists_url": "https://api.github.com/users/RylanSchaeffer/gists{/gist_id}", "starred_url": "https://api.github.com/users/RylanSchaeffer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RylanSchaeffer/subscriptions", "organizations_url": "https://api.github.com/users/RylanSchaeffer/orgs", "repos_url": "https://api.github.com/users/RylanSchaeffer/repos", "events_url": "https://api.github.com/users/RylanSchaeffer/events{/privacy}", "received_events_url": "https://api.github.com/users/RylanSchaeffer/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-25T17:36:41Z", "updated_at": "2018-01-25T17:36:41Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=34604047\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzfitzpatrick\">@fritzfitzpatrick</a> , I'd rather help you here in case anyone else runs into a similar issue.</p>\n<p>Here's the code I used. In my case, I had a (4,)-shaped tensor of zeros and ones as outputs, hence 16 possible outcomes, hence my sampling function. However, the sampling function was just for helping me debug whereas you can get by with a function that does nothing.</p>\n<h1>inference</h1>\n<pre><code>        elif self.mode == 'inference':\n\n            def initialize_fn():\n                finished = tf.tile([False], [FLAGS.batch_size])\n                start_inputs = tf.fill([FLAGS.batch_size, 4], -1.)\n                return (finished, start_inputs)\n\n            def sample_fn(time, outputs, state):\n                del time, state\n                outputs = tf.cast(tf.round(tf.nn.sigmoid(outputs)),\n                                  dtype=tf.int32)\n                sample_ids = outputs[:, 0] + 2 * outputs[:, 1] + \\\n                             4 * outputs[:, 2] + 8 * outputs[:, 3]\n                return sample_ids\n\n            def next_inputs_fn(time, outputs, state, sample_ids):\n                del time, sample_ids\n                squashed_logits = tf.nn.sigmoid(outputs)\n                binary_decoder_outputs = tf.round(squashed_logits)\n                finished = tf.equal(\n                    0.,\n                    tf.reduce_sum(binary_decoder_outputs, axis=1))\n                all_finished = tf.reduce_all(finished)\n                next_inputs = tf.cond(\n                    all_finished,\n                    # If we're finished, the next_inputs value doesn't matter\n                    lambda: tf.zeros_like(outputs),\n                    lambda: squashed_logits)\n                return (finished, next_inputs, state)\n\n            helper = CustomHelper(initialize_fn=initialize_fn,\n                                  sample_fn=sample_fn,\n                                  next_inputs_fn=next_inputs_fn)\n</code></pre>", "body_text": "@fritzfitzpatrick , I'd rather help you here in case anyone else runs into a similar issue.\nHere's the code I used. In my case, I had a (4,)-shaped tensor of zeros and ones as outputs, hence 16 possible outcomes, hence my sampling function. However, the sampling function was just for helping me debug whereas you can get by with a function that does nothing.\ninference\n        elif self.mode == 'inference':\n\n            def initialize_fn():\n                finished = tf.tile([False], [FLAGS.batch_size])\n                start_inputs = tf.fill([FLAGS.batch_size, 4], -1.)\n                return (finished, start_inputs)\n\n            def sample_fn(time, outputs, state):\n                del time, state\n                outputs = tf.cast(tf.round(tf.nn.sigmoid(outputs)),\n                                  dtype=tf.int32)\n                sample_ids = outputs[:, 0] + 2 * outputs[:, 1] + \\\n                             4 * outputs[:, 2] + 8 * outputs[:, 3]\n                return sample_ids\n\n            def next_inputs_fn(time, outputs, state, sample_ids):\n                del time, sample_ids\n                squashed_logits = tf.nn.sigmoid(outputs)\n                binary_decoder_outputs = tf.round(squashed_logits)\n                finished = tf.equal(\n                    0.,\n                    tf.reduce_sum(binary_decoder_outputs, axis=1))\n                all_finished = tf.reduce_all(finished)\n                next_inputs = tf.cond(\n                    all_finished,\n                    # If we're finished, the next_inputs value doesn't matter\n                    lambda: tf.zeros_like(outputs),\n                    lambda: squashed_logits)\n                return (finished, next_inputs, state)\n\n            helper = CustomHelper(initialize_fn=initialize_fn,\n                                  sample_fn=sample_fn,\n                                  next_inputs_fn=next_inputs_fn)", "body": "@fritzfitzpatrick , I'd rather help you here in case anyone else runs into a similar issue.\r\n\r\nHere's the code I used. In my case, I had a (4,)-shaped tensor of zeros and ones as outputs, hence 16 possible outcomes, hence my sampling function. However, the sampling function was just for helping me debug whereas you can get by with a function that does nothing.\r\n\r\n# inference\r\n            elif self.mode == 'inference':\r\n\r\n                def initialize_fn():\r\n                    finished = tf.tile([False], [FLAGS.batch_size])\r\n                    start_inputs = tf.fill([FLAGS.batch_size, 4], -1.)\r\n                    return (finished, start_inputs)\r\n\r\n                def sample_fn(time, outputs, state):\r\n                    del time, state\r\n                    outputs = tf.cast(tf.round(tf.nn.sigmoid(outputs)),\r\n                                      dtype=tf.int32)\r\n                    sample_ids = outputs[:, 0] + 2 * outputs[:, 1] + \\\r\n                                 4 * outputs[:, 2] + 8 * outputs[:, 3]\r\n                    return sample_ids\r\n\r\n                def next_inputs_fn(time, outputs, state, sample_ids):\r\n                    del time, sample_ids\r\n                    squashed_logits = tf.nn.sigmoid(outputs)\r\n                    binary_decoder_outputs = tf.round(squashed_logits)\r\n                    finished = tf.equal(\r\n                        0.,\r\n                        tf.reduce_sum(binary_decoder_outputs, axis=1))\r\n                    all_finished = tf.reduce_all(finished)\r\n                    next_inputs = tf.cond(\r\n                        all_finished,\r\n                        # If we're finished, the next_inputs value doesn't matter\r\n                        lambda: tf.zeros_like(outputs),\r\n                        lambda: squashed_logits)\r\n                    return (finished, next_inputs, state)\r\n\r\n                helper = CustomHelper(initialize_fn=initialize_fn,\r\n                                      sample_fn=sample_fn,\r\n                                      next_inputs_fn=next_inputs_fn)"}