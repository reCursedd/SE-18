{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/320997810", "html_url": "https://github.com/tensorflow/tensorflow/issues/12065#issuecomment-320997810", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12065", "id": 320997810, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDk5NzgxMA==", "user": {"login": "RylanSchaeffer", "id": 8942987, "node_id": "MDQ6VXNlcjg5NDI5ODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/8942987?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RylanSchaeffer", "html_url": "https://github.com/RylanSchaeffer", "followers_url": "https://api.github.com/users/RylanSchaeffer/followers", "following_url": "https://api.github.com/users/RylanSchaeffer/following{/other_user}", "gists_url": "https://api.github.com/users/RylanSchaeffer/gists{/gist_id}", "starred_url": "https://api.github.com/users/RylanSchaeffer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RylanSchaeffer/subscriptions", "organizations_url": "https://api.github.com/users/RylanSchaeffer/orgs", "repos_url": "https://api.github.com/users/RylanSchaeffer/repos", "events_url": "https://api.github.com/users/RylanSchaeffer/events{/privacy}", "received_events_url": "https://api.github.com/users/RylanSchaeffer/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-08T15:47:44Z", "updated_at": "2017-08-09T16:34:03Z", "author_association": "NONE", "body_html": "<p>I'm trying to implement my suggestion, but I'm running into an error that I'm unsure of how to debug.</p>\n<p>My code:</p>\n<pre><code>class OutputInferenceHelper(Helper):\n\n    def __init__(self, start_tensors, end_tensor, name=None):\n        \"\"\"Initializer.\n        \n        Args:\n          start_tensors: `float32` tensor shaped `[batch_size, ...]`, the start\n           tensors.\n          end_tensor: `float32` tensor shaped `[...]`, the tensor that marks \n           end of decoding.\n        \"\"\"\n        with ops.name_scope(name, \"OutputInferenceHelper\"):\n            self._start_tensors = ops.convert_to_tensor(\n                start_tensors, dtype=dtypes.float32, name=\"start_tensors\")\n            self._end_tensor = ops.convert_to_tensor(\n                end_tensor, dtype=dtypes.float32, name=\"end_tensor\")\n            self._batch_size = array_ops.shape(start_tensors)[0]\n\n    @property\n    def batch_size(self):\n        return self._batch_size\n\n    def initialize(self, name=None):\n        with ops.name_scope(name, \"OutputInferenceHelperInitialize\"):\n            finished = array_ops.tile([False], [self._batch_size])\n            return (finished, self._start_tensors)\n\n    def sample(self, time, outputs, state, name=None):\n        with ops.name_scope(name, \"OutputInferenceHelperSample\"):\n            del time, state\n            if not isinstance(outputs, ops.Tensor):\n                raise TypeError(\"Expected outputs to be a single Tensor, got: %s\" %\n                                type(outputs))\n            return outputs\n\n    def next_inputs(self, time, outputs, state, sample_ids, name=None):\n        with ops.name_scope(name, \"OutputInferenceHelperNextInputs\"):\n            del time, sample_ids\n            finished = math_ops.equal(outputs, self._end_tensor)\n            all_finished = math_ops.reduce_all(finished)\n            next_inputs = control_flow_ops.cond(\n                all_finished,\n                # If we're finished, the next_inputs value doesn't matter\n                lambda: self._start_tensors,\n                lambda: outputs)\n\n            return (finished, next_inputs, state)\n</code></pre>\n<p>I'm receiving the following error: <code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 1 and 2 for 'add_inference/add_decoder/decoder/while/Select' (op: 'Select') with input shapes: [128,4], [?], [?].</code></p>\n<p>My formal parameter for <code>start_tensors</code> when instantiating a <code>OutputInferenceHelper</code> object has shape [128, 4], but beyond that, I'm lost.</p>\n<p>My Traceback:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 671, in _call_cpp_shape_fn_impl\n    input_tensors_as_shapes, status)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\", line 89, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  &lt;my function calls&gt;\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 286, in dynamic_decode\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 242, in body\n    sequence_lengths)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2328, in where\n    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2145, in _select\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\n    debug_python_shape_fn, require_shape_fn)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Shapes must be equal rank, but are 1 and 2 for 'add_inference/add_decoder/decoder/while/Select' (op: 'Select') with input shapes: [128,4], [?], [?].\n\n</code></pre>", "body_text": "I'm trying to implement my suggestion, but I'm running into an error that I'm unsure of how to debug.\nMy code:\nclass OutputInferenceHelper(Helper):\n\n    def __init__(self, start_tensors, end_tensor, name=None):\n        \"\"\"Initializer.\n        \n        Args:\n          start_tensors: `float32` tensor shaped `[batch_size, ...]`, the start\n           tensors.\n          end_tensor: `float32` tensor shaped `[...]`, the tensor that marks \n           end of decoding.\n        \"\"\"\n        with ops.name_scope(name, \"OutputInferenceHelper\"):\n            self._start_tensors = ops.convert_to_tensor(\n                start_tensors, dtype=dtypes.float32, name=\"start_tensors\")\n            self._end_tensor = ops.convert_to_tensor(\n                end_tensor, dtype=dtypes.float32, name=\"end_tensor\")\n            self._batch_size = array_ops.shape(start_tensors)[0]\n\n    @property\n    def batch_size(self):\n        return self._batch_size\n\n    def initialize(self, name=None):\n        with ops.name_scope(name, \"OutputInferenceHelperInitialize\"):\n            finished = array_ops.tile([False], [self._batch_size])\n            return (finished, self._start_tensors)\n\n    def sample(self, time, outputs, state, name=None):\n        with ops.name_scope(name, \"OutputInferenceHelperSample\"):\n            del time, state\n            if not isinstance(outputs, ops.Tensor):\n                raise TypeError(\"Expected outputs to be a single Tensor, got: %s\" %\n                                type(outputs))\n            return outputs\n\n    def next_inputs(self, time, outputs, state, sample_ids, name=None):\n        with ops.name_scope(name, \"OutputInferenceHelperNextInputs\"):\n            del time, sample_ids\n            finished = math_ops.equal(outputs, self._end_tensor)\n            all_finished = math_ops.reduce_all(finished)\n            next_inputs = control_flow_ops.cond(\n                all_finished,\n                # If we're finished, the next_inputs value doesn't matter\n                lambda: self._start_tensors,\n                lambda: outputs)\n\n            return (finished, next_inputs, state)\n\nI'm receiving the following error: tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 1 and 2 for 'add_inference/add_decoder/decoder/while/Select' (op: 'Select') with input shapes: [128,4], [?], [?].\nMy formal parameter for start_tensors when instantiating a OutputInferenceHelper object has shape [128, 4], but beyond that, I'm lost.\nMy Traceback:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 671, in _call_cpp_shape_fn_impl\n    input_tensors_as_shapes, status)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\", line 89, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  <my function calls>\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 286, in dynamic_decode\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 242, in body\n    sequence_lengths)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2328, in where\n    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2145, in _select\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\n    debug_python_shape_fn, require_shape_fn)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Shapes must be equal rank, but are 1 and 2 for 'add_inference/add_decoder/decoder/while/Select' (op: 'Select') with input shapes: [128,4], [?], [?].", "body": "I'm trying to implement my suggestion, but I'm running into an error that I'm unsure of how to debug.\r\n\r\nMy code:\r\n\r\n```\r\nclass OutputInferenceHelper(Helper):\r\n\r\n    def __init__(self, start_tensors, end_tensor, name=None):\r\n        \"\"\"Initializer.\r\n        \r\n        Args:\r\n          start_tensors: `float32` tensor shaped `[batch_size, ...]`, the start\r\n           tensors.\r\n          end_tensor: `float32` tensor shaped `[...]`, the tensor that marks \r\n           end of decoding.\r\n        \"\"\"\r\n        with ops.name_scope(name, \"OutputInferenceHelper\"):\r\n            self._start_tensors = ops.convert_to_tensor(\r\n                start_tensors, dtype=dtypes.float32, name=\"start_tensors\")\r\n            self._end_tensor = ops.convert_to_tensor(\r\n                end_tensor, dtype=dtypes.float32, name=\"end_tensor\")\r\n            self._batch_size = array_ops.shape(start_tensors)[0]\r\n\r\n    @property\r\n    def batch_size(self):\r\n        return self._batch_size\r\n\r\n    def initialize(self, name=None):\r\n        with ops.name_scope(name, \"OutputInferenceHelperInitialize\"):\r\n            finished = array_ops.tile([False], [self._batch_size])\r\n            return (finished, self._start_tensors)\r\n\r\n    def sample(self, time, outputs, state, name=None):\r\n        with ops.name_scope(name, \"OutputInferenceHelperSample\"):\r\n            del time, state\r\n            if not isinstance(outputs, ops.Tensor):\r\n                raise TypeError(\"Expected outputs to be a single Tensor, got: %s\" %\r\n                                type(outputs))\r\n            return outputs\r\n\r\n    def next_inputs(self, time, outputs, state, sample_ids, name=None):\r\n        with ops.name_scope(name, \"OutputInferenceHelperNextInputs\"):\r\n            del time, sample_ids\r\n            finished = math_ops.equal(outputs, self._end_tensor)\r\n            all_finished = math_ops.reduce_all(finished)\r\n            next_inputs = control_flow_ops.cond(\r\n                all_finished,\r\n                # If we're finished, the next_inputs value doesn't matter\r\n                lambda: self._start_tensors,\r\n                lambda: outputs)\r\n\r\n            return (finished, next_inputs, state)\r\n```\r\n\r\nI'm receiving the following error: `tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 1 and 2 for 'add_inference/add_decoder/decoder/while/Select' (op: 'Select') with input shapes: [128,4], [?], [?].`\r\n\r\nMy formal parameter for `start_tensors` when instantiating a `OutputInferenceHelper` object has shape [128, 4], but beyond that, I'm lost.\r\n\r\nMy Traceback:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 671, in _call_cpp_shape_fn_impl\r\n    input_tensors_as_shapes, status)\r\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  <my function calls>\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 286, in dynamic_decode\r\n    swap_memory=swap_memory)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 242, in body\r\n    sequence_lengths)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2328, in where\r\n    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2145, in _select\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: Shapes must be equal rank, but are 1 and 2 for 'add_inference/add_decoder/decoder/while/Select' (op: 'Select') with input shapes: [128,4], [?], [?].\r\n\r\n```"}