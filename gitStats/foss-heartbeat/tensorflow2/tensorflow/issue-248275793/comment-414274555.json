{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/414274555", "html_url": "https://github.com/tensorflow/tensorflow/issues/12065#issuecomment-414274555", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12065", "id": 414274555, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNDI3NDU1NQ==", "user": {"login": "Andreea-G", "id": 8748158, "node_id": "MDQ6VXNlcjg3NDgxNTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/8748158?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Andreea-G", "html_url": "https://github.com/Andreea-G", "followers_url": "https://api.github.com/users/Andreea-G/followers", "following_url": "https://api.github.com/users/Andreea-G/following{/other_user}", "gists_url": "https://api.github.com/users/Andreea-G/gists{/gist_id}", "starred_url": "https://api.github.com/users/Andreea-G/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Andreea-G/subscriptions", "organizations_url": "https://api.github.com/users/Andreea-G/orgs", "repos_url": "https://api.github.com/users/Andreea-G/repos", "events_url": "https://api.github.com/users/Andreea-G/events{/privacy}", "received_events_url": "https://api.github.com/users/Andreea-G/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-20T10:45:27Z", "updated_at": "2018-08-20T10:45:27Z", "author_association": "NONE", "body_html": "<p>I got it to work for no embedding in a much simpler way, using a very rudimentary <code>InferenceHelper</code>:</p>\n<pre><code>inference_helper = tf.contrib.seq2seq.InferenceHelper(\n            sample_fn=lambda outputs: outputs,\n            sample_shape=[dim],\n            sample_dtype=dtypes.float32,\n            start_inputs=start_tokens,\n            end_fn=lambda sample_ids: False)\n</code></pre>\n<p>My inputs are floats with the shape <code>[batch_size, time, dim]</code>. For the example above with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10939319\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/MrfksIv\">@MrfksIv</a> 's plot, <code>dim</code> would be 1, but this can easily be extended to more dimensions.  Here's the relevant chunk of the code:</p>\n<pre><code># Dense layer to translate the decoder's output at each time\n# step.\nprojection_layer = tf.layers.Dense(\n    units=1,  # = dim\n    kernel_initializer=tf.truncated_normal_initializer(\n        mean=0.0, stddev=0.1))\n\n# Training Decoder\ntraining_decoder_output = None\nwith tf.variable_scope(\"decode\"):\n    # output_data doesn't exist during prediction phase.\n    if output_data is not None:\n        # Prepend the \"go\" token\n        go_tokens = tf.constant(go_token, shape=[batch_size, 1, 1])\n        dec_input = tf.concat([go_tokens, target_data], axis=1)\n\n        # Helper for the training process.\n        training_helper = tf.contrib.seq2seq.TrainingHelper(\n            inputs=dec_input,\n            sequence_length=[output_size] * batch_size)\n\n        # Basic decoder\n        training_decoder = tf.contrib.seq2seq.BasicDecoder(\n            dec_cell,  training_helper, enc_state, projection_layer)\n\n        # Perform dynamic decoding using the decoder\n        training_decoder_output = tf.contrib.seq2seq.dynamic_decode(\n            training_decoder, impute_finished=True,\n            maximum_iterations=output_size)[0]\n\n# Inference Decoder\n# Reuses the same parameters trained by the training process.\nwith tf.variable_scope(\"decode\", reuse=tf.AUTO_REUSE):\n    start_tokens = tf.constant(\n        go_token, shape=[batch_size, 1])\n\n    # The sample_ids are the actual output in this case (not dealing with any logits here).\n    # My end_fn is always False because I'm working with a generator that will stop giving \n    # more data. You may extend the end_fn as you wish. E.g. you can append end_tokens \n    # and make end_fn be true when the sample_id is the end token.\n    inference_helper = tf.contrib.seq2seq.InferenceHelper(\n        sample_fn=lambda outputs: outputs,\n        sample_shape=[1],  # again because dim=1\n        sample_dtype=dtypes.float32,\n        start_inputs=start_tokens,\n        end_fn=lambda sample_ids: False)\n\n    # Basic decoder\n    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n        inference_helper, enc_state, projection_layer)\n\n    # Perform dynamic decoding using the decoder\n    inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(\n        inference_decoder, impute_finished=True,\n        maximum_iterations=output_size)[0]\n</code></pre>", "body_text": "I got it to work for no embedding in a much simpler way, using a very rudimentary InferenceHelper:\ninference_helper = tf.contrib.seq2seq.InferenceHelper(\n            sample_fn=lambda outputs: outputs,\n            sample_shape=[dim],\n            sample_dtype=dtypes.float32,\n            start_inputs=start_tokens,\n            end_fn=lambda sample_ids: False)\n\nMy inputs are floats with the shape [batch_size, time, dim]. For the example above with @MrfksIv 's plot, dim would be 1, but this can easily be extended to more dimensions.  Here's the relevant chunk of the code:\n# Dense layer to translate the decoder's output at each time\n# step.\nprojection_layer = tf.layers.Dense(\n    units=1,  # = dim\n    kernel_initializer=tf.truncated_normal_initializer(\n        mean=0.0, stddev=0.1))\n\n# Training Decoder\ntraining_decoder_output = None\nwith tf.variable_scope(\"decode\"):\n    # output_data doesn't exist during prediction phase.\n    if output_data is not None:\n        # Prepend the \"go\" token\n        go_tokens = tf.constant(go_token, shape=[batch_size, 1, 1])\n        dec_input = tf.concat([go_tokens, target_data], axis=1)\n\n        # Helper for the training process.\n        training_helper = tf.contrib.seq2seq.TrainingHelper(\n            inputs=dec_input,\n            sequence_length=[output_size] * batch_size)\n\n        # Basic decoder\n        training_decoder = tf.contrib.seq2seq.BasicDecoder(\n            dec_cell,  training_helper, enc_state, projection_layer)\n\n        # Perform dynamic decoding using the decoder\n        training_decoder_output = tf.contrib.seq2seq.dynamic_decode(\n            training_decoder, impute_finished=True,\n            maximum_iterations=output_size)[0]\n\n# Inference Decoder\n# Reuses the same parameters trained by the training process.\nwith tf.variable_scope(\"decode\", reuse=tf.AUTO_REUSE):\n    start_tokens = tf.constant(\n        go_token, shape=[batch_size, 1])\n\n    # The sample_ids are the actual output in this case (not dealing with any logits here).\n    # My end_fn is always False because I'm working with a generator that will stop giving \n    # more data. You may extend the end_fn as you wish. E.g. you can append end_tokens \n    # and make end_fn be true when the sample_id is the end token.\n    inference_helper = tf.contrib.seq2seq.InferenceHelper(\n        sample_fn=lambda outputs: outputs,\n        sample_shape=[1],  # again because dim=1\n        sample_dtype=dtypes.float32,\n        start_inputs=start_tokens,\n        end_fn=lambda sample_ids: False)\n\n    # Basic decoder\n    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n        inference_helper, enc_state, projection_layer)\n\n    # Perform dynamic decoding using the decoder\n    inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(\n        inference_decoder, impute_finished=True,\n        maximum_iterations=output_size)[0]", "body": "I got it to work for no embedding in a much simpler way, using a very rudimentary `InferenceHelper`:\r\n\r\n```\r\ninference_helper = tf.contrib.seq2seq.InferenceHelper(\r\n            sample_fn=lambda outputs: outputs,\r\n            sample_shape=[dim],\r\n            sample_dtype=dtypes.float32,\r\n            start_inputs=start_tokens,\r\n            end_fn=lambda sample_ids: False)\r\n```\r\n\r\nMy inputs are floats with the shape `[batch_size, time, dim]`. For the example above with @MrfksIv 's plot, `dim` would be 1, but this can easily be extended to more dimensions.  Here's the relevant chunk of the code:\r\n\r\n```\r\n# Dense layer to translate the decoder's output at each time\r\n# step.\r\nprojection_layer = tf.layers.Dense(\r\n    units=1,  # = dim\r\n    kernel_initializer=tf.truncated_normal_initializer(\r\n        mean=0.0, stddev=0.1))\r\n\r\n# Training Decoder\r\ntraining_decoder_output = None\r\nwith tf.variable_scope(\"decode\"):\r\n    # output_data doesn't exist during prediction phase.\r\n    if output_data is not None:\r\n        # Prepend the \"go\" token\r\n        go_tokens = tf.constant(go_token, shape=[batch_size, 1, 1])\r\n        dec_input = tf.concat([go_tokens, target_data], axis=1)\r\n\r\n        # Helper for the training process.\r\n        training_helper = tf.contrib.seq2seq.TrainingHelper(\r\n            inputs=dec_input,\r\n            sequence_length=[output_size] * batch_size)\r\n\r\n        # Basic decoder\r\n        training_decoder = tf.contrib.seq2seq.BasicDecoder(\r\n            dec_cell,  training_helper, enc_state, projection_layer)\r\n\r\n        # Perform dynamic decoding using the decoder\r\n        training_decoder_output = tf.contrib.seq2seq.dynamic_decode(\r\n            training_decoder, impute_finished=True,\r\n            maximum_iterations=output_size)[0]\r\n\r\n# Inference Decoder\r\n# Reuses the same parameters trained by the training process.\r\nwith tf.variable_scope(\"decode\", reuse=tf.AUTO_REUSE):\r\n    start_tokens = tf.constant(\r\n        go_token, shape=[batch_size, 1])\r\n\r\n    # The sample_ids are the actual output in this case (not dealing with any logits here).\r\n    # My end_fn is always False because I'm working with a generator that will stop giving \r\n    # more data. You may extend the end_fn as you wish. E.g. you can append end_tokens \r\n    # and make end_fn be true when the sample_id is the end token.\r\n    inference_helper = tf.contrib.seq2seq.InferenceHelper(\r\n        sample_fn=lambda outputs: outputs,\r\n        sample_shape=[1],  # again because dim=1\r\n        sample_dtype=dtypes.float32,\r\n        start_inputs=start_tokens,\r\n        end_fn=lambda sample_ids: False)\r\n\r\n    # Basic decoder\r\n    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\r\n        inference_helper, enc_state, projection_layer)\r\n\r\n    # Perform dynamic decoding using the decoder\r\n    inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(\r\n        inference_decoder, impute_finished=True,\r\n        maximum_iterations=output_size)[0]\r\n```"}