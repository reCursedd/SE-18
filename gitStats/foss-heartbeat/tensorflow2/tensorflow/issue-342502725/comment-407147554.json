{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/407147554", "html_url": "https://github.com/tensorflow/tensorflow/issues/20942#issuecomment-407147554", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20942", "id": 407147554, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzE0NzU1NA==", "user": {"login": "kevintrankt", "id": 17175069, "node_id": "MDQ6VXNlcjE3MTc1MDY5", "avatar_url": "https://avatars3.githubusercontent.com/u/17175069?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevintrankt", "html_url": "https://github.com/kevintrankt", "followers_url": "https://api.github.com/users/kevintrankt/followers", "following_url": "https://api.github.com/users/kevintrankt/following{/other_user}", "gists_url": "https://api.github.com/users/kevintrankt/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevintrankt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevintrankt/subscriptions", "organizations_url": "https://api.github.com/users/kevintrankt/orgs", "repos_url": "https://api.github.com/users/kevintrankt/repos", "events_url": "https://api.github.com/users/kevintrankt/events{/privacy}", "received_events_url": "https://api.github.com/users/kevintrankt/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-23T18:00:47Z", "updated_at": "2018-07-23T18:00:47Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> I was able to implement the KMeans training using tensorflow operators</p>\n<p>`class KmeansTensorflow:<br>\ndef <strong>init</strong>(self, input_matrix, num_clusters):<br>\nself._input = input_matrix.todense()<br>\nself._num_clusters = num_clusters</p>\n<pre><code>def train(self):\n    k = self._num_clusters\n    # centroid initialization\n    start_pos = tf.Variable(self._input[np.random.randint(self._input.shape[0], size=k), :],\n                            dtype=tf.float32)\n    centroids = tf.Variable(start_pos.initialized_value(), 'S', dtype=tf.float32)\n\n    # populate points\n    points = tf.Variable(self._input, 'X', dtype=tf.float32)\n    ones_like = tf.ones((points.get_shape()[0], 1))\n    prev_assignments = tf.Variable(tf.zeros((points.get_shape()[0],), dtype=tf.int64))\n\n    # distance function\n    p1 = tf.matmul(\n        tf.expand_dims(tf.reduce_sum(tf.square(points), 1), 1),\n        tf.ones(shape=(1, k))\n    )\n    p2 = tf.transpose(tf.matmul(\n        tf.reshape(tf.reduce_sum(tf.square(centroids), 1), shape=[-1, 1]),\n        ones_like,\n        transpose_b=True\n    ))\n    distance = tf.sqrt(tf.add(p1, p2) - 2 * tf.matmul(points, centroids, transpose_b=True))\n\n    # assign each point to a closest centroid\n    point_to_centroid_assignment = tf.argmin(distance, axis=1)\n\n    # recalculate the centroid (mean)\n    total = tf.unsorted_segment_sum(points, point_to_centroid_assignment, k)\n    count = tf.unsorted_segment_sum(ones_like, point_to_centroid_assignment, k)\n    means = total / count\n\n    # continue if there is any delta\n    is_continue = tf.reduce_any(tf.not_equal(point_to_centroid_assignment, prev_assignments))\n\n    with tf.control_dependencies([is_continue]):\n        loop = tf.group(centroids.assign(means), prev_assignments.assign(point_to_centroid_assignment))\n\n    sess = tf.Session()\n    sess.run(tf.global_variables_initializer())\n\n    # 1000 iterations or no delta\n    has_changed, cnt = True, 0\n    while has_changed and cnt &lt; 1000:\n        cnt += 1\n        has_changed, _ = sess.run([is_continue, loop])\n    # see how the data is assigned\n    res = sess.run(point_to_centroid_assignment)\n    print(list(res))\n</code></pre>\n<p>`</p>\n<p>But I have been having trouble with making a prediction method. That's why I thought about using tf.contrib.factorization.KmeansClustering</p>", "body_text": "@drpngx I was able to implement the KMeans training using tensorflow operators\n`class KmeansTensorflow:\ndef init(self, input_matrix, num_clusters):\nself._input = input_matrix.todense()\nself._num_clusters = num_clusters\ndef train(self):\n    k = self._num_clusters\n    # centroid initialization\n    start_pos = tf.Variable(self._input[np.random.randint(self._input.shape[0], size=k), :],\n                            dtype=tf.float32)\n    centroids = tf.Variable(start_pos.initialized_value(), 'S', dtype=tf.float32)\n\n    # populate points\n    points = tf.Variable(self._input, 'X', dtype=tf.float32)\n    ones_like = tf.ones((points.get_shape()[0], 1))\n    prev_assignments = tf.Variable(tf.zeros((points.get_shape()[0],), dtype=tf.int64))\n\n    # distance function\n    p1 = tf.matmul(\n        tf.expand_dims(tf.reduce_sum(tf.square(points), 1), 1),\n        tf.ones(shape=(1, k))\n    )\n    p2 = tf.transpose(tf.matmul(\n        tf.reshape(tf.reduce_sum(tf.square(centroids), 1), shape=[-1, 1]),\n        ones_like,\n        transpose_b=True\n    ))\n    distance = tf.sqrt(tf.add(p1, p2) - 2 * tf.matmul(points, centroids, transpose_b=True))\n\n    # assign each point to a closest centroid\n    point_to_centroid_assignment = tf.argmin(distance, axis=1)\n\n    # recalculate the centroid (mean)\n    total = tf.unsorted_segment_sum(points, point_to_centroid_assignment, k)\n    count = tf.unsorted_segment_sum(ones_like, point_to_centroid_assignment, k)\n    means = total / count\n\n    # continue if there is any delta\n    is_continue = tf.reduce_any(tf.not_equal(point_to_centroid_assignment, prev_assignments))\n\n    with tf.control_dependencies([is_continue]):\n        loop = tf.group(centroids.assign(means), prev_assignments.assign(point_to_centroid_assignment))\n\n    sess = tf.Session()\n    sess.run(tf.global_variables_initializer())\n\n    # 1000 iterations or no delta\n    has_changed, cnt = True, 0\n    while has_changed and cnt < 1000:\n        cnt += 1\n        has_changed, _ = sess.run([is_continue, loop])\n    # see how the data is assigned\n    res = sess.run(point_to_centroid_assignment)\n    print(list(res))\n\n`\nBut I have been having trouble with making a prediction method. That's why I thought about using tf.contrib.factorization.KmeansClustering", "body": "@drpngx I was able to implement the KMeans training using tensorflow operators\r\n\r\n`class KmeansTensorflow:\r\n    def __init__(self, input_matrix, num_clusters):\r\n        self._input = input_matrix.todense()\r\n        self._num_clusters = num_clusters\r\n\r\n    def train(self):\r\n        k = self._num_clusters\r\n        # centroid initialization\r\n        start_pos = tf.Variable(self._input[np.random.randint(self._input.shape[0], size=k), :],\r\n                                dtype=tf.float32)\r\n        centroids = tf.Variable(start_pos.initialized_value(), 'S', dtype=tf.float32)\r\n\r\n        # populate points\r\n        points = tf.Variable(self._input, 'X', dtype=tf.float32)\r\n        ones_like = tf.ones((points.get_shape()[0], 1))\r\n        prev_assignments = tf.Variable(tf.zeros((points.get_shape()[0],), dtype=tf.int64))\r\n\r\n        # distance function\r\n        p1 = tf.matmul(\r\n            tf.expand_dims(tf.reduce_sum(tf.square(points), 1), 1),\r\n            tf.ones(shape=(1, k))\r\n        )\r\n        p2 = tf.transpose(tf.matmul(\r\n            tf.reshape(tf.reduce_sum(tf.square(centroids), 1), shape=[-1, 1]),\r\n            ones_like,\r\n            transpose_b=True\r\n        ))\r\n        distance = tf.sqrt(tf.add(p1, p2) - 2 * tf.matmul(points, centroids, transpose_b=True))\r\n\r\n        # assign each point to a closest centroid\r\n        point_to_centroid_assignment = tf.argmin(distance, axis=1)\r\n\r\n        # recalculate the centroid (mean)\r\n        total = tf.unsorted_segment_sum(points, point_to_centroid_assignment, k)\r\n        count = tf.unsorted_segment_sum(ones_like, point_to_centroid_assignment, k)\r\n        means = total / count\r\n\r\n        # continue if there is any delta\r\n        is_continue = tf.reduce_any(tf.not_equal(point_to_centroid_assignment, prev_assignments))\r\n\r\n        with tf.control_dependencies([is_continue]):\r\n            loop = tf.group(centroids.assign(means), prev_assignments.assign(point_to_centroid_assignment))\r\n\r\n        sess = tf.Session()\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n        # 1000 iterations or no delta\r\n        has_changed, cnt = True, 0\r\n        while has_changed and cnt < 1000:\r\n            cnt += 1\r\n            has_changed, _ = sess.run([is_continue, loop])\r\n        # see how the data is assigned\r\n        res = sess.run(point_to_centroid_assignment)\r\n        print(list(res))\r\n`\r\n\r\nBut I have been having trouble with making a prediction method. That's why I thought about using tf.contrib.factorization.KmeansClustering "}