{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7609", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7609/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7609/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7609/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7609", "id": 208344371, "node_id": "MDU6SXNzdWUyMDgzNDQzNzE=", "number": 7609, "title": "Maybe  a bug: Different eval step between CPU and GPU", "user": {"login": "burness", "id": 3112825, "node_id": "MDQ6VXNlcjMxMTI4MjU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3112825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/burness", "html_url": "https://github.com/burness", "followers_url": "https://api.github.com/users/burness/followers", "following_url": "https://api.github.com/users/burness/following{/other_user}", "gists_url": "https://api.github.com/users/burness/gists{/gist_id}", "starred_url": "https://api.github.com/users/burness/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/burness/subscriptions", "organizations_url": "https://api.github.com/users/burness/orgs", "repos_url": "https://api.github.com/users/burness/repos", "events_url": "https://api.github.com/users/burness/events{/privacy}", "received_events_url": "https://api.github.com/users/burness/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-17T05:57:26Z", "updated_at": "2017-02-17T23:02:48Z", "closed_at": "2017-02-17T23:02:48Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<h3>Environment info</h3>\n<p>ubuntu 14.04<br>\nInstalled version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p><code>-rw-r--r-- 1 root root   322936 Aug 16  2015 /usr/local/cuda/lib64/libcudadevrt.a lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.7.5 lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -&gt; libcudart.so.7.5.18 -rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18 -rw-r--r-- 1 root root   720192 Aug 16  2015 /usr/local/cuda/lib64/libcudart_static.a lrwxrwxrwx 1 root root       13 Oct 20 14:34 /usr/local/cuda/lib64/libcudnn.so -&gt; libcudnn.so.5 lrwxrwxrwx 1 root root       17 Oct 20 14:33 /usr/local/cuda/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.1.3 -rwxr-xr-x 1 root root 60696704 Oct 20 14:28 /usr/local/cuda/lib64/libcudnn.so.5.1.3 -rw-r--r-- 1 root root 59715990 Oct 20 14:28 /usr/local/cuda/lib64/libcudnn_static.a</code></p>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>): <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/16485a3fb5ffcbaa244e55c388e43279d2770982/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/16485a3fb5ffcbaa244e55c388e43279d2770982\"><tt>16485a3</tt></a></li>\n<li>The output of <code>bazel version</code>:<br>\n.........<br>\nBuild label: 0.4.4<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)<br>\nBuild timestamp: 1485975261<br>\nBuild timestamp as int: 1485975261</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>I'm sorry that I can't reproduce it in minimal (mnist) example(it seems to be all right), but in my code, the global_step would pulse agin in the eval stage:</p>\n<pre><code>import tensorflow as tf\nimport os\nimport random\nimport tensorflow.contrib.slim as slim\nimport time\nimport logging\nimport numpy as np\nimport pickle\nfrom PIL import Image\n\n\nlogger = logging.getLogger('Training a chinese write char recognition')\nlogger.setLevel(logging.INFO)\n# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nch = logging.StreamHandler()\nch.setLevel(logging.INFO)\nlogger.addHandler(ch)\n\n\ntf.app.flags.DEFINE_boolean('random_flip_up_down', False, \"Whether to random flip up down\")\ntf.app.flags.DEFINE_boolean('random_brightness', True, \"whether to adjust brightness\")\ntf.app.flags.DEFINE_boolean('random_contrast', True, \"whether to random constrast\")\n\ntf.app.flags.DEFINE_integer('charset_size', 120, \"Choose the first `charset_size` character to conduct our experiment.\")\ntf.app.flags.DEFINE_integer('image_size', 64, \"Needs to provide same value as in training.\")\ntf.app.flags.DEFINE_boolean('gray', True, \"whether to change the rbg to gray\")\ntf.app.flags.DEFINE_integer('max_steps', 12002, 'the max training steps ')\ntf.app.flags.DEFINE_integer('eval_steps', 50, \"the step num to eval\")\ntf.app.flags.DEFINE_integer('save_steps', 50, \"the steps to save\")\n\ntf.app.flags.DEFINE_string('checkpoint_dir', './checkpoint/', 'the checkpoint dir')\ntf.app.flags.DEFINE_string('train_data_dir', '../data/train/', 'the train dataset dir')\ntf.app.flags.DEFINE_string('test_data_dir', '../data/test/', 'the test dataset dir')\ntf.app.flags.DEFINE_string('log_dir', './log', 'the logging dir')\n\ntf.app.flags.DEFINE_boolean('restore', False, 'whether to restore from checkpoint')\ntf.app.flags.DEFINE_boolean('epoch', 1, 'Number of epoches')\ntf.app.flags.DEFINE_boolean('batch_size', 128, 'Validation batch size')\ntf.app.flags.DEFINE_string('mode', 'train', 'Running mode. One of {\"train\", \"valid\", \"test\"}')\nFLAGS = tf.app.flags.FLAGS\n\n\nclass DataIterator:\n    def __init__(self, data_dir):\n        # Set FLAGS.charset_size to a small value if available computation power is limited.\n        truncate_path = data_dir + ('%05d' % FLAGS.charset_size)\n        print(truncate_path)\n        self.image_names = []\n        for root, sub_folder, file_list in os.walk(data_dir):\n            if root &lt; truncate_path:\n                self.image_names += [os.path.join(root, file_path) for file_path in file_list]\n        random.shuffle(self.image_names)\n        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\n\n    @property\n    def size(self):\n        return len(self.labels)\n\n    @staticmethod\n    def data_augmentation(images):\n        if FLAGS.random_flip_up_down:\n            images = tf.image.random_flip_up_down(images)\n        if FLAGS.random_brightness:\n            images = tf.image.random_brightness(images, max_delta=0.3)\n        if FLAGS.random_contrast:\n            images = tf.image.random_contrast(images, 0.8, 1.2)\n        return images\n\n    def input_pipeline(self, batch_size, num_epochs=None, aug=False):\n        images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\n        labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\n        input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\n\n        labels = input_queue[1]\n        images_content = tf.read_file(input_queue[0])\n        images = tf.image.convert_image_dtype(tf.image.decode_png(images_content, channels=1), tf.float32)\n        if aug:\n            images = self.data_augmentation(images)\n        new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\n        images = tf.image.resize_images(images, new_size)\n        image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batch_size, capacity=50000,\n                                                          min_after_dequeue=10000)\n        # print 'image_batch', image_batch.get_shape()\n        return image_batch, label_batch\n\n\ndef build_graph(top_k):\n    keep_prob = tf.placeholder(dtype=tf.float32, shape=[], name='keep_prob')\n    images = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 1], name='image_batch')\n    labels = tf.placeholder(dtype=tf.int64, shape=[None], name='label_batch')\n\n    conv3_1 = slim.conv2d(images, 64, [3, 3], 1, padding='SAME', scope='conv3_1')\n    max_pool_1 = slim.max_pool2d(conv3_1, [2, 2], [2, 2], padding='SAME')\n    conv3_2 = slim.conv2d(max_pool_1, 128, [3, 3], padding='SAME', scope='conv3_2')\n    max_pool_2 = slim.max_pool2d(conv3_2, [2, 2], [2, 2], padding='SAME')\n    conv3_3 = slim.conv2d(max_pool_2, 256, [3, 3], padding='SAME', scope='conv3_3')\n    max_pool_3 = slim.max_pool2d(conv3_3, [2, 2], [2, 2], padding='SAME')\n    # conv3_4 = slim.conv2d(max_pool_3, 512, [3, 3], padding='SAME', scope='conv3_4')\n    # max_pool_4 = slim.max_pool2d(conv3_4, [2, 2], [2, 2], padding='SAME')\n\n    flatten = slim.flatten(max_pool_3)\n    fc1 = slim.fully_connected(slim.dropout(flatten, keep_prob), 1024,\n    activation_fn=tf.nn.tanh, scope='fc1')\n    logits = slim.fully_connected(slim.dropout(fc1, keep_prob), FLAGS.charset_size,activation_fn=None, scope='fc2')\n    # logits = slim.fully_connected(flatten, FLAGS.charset_size, activation_fn=None, reuse=reuse, scope='fc')\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), labels), tf.float32))\n\n    global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(0.0), trainable=False)\n    rate = tf.train.exponential_decay(2e-4, global_step, decay_steps=2000, decay_rate=0.8, staircase=True)\n    train_op = tf.train.AdamOptimizer(learning_rate=rate).minimize(loss, global_step=global_step)\n    probabilities = tf.nn.softmax(logits)\n\n    tf.summary.scalar('loss', loss)\n    tf.summary.scalar('accuracy', accuracy)\n    merged_summary_op = tf.summary.merge_all()\n    predicted_val_top_k, predicted_index_top_k = tf.nn.top_k(probabilities, k=top_k)\n    accuracy_in_top_k = tf.reduce_mean(tf.cast(tf.nn.in_top_k(probabilities, labels, top_k), tf.float32))\n\n    return {'images': images,\n            'labels': labels,\n            'keep_prob': keep_prob,\n            'top_k': top_k,\n            'global_step': global_step,\n            'train_op': train_op,\n            'loss': loss,\n            'accuracy': accuracy,\n            'accuracy_top_k': accuracy_in_top_k,\n            'merged_summary_op': merged_summary_op,\n            'predicted_distribution': probabilities,\n            'predicted_index_top_k': predicted_index_top_k,\n            'predicted_val_top_k': predicted_val_top_k}\n\n\ndef train():\n    print('Begin training')\n    train_feeder = DataIterator(data_dir='../data/train/')\n    test_feeder = DataIterator(data_dir='../data/test/')\n    with tf.Session() as sess:\n        train_images, train_labels = train_feeder.input_pipeline(batch_size=FLAGS.batch_size, aug=True)\n        test_images, test_labels = test_feeder.input_pipeline(batch_size=FLAGS.batch_size)\n        graph = build_graph(top_k=1)\n        sess.run(tf.global_variables_initializer())\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        saver = tf.train.Saver()\n\n        train_writer = tf.summary.FileWriter(FLAGS.log_dir + '/train', sess.graph)\n        test_writer = tf.summary.FileWriter(FLAGS.log_dir + '/val')\n        start_step = 0\n        if FLAGS.restore:\n            ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n            if ckpt:\n                saver.restore(sess, ckpt)\n                print(\"restore from the checkpoint {0}\".format(ckpt))\n                start_step += int(ckpt.split('-')[-1])\n\n        logger.info(':::Training Start:::')\n        try:\n            i = 0\n            while not coord.should_stop():\n                i += 1\n                start_time = time.time()\n                train_images_batch, train_labels_batch = sess.run([train_images, train_labels])\n                feed_dict = {graph['images']: train_images_batch,\n                             graph['labels']: train_labels_batch,\n                             graph['keep_prob']: 0.8}\n                _, loss_val, train_summary, step = sess.run(\n                    [graph['train_op'], graph['loss'], graph['merged_summary_op'], graph['global_step']],\n                    feed_dict=feed_dict)\n                train_writer.add_summary(train_summary, step)\n                end_time = time.time()\n                logger.info(\"the step {0} takes {1} loss {2}\".format(step, end_time - start_time, loss_val))\n                if step &gt; FLAGS.max_steps:\n                    break\n                if step % FLAGS.eval_steps == 1:\n                    test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\n                    feed_dict = {graph['images']: test_images_batch,\n                                 graph['labels']: test_labels_batch,\n                                 graph['keep_prob']: 1.0}\n                    accuracy_test, test_summary, step = sess.run(\n                        [graph['accuracy'], graph['merged_summary_op'], graph['global_step']],\n                        feed_dict=feed_dict)\n                    test_writer.add_summary(test_summary, step)\n                    logger.info('===============Eval a batch=======================')\n                    logger.info('the step {0} test accuracy: {1}'\n                                .format(step, accuracy_test))\n                    logger.info('===============Eval a batch=======================')\n\n                    for tt in range(10):\n                        _, _, step = sess.run(\n                            [graph['accuracy'], graph['merged_summary_op'], graph['global_step']],\n                            feed_dict=feed_dict)\n                        logger.info('eval step again: step = {}'.format(step))\n\n\n                if step % FLAGS.save_steps == 1:\n                    logger.info('Save the ckpt of {0}'.format(step))\n                    saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'my-model'),\n                               global_step=graph['global_step'])\n        except tf.errors.OutOfRangeError:\n            logger.info('==================Train Finished================')\n            saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'my-model'), global_step=graph['global_step'])\n        finally:\n            coord.request_stop()\n        coord.join(threads)\n\n\n\ndef main(_):\n    print(FLAGS.mode)\n    if FLAGS.mode == \"train\":\n        train()\nif __name__ == \"__main__\":\n    tf.app.run()\n\n</code></pre>\n<p>Just focus on the block after <code>if step % FLAGS.eval_steps == 1:</code>  It is all right\uff08the step shouldn't  add one\uff09 to run on CPU(add line <code>with tf.device(\"/cpu:0\")</code>  after<code>with tf.Session() as sess:</code> ) , But as show the below image, it will add one when we use GPU:<br>\nOn CPU:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/3112825/23053809/dcc5d930-f516-11e6-8797-6701370c4da3.png\"><img src=\"https://cloud.githubusercontent.com/assets/3112825/23053809/dcc5d930-f516-11e6-8797-6701370c4da3.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>On GPU:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/3112825/23053823/ee505298-f516-11e6-8b92-954b3da4d34f.png\"><img src=\"https://cloud.githubusercontent.com/assets/3112825/23053823/ee505298-f516-11e6-8b92-954b3da4d34f.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>It's very strange for me! And I try to reproduce it on MNIST but i seem to be all right both On CPU and GPU.</p>\n<p>Anyone could help me with  it ?<br>\nIf you want to run the code just download the dataset from the url <a href=\"https://pan.baidu.com/s/1o84jIrg#list/path=%2F\" rel=\"nofollow\">data download</a></p>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nEnvironment info\nubuntu 14.04\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n-rw-r--r-- 1 root root   322936 Aug 16  2015 /usr/local/cuda/lib64/libcudadevrt.a lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5 lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18 -rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18 -rw-r--r-- 1 root root   720192 Aug 16  2015 /usr/local/cuda/lib64/libcudart_static.a lrwxrwxrwx 1 root root       13 Oct 20 14:34 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5 lrwxrwxrwx 1 root root       17 Oct 20 14:33 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.3 -rwxr-xr-x 1 root root 60696704 Oct 20 14:28 /usr/local/cuda/lib64/libcudnn.so.5.1.3 -rw-r--r-- 1 root root 59715990 Oct 20 14:28 /usr/local/cuda/lib64/libcudnn_static.a\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD): 16485a3\nThe output of bazel version:\n.........\nBuild label: 0.4.4\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\nBuild timestamp: 1485975261\nBuild timestamp as int: 1485975261\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nI'm sorry that I can't reproduce it in minimal (mnist) example(it seems to be all right), but in my code, the global_step would pulse agin in the eval stage:\nimport tensorflow as tf\nimport os\nimport random\nimport tensorflow.contrib.slim as slim\nimport time\nimport logging\nimport numpy as np\nimport pickle\nfrom PIL import Image\n\n\nlogger = logging.getLogger('Training a chinese write char recognition')\nlogger.setLevel(logging.INFO)\n# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nch = logging.StreamHandler()\nch.setLevel(logging.INFO)\nlogger.addHandler(ch)\n\n\ntf.app.flags.DEFINE_boolean('random_flip_up_down', False, \"Whether to random flip up down\")\ntf.app.flags.DEFINE_boolean('random_brightness', True, \"whether to adjust brightness\")\ntf.app.flags.DEFINE_boolean('random_contrast', True, \"whether to random constrast\")\n\ntf.app.flags.DEFINE_integer('charset_size', 120, \"Choose the first `charset_size` character to conduct our experiment.\")\ntf.app.flags.DEFINE_integer('image_size', 64, \"Needs to provide same value as in training.\")\ntf.app.flags.DEFINE_boolean('gray', True, \"whether to change the rbg to gray\")\ntf.app.flags.DEFINE_integer('max_steps', 12002, 'the max training steps ')\ntf.app.flags.DEFINE_integer('eval_steps', 50, \"the step num to eval\")\ntf.app.flags.DEFINE_integer('save_steps', 50, \"the steps to save\")\n\ntf.app.flags.DEFINE_string('checkpoint_dir', './checkpoint/', 'the checkpoint dir')\ntf.app.flags.DEFINE_string('train_data_dir', '../data/train/', 'the train dataset dir')\ntf.app.flags.DEFINE_string('test_data_dir', '../data/test/', 'the test dataset dir')\ntf.app.flags.DEFINE_string('log_dir', './log', 'the logging dir')\n\ntf.app.flags.DEFINE_boolean('restore', False, 'whether to restore from checkpoint')\ntf.app.flags.DEFINE_boolean('epoch', 1, 'Number of epoches')\ntf.app.flags.DEFINE_boolean('batch_size', 128, 'Validation batch size')\ntf.app.flags.DEFINE_string('mode', 'train', 'Running mode. One of {\"train\", \"valid\", \"test\"}')\nFLAGS = tf.app.flags.FLAGS\n\n\nclass DataIterator:\n    def __init__(self, data_dir):\n        # Set FLAGS.charset_size to a small value if available computation power is limited.\n        truncate_path = data_dir + ('%05d' % FLAGS.charset_size)\n        print(truncate_path)\n        self.image_names = []\n        for root, sub_folder, file_list in os.walk(data_dir):\n            if root < truncate_path:\n                self.image_names += [os.path.join(root, file_path) for file_path in file_list]\n        random.shuffle(self.image_names)\n        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\n\n    @property\n    def size(self):\n        return len(self.labels)\n\n    @staticmethod\n    def data_augmentation(images):\n        if FLAGS.random_flip_up_down:\n            images = tf.image.random_flip_up_down(images)\n        if FLAGS.random_brightness:\n            images = tf.image.random_brightness(images, max_delta=0.3)\n        if FLAGS.random_contrast:\n            images = tf.image.random_contrast(images, 0.8, 1.2)\n        return images\n\n    def input_pipeline(self, batch_size, num_epochs=None, aug=False):\n        images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\n        labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\n        input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\n\n        labels = input_queue[1]\n        images_content = tf.read_file(input_queue[0])\n        images = tf.image.convert_image_dtype(tf.image.decode_png(images_content, channels=1), tf.float32)\n        if aug:\n            images = self.data_augmentation(images)\n        new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\n        images = tf.image.resize_images(images, new_size)\n        image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batch_size, capacity=50000,\n                                                          min_after_dequeue=10000)\n        # print 'image_batch', image_batch.get_shape()\n        return image_batch, label_batch\n\n\ndef build_graph(top_k):\n    keep_prob = tf.placeholder(dtype=tf.float32, shape=[], name='keep_prob')\n    images = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 1], name='image_batch')\n    labels = tf.placeholder(dtype=tf.int64, shape=[None], name='label_batch')\n\n    conv3_1 = slim.conv2d(images, 64, [3, 3], 1, padding='SAME', scope='conv3_1')\n    max_pool_1 = slim.max_pool2d(conv3_1, [2, 2], [2, 2], padding='SAME')\n    conv3_2 = slim.conv2d(max_pool_1, 128, [3, 3], padding='SAME', scope='conv3_2')\n    max_pool_2 = slim.max_pool2d(conv3_2, [2, 2], [2, 2], padding='SAME')\n    conv3_3 = slim.conv2d(max_pool_2, 256, [3, 3], padding='SAME', scope='conv3_3')\n    max_pool_3 = slim.max_pool2d(conv3_3, [2, 2], [2, 2], padding='SAME')\n    # conv3_4 = slim.conv2d(max_pool_3, 512, [3, 3], padding='SAME', scope='conv3_4')\n    # max_pool_4 = slim.max_pool2d(conv3_4, [2, 2], [2, 2], padding='SAME')\n\n    flatten = slim.flatten(max_pool_3)\n    fc1 = slim.fully_connected(slim.dropout(flatten, keep_prob), 1024,\n    activation_fn=tf.nn.tanh, scope='fc1')\n    logits = slim.fully_connected(slim.dropout(fc1, keep_prob), FLAGS.charset_size,activation_fn=None, scope='fc2')\n    # logits = slim.fully_connected(flatten, FLAGS.charset_size, activation_fn=None, reuse=reuse, scope='fc')\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), labels), tf.float32))\n\n    global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(0.0), trainable=False)\n    rate = tf.train.exponential_decay(2e-4, global_step, decay_steps=2000, decay_rate=0.8, staircase=True)\n    train_op = tf.train.AdamOptimizer(learning_rate=rate).minimize(loss, global_step=global_step)\n    probabilities = tf.nn.softmax(logits)\n\n    tf.summary.scalar('loss', loss)\n    tf.summary.scalar('accuracy', accuracy)\n    merged_summary_op = tf.summary.merge_all()\n    predicted_val_top_k, predicted_index_top_k = tf.nn.top_k(probabilities, k=top_k)\n    accuracy_in_top_k = tf.reduce_mean(tf.cast(tf.nn.in_top_k(probabilities, labels, top_k), tf.float32))\n\n    return {'images': images,\n            'labels': labels,\n            'keep_prob': keep_prob,\n            'top_k': top_k,\n            'global_step': global_step,\n            'train_op': train_op,\n            'loss': loss,\n            'accuracy': accuracy,\n            'accuracy_top_k': accuracy_in_top_k,\n            'merged_summary_op': merged_summary_op,\n            'predicted_distribution': probabilities,\n            'predicted_index_top_k': predicted_index_top_k,\n            'predicted_val_top_k': predicted_val_top_k}\n\n\ndef train():\n    print('Begin training')\n    train_feeder = DataIterator(data_dir='../data/train/')\n    test_feeder = DataIterator(data_dir='../data/test/')\n    with tf.Session() as sess:\n        train_images, train_labels = train_feeder.input_pipeline(batch_size=FLAGS.batch_size, aug=True)\n        test_images, test_labels = test_feeder.input_pipeline(batch_size=FLAGS.batch_size)\n        graph = build_graph(top_k=1)\n        sess.run(tf.global_variables_initializer())\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        saver = tf.train.Saver()\n\n        train_writer = tf.summary.FileWriter(FLAGS.log_dir + '/train', sess.graph)\n        test_writer = tf.summary.FileWriter(FLAGS.log_dir + '/val')\n        start_step = 0\n        if FLAGS.restore:\n            ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n            if ckpt:\n                saver.restore(sess, ckpt)\n                print(\"restore from the checkpoint {0}\".format(ckpt))\n                start_step += int(ckpt.split('-')[-1])\n\n        logger.info(':::Training Start:::')\n        try:\n            i = 0\n            while not coord.should_stop():\n                i += 1\n                start_time = time.time()\n                train_images_batch, train_labels_batch = sess.run([train_images, train_labels])\n                feed_dict = {graph['images']: train_images_batch,\n                             graph['labels']: train_labels_batch,\n                             graph['keep_prob']: 0.8}\n                _, loss_val, train_summary, step = sess.run(\n                    [graph['train_op'], graph['loss'], graph['merged_summary_op'], graph['global_step']],\n                    feed_dict=feed_dict)\n                train_writer.add_summary(train_summary, step)\n                end_time = time.time()\n                logger.info(\"the step {0} takes {1} loss {2}\".format(step, end_time - start_time, loss_val))\n                if step > FLAGS.max_steps:\n                    break\n                if step % FLAGS.eval_steps == 1:\n                    test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\n                    feed_dict = {graph['images']: test_images_batch,\n                                 graph['labels']: test_labels_batch,\n                                 graph['keep_prob']: 1.0}\n                    accuracy_test, test_summary, step = sess.run(\n                        [graph['accuracy'], graph['merged_summary_op'], graph['global_step']],\n                        feed_dict=feed_dict)\n                    test_writer.add_summary(test_summary, step)\n                    logger.info('===============Eval a batch=======================')\n                    logger.info('the step {0} test accuracy: {1}'\n                                .format(step, accuracy_test))\n                    logger.info('===============Eval a batch=======================')\n\n                    for tt in range(10):\n                        _, _, step = sess.run(\n                            [graph['accuracy'], graph['merged_summary_op'], graph['global_step']],\n                            feed_dict=feed_dict)\n                        logger.info('eval step again: step = {}'.format(step))\n\n\n                if step % FLAGS.save_steps == 1:\n                    logger.info('Save the ckpt of {0}'.format(step))\n                    saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'my-model'),\n                               global_step=graph['global_step'])\n        except tf.errors.OutOfRangeError:\n            logger.info('==================Train Finished================')\n            saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'my-model'), global_step=graph['global_step'])\n        finally:\n            coord.request_stop()\n        coord.join(threads)\n\n\n\ndef main(_):\n    print(FLAGS.mode)\n    if FLAGS.mode == \"train\":\n        train()\nif __name__ == \"__main__\":\n    tf.app.run()\n\n\nJust focus on the block after if step % FLAGS.eval_steps == 1:  It is all right\uff08the step shouldn't  add one\uff09 to run on CPU(add line with tf.device(\"/cpu:0\")  afterwith tf.Session() as sess: ) , But as show the below image, it will add one when we use GPU:\nOn CPU:\n\nOn GPU:\n\nIt's very strange for me! And I try to reproduce it on MNIST but i seem to be all right both On CPU and GPU.\nAnyone could help me with  it ?\nIf you want to run the code just download the dataset from the url data download", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nubuntu 14.04\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n`-rw-r--r-- 1 root root   322936 Aug 16  2015 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\r\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\r\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\r\n-rw-r--r-- 1 root root   720192 Aug 16  2015 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Oct 20 14:34 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Oct 20 14:33 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.3\r\n-rwxr-xr-x 1 root root 60696704 Oct 20 14:28 /usr/local/cuda/lib64/libcudnn.so.5.1.3\r\n-rw-r--r-- 1 root root 59715990 Oct 20 14:28 /usr/local/cuda/lib64/libcudnn_static.a`\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`): 16485a3fb5ffcbaa244e55c388e43279d2770982\r\n2. The output of `bazel version`: \r\n.........\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nI'm sorry that I can't reproduce it in minimal (mnist) example(it seems to be all right), but in my code, the global_step would pulse agin in the eval stage:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nimport random\r\nimport tensorflow.contrib.slim as slim\r\nimport time\r\nimport logging\r\nimport numpy as np\r\nimport pickle\r\nfrom PIL import Image\r\n\r\n\r\nlogger = logging.getLogger('Training a chinese write char recognition')\r\nlogger.setLevel(logging.INFO)\r\n# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\r\nch = logging.StreamHandler()\r\nch.setLevel(logging.INFO)\r\nlogger.addHandler(ch)\r\n\r\n\r\ntf.app.flags.DEFINE_boolean('random_flip_up_down', False, \"Whether to random flip up down\")\r\ntf.app.flags.DEFINE_boolean('random_brightness', True, \"whether to adjust brightness\")\r\ntf.app.flags.DEFINE_boolean('random_contrast', True, \"whether to random constrast\")\r\n\r\ntf.app.flags.DEFINE_integer('charset_size', 120, \"Choose the first `charset_size` character to conduct our experiment.\")\r\ntf.app.flags.DEFINE_integer('image_size', 64, \"Needs to provide same value as in training.\")\r\ntf.app.flags.DEFINE_boolean('gray', True, \"whether to change the rbg to gray\")\r\ntf.app.flags.DEFINE_integer('max_steps', 12002, 'the max training steps ')\r\ntf.app.flags.DEFINE_integer('eval_steps', 50, \"the step num to eval\")\r\ntf.app.flags.DEFINE_integer('save_steps', 50, \"the steps to save\")\r\n\r\ntf.app.flags.DEFINE_string('checkpoint_dir', './checkpoint/', 'the checkpoint dir')\r\ntf.app.flags.DEFINE_string('train_data_dir', '../data/train/', 'the train dataset dir')\r\ntf.app.flags.DEFINE_string('test_data_dir', '../data/test/', 'the test dataset dir')\r\ntf.app.flags.DEFINE_string('log_dir', './log', 'the logging dir')\r\n\r\ntf.app.flags.DEFINE_boolean('restore', False, 'whether to restore from checkpoint')\r\ntf.app.flags.DEFINE_boolean('epoch', 1, 'Number of epoches')\r\ntf.app.flags.DEFINE_boolean('batch_size', 128, 'Validation batch size')\r\ntf.app.flags.DEFINE_string('mode', 'train', 'Running mode. One of {\"train\", \"valid\", \"test\"}')\r\nFLAGS = tf.app.flags.FLAGS\r\n\r\n\r\nclass DataIterator:\r\n    def __init__(self, data_dir):\r\n        # Set FLAGS.charset_size to a small value if available computation power is limited.\r\n        truncate_path = data_dir + ('%05d' % FLAGS.charset_size)\r\n        print(truncate_path)\r\n        self.image_names = []\r\n        for root, sub_folder, file_list in os.walk(data_dir):\r\n            if root < truncate_path:\r\n                self.image_names += [os.path.join(root, file_path) for file_path in file_list]\r\n        random.shuffle(self.image_names)\r\n        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\r\n\r\n    @property\r\n    def size(self):\r\n        return len(self.labels)\r\n\r\n    @staticmethod\r\n    def data_augmentation(images):\r\n        if FLAGS.random_flip_up_down:\r\n            images = tf.image.random_flip_up_down(images)\r\n        if FLAGS.random_brightness:\r\n            images = tf.image.random_brightness(images, max_delta=0.3)\r\n        if FLAGS.random_contrast:\r\n            images = tf.image.random_contrast(images, 0.8, 1.2)\r\n        return images\r\n\r\n    def input_pipeline(self, batch_size, num_epochs=None, aug=False):\r\n        images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\r\n        labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\r\n        input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\r\n\r\n        labels = input_queue[1]\r\n        images_content = tf.read_file(input_queue[0])\r\n        images = tf.image.convert_image_dtype(tf.image.decode_png(images_content, channels=1), tf.float32)\r\n        if aug:\r\n            images = self.data_augmentation(images)\r\n        new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\r\n        images = tf.image.resize_images(images, new_size)\r\n        image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batch_size, capacity=50000,\r\n                                                          min_after_dequeue=10000)\r\n        # print 'image_batch', image_batch.get_shape()\r\n        return image_batch, label_batch\r\n\r\n\r\ndef build_graph(top_k):\r\n    keep_prob = tf.placeholder(dtype=tf.float32, shape=[], name='keep_prob')\r\n    images = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 1], name='image_batch')\r\n    labels = tf.placeholder(dtype=tf.int64, shape=[None], name='label_batch')\r\n\r\n    conv3_1 = slim.conv2d(images, 64, [3, 3], 1, padding='SAME', scope='conv3_1')\r\n    max_pool_1 = slim.max_pool2d(conv3_1, [2, 2], [2, 2], padding='SAME')\r\n    conv3_2 = slim.conv2d(max_pool_1, 128, [3, 3], padding='SAME', scope='conv3_2')\r\n    max_pool_2 = slim.max_pool2d(conv3_2, [2, 2], [2, 2], padding='SAME')\r\n    conv3_3 = slim.conv2d(max_pool_2, 256, [3, 3], padding='SAME', scope='conv3_3')\r\n    max_pool_3 = slim.max_pool2d(conv3_3, [2, 2], [2, 2], padding='SAME')\r\n    # conv3_4 = slim.conv2d(max_pool_3, 512, [3, 3], padding='SAME', scope='conv3_4')\r\n    # max_pool_4 = slim.max_pool2d(conv3_4, [2, 2], [2, 2], padding='SAME')\r\n\r\n    flatten = slim.flatten(max_pool_3)\r\n    fc1 = slim.fully_connected(slim.dropout(flatten, keep_prob), 1024,\r\n    activation_fn=tf.nn.tanh, scope='fc1')\r\n    logits = slim.fully_connected(slim.dropout(fc1, keep_prob), FLAGS.charset_size,activation_fn=None, scope='fc2')\r\n    # logits = slim.fully_connected(flatten, FLAGS.charset_size, activation_fn=None, reuse=reuse, scope='fc')\r\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\r\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), labels), tf.float32))\r\n\r\n    global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(0.0), trainable=False)\r\n    rate = tf.train.exponential_decay(2e-4, global_step, decay_steps=2000, decay_rate=0.8, staircase=True)\r\n    train_op = tf.train.AdamOptimizer(learning_rate=rate).minimize(loss, global_step=global_step)\r\n    probabilities = tf.nn.softmax(logits)\r\n\r\n    tf.summary.scalar('loss', loss)\r\n    tf.summary.scalar('accuracy', accuracy)\r\n    merged_summary_op = tf.summary.merge_all()\r\n    predicted_val_top_k, predicted_index_top_k = tf.nn.top_k(probabilities, k=top_k)\r\n    accuracy_in_top_k = tf.reduce_mean(tf.cast(tf.nn.in_top_k(probabilities, labels, top_k), tf.float32))\r\n\r\n    return {'images': images,\r\n            'labels': labels,\r\n            'keep_prob': keep_prob,\r\n            'top_k': top_k,\r\n            'global_step': global_step,\r\n            'train_op': train_op,\r\n            'loss': loss,\r\n            'accuracy': accuracy,\r\n            'accuracy_top_k': accuracy_in_top_k,\r\n            'merged_summary_op': merged_summary_op,\r\n            'predicted_distribution': probabilities,\r\n            'predicted_index_top_k': predicted_index_top_k,\r\n            'predicted_val_top_k': predicted_val_top_k}\r\n\r\n\r\ndef train():\r\n    print('Begin training')\r\n    train_feeder = DataIterator(data_dir='../data/train/')\r\n    test_feeder = DataIterator(data_dir='../data/test/')\r\n    with tf.Session() as sess:\r\n        train_images, train_labels = train_feeder.input_pipeline(batch_size=FLAGS.batch_size, aug=True)\r\n        test_images, test_labels = test_feeder.input_pipeline(batch_size=FLAGS.batch_size)\r\n        graph = build_graph(top_k=1)\r\n        sess.run(tf.global_variables_initializer())\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n        saver = tf.train.Saver()\r\n\r\n        train_writer = tf.summary.FileWriter(FLAGS.log_dir + '/train', sess.graph)\r\n        test_writer = tf.summary.FileWriter(FLAGS.log_dir + '/val')\r\n        start_step = 0\r\n        if FLAGS.restore:\r\n            ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\r\n            if ckpt:\r\n                saver.restore(sess, ckpt)\r\n                print(\"restore from the checkpoint {0}\".format(ckpt))\r\n                start_step += int(ckpt.split('-')[-1])\r\n\r\n        logger.info(':::Training Start:::')\r\n        try:\r\n            i = 0\r\n            while not coord.should_stop():\r\n                i += 1\r\n                start_time = time.time()\r\n                train_images_batch, train_labels_batch = sess.run([train_images, train_labels])\r\n                feed_dict = {graph['images']: train_images_batch,\r\n                             graph['labels']: train_labels_batch,\r\n                             graph['keep_prob']: 0.8}\r\n                _, loss_val, train_summary, step = sess.run(\r\n                    [graph['train_op'], graph['loss'], graph['merged_summary_op'], graph['global_step']],\r\n                    feed_dict=feed_dict)\r\n                train_writer.add_summary(train_summary, step)\r\n                end_time = time.time()\r\n                logger.info(\"the step {0} takes {1} loss {2}\".format(step, end_time - start_time, loss_val))\r\n                if step > FLAGS.max_steps:\r\n                    break\r\n                if step % FLAGS.eval_steps == 1:\r\n                    test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\r\n                    feed_dict = {graph['images']: test_images_batch,\r\n                                 graph['labels']: test_labels_batch,\r\n                                 graph['keep_prob']: 1.0}\r\n                    accuracy_test, test_summary, step = sess.run(\r\n                        [graph['accuracy'], graph['merged_summary_op'], graph['global_step']],\r\n                        feed_dict=feed_dict)\r\n                    test_writer.add_summary(test_summary, step)\r\n                    logger.info('===============Eval a batch=======================')\r\n                    logger.info('the step {0} test accuracy: {1}'\r\n                                .format(step, accuracy_test))\r\n                    logger.info('===============Eval a batch=======================')\r\n\r\n                    for tt in range(10):\r\n                        _, _, step = sess.run(\r\n                            [graph['accuracy'], graph['merged_summary_op'], graph['global_step']],\r\n                            feed_dict=feed_dict)\r\n                        logger.info('eval step again: step = {}'.format(step))\r\n\r\n\r\n                if step % FLAGS.save_steps == 1:\r\n                    logger.info('Save the ckpt of {0}'.format(step))\r\n                    saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'my-model'),\r\n                               global_step=graph['global_step'])\r\n        except tf.errors.OutOfRangeError:\r\n            logger.info('==================Train Finished================')\r\n            saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'my-model'), global_step=graph['global_step'])\r\n        finally:\r\n            coord.request_stop()\r\n        coord.join(threads)\r\n\r\n\r\n\r\ndef main(_):\r\n    print(FLAGS.mode)\r\n    if FLAGS.mode == \"train\":\r\n        train()\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n\r\n```\r\nJust focus on the block after `if step % FLAGS.eval_steps == 1:`  It is all right\uff08the step shouldn't  add one\uff09 to run on CPU(add line `with tf.device(\"/cpu:0\")`  after`with tf.Session() as sess:` ) , But as show the below image, it will add one when we use GPU:\r\nOn CPU:\r\n![image](https://cloud.githubusercontent.com/assets/3112825/23053809/dcc5d930-f516-11e6-8797-6701370c4da3.png)\r\n\r\nOn GPU:\r\n![image](https://cloud.githubusercontent.com/assets/3112825/23053823/ee505298-f516-11e6-8b92-954b3da4d34f.png)\r\n\r\nIt's very strange for me! And I try to reproduce it on MNIST but i seem to be all right both On CPU and GPU.\r\n\r\nAnyone could help me with  it ?\r\nIf you want to run the code just download the dataset from the url [data download](https://pan.baidu.com/s/1o84jIrg#list/path=%2F) \r\n"}