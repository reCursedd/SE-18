{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/381228653", "html_url": "https://github.com/tensorflow/tensorflow/issues/15041#issuecomment-381228653", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15041", "id": 381228653, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MTIyODY1Mw==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-13T18:50:35Z", "updated_at": "2018-04-13T18:50:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p>btw; one of the main reasons your memory is blowing up may be this line:</p>\n<div class=\"highlight highlight-source-python\"><pre>    single_output <span class=\"pl-k\">=</span> vgg_m(input_tensor[:, t, :, :, :], <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<p>transpose input_tensor to time, major, unstack it into a TensorArray, and use .read(t) on the TensorArray.  this should significantly reduce memory usage if you backprop into input_tensor.</p>", "body_text": "btw; one of the main reasons your memory is blowing up may be this line:\n    single_output = vgg_m(input_tensor[:, t, :, :, :], reuse=True)\ntranspose input_tensor to time, major, unstack it into a TensorArray, and use .read(t) on the TensorArray.  this should significantly reduce memory usage if you backprop into input_tensor.", "body": "btw; one of the main reasons your memory is blowing up may be this line:\r\n\r\n```python\r\n    single_output = vgg_m(input_tensor[:, t, :, :, :], reuse=True)\r\n```\r\n\r\ntranspose input_tensor to time, major, unstack it into a TensorArray, and use .read(t) on the TensorArray.  this should significantly reduce memory usage if you backprop into input_tensor."}