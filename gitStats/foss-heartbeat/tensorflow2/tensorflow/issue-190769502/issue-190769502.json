{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5751", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5751/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5751/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5751/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5751", "id": 190769502, "node_id": "MDU6SXNzdWUxOTA3Njk1MDI=", "number": 5751, "title": "failed sess.run error \"Cannot feed value of shape (50, 2352) for Tensor 'Placeholder:0', which has shape '(?, 784)'\"", "user": {"login": "TatsujiNakayama", "id": 11674961, "node_id": "MDQ6VXNlcjExNjc0OTYx", "avatar_url": "https://avatars1.githubusercontent.com/u/11674961?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TatsujiNakayama", "html_url": "https://github.com/TatsujiNakayama", "followers_url": "https://api.github.com/users/TatsujiNakayama/followers", "following_url": "https://api.github.com/users/TatsujiNakayama/following{/other_user}", "gists_url": "https://api.github.com/users/TatsujiNakayama/gists{/gist_id}", "starred_url": "https://api.github.com/users/TatsujiNakayama/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TatsujiNakayama/subscriptions", "organizations_url": "https://api.github.com/users/TatsujiNakayama/orgs", "repos_url": "https://api.github.com/users/TatsujiNakayama/repos", "events_url": "https://api.github.com/users/TatsujiNakayama/events{/privacy}", "received_events_url": "https://api.github.com/users/TatsujiNakayama/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-11-21T16:35:18Z", "updated_at": "2016-11-21T17:05:20Z", "closed_at": "2016-11-21T17:05:20Z", "author_association": "NONE", "body_html": "<p>Hi<br>\nPlease Help me...<br>\nI learning to tensorflow using my own data based on tutorial expert.<br>\nfollowing my code:</p>\n<pre><code>#datasets define\nNUM_CLASSES = 65535\nIMAGE_SIZE = 28\nIMAGE_PIXELS = IMAGE_SIZE*IMAGE_SIZE*1\n</code></pre>\n<pre><code>#read datasets\n    with open(FLAGS.train, 'r') as f: # train.txt\n        train_image = []\n        train_label = []\n        num = 0\n        for line in f:\n            if num == 500:\n                break\n            line = line.rstrip()\n            l = line.split(',')\n            print(l[0])\n            img = cv2.imread(l[0])\n            img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n            train_image.append(img.flatten().astype(np.float32)/255.0)\n            tmp = np.zeros(NUM_CLASSES)\n            tmp[int(l[1])] = 1\n            train_label.append(tmp)\n            num += 1\n        train_image = np.asarray(train_image)\n        train_label = np.asarray(train_label)\n        train_len = len(train_image)\n</code></pre>\n<pre><code>def inference(images_placeholder, keep_prob):\n    def weight_variable(shape):\n        initial = tf.truncated_normal(shape, stddev=0.1)\n        return tf.Variable(initial)\n    def bias_variable(shape):\n        initial = tf.constant(0.1, shape=shape)\n        return tf.Variable(initial)\n    def conv2d(x, W):\n        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n    def max_pool_2x2(x):\n        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                              strides=[1, 2, 2, 1], padding='SAME')\n    x_images = tf.reshape(images_placeholder, [-1, IMAGE_SIZE, IMAGE_SIZE, 1])\n    with tf.name_scope('conv1') as scope:\n        W_conv1 = weight_variable([5, 5, 1, 32])\n        b_conv1 = bias_variable([32])\n        h_conv1 = tf.nn.relu(conv2d(x_images, W_conv1) + b_conv1)\n    with tf.name_scope('pool1') as scope:\n        h_pool1 = max_pool_2x2(h_conv1)\n    with tf.name_scope('conv2') as scope:\n        W_conv2 = weight_variable([5, 5, 32, 64])\n        b_conv2 = bias_variable([64])\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n    with tf.name_scope('pool2') as scope:\n        h_pool2 = max_pool_2x2(h_conv2)\n    with tf.name_scope('fc1') as scope:\n        W_fc1 = weight_variable([7*7*64, 1024])\n        b_fc1 = bias_variable([1024])\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n    with tf.name_scope('fc2') as scope:\n        W_fc2 = weight_variable([1024, NUM_CLASSES])\n        b_fc2 = bias_variable([NUM_CLASSES])\n    with tf.name_scope('softmax') as scope:\n        y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n    return y_conv\n</code></pre>\n<pre><code>#learn\n    with tf.Graph().as_default():\n        images_placeholder = tf.placeholder(\"float\", shape=(None, IMAGE_PIXELS))\n        labels_placeholder = tf.placeholder(\"float\", shape=(None, NUM_CLASSES))\n        keep_prob = tf.placeholder(\"float\")\n        \n        logits = inference(images_placeholder, keep_prob)\n        loss_value = loss(logits, labels_placeholder)\n        train_op = training(loss_value, FLAGS.learning_rate)\n        print(\"train_op =\", train_op)\n\n        acc = accuracy(logits, labels_placeholder)\n        \n        saver = tf.train.Saver()\n        sess = tf.Session()\n        sess.run(tf.initialize_all_variables())\n        summary_op = tf.merge_all_summaries()\n        summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph_def)\n        \n        if train_len % FLAGS.batch_size is 0:\n            train_batch = train_len/FLAGS.batch_size\n        else:\n            train_batch = (train_len/FLAGS.batch_size)+1\n        print(\"train_batch = %d\",str(train_batch))\n        for step in range(FLAGS.max_steps):\n            for i in range(int(train_batch)):\n                batch = FLAGS.batch_size*i\n                batch_plus = FLAGS.batch_size*(i+1)\n                print(\"batch_plus =\", batch_plus)\n                if batch_plus &gt; train_len: batch_plus = train_len\n                sess.run(train_op, feed_dict={\n                         images_placeholder: train_image[batch:batch_plus],\n                         labels_placeholder: train_label[batch:batch_plus],\n                         keep_prob: 0.5})\n            \n            if step % 10 == 0:\n                train_accuracy = 0.0\n                for i in range(train_batch):\n                    batch = FLAGS.batch_size*i\n                    batch_plus = FLAGS.batch_size*(i+1)\n                    if batch_plus &gt; train_len: batch_plus = train_len\n                    train_accuracy += sess.run(acc, feed_dict={\n                                               images_placeholder: train_image[batch:batch_plus],\n                                               labels_placeholder: train_label[batch:batch_plus],\n                                               keep_prob: 1.0})\n                    if i is not 0: train_accuracy /= 2.0\n                #summary_str = sess.run(summary_op, feed_dict={\n                #    images_placeholder: train_image,\n                #    labels_placeholder: train_label,\n                #    keep_prob: 1.0})\n                #summary_writer.add_summary(summary_str, step)\n                print(\"step %d, training accuracy %g\",(step, train_accuracy))\n\n    if test_len % FLAGS.batch_size is 0:\n        test_batch = test_len/FLAGS.batch_size\n    else:\n        test_batch = (test_len/FLAGS.batch_size)+1\n        print(\"test_batch = \",str(test_batch))\n        test_accuracy = 0.0\n    for i in range(test_batch):\n        batch = FLAGS.batch_size*i\n        batch_plus = FLAGS.batch_size*(i+1)\n        if batch_plus &gt; train_len: batch_plus = train_len\n        test_accuracy += sess.run(acc, feed_dict={\n                                  images_placeholder: test_image[batch:batch_plus],\n                                  labels_placeholder: test_label[batch:batch_plus],\n                                  keep_prob: 1.0})\n        if i is not 0: test_accuracy /= 2.0\n    print(\"test accuracy %g\",(test_accuracy))\n    save_path = saver.save(sess, FLAGS.save_model)\n</code></pre>\n<p>but when I try to run it I gives me an error:<br>\n<code>ValueError:Cannot feed value of shape (50, 2352) for Tensor 'Placeholder:0', which has shape '(?, 784)'</code></p>\n<p>I feel like i'm overlooking something small but I don't see it.</p>", "body_text": "Hi\nPlease Help me...\nI learning to tensorflow using my own data based on tutorial expert.\nfollowing my code:\n#datasets define\nNUM_CLASSES = 65535\nIMAGE_SIZE = 28\nIMAGE_PIXELS = IMAGE_SIZE*IMAGE_SIZE*1\n\n#read datasets\n    with open(FLAGS.train, 'r') as f: # train.txt\n        train_image = []\n        train_label = []\n        num = 0\n        for line in f:\n            if num == 500:\n                break\n            line = line.rstrip()\n            l = line.split(',')\n            print(l[0])\n            img = cv2.imread(l[0])\n            img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n            train_image.append(img.flatten().astype(np.float32)/255.0)\n            tmp = np.zeros(NUM_CLASSES)\n            tmp[int(l[1])] = 1\n            train_label.append(tmp)\n            num += 1\n        train_image = np.asarray(train_image)\n        train_label = np.asarray(train_label)\n        train_len = len(train_image)\n\ndef inference(images_placeholder, keep_prob):\n    def weight_variable(shape):\n        initial = tf.truncated_normal(shape, stddev=0.1)\n        return tf.Variable(initial)\n    def bias_variable(shape):\n        initial = tf.constant(0.1, shape=shape)\n        return tf.Variable(initial)\n    def conv2d(x, W):\n        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n    def max_pool_2x2(x):\n        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                              strides=[1, 2, 2, 1], padding='SAME')\n    x_images = tf.reshape(images_placeholder, [-1, IMAGE_SIZE, IMAGE_SIZE, 1])\n    with tf.name_scope('conv1') as scope:\n        W_conv1 = weight_variable([5, 5, 1, 32])\n        b_conv1 = bias_variable([32])\n        h_conv1 = tf.nn.relu(conv2d(x_images, W_conv1) + b_conv1)\n    with tf.name_scope('pool1') as scope:\n        h_pool1 = max_pool_2x2(h_conv1)\n    with tf.name_scope('conv2') as scope:\n        W_conv2 = weight_variable([5, 5, 32, 64])\n        b_conv2 = bias_variable([64])\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n    with tf.name_scope('pool2') as scope:\n        h_pool2 = max_pool_2x2(h_conv2)\n    with tf.name_scope('fc1') as scope:\n        W_fc1 = weight_variable([7*7*64, 1024])\n        b_fc1 = bias_variable([1024])\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n    with tf.name_scope('fc2') as scope:\n        W_fc2 = weight_variable([1024, NUM_CLASSES])\n        b_fc2 = bias_variable([NUM_CLASSES])\n    with tf.name_scope('softmax') as scope:\n        y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n    return y_conv\n\n#learn\n    with tf.Graph().as_default():\n        images_placeholder = tf.placeholder(\"float\", shape=(None, IMAGE_PIXELS))\n        labels_placeholder = tf.placeholder(\"float\", shape=(None, NUM_CLASSES))\n        keep_prob = tf.placeholder(\"float\")\n        \n        logits = inference(images_placeholder, keep_prob)\n        loss_value = loss(logits, labels_placeholder)\n        train_op = training(loss_value, FLAGS.learning_rate)\n        print(\"train_op =\", train_op)\n\n        acc = accuracy(logits, labels_placeholder)\n        \n        saver = tf.train.Saver()\n        sess = tf.Session()\n        sess.run(tf.initialize_all_variables())\n        summary_op = tf.merge_all_summaries()\n        summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph_def)\n        \n        if train_len % FLAGS.batch_size is 0:\n            train_batch = train_len/FLAGS.batch_size\n        else:\n            train_batch = (train_len/FLAGS.batch_size)+1\n        print(\"train_batch = %d\",str(train_batch))\n        for step in range(FLAGS.max_steps):\n            for i in range(int(train_batch)):\n                batch = FLAGS.batch_size*i\n                batch_plus = FLAGS.batch_size*(i+1)\n                print(\"batch_plus =\", batch_plus)\n                if batch_plus > train_len: batch_plus = train_len\n                sess.run(train_op, feed_dict={\n                         images_placeholder: train_image[batch:batch_plus],\n                         labels_placeholder: train_label[batch:batch_plus],\n                         keep_prob: 0.5})\n            \n            if step % 10 == 0:\n                train_accuracy = 0.0\n                for i in range(train_batch):\n                    batch = FLAGS.batch_size*i\n                    batch_plus = FLAGS.batch_size*(i+1)\n                    if batch_plus > train_len: batch_plus = train_len\n                    train_accuracy += sess.run(acc, feed_dict={\n                                               images_placeholder: train_image[batch:batch_plus],\n                                               labels_placeholder: train_label[batch:batch_plus],\n                                               keep_prob: 1.0})\n                    if i is not 0: train_accuracy /= 2.0\n                #summary_str = sess.run(summary_op, feed_dict={\n                #    images_placeholder: train_image,\n                #    labels_placeholder: train_label,\n                #    keep_prob: 1.0})\n                #summary_writer.add_summary(summary_str, step)\n                print(\"step %d, training accuracy %g\",(step, train_accuracy))\n\n    if test_len % FLAGS.batch_size is 0:\n        test_batch = test_len/FLAGS.batch_size\n    else:\n        test_batch = (test_len/FLAGS.batch_size)+1\n        print(\"test_batch = \",str(test_batch))\n        test_accuracy = 0.0\n    for i in range(test_batch):\n        batch = FLAGS.batch_size*i\n        batch_plus = FLAGS.batch_size*(i+1)\n        if batch_plus > train_len: batch_plus = train_len\n        test_accuracy += sess.run(acc, feed_dict={\n                                  images_placeholder: test_image[batch:batch_plus],\n                                  labels_placeholder: test_label[batch:batch_plus],\n                                  keep_prob: 1.0})\n        if i is not 0: test_accuracy /= 2.0\n    print(\"test accuracy %g\",(test_accuracy))\n    save_path = saver.save(sess, FLAGS.save_model)\n\nbut when I try to run it I gives me an error:\nValueError:Cannot feed value of shape (50, 2352) for Tensor 'Placeholder:0', which has shape '(?, 784)'\nI feel like i'm overlooking something small but I don't see it.", "body": "Hi \r\nPlease Help me...\r\nI learning to tensorflow using my own data based on tutorial expert.\r\nfollowing my code:\r\n```\r\n#datasets define\r\nNUM_CLASSES = 65535\r\nIMAGE_SIZE = 28\r\nIMAGE_PIXELS = IMAGE_SIZE*IMAGE_SIZE*1\r\n```\r\n\r\n```\r\n#read datasets\r\n    with open(FLAGS.train, 'r') as f: # train.txt\r\n        train_image = []\r\n        train_label = []\r\n        num = 0\r\n        for line in f:\r\n            if num == 500:\r\n                break\r\n            line = line.rstrip()\r\n            l = line.split(',')\r\n            print(l[0])\r\n            img = cv2.imread(l[0])\r\n            img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\r\n            train_image.append(img.flatten().astype(np.float32)/255.0)\r\n            tmp = np.zeros(NUM_CLASSES)\r\n            tmp[int(l[1])] = 1\r\n            train_label.append(tmp)\r\n            num += 1\r\n        train_image = np.asarray(train_image)\r\n        train_label = np.asarray(train_label)\r\n        train_len = len(train_image)\r\n```\r\n\r\n```\r\ndef inference(images_placeholder, keep_prob):\r\n    def weight_variable(shape):\r\n        initial = tf.truncated_normal(shape, stddev=0.1)\r\n        return tf.Variable(initial)\r\n    def bias_variable(shape):\r\n        initial = tf.constant(0.1, shape=shape)\r\n        return tf.Variable(initial)\r\n    def conv2d(x, W):\r\n        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n    def max_pool_2x2(x):\r\n        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\r\n                              strides=[1, 2, 2, 1], padding='SAME')\r\n    x_images = tf.reshape(images_placeholder, [-1, IMAGE_SIZE, IMAGE_SIZE, 1])\r\n    with tf.name_scope('conv1') as scope:\r\n        W_conv1 = weight_variable([5, 5, 1, 32])\r\n        b_conv1 = bias_variable([32])\r\n        h_conv1 = tf.nn.relu(conv2d(x_images, W_conv1) + b_conv1)\r\n    with tf.name_scope('pool1') as scope:\r\n        h_pool1 = max_pool_2x2(h_conv1)\r\n    with tf.name_scope('conv2') as scope:\r\n        W_conv2 = weight_variable([5, 5, 32, 64])\r\n        b_conv2 = bias_variable([64])\r\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\r\n    with tf.name_scope('pool2') as scope:\r\n        h_pool2 = max_pool_2x2(h_conv2)\r\n    with tf.name_scope('fc1') as scope:\r\n        W_fc1 = weight_variable([7*7*64, 1024])\r\n        b_fc1 = bias_variable([1024])\r\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\r\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\r\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\r\n    with tf.name_scope('fc2') as scope:\r\n        W_fc2 = weight_variable([1024, NUM_CLASSES])\r\n        b_fc2 = bias_variable([NUM_CLASSES])\r\n    with tf.name_scope('softmax') as scope:\r\n        y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\r\n    return y_conv\r\n```\r\n\r\n```\r\n#learn\r\n    with tf.Graph().as_default():\r\n        images_placeholder = tf.placeholder(\"float\", shape=(None, IMAGE_PIXELS))\r\n        labels_placeholder = tf.placeholder(\"float\", shape=(None, NUM_CLASSES))\r\n        keep_prob = tf.placeholder(\"float\")\r\n        \r\n        logits = inference(images_placeholder, keep_prob)\r\n        loss_value = loss(logits, labels_placeholder)\r\n        train_op = training(loss_value, FLAGS.learning_rate)\r\n        print(\"train_op =\", train_op)\r\n\r\n        acc = accuracy(logits, labels_placeholder)\r\n        \r\n        saver = tf.train.Saver()\r\n        sess = tf.Session()\r\n        sess.run(tf.initialize_all_variables())\r\n        summary_op = tf.merge_all_summaries()\r\n        summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph_def)\r\n        \r\n        if train_len % FLAGS.batch_size is 0:\r\n            train_batch = train_len/FLAGS.batch_size\r\n        else:\r\n            train_batch = (train_len/FLAGS.batch_size)+1\r\n        print(\"train_batch = %d\",str(train_batch))\r\n        for step in range(FLAGS.max_steps):\r\n            for i in range(int(train_batch)):\r\n                batch = FLAGS.batch_size*i\r\n                batch_plus = FLAGS.batch_size*(i+1)\r\n                print(\"batch_plus =\", batch_plus)\r\n                if batch_plus > train_len: batch_plus = train_len\r\n                sess.run(train_op, feed_dict={\r\n                         images_placeholder: train_image[batch:batch_plus],\r\n                         labels_placeholder: train_label[batch:batch_plus],\r\n                         keep_prob: 0.5})\r\n            \r\n            if step % 10 == 0:\r\n                train_accuracy = 0.0\r\n                for i in range(train_batch):\r\n                    batch = FLAGS.batch_size*i\r\n                    batch_plus = FLAGS.batch_size*(i+1)\r\n                    if batch_plus > train_len: batch_plus = train_len\r\n                    train_accuracy += sess.run(acc, feed_dict={\r\n                                               images_placeholder: train_image[batch:batch_plus],\r\n                                               labels_placeholder: train_label[batch:batch_plus],\r\n                                               keep_prob: 1.0})\r\n                    if i is not 0: train_accuracy /= 2.0\r\n                #summary_str = sess.run(summary_op, feed_dict={\r\n                #    images_placeholder: train_image,\r\n                #    labels_placeholder: train_label,\r\n                #    keep_prob: 1.0})\r\n                #summary_writer.add_summary(summary_str, step)\r\n                print(\"step %d, training accuracy %g\",(step, train_accuracy))\r\n\r\n    if test_len % FLAGS.batch_size is 0:\r\n        test_batch = test_len/FLAGS.batch_size\r\n    else:\r\n        test_batch = (test_len/FLAGS.batch_size)+1\r\n        print(\"test_batch = \",str(test_batch))\r\n        test_accuracy = 0.0\r\n    for i in range(test_batch):\r\n        batch = FLAGS.batch_size*i\r\n        batch_plus = FLAGS.batch_size*(i+1)\r\n        if batch_plus > train_len: batch_plus = train_len\r\n        test_accuracy += sess.run(acc, feed_dict={\r\n                                  images_placeholder: test_image[batch:batch_plus],\r\n                                  labels_placeholder: test_label[batch:batch_plus],\r\n                                  keep_prob: 1.0})\r\n        if i is not 0: test_accuracy /= 2.0\r\n    print(\"test accuracy %g\",(test_accuracy))\r\n    save_path = saver.save(sess, FLAGS.save_model)\r\n```\r\nbut when I try to run it I gives me an error:\r\n`ValueError:Cannot feed value of shape (50, 2352) for Tensor 'Placeholder:0', which has shape '(?, 784)'`\r\n\r\nI feel like i'm overlooking something small but I don't see it.\r\n"}