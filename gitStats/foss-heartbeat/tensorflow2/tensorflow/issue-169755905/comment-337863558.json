{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/337863558", "html_url": "https://github.com/tensorflow/tensorflow/issues/3678#issuecomment-337863558", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3678", "id": 337863558, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzg2MzU1OA==", "user": {"login": "evolu8", "id": 1828165, "node_id": "MDQ6VXNlcjE4MjgxNjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1828165?v=4", "gravatar_id": "", "url": "https://api.github.com/users/evolu8", "html_url": "https://github.com/evolu8", "followers_url": "https://api.github.com/users/evolu8/followers", "following_url": "https://api.github.com/users/evolu8/following{/other_user}", "gists_url": "https://api.github.com/users/evolu8/gists{/gist_id}", "starred_url": "https://api.github.com/users/evolu8/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/evolu8/subscriptions", "organizations_url": "https://api.github.com/users/evolu8/orgs", "repos_url": "https://api.github.com/users/evolu8/repos", "events_url": "https://api.github.com/users/evolu8/events{/privacy}", "received_events_url": "https://api.github.com/users/evolu8/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-19T10:12:47Z", "updated_at": "2017-10-19T10:12:47Z", "author_association": "NONE", "body_html": "<p>UVM support throughout would be of enormous benefit. I would be very keen to see this implemented. Having ideal training throughput is often less important than coping with large input and large model sizes which simply fail to fit on a card.</p>", "body_text": "UVM support throughout would be of enormous benefit. I would be very keen to see this implemented. Having ideal training throughput is often less important than coping with large input and large model sizes which simply fail to fit on a card.", "body": "UVM support throughout would be of enormous benefit. I would be very keen to see this implemented. Having ideal training throughput is often less important than coping with large input and large model sizes which simply fail to fit on a card. "}