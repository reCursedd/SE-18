{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/272588408", "html_url": "https://github.com/tensorflow/tensorflow/issues/5#issuecomment-272588408", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5", "id": 272588408, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjU4ODQwOA==", "user": {"login": "jbolla", "id": 2093086, "node_id": "MDQ6VXNlcjIwOTMwODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/2093086?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbolla", "html_url": "https://github.com/jbolla", "followers_url": "https://api.github.com/users/jbolla/followers", "following_url": "https://api.github.com/users/jbolla/following{/other_user}", "gists_url": "https://api.github.com/users/jbolla/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbolla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbolla/subscriptions", "organizations_url": "https://api.github.com/users/jbolla/orgs", "repos_url": "https://api.github.com/users/jbolla/repos", "events_url": "https://api.github.com/users/jbolla/events{/privacy}", "received_events_url": "https://api.github.com/users/jbolla/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-14T01:08:27Z", "updated_at": "2017-01-14T01:08:27Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16018\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/asimshankar\">@asimshankar</a> Thanks for your thoughts.</p>\n<p>Regarding the first point, it's not really a big deal. As you say there are times where a byte[] makes the most sense. In my own use case I have an InputStream, which is trivial to convert to byte[]. The protocol buffer API makes conversion straightforward. I just consider the byte[] a wart on the API because you're going to have to deserialize anyway (in TF_GraphImportGraphDef) and this way you lose some type safety. There's also proto3's json serialization to consider.</p>\n<p>On swallowing status, you're right. I missed the unchecked exception.</p>\n<p>The most obvious way to handle 2 and 3 is to give org.tensorflow.Tensor a factory that converts from a TensorProto and some toTensorProto(). If resource limited use cases is the issue with protocol buffers, then people in those circumstances could simply not use those functions. The problem is that people who do use those functions would be paying the cost of a conversion that could likely be avoided by having the Tensor store its data directly in a protobuff. I've never worked with jni before, so I'm having trouble following how the data are stored, but it looks like it's essentially treating nativeHandle like a pointer to a TF_Tensor which has a TensorBuffer that is treated essentially like a sized void*.</p>", "body_text": "@asimshankar Thanks for your thoughts.\nRegarding the first point, it's not really a big deal. As you say there are times where a byte[] makes the most sense. In my own use case I have an InputStream, which is trivial to convert to byte[]. The protocol buffer API makes conversion straightforward. I just consider the byte[] a wart on the API because you're going to have to deserialize anyway (in TF_GraphImportGraphDef) and this way you lose some type safety. There's also proto3's json serialization to consider.\nOn swallowing status, you're right. I missed the unchecked exception.\nThe most obvious way to handle 2 and 3 is to give org.tensorflow.Tensor a factory that converts from a TensorProto and some toTensorProto(). If resource limited use cases is the issue with protocol buffers, then people in those circumstances could simply not use those functions. The problem is that people who do use those functions would be paying the cost of a conversion that could likely be avoided by having the Tensor store its data directly in a protobuff. I've never worked with jni before, so I'm having trouble following how the data are stored, but it looks like it's essentially treating nativeHandle like a pointer to a TF_Tensor which has a TensorBuffer that is treated essentially like a sized void*.", "body": "@asimshankar Thanks for your thoughts.\r\n\r\nRegarding the first point, it's not really a big deal. As you say there are times where a byte[] makes the most sense. In my own use case I have an InputStream, which is trivial to convert to byte[]. The protocol buffer API makes conversion straightforward. I just consider the byte[] a wart on the API because you're going to have to deserialize anyway (in TF_GraphImportGraphDef) and this way you lose some type safety. There's also proto3's json serialization to consider.\r\n\r\nOn swallowing status, you're right. I missed the unchecked exception.\r\n\r\nThe most obvious way to handle 2 and 3 is to give org.tensorflow.Tensor a factory that converts from a TensorProto and some toTensorProto(). If resource limited use cases is the issue with protocol buffers, then people in those circumstances could simply not use those functions. The problem is that people who do use those functions would be paying the cost of a conversion that could likely be avoided by having the Tensor store its data directly in a protobuff. I've never worked with jni before, so I'm having trouble following how the data are stored, but it looks like it's essentially treating nativeHandle like a pointer to a TF_Tensor which has a TensorBuffer that is treated essentially like a sized void*."}