{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21782", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21782/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21782/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21782/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21782", "id": 352790026, "node_id": "MDU6SXNzdWUzNTI3OTAwMjY=", "number": 21782, "title": "profiler trace_steps is not match global step in distribution training", "user": {"login": "PaulChongPeng", "id": 18079752, "node_id": "MDQ6VXNlcjE4MDc5NzUy", "avatar_url": "https://avatars1.githubusercontent.com/u/18079752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PaulChongPeng", "html_url": "https://github.com/PaulChongPeng", "followers_url": "https://api.github.com/users/PaulChongPeng/followers", "following_url": "https://api.github.com/users/PaulChongPeng/following{/other_user}", "gists_url": "https://api.github.com/users/PaulChongPeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/PaulChongPeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PaulChongPeng/subscriptions", "organizations_url": "https://api.github.com/users/PaulChongPeng/orgs", "repos_url": "https://api.github.com/users/PaulChongPeng/repos", "events_url": "https://api.github.com/users/PaulChongPeng/events{/privacy}", "received_events_url": "https://api.github.com/users/PaulChongPeng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 996845227, "node_id": "MDU6TGFiZWw5OTY4NDUyMjc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:dist-strat", "name": "comp:dist-strat", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-08-22T03:29:10Z", "updated_at": "2018-11-21T17:05:59Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<p>== cat /etc/issue ===============================================<br>\nLinux gpu0198 3.10.0-229.el7.x86_64 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a> SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"7 (Core)\"<br>\nVERSION_ID=\"7\"<br>\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"<br>\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"</p>\n<p>== are we in docker =============================================<br>\nYes</p>\n<p>== compiler =====================================================<br>\nc++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux gpu0198 3.10.0-229.el7.x86_64 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a> SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy                              1.14.5<br>\nprotobuf                           3.6.1<br>\ntensorflow-gpu                     1.10.0</p>\n<p>== check for virtualenv =========================================<br>\nTrue</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.10.0<br>\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34<br>\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH :/usr/local/nvidia/cpu_lib:/nodemanager/lib/native:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java//jre/lib/amd64/server:/nodemanager/lib/native<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nWed Aug 22 03:12:21 2018<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Tesla V100-PCIE...  On   | 00000000:86:00.0 Off |                    0 |<br>\n| N/A   28C    P0    38W / 250W |      0MiB / 16160MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|  No running processes found                                                 |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176<br>\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a</p>\n<h3>Describe the problem</h3>\n<p>When I use tensorflow profiler to get the timeline for distribution training, I found the trace_steps didn't match the global step and it result in useless timeline.<br>\nI check the profile_context.py and find that the profile step is not related to the global step.</p>\n<p>distribution config:<br>\nps 2<br>\nworker 8<br>\n1 gpu per worker</p>\n<h3>Source code / logs</h3>\n<p>sync code:<br>\nwith tf.contrib.tfprof.ProfileContext(profile_dir=FLAGS.train_dir,<br>\ntrace_steps=range(100, 200,3),<br>\ndump_steps=[200],<br>\nenabled=FLAGS.enable_profile,<br>\ndebug=FLAGS.enable_profile_debug) as pctx:<br>\n...<br>\n...<br>\noptimizer = tf.train.SyncReplicasOptimizer(<br>\nopt=optimizer,<br>\nreplicas_to_aggregate=FLAGS.replicas_to_aggregate,<br>\ntotal_num_replicas=worker_replicas,<br>\nvariable_averages=variable_averages,<br>\nvariables_to_average=moving_average_variables)</p>\n<p>sync train log :<br>\nworker 0:<br>\ndebug: tracing step: 148<br>\ndebug: tracing step: 151<br>\nINFO:tensorflow:global step 19: loss = 2.1377 (8.300 sec/step)<br>\ndebug: tracing step: 154<br>\ndebug: tracing step: 157</p>\n<p>async code:<br>\nwith tf.contrib.tfprof.ProfileContext(profile_dir=FLAGS.train_dir,<br>\ntrace_steps=range(800, 900),<br>\ndump_steps=[200],<br>\nenabled=FLAGS.enable_profile,<br>\ndebug=FLAGS.enable_profile_debug) as pctx:</p>\n<p>async train log:<br>\nworker 0:<br>\ndebug: tracing step: 838<br>\nINFO:tensorflow:global step 2198: loss = 2.0687 (6.361 sec/step)<br>\ndebug: tracing step: 839</p>\n<p>worker 7:<br>\ndebug: tracing step: 825<br>\nINFO:tensorflow:global step 3137: loss = 2.5605 (7.343 sec/step)<br>\ndebug: tracing step: 826</p>", "body_text": "System information\n== cat /etc/issue ===============================================\nLinux gpu0198 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"7 (Core)\"\nVERSION_ID=\"7\"\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\n== are we in docker =============================================\nYes\n== compiler =====================================================\nc++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux gpu0198 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy                              1.14.5\nprotobuf                           3.6.1\ntensorflow-gpu                     1.10.0\n== check for virtualenv =========================================\nTrue\n== tensorflow import ============================================\ntf.VERSION = 1.10.0\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH :/usr/local/nvidia/cpu_lib:/nodemanager/lib/native:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java//jre/lib/amd64/server:/nodemanager/lib/native\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nWed Aug 22 03:12:21 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla V100-PCIE...  On   | 00000000:86:00.0 Off |                    0 |\n| N/A   28C    P0    38W / 250W |      0MiB / 16160MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\nDescribe the problem\nWhen I use tensorflow profiler to get the timeline for distribution training, I found the trace_steps didn't match the global step and it result in useless timeline.\nI check the profile_context.py and find that the profile step is not related to the global step.\ndistribution config:\nps 2\nworker 8\n1 gpu per worker\nSource code / logs\nsync code:\nwith tf.contrib.tfprof.ProfileContext(profile_dir=FLAGS.train_dir,\ntrace_steps=range(100, 200,3),\ndump_steps=[200],\nenabled=FLAGS.enable_profile,\ndebug=FLAGS.enable_profile_debug) as pctx:\n...\n...\noptimizer = tf.train.SyncReplicasOptimizer(\nopt=optimizer,\nreplicas_to_aggregate=FLAGS.replicas_to_aggregate,\ntotal_num_replicas=worker_replicas,\nvariable_averages=variable_averages,\nvariables_to_average=moving_average_variables)\nsync train log :\nworker 0:\ndebug: tracing step: 148\ndebug: tracing step: 151\nINFO:tensorflow:global step 19: loss = 2.1377 (8.300 sec/step)\ndebug: tracing step: 154\ndebug: tracing step: 157\nasync code:\nwith tf.contrib.tfprof.ProfileContext(profile_dir=FLAGS.train_dir,\ntrace_steps=range(800, 900),\ndump_steps=[200],\nenabled=FLAGS.enable_profile,\ndebug=FLAGS.enable_profile_debug) as pctx:\nasync train log:\nworker 0:\ndebug: tracing step: 838\nINFO:tensorflow:global step 2198: loss = 2.0687 (6.361 sec/step)\ndebug: tracing step: 839\nworker 7:\ndebug: tracing step: 825\nINFO:tensorflow:global step 3137: loss = 2.5605 (7.343 sec/step)\ndebug: tracing step: 826", "body": "### System information\r\n\r\n== cat /etc/issue ===============================================\r\nLinux gpu0198 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"7 (Core)\"\r\nVERSION_ID=\"7\"\r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux gpu0198 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.5\r\nprotobuf                           3.6.1\r\ntensorflow-gpu                     1.10.0\r\n\r\n== check for virtualenv =========================================\r\nTrue\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.0\r\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34\r\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/nvidia/cpu_lib:/nodemanager/lib/native:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java//jre/lib/amd64/server:/nodemanager/lib/native\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Aug 22 03:12:21 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-PCIE...  On   | 00000000:86:00.0 Off |                    0 |\r\n| N/A   28C    P0    38W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a \r\n\r\n\r\n### Describe the problem\r\n\r\nWhen I use tensorflow profiler to get the timeline for distribution training, I found the trace_steps didn't match the global step and it result in useless timeline.\r\nI check the profile_context.py and find that the profile step is not related to the global step.\r\n\r\ndistribution config:\r\nps 2\r\nworker 8\r\n1 gpu per worker\r\n\r\n### Source code / logs\r\nsync code:\r\nwith tf.contrib.tfprof.ProfileContext(profile_dir=FLAGS.train_dir,\r\n                                                trace_steps=range(100, 200,3),\r\n                                                dump_steps=[200],\r\n                                                enabled=FLAGS.enable_profile,\r\n                                                debug=FLAGS.enable_profile_debug) as pctx:\r\n...\r\n...\r\n                optimizer = tf.train.SyncReplicasOptimizer(\r\n                    opt=optimizer,\r\n                    replicas_to_aggregate=FLAGS.replicas_to_aggregate,\r\n                    total_num_replicas=worker_replicas,\r\n                    variable_averages=variable_averages,\r\n                    variables_to_average=moving_average_variables)\r\n\r\n\r\nsync train log :\r\nworker 0:\r\ndebug: tracing step: 148\r\ndebug: tracing step: 151\r\nINFO:tensorflow:global step 19: loss = 2.1377 (8.300 sec/step)\r\ndebug: tracing step: 154\r\ndebug: tracing step: 157\r\n\r\nasync code:\r\nwith tf.contrib.tfprof.ProfileContext(profile_dir=FLAGS.train_dir,\r\n                                                trace_steps=range(800, 900),\r\n                                                dump_steps=[200],\r\n                                                enabled=FLAGS.enable_profile,\r\n                                                debug=FLAGS.enable_profile_debug) as pctx:\r\n\r\nasync train log:\r\nworker 0:\r\ndebug: tracing step: 838\r\nINFO:tensorflow:global step 2198: loss = 2.0687 (6.361 sec/step)\r\ndebug: tracing step: 839\r\n\r\nworker 7:\r\ndebug: tracing step: 825\r\nINFO:tensorflow:global step 3137: loss = 2.5605 (7.343 sec/step)\r\ndebug: tracing step: 826\r\n"}