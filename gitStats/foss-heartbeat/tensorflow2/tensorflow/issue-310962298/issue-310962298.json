{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18213", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18213/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18213/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18213/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18213", "id": 310962298, "node_id": "MDU6SXNzdWUzMTA5NjIyOTg=", "number": 18213, "title": "Request a new padding mode", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-04-03T19:14:29Z", "updated_at": "2018-11-20T07:52:27Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: n/a</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: n/a</li>\n<li><strong>TensorFlow version (use command below)</strong>: n/a</li>\n<li><strong>Python version</strong>: n/a</li>\n<li><strong>Bazel version (if compiling from source)</strong>: n/a</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: n/a</li>\n<li><strong>CUDA/cuDNN version</strong>: n/a</li>\n<li><strong>GPU model and memory</strong>: n/a</li>\n<li><strong>Exact command to reproduce</strong>: n/a</li>\n</ul>\n<p>According to <a href=\"https://www.tensorflow.org/api_guides/python/nn#Convolution\" rel=\"nofollow\">https://www.tensorflow.org/api_guides/python/nn#Convolution</a>, the current padding mode \"SAME\" will depend on the input size to determine how many pixels to pad, for example:</p>\n<p>input=225, kernel=7, stride=2  ---&gt; padding = [3, 3]<br>\ninput=224, kernel=7, stride=2  ---&gt; padding = [2, 3]</p>\n<p>However, in most other CNN implementations, (and also, historically), padding does not depend on the input size. For kernel=7 and stride=2, padding usually will be [3, 3] (which is actually equivalent to [3, 2] when input=224).</p>\n<p>Potential issues:</p>\n<ol>\n<li>\n<p>Inconsistent with models trained in other frameworks. It's not the first time I have to manually fix the padding when loading a model released by others, e.g. <a href=\"https://github.com/ppwwyyxx/tensorpack/blob/1139854d7e286b56f87a92f96fe8f1b70789d794/examples/ResNet/load-resnet.py#L40-L42\">here</a>. This also causes pain for multi-backend framework such as Keras, because \"SAME\" does not mean the same thing for each backend. One example Keras issue <a href=\"https://github.com/keras-team/keras/pull/9473\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/keras-team/keras/pull/9473/hovercard\">here</a>. Also Keras has to explicit pad the image in its ResNet50 model: <a href=\"https://github.com/keras-team/keras/blob/ef13db05731bfd53fa0a877637c99c1734be933b/keras/applications/resnet50.py#L213\">here</a>.</p>\n</li>\n<li>\n<p>Due to how padding is computed (by <code>left=total_padding//2, right=total_padding-left</code>), the number of pixels padded on <strong>left or top</strong> of the image may change with different input size, as shown by the example above. This is not a good default and in particular harmful for pixel-level tasks, such as detection&amp;segmentation, where all the annotations have an offset starting from the top-left corner of the image.</p>\n</li>\n</ol>\n<p>In fact, many of TF team's own code has to fix this manually by <code>tf.pad</code>, for example:</p>\n<ol>\n<li>tensorflow/benchmarks has a new mode called \"SAME_RESNET\": <a href=\"https://github.com/tensorflow/benchmarks/blob/bab8a61aaca3d2b94072ae2b87f0aafe1797b165/scripts/tf_cnn_benchmarks/convnet_builder.py#L183-L199\">https://github.com/tensorflow/benchmarks/blob/bab8a61aaca3d2b94072ae2b87f0aafe1797b165/scripts/tf_cnn_benchmarks/convnet_builder.py#L183-L199</a></li>\n<li>The recent tpu training code has a function called \"conv2d_fixed_padding\": <a href=\"https://github.com/tensorflow/tpu/blob/b189540102d6b5b40b1730d7e5ad5c884bae323c/models/experimental/resnet_bfloat16/resnet_model.py#L102-L107\">https://github.com/tensorflow/tpu/blob/b189540102d6b5b40b1730d7e5ad5c884bae323c/models/experimental/resnet_bfloat16/resnet_model.py#L102-L107</a></li>\n<li>slim has a function called <code>conv2d_same</code>: <a href=\"https://github.com/tensorflow/models/blob/696b69a498b43f8e6a1ecb24bb82f7b9db87c570/research/slim/nets/resnet_utils.py#L77-L122\">https://github.com/tensorflow/models/blob/696b69a498b43f8e6a1ecb24bb82f7b9db87c570/research/slim/nets/resnet_utils.py#L77-L122</a></li>\n</ol>\n<p>Given all these I think it's reasonable to add a new mode to make things easier.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): n/a\nTensorFlow installed from (source or binary): n/a\nTensorFlow version (use command below): n/a\nPython version: n/a\nBazel version (if compiling from source): n/a\nGCC/Compiler version (if compiling from source): n/a\nCUDA/cuDNN version: n/a\nGPU model and memory: n/a\nExact command to reproduce: n/a\n\nAccording to https://www.tensorflow.org/api_guides/python/nn#Convolution, the current padding mode \"SAME\" will depend on the input size to determine how many pixels to pad, for example:\ninput=225, kernel=7, stride=2  ---> padding = [3, 3]\ninput=224, kernel=7, stride=2  ---> padding = [2, 3]\nHowever, in most other CNN implementations, (and also, historically), padding does not depend on the input size. For kernel=7 and stride=2, padding usually will be [3, 3] (which is actually equivalent to [3, 2] when input=224).\nPotential issues:\n\n\nInconsistent with models trained in other frameworks. It's not the first time I have to manually fix the padding when loading a model released by others, e.g. here. This also causes pain for multi-backend framework such as Keras, because \"SAME\" does not mean the same thing for each backend. One example Keras issue here. Also Keras has to explicit pad the image in its ResNet50 model: here.\n\n\nDue to how padding is computed (by left=total_padding//2, right=total_padding-left), the number of pixels padded on left or top of the image may change with different input size, as shown by the example above. This is not a good default and in particular harmful for pixel-level tasks, such as detection&segmentation, where all the annotations have an offset starting from the top-left corner of the image.\n\n\nIn fact, many of TF team's own code has to fix this manually by tf.pad, for example:\n\ntensorflow/benchmarks has a new mode called \"SAME_RESNET\": https://github.com/tensorflow/benchmarks/blob/bab8a61aaca3d2b94072ae2b87f0aafe1797b165/scripts/tf_cnn_benchmarks/convnet_builder.py#L183-L199\nThe recent tpu training code has a function called \"conv2d_fixed_padding\": https://github.com/tensorflow/tpu/blob/b189540102d6b5b40b1730d7e5ad5c884bae323c/models/experimental/resnet_bfloat16/resnet_model.py#L102-L107\nslim has a function called conv2d_same: https://github.com/tensorflow/models/blob/696b69a498b43f8e6a1ecb24bb82f7b9db87c570/research/slim/nets/resnet_utils.py#L77-L122\n\nGiven all these I think it's reasonable to add a new mode to make things easier.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a\r\n- **TensorFlow installed from (source or binary)**: n/a\r\n- **TensorFlow version (use command below)**: n/a\r\n- **Python version**: n/a\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: n/a\r\n\r\nAccording to https://www.tensorflow.org/api_guides/python/nn#Convolution, the current padding mode \"SAME\" will depend on the input size to determine how many pixels to pad, for example:\r\n\r\ninput=225, kernel=7, stride=2  ---> padding = [3, 3]\r\ninput=224, kernel=7, stride=2  ---> padding = [2, 3]\r\n\r\nHowever, in most other CNN implementations, (and also, historically), padding does not depend on the input size. For kernel=7 and stride=2, padding usually will be [3, 3] (which is actually equivalent to [3, 2] when input=224).\r\n\r\nPotential issues:\r\n1. Inconsistent with models trained in other frameworks. It's not the first time I have to manually fix the padding when loading a model released by others, e.g. [here](https://github.com/ppwwyyxx/tensorpack/blob/1139854d7e286b56f87a92f96fe8f1b70789d794/examples/ResNet/load-resnet.py#L40-L42). This also causes pain for multi-backend framework such as Keras, because \"SAME\" does not mean the same thing for each backend. One example Keras issue [here](https://github.com/keras-team/keras/pull/9473). Also Keras has to explicit pad the image in its ResNet50 model: [here](https://github.com/keras-team/keras/blob/ef13db05731bfd53fa0a877637c99c1734be933b/keras/applications/resnet50.py#L213).\r\n\r\n2. Due to how padding is computed (by `left=total_padding//2, right=total_padding-left`), the number of pixels padded on __left or top__ of the image may change with different input size, as shown by the example above. This is not a good default and in particular harmful for pixel-level tasks, such as detection&segmentation, where all the annotations have an offset starting from the top-left corner of the image.\r\n\r\nIn fact, many of TF team's own code has to fix this manually by `tf.pad`, for example:\r\n1. tensorflow/benchmarks has a new mode called \"SAME_RESNET\": https://github.com/tensorflow/benchmarks/blob/bab8a61aaca3d2b94072ae2b87f0aafe1797b165/scripts/tf_cnn_benchmarks/convnet_builder.py#L183-L199\r\n2. The recent tpu training code has a function called \"conv2d_fixed_padding\": https://github.com/tensorflow/tpu/blob/b189540102d6b5b40b1730d7e5ad5c884bae323c/models/experimental/resnet_bfloat16/resnet_model.py#L102-L107\r\n3. slim has a function called `conv2d_same`: https://github.com/tensorflow/models/blob/696b69a498b43f8e6a1ecb24bb82f7b9db87c570/research/slim/nets/resnet_utils.py#L77-L122\r\n\r\nGiven all these I think it's reasonable to add a new mode to make things easier."}