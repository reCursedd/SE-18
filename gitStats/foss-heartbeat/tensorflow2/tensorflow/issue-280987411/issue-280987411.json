{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15271", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15271/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15271/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15271/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15271", "id": 280987411, "node_id": "MDU6SXNzdWUyODA5ODc0MTE=", "number": 15271, "title": "TFGAN ideas for pretraining/training", "user": {"login": "sleighsoft", "id": 9438971, "node_id": "MDQ6VXNlcjk0Mzg5NzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/9438971?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sleighsoft", "html_url": "https://github.com/sleighsoft", "followers_url": "https://api.github.com/users/sleighsoft/followers", "following_url": "https://api.github.com/users/sleighsoft/following{/other_user}", "gists_url": "https://api.github.com/users/sleighsoft/gists{/gist_id}", "starred_url": "https://api.github.com/users/sleighsoft/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sleighsoft/subscriptions", "organizations_url": "https://api.github.com/users/sleighsoft/orgs", "repos_url": "https://api.github.com/users/sleighsoft/repos", "events_url": "https://api.github.com/users/sleighsoft/events{/privacy}", "received_events_url": "https://api.github.com/users/sleighsoft/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "joel-shor", "id": 6020988, "node_id": "MDQ6VXNlcjYwMjA5ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/6020988?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joel-shor", "html_url": "https://github.com/joel-shor", "followers_url": "https://api.github.com/users/joel-shor/followers", "following_url": "https://api.github.com/users/joel-shor/following{/other_user}", "gists_url": "https://api.github.com/users/joel-shor/gists{/gist_id}", "starred_url": "https://api.github.com/users/joel-shor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joel-shor/subscriptions", "organizations_url": "https://api.github.com/users/joel-shor/orgs", "repos_url": "https://api.github.com/users/joel-shor/repos", "events_url": "https://api.github.com/users/joel-shor/events{/privacy}", "received_events_url": "https://api.github.com/users/joel-shor/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "joel-shor", "id": 6020988, "node_id": "MDQ6VXNlcjYwMjA5ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/6020988?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joel-shor", "html_url": "https://github.com/joel-shor", "followers_url": "https://api.github.com/users/joel-shor/followers", "following_url": "https://api.github.com/users/joel-shor/following{/other_user}", "gists_url": "https://api.github.com/users/joel-shor/gists{/gist_id}", "starred_url": "https://api.github.com/users/joel-shor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joel-shor/subscriptions", "organizations_url": "https://api.github.com/users/joel-shor/orgs", "repos_url": "https://api.github.com/users/joel-shor/repos", "events_url": "https://api.github.com/users/joel-shor/events{/privacy}", "received_events_url": "https://api.github.com/users/joel-shor/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 20, "created_at": "2017-12-11T11:44:24Z", "updated_at": "2018-02-17T06:09:05Z", "closed_at": "2018-01-11T02:52:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p>With the PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"275361445\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/14723\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/14723/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/14723\">#14723</a> enabling <code>get_hooks_fn</code> to be set manually instead of the default <code>1</code> step generator and <code>1</code> step discriminator there comes a set of new \"problems\" / things to consider.</p>\n<ol>\n<li>\n<p>The <code>Estimator</code> saves configured tensor summaries in the background. This does not work when doing something like a <code>2/2</code> split for generator/discriminator or a <code>2/3</code>. Then <code>Estimator</code> will only save one step instead of the actual amounts of steps taken (right?). This means that we have to consider an option to configure the <code>FileWriter</code>. I believe that is possible for the vanilla <code>Estimator</code> with <code>scaffolds</code> but not for the <code>GANEstimator</code> currently. This <code>FileWriter</code> has to be accessible by the <code>RunTrainOpsHook</code>. We would also need a generator + discriminator specific \"global_step\" that will be used in the <code>RunTrainOpsHook</code>. A quick idea would be to use the <code>overall_global_step * train_steps</code> of a <code>RunTrainOpsHook</code> or to use <code>dummy_global_step_generator</code> and <code>dummy_global_step_discriminator</code>.</p>\n</li>\n<li>\n<p>When \"pre-training\" (with a normal call to <code>.train()</code> and a modified <code>sequential_train_hook(10,10)</code>) the generator for e.g. <code>10</code> steps and then the discriminator for <code>10</code> steps. Does the discriminator <code>loss_fn</code> receive 10 times new data from the generator through <code>gan_model.discriminator_real_outputs</code> or will it always be the same data? For pre-training I would assume I can feed in the same output data from the generator in batches multiple epochs. I believe that is not possible in the current setup, but correct me if I am wrong.</p>\n</li>\n<li>\n<p>I have different loss functions for both pre-training and training. There is not <code>ModeKeys.PRETRAIN</code> to switch between them.</p>\n</li>\n</ol>\n<p>If I find more things I'll add them here.</p>", "body_text": "With the PR #14723 enabling get_hooks_fn to be set manually instead of the default 1 step generator and 1 step discriminator there comes a set of new \"problems\" / things to consider.\n\n\nThe Estimator saves configured tensor summaries in the background. This does not work when doing something like a 2/2 split for generator/discriminator or a 2/3. Then Estimator will only save one step instead of the actual amounts of steps taken (right?). This means that we have to consider an option to configure the FileWriter. I believe that is possible for the vanilla Estimator with scaffolds but not for the GANEstimator currently. This FileWriter has to be accessible by the RunTrainOpsHook. We would also need a generator + discriminator specific \"global_step\" that will be used in the RunTrainOpsHook. A quick idea would be to use the overall_global_step * train_steps of a RunTrainOpsHook or to use dummy_global_step_generator and dummy_global_step_discriminator.\n\n\nWhen \"pre-training\" (with a normal call to .train() and a modified sequential_train_hook(10,10)) the generator for e.g. 10 steps and then the discriminator for 10 steps. Does the discriminator loss_fn receive 10 times new data from the generator through gan_model.discriminator_real_outputs or will it always be the same data? For pre-training I would assume I can feed in the same output data from the generator in batches multiple epochs. I believe that is not possible in the current setup, but correct me if I am wrong.\n\n\nI have different loss functions for both pre-training and training. There is not ModeKeys.PRETRAIN to switch between them.\n\n\nIf I find more things I'll add them here.", "body": "With the PR #14723 enabling `get_hooks_fn` to be set manually instead of the default `1` step generator and `1` step discriminator there comes a set of new \"problems\" / things to consider.\r\n\r\n1. The `Estimator` saves configured tensor summaries in the background. This does not work when doing something like a `2/2` split for generator/discriminator or a `2/3`. Then `Estimator` will only save one step instead of the actual amounts of steps taken (right?). This means that we have to consider an option to configure the `FileWriter`. I believe that is possible for the vanilla `Estimator` with `scaffolds` but not for the `GANEstimator` currently. This `FileWriter` has to be accessible by the `RunTrainOpsHook`. We would also need a generator + discriminator specific \"global_step\" that will be used in the `RunTrainOpsHook`. A quick idea would be to use the `overall_global_step * train_steps` of a `RunTrainOpsHook` or to use `dummy_global_step_generator` and `dummy_global_step_discriminator`.\r\n\r\n2. When \"pre-training\" (with a normal call to `.train()` and a modified `sequential_train_hook(10,10)`) the generator for e.g. `10` steps and then the discriminator for `10` steps. Does the discriminator `loss_fn` receive 10 times new data from the generator through `gan_model.discriminator_real_outputs` or will it always be the same data? For pre-training I would assume I can feed in the same output data from the generator in batches multiple epochs. I believe that is not possible in the current setup, but correct me if I am wrong.\r\n\r\n3. I have different loss functions for both pre-training and training. There is not `ModeKeys.PRETRAIN` to switch between them.\r\n\r\nIf I find more things I'll add them here."}