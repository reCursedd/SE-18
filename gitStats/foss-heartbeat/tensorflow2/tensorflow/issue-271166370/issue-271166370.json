{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14241", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14241/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14241/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14241/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14241", "id": 271166370, "node_id": "MDU6SXNzdWUyNzExNjYzNzA=", "number": 14241, "title": "`Network` behaviour inconsistent with `Layer` w.r.t `build`", "user": {"login": "jackd", "id": 659115, "node_id": "MDQ6VXNlcjY1OTExNQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/659115?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jackd", "html_url": "https://github.com/jackd", "followers_url": "https://api.github.com/users/jackd/followers", "following_url": "https://api.github.com/users/jackd/following{/other_user}", "gists_url": "https://api.github.com/users/jackd/gists{/gist_id}", "starred_url": "https://api.github.com/users/jackd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jackd/subscriptions", "organizations_url": "https://api.github.com/users/jackd/orgs", "repos_url": "https://api.github.com/users/jackd/repos", "events_url": "https://api.github.com/users/jackd/events{/privacy}", "received_events_url": "https://api.github.com/users/jackd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-04T04:43:30Z", "updated_at": "2017-11-04T21:12:47Z", "closed_at": "2017-11-04T21:12:02Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes (provided below)</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary, <code>pip install tf-nightly-gpu</code></li>\n<li><strong>TensorFlow version (use command below)</strong>: git: v1.3.0-rc1-4090-g4e75ae1, tf: 1.5.0-dev20171103</li>\n<li><strong>Python version</strong>:  2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>: -</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: -</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0</li>\n<li><strong>GPU model and memory</strong>: GTX-1070 8GB</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The <code>tf.layers.Layer</code> class exposes a <code>build</code> method which can optionally be called prior to first <code>__call__</code> e.g. to construct variables in a different scope to where the call is made. The documentation does not explicitly promise that layers are built during <code>build</code> and not elsewhere, but this seems to be the pattern with the implemented layers and is very useful in a narrow set of circumstances.</p>\n<p>The <code>tensorflow.python.layers.base.Network</code> class implements <code>tf.layers.Layer</code> and exposes the same method, but there is no way to construct the constructor arguments without building constituent layers. This is unexpected and misleading, and prevents use of <code>Network</code>s where unbuilt <code>Layer</code>s are expected/required.</p>\n<p>A lazily-built <code>Network</code> implementation would be greatly appreciated, as would clarity on whether it is the intention that all classes implementing <code>Layer</code> should be <code>build</code> separately from their constructor.</p>\n<p>Illustrative example/ basic lazy implementation below.</p>\n<h3>Source code</h3>\n<pre><code>from tensorflow.python.layers import base\nimport tensorflow as tf\n\nn_features = 16\nn_hidden = 8\nn_out = 3\n\n\ndef n_vars():\n    return len(tf.trainable_variables())\n\n\n# Layers, variable created on build\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\nl0 = tf.layers.Dense(n_hidden)\nl1 = tf.layers.Dense(n_out)\nprint(n_vars())  # 0\nl0.build((n_features,))\nl1.build((n_hidden,))\nprint(n_vars())  # 4\n\n\nprint('---------')\n# Network, variables must be created prior to Network construction.\ntf.reset_default_graph()\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\n\nl0 = tf.layers.Dense(n_hidden)\nl1 = tf.layers.Dense(n_out)\n\ninp = base.Input((n_features,))\noutputs = l1(l0(inp))\nprint(n_vars())  # 4\nnetwork = base.Network(inp, outputs)\n\nprint(network.built)  # Already true: no way around with constructor signature\nnetwork.build(None)\nprint(network.built)  # True as expected\n\n\ndef _transform_inputs(inputs):\n    if isinstance(inputs, base.InputSpec):\n        return inputs\n    elif isinstance(inputs, (tuple, tf.TensorShape)):\n        return base.Input(shape=inputs[1:], batch_size=inputs[0])\n    elif isinstance(inputs, tf.Tensor):\n        return base.Input(tensor=inputs)\n    elif isinstance(inputs, list):\n        return [_transform_inputs(inp) for inp in inputs]\n    else:\n        raise NotImplementedError(\n            'Unrecognized type for _transform_inputs: %s' % type(inputs))\n\n\nclass LazyNetwork(base.Network):\n    def __init__(self, outputs_fn, **kwargs):\n        self._outputs_fn = outputs_fn\n        self._kwargs = kwargs\n        self.built = False\n\n    def build(self, inputs):\n        if self.built:\n            return\n        inputs = _transform_inputs(inputs)\n        outputs = self._outputs_fn(inputs)\n        super(LazyNetwork, self).__init__(\n            inputs, outputs, **self._kwargs)\n\n    def __call__(self, inputs):\n        if not self.built:\n            self.build(_transform_inputs(inputs))\n        return super(LazyNetwork, self).__call__(inputs)\n\n\nprint('---------')\n# LazyNetwork, variables created on build\ntf.reset_default_graph()\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\n\nl0 = tf.layers.Dense(n_hidden)\nl1 = tf.layers.Dense(n_out)\nnetwork = LazyNetwork(lambda x: l1(l0(x)))\n\nprint(n_vars())  # 0\nprint(network.built)  # False\nnetwork.build(base.Input((n_features,)))\nprint(n_vars())  # 4\nprint(network.built)  # True\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (provided below)\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): binary, pip install tf-nightly-gpu\nTensorFlow version (use command below): git: v1.3.0-rc1-4090-g4e75ae1, tf: 1.5.0-dev20171103\nPython version:  2.7.12\nBazel version (if compiling from source): -\nGCC/Compiler version (if compiling from source): -\nCUDA/cuDNN version: 8.0\nGPU model and memory: GTX-1070 8GB\n\nDescribe the problem\nThe tf.layers.Layer class exposes a build method which can optionally be called prior to first __call__ e.g. to construct variables in a different scope to where the call is made. The documentation does not explicitly promise that layers are built during build and not elsewhere, but this seems to be the pattern with the implemented layers and is very useful in a narrow set of circumstances.\nThe tensorflow.python.layers.base.Network class implements tf.layers.Layer and exposes the same method, but there is no way to construct the constructor arguments without building constituent layers. This is unexpected and misleading, and prevents use of Networks where unbuilt Layers are expected/required.\nA lazily-built Network implementation would be greatly appreciated, as would clarity on whether it is the intention that all classes implementing Layer should be build separately from their constructor.\nIllustrative example/ basic lazy implementation below.\nSource code\nfrom tensorflow.python.layers import base\nimport tensorflow as tf\n\nn_features = 16\nn_hidden = 8\nn_out = 3\n\n\ndef n_vars():\n    return len(tf.trainable_variables())\n\n\n# Layers, variable created on build\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\nl0 = tf.layers.Dense(n_hidden)\nl1 = tf.layers.Dense(n_out)\nprint(n_vars())  # 0\nl0.build((n_features,))\nl1.build((n_hidden,))\nprint(n_vars())  # 4\n\n\nprint('---------')\n# Network, variables must be created prior to Network construction.\ntf.reset_default_graph()\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\n\nl0 = tf.layers.Dense(n_hidden)\nl1 = tf.layers.Dense(n_out)\n\ninp = base.Input((n_features,))\noutputs = l1(l0(inp))\nprint(n_vars())  # 4\nnetwork = base.Network(inp, outputs)\n\nprint(network.built)  # Already true: no way around with constructor signature\nnetwork.build(None)\nprint(network.built)  # True as expected\n\n\ndef _transform_inputs(inputs):\n    if isinstance(inputs, base.InputSpec):\n        return inputs\n    elif isinstance(inputs, (tuple, tf.TensorShape)):\n        return base.Input(shape=inputs[1:], batch_size=inputs[0])\n    elif isinstance(inputs, tf.Tensor):\n        return base.Input(tensor=inputs)\n    elif isinstance(inputs, list):\n        return [_transform_inputs(inp) for inp in inputs]\n    else:\n        raise NotImplementedError(\n            'Unrecognized type for _transform_inputs: %s' % type(inputs))\n\n\nclass LazyNetwork(base.Network):\n    def __init__(self, outputs_fn, **kwargs):\n        self._outputs_fn = outputs_fn\n        self._kwargs = kwargs\n        self.built = False\n\n    def build(self, inputs):\n        if self.built:\n            return\n        inputs = _transform_inputs(inputs)\n        outputs = self._outputs_fn(inputs)\n        super(LazyNetwork, self).__init__(\n            inputs, outputs, **self._kwargs)\n\n    def __call__(self, inputs):\n        if not self.built:\n            self.build(_transform_inputs(inputs))\n        return super(LazyNetwork, self).__call__(inputs)\n\n\nprint('---------')\n# LazyNetwork, variables created on build\ntf.reset_default_graph()\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\n\nl0 = tf.layers.Dense(n_hidden)\nl1 = tf.layers.Dense(n_out)\nnetwork = LazyNetwork(lambda x: l1(l0(x)))\n\nprint(n_vars())  # 0\nprint(network.built)  # False\nnetwork.build(base.Input((n_features,)))\nprint(n_vars())  # 4\nprint(network.built)  # True", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (provided below)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary, `pip install tf-nightly-gpu`\r\n- **TensorFlow version (use command below)**: git: v1.3.0-rc1-4090-g4e75ae1, tf: 1.5.0-dev20171103\r\n- **Python version**:  2.7.12\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GTX-1070 8GB\r\n\r\n### Describe the problem\r\nThe `tf.layers.Layer` class exposes a `build` method which can optionally be called prior to first `__call__` e.g. to construct variables in a different scope to where the call is made. The documentation does not explicitly promise that layers are built during `build` and not elsewhere, but this seems to be the pattern with the implemented layers and is very useful in a narrow set of circumstances.\r\n\r\nThe `tensorflow.python.layers.base.Network` class implements `tf.layers.Layer` and exposes the same method, but there is no way to construct the constructor arguments without building constituent layers. This is unexpected and misleading, and prevents use of `Network`s where unbuilt `Layer`s are expected/required.\r\n\r\nA lazily-built `Network` implementation would be greatly appreciated, as would clarity on whether it is the intention that all classes implementing `Layer` should be `build` separately from their constructor. \r\n\r\nIllustrative example/ basic lazy implementation below.\r\n\r\n### Source code\r\n```\r\nfrom tensorflow.python.layers import base\r\nimport tensorflow as tf\r\n\r\nn_features = 16\r\nn_hidden = 8\r\nn_out = 3\r\n\r\n\r\ndef n_vars():\r\n    return len(tf.trainable_variables())\r\n\r\n\r\n# Layers, variable created on build\r\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\r\nl0 = tf.layers.Dense(n_hidden)\r\nl1 = tf.layers.Dense(n_out)\r\nprint(n_vars())  # 0\r\nl0.build((n_features,))\r\nl1.build((n_hidden,))\r\nprint(n_vars())  # 4\r\n\r\n\r\nprint('---------')\r\n# Network, variables must be created prior to Network construction.\r\ntf.reset_default_graph()\r\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\r\n\r\nl0 = tf.layers.Dense(n_hidden)\r\nl1 = tf.layers.Dense(n_out)\r\n\r\ninp = base.Input((n_features,))\r\noutputs = l1(l0(inp))\r\nprint(n_vars())  # 4\r\nnetwork = base.Network(inp, outputs)\r\n\r\nprint(network.built)  # Already true: no way around with constructor signature\r\nnetwork.build(None)\r\nprint(network.built)  # True as expected\r\n\r\n\r\ndef _transform_inputs(inputs):\r\n    if isinstance(inputs, base.InputSpec):\r\n        return inputs\r\n    elif isinstance(inputs, (tuple, tf.TensorShape)):\r\n        return base.Input(shape=inputs[1:], batch_size=inputs[0])\r\n    elif isinstance(inputs, tf.Tensor):\r\n        return base.Input(tensor=inputs)\r\n    elif isinstance(inputs, list):\r\n        return [_transform_inputs(inp) for inp in inputs]\r\n    else:\r\n        raise NotImplementedError(\r\n            'Unrecognized type for _transform_inputs: %s' % type(inputs))\r\n\r\n\r\nclass LazyNetwork(base.Network):\r\n    def __init__(self, outputs_fn, **kwargs):\r\n        self._outputs_fn = outputs_fn\r\n        self._kwargs = kwargs\r\n        self.built = False\r\n\r\n    def build(self, inputs):\r\n        if self.built:\r\n            return\r\n        inputs = _transform_inputs(inputs)\r\n        outputs = self._outputs_fn(inputs)\r\n        super(LazyNetwork, self).__init__(\r\n            inputs, outputs, **self._kwargs)\r\n\r\n    def __call__(self, inputs):\r\n        if not self.built:\r\n            self.build(_transform_inputs(inputs))\r\n        return super(LazyNetwork, self).__call__(inputs)\r\n\r\n\r\nprint('---------')\r\n# LazyNetwork, variables created on build\r\ntf.reset_default_graph()\r\nx = tf.placeholder(shape=(None, n_features), dtype=tf.float32)\r\n\r\nl0 = tf.layers.Dense(n_hidden)\r\nl1 = tf.layers.Dense(n_out)\r\nnetwork = LazyNetwork(lambda x: l1(l0(x)))\r\n\r\nprint(n_vars())  # 0\r\nprint(network.built)  # False\r\nnetwork.build(base.Input((n_features,)))\r\nprint(n_vars())  # 4\r\nprint(network.built)  # True\r\n```"}