{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18527", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18527/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18527/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18527/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18527", "id": 314377403, "node_id": "MDU6SXNzdWUzMTQzNzc0MDM=", "number": 18527, "title": "New implementation of `tf.clip_by_value` changes behavior of the op.", "user": {"login": "chihuahua", "id": 4221553, "node_id": "MDQ6VXNlcjQyMjE1NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/4221553?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chihuahua", "html_url": "https://github.com/chihuahua", "followers_url": "https://api.github.com/users/chihuahua/followers", "following_url": "https://api.github.com/users/chihuahua/following{/other_user}", "gists_url": "https://api.github.com/users/chihuahua/gists{/gist_id}", "starred_url": "https://api.github.com/users/chihuahua/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chihuahua/subscriptions", "organizations_url": "https://api.github.com/users/chihuahua/orgs", "repos_url": "https://api.github.com/users/chihuahua/repos", "events_url": "https://api.github.com/users/chihuahua/events{/privacy}", "received_events_url": "https://api.github.com/users/chihuahua/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-04-15T01:43:56Z", "updated_at": "2018-04-26T06:31:41Z", "closed_at": "2018-04-26T06:31:41Z", "author_association": "MEMBER", "body_html": "<p>FYI, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=49262\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jart\">@jart</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710113\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nfelt\">@nfelt</a></p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Debian GNU/Linux (upgraded from: Ubuntu 14.04.5 LTS)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary (pip package)</li>\n<li><strong>TensorFlow version (use command below)</strong>: Nightly 1.8.0 build 254 (<code>tf-nightly</code>)</li>\n<li><strong>Python version</strong>: Python 2.7.13</li>\n<li><strong>Exact command to reproduce within TensorBoard's repository</strong>:<br>\nbazel test //tensorboard/plugins/pr_curve:pr_curves_plugin_test</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Every night, TensorBoard's python tests on travis installs the latest nightly version of TensorFlow. One day, I find that TensorBoard's <code>:pr_curves_plugin_test</code> is failing for python 2.<br>\n<a href=\"https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\">https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py</a><br>\nInterestingly, the test still passes for python 3.</p>\n<p>I confirmed that the test succeeds if I install <code>tf-nightly</code> build 253 and then <code>bazel test</code> the target within <a href=\"https://github.com/tensorflow/tensorboard\">TensorBoard's repo</a>.</p>\n<pre><code>pip install -I https://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/253/artifact/pip_test/whl/tf_nightly-1.8.0.dev20180409-cp27-cp27mu-linux_x86_64.whl\n</code></pre>\n<p>The <code>:pr_curves_plugin_test</code> fails if I install <code>tf-nightly</code> build 254.</p>\n<pre><code>pip install -I https://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/254/artifact/pip_test/whl/tf_nightly-1.8.0.dev20180410-cp27-cp27mu-linux_x86_64.whl\n</code></pre>\n<p>Therefore, a TensorFlow change introduced to build 254 seems to be a likely cause. During <code>setUp</code>, the <code>:pr_curves_plugin_test</code> runs a <a href=\"https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curve_demo.py\">demo script</a> that <a href=\"https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curve_demo.py#L65\">seeds randomness</a> and then <a href=\"https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curve_demo.py#L68\">generates test data</a> from a <code>tf.distributions.Normal</code> distribution.</p>\n<p>Could any changes to TensorFlow's seeding or <code>tf.distributions.Normal</code> logic (introduced to build 254) cause this breakage? Regardless of how we fix <code>:pr_curves_plugin_test</code> (Either TensorBoard's test logic could change, or we could partially roll back a TensorFlow change.), I'm curious about the root cause of the difference in behavior. Thanks!</p>\n<h3>Source code / logs</h3>\n<p>Here are the logs for the failed test. They just describe how the floating point data derived from the PR curves plugin demo have changed.</p>\n<pre><code>Testing //.../plugins/pr_curve:pr_curves_plugin_test; 40s linux-sandbox\n...F....\n======================================================================\nFAIL: testPrCurvesDataCorrect (__main__.PrCurvesPluginTest)\nTests that responses for PR curves for run-tag combos are correct.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/travis/.bazel-output-base/bazel-sandbox/2643229171274820909/execroot/org_tensorflow_tensorboard/bazel-out/k8-fastbuild/bin/tensorboard/plugins/pr_curve/pr_curves_plugin_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\", line 217, in testPrCurvesDataCorrect\n    pr_curve_entry=entries[0])\n  File \"/home/travis/.bazel-output-base/bazel-sandbox/2643229171274820909/execroot/org_tensorflow_tensorboard/bazel-out/k8-fastbuild/bin/tensorboard/plugins/pr_curve/pr_curves_plugin_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\", line 87, in validatePrCurveEntry\n    assert_allclose(expected_precision, pr_curve_entry['precision'])\n  File \"/home/travis/virtualenv/python2.7.14/lib/python2.7/site-packages/numpy/testing/nose_tools/utils.py\", line 1396, in assert_allclose\n    verbose=verbose, header=header, equal_nan=equal_nan)\n  File \"/home/travis/virtualenv/python2.7.14/lib/python2.7/site-packages/numpy/testing/nose_tools/utils.py\", line 779, in assert_array_compare\n    raise AssertionError(msg)\nAssertionError: \nNot equal to tolerance rtol=0, atol=1e-07\n(mismatch 75.0%)\n x: array([0.333333, 0.385321, 0.542169, 0.75    ])\n y: array([0.333333, 0.391026, 0.630137, 0.666667])\n----------------------------------------------------------------------\nRan 8 tests in 38.439s\nFAILED (failures=1)\n================================================================================\n</code></pre>", "body_text": "FYI, @jart and @nfelt\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux (upgraded from: Ubuntu 14.04.5 LTS)\nTensorFlow installed from (source or binary): binary (pip package)\nTensorFlow version (use command below): Nightly 1.8.0 build 254 (tf-nightly)\nPython version: Python 2.7.13\nExact command to reproduce within TensorBoard's repository:\nbazel test //tensorboard/plugins/pr_curve:pr_curves_plugin_test\n\nDescribe the problem\nEvery night, TensorBoard's python tests on travis installs the latest nightly version of TensorFlow. One day, I find that TensorBoard's :pr_curves_plugin_test is failing for python 2.\nhttps://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\nInterestingly, the test still passes for python 3.\nI confirmed that the test succeeds if I install tf-nightly build 253 and then bazel test the target within TensorBoard's repo.\npip install -I https://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/253/artifact/pip_test/whl/tf_nightly-1.8.0.dev20180409-cp27-cp27mu-linux_x86_64.whl\n\nThe :pr_curves_plugin_test fails if I install tf-nightly build 254.\npip install -I https://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/254/artifact/pip_test/whl/tf_nightly-1.8.0.dev20180410-cp27-cp27mu-linux_x86_64.whl\n\nTherefore, a TensorFlow change introduced to build 254 seems to be a likely cause. During setUp, the :pr_curves_plugin_test runs a demo script that seeds randomness and then generates test data from a tf.distributions.Normal distribution.\nCould any changes to TensorFlow's seeding or tf.distributions.Normal logic (introduced to build 254) cause this breakage? Regardless of how we fix :pr_curves_plugin_test (Either TensorBoard's test logic could change, or we could partially roll back a TensorFlow change.), I'm curious about the root cause of the difference in behavior. Thanks!\nSource code / logs\nHere are the logs for the failed test. They just describe how the floating point data derived from the PR curves plugin demo have changed.\nTesting //.../plugins/pr_curve:pr_curves_plugin_test; 40s linux-sandbox\n...F....\n======================================================================\nFAIL: testPrCurvesDataCorrect (__main__.PrCurvesPluginTest)\nTests that responses for PR curves for run-tag combos are correct.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/travis/.bazel-output-base/bazel-sandbox/2643229171274820909/execroot/org_tensorflow_tensorboard/bazel-out/k8-fastbuild/bin/tensorboard/plugins/pr_curve/pr_curves_plugin_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\", line 217, in testPrCurvesDataCorrect\n    pr_curve_entry=entries[0])\n  File \"/home/travis/.bazel-output-base/bazel-sandbox/2643229171274820909/execroot/org_tensorflow_tensorboard/bazel-out/k8-fastbuild/bin/tensorboard/plugins/pr_curve/pr_curves_plugin_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\", line 87, in validatePrCurveEntry\n    assert_allclose(expected_precision, pr_curve_entry['precision'])\n  File \"/home/travis/virtualenv/python2.7.14/lib/python2.7/site-packages/numpy/testing/nose_tools/utils.py\", line 1396, in assert_allclose\n    verbose=verbose, header=header, equal_nan=equal_nan)\n  File \"/home/travis/virtualenv/python2.7.14/lib/python2.7/site-packages/numpy/testing/nose_tools/utils.py\", line 779, in assert_array_compare\n    raise AssertionError(msg)\nAssertionError: \nNot equal to tolerance rtol=0, atol=1e-07\n(mismatch 75.0%)\n x: array([0.333333, 0.385321, 0.542169, 0.75    ])\n y: array([0.333333, 0.391026, 0.630137, 0.666667])\n----------------------------------------------------------------------\nRan 8 tests in 38.439s\nFAILED (failures=1)\n================================================================================", "body": "FYI, @jart and @nfelt \r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux (upgraded from: Ubuntu 14.04.5 LTS)\r\n- **TensorFlow installed from (source or binary)**: binary (pip package)\r\n- **TensorFlow version (use command below)**: Nightly 1.8.0 build 254 (`tf-nightly`)\r\n- **Python version**: Python 2.7.13\r\n- **Exact command to reproduce within TensorBoard's repository**:\r\nbazel test //tensorboard/plugins/pr_curve:pr_curves_plugin_test\r\n\r\n### Describe the problem\r\nEvery night, TensorBoard's python tests on travis installs the latest nightly version of TensorFlow. One day, I find that TensorBoard's `:pr_curves_plugin_test` is failing for python 2.\r\nhttps://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\r\nInterestingly, the test still passes for python 3.\r\n\r\nI confirmed that the test succeeds if I install `tf-nightly` build 253 and then `bazel test` the target within [TensorBoard's repo](https://github.com/tensorflow/tensorboard).\r\n```\r\npip install -I https://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/253/artifact/pip_test/whl/tf_nightly-1.8.0.dev20180409-cp27-cp27mu-linux_x86_64.whl\r\n```\r\n\r\nThe `:pr_curves_plugin_test` fails if I install `tf-nightly` build 254.\r\n```\r\npip install -I https://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/254/artifact/pip_test/whl/tf_nightly-1.8.0.dev20180410-cp27-cp27mu-linux_x86_64.whl\r\n```\r\n\r\nTherefore, a TensorFlow change introduced to build 254 seems to be a likely cause. During `setUp`, the `:pr_curves_plugin_test` runs a [demo script](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curve_demo.py) that [seeds randomness](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curve_demo.py#L65) and then [generates test data](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/pr_curve_demo.py#L68) from a `tf.distributions.Normal` distribution.\r\n\r\nCould any changes to TensorFlow's seeding or `tf.distributions.Normal` logic (introduced to build 254) cause this breakage? Regardless of how we fix `:pr_curves_plugin_test` (Either TensorBoard's test logic could change, or we could partially roll back a TensorFlow change.), I'm curious about the root cause of the difference in behavior. Thanks! \r\n\r\n### Source code / logs\r\n\r\nHere are the logs for the failed test. They just describe how the floating point data derived from the PR curves plugin demo have changed.\r\n\r\n```\r\nTesting //.../plugins/pr_curve:pr_curves_plugin_test; 40s linux-sandbox\r\n...F....\r\n======================================================================\r\nFAIL: testPrCurvesDataCorrect (__main__.PrCurvesPluginTest)\r\nTests that responses for PR curves for run-tag combos are correct.\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/travis/.bazel-output-base/bazel-sandbox/2643229171274820909/execroot/org_tensorflow_tensorboard/bazel-out/k8-fastbuild/bin/tensorboard/plugins/pr_curve/pr_curves_plugin_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\", line 217, in testPrCurvesDataCorrect\r\n    pr_curve_entry=entries[0])\r\n  File \"/home/travis/.bazel-output-base/bazel-sandbox/2643229171274820909/execroot/org_tensorflow_tensorboard/bazel-out/k8-fastbuild/bin/tensorboard/plugins/pr_curve/pr_curves_plugin_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/pr_curves_plugin_test.py\", line 87, in validatePrCurveEntry\r\n    assert_allclose(expected_precision, pr_curve_entry['precision'])\r\n  File \"/home/travis/virtualenv/python2.7.14/lib/python2.7/site-packages/numpy/testing/nose_tools/utils.py\", line 1396, in assert_allclose\r\n    verbose=verbose, header=header, equal_nan=equal_nan)\r\n  File \"/home/travis/virtualenv/python2.7.14/lib/python2.7/site-packages/numpy/testing/nose_tools/utils.py\", line 779, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError: \r\nNot equal to tolerance rtol=0, atol=1e-07\r\n(mismatch 75.0%)\r\n x: array([0.333333, 0.385321, 0.542169, 0.75    ])\r\n y: array([0.333333, 0.391026, 0.630137, 0.666667])\r\n----------------------------------------------------------------------\r\nRan 8 tests in 38.439s\r\nFAILED (failures=1)\r\n================================================================================\r\n```\r\n"}