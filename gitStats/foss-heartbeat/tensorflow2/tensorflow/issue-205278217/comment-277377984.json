{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277377984", "html_url": "https://github.com/tensorflow/tensorflow/issues/7251#issuecomment-277377984", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7251", "id": 277377984, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NzM3Nzk4NA==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-03T22:18:48Z", "updated_at": "2017-02-03T23:22:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is probably due to the following <code>HostMemory</code> annotations in definition of DynamicStitch in <a href=\"https://github.com/tensorflow/tensorflow/blob/27711108b5fce2e1692f9440631a183b3808fa01/tensorflow/core/kernels/dynamic_stitch_op.cc#L184\">dynamic_stitch_op.cc</a></p>\n<pre><code>#define REGISTER_DYNAMIC_STITCH_GPU(type)                \\\n  REGISTER_KERNEL_BUILDER(Name(\"DynamicStitch\")          \\\n                              .Device(DEVICE_GPU)        \\\n                              .TypeConstraint&lt;type&gt;(\"T\") \\\n                              .HostMemory(\"indices\")     \\\n                              .HostMemory(\"data\")        \\\n                              .HostMemory(\"merged\"),     \\\n                          DynamicStitchOp&lt;type&gt;)\n</code></pre>\n<p>Now if you look at <a href=\"https://github.com/tensorflow/tensorflow/blob/b00fc538638f87ac45be9105057b9865f0f9418b/tensorflow/core/ops/data_flow_ops.cc#L112\">data_flow_ops.cc</a>, you see this</p>\n<pre><code>REGISTER_OP(\"DynamicStitch\")\n    .Input(\"indices: N * int32\")\n    .Input(\"data: N * T\")\n    .Output(\"merged: T\")\n    .Attr(\"N : int &gt;= 1\")\n</code></pre>\n<p>This means that GPU implementation of DynamicStitch keeps all of its inputs and outputs in main memory. It may seem useless to have this kind of implementation, but it reduces overhead in some cases - it could make sense to place the op on <code>/gpu:0</code> logical device to avoid having to cross the logical device boundary, even though an op the op would actually use CPU hardware resources to compute things.</p>", "body_text": "This is probably due to the following HostMemory annotations in definition of DynamicStitch in dynamic_stitch_op.cc\n#define REGISTER_DYNAMIC_STITCH_GPU(type)                \\\n  REGISTER_KERNEL_BUILDER(Name(\"DynamicStitch\")          \\\n                              .Device(DEVICE_GPU)        \\\n                              .TypeConstraint<type>(\"T\") \\\n                              .HostMemory(\"indices\")     \\\n                              .HostMemory(\"data\")        \\\n                              .HostMemory(\"merged\"),     \\\n                          DynamicStitchOp<type>)\n\nNow if you look at data_flow_ops.cc, you see this\nREGISTER_OP(\"DynamicStitch\")\n    .Input(\"indices: N * int32\")\n    .Input(\"data: N * T\")\n    .Output(\"merged: T\")\n    .Attr(\"N : int >= 1\")\n\nThis means that GPU implementation of DynamicStitch keeps all of its inputs and outputs in main memory. It may seem useless to have this kind of implementation, but it reduces overhead in some cases - it could make sense to place the op on /gpu:0 logical device to avoid having to cross the logical device boundary, even though an op the op would actually use CPU hardware resources to compute things.", "body": "This is probably due to the following `HostMemory` annotations in definition of DynamicStitch in [dynamic_stitch_op.cc](https://github.com/tensorflow/tensorflow/blob/27711108b5fce2e1692f9440631a183b3808fa01/tensorflow/core/kernels/dynamic_stitch_op.cc#L184)\r\n\r\n```\r\n#define REGISTER_DYNAMIC_STITCH_GPU(type)                \\\r\n  REGISTER_KERNEL_BUILDER(Name(\"DynamicStitch\")          \\\r\n                              .Device(DEVICE_GPU)        \\\r\n                              .TypeConstraint<type>(\"T\") \\\r\n                              .HostMemory(\"indices\")     \\\r\n                              .HostMemory(\"data\")        \\\r\n                              .HostMemory(\"merged\"),     \\\r\n                          DynamicStitchOp<type>)\r\n```\r\n\r\nNow if you look at [data_flow_ops.cc](https://github.com/tensorflow/tensorflow/blob/b00fc538638f87ac45be9105057b9865f0f9418b/tensorflow/core/ops/data_flow_ops.cc#L112), you see this\r\n\r\n```\r\nREGISTER_OP(\"DynamicStitch\")\r\n    .Input(\"indices: N * int32\")\r\n    .Input(\"data: N * T\")\r\n    .Output(\"merged: T\")\r\n    .Attr(\"N : int >= 1\")\r\n```\r\n\r\nThis means that GPU implementation of DynamicStitch keeps all of its inputs and outputs in main memory. It may seem useless to have this kind of implementation, but it reduces overhead in some cases - it could make sense to place the op on `/gpu:0` logical device to avoid having to cross the logical device boundary, even though an op the op would actually use CPU hardware resources to compute things."}