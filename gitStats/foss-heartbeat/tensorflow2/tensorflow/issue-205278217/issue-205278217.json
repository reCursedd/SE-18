{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7251", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7251/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7251/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7251/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7251", "id": 205278217, "node_id": "MDU6SXNzdWUyMDUyNzgyMTc=", "number": 7251, "title": "Native GPU version of `tf.dynamic_stitch`", "user": {"login": "drasmuss", "id": 1952220, "node_id": "MDQ6VXNlcjE5NTIyMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1952220?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drasmuss", "html_url": "https://github.com/drasmuss", "followers_url": "https://api.github.com/users/drasmuss/followers", "following_url": "https://api.github.com/users/drasmuss/following{/other_user}", "gists_url": "https://api.github.com/users/drasmuss/gists{/gist_id}", "starred_url": "https://api.github.com/users/drasmuss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drasmuss/subscriptions", "organizations_url": "https://api.github.com/users/drasmuss/orgs", "repos_url": "https://api.github.com/users/drasmuss/repos", "events_url": "https://api.github.com/users/drasmuss/events{/privacy}", "received_events_url": "https://api.github.com/users/drasmuss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2017-02-03T21:48:30Z", "updated_at": "2018-02-08T01:06:26Z", "closed_at": "2018-02-08T01:06:26Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Windows 10</p>\n<p>Installed version of CUDA and cuDNN: 8.0, 5105<br>\ntensorflow release 0.12.1</p>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.client.timeline <span class=\"pl-k\">import</span> Timeline\n\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:0<span class=\"pl-pds\">\"</span></span>):\n    x <span class=\"pl-k\">=</span> tf.ones(<span class=\"pl-c1\">100</span>)\n    idxs <span class=\"pl-k\">=</span> tf.range(<span class=\"pl-c1\">100</span>)\n\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n        y <span class=\"pl-k\">=</span> tf.identity(x)\n        x <span class=\"pl-k\">=</span> tf.dynamic_stitch([idxs, idxs], [x, y])\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> x = tf.gather(y, idxs)</span>\n\n<span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>tf.ConfigProto(<span class=\"pl-v\">log_device_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)) <span class=\"pl-k\">as</span> sess:\n    metadata <span class=\"pl-k\">=</span> tf.RunMetadata()\n    sess.run(x, <span class=\"pl-v\">options</span><span class=\"pl-k\">=</span>tf.RunOptions(<span class=\"pl-v\">trace_level</span><span class=\"pl-k\">=</span>tf.RunOptions.<span class=\"pl-c1\">FULL_TRACE</span>),\n             <span class=\"pl-v\">run_metadata</span><span class=\"pl-k\">=</span>metadata)\n\ntimeline <span class=\"pl-k\">=</span> Timeline(metadata.step_stats)\n<span class=\"pl-k\">with</span> <span class=\"pl-c1\">open</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>profile.json<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>w<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> f:\n    f.write(timeline.generate_chrome_trace_format())</pre></div>\n<p>The <code>log_device_placement</code> output shows that everything is assigned to the GPU, as expected.  However, inspecting the trace output shows that data is being copied on and off the GPU for each call to <code>dynamic_stitch</code>.  This is something specific to the <code>dynamic_stitch</code> implementation, because using <code>tf.gather</code> (a similar indexed read operation, and functionally equivalent in this case), doesn't show this behaviour.</p>\n<p>Is this intended behaviour for <code>dynamic_stitch</code> (i.e., the copying to and from the GPU is necessary)?  Or is this a bug?  If it isn't a bug, is there some equivalent solution that doesn't require the data to be copied back and forth?</p>", "body_text": "Environment info\nOperating System: Windows 10\nInstalled version of CUDA and cuDNN: 8.0, 5105\ntensorflow release 0.12.1\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nimport tensorflow as tf\nfrom tensorflow.python.client.timeline import Timeline\n\nwith tf.device(\"/gpu:0\"):\n    x = tf.ones(100)\n    idxs = tf.range(100)\n\n    for _ in range(10):\n        y = tf.identity(x)\n        x = tf.dynamic_stitch([idxs, idxs], [x, y])\n        # x = tf.gather(y, idxs)\n\nwith tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n    metadata = tf.RunMetadata()\n    sess.run(x, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n             run_metadata=metadata)\n\ntimeline = Timeline(metadata.step_stats)\nwith open(\"profile.json\", \"w\") as f:\n    f.write(timeline.generate_chrome_trace_format())\nThe log_device_placement output shows that everything is assigned to the GPU, as expected.  However, inspecting the trace output shows that data is being copied on and off the GPU for each call to dynamic_stitch.  This is something specific to the dynamic_stitch implementation, because using tf.gather (a similar indexed read operation, and functionally equivalent in this case), doesn't show this behaviour.\nIs this intended behaviour for dynamic_stitch (i.e., the copying to and from the GPU is necessary)?  Or is this a bug?  If it isn't a bug, is there some equivalent solution that doesn't require the data to be copied back and forth?", "body": "### Environment info\r\nOperating System: Windows 10\r\n\r\nInstalled version of CUDA and cuDNN: 8.0, 5105\r\ntensorflow release 0.12.1\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n``` python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client.timeline import Timeline\r\n\r\nwith tf.device(\"/gpu:0\"):\r\n    x = tf.ones(100)\r\n    idxs = tf.range(100)\r\n\r\n    for _ in range(10):\r\n        y = tf.identity(x)\r\n        x = tf.dynamic_stitch([idxs, idxs], [x, y])\r\n        # x = tf.gather(y, idxs)\r\n\r\nwith tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\r\n    metadata = tf.RunMetadata()\r\n    sess.run(x, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\r\n             run_metadata=metadata)\r\n\r\ntimeline = Timeline(metadata.step_stats)\r\nwith open(\"profile.json\", \"w\") as f:\r\n    f.write(timeline.generate_chrome_trace_format())\r\n```\r\n\r\nThe `log_device_placement` output shows that everything is assigned to the GPU, as expected.  However, inspecting the trace output shows that data is being copied on and off the GPU for each call to `dynamic_stitch`.  This is something specific to the `dynamic_stitch` implementation, because using `tf.gather` (a similar indexed read operation, and functionally equivalent in this case), doesn't show this behaviour.\r\n\r\nIs this intended behaviour for `dynamic_stitch` (i.e., the copying to and from the GPU is necessary)?  Or is this a bug?  If it isn't a bug, is there some equivalent solution that doesn't require the data to be copied back and forth?"}