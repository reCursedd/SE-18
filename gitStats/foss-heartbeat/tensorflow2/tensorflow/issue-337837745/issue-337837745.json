{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20511", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20511/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20511/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20511/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20511", "id": 337837745, "node_id": "MDU6SXNzdWUzMzc4Mzc3NDU=", "number": 20511, "title": "How to use pre-train cnn model with tensorflow-go", "user": {"login": "qianlnk", "id": 9543166, "node_id": "MDQ6VXNlcjk1NDMxNjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/9543166?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qianlnk", "html_url": "https://github.com/qianlnk", "followers_url": "https://api.github.com/users/qianlnk/followers", "following_url": "https://api.github.com/users/qianlnk/following{/other_user}", "gists_url": "https://api.github.com/users/qianlnk/gists{/gist_id}", "starred_url": "https://api.github.com/users/qianlnk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qianlnk/subscriptions", "organizations_url": "https://api.github.com/users/qianlnk/orgs", "repos_url": "https://api.github.com/users/qianlnk/repos", "events_url": "https://api.github.com/users/qianlnk/events{/privacy}", "received_events_url": "https://api.github.com/users/qianlnk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-07-03T10:25:53Z", "updated_at": "2018-07-11T02:46:26Z", "closed_at": "2018-07-11T02:46:26Z", "author_association": "NONE", "body_html": "<p>Hi all,</p>\n<p>I had train a cnn model with python, it has 57 inputs, one hidden layer with 12nodes, 3 output, and save the model as follow:</p>\n<div class=\"highlight highlight-source-python\"><pre>        builder <span class=\"pl-k\">=</span> tf.saved_model.builder.SavedModelBuilder(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>shield<span class=\"pl-pds\">'</span></span>)\n        builder.add_meta_graph_and_variables(<span class=\"pl-c1\">self</span>.sess, [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>login3<span class=\"pl-pds\">'</span></span>])\n        builder.save()</pre></div>\n<p>then load it:</p>\n<div class=\"highlight highlight-source-go\"><pre>\t<span class=\"pl-smi\">model</span>, <span class=\"pl-smi\">err</span> <span class=\"pl-k\">:=</span> tf.<span class=\"pl-c1\">LoadSavedModel</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>shield<span class=\"pl-pds\">\"</span></span>, []<span class=\"pl-k\">string</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>login3<span class=\"pl-pds\">\"</span></span>}, <span class=\"pl-c1\">nil</span>)</pre></div>\n<p>but I got error like:</p>\n<div class=\"highlight highlight-source-shell\"><pre>2018-07-03 18:23:14.476427: I tensorflow/cc/saved_model/loader.cc:242] Loading SavedModel with tags: { login3 }<span class=\"pl-k\">;</span> from: shield\n2018-07-03 18:23:14.481530: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n2018-07-03 18:23:14.486676: I tensorflow/cc/saved_model/loader.cc:161] Restoring SavedModel bundle.\n2018-07-03 18:23:14.500925: I tensorflow/cc/saved_model/loader.cc:196] Running LegacyInitOp on SavedModel bundle.\n2018-07-03 18:23:14.501650: I tensorflow/cc/saved_model/loader.cc:291] SavedModel load <span class=\"pl-k\">for</span> tags { login3 }<span class=\"pl-k\">;</span> Status: success. Took 25441 microseconds.\n2 In[0] is not a matrix\n\t [[Node: MatMul <span class=\"pl-k\">=</span> MatMul[T<span class=\"pl-k\">=</span>DT_FLOAT, _output_shapes<span class=\"pl-k\">=</span>[[<span class=\"pl-k\">?</span>,12]], transpose_a<span class=\"pl-k\">=</span>false, transpose_b<span class=\"pl-k\">=</span>false, _device<span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/device:CPU:0<span class=\"pl-pds\">\"</span></span>](_arg_input_0_0, Variable/read)]]</pre></div>\n<p>How to make it work?</p>\n<p>here is my all code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> pandas <span class=\"pl-k\">as</span> pd\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">NeturalNetwork</span>:\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">model_path</span>, <span class=\"pl-smi\">input_nodes</span>, <span class=\"pl-smi\">hidden_layer_nodes</span>, <span class=\"pl-smi\">output_nodes</span>, <span class=\"pl-smi\">learning_rate</span>):\n        <span class=\"pl-c1\">self</span>.input_nodes <span class=\"pl-k\">=</span> input_nodes\n        <span class=\"pl-c1\">self</span>.hidden_layer_nodes <span class=\"pl-k\">=</span> hidden_layer_nodes\n        <span class=\"pl-c1\">self</span>.output_nodes <span class=\"pl-k\">=</span> output_nodes\n        <span class=\"pl-c1\">self</span>.learning_rate <span class=\"pl-k\">=</span> learning_rate\n        <span class=\"pl-c1\">self</span>.model_path <span class=\"pl-k\">=</span> model_path\n        <span class=\"pl-c1\">self</span>.x_data <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, input_nodes], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">self</span>.y_target <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, output_nodes], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>target<span class=\"pl-pds\">\"</span></span>)\n\n        l1 <span class=\"pl-k\">=</span> add_layer(<span class=\"pl-c1\">self</span>.x_data, input_nodes, <span class=\"pl-c1\">self</span>.hidden_layer_nodes, <span class=\"pl-v\">activation_function</span><span class=\"pl-k\">=</span>tf.nn.relu)\n        <span class=\"pl-c1\">self</span>.prediction <span class=\"pl-k\">=</span> add_layer(l1, <span class=\"pl-c1\">self</span>.hidden_layer_nodes, output_nodes, <span class=\"pl-v\">activation_function</span><span class=\"pl-k\">=</span>tf.nn.softmax)\n\n        y_clipped <span class=\"pl-k\">=</span> tf.clip_by_value(<span class=\"pl-c1\">self</span>.prediction, <span class=\"pl-c1\">1e-10</span>, <span class=\"pl-c1\">1</span>)\n        <span class=\"pl-c1\">self</span>.loss <span class=\"pl-k\">=</span> <span class=\"pl-k\">-</span>tf.reduce_mean(tf.reduce_sum(<span class=\"pl-c1\">self</span>.y_target <span class=\"pl-k\">*</span> tf.log(y_clipped), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>))\n\n        <span class=\"pl-c1\">self</span>.optimizer <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.learning_rate).minimize(<span class=\"pl-c1\">self</span>.loss)\n    \n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> GO</span>\n        infer <span class=\"pl-k\">=</span> tf.argmax(<span class=\"pl-c1\">self</span>.prediction, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>infer<span class=\"pl-pds\">\"</span></span>)\n        correct_prediction <span class=\"pl-k\">=</span> tf.equal(infer, tf.argmax(<span class=\"pl-c1\">self</span>.y_target, <span class=\"pl-c1\">1</span>))\n        <span class=\"pl-c1\">self</span>.accuracy <span class=\"pl-k\">=</span> tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n        <span class=\"pl-c1\">self</span>.saver <span class=\"pl-k\">=</span> tf.train.Saver()\n\n        <span class=\"pl-c1\">self</span>.sess <span class=\"pl-k\">=</span> tf.Session()\n        init <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n        <span class=\"pl-c1\">self</span>.sess.run(init)\n\n        meta_path <span class=\"pl-k\">=</span> model_path <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/shield.nn.meta<span class=\"pl-pds\">'</span></span>\n        <span class=\"pl-k\">if</span> os.path.exists(meta_path):\n            nn_path <span class=\"pl-k\">=</span> model_path <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/shield.nn<span class=\"pl-pds\">'</span></span>\n            <span class=\"pl-c1\">self</span>.saver.restore(<span class=\"pl-c1\">self</span>.sess, nn_path)\n        <span class=\"pl-k\">else</span>:\n            <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>ERROR: no model or restore model fail<span class=\"pl-pds\">'</span></span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">Train</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">epoch</span>, <span class=\"pl-smi\">filenames</span>):\n        interval <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n\n        x, y <span class=\"pl-k\">=</span> load_dataset(filenames, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>ShieldResult<span class=\"pl-pds\">'</span></span>)\n        x_values, y_values <span class=\"pl-k\">=</span> shuffle(x, y)\n\n        x_train <span class=\"pl-k\">=</span> x_values\n        y_train <span class=\"pl-k\">=</span> y_values\n\n        test_size  <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10000</span>\n        x_test <span class=\"pl-k\">=</span> x_values[<span class=\"pl-k\">-</span>test_size:]\n        y_test <span class=\"pl-k\">=</span> y_values[<span class=\"pl-k\">-</span>test_size:]\n\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Training the model...<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">len</span>(x_train))\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1</span>, (epoch <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>)):\n            <span class=\"pl-c1\">self</span>.sess.run(<span class=\"pl-c1\">self</span>.optimizer, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{<span class=\"pl-c1\">self</span>.x_data: x_train, <span class=\"pl-c1\">self</span>.y_target: y_train})\n            <span class=\"pl-k\">if</span> i <span class=\"pl-k\">%</span> interval <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n                <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Epoch<span class=\"pl-pds\">'</span></span>, i, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>|<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Loss:<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">self</span>.sess.run(<span class=\"pl-c1\">self</span>.loss, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{<span class=\"pl-c1\">self</span>.x_data: x_train, <span class=\"pl-c1\">self</span>.y_target: y_train}))\n\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">self</span>.sess.run(<span class=\"pl-c1\">self</span>.accuracy, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{<span class=\"pl-c1\">self</span>.x_data: x_test, <span class=\"pl-c1\">self</span>.y_target: y_test}))\n\n        builder <span class=\"pl-k\">=</span> tf.saved_model.builder.SavedModelBuilder(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>shield<span class=\"pl-pds\">'</span></span>)\n        builder.add_meta_graph_and_variables(<span class=\"pl-c1\">self</span>.sess, [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>login3<span class=\"pl-pds\">'</span></span>])\n        builder.save()\n\n        <span class=\"pl-c1\">self</span>.saver.save(<span class=\"pl-c1\">self</span>.sess, <span class=\"pl-c1\">self</span>.model_path <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/shield.nn<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">Predict</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">filenames</span>):\n        x, y <span class=\"pl-k\">=</span> load_dataset(filenames, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>ShieldResult<span class=\"pl-pds\">'</span></span>)\n        x_values, y_values <span class=\"pl-k\">=</span> shuffle(x, y)\n\n        test_size  <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10000</span>\n        x_test <span class=\"pl-k\">=</span> x_values[<span class=\"pl-k\">-</span>test_size:]\n        y_test <span class=\"pl-k\">=</span> y_values[<span class=\"pl-k\">-</span>test_size:]\n\n        yes <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span> \n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(x_test)):\n            pred <span class=\"pl-k\">=</span> np.rint(<span class=\"pl-c1\">self</span>.sess.run(<span class=\"pl-c1\">self</span>.prediction, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{<span class=\"pl-c1\">self</span>.x_data: [x_test[i]]}))\n            <span class=\"pl-k\">if</span> (y_test[i] <span class=\"pl-k\">==</span> pred[<span class=\"pl-c1\">0</span>]).all():\n                <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>=== Actual:<span class=\"pl-pds\">'</span></span>, y_test[i], <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Predicted:<span class=\"pl-pds\">'</span></span>, pred[<span class=\"pl-c1\">0</span>])\n                yes <span class=\"pl-k\">=</span> yes <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n            <span class=\"pl-k\">else</span>:\n                <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>!!! Actual:<span class=\"pl-pds\">'</span></span>, y_test[i], <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Predicted:<span class=\"pl-pds\">'</span></span>, pred[<span class=\"pl-c1\">0</span>])\n\n        <span class=\"pl-c1\">print</span>(yes)\n        <span class=\"pl-c1\">print</span>(yes <span class=\"pl-k\">/</span> (<span class=\"pl-c1\">len</span>(x_test) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1.0</span>))\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">random_seed</span>():\n    seed <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1234</span>\n    np.random.seed(seed)\n    tf.set_random_seed(seed)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">load_dataset</span>(<span class=\"pl-smi\">filenames</span>, <span class=\"pl-smi\">resultField</span>):\n    dataset <span class=\"pl-k\">=</span> pd.read_csv(filenames[<span class=\"pl-c1\">0</span>])\n    dataset <span class=\"pl-k\">=</span> pd.get_dummies(dataset, <span class=\"pl-v\">columns</span><span class=\"pl-k\">=</span>[resultField]) <span class=\"pl-c\"><span class=\"pl-c\">#</span> One Hot Encoding</span>\n    values <span class=\"pl-k\">=</span> <span class=\"pl-c1\">list</span>(dataset.columns.values)\n\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(filenames)):\n        <span class=\"pl-k\">if</span> i <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n            <span class=\"pl-k\">continue</span>\n\n        tmpdataset <span class=\"pl-k\">=</span> pd.read_csv(filenames[i])\n        tmpdataset <span class=\"pl-k\">=</span> pd.get_dummies(tmpdataset, <span class=\"pl-v\">columns</span><span class=\"pl-k\">=</span>[resultField]) <span class=\"pl-c\"><span class=\"pl-c\">#</span> One Hot Encoding</span>\n        dataset <span class=\"pl-k\">=</span> dataset.append(tmpdataset)\n\n    y <span class=\"pl-k\">=</span> dataset[values[<span class=\"pl-k\">-</span><span class=\"pl-c1\">3</span>:]]\n    x <span class=\"pl-k\">=</span> dataset[values[<span class=\"pl-c1\">0</span>:<span class=\"pl-k\">-</span><span class=\"pl-c1\">3</span>]]\n\n    <span class=\"pl-k\">return</span> np.array(x, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>), np.array(y, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">shuffle</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>):\n    indices <span class=\"pl-k\">=</span> np.random.choice(<span class=\"pl-c1\">len</span>(x), <span class=\"pl-c1\">len</span>(x), <span class=\"pl-v\">replace</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    \n    <span class=\"pl-k\">return</span> x[indices], y[indices]\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">add_layer</span>(<span class=\"pl-smi\">inputs</span>, <span class=\"pl-smi\">in_size</span>, <span class=\"pl-smi\">out_size</span>, <span class=\"pl-smi\">activation_function</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    weights <span class=\"pl-k\">=</span> tf.Variable(tf.random_normal(<span class=\"pl-v\">shape</span> <span class=\"pl-k\">=</span> [in_size, out_size]))\n    biases <span class=\"pl-k\">=</span> tf.Variable(tf.random_normal(<span class=\"pl-v\">shape</span> <span class=\"pl-k\">=</span> [out_size]))\n\n    w_plus_b <span class=\"pl-k\">=</span> tf.matmul(inputs, weights) <span class=\"pl-k\">+</span> biases\n\n    <span class=\"pl-k\">if</span> activation_function <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n        outputs <span class=\"pl-k\">=</span> w_plus_b\n    <span class=\"pl-k\">else</span>:\n        outputs <span class=\"pl-k\">=</span> activation_function(w_plus_b)\n\n    <span class=\"pl-k\">return</span> outputs\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    epoch <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>(sys.argv[<span class=\"pl-c1\">1</span>])\n    node <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>(sys.argv[<span class=\"pl-c1\">2</span>])\n    rate <span class=\"pl-k\">=</span> <span class=\"pl-c1\">float</span>(sys.argv[<span class=\"pl-c1\">3</span>])\n    csv_num <span class=\"pl-k\">=</span> sys.argv[<span class=\"pl-c1\">4</span>]\n\n    <span class=\"pl-c1\">print</span>(epoch)\n    <span class=\"pl-c1\">print</span>(node)\n    <span class=\"pl-c1\">print</span>(rate)\n    <span class=\"pl-c1\">print</span>(csv_num)\n\n    random_seed()\n\n    ann <span class=\"pl-k\">=</span> NeturalNetwork(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>./shield-ai-engine<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">57</span>, node, <span class=\"pl-c1\">3</span>, rate)\n    csvs <span class=\"pl-k\">=</span> [\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>../data/deal/11_<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">+</span> csv_num <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>.csv<span class=\"pl-pds\">'</span></span>, \n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>../data/deal/12_<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">+</span> csv_num <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>.csv<span class=\"pl-pds\">'</span></span>,\n    ]\n\n    ann.Train(epoch, csvs)\n</pre></div>\n<div class=\"highlight highlight-source-go\"><pre><span class=\"pl-k\">package</span> main\n\n<span class=\"pl-k\">import</span> (\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>fmt<span class=\"pl-pds\">\"</span></span>\n\n\ttf <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>github.com/tensorflow/tensorflow/tensorflow/go<span class=\"pl-pds\">\"</span></span>\n)\n\n<span class=\"pl-k\">func</span> <span class=\"pl-en\">main</span>() {\n\t<span class=\"pl-smi\">model</span>, <span class=\"pl-smi\">err</span> <span class=\"pl-k\">:=</span> tf.<span class=\"pl-c1\">LoadSavedModel</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>shield<span class=\"pl-pds\">\"</span></span>, []<span class=\"pl-k\">string</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>login3<span class=\"pl-pds\">\"</span></span>}, <span class=\"pl-c1\">nil</span>)\n\t<span class=\"pl-k\">if</span> err != <span class=\"pl-c1\">nil</span> {\n\t\tfmt.<span class=\"pl-c1\">Println</span>(<span class=\"pl-c1\">1</span>, err)\n\t\t<span class=\"pl-k\">return</span>\n\t}\n\n\t<span class=\"pl-k\">defer</span> model.<span class=\"pl-smi\">Session</span>.<span class=\"pl-c1\">Close</span>()\n\n\t<span class=\"pl-smi\">output</span> <span class=\"pl-k\">:=</span> tf.<span class=\"pl-smi\">Output</span>{\n\t\tOp:    model.<span class=\"pl-smi\">Graph</span>.<span class=\"pl-c1\">Operation</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input<span class=\"pl-pds\">\"</span></span>),\n\t\tIndex: <span class=\"pl-c1\">0</span>,\n\t}\n\n\t<span class=\"pl-smi\">tensor</span>, <span class=\"pl-smi\">err</span> <span class=\"pl-k\">:=</span> tf.<span class=\"pl-c1\">NewTensor</span>([]<span class=\"pl-k\">float32</span>{\n\t\t<span class=\"pl-c1\">12</span>, <span class=\"pl-c1\">41</span>, <span class=\"pl-c1\">41</span>, <span class=\"pl-c1\">41</span>, <span class=\"pl-c1\">41</span>, <span class=\"pl-c1\">41</span>, <span class=\"pl-c1\">70</span>, <span class=\"pl-c1\">137</span>, <span class=\"pl-c1\">259</span>, <span class=\"pl-c1\">305</span>, <span class=\"pl-c1\">344</span>, <span class=\"pl-c1\">81</span>, <span class=\"pl-c1\">148</span>, <span class=\"pl-c1\">271</span>, <span class=\"pl-c1\">370</span>, <span class=\"pl-c1\">397</span>, <span class=\"pl-c1\">81</span>, <span class=\"pl-c1\">148</span>, <span class=\"pl-c1\">271</span>, <span class=\"pl-c1\">370</span>, <span class=\"pl-c1\">397</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">122</span>, <span class=\"pl-c1\">233</span>, <span class=\"pl-c1\">295</span>, <span class=\"pl-c1\">391</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">58</span>, <span class=\"pl-c1\">195</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">195</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">165</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>,\n\t})\n\n\t<span class=\"pl-smi\">target</span>, <span class=\"pl-smi\">err</span> <span class=\"pl-k\">:=</span> tf.<span class=\"pl-c1\">NewTensor</span>([]<span class=\"pl-k\">float32</span>{})\n\n\t<span class=\"pl-k\">if</span> err != <span class=\"pl-c1\">nil</span> {\n\t\tfmt.<span class=\"pl-c1\">Println</span>(<span class=\"pl-c1\">3</span>, err)\n\t}\n\n\t<span class=\"pl-smi\">feeds</span> <span class=\"pl-k\">:=</span> <span class=\"pl-k\">map</span>[tf.<span class=\"pl-smi\">Output</span>]*tf.<span class=\"pl-smi\">Tensor</span>{\n\t\toutput: tensor,\n\t\tmodel.<span class=\"pl-smi\">Graph</span>.<span class=\"pl-c1\">Operation</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>target<span class=\"pl-pds\">\"</span></span>).<span class=\"pl-c1\">Output</span>(<span class=\"pl-c1\">0</span>): target,\n\t}\n\n\t<span class=\"pl-smi\">fetches</span> <span class=\"pl-k\">:=</span> []tf.<span class=\"pl-smi\">Output</span>{\n\t\t{\n\t\t\tOp:    model.<span class=\"pl-smi\">Graph</span>.<span class=\"pl-c1\">Operation</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>infer<span class=\"pl-pds\">\"</span></span>),\n\t\t\tIndex: <span class=\"pl-c1\">0</span>,\n\t\t},\n\t}\n\n\t<span class=\"pl-smi\">result</span>, <span class=\"pl-smi\">err</span> <span class=\"pl-k\">:=</span> model.<span class=\"pl-smi\">Session</span>.<span class=\"pl-c1\">Run</span>(\n\t\tfeeds,\n\t\tfetches,\n\t\t<span class=\"pl-c1\">nil</span>,\n\t)\n\n\t<span class=\"pl-k\">if</span> err != <span class=\"pl-c1\">nil</span> {\n\t\tfmt.<span class=\"pl-c1\">Println</span>(<span class=\"pl-c1\">2</span>, err)\n\t\t<span class=\"pl-k\">return</span>\n\t}\n\n\tfmt.<span class=\"pl-c1\">Println</span>(result[<span class=\"pl-c1\">0</span>].<span class=\"pl-c1\">Value</span>())\n}\n</pre></div>", "body_text": "Hi all,\nI had train a cnn model with python, it has 57 inputs, one hidden layer with 12nodes, 3 output, and save the model as follow:\n        builder = tf.saved_model.builder.SavedModelBuilder('shield')\n        builder.add_meta_graph_and_variables(self.sess, ['login3'])\n        builder.save()\nthen load it:\n\tmodel, err := tf.LoadSavedModel(\"shield\", []string{\"login3\"}, nil)\nbut I got error like:\n2018-07-03 18:23:14.476427: I tensorflow/cc/saved_model/loader.cc:242] Loading SavedModel with tags: { login3 }; from: shield\n2018-07-03 18:23:14.481530: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n2018-07-03 18:23:14.486676: I tensorflow/cc/saved_model/loader.cc:161] Restoring SavedModel bundle.\n2018-07-03 18:23:14.500925: I tensorflow/cc/saved_model/loader.cc:196] Running LegacyInitOp on SavedModel bundle.\n2018-07-03 18:23:14.501650: I tensorflow/cc/saved_model/loader.cc:291] SavedModel load for tags { login3 }; Status: success. Took 25441 microseconds.\n2 In[0] is not a matrix\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, _output_shapes=[[?,12]], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_0_0, Variable/read)]]\nHow to make it work?\nhere is my all code:\nimport os\nimport sys\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\n\nclass NeturalNetwork:\n\n    def __init__(self, model_path, input_nodes, hidden_layer_nodes, output_nodes, learning_rate):\n        self.input_nodes = input_nodes\n        self.hidden_layer_nodes = hidden_layer_nodes\n        self.output_nodes = output_nodes\n        self.learning_rate = learning_rate\n        self.model_path = model_path\n        self.x_data = tf.placeholder(shape=[None, input_nodes], dtype=tf.float32, name=\"input\")\n        self.y_target = tf.placeholder(shape=[None, output_nodes], dtype=tf.float32, name=\"target\")\n\n        l1 = add_layer(self.x_data, input_nodes, self.hidden_layer_nodes, activation_function=tf.nn.relu)\n        self.prediction = add_layer(l1, self.hidden_layer_nodes, output_nodes, activation_function=tf.nn.softmax)\n\n        y_clipped = tf.clip_by_value(self.prediction, 1e-10, 1)\n        self.loss = -tf.reduce_mean(tf.reduce_sum(self.y_target * tf.log(y_clipped), axis=1))\n\n        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate).minimize(self.loss)\n    \n        # GO\n        infer = tf.argmax(self.prediction, 1, name=\"infer\")\n        correct_prediction = tf.equal(infer, tf.argmax(self.y_target, 1))\n        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n        self.saver = tf.train.Saver()\n\n        self.sess = tf.Session()\n        init = tf.global_variables_initializer()\n        self.sess.run(init)\n\n        meta_path = model_path + '/shield.nn.meta'\n        if os.path.exists(meta_path):\n            nn_path = model_path + '/shield.nn'\n            self.saver.restore(self.sess, nn_path)\n        else:\n            print 'ERROR: no model or restore model fail'\n\n    def Train(self, epoch, filenames):\n        interval = 5\n\n        x, y = load_dataset(filenames, 'ShieldResult')\n        x_values, y_values = shuffle(x, y)\n\n        x_train = x_values\n        y_train = y_values\n\n        test_size  = 10000\n        x_test = x_values[-test_size:]\n        y_test = y_values[-test_size:]\n\n        print('Training the model...', len(x_train))\n        for i in range(1, (epoch + 1)):\n            self.sess.run(self.optimizer, feed_dict={self.x_data: x_train, self.y_target: y_train})\n            if i % interval == 0:\n                print('Epoch', i, '|', 'Loss:', self.sess.run(self.loss, feed_dict={self.x_data: x_train, self.y_target: y_train}))\n\n        print(self.sess.run(self.accuracy, feed_dict={self.x_data: x_test, self.y_target: y_test}))\n\n        builder = tf.saved_model.builder.SavedModelBuilder('shield')\n        builder.add_meta_graph_and_variables(self.sess, ['login3'])\n        builder.save()\n\n        self.saver.save(self.sess, self.model_path + '/shield.nn')\n\n    def Predict(self, filenames):\n        x, y = load_dataset(filenames, 'ShieldResult')\n        x_values, y_values = shuffle(x, y)\n\n        test_size  = 10000\n        x_test = x_values[-test_size:]\n        y_test = y_values[-test_size:]\n\n        yes = 0 \n        for i in range(len(x_test)):\n            pred = np.rint(self.sess.run(self.prediction, feed_dict={self.x_data: [x_test[i]]}))\n            if (y_test[i] == pred[0]).all():\n                print('=== Actual:', y_test[i], 'Predicted:', pred[0])\n                yes = yes + 1\n            else:\n                print('!!! Actual:', y_test[i], 'Predicted:', pred[0])\n\n        print(yes)\n        print(yes / (len(x_test) * 1.0))\n\ndef random_seed():\n    seed = 1234\n    np.random.seed(seed)\n    tf.set_random_seed(seed)\n\ndef load_dataset(filenames, resultField):\n    dataset = pd.read_csv(filenames[0])\n    dataset = pd.get_dummies(dataset, columns=[resultField]) # One Hot Encoding\n    values = list(dataset.columns.values)\n\n    for i in range(len(filenames)):\n        if i == 0:\n            continue\n\n        tmpdataset = pd.read_csv(filenames[i])\n        tmpdataset = pd.get_dummies(tmpdataset, columns=[resultField]) # One Hot Encoding\n        dataset = dataset.append(tmpdataset)\n\n    y = dataset[values[-3:]]\n    x = dataset[values[0:-3]]\n\n    return np.array(x, dtype='float32'), np.array(y, dtype='float32')\n\ndef shuffle(x, y):\n    indices = np.random.choice(len(x), len(x), replace=False)\n    \n    return x[indices], y[indices]\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    weights = tf.Variable(tf.random_normal(shape = [in_size, out_size]))\n    biases = tf.Variable(tf.random_normal(shape = [out_size]))\n\n    w_plus_b = tf.matmul(inputs, weights) + biases\n\n    if activation_function is None:\n        outputs = w_plus_b\n    else:\n        outputs = activation_function(w_plus_b)\n\n    return outputs\n\nif __name__ == \"__main__\":\n    epoch = int(sys.argv[1])\n    node = int(sys.argv[2])\n    rate = float(sys.argv[3])\n    csv_num = sys.argv[4]\n\n    print(epoch)\n    print(node)\n    print(rate)\n    print(csv_num)\n\n    random_seed()\n\n    ann = NeturalNetwork('./shield-ai-engine', 57, node, 3, rate)\n    csvs = [\n        '../data/deal/11_' + csv_num + '.csv', \n        '../data/deal/12_' + csv_num + '.csv',\n    ]\n\n    ann.Train(epoch, csvs)\n\npackage main\n\nimport (\n\t\"fmt\"\n\n\ttf \"github.com/tensorflow/tensorflow/tensorflow/go\"\n)\n\nfunc main() {\n\tmodel, err := tf.LoadSavedModel(\"shield\", []string{\"login3\"}, nil)\n\tif err != nil {\n\t\tfmt.Println(1, err)\n\t\treturn\n\t}\n\n\tdefer model.Session.Close()\n\n\toutput := tf.Output{\n\t\tOp:    model.Graph.Operation(\"input\"),\n\t\tIndex: 0,\n\t}\n\n\ttensor, err := tf.NewTensor([]float32{\n\t\t12, 41, 41, 41, 41, 41, 70, 137, 259, 305, 344, 81, 148, 271, 370, 397, 81, 148, 271, 370, 397, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 64, 122, 233, 295, 391, 1, 58, 195, 1, 6, 4, 195, 1, 6, 4, 165, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n\t})\n\n\ttarget, err := tf.NewTensor([]float32{})\n\n\tif err != nil {\n\t\tfmt.Println(3, err)\n\t}\n\n\tfeeds := map[tf.Output]*tf.Tensor{\n\t\toutput: tensor,\n\t\tmodel.Graph.Operation(\"target\").Output(0): target,\n\t}\n\n\tfetches := []tf.Output{\n\t\t{\n\t\t\tOp:    model.Graph.Operation(\"infer\"),\n\t\t\tIndex: 0,\n\t\t},\n\t}\n\n\tresult, err := model.Session.Run(\n\t\tfeeds,\n\t\tfetches,\n\t\tnil,\n\t)\n\n\tif err != nil {\n\t\tfmt.Println(2, err)\n\t\treturn\n\t}\n\n\tfmt.Println(result[0].Value())\n}", "body": "Hi all,\r\n\r\nI had train a cnn model with python, it has 57 inputs, one hidden layer with 12nodes, 3 output, and save the model as follow:\r\n\r\n```py\r\n        builder = tf.saved_model.builder.SavedModelBuilder('shield')\r\n        builder.add_meta_graph_and_variables(self.sess, ['login3'])\r\n        builder.save()\r\n```\r\n\r\nthen load it:\r\n\r\n```go\r\n\tmodel, err := tf.LoadSavedModel(\"shield\", []string{\"login3\"}, nil)\r\n```\r\n\r\nbut I got error like:\r\n\r\n```sh\r\n2018-07-03 18:23:14.476427: I tensorflow/cc/saved_model/loader.cc:242] Loading SavedModel with tags: { login3 }; from: shield\r\n2018-07-03 18:23:14.481530: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\r\n2018-07-03 18:23:14.486676: I tensorflow/cc/saved_model/loader.cc:161] Restoring SavedModel bundle.\r\n2018-07-03 18:23:14.500925: I tensorflow/cc/saved_model/loader.cc:196] Running LegacyInitOp on SavedModel bundle.\r\n2018-07-03 18:23:14.501650: I tensorflow/cc/saved_model/loader.cc:291] SavedModel load for tags { login3 }; Status: success. Took 25441 microseconds.\r\n2 In[0] is not a matrix\r\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, _output_shapes=[[?,12]], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_0_0, Variable/read)]]\r\n```\r\n\r\nHow to make it work?\r\n\r\nhere is my all code:\r\n\r\n```py\r\nimport os\r\nimport sys\r\nimport tensorflow as tf\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nclass NeturalNetwork:\r\n\r\n    def __init__(self, model_path, input_nodes, hidden_layer_nodes, output_nodes, learning_rate):\r\n        self.input_nodes = input_nodes\r\n        self.hidden_layer_nodes = hidden_layer_nodes\r\n        self.output_nodes = output_nodes\r\n        self.learning_rate = learning_rate\r\n        self.model_path = model_path\r\n        self.x_data = tf.placeholder(shape=[None, input_nodes], dtype=tf.float32, name=\"input\")\r\n        self.y_target = tf.placeholder(shape=[None, output_nodes], dtype=tf.float32, name=\"target\")\r\n\r\n        l1 = add_layer(self.x_data, input_nodes, self.hidden_layer_nodes, activation_function=tf.nn.relu)\r\n        self.prediction = add_layer(l1, self.hidden_layer_nodes, output_nodes, activation_function=tf.nn.softmax)\r\n\r\n        y_clipped = tf.clip_by_value(self.prediction, 1e-10, 1)\r\n        self.loss = -tf.reduce_mean(tf.reduce_sum(self.y_target * tf.log(y_clipped), axis=1))\r\n\r\n        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate).minimize(self.loss)\r\n    \r\n        # GO\r\n        infer = tf.argmax(self.prediction, 1, name=\"infer\")\r\n        correct_prediction = tf.equal(infer, tf.argmax(self.y_target, 1))\r\n        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\n        self.saver = tf.train.Saver()\r\n\r\n        self.sess = tf.Session()\r\n        init = tf.global_variables_initializer()\r\n        self.sess.run(init)\r\n\r\n        meta_path = model_path + '/shield.nn.meta'\r\n        if os.path.exists(meta_path):\r\n            nn_path = model_path + '/shield.nn'\r\n            self.saver.restore(self.sess, nn_path)\r\n        else:\r\n            print 'ERROR: no model or restore model fail'\r\n\r\n    def Train(self, epoch, filenames):\r\n        interval = 5\r\n\r\n        x, y = load_dataset(filenames, 'ShieldResult')\r\n        x_values, y_values = shuffle(x, y)\r\n\r\n        x_train = x_values\r\n        y_train = y_values\r\n\r\n        test_size  = 10000\r\n        x_test = x_values[-test_size:]\r\n        y_test = y_values[-test_size:]\r\n\r\n        print('Training the model...', len(x_train))\r\n        for i in range(1, (epoch + 1)):\r\n            self.sess.run(self.optimizer, feed_dict={self.x_data: x_train, self.y_target: y_train})\r\n            if i % interval == 0:\r\n                print('Epoch', i, '|', 'Loss:', self.sess.run(self.loss, feed_dict={self.x_data: x_train, self.y_target: y_train}))\r\n\r\n        print(self.sess.run(self.accuracy, feed_dict={self.x_data: x_test, self.y_target: y_test}))\r\n\r\n        builder = tf.saved_model.builder.SavedModelBuilder('shield')\r\n        builder.add_meta_graph_and_variables(self.sess, ['login3'])\r\n        builder.save()\r\n\r\n        self.saver.save(self.sess, self.model_path + '/shield.nn')\r\n\r\n    def Predict(self, filenames):\r\n        x, y = load_dataset(filenames, 'ShieldResult')\r\n        x_values, y_values = shuffle(x, y)\r\n\r\n        test_size  = 10000\r\n        x_test = x_values[-test_size:]\r\n        y_test = y_values[-test_size:]\r\n\r\n        yes = 0 \r\n        for i in range(len(x_test)):\r\n            pred = np.rint(self.sess.run(self.prediction, feed_dict={self.x_data: [x_test[i]]}))\r\n            if (y_test[i] == pred[0]).all():\r\n                print('=== Actual:', y_test[i], 'Predicted:', pred[0])\r\n                yes = yes + 1\r\n            else:\r\n                print('!!! Actual:', y_test[i], 'Predicted:', pred[0])\r\n\r\n        print(yes)\r\n        print(yes / (len(x_test) * 1.0))\r\n\r\ndef random_seed():\r\n    seed = 1234\r\n    np.random.seed(seed)\r\n    tf.set_random_seed(seed)\r\n\r\ndef load_dataset(filenames, resultField):\r\n    dataset = pd.read_csv(filenames[0])\r\n    dataset = pd.get_dummies(dataset, columns=[resultField]) # One Hot Encoding\r\n    values = list(dataset.columns.values)\r\n\r\n    for i in range(len(filenames)):\r\n        if i == 0:\r\n            continue\r\n\r\n        tmpdataset = pd.read_csv(filenames[i])\r\n        tmpdataset = pd.get_dummies(tmpdataset, columns=[resultField]) # One Hot Encoding\r\n        dataset = dataset.append(tmpdataset)\r\n\r\n    y = dataset[values[-3:]]\r\n    x = dataset[values[0:-3]]\r\n\r\n    return np.array(x, dtype='float32'), np.array(y, dtype='float32')\r\n\r\ndef shuffle(x, y):\r\n    indices = np.random.choice(len(x), len(x), replace=False)\r\n    \r\n    return x[indices], y[indices]\r\n\r\ndef add_layer(inputs, in_size, out_size, activation_function=None):\r\n    weights = tf.Variable(tf.random_normal(shape = [in_size, out_size]))\r\n    biases = tf.Variable(tf.random_normal(shape = [out_size]))\r\n\r\n    w_plus_b = tf.matmul(inputs, weights) + biases\r\n\r\n    if activation_function is None:\r\n        outputs = w_plus_b\r\n    else:\r\n        outputs = activation_function(w_plus_b)\r\n\r\n    return outputs\r\n\r\nif __name__ == \"__main__\":\r\n    epoch = int(sys.argv[1])\r\n    node = int(sys.argv[2])\r\n    rate = float(sys.argv[3])\r\n    csv_num = sys.argv[4]\r\n\r\n    print(epoch)\r\n    print(node)\r\n    print(rate)\r\n    print(csv_num)\r\n\r\n    random_seed()\r\n\r\n    ann = NeturalNetwork('./shield-ai-engine', 57, node, 3, rate)\r\n    csvs = [\r\n        '../data/deal/11_' + csv_num + '.csv', \r\n        '../data/deal/12_' + csv_num + '.csv',\r\n    ]\r\n\r\n    ann.Train(epoch, csvs)\r\n\r\n```\r\n\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"fmt\"\r\n\r\n\ttf \"github.com/tensorflow/tensorflow/tensorflow/go\"\r\n)\r\n\r\nfunc main() {\r\n\tmodel, err := tf.LoadSavedModel(\"shield\", []string{\"login3\"}, nil)\r\n\tif err != nil {\r\n\t\tfmt.Println(1, err)\r\n\t\treturn\r\n\t}\r\n\r\n\tdefer model.Session.Close()\r\n\r\n\toutput := tf.Output{\r\n\t\tOp:    model.Graph.Operation(\"input\"),\r\n\t\tIndex: 0,\r\n\t}\r\n\r\n\ttensor, err := tf.NewTensor([]float32{\r\n\t\t12, 41, 41, 41, 41, 41, 70, 137, 259, 305, 344, 81, 148, 271, 370, 397, 81, 148, 271, 370, 397, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 64, 122, 233, 295, 391, 1, 58, 195, 1, 6, 4, 195, 1, 6, 4, 165, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\r\n\t})\r\n\r\n\ttarget, err := tf.NewTensor([]float32{})\r\n\r\n\tif err != nil {\r\n\t\tfmt.Println(3, err)\r\n\t}\r\n\r\n\tfeeds := map[tf.Output]*tf.Tensor{\r\n\t\toutput: tensor,\r\n\t\tmodel.Graph.Operation(\"target\").Output(0): target,\r\n\t}\r\n\r\n\tfetches := []tf.Output{\r\n\t\t{\r\n\t\t\tOp:    model.Graph.Operation(\"infer\"),\r\n\t\t\tIndex: 0,\r\n\t\t},\r\n\t}\r\n\r\n\tresult, err := model.Session.Run(\r\n\t\tfeeds,\r\n\t\tfetches,\r\n\t\tnil,\r\n\t)\r\n\r\n\tif err != nil {\r\n\t\tfmt.Println(2, err)\r\n\t\treturn\r\n\t}\r\n\r\n\tfmt.Println(result[0].Value())\r\n}\r\n\r\n```"}