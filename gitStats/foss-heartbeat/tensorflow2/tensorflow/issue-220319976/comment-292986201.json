{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/292986201", "html_url": "https://github.com/tensorflow/tensorflow/issues/9055#issuecomment-292986201", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9055", "id": 292986201, "node_id": "MDEyOklzc3VlQ29tbWVudDI5Mjk4NjIwMQ==", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-10T15:31:55Z", "updated_at": "2017-04-13T15:38:07Z", "author_association": "MEMBER", "body_html": "<p>I too would like to find a compromise to allow vector*matrix, matrix*vector to be expressed more concisely.</p>\n<p>However, we have not allowed this because it would be ambiguous in the presence of broadcasting (which we have not yet implemented) and batched matmul.</p>\n<p>One approach is that taken by numpy.matmul(<strong>a</strong>,<br>\n<strong>b</strong>) (<a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html\" rel=\"nofollow\">https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html</a>), which special cases rank(<strong>a</strong>) == 1 by implicitly promoting <strong>a</strong> to a 1 x n matrix. Likewise it promotes <strong>b</strong> to a m x 1 matrix for rank(<strong>b</strong>) == 1. For other ranks, the usual numpy broadcasting rules apply.</p>\n<p>The numpy approach is also not completely satisfactory, as I've seen (and written) several examples of code wanting to do batch_of_matrices * batch_of_vectors. An alternative to support this without extra code is to promote <strong>a</strong> of shape [k, l, ... n] =&gt; [k, l, ..., 1, n] when rank(<strong>a</strong>) == rank(<strong>b</strong>) - 1 (and similarly promote <strong>b</strong> of shape [s, t, ..., m] to [s,t,...,m,1] when rank(<strong>b</strong>) == rank(<strong>a</strong>) - 1.<br>\nBut this alternative is not compatible with Numpy broadcasting.</p>\n<p>So in the absence of a clear choice, we have left the functionality as is. I'd be curious to hear more opinions on this.</p>", "body_text": "I too would like to find a compromise to allow vector*matrix, matrix*vector to be expressed more concisely.\nHowever, we have not allowed this because it would be ambiguous in the presence of broadcasting (which we have not yet implemented) and batched matmul.\nOne approach is that taken by numpy.matmul(a,\nb) (https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html), which special cases rank(a) == 1 by implicitly promoting a to a 1 x n matrix. Likewise it promotes b to a m x 1 matrix for rank(b) == 1. For other ranks, the usual numpy broadcasting rules apply.\nThe numpy approach is also not completely satisfactory, as I've seen (and written) several examples of code wanting to do batch_of_matrices * batch_of_vectors. An alternative to support this without extra code is to promote a of shape [k, l, ... n] => [k, l, ..., 1, n] when rank(a) == rank(b) - 1 (and similarly promote b of shape [s, t, ..., m] to [s,t,...,m,1] when rank(b) == rank(a) - 1.\nBut this alternative is not compatible with Numpy broadcasting.\nSo in the absence of a clear choice, we have left the functionality as is. I'd be curious to hear more opinions on this.", "body": "I too would like to find a compromise to allow vector\\*matrix, matrix\\*vector to be expressed more concisely. \r\n\r\nHowever, we have not allowed this because it would be ambiguous in the presence of broadcasting (which we have not yet implemented) and batched matmul.  \r\n\r\nOne approach is that taken by numpy.matmul(**a**,\r\n **b**) (https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html), which special cases rank(**a**) == 1 by implicitly promoting **a** to a 1 x n matrix. Likewise it promotes **b** to a m x 1 matrix for rank(**b**) == 1. For other ranks, the usual numpy broadcasting rules apply. \r\n\r\nThe numpy approach is also not completely satisfactory, as I've seen (and written) several examples of code wanting to do batch_of_matrices * batch_of_vectors. An alternative to support this without extra code is to promote **a** of shape [k, l, ... n] => [k, l, ..., 1, n] when rank(**a**) == rank(**b**) - 1 (and similarly promote **b** of shape [s, t, ..., m] to [s,t,...,m,1] when rank(**b**) == rank(**a**) - 1.\r\nBut this alternative is not compatible with Numpy broadcasting.\r\n\r\nSo in the absence of a clear choice, we have left the functionality as is. I'd be curious to hear more opinions on this.\r\n"}