{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11493", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11493/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11493/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11493/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11493", "id": 242896394, "node_id": "MDU6SXNzdWUyNDI4OTYzOTQ=", "number": 11493, "title": "Using TF-slim DatasetDataProvider generate batch data, but get an error", "user": {"login": "szpssky", "id": 5045936, "node_id": "MDQ6VXNlcjUwNDU5MzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/5045936?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szpssky", "html_url": "https://github.com/szpssky", "followers_url": "https://api.github.com/users/szpssky/followers", "following_url": "https://api.github.com/users/szpssky/following{/other_user}", "gists_url": "https://api.github.com/users/szpssky/gists{/gist_id}", "starred_url": "https://api.github.com/users/szpssky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szpssky/subscriptions", "organizations_url": "https://api.github.com/users/szpssky/orgs", "repos_url": "https://api.github.com/users/szpssky/repos", "events_url": "https://api.github.com/users/szpssky/events{/privacy}", "received_events_url": "https://api.github.com/users/szpssky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-07-14T04:47:52Z", "updated_at": "2017-12-25T16:44:11Z", "closed_at": "2017-07-21T15:28:02Z", "author_association": "CONTRIBUTOR", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:macOS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.2.1</li>\n<li><strong>Python version</strong>: 3.5.0</li>\n</ul>\n<p>In the <a href=\"https://stackoverflow.com/search?q=slim+OutOfRangeError\" rel=\"nofollow\">StackOverflow</a> I find similar problems but no one answered.<br>\nPlease give me some advice. Thanks.</p>\n<pre><code>def read_and_decode():\n    file_pattern = './voc*.tfrecord'\n    keys_to_features = {\n        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n        'image/height': tf.FixedLenFeature([1], tf.int64),\n        'image/width': tf.FixedLenFeature([1], tf.int64),\n        'image/channels': tf.FixedLenFeature([1], tf.int64),\n        'image/shape': tf.FixedLenFeature([3], tf.int64),\n        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32),\n        'image/object/bbox/label': tf.VarLenFeature(dtype=tf.int64),\n        'image/object/bbox/difficult': tf.VarLenFeature(dtype=tf.int64),\n        'image/object/bbox/truncated': tf.VarLenFeature(dtype=tf.int64),\n    }\n    items_to_handlers = {\n        'image': slim.tfexample_decoder.Image('image/encoded', 'image/format'),\n        'shape': slim.tfexample_decoder.Tensor('image/shape'),\n        'object/bbox': slim.tfexample_decoder.BoundingBox(\n            ['ymin', 'xmin', 'ymax', 'xmax'], 'image/object/bbox/'),\n        'object/label': slim.tfexample_decoder.Tensor('image/object/bbox/label'),\n        'object/difficult': slim.tfexample_decoder.Tensor('image/object/bbox/difficult'),\n        'object/truncated': slim.tfexample_decoder.Tensor('image/object/bbox/truncated'),\n    }\n    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n    return slim.dataset.Dataset(\n        data_sources=file_pattern,\n        reader=tf.TFRecordReader,\n        num_samples=1,\n        decoder=decoder,\n        items_to_descriptions={},\n        num_classes=21)\n\n\nslim = tf.contrib.slim\ndataset = read_and_decode()\nprovider = slim.dataset_data_provider.DatasetDataProvider(dataset, num_readers=3, shuffle=False)\n\n[image, shape, glabels, gbboxes] = provider.get(['image', 'shape', 'object/label', 'object/bbox'])\nimage = tf.expand_dims(image, 0)\nimage = tf.image.resize_images(image, [224,224],tf.image.ResizeMethod.BILINEAR)\nglabels.set_shape([1])\n\nimg_batch, label_batch = tf.train.batch([image, glabels], 64, capacity=2000)\nwith tf.Session() as sess:\n    ini_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    sess.run(ini_op)\n    coord = tf.train.Coordinator()\n    thread = tf.train.start_queue_runners(sess=sess,coord=coord)\n    for i in range(2):\n        cur_example_batch,cur_label_batch = sess.run([img_batch,label_batch])\n        print(cur_example_batch.shape)\n    coord.request_stop()\n    coord.join(thread)\n</code></pre>\n<p>The error infomation:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1139, in _do_call\n    return fn(*args)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1121, in _run_fn\n    status, run_metadata)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/szp/Documents/github/RCNN/RCNN.py\", line 140, in &lt;module&gt;\n    cur_example_batch,cur_label_batch = sess.run([img_batch,label_batch])\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 789, in run\n    run_metadata_ptr)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 997, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\n    target_list, options, run_metadata)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1152, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\n\nCaused by op 'batch', defined at:\n  File \"/Users/szp/Documents/github/RCNN/RCNN.py\", line 133, in &lt;module&gt;\n    img_batch, label_batch = tf.train.batch([image, glabels], 64, capacity=2000)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 919, in batch\n    name=name)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 716, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 457, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\n</code></pre>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.2.1\nPython version: 3.5.0\n\nIn the StackOverflow I find similar problems but no one answered.\nPlease give me some advice. Thanks.\ndef read_and_decode():\n    file_pattern = './voc*.tfrecord'\n    keys_to_features = {\n        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n        'image/height': tf.FixedLenFeature([1], tf.int64),\n        'image/width': tf.FixedLenFeature([1], tf.int64),\n        'image/channels': tf.FixedLenFeature([1], tf.int64),\n        'image/shape': tf.FixedLenFeature([3], tf.int64),\n        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32),\n        'image/object/bbox/label': tf.VarLenFeature(dtype=tf.int64),\n        'image/object/bbox/difficult': tf.VarLenFeature(dtype=tf.int64),\n        'image/object/bbox/truncated': tf.VarLenFeature(dtype=tf.int64),\n    }\n    items_to_handlers = {\n        'image': slim.tfexample_decoder.Image('image/encoded', 'image/format'),\n        'shape': slim.tfexample_decoder.Tensor('image/shape'),\n        'object/bbox': slim.tfexample_decoder.BoundingBox(\n            ['ymin', 'xmin', 'ymax', 'xmax'], 'image/object/bbox/'),\n        'object/label': slim.tfexample_decoder.Tensor('image/object/bbox/label'),\n        'object/difficult': slim.tfexample_decoder.Tensor('image/object/bbox/difficult'),\n        'object/truncated': slim.tfexample_decoder.Tensor('image/object/bbox/truncated'),\n    }\n    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n    return slim.dataset.Dataset(\n        data_sources=file_pattern,\n        reader=tf.TFRecordReader,\n        num_samples=1,\n        decoder=decoder,\n        items_to_descriptions={},\n        num_classes=21)\n\n\nslim = tf.contrib.slim\ndataset = read_and_decode()\nprovider = slim.dataset_data_provider.DatasetDataProvider(dataset, num_readers=3, shuffle=False)\n\n[image, shape, glabels, gbboxes] = provider.get(['image', 'shape', 'object/label', 'object/bbox'])\nimage = tf.expand_dims(image, 0)\nimage = tf.image.resize_images(image, [224,224],tf.image.ResizeMethod.BILINEAR)\nglabels.set_shape([1])\n\nimg_batch, label_batch = tf.train.batch([image, glabels], 64, capacity=2000)\nwith tf.Session() as sess:\n    ini_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    sess.run(ini_op)\n    coord = tf.train.Coordinator()\n    thread = tf.train.start_queue_runners(sess=sess,coord=coord)\n    for i in range(2):\n        cur_example_batch,cur_label_batch = sess.run([img_batch,label_batch])\n        print(cur_example_batch.shape)\n    coord.request_stop()\n    coord.join(thread)\n\nThe error infomation:\nTraceback (most recent call last):\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1139, in _do_call\n    return fn(*args)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1121, in _run_fn\n    status, run_metadata)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/szp/Documents/github/RCNN/RCNN.py\", line 140, in <module>\n    cur_example_batch,cur_label_batch = sess.run([img_batch,label_batch])\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 789, in run\n    run_metadata_ptr)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 997, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\n    target_list, options, run_metadata)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1152, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\n\nCaused by op 'batch', defined at:\n  File \"/Users/szp/Documents/github/RCNN/RCNN.py\", line 133, in <module>\n    img_batch, label_batch = tf.train.batch([image, glabels], 64, capacity=2000)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 919, in batch\n    name=name)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 716, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 457, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]", "body": "------------------------\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:macOS\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.2.1\r\n- **Python version**: 3.5.0\r\n\r\nIn the [StackOverflow](https://stackoverflow.com/search?q=slim+OutOfRangeError) I find similar problems but no one answered.\r\nPlease give me some advice. Thanks.\r\n```\r\ndef read_and_decode():\r\n    file_pattern = './voc*.tfrecord'\r\n    keys_to_features = {\r\n        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\r\n        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\r\n        'image/height': tf.FixedLenFeature([1], tf.int64),\r\n        'image/width': tf.FixedLenFeature([1], tf.int64),\r\n        'image/channels': tf.FixedLenFeature([1], tf.int64),\r\n        'image/shape': tf.FixedLenFeature([3], tf.int64),\r\n        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\r\n        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\r\n        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\r\n        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32),\r\n        'image/object/bbox/label': tf.VarLenFeature(dtype=tf.int64),\r\n        'image/object/bbox/difficult': tf.VarLenFeature(dtype=tf.int64),\r\n        'image/object/bbox/truncated': tf.VarLenFeature(dtype=tf.int64),\r\n    }\r\n    items_to_handlers = {\r\n        'image': slim.tfexample_decoder.Image('image/encoded', 'image/format'),\r\n        'shape': slim.tfexample_decoder.Tensor('image/shape'),\r\n        'object/bbox': slim.tfexample_decoder.BoundingBox(\r\n            ['ymin', 'xmin', 'ymax', 'xmax'], 'image/object/bbox/'),\r\n        'object/label': slim.tfexample_decoder.Tensor('image/object/bbox/label'),\r\n        'object/difficult': slim.tfexample_decoder.Tensor('image/object/bbox/difficult'),\r\n        'object/truncated': slim.tfexample_decoder.Tensor('image/object/bbox/truncated'),\r\n    }\r\n    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\r\n    return slim.dataset.Dataset(\r\n        data_sources=file_pattern,\r\n        reader=tf.TFRecordReader,\r\n        num_samples=1,\r\n        decoder=decoder,\r\n        items_to_descriptions={},\r\n        num_classes=21)\r\n\r\n\r\nslim = tf.contrib.slim\r\ndataset = read_and_decode()\r\nprovider = slim.dataset_data_provider.DatasetDataProvider(dataset, num_readers=3, shuffle=False)\r\n\r\n[image, shape, glabels, gbboxes] = provider.get(['image', 'shape', 'object/label', 'object/bbox'])\r\nimage = tf.expand_dims(image, 0)\r\nimage = tf.image.resize_images(image, [224,224],tf.image.ResizeMethod.BILINEAR)\r\nglabels.set_shape([1])\r\n\r\nimg_batch, label_batch = tf.train.batch([image, glabels], 64, capacity=2000)\r\nwith tf.Session() as sess:\r\n    ini_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\n    sess.run(ini_op)\r\n    coord = tf.train.Coordinator()\r\n    thread = tf.train.start_queue_runners(sess=sess,coord=coord)\r\n    for i in range(2):\r\n        cur_example_batch,cur_label_batch = sess.run([img_batch,label_batch])\r\n        print(cur_example_batch.shape)\r\n    coord.request_stop()\r\n    coord.join(thread)\r\n```\r\n\r\nThe error infomation:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1139, in _do_call\r\n    return fn(*args)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1121, in _run_fn\r\n    status, run_metadata)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\r\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/szp/Documents/github/RCNN/RCNN.py\", line 140, in <module>\r\n    cur_example_batch,cur_label_batch = sess.run([img_batch,label_batch])\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 997, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1152, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\r\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\r\n\r\nCaused by op 'batch', defined at:\r\n  File \"/Users/szp/Documents/github/RCNN/RCNN.py\", line 133, in <module>\r\n    img_batch, label_batch = tf.train.batch([image, glabels], 64, capacity=2000)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 919, in batch\r\n    name=name)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 716, in _batch\r\n    dequeued = queue.dequeue_many(batch_size, name=name)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 457, in dequeue_many\r\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/Users/szp/Documents/github/Tianchi_MedicalAI/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nOutOfRangeError (see above for traceback): FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 64, current size 0)\r\n\t [[Node: batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/n)]]\r\n```\r\n\r\n"}