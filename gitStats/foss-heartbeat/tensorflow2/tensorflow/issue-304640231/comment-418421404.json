{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/418421404", "html_url": "https://github.com/tensorflow/tensorflow/issues/17669#issuecomment-418421404", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17669", "id": 418421404, "node_id": "MDEyOklzc3VlQ29tbWVudDQxODQyMTQwNA==", "user": {"login": "hendaboudegga", "id": 42771444, "node_id": "MDQ6VXNlcjQyNzcxNDQ0", "avatar_url": "https://avatars1.githubusercontent.com/u/42771444?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hendaboudegga", "html_url": "https://github.com/hendaboudegga", "followers_url": "https://api.github.com/users/hendaboudegga/followers", "following_url": "https://api.github.com/users/hendaboudegga/following{/other_user}", "gists_url": "https://api.github.com/users/hendaboudegga/gists{/gist_id}", "starred_url": "https://api.github.com/users/hendaboudegga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hendaboudegga/subscriptions", "organizations_url": "https://api.github.com/users/hendaboudegga/orgs", "repos_url": "https://api.github.com/users/hendaboudegga/repos", "events_url": "https://api.github.com/users/hendaboudegga/events{/privacy}", "received_events_url": "https://api.github.com/users/hendaboudegga/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-04T15:54:59Z", "updated_at": "2018-09-04T15:57:56Z", "author_association": "NONE", "body_html": "<p>hello,<br>\ni am beginner of tensorflow and Neural network, I am working on a semantic segmentation project with Neural network  mobilenet/Unet.<br>\ni reduce the batch size and i fix it to 1 and the image have the size 500*500.</p>\n<p>the machine utilised is 64 bit: lenovo i3 500,  RAM 4G, OS wind10</p>\n<p>when l run the training, i have the following error:</p>\n<p>Traceback (most recent call last):<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call<br>\nreturn fn(*args)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn<br>\noptions, feed_dict, fetch_list, target_list, run_metadata)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun<br>\nrun_metadata)<br>\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu<br>\n[[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]<br>\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\test-main.py\", line 283, in <br>\n_,current=sess.run([opt,cost],feed_dict={net_input:input_image_batch, net_output:segmented_image_batch})<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run<br>\nrun_metadata_ptr)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run<br>\nfeed_dict_tensor, options, run_metadata)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run<br>\nrun_metadata)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu<br>\n[[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]<br>\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.</p>\n<p>Caused by op 'BatchNorm_19/FusedBatchNorm', defined at:<br>\nFile \"\", line 1, in <br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\idlelib\\run.py\", line 124, in main<br>\nret = method(*args, **kwargs)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\idlelib\\run.py\", line 351, in runcode<br>\nexec(code, self.locals)<br>\nFile \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\test-main.py\", line 190, in <br>\nnetwork = build_mobile_unet(net_input, preset_model = args.model, num_classes=num_classes)<br>\nFile \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\MobileUNet.py\", line 80, in build_mobile_unet<br>\nb10 = DepthwiseSeparableConvBlock(b09, 512)<br>\nFile \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\MobileUNet.py\", line 25, in DepthwiseSeparableConvBlock<br>\nnet = slim.batch_norm(net, fused=True)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 183, in func_with_args<br>\nreturn func(*args, **current_args)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 650, in batch_norm<br>\noutputs = layer.apply(inputs, training=is_training)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 774, in apply<br>\nreturn self.<strong>call</strong>(inputs, *args, **kwargs)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 329, in <strong>call</strong><br>\noutputs = super(Layer, self).<strong>call</strong>(inputs, *args, **kwargs)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 703, in <strong>call</strong><br>\noutputs = self.call(inputs, *args, **kwargs)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 158, in call<br>\nreturn super(BatchNormalization, self).call(inputs, training=training)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 511, in call<br>\noutputs = self._fused_batch_norm(inputs, training=training)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 398, in _fused_batch_norm<br>\ntraining, _fused_batch_norm_training, _fused_batch_norm_inference)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\", line 51, in smart_cond<br>\npred, true_fn=true_fn, false_fn=false_fn, name=name)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\", line 54, in smart_cond<br>\nreturn true_fn()<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 384, in _fused_batch_norm_training<br>\ndata_format=self._data_format)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 906, in fused_batch_norm<br>\nname=name)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3810, in _fused_batch_norm<br>\nis_training=is_training, name=name)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op<br>\nop_def=op_def)<br>\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in <strong>init</strong><br>\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access</p>\n<p>ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu<br>\n[[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]<br>\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.</p>\n<p><strong>this is my following Neural network:</strong></p>\n<p>import os,time,cv2<br>\nimport tensorflow as tf<br>\nimport tensorflow.contrib.slim as slim<br>\nimport numpy as np</p>\n<p>def ConvBlock(inputs, n_filters, kernel_size=[3, 3]):<br>\n\"\"\"<br>\nBuilds the conv block for MobileNets<br>\nApply successivly a 2D convolution, BatchNormalization relu<br>\n\"\"\"<br>\n# Skip pointwise by setting num_outputs=Non<br>\nnet = slim.conv2d(inputs, n_filters, kernel_size=[1, 1], activation_fn=None)<br>\nnet = slim.batch_norm(net, fused=True)<br>\nnet = tf.nn.relu(net)<br>\nreturn net</p>\n<p>def DepthwiseSeparableConvBlock(inputs, n_filters, kernel_size=[3, 3]):<br>\n\"\"\"<br>\nBuilds the Depthwise Separable conv block for MobileNets<br>\nApply successivly a 2D separable convolution, BatchNormalization relu, conv, BatchNormalization, relu<br>\n\"\"\"<br>\n# Skip pointwise by setting num_outputs=None<br>\nnet = slim.separable_convolution2d(inputs, num_outputs=None, depth_multiplier=1, kernel_size=[3, 3], activation_fn=None)</p>\n<pre><code>net = slim.batch_norm(net, fused=True)\nnet = tf.nn.relu(net)\nnet = slim.conv2d(net, n_filters, kernel_size=[1, 1], activation_fn=None)\nnet = slim.batch_norm(net, fused=True)\nnet = tf.nn.relu(net)\nreturn net\n</code></pre>\n<p>def conv_transpose_block(inputs, n_filters, kernel_size=[3, 3]):<br>\n\"\"\"<br>\nBasic conv transpose block for Encoder-Decoder upsampling<br>\nApply successivly Transposed Convolution, BatchNormalization, ReLU nonlinearity<br>\n\"\"\"<br>\nnet = slim.conv2d_transpose(inputs, n_filters, kernel_size=[3, 3], stride=[2, 2], activation_fn=None)<br>\nnet= slim.batch_norm(net)<br>\nnet = tf.nn.relu(net)<br>\nreturn net</p>\n<p>def build_mobile_unet(inputs, preset_model, num_classes):</p>\n<pre><code>has_skip = False\nif preset_model == \"MobileUNet\":\n\thas_skip = False\nelif preset_model == \"MobileUNet-Skip\":\n\thas_skip = True\nelse:\n\traise ValueError(\"Unsupported MobileUNet model '%s'. This function only supports MobileUNet and MobileUNet-Skip\" % (preset_model))\n\n#####################\n# Downsampling block  #\n#####################\nb00 = ConvBlock(inputs, 32)\n\nb01 = DepthwiseSeparableConvBlock(b00, 64)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\n#skip_1 = net\n\nb02 = DepthwiseSeparableConvBlock(b01, 128)\nb03 = DepthwiseSeparableConvBlock(b02, 128)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX') #2x2 max pooling operation\n#skip_2 = net\n\nb04 = DepthwiseSeparableConvBlock(b03, 256)\nb05 = DepthwiseSeparableConvBlock(b04, 256)\n#net = DepthwiseSeparableConvBlock(net, 256)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\n#skip_3 = net\n\nb06 = DepthwiseSeparableConvBlock(b05, 512)\nb07 = DepthwiseSeparableConvBlock(b06, 512)\nb08 = DepthwiseSeparableConvBlock(b07, 512)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\n#skip_4 = net\n\n\nb09 = DepthwiseSeparableConvBlock(b08, 512)\nb10 = DepthwiseSeparableConvBlock(b09, 512)\nb11 = DepthwiseSeparableConvBlock(b10, 512)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\n#skip_5 = net\n\nb12 = DepthwiseSeparableConvBlock(b11, 1024)\nb13 = DepthwiseSeparableConvBlock(b12, 1024)\n##################################################\n##################################################\n\nfilters = int(512 * 1.0)\nnet_01 = conv_transpose_block(b13, filters)\nup1 = tf.add(net_01, b11)\nb14 = DepthwiseSeparableConvBlock(up1, filters)\n\n\n\nfilters = int(256 * 1.0)\nnet02 = conv_transpose_block(b14, filters)\nup2 = tf.add(net02, b05)\nb15 = DepthwiseSeparableConvBlock(up2, filters)\n\n\nfilters = int(128 * 1.0)\nnet03 = conv_transpose_block(b15, filters)\nup3 = tf.add(net03, b03)\nb16 = DepthwiseSeparableConvBlock(up3, filters)\n\n\nfilters = int(64 * 1.0)\nnet04=conv_transpose_block(b16, filters)\nup4 = tf.add(net04, b01)\nb17= DepthwiseSeparableConvBlock(up4, filters)\n\n\nfilters = int(32 * 1.0)\nnet05=conv_transpose_block(b17, filters)\nup5 = tf.add(net05, b00)\nb18 = ConvBlock(up5, filters)\n\n\n#net = slim.conv2d(b18, num_classes, [1, 1], activation_fn='linear', scope='logits')\nnet = slim.conv2d(b18, num_classes, [1, 1], activation_fn=None, scope='logits')\n#net = BilinearUpSampling2D(net, size=(2, 2))\nnet = tf.sigmoid(net,name=None)\n\n\nreturn net\n</code></pre>\n<p>can someone help me, and sorry for the poor english</p>", "body_text": "hello,\ni am beginner of tensorflow and Neural network, I am working on a semantic segmentation project with Neural network  mobilenet/Unet.\ni reduce the batch size and i fix it to 1 and the image have the size 500*500.\nthe machine utilised is 64 bit: lenovo i3 500,  RAM 4G, OS wind10\nwhen l run the training, i have the following error:\nTraceback (most recent call last):\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\nreturn fn(*args)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\noptions, feed_dict, fetch_list, target_list, run_metadata)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\nrun_metadata)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n[[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\test-main.py\", line 283, in \n_,current=sess.run([opt,cost],feed_dict={net_input:input_image_batch, net_output:segmented_image_batch})\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\nrun_metadata_ptr)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\nfeed_dict_tensor, options, run_metadata)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\nrun_metadata)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n[[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\nCaused by op 'BatchNorm_19/FusedBatchNorm', defined at:\nFile \"\", line 1, in \nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\idlelib\\run.py\", line 124, in main\nret = method(*args, **kwargs)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\idlelib\\run.py\", line 351, in runcode\nexec(code, self.locals)\nFile \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\test-main.py\", line 190, in \nnetwork = build_mobile_unet(net_input, preset_model = args.model, num_classes=num_classes)\nFile \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\MobileUNet.py\", line 80, in build_mobile_unet\nb10 = DepthwiseSeparableConvBlock(b09, 512)\nFile \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\MobileUNet.py\", line 25, in DepthwiseSeparableConvBlock\nnet = slim.batch_norm(net, fused=True)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 183, in func_with_args\nreturn func(*args, **current_args)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 650, in batch_norm\noutputs = layer.apply(inputs, training=is_training)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 774, in apply\nreturn self.call(inputs, *args, **kwargs)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 329, in call\noutputs = super(Layer, self).call(inputs, *args, **kwargs)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 703, in call\noutputs = self.call(inputs, *args, **kwargs)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 158, in call\nreturn super(BatchNormalization, self).call(inputs, training=training)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 511, in call\noutputs = self._fused_batch_norm(inputs, training=training)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 398, in _fused_batch_norm\ntraining, _fused_batch_norm_training, _fused_batch_norm_inference)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\", line 51, in smart_cond\npred, true_fn=true_fn, false_fn=false_fn, name=name)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\", line 54, in smart_cond\nreturn true_fn()\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 384, in _fused_batch_norm_training\ndata_format=self._data_format)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 906, in fused_batch_norm\nname=name)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3810, in _fused_batch_norm\nis_training=is_training, name=name)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\nop_def=op_def)\nFile \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in init\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n[[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\nthis is my following Neural network:\nimport os,time,cv2\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\ndef ConvBlock(inputs, n_filters, kernel_size=[3, 3]):\n\"\"\"\nBuilds the conv block for MobileNets\nApply successivly a 2D convolution, BatchNormalization relu\n\"\"\"\n# Skip pointwise by setting num_outputs=Non\nnet = slim.conv2d(inputs, n_filters, kernel_size=[1, 1], activation_fn=None)\nnet = slim.batch_norm(net, fused=True)\nnet = tf.nn.relu(net)\nreturn net\ndef DepthwiseSeparableConvBlock(inputs, n_filters, kernel_size=[3, 3]):\n\"\"\"\nBuilds the Depthwise Separable conv block for MobileNets\nApply successivly a 2D separable convolution, BatchNormalization relu, conv, BatchNormalization, relu\n\"\"\"\n# Skip pointwise by setting num_outputs=None\nnet = slim.separable_convolution2d(inputs, num_outputs=None, depth_multiplier=1, kernel_size=[3, 3], activation_fn=None)\nnet = slim.batch_norm(net, fused=True)\nnet = tf.nn.relu(net)\nnet = slim.conv2d(net, n_filters, kernel_size=[1, 1], activation_fn=None)\nnet = slim.batch_norm(net, fused=True)\nnet = tf.nn.relu(net)\nreturn net\n\ndef conv_transpose_block(inputs, n_filters, kernel_size=[3, 3]):\n\"\"\"\nBasic conv transpose block for Encoder-Decoder upsampling\nApply successivly Transposed Convolution, BatchNormalization, ReLU nonlinearity\n\"\"\"\nnet = slim.conv2d_transpose(inputs, n_filters, kernel_size=[3, 3], stride=[2, 2], activation_fn=None)\nnet= slim.batch_norm(net)\nnet = tf.nn.relu(net)\nreturn net\ndef build_mobile_unet(inputs, preset_model, num_classes):\nhas_skip = False\nif preset_model == \"MobileUNet\":\n\thas_skip = False\nelif preset_model == \"MobileUNet-Skip\":\n\thas_skip = True\nelse:\n\traise ValueError(\"Unsupported MobileUNet model '%s'. This function only supports MobileUNet and MobileUNet-Skip\" % (preset_model))\n\n#####################\n# Downsampling block  #\n#####################\nb00 = ConvBlock(inputs, 32)\n\nb01 = DepthwiseSeparableConvBlock(b00, 64)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\n#skip_1 = net\n\nb02 = DepthwiseSeparableConvBlock(b01, 128)\nb03 = DepthwiseSeparableConvBlock(b02, 128)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX') #2x2 max pooling operation\n#skip_2 = net\n\nb04 = DepthwiseSeparableConvBlock(b03, 256)\nb05 = DepthwiseSeparableConvBlock(b04, 256)\n#net = DepthwiseSeparableConvBlock(net, 256)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\n#skip_3 = net\n\nb06 = DepthwiseSeparableConvBlock(b05, 512)\nb07 = DepthwiseSeparableConvBlock(b06, 512)\nb08 = DepthwiseSeparableConvBlock(b07, 512)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\n#skip_4 = net\n\n\nb09 = DepthwiseSeparableConvBlock(b08, 512)\nb10 = DepthwiseSeparableConvBlock(b09, 512)\nb11 = DepthwiseSeparableConvBlock(b10, 512)\n#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\n#skip_5 = net\n\nb12 = DepthwiseSeparableConvBlock(b11, 1024)\nb13 = DepthwiseSeparableConvBlock(b12, 1024)\n##################################################\n##################################################\n\nfilters = int(512 * 1.0)\nnet_01 = conv_transpose_block(b13, filters)\nup1 = tf.add(net_01, b11)\nb14 = DepthwiseSeparableConvBlock(up1, filters)\n\n\n\nfilters = int(256 * 1.0)\nnet02 = conv_transpose_block(b14, filters)\nup2 = tf.add(net02, b05)\nb15 = DepthwiseSeparableConvBlock(up2, filters)\n\n\nfilters = int(128 * 1.0)\nnet03 = conv_transpose_block(b15, filters)\nup3 = tf.add(net03, b03)\nb16 = DepthwiseSeparableConvBlock(up3, filters)\n\n\nfilters = int(64 * 1.0)\nnet04=conv_transpose_block(b16, filters)\nup4 = tf.add(net04, b01)\nb17= DepthwiseSeparableConvBlock(up4, filters)\n\n\nfilters = int(32 * 1.0)\nnet05=conv_transpose_block(b17, filters)\nup5 = tf.add(net05, b00)\nb18 = ConvBlock(up5, filters)\n\n\n#net = slim.conv2d(b18, num_classes, [1, 1], activation_fn='linear', scope='logits')\nnet = slim.conv2d(b18, num_classes, [1, 1], activation_fn=None, scope='logits')\n#net = BilinearUpSampling2D(net, size=(2, 2))\nnet = tf.sigmoid(net,name=None)\n\n\nreturn net\n\ncan someone help me, and sorry for the poor english", "body": "hello, \r\ni am beginner of tensorflow and Neural network, I am working on a semantic segmentation project with Neural network  mobilenet/Unet.\r\ni reduce the batch size and i fix it to 1 and the image have the size 500*500. \r\n\r\nthe machine utilised is 64 bit: lenovo i3 500,  RAM 4G, OS wind10\r\n\r\nwhen l run the training, i have the following error:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\r\n\t [[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\test-main.py\", line 283, in <module>\r\n    _,current=sess.run([opt,cost],feed_dict={net_input:input_image_batch, net_output:segmented_image_batch})\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\r\n\t [[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'BatchNorm_19/FusedBatchNorm', defined at:\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\idlelib\\run.py\", line 124, in main\r\n    ret = method(*args, **kwargs)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\idlelib\\run.py\", line 351, in runcode\r\n    exec(code, self.locals)\r\n  File \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\test-main.py\", line 190, in <module>\r\n    network = build_mobile_unet(net_input, preset_model = args.model, num_classes=num_classes)\r\n  File \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\MobileUNet.py\", line 80, in build_mobile_unet\r\n    b10 = DepthwiseSeparableConvBlock(b09, 512)\r\n  File \"C:\\Users\\henda boudegga\\Desktop\\retinal-image-segmentation - Copie30-8\\MobileUNet.py\", line 25, in DepthwiseSeparableConvBlock\r\n    net = slim.batch_norm(net, fused=True)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 650, in batch_norm\r\n    outputs = layer.apply(inputs, training=is_training)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 774, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 329, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 703, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 158, in call\r\n    return super(BatchNormalization, self).call(inputs, training=training)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 511, in call\r\n    outputs = self._fused_batch_norm(inputs, training=training)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 398, in _fused_batch_norm\r\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\", line 51, in smart_cond\r\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\", line 54, in smart_cond\r\n    return true_fn()\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\", line 384, in _fused_batch_norm_training\r\n    data_format=self._data_format)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 906, in fused_batch_norm\r\n    name=name)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3810, in _fused_batch_norm\r\n    is_training=is_training, name=name)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\henda boudegga\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,500,500,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\r\n\t [[Node: BatchNorm_19/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=0.001, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SeparableConv2d_9/BiasAdd, BatchNorm_23/Const, BatchNorm_19/beta/read, BatchNorm_23/Const_1, BatchNorm_23/Const_1)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\n\r\n**this is my following Neural network:** \r\n\r\nimport os,time,cv2\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nimport numpy as np\r\n\r\ndef ConvBlock(inputs, n_filters, kernel_size=[3, 3]):\r\n\t\"\"\"\r\n\tBuilds the conv block for MobileNets\r\n\tApply successivly a 2D convolution, BatchNormalization relu\r\n\t\"\"\"\r\n\t# Skip pointwise by setting num_outputs=Non\r\n\tnet = slim.conv2d(inputs, n_filters, kernel_size=[1, 1], activation_fn=None)\r\n\tnet = slim.batch_norm(net, fused=True)\r\n\tnet = tf.nn.relu(net)\r\n\treturn net\r\n\r\ndef DepthwiseSeparableConvBlock(inputs, n_filters, kernel_size=[3, 3]):\r\n\t\"\"\"\r\n\tBuilds the Depthwise Separable conv block for MobileNets\r\n\tApply successivly a 2D separable convolution, BatchNormalization relu, conv, BatchNormalization, relu\r\n\t\"\"\"\r\n\t# Skip pointwise by setting num_outputs=None\r\n\tnet = slim.separable_convolution2d(inputs, num_outputs=None, depth_multiplier=1, kernel_size=[3, 3], activation_fn=None)\r\n\r\n\tnet = slim.batch_norm(net, fused=True)\r\n\tnet = tf.nn.relu(net)\r\n\tnet = slim.conv2d(net, n_filters, kernel_size=[1, 1], activation_fn=None)\r\n\tnet = slim.batch_norm(net, fused=True)\r\n\tnet = tf.nn.relu(net)\r\n\treturn net\r\n\r\ndef conv_transpose_block(inputs, n_filters, kernel_size=[3, 3]):\r\n\t\"\"\"\r\n\tBasic conv transpose block for Encoder-Decoder upsampling\r\n\tApply successivly Transposed Convolution, BatchNormalization, ReLU nonlinearity\r\n\t\"\"\"\r\n\tnet = slim.conv2d_transpose(inputs, n_filters, kernel_size=[3, 3], stride=[2, 2], activation_fn=None)\r\n\tnet= slim.batch_norm(net)\r\n\tnet = tf.nn.relu(net)\r\n\treturn net\r\n\r\ndef build_mobile_unet(inputs, preset_model, num_classes):\r\n\r\n\thas_skip = False\r\n\tif preset_model == \"MobileUNet\":\r\n\t\thas_skip = False\r\n\telif preset_model == \"MobileUNet-Skip\":\r\n\t\thas_skip = True\r\n\telse:\r\n\t\traise ValueError(\"Unsupported MobileUNet model '%s'. This function only supports MobileUNet and MobileUNet-Skip\" % (preset_model))\r\n\r\n    #####################\r\n\t# Downsampling block  #\r\n\t#####################\r\n\tb00 = ConvBlock(inputs, 32)\r\n\t\r\n\tb01 = DepthwiseSeparableConvBlock(b00, 64)\r\n\t#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\r\n\t#skip_1 = net\r\n\r\n\tb02 = DepthwiseSeparableConvBlock(b01, 128)\r\n\tb03 = DepthwiseSeparableConvBlock(b02, 128)\r\n\t#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX') #2x2 max pooling operation\r\n\t#skip_2 = net\r\n\r\n\tb04 = DepthwiseSeparableConvBlock(b03, 256)\r\n\tb05 = DepthwiseSeparableConvBlock(b04, 256)\r\n\t#net = DepthwiseSeparableConvBlock(net, 256)\r\n\t#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\r\n\t#skip_3 = net\r\n\r\n\tb06 = DepthwiseSeparableConvBlock(b05, 512)\r\n\tb07 = DepthwiseSeparableConvBlock(b06, 512)\r\n\tb08 = DepthwiseSeparableConvBlock(b07, 512)\r\n\t#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\r\n\t#skip_4 = net\r\n\r\n\t\r\n\tb09 = DepthwiseSeparableConvBlock(b08, 512)\r\n\tb10 = DepthwiseSeparableConvBlock(b09, 512)\r\n\tb11 = DepthwiseSeparableConvBlock(b10, 512)\r\n\t#net = slim.pool(net, [2, 2], stride=[2, 2], pooling_type='MAX')\r\n\t#skip_5 = net\r\n\r\n\tb12 = DepthwiseSeparableConvBlock(b11, 1024)\r\n\tb13 = DepthwiseSeparableConvBlock(b12, 1024)\r\n\t##################################################\r\n\t##################################################\r\n\t\r\n\tfilters = int(512 * 1.0)\r\n\tnet_01 = conv_transpose_block(b13, filters)\r\n\tup1 = tf.add(net_01, b11)\r\n\tb14 = DepthwiseSeparableConvBlock(up1, filters)\r\n\t\r\n\r\n\t\r\n\tfilters = int(256 * 1.0)\r\n\tnet02 = conv_transpose_block(b14, filters)\r\n\tup2 = tf.add(net02, b05)\r\n\tb15 = DepthwiseSeparableConvBlock(up2, filters)\r\n\t\r\n\r\n\tfilters = int(128 * 1.0)\r\n\tnet03 = conv_transpose_block(b15, filters)\r\n\tup3 = tf.add(net03, b03)\r\n\tb16 = DepthwiseSeparableConvBlock(up3, filters)\r\n\t\r\n\r\n\tfilters = int(64 * 1.0)\r\n\tnet04=conv_transpose_block(b16, filters)\r\n\tup4 = tf.add(net04, b01)\r\n\tb17= DepthwiseSeparableConvBlock(up4, filters)\r\n\t\r\n\r\n\tfilters = int(32 * 1.0)\r\n\tnet05=conv_transpose_block(b17, filters)\r\n\tup5 = tf.add(net05, b00)\r\n\tb18 = ConvBlock(up5, filters)\r\n\t\r\n\r\n\t#net = slim.conv2d(b18, num_classes, [1, 1], activation_fn='linear', scope='logits')\r\n\tnet = slim.conv2d(b18, num_classes, [1, 1], activation_fn=None, scope='logits')\r\n\t#net = BilinearUpSampling2D(net, size=(2, 2))\r\n\tnet = tf.sigmoid(net,name=None)\r\n\t\r\n\r\n\treturn net\r\n\r\n\r\n\r\ncan someone help me, and sorry for the poor english\r\n\r\n"}