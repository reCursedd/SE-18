{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1193", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1193/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1193/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1193/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1193", "id": 134838463, "node_id": "MDU6SXNzdWUxMzQ4Mzg0NjM=", "number": 1193, "title": "'utf-8' codec can't decode byte (in tutorial)", "user": {"login": "zplizzi", "id": 5598968, "node_id": "MDQ6VXNlcjU1OTg5Njg=", "avatar_url": "https://avatars0.githubusercontent.com/u/5598968?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zplizzi", "html_url": "https://github.com/zplizzi", "followers_url": "https://api.github.com/users/zplizzi/followers", "following_url": "https://api.github.com/users/zplizzi/following{/other_user}", "gists_url": "https://api.github.com/users/zplizzi/gists{/gist_id}", "starred_url": "https://api.github.com/users/zplizzi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zplizzi/subscriptions", "organizations_url": "https://api.github.com/users/zplizzi/orgs", "repos_url": "https://api.github.com/users/zplizzi/repos", "events_url": "https://api.github.com/users/zplizzi/events{/privacy}", "received_events_url": "https://api.github.com/users/zplizzi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-02-19T11:07:02Z", "updated_at": "2016-02-19T17:31:48Z", "closed_at": "2016-02-19T17:31:47Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm getting an error \"'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\" error when I try to run the MNIST tutorial (specifically, the dataset import).</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 15.04<br>\nPython: 3.4.3<br>\nTensorflow from source, commit: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/03bff43060229357cbe2cc1659e7d129c2799b06/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/03bff43060229357cbe2cc1659e7d129c2799b06\"><tt>03bff43</tt></a></p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Install fresh python3 venv (pyvenv venv)</li>\n<li>Activate venv</li>\n<li>uninstall and re-install protobuf 3.0.0a3 to fix <a href=\"https://github.com/tensorflow/tensorflow/issues/487\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/487/hovercard\">487</a></li>\n<li>pip install \"built whl file\"</li>\n<li>In a python terminal, run:</li>\n</ol>\n<p>from tensorflow.examples.tutorials.mnist import input_data<br>\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)</p>\n<h3>Full Error Output</h3>\n<p>UnicodeDecodeError                        Traceback (most recent call last)<br>\n in ()<br>\n1 import tensorflow<br>\n2 from tensorflow.examples.tutorials.mnist import input_data<br>\n----&gt; 3 mnist = input_data.read_data_sets('MNIST_data', one_hot=True)</p>\n<p>/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in read_data_sets(train_dir, fake_data, one_hot, dtype)<br>\n197<br>\n198   local_file = maybe_download(TRAIN_IMAGES, train_dir)<br>\n--&gt; 199   train_images = extract_images(local_file)<br>\n200<br>\n201   local_file = maybe_download(TRAIN_LABELS, train_dir)</p>\n<p>/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in extract_images(filename)<br>\n56   print('Extracting', filename)<br>\n57   with tf.gfile.Open(filename) as f, gzip.GzipFile(fileobj=f) as bytestream:<br>\n---&gt; 58     magic = _read32(bytestream)<br>\n59     if magic != 2051:<br>\n60       raise ValueError(</p>\n<p>/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in _read32(bytestream)<br>\n49 def _read32(bytestream):<br>\n50   dt = numpy.dtype(numpy.uint32).newbyteorder('&gt;')<br>\n---&gt; 51   return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]<br>\n52<br>\n53</p>\n<p>/usr/lib/python3.4/gzip.py in read(self, size)<br>\n363         else:               # just get some more of it<br>\n364             while size &gt; self.extrasize:<br>\n--&gt; 365                 if not self._read(readsize):<br>\n366                     if size &gt; self.extrasize:<br>\n367                         size = self.extrasize</p>\n<p>/usr/lib/python3.4/gzip.py in _read(self, size)<br>\n431             # jump to the next member, if there is one.<br>\n432             self._init_read()<br>\n--&gt; 433             if not self._read_gzip_header():<br>\n434                 return False<br>\n435             self.decompress = zlib.decompressobj(-zlib.MAX_WBITS)</p>\n<p>/usr/lib/python3.4/gzip.py in _read_gzip_header(self)<br>\n290<br>\n291     def _read_gzip_header(self):<br>\n--&gt; 292         magic = self.fileobj.read(2)<br>\n293         if magic == b'':<br>\n294             return False</p>\n<p>/usr/lib/python3.4/gzip.py in read(self, size)<br>\n88             self._read = None<br>\n89             return self._buffer[read:] + <br>\n---&gt; 90                    self.file.read(size-self._length+read)<br>\n91<br>\n92     def prepend(self, prepend=b'', readprevious=False):</p>\n<p>/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/platform/default/_gfile.py in sync(self, _args, *_kwargs)<br>\n43       if hasattr(self, '_locker'): self._locker.lock()<br>\n44       try:<br>\n---&gt; 45         return fn(self, _args, *_kwargs)<br>\n46       finally:<br>\n47         if hasattr(self, '_locker'): self._locker.unlock()</p>\n<p>/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/platform/default/_gfile.py in read(self, n)<br>\n197       A string of the bytes read, up to the end of file.<br>\n198     \"\"\"<br>\n--&gt; 199     return self._fp.read(n)<br>\n200<br>\n201   @_synchronized</p>\n<p>/usr/lib/python3.4/codecs.py in decode(self, input, final)<br>\n317         # decode input (taking the buffer into account)<br>\n318         data = self.buffer + input<br>\n--&gt; 319         (result, consumed) = self._buffer_decode(data, self.errors, final)<br>\n320         # keep undecoded input until the next call<br>\n321         self.buffer = data[consumed:]</p>\n<p>UnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte</p>", "body_text": "I'm getting an error \"'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\" error when I try to run the MNIST tutorial (specifically, the dataset import).\nEnvironment info\nOperating System: Ubuntu 15.04\nPython: 3.4.3\nTensorflow from source, commit: 03bff43\nSteps to reproduce\n\nInstall fresh python3 venv (pyvenv venv)\nActivate venv\nuninstall and re-install protobuf 3.0.0a3 to fix 487\npip install \"built whl file\"\nIn a python terminal, run:\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\nFull Error Output\nUnicodeDecodeError                        Traceback (most recent call last)\n in ()\n1 import tensorflow\n2 from tensorflow.examples.tutorials.mnist import input_data\n----> 3 mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in read_data_sets(train_dir, fake_data, one_hot, dtype)\n197\n198   local_file = maybe_download(TRAIN_IMAGES, train_dir)\n--> 199   train_images = extract_images(local_file)\n200\n201   local_file = maybe_download(TRAIN_LABELS, train_dir)\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in extract_images(filename)\n56   print('Extracting', filename)\n57   with tf.gfile.Open(filename) as f, gzip.GzipFile(fileobj=f) as bytestream:\n---> 58     magic = _read32(bytestream)\n59     if magic != 2051:\n60       raise ValueError(\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in _read32(bytestream)\n49 def _read32(bytestream):\n50   dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n---> 51   return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n52\n53\n/usr/lib/python3.4/gzip.py in read(self, size)\n363         else:               # just get some more of it\n364             while size > self.extrasize:\n--> 365                 if not self._read(readsize):\n366                     if size > self.extrasize:\n367                         size = self.extrasize\n/usr/lib/python3.4/gzip.py in _read(self, size)\n431             # jump to the next member, if there is one.\n432             self._init_read()\n--> 433             if not self._read_gzip_header():\n434                 return False\n435             self.decompress = zlib.decompressobj(-zlib.MAX_WBITS)\n/usr/lib/python3.4/gzip.py in _read_gzip_header(self)\n290\n291     def _read_gzip_header(self):\n--> 292         magic = self.fileobj.read(2)\n293         if magic == b'':\n294             return False\n/usr/lib/python3.4/gzip.py in read(self, size)\n88             self._read = None\n89             return self._buffer[read:] + \n---> 90                    self.file.read(size-self._length+read)\n91\n92     def prepend(self, prepend=b'', readprevious=False):\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/platform/default/_gfile.py in sync(self, _args, *_kwargs)\n43       if hasattr(self, '_locker'): self._locker.lock()\n44       try:\n---> 45         return fn(self, _args, *_kwargs)\n46       finally:\n47         if hasattr(self, '_locker'): self._locker.unlock()\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/platform/default/_gfile.py in read(self, n)\n197       A string of the bytes read, up to the end of file.\n198     \"\"\"\n--> 199     return self._fp.read(n)\n200\n201   @_synchronized\n/usr/lib/python3.4/codecs.py in decode(self, input, final)\n317         # decode input (taking the buffer into account)\n318         data = self.buffer + input\n--> 319         (result, consumed) = self._buffer_decode(data, self.errors, final)\n320         # keep undecoded input until the next call\n321         self.buffer = data[consumed:]\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte", "body": "I'm getting an error \"'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\" error when I try to run the MNIST tutorial (specifically, the dataset import).\n### Environment info\n\nOperating System: Ubuntu 15.04\nPython: 3.4.3\nTensorflow from source, commit: 03bff43\n### Steps to reproduce\n\n1) Install fresh python3 venv (pyvenv venv)\n2) Activate venv\n3) uninstall and re-install protobuf 3.0.0a3 to fix [487](https://github.com/tensorflow/tensorflow/issues/487)\n3) pip install \"built whl file\"\n4) In a python terminal, run:\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n### Full Error Output\n\nUnicodeDecodeError                        Traceback (most recent call last)\n<ipython-input-1-4fcb59292e9b> in <module>()\n      1 import tensorflow\n      2 from tensorflow.examples.tutorials.mnist import input_data\n----> 3 mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in read_data_sets(train_dir, fake_data, one_hot, dtype)\n    197 \n    198   local_file = maybe_download(TRAIN_IMAGES, train_dir)\n--> 199   train_images = extract_images(local_file)\n    200 \n    201   local_file = maybe_download(TRAIN_LABELS, train_dir)\n\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in extract_images(filename)\n     56   print('Extracting', filename)\n     57   with tf.gfile.Open(filename) as f, gzip.GzipFile(fileobj=f) as bytestream:\n---> 58     magic = _read32(bytestream)\n     59     if magic != 2051:\n     60       raise ValueError(\n\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in _read32(bytestream)\n     49 def _read32(bytestream):\n     50   dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n---> 51   return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n     52 \n     53 \n\n/usr/lib/python3.4/gzip.py in read(self, size)\n    363         else:               # just get some more of it\n    364             while size > self.extrasize:\n--> 365                 if not self._read(readsize):\n    366                     if size > self.extrasize:\n    367                         size = self.extrasize\n\n/usr/lib/python3.4/gzip.py in _read(self, size)\n    431             # jump to the next member, if there is one.\n    432             self._init_read()\n--> 433             if not self._read_gzip_header():\n    434                 return False\n    435             self.decompress = zlib.decompressobj(-zlib.MAX_WBITS)\n\n/usr/lib/python3.4/gzip.py in _read_gzip_header(self)\n    290 \n    291     def _read_gzip_header(self):\n--> 292         magic = self.fileobj.read(2)\n    293         if magic == b'':\n    294             return False\n\n/usr/lib/python3.4/gzip.py in read(self, size)\n     88             self._read = None\n     89             return self._buffer[read:] + \\\n---> 90                    self.file.read(size-self._length+read)\n     91 \n     92     def prepend(self, prepend=b'', readprevious=False):\n\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/platform/default/_gfile.py in sync(self, _args, *_kwargs)\n     43       if hasattr(self, '_locker'): self._locker.lock()\n     44       try:\n---> 45         return fn(self, _args, *_kwargs)\n     46       finally:\n     47         if hasattr(self, '_locker'): self._locker.unlock()\n\n/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/platform/default/_gfile.py in read(self, n)\n    197       A string of the bytes read, up to the end of file.\n    198     \"\"\"\n--> 199     return self._fp.read(n)\n    200 \n    201   @_synchronized\n\n/usr/lib/python3.4/codecs.py in decode(self, input, final)\n    317         # decode input (taking the buffer into account)\n    318         data = self.buffer + input\n--> 319         (result, consumed) = self._buffer_decode(data, self.errors, final)\n    320         # keep undecoded input until the next call\n    321         self.buffer = data[consumed:]\n\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n"}