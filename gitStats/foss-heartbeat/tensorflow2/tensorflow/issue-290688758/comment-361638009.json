{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/361638009", "html_url": "https://github.com/tensorflow/tensorflow/pull/16306#issuecomment-361638009", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16306", "id": 361638009, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTYzODAwOQ==", "user": {"login": "yangjunpro", "id": 407784, "node_id": "MDQ6VXNlcjQwNzc4NA==", "avatar_url": "https://avatars3.githubusercontent.com/u/407784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yangjunpro", "html_url": "https://github.com/yangjunpro", "followers_url": "https://api.github.com/users/yangjunpro/followers", "following_url": "https://api.github.com/users/yangjunpro/following{/other_user}", "gists_url": "https://api.github.com/users/yangjunpro/gists{/gist_id}", "starred_url": "https://api.github.com/users/yangjunpro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yangjunpro/subscriptions", "organizations_url": "https://api.github.com/users/yangjunpro/orgs", "repos_url": "https://api.github.com/users/yangjunpro/repos", "events_url": "https://api.github.com/users/yangjunpro/events{/privacy}", "received_events_url": "https://api.github.com/users/yangjunpro/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-30T15:54:44Z", "updated_at": "2018-01-30T15:54:44Z", "author_association": "NONE", "body_html": "<p>Thanks for you guys' response.<br>\nWe would like to migrate our code from original TF graph optimization passes to grappler optimization passes(actually we have made a small PR related to grappler's memory optimization accepted by r1.4 before, also recently there is another op fusion work done at grappler code base which we would also like to push to TF upstream when internal test is ready enough).<br>\nAs <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6969686\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/benoitsteiner\">@benoitsteiner</a> mentioned you are also adding some loop optimization work in grappler, could you share a little bit more detail as to those loop optimization? Since we have already implemented LINM optimization, we would be more than happy to re-implement it as another grappler optimization pass. Also I want to know more details about your grappler-level loop optimization work to ensure that your internal work will not be quite duplicated from ours since engineering resource is always limited and there are still quite a lot of things that we could put at our radar:)<br>\nWe have already had such issues with TensorRT&amp;TF integration work:), and also I know working with community will not completely avoid such duplicated and overlap work since people seeing the same code base may figure out the same optimization idea based on their specific scenarios. But I do want to set up a mechanism so that we could catch up with the community as soon as possible and then we can steer the direction of our engineering resources in a more productive way.</p>\n<p>Thanks</p>", "body_text": "Thanks for you guys' response.\nWe would like to migrate our code from original TF graph optimization passes to grappler optimization passes(actually we have made a small PR related to grappler's memory optimization accepted by r1.4 before, also recently there is another op fusion work done at grappler code base which we would also like to push to TF upstream when internal test is ready enough).\nAs @benoitsteiner mentioned you are also adding some loop optimization work in grappler, could you share a little bit more detail as to those loop optimization? Since we have already implemented LINM optimization, we would be more than happy to re-implement it as another grappler optimization pass. Also I want to know more details about your grappler-level loop optimization work to ensure that your internal work will not be quite duplicated from ours since engineering resource is always limited and there are still quite a lot of things that we could put at our radar:)\nWe have already had such issues with TensorRT&TF integration work:), and also I know working with community will not completely avoid such duplicated and overlap work since people seeing the same code base may figure out the same optimization idea based on their specific scenarios. But I do want to set up a mechanism so that we could catch up with the community as soon as possible and then we can steer the direction of our engineering resources in a more productive way.\nThanks", "body": "Thanks for you guys' response.\r\nWe would like to migrate our code from original TF graph optimization passes to grappler optimization passes(actually we have made a small PR related to grappler's memory optimization accepted by r1.4 before, also recently there is another op fusion work done at grappler code base which we would also like to push to TF upstream when internal test is ready enough).\r\nAs @benoitsteiner mentioned you are also adding some loop optimization work in grappler, could you share a little bit more detail as to those loop optimization? Since we have already implemented LINM optimization, we would be more than happy to re-implement it as another grappler optimization pass. Also I want to know more details about your grappler-level loop optimization work to ensure that your internal work will not be quite duplicated from ours since engineering resource is always limited and there are still quite a lot of things that we could put at our radar:) \r\nWe have already had such issues with TensorRT&TF integration work:), and also I know working with community will not completely avoid such duplicated and overlap work since people seeing the same code base may figure out the same optimization idea based on their specific scenarios. But I do want to set up a mechanism so that we could catch up with the community as soon as possible and then we can steer the direction of our engineering resources in a more productive way.\r\n\r\nThanks"}