{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/332530880", "html_url": "https://github.com/tensorflow/tensorflow/issues/13341#issuecomment-332530880", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13341", "id": 332530880, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMjUzMDg4MA==", "user": {"login": "rahulsingh1288", "id": 19755571, "node_id": "MDQ6VXNlcjE5NzU1NTcx", "avatar_url": "https://avatars3.githubusercontent.com/u/19755571?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rahulsingh1288", "html_url": "https://github.com/rahulsingh1288", "followers_url": "https://api.github.com/users/rahulsingh1288/followers", "following_url": "https://api.github.com/users/rahulsingh1288/following{/other_user}", "gists_url": "https://api.github.com/users/rahulsingh1288/gists{/gist_id}", "starred_url": "https://api.github.com/users/rahulsingh1288/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rahulsingh1288/subscriptions", "organizations_url": "https://api.github.com/users/rahulsingh1288/orgs", "repos_url": "https://api.github.com/users/rahulsingh1288/repos", "events_url": "https://api.github.com/users/rahulsingh1288/events{/privacy}", "received_events_url": "https://api.github.com/users/rahulsingh1288/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-27T14:01:34Z", "updated_at": "2017-09-27T14:01:34Z", "author_association": "NONE", "body_html": "<p>I am trying to build a two layered stacked LSTM without using MultiRNNcell, as follows,<br>\ndef initialize_lstm(self):<br>\nwith tf.variable_scope(\"lstm_layer_1\") as scope:<br>\nself.lstm_cell_1 = tf.nn.rnn_cell.BasicLSTMCell(self.num_cells_1,reuse=tf.get_variable_scope().reuse)<br>\nwith tf.variable_scope(\"lstm_layer_2\") as scope:<br>\nself.lstm_cell_2 = tf.nn.rnn_cell.BasicLSTMCell(self.num_cells_2)<br>\nself.lstm_c1 = tf.placeholder(tf.float32,[None,self.num_cells_1])<br>\nself.lstm_h1 = tf.placeholder(tf.float32,[None,self.num_cells_1])<br>\nself.lstm_c2 = tf.placeholder(tf.float32,[None,self.num_cells_2])<br>\nself.lstm_h2 = tf.placeholder(tf.float32,[None,self.num_cells_2])<br>\nself.lstm_start_cell_1 = tf.nn.rnn_cell.LSTMStateTuple(self.lstm_c1,self.lstm_h1)<br>\nself.lstm_start_cell_2 = tf.nn.rnn_cell.LSTMStateTuple(self.lstm_c2,self.lstm_h2)<br>\nself.lstm_output_1,self.lstm_state_1 = <br>\ntf.nn.dynamic_rnn(self.lstm_cell_1,self.state_seq,initial_state = self.lstm_start_cell_1)<br>\nself.lstm_output_2,self.lstm_state_2 = <br>\ntf.nn.dynamic_rnn(self.lstm_cell_2,self.lstm_output_1,initial_state = self.lstm_start_cell_2)</p>\n<p>However, I get the following error, \"ValueError: Variable rnn/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\"...I am unable to figure out what is the issue?</p>", "body_text": "I am trying to build a two layered stacked LSTM without using MultiRNNcell, as follows,\ndef initialize_lstm(self):\nwith tf.variable_scope(\"lstm_layer_1\") as scope:\nself.lstm_cell_1 = tf.nn.rnn_cell.BasicLSTMCell(self.num_cells_1,reuse=tf.get_variable_scope().reuse)\nwith tf.variable_scope(\"lstm_layer_2\") as scope:\nself.lstm_cell_2 = tf.nn.rnn_cell.BasicLSTMCell(self.num_cells_2)\nself.lstm_c1 = tf.placeholder(tf.float32,[None,self.num_cells_1])\nself.lstm_h1 = tf.placeholder(tf.float32,[None,self.num_cells_1])\nself.lstm_c2 = tf.placeholder(tf.float32,[None,self.num_cells_2])\nself.lstm_h2 = tf.placeholder(tf.float32,[None,self.num_cells_2])\nself.lstm_start_cell_1 = tf.nn.rnn_cell.LSTMStateTuple(self.lstm_c1,self.lstm_h1)\nself.lstm_start_cell_2 = tf.nn.rnn_cell.LSTMStateTuple(self.lstm_c2,self.lstm_h2)\nself.lstm_output_1,self.lstm_state_1 = \ntf.nn.dynamic_rnn(self.lstm_cell_1,self.state_seq,initial_state = self.lstm_start_cell_1)\nself.lstm_output_2,self.lstm_state_2 = \ntf.nn.dynamic_rnn(self.lstm_cell_2,self.lstm_output_1,initial_state = self.lstm_start_cell_2)\nHowever, I get the following error, \"ValueError: Variable rnn/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\"...I am unable to figure out what is the issue?", "body": "I am trying to build a two layered stacked LSTM without using MultiRNNcell, as follows,\r\n    def initialize_lstm(self): \r\n        with tf.variable_scope(\"lstm_layer_1\") as scope:\r\n            self.lstm_cell_1 = tf.nn.rnn_cell.BasicLSTMCell(self.num_cells_1,reuse=tf.get_variable_scope().reuse)\r\n        with tf.variable_scope(\"lstm_layer_2\") as scope: \r\n            self.lstm_cell_2 = tf.nn.rnn_cell.BasicLSTMCell(self.num_cells_2)\r\n        self.lstm_c1 = tf.placeholder(tf.float32,[None,self.num_cells_1])\r\n        self.lstm_h1 = tf.placeholder(tf.float32,[None,self.num_cells_1])\r\n        self.lstm_c2 = tf.placeholder(tf.float32,[None,self.num_cells_2])\r\n        self.lstm_h2 = tf.placeholder(tf.float32,[None,self.num_cells_2])        \r\n        self.lstm_start_cell_1 = tf.nn.rnn_cell.LSTMStateTuple(self.lstm_c1,self.lstm_h1)\r\n        self.lstm_start_cell_2 = tf.nn.rnn_cell.LSTMStateTuple(self.lstm_c2,self.lstm_h2)\r\n        self.lstm_output_1,self.lstm_state_1 = \\\r\n        tf.nn.dynamic_rnn(self.lstm_cell_1,self.state_seq,initial_state = self.lstm_start_cell_1)\r\n        self.lstm_output_2,self.lstm_state_2 = \\\r\n        tf.nn.dynamic_rnn(self.lstm_cell_2,self.lstm_output_1,initial_state = self.lstm_start_cell_2)\r\n\r\nHowever, I get the following error, \"ValueError: Variable rnn/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\"...I am unable to figure out what is the issue?"}