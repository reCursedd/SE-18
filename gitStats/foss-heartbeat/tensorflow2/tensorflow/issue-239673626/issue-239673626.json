{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11164", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11164/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11164/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11164/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11164", "id": 239673626, "node_id": "MDU6SXNzdWUyMzk2NzM2MjY=", "number": 11164, "title": "Expose reader.read_up_to in slim parallel reader", "user": {"login": "panmari", "id": 719020, "node_id": "MDQ6VXNlcjcxOTAyMA==", "avatar_url": "https://avatars1.githubusercontent.com/u/719020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/panmari", "html_url": "https://github.com/panmari", "followers_url": "https://api.github.com/users/panmari/followers", "following_url": "https://api.github.com/users/panmari/following{/other_user}", "gists_url": "https://api.github.com/users/panmari/gists{/gist_id}", "starred_url": "https://api.github.com/users/panmari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/panmari/subscriptions", "organizations_url": "https://api.github.com/users/panmari/orgs", "repos_url": "https://api.github.com/users/panmari/repos", "events_url": "https://api.github.com/users/panmari/events{/privacy}", "received_events_url": "https://api.github.com/users/panmari/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-06-30T04:19:10Z", "updated_at": "2018-11-10T16:39:01Z", "closed_at": "2018-11-10T16:39:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>When reading small records (in my case, one example is a a floatlist of about 150 floats), the DataSetProvider from slim is very slow. I found out that things get much faster if I write a custom input pipeline that leverages reader.read_up_to</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">ReadTFRecord</span>(<span class=\"pl-smi\">filename_queue</span>):\n  num_tfrecords_at_once <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1024</span> \n  reader <span class=\"pl-k\">=</span> tf.TFRecordReader()\n  _, queue_batch <span class=\"pl-k\">=</span> reader.read_up_to(filename_queue, num_tfrecords_at_once)\n  <span class=\"pl-k\">return</span> [queue_batch]</pre></div>\n<p>the returned value is then fed to <code>tf.train.shuffle_batch</code> with enqueue_many set to true.</p>\n<p>As far as I understand, this behavior is currently not exposed in slim.ParallelReader, see <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/parallel_reader.py#L132\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/parallel_reader.py#L132</a>. Are there any plans for adding it?</p>", "body_text": "When reading small records (in my case, one example is a a floatlist of about 150 floats), the DataSetProvider from slim is very slow. I found out that things get much faster if I write a custom input pipeline that leverages reader.read_up_to\ndef ReadTFRecord(filename_queue):\n  num_tfrecords_at_once = 1024 \n  reader = tf.TFRecordReader()\n  _, queue_batch = reader.read_up_to(filename_queue, num_tfrecords_at_once)\n  return [queue_batch]\nthe returned value is then fed to tf.train.shuffle_batch with enqueue_many set to true.\nAs far as I understand, this behavior is currently not exposed in slim.ParallelReader, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/parallel_reader.py#L132. Are there any plans for adding it?", "body": "When reading small records (in my case, one example is a a floatlist of about 150 floats), the DataSetProvider from slim is very slow. I found out that things get much faster if I write a custom input pipeline that leverages reader.read_up_to \r\n\r\n```python\r\ndef ReadTFRecord(filename_queue):\r\n  num_tfrecords_at_once = 1024 \r\n  reader = tf.TFRecordReader()\r\n  _, queue_batch = reader.read_up_to(filename_queue, num_tfrecords_at_once)\r\n  return [queue_batch]\r\n```\r\nthe returned value is then fed to `tf.train.shuffle_batch` with enqueue_many set to true. \r\n\r\nAs far as I understand, this behavior is currently not exposed in slim.ParallelReader, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/parallel_reader.py#L132. Are there any plans for adding it?"}