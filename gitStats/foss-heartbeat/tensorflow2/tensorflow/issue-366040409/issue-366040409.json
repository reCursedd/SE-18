{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22674", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22674/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22674/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22674/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22674", "id": 366040409, "node_id": "MDU6SXNzdWUzNjYwNDA0MDk=", "number": 22674, "title": "tf.parse_single_example parses the record incorrectly", "user": {"login": "pennypacker91", "id": 31741300, "node_id": "MDQ6VXNlcjMxNzQxMzAw", "avatar_url": "https://avatars2.githubusercontent.com/u/31741300?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pennypacker91", "html_url": "https://github.com/pennypacker91", "followers_url": "https://api.github.com/users/pennypacker91/followers", "following_url": "https://api.github.com/users/pennypacker91/following{/other_user}", "gists_url": "https://api.github.com/users/pennypacker91/gists{/gist_id}", "starred_url": "https://api.github.com/users/pennypacker91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pennypacker91/subscriptions", "organizations_url": "https://api.github.com/users/pennypacker91/orgs", "repos_url": "https://api.github.com/users/pennypacker91/repos", "events_url": "https://api.github.com/users/pennypacker91/events{/privacy}", "received_events_url": "https://api.github.com/users/pennypacker91/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-02T19:13:19Z", "updated_at": "2018-10-19T07:05:55Z", "closed_at": "2018-10-02T21:15:39Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>I have written custom code</strong>:</li>\n<li><strong>OS  -  Linux Ubuntu 16.04</strong>:</li>\n<li><strong>TensorFlow installed from binary</strong>:</li>\n<li><strong>TensorFlow version - 1.10.1 (GPU)</strong>:</li>\n<li><strong>Python version - 3.6.5</strong>:</li>\n<li><strong>CUDA/cuDNN version - 9.0/7.0</strong>:</li>\n</ul>\n<h3>Issue:</h3>\n<p>I trying to create tfrecords for my sematic segmentation dataset (rgb_image_in -&gt; binary_raycast_out).</p>\n<h4>Below is my code to write the list of images to a train.tfrecord.</h4>\n<pre><code>        def _process_image_files(image_names, raycast_names):\n        \n            writer = tf.python_io.TFRecordWriter('train')\n    \n            #My implementation of decoding jpeg/png image\n            coder = ImageCoder()\n    \n            for i in range(len(image_names)):\n                print('{}\\n{}\\n\\n'.format(image_names[i], raycast_names[i]))\n\n                image_buffer, im_height, im_width, im_channels = _process_image(image_names[i], coder)\n\n                raycast_buffer, rc_height, rc_width, rc_channels = _process_image(raycast_names[i], coder)\n\n                example = _convert_to_example(image_names[i], raycast_names[i], image_buffer, raycast_buffer, \\\n                                              im_height, im_width, im_channels)\n\n                writer.write(example.SerializeToString())\n            writer.close()\n            sys.stdout.flush() \n    \n    def _process_image(filename, coder):\n        with tf.gfile.FastGFile(filename, 'rb') as f:\n            image_data = f.read()\n\n        # Decode the RGB JPEG.\n        image = coder.decode_jpeg(image_data)\n\n        return image_data, height, width, channels\n    \n    \n    def _convert_to_example(image_name, raycast_name, image_buffer, raycast_buffer, sample_height, sample_width, sample_channels):\n    \n        example = tf.train.Example(features=tf.train.Features(feature={\n            'height': _int64_feature(sample_height),\n            'width': _int64_feature(sample_width),\n            'channels': _int64_feature(sample_channels),\n            'image/filename': _bytes_feature(tf.compat.as_bytes(image_name)),\n            'image/encoded': _bytes_feature(tf.compat.as_bytes(image_buffer)),\n            'raycast/filename': _bytes_feature(tf.compat.as_bytes(raycast_name)),\n            'raycast/encoded': _bytes_feature(tf.compat.as_bytes(raycast_buffer))}))\n    \n        return example\n</code></pre>\n<p>The above code works fine in creating the tfrecord file. I put some print statements inside the <code>_convert_to_example</code> method to make sure the corresponding filenames (image_file &amp; raycast_file) are getting written in one example.</p>\n<p>However, when I read the examples from tfrecord and print the image names, it looks like the image_file &amp; raycast_file names do not correspond. The pair of images read by the tfRecordReader() is wrong.</p>\n<h4>Below is my code to read the record:</h4>\n<pre><code>    def parse_example_proto(example_serialized):\n    \n        feature_map = {\n                        'image/encoded': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n                        'raycast/encoded': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n                        'height': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\n                        'width': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\n                        'channels': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\n                        'image/filename': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n                        'raycast/filename': tf.FixedLenFeature([], dtype=tf.string, default_value='')\n                        }\n    \n        features = tf.parse_single_example(example_serialized, feature_map)\n    \n        return features['image/encoded'], features['raycast/encoded'], \\\n               features['height'], features['width'], features['channels'],\\\n               features['image/filename'], features['raycast/filename']\n    \n                \n    \n    def retirieve_samples():\n        \n        with tf.name_scope('batch_processing'):\n            data_files = ['train']\n    \n            filename_queue = tf.train.string_input_producer(data_files, shuffle=False)\n    \n            reader = tf.TFRecordReader()\n    \n            _, example_serialized = reader.read(filename_queue)\n    \n            image_buffer, raycast_buffer, height, width, channels, image_name, raycast_name = parse_example_proto(example_serialized)            \n            \n            return image_name, raycast_name\n</code></pre>\n<h4>Below is my code to print a pair of filenames</h4>\n<pre><code>    image_name, raycast_name = retirieve_samples()\n    with tf.Session() as sess:    \n        for i in range(1):\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n            print(sess.run(image_name))\n            print(sess.run(raycast_name))\n            coord.request_stop()\n            coord.join(threads)\n</code></pre>\n<p>I have spent few days on this. I am not able to identify why I am not able to retrieve the correct pair. An example being retrieved should have the same data as the example being created right ? Why am I seeing different name pairs when I read and write ?</p>\n<p>Any help would be appriciated</p>", "body_text": "System information\n\nI have written custom code:\nOS  -  Linux Ubuntu 16.04:\nTensorFlow installed from binary:\nTensorFlow version - 1.10.1 (GPU):\nPython version - 3.6.5:\nCUDA/cuDNN version - 9.0/7.0:\n\nIssue:\nI trying to create tfrecords for my sematic segmentation dataset (rgb_image_in -> binary_raycast_out).\nBelow is my code to write the list of images to a train.tfrecord.\n        def _process_image_files(image_names, raycast_names):\n        \n            writer = tf.python_io.TFRecordWriter('train')\n    \n            #My implementation of decoding jpeg/png image\n            coder = ImageCoder()\n    \n            for i in range(len(image_names)):\n                print('{}\\n{}\\n\\n'.format(image_names[i], raycast_names[i]))\n\n                image_buffer, im_height, im_width, im_channels = _process_image(image_names[i], coder)\n\n                raycast_buffer, rc_height, rc_width, rc_channels = _process_image(raycast_names[i], coder)\n\n                example = _convert_to_example(image_names[i], raycast_names[i], image_buffer, raycast_buffer, \\\n                                              im_height, im_width, im_channels)\n\n                writer.write(example.SerializeToString())\n            writer.close()\n            sys.stdout.flush() \n    \n    def _process_image(filename, coder):\n        with tf.gfile.FastGFile(filename, 'rb') as f:\n            image_data = f.read()\n\n        # Decode the RGB JPEG.\n        image = coder.decode_jpeg(image_data)\n\n        return image_data, height, width, channels\n    \n    \n    def _convert_to_example(image_name, raycast_name, image_buffer, raycast_buffer, sample_height, sample_width, sample_channels):\n    \n        example = tf.train.Example(features=tf.train.Features(feature={\n            'height': _int64_feature(sample_height),\n            'width': _int64_feature(sample_width),\n            'channels': _int64_feature(sample_channels),\n            'image/filename': _bytes_feature(tf.compat.as_bytes(image_name)),\n            'image/encoded': _bytes_feature(tf.compat.as_bytes(image_buffer)),\n            'raycast/filename': _bytes_feature(tf.compat.as_bytes(raycast_name)),\n            'raycast/encoded': _bytes_feature(tf.compat.as_bytes(raycast_buffer))}))\n    \n        return example\n\nThe above code works fine in creating the tfrecord file. I put some print statements inside the _convert_to_example method to make sure the corresponding filenames (image_file & raycast_file) are getting written in one example.\nHowever, when I read the examples from tfrecord and print the image names, it looks like the image_file & raycast_file names do not correspond. The pair of images read by the tfRecordReader() is wrong.\nBelow is my code to read the record:\n    def parse_example_proto(example_serialized):\n    \n        feature_map = {\n                        'image/encoded': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n                        'raycast/encoded': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n                        'height': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\n                        'width': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\n                        'channels': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\n                        'image/filename': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n                        'raycast/filename': tf.FixedLenFeature([], dtype=tf.string, default_value='')\n                        }\n    \n        features = tf.parse_single_example(example_serialized, feature_map)\n    \n        return features['image/encoded'], features['raycast/encoded'], \\\n               features['height'], features['width'], features['channels'],\\\n               features['image/filename'], features['raycast/filename']\n    \n                \n    \n    def retirieve_samples():\n        \n        with tf.name_scope('batch_processing'):\n            data_files = ['train']\n    \n            filename_queue = tf.train.string_input_producer(data_files, shuffle=False)\n    \n            reader = tf.TFRecordReader()\n    \n            _, example_serialized = reader.read(filename_queue)\n    \n            image_buffer, raycast_buffer, height, width, channels, image_name, raycast_name = parse_example_proto(example_serialized)            \n            \n            return image_name, raycast_name\n\nBelow is my code to print a pair of filenames\n    image_name, raycast_name = retirieve_samples()\n    with tf.Session() as sess:    \n        for i in range(1):\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n            print(sess.run(image_name))\n            print(sess.run(raycast_name))\n            coord.request_stop()\n            coord.join(threads)\n\nI have spent few days on this. I am not able to identify why I am not able to retrieve the correct pair. An example being retrieved should have the same data as the example being created right ? Why am I seeing different name pairs when I read and write ?\nAny help would be appriciated", "body": "### System information\r\n- **I have written custom code**:\r\n- **OS  -  Linux Ubuntu 16.04**:\r\n- **TensorFlow installed from binary**:\r\n- **TensorFlow version - 1.10.1 (GPU)**:\r\n- **Python version - 3.6.5**:\r\n- **CUDA/cuDNN version - 9.0/7.0**:\r\n\r\n### Issue:\r\nI trying to create tfrecords for my sematic segmentation dataset (rgb_image_in -> binary_raycast_out). \r\n\r\n#### Below is my code to write the list of images to a train.tfrecord.\r\n\r\n\r\n```\r\n        def _process_image_files(image_names, raycast_names):\r\n        \r\n            writer = tf.python_io.TFRecordWriter('train')\r\n    \r\n            #My implementation of decoding jpeg/png image\r\n            coder = ImageCoder()\r\n    \r\n            for i in range(len(image_names)):\r\n                print('{}\\n{}\\n\\n'.format(image_names[i], raycast_names[i]))\r\n\r\n                image_buffer, im_height, im_width, im_channels = _process_image(image_names[i], coder)\r\n\r\n                raycast_buffer, rc_height, rc_width, rc_channels = _process_image(raycast_names[i], coder)\r\n\r\n                example = _convert_to_example(image_names[i], raycast_names[i], image_buffer, raycast_buffer, \\\r\n                                              im_height, im_width, im_channels)\r\n\r\n                writer.write(example.SerializeToString())\r\n            writer.close()\r\n            sys.stdout.flush() \r\n    \r\n    def _process_image(filename, coder):\r\n        with tf.gfile.FastGFile(filename, 'rb') as f:\r\n            image_data = f.read()\r\n\r\n        # Decode the RGB JPEG.\r\n        image = coder.decode_jpeg(image_data)\r\n\r\n        return image_data, height, width, channels\r\n    \r\n    \r\n    def _convert_to_example(image_name, raycast_name, image_buffer, raycast_buffer, sample_height, sample_width, sample_channels):\r\n    \r\n        example = tf.train.Example(features=tf.train.Features(feature={\r\n            'height': _int64_feature(sample_height),\r\n            'width': _int64_feature(sample_width),\r\n            'channels': _int64_feature(sample_channels),\r\n            'image/filename': _bytes_feature(tf.compat.as_bytes(image_name)),\r\n            'image/encoded': _bytes_feature(tf.compat.as_bytes(image_buffer)),\r\n            'raycast/filename': _bytes_feature(tf.compat.as_bytes(raycast_name)),\r\n            'raycast/encoded': _bytes_feature(tf.compat.as_bytes(raycast_buffer))}))\r\n    \r\n        return example\r\n```\r\n\r\n\r\nThe above code works fine in creating the tfrecord file. I put some print statements inside the `_convert_to_example` method to make sure the corresponding filenames (image_file & raycast_file) are getting written in one example.\r\n\r\nHowever, when I read the examples from tfrecord and print the image names, it looks like the image_file & raycast_file names do not correspond. The pair of images read by the tfRecordReader() is wrong.\r\n\r\n#### Below is my code to read the record:\r\n\r\n\r\n```\r\n    def parse_example_proto(example_serialized):\r\n    \r\n        feature_map = {\r\n                        'image/encoded': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\r\n                        'raycast/encoded': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\r\n                        'height': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\r\n                        'width': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\r\n                        'channels': tf.FixedLenFeature([1], dtype=tf.int64, default_value=-1),\r\n                        'image/filename': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\r\n                        'raycast/filename': tf.FixedLenFeature([], dtype=tf.string, default_value='')\r\n                        }\r\n    \r\n        features = tf.parse_single_example(example_serialized, feature_map)\r\n    \r\n        return features['image/encoded'], features['raycast/encoded'], \\\r\n               features['height'], features['width'], features['channels'],\\\r\n               features['image/filename'], features['raycast/filename']\r\n    \r\n                \r\n    \r\n    def retirieve_samples():\r\n        \r\n        with tf.name_scope('batch_processing'):\r\n            data_files = ['train']\r\n    \r\n            filename_queue = tf.train.string_input_producer(data_files, shuffle=False)\r\n    \r\n            reader = tf.TFRecordReader()\r\n    \r\n            _, example_serialized = reader.read(filename_queue)\r\n    \r\n            image_buffer, raycast_buffer, height, width, channels, image_name, raycast_name = parse_example_proto(example_serialized)            \r\n            \r\n            return image_name, raycast_name\r\n```\r\n\r\n#### Below is my code to print a pair of filenames\r\n\r\n\r\n\r\n```\r\n    image_name, raycast_name = retirieve_samples()\r\n    with tf.Session() as sess:    \r\n        for i in range(1):\r\n            coord = tf.train.Coordinator()\r\n            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n            print(sess.run(image_name))\r\n            print(sess.run(raycast_name))\r\n            coord.request_stop()\r\n            coord.join(threads)\r\n```\r\nI have spent few days on this. I am not able to identify why I am not able to retrieve the correct pair. An example being retrieved should have the same data as the example being created right ? Why am I seeing different name pairs when I read and write ?\r\n\r\nAny help would be appriciated\r\n"}