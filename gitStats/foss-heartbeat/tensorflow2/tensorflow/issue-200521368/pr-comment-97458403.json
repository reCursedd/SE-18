{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/97458403", "pull_request_review_id": 18066028, "id": 97458403, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk3NDU4NDAz", "diff_hunk": "@@ -0,0 +1,147 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+    http://www.apache.org/licenses/LICENSE-2.0\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#if GOOGLE_CUDA\n+\n+#define EIGEN_USE_GPU\n+\n+#include \"tensorflow/core/kernels/adjust_hsv_op_common.h\"\n+#include \"tensorflow/core/util/cuda_kernel_helper.h\"\n+\n+namespace tensorflow {\n+\n+typedef Eigen::GpuDevice GPUDevice;\n+\n+namespace internal {\n+\n+typedef struct RgbTuple {\n+  float r;\n+  float g;\n+  float b;\n+} RgbTuple;\n+\n+typedef struct HsvTuple {\n+  float h;\n+  float s;\n+  float v;\n+} HsvTuple;\n+\n+__device__ HsvTuple rgb2hsv_cuda(const float r, const float g, const float b) {\n+  HsvTuple tuple;\n+  const float M = fmaxf(r, fmaxf(g, b));\n+  const float m = fminf(r, fminf(g, b));\n+  const float chroma = M - m;\n+  float h = 0.0f, s = 0.0f;\n+  // hue\n+  if (chroma > 0.0f) {\n+    if (M == r) {\n+      const float num = (g - b) / chroma;\n+      const float sgn = num < 0.0f;\n+      const float sign = powf(-1.0f, sgn);\n+      h = (sgn * 6.0f + sign * fmodf(sign * num, 6.0f)) / 6.0f;\n+    } else if (M == g) {\n+      h = ((b - r) / chroma + 2.0) / 6.0f;\n+    } else {\n+      h = ((r - g) / chroma + 4.0) / 6.0f;\n+    }\n+  } else {\n+    h = 0.0f;\n+  }\n+  // saturation\n+  if (M > 0.0) {\n+    s = chroma / M;\n+  } else {\n+    s = 0.0f;\n+  }\n+  tuple.h = h;\n+  tuple.s = s;\n+  tuple.v = M;\n+  return tuple;\n+}\n+\n+__device__ RgbTuple hsv2rgb_cuda(const float h, const float s, const float v) {\n+  RgbTuple tuple;\n+  const float new_h = h * 6.0f;\n+  const float chroma = v * s;\n+  const float x = chroma * (1.0 - fabsf(fmodf(new_h, 2.0f) - 1.0f));\n+  const float new_m = v - chroma;\n+  const bool between_0_and_1 = new_h >= 0.0 && new_h < 1;\n+  const bool between_1_and_2 = new_h >= 1.0 && new_h < 2;\n+  const bool between_2_and_3 = new_h >= 2 && new_h < 3;\n+  const bool between_3_and_4 = new_h >= 3 && new_h < 4;\n+  const bool between_4_and_5 = new_h >= 4 && new_h < 5;\n+  const bool between_5_and_6 = new_h >= 5 && new_h < 6;\n+  tuple.r = chroma * (between_0_and_1 || between_5_and_6) +\n+    x * (between_1_and_2 || between_4_and_5) + new_m;\n+  tuple.g = chroma * (between_1_and_2 || between_2_and_3) +\n+    x * (between_0_and_1 || between_3_and_4) + new_m;\n+  tuple.b =  chroma * (between_3_and_4 || between_4_and_5) +\n+    x * (between_2_and_3 || between_5_and_6) + new_m;\n+  return tuple;\n+}\n+\n+__global__ void adjust_hue_nhwc(const int number_elements,\n+                                const float * const input, float * const output, const float * const hue_delta) {\n+  const float delta = hue_delta[0];\n+  // multiply by 3 since we're dealing with contiguous RGB bytes for each pixel (NHWC)\n+  const int idx = (blockDim.x * blockIdx.x + threadIdx.x) * 3;\n+  // bounds check\n+  if (idx > number_elements) {\n+    return;\n+  }\n+  const HsvTuple hsv = rgb2hsv_cuda(input[idx], input[idx+1], input[idx+2]);\n+  // hue adjustment\n+  float new_h = fmodf(hsv.h + delta, 1.0f);\n+  if (new_h < 0.0f) {\n+    new_h = fmodf(1.0f + new_h, 1.0f);\n+  }\n+  const RgbTuple rgb = hsv2rgb_cuda(new_h, hsv.s, hsv.v);\n+  output[idx] = rgb.r;\n+  output[idx + 1] = rgb.g;\n+  output[idx + 2] = rgb.b;\n+}\n+} // namespace internal\n+\n+template <>\n+class AdjustHueOp<GPUDevice> : public AdjustHueOpBase {\n+public:\n+explicit AdjustHueOp(OpKernelConstruction* const context)\n+  : AdjustHueOpBase(context) {}\n+\n+void DoCompute(OpKernelContext* const context,\n+  const ComputeOptions& options) override {\n+  const Tensor* input = options.input;\n+  const Tensor* delta = options.delta;\n+  Tensor* const output = options.output;\n+  const int64 number_elements = input->NumElements();\n+  const GPUDevice &d = context->eigen_gpu_device();\n+  const auto stream = d.stream();\n+  OP_REQUIRES(context, stream, errors::Internal(\"No GPU stream available.\"));\n+  if (number_elements > 0) {\n+    const CudaLaunchConfig config = GetCudaLaunchConfig(number_elements, d);\n+    const float * const input_data = input->flat<float>().data();\n+    const float * const delta_h = delta->flat<float>().data();\n+    float * const output_data = output->flat<float>().data();\n+    const int threads_per_block = config.thread_per_block;\n+    const int block_count = (number_elements + threads_per_block - 1) / threads_per_block;\n+    internal::adjust_hue_nhwc<<<block_count, threads_per_block, 0, stream>>>(\n+      number_elements, input_data, output_data, delta_h\n+    );\n+  }\n+}\n+};\n+\n+REGISTER_KERNEL_BUILDER(Name(\"AdjustHue\").Device(DEVICE_GPU),", "path": "tensorflow/core/kernels/adjust_hue_op_gpu.cu.cc", "position": null, "original_position": 142, "commit_id": "9dde8ec884e556295cd942c765cd18b8c91479f7", "original_commit_id": "226b40ff0e2d3f09c9ee14bf7d0e2c31c9c01584", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "body": "Ah! I am a bit surprised that this worked at all. \r\n\r\nOlder nvcc cannot handle OpKernel and its registration process. So we had to do all the OpKernel in the CPU translation unit, and only call out an launch function into the Cuda translation unit. \r\n\r\nIt might be safer to follow that convention for the multiple Cuda compilers we are supporting. Here is an example, there are many in the kernels directory. \r\n\r\n1. GPU kernel registration in the CPU translation unit: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L315\r\n2. The kernel does all the OpKernel related things in this file, and call out to its GPU functor at. Only simpler data structure crosses the file boundary. \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L291\r\n3. The GPU functor is defined here: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc#L59\r\n4. And instantiated here: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc#L95\r\n", "created_at": "2017-01-24T01:39:47Z", "updated_at": "2017-03-08T21:09:05Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/6818#discussion_r97458403", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6818", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/97458403"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/6818#discussion_r97458403"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6818"}}, "body_html": "<p>Ah! I am a bit surprised that this worked at all.</p>\n<p>Older nvcc cannot handle OpKernel and its registration process. So we had to do all the OpKernel in the CPU translation unit, and only call out an launch function into the Cuda translation unit.</p>\n<p>It might be safer to follow that convention for the multiple Cuda compilers we are supporting. Here is an example, there are many in the kernels directory.</p>\n<ol>\n<li>GPU kernel registration in the CPU translation unit:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L315\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L315</a></li>\n<li>The kernel does all the OpKernel related things in this file, and call out to its GPU functor at. Only simpler data structure crosses the file boundary.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L291\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L291</a></li>\n<li>The GPU functor is defined here:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc#L59\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc#L59</a></li>\n<li>And instantiated here:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc#L95\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc#L95</a></li>\n</ol>", "body_text": "Ah! I am a bit surprised that this worked at all.\nOlder nvcc cannot handle OpKernel and its registration process. So we had to do all the OpKernel in the CPU translation unit, and only call out an launch function into the Cuda translation unit.\nIt might be safer to follow that convention for the multiple Cuda compilers we are supporting. Here is an example, there are many in the kernels directory.\n\nGPU kernel registration in the CPU translation unit:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L315\nThe kernel does all the OpKernel related things in this file, and call out to its GPU functor at. Only simpler data structure crosses the file boundary.\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L291\nThe GPU functor is defined here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc#L59\nAnd instantiated here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc#L95"}