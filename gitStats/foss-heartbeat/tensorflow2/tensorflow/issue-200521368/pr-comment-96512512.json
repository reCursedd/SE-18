{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/96512512", "pull_request_review_id": 17093385, "id": 96512512, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk2NTEyNTEy", "diff_hunk": "@@ -0,0 +1,182 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+    http://www.apache.org/licenses/LICENSE-2.0\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#if GOOGLE_CUDA\n+\n+#define EIGEN_USE_GPU\n+\n+#include \"adjust_hue_op.h\"\n+#include \"tensorflow/core/util/cuda_kernel_helper.h\"\n+\n+namespace tensorflow {\n+\n+typedef Eigen::GpuDevice GPUDevice;\n+\n+namespace internal {\n+\n+typedef struct RgbTuple {\n+\n+  float r, g, b;\n+\n+} RgbTuple;\n+\n+typedef struct HsvTuple {\n+\n+  float h, s, v;\n+\n+} HsvTuple;\n+\n+__device__ HsvTuple rgb2hsv_cuda(const float r, const float g, const float b) {\n+\n+  HsvTuple tuple;\n+\n+  const float M = fmaxf(r, fmaxf(g, b));\n+  const float m = fminf(r, fminf(g, b));\n+  const float chroma = M - m;\n+\n+  float h = 0.0f, s = 0.0f;\n+\n+    // hue\n+    if (chroma > 0.0f) {\n+      if (M == r) {\n+\n+        const float num = (g - b) / chroma;\n+        const float sgn = num < 0.0f;\n+        const float sign = powf(-1.0f, sgn);\n+        h = (sgn * 6.0f + sign * fmodf(sign * num, 6.0f)) / 6.0f;\n+\n+      } else if (M == g) {\n+\n+        h = ((b - r) / chroma + 2.0) / 6.0f;\n+\n+      } else {\n+\n+        h = ((r - g) / chroma + 4.0) / 6.0f;\n+      }\n+\n+    } else {\n+\n+      h = 0.0f;\n+    }\n+\n+   // saturation\n+   if (M > 0.0) {\n+\n+     s = chroma / M;\n+\n+   } else {\n+\n+     s = 0.0f;\n+   }\n+\n+  tuple.h = h;\n+  tuple.s = s;\n+  tuple.v = M;\n+\n+  return tuple;\n+}\n+\n+__device__ RgbTuple hsv2rgb_cuda(const float h, const float s, const float v) {\n+\n+  RgbTuple tuple;\n+\n+  const float new_h = h * 6.0f;\n+  const float chroma = v * s;\n+  const float x = chroma * (1.0 - fabsf(fmodf(new_h, 2.0f) - 1.0f));\n+\n+  const float new_m = v - chroma;\n+  const bool between_0_and_1 = new_h >= 0.0 && new_h < 1;\n+  const bool between_1_and_2 = new_h >= 1.0 && new_h < 2;\n+  const bool between_2_and_3 = new_h >= 2 && new_h < 3;\n+  const bool between_3_and_4 = new_h >= 3 && new_h < 4;\n+  const bool between_4_and_5 = new_h >= 4 && new_h < 5;\n+  const bool between_5_and_6 = new_h >= 5 && new_h < 6;\n+\n+  tuple.r = chroma * (between_0_and_1 || between_5_and_6) +\n+                  x * (between_1_and_2 || between_4_and_5) + new_m;\n+\n+  tuple.g = chroma * (between_1_and_2 || between_2_and_3) +\n+                      x * (between_0_and_1 || between_3_and_4) + new_m;\n+\n+  tuple.b =  chroma * (between_3_and_4 || between_4_and_5) +\n+                      x * (between_2_and_3 || between_5_and_6) + new_m;\n+\n+  return tuple;\n+}\n+\n+__global__ void adjust_hue_nhwc(const int number_elements,\n+                                const float * const input, float * const output, const float * const hue_delta) {\n+\n+        const float delta = hue_delta[0];\n+\n+\t// multiply by 3 since we're dealing with contiguous RGB bytes for each pixel\n+\tconst int idx = (blockDim.x * blockIdx.x + threadIdx.x) * 3;\n+\n+\t// bounds check\n+\tif (idx > number_elements) {\n+\t\treturn;\n+\t}\n+\n+        const HsvTuple hsv = rgb2hsv_cuda(input[idx], input[idx+1], input[idx+2]);\n+\n+\t// hue adjustment\n+\tconst float new_h = fmodf(hsv.h + delta, 1.0f);\n+\n+        const RgbTuple rgb = hsv2rgb_cuda(new_h, hsv.s, hsv.v);\n+        output[idx] = rgb.r;\n+        output[idx + 1] = rgb.g;\n+        output[idx + 2] = rgb.b;\n+\n+}\n+}\n+\n+template <>\n+class AdjustHueOp<GPUDevice> : public AdjustHueOpBase {\n+public:\n+\texplicit AdjustHueOp(OpKernelConstruction* const context)\n+\t\t: AdjustHueOpBase(context) {}\n+\n+\tvoid DoCompute(OpKernelContext* const context,\n+\t               const ComputeOptions& options) override {\n+\n+\t\tconst Tensor* input = options.input;\n+\t\tconst Tensor* delta = options.delta;\n+\t\tTensor* const output = options.output;\n+\t\tconst int64 number_elements = input->NumElements();\n+\t\tconst GPUDevice &d = context->eigen_gpu_device();\n+\t\tconst auto stream = d.stream();\n+\n+\t\tOP_REQUIRES(context, stream, errors::Internal(\"No GPU stream available.\"));\n+\n+\t\tif (number_elements > 0) {\n+\n+\n+\t\t\tconst CudaLaunchConfig config = GetCudaLaunchConfig(number_elements, d);\n+\t\t\tconst float * const input_data = input->flat<float>().data();\n+\t\t\tconst float * const delta_h = delta->flat<float>().data();\n+\t\t\tfloat * const output_data = output->flat<float>().data();\n+                        const int threads_per_block = config.thread_per_block;\n+                        const int block_count = (number_elements + threads_per_block - 1) / threads_per_block;", "path": "tensorflow/core/kernels/adjust_hue_op_gpu.cu.cc", "position": null, "original_position": 167, "commit_id": "9dde8ec884e556295cd942c765cd18b8c91479f7", "original_commit_id": "d91f66d32a1e9318b2df97f40044ff46b2ca849c", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "body": "This or Eigen::divup. Really up to you. ", "created_at": "2017-01-17T21:17:56Z", "updated_at": "2017-03-08T21:09:05Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/6818#discussion_r96512512", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6818", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/96512512"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/6818#discussion_r96512512"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6818"}}, "body_html": "<p>This or Eigen::divup. Really up to you.</p>", "body_text": "This or Eigen::divup. Really up to you."}