{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/243614376", "html_url": "https://github.com/tensorflow/tensorflow/issues/4093#issuecomment-243614376", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4093", "id": 243614376, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MzYxNDM3Ng==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-30T23:32:54Z", "updated_at": "2016-08-30T23:32:54Z", "author_association": "MEMBER", "body_html": "<p>You're trying to allocate a 4D tensor of 2400485376 elements.  Assuming these are float32, that's about 9GB which is quite large.  It looks like it's for a GPU Op.  How big is the memory on your GPU, and what other tensors are live at the same time?  Did you really manage to train 1750 steps with this tensor allocating at every step?</p>", "body_text": "You're trying to allocate a 4D tensor of 2400485376 elements.  Assuming these are float32, that's about 9GB which is quite large.  It looks like it's for a GPU Op.  How big is the memory on your GPU, and what other tensors are live at the same time?  Did you really manage to train 1750 steps with this tensor allocating at every step?", "body": "You're trying to allocate a 4D tensor of 2400485376 elements.  Assuming these are float32, that's about 9GB which is quite large.  It looks like it's for a GPU Op.  How big is the memory on your GPU, and what other tensors are live at the same time?  Did you really manage to train 1750 steps with this tensor allocating at every step?\n"}