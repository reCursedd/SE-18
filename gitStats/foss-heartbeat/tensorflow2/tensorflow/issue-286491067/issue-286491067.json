{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15912", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15912/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15912/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15912/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15912", "id": 286491067, "node_id": "MDU6SXNzdWUyODY0OTEwNjc=", "number": 15912, "title": "Eager: error when restore tfe.Network checkpoint by tfe.restore_network_checkpoint", "user": {"login": "traveller59", "id": 28866047, "node_id": "MDQ6VXNlcjI4ODY2MDQ3", "avatar_url": "https://avatars1.githubusercontent.com/u/28866047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/traveller59", "html_url": "https://github.com/traveller59", "followers_url": "https://api.github.com/users/traveller59/followers", "following_url": "https://api.github.com/users/traveller59/following{/other_user}", "gists_url": "https://api.github.com/users/traveller59/gists{/gist_id}", "starred_url": "https://api.github.com/users/traveller59/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/traveller59/subscriptions", "organizations_url": "https://api.github.com/users/traveller59/orgs", "repos_url": "https://api.github.com/users/traveller59/repos", "events_url": "https://api.github.com/users/traveller59/events{/privacy}", "received_events_url": "https://api.github.com/users/traveller59/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-06T15:19:47Z", "updated_at": "2018-01-06T15:31:16Z", "closed_at": "2018-01-06T15:31:16Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Win10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.6.0dev20170105</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:N/A</li>\n<li><strong>CUDA/cuDNN version</strong>:9.0/7.0</li>\n<li><strong>GPU model and memory</strong>:pascal</li>\n<li><strong>Exact command to reproduce</strong>:N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When I want to restore tfe.Network by using tfe.restore_network_checkpoint from a graph-mode checkpoint(such as pretrained slim resnet ckpt, so need name map of tfe.restore_network_checkpoint), I get an error:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">RuntimeError</span>                              Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span><span class=\"pl-k\">-</span>cbde22383c9e<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n     <span class=\"pl-c1\">20</span>     images <span class=\"pl-k\">=</span> tf.constant(toy_data)\n     <span class=\"pl-c1\">21</span>     logits <span class=\"pl-k\">=</span> net(images)\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">22</span>     tf.contrib.eager.restore_network_checkpoint(net, ckpt)\n\nc:\\<span class=\"pl-ii\">users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\eager\\python\\network.py in restore_network_checkpoint(network, save_path, map_func)</span>\n    <span class=\"pl-c1\">946</span>       save_path<span class=\"pl-k\">=</span>save_path,\n    <span class=\"pl-c1\">947</span>       map_func<span class=\"pl-k\">=</span>map_func,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">948</span>       user_map_func<span class=\"pl-k\">=</span>user_map_func)\n    <span class=\"pl-c1\">949</span>   <span class=\"pl-c\"><span class=\"pl-c\">#</span> Step two is to set a custom getter which restores variables on creation,</span>\n    <span class=\"pl-c1\">950</span>   <span class=\"pl-c\"><span class=\"pl-c\">#</span> for those variables which have not been added to sub-Layers yet.</span>\n\nc:\\<span class=\"pl-ii\">users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\eager\\python\\network.py in _restore_existing_variables(network, save_path, map_func, user_map_func)</span>\n    <span class=\"pl-c1\">859</span>       sess <span class=\"pl-k\">=</span> ops.get_default_session()\n    <span class=\"pl-c1\">860</span>     saver_lib.Saver(<span class=\"pl-v\">var_list</span><span class=\"pl-k\">=</span>existing_variables_by_checkpoint_name).restore(\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">861</span>         <span class=\"pl-v\">sess</span><span class=\"pl-k\">=</span>sess, <span class=\"pl-v\">save_path</span><span class=\"pl-k\">=</span>save_path)\n    <span class=\"pl-c1\">862</span>   <span class=\"pl-k\">return</span> existing_variables_by_checkpoint_name\n    <span class=\"pl-c1\">863</span> \n\nc:\\<span class=\"pl-ii\">users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in restore(self, sess, save_path)</span>\n   <span class=\"pl-c1\">1686</span>                {<span class=\"pl-c1\">self</span>.saver_def.filename_tensor_name: save_path})\n   <span class=\"pl-c1\">1687</span>     <span class=\"pl-k\">else</span>:\n<span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">1688</span>       <span class=\"pl-c1\">self</span>._build_eager(save_path, <span class=\"pl-v\">build_save</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">build_restore</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n   <span class=\"pl-c1\">1689</span> \n   <span class=\"pl-c1\">1690</span>   <span class=\"pl-k\">@</span><span class=\"pl-c1\">staticmethod</span>\n\nc:\\<span class=\"pl-ii\">users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build_eager(self, checkpoint_path, build_save, build_restore)</span>\n   <span class=\"pl-c1\">1250</span>   <span class=\"pl-k\">def</span> <span class=\"pl-en\">_build_eager</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">checkpoint_path</span>, <span class=\"pl-smi\">build_save</span>, <span class=\"pl-smi\">build_restore</span>):\n   <span class=\"pl-c1\">1251</span>     <span class=\"pl-c1\">self</span>._build(\n<span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">1252</span>         checkpoint_path, <span class=\"pl-v\">build_save</span><span class=\"pl-k\">=</span>build_save, <span class=\"pl-v\">build_restore</span><span class=\"pl-k\">=</span>build_restore)\n   <span class=\"pl-c1\">1253</span> \n   <span class=\"pl-c1\">1254</span>   <span class=\"pl-k\">def</span> <span class=\"pl-en\">_build</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">checkpoint_path</span>, <span class=\"pl-smi\">build_save</span>, <span class=\"pl-smi\">build_restore</span>):\n\nc:\\<span class=\"pl-ii\">users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build(self, checkpoint_path, build_save, build_restore)</span>\n   <span class=\"pl-c1\">1282</span>           restore_sequentially<span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._restore_sequentially,\n   <span class=\"pl-c1\">1283</span>           filename<span class=\"pl-k\">=</span>checkpoint_path,\n<span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">1284</span>           build_save<span class=\"pl-k\">=</span>build_save, build_restore<span class=\"pl-k\">=</span>build_restore)\n   <span class=\"pl-c1\">1285</span>     <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">self</span>.saver_def <span class=\"pl-k\">and</span> <span class=\"pl-c1\">self</span>._name:\n   <span class=\"pl-c1\">1286</span>       <span class=\"pl-c\"><span class=\"pl-c\">#</span> Since self._name is used as a name_scope by builder(), we are</span>\n\nc:\\<span class=\"pl-ii\">users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build_internal(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)</span>\n    <span class=\"pl-c1\">748</span>                         [saveable.op <span class=\"pl-k\">for</span> saveable <span class=\"pl-k\">in</span> saveables]) <span class=\"pl-k\">as</span> name:\n    <span class=\"pl-c1\">749</span>       <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add the Constant string tensor for the filename.</span>\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">750</span>       filename_tensor <span class=\"pl-k\">=</span> constant_op.constant(filename <span class=\"pl-k\">or</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>model<span class=\"pl-pds\">\"</span></span>)\n    <span class=\"pl-c1\">751</span> \n    <span class=\"pl-c1\">752</span>       <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add the save ops.</span>\n\nc:\\<span class=\"pl-ii\">users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in constant(value, dtype, shape, name, verify_shape)</span>\n    <span class=\"pl-c1\">182</span>   ctx <span class=\"pl-k\">=</span> context.context()\n    <span class=\"pl-c1\">183</span>   <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> ctx.in_graph_mode():\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">184</span>     t <span class=\"pl-k\">=</span> convert_to_eager_tensor(value, ctx, dtype)\n    <span class=\"pl-c1\">185</span>     <span class=\"pl-k\">if</span> shape <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n    <span class=\"pl-c1\">186</span>       <span class=\"pl-k\">return</span> t\n\nc:\\<span class=\"pl-ii\">users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in convert_to_eager_tensor(value, ctx, dtype)</span>\n    <span class=\"pl-c1\">129</span>     <span class=\"pl-k\">return</span> t\n    <span class=\"pl-c1\">130</span>   <span class=\"pl-k\">else</span>:\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">131</span>     <span class=\"pl-k\">return</span> ops.EagerTensor(value, <span class=\"pl-v\">context</span><span class=\"pl-k\">=</span>handle, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span>device, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype)\n    <span class=\"pl-c1\">132</span> \n    <span class=\"pl-c1\">133</span> \n\n<span class=\"pl-c1\">RuntimeError</span>: Error copying tensor to device: <span class=\"pl-k\">/</span>job:localhost<span class=\"pl-k\">/</span>replica:<span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>task:<span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>device:<span class=\"pl-c1\">GPU</span>:<span class=\"pl-c1\">0</span>. Can<span class=\"pl-s\"><span class=\"pl-pds\">'</span>t copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.<span class=\"pl-ii\"></span></span></pre></div>\n<p>code to reproduce this error:<br>\nfirst run graph code to save a ckpt:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto()\nconfig.gpu_options.allow_growth<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">cnn</span>(<span class=\"pl-smi\">x</span>):\n    <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>net<span class=\"pl-pds\">'</span></span>):\n        x <span class=\"pl-k\">=</span> tf.layers.dense(x, <span class=\"pl-c1\">10</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc<span class=\"pl-pds\">'</span></span>)\n        <span class=\"pl-k\">return</span> x\nckpt <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/tmp/graph/test.ckpt<span class=\"pl-pds\">'</span></span>\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n    images <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">784</span>])\n    logits <span class=\"pl-k\">=</span> cnn(images)\n    saver <span class=\"pl-k\">=</span> tf.train.Saver(<span class=\"pl-v\">save_relative_paths</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    <span class=\"pl-c1\">print</span>(tf.global_variables())\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n        sess.run(tf.global_variables_initializer())\n        saver.save(sess, ckpt)</pre></div>\n<p>Then run eager code to load ckpt, note that any ckpt path can produce same error, so I think ckpt file has no problem.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.eager <span class=\"pl-k\">as</span> tfe\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto()\nconfig.gpu_options.allow_growth<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\ntfe.enable_eager_execution(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config)\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">CNN</span>(<span class=\"pl-e\">tfe</span>.<span class=\"pl-e\">Network</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">name</span>):\n        <span class=\"pl-c1\">super</span>(<span class=\"pl-c1\">CNN</span>, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>(name)\n        <span class=\"pl-c1\">self</span>.fc <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.track_layer(tf.layers.Dense(<span class=\"pl-c1\">10</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc<span class=\"pl-pds\">'</span></span>))\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">call</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        x <span class=\"pl-k\">=</span> tf.reshape(x, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">784</span>])\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.fc(x)\n        <span class=\"pl-k\">return</span> x\ntoy_data <span class=\"pl-k\">=</span> np.ones((<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">784</span>)).astype(np.float32)\ndevice <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu:0<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">if</span> tfe.num_gpus() <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu:0<span class=\"pl-pds\">\"</span></span>\nnet <span class=\"pl-k\">=</span> CNN(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>net<span class=\"pl-pds\">'</span></span>)\nckpt <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/tmp/graph/test.ckpt<span class=\"pl-pds\">'</span></span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> any other paths produce same error</span>\n<span class=\"pl-k\">with</span> tf.device(device):\n    images <span class=\"pl-k\">=</span> tf.constant(toy_data)\n    logits <span class=\"pl-k\">=</span> net(images)\n    tfe.restore_network_checkpoint(net, ckpt)</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Win10\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.6.0dev20170105\nPython version: 3.6\nBazel version (if compiling from source):N/A\nGCC/Compiler version (if compiling from source):N/A\nCUDA/cuDNN version:9.0/7.0\nGPU model and memory:pascal\nExact command to reproduce:N/A\n\nDescribe the problem\nWhen I want to restore tfe.Network by using tfe.restore_network_checkpoint from a graph-mode checkpoint(such as pretrained slim resnet ckpt, so need name map of tfe.restore_network_checkpoint), I get an error:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-1-cbde22383c9e> in <module>()\n     20     images = tf.constant(toy_data)\n     21     logits = net(images)\n---> 22     tf.contrib.eager.restore_network_checkpoint(net, ckpt)\n\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\eager\\python\\network.py in restore_network_checkpoint(network, save_path, map_func)\n    946       save_path=save_path,\n    947       map_func=map_func,\n--> 948       user_map_func=user_map_func)\n    949   # Step two is to set a custom getter which restores variables on creation,\n    950   # for those variables which have not been added to sub-Layers yet.\n\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\eager\\python\\network.py in _restore_existing_variables(network, save_path, map_func, user_map_func)\n    859       sess = ops.get_default_session()\n    860     saver_lib.Saver(var_list=existing_variables_by_checkpoint_name).restore(\n--> 861         sess=sess, save_path=save_path)\n    862   return existing_variables_by_checkpoint_name\n    863 \n\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in restore(self, sess, save_path)\n   1686                {self.saver_def.filename_tensor_name: save_path})\n   1687     else:\n-> 1688       self._build_eager(save_path, build_save=False, build_restore=True)\n   1689 \n   1690   @staticmethod\n\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build_eager(self, checkpoint_path, build_save, build_restore)\n   1250   def _build_eager(self, checkpoint_path, build_save, build_restore):\n   1251     self._build(\n-> 1252         checkpoint_path, build_save=build_save, build_restore=build_restore)\n   1253 \n   1254   def _build(self, checkpoint_path, build_save, build_restore):\n\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build(self, checkpoint_path, build_save, build_restore)\n   1282           restore_sequentially=self._restore_sequentially,\n   1283           filename=checkpoint_path,\n-> 1284           build_save=build_save, build_restore=build_restore)\n   1285     elif self.saver_def and self._name:\n   1286       # Since self._name is used as a name_scope by builder(), we are\n\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build_internal(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\n    748                         [saveable.op for saveable in saveables]) as name:\n    749       # Add the Constant string tensor for the filename.\n--> 750       filename_tensor = constant_op.constant(filename or \"model\")\n    751 \n    752       # Add the save ops.\n\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in constant(value, dtype, shape, name, verify_shape)\n    182   ctx = context.context()\n    183   if not ctx.in_graph_mode():\n--> 184     t = convert_to_eager_tensor(value, ctx, dtype)\n    185     if shape is None:\n    186       return t\n\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\n    129     return t\n    130   else:\n--> 131     return ops.EagerTensor(value, context=handle, device=device, dtype=dtype)\n    132 \n    133 \n\nRuntimeError: Error copying tensor to device: /job:localhost/replica:0/task:0/device:GPU:0. Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.\ncode to reproduce this error:\nfirst run graph code to save a ckpt:\nimport tensorflow as tf\nimport numpy as np\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth=True\ndef cnn(x):\n    with tf.variable_scope('net'):\n        x = tf.layers.dense(x, 10, name='fc')\n        return x\nckpt = '/tmp/graph/test.ckpt'\nwith tf.Graph().as_default():\n    images = tf.placeholder(tf.float32, [None, 784])\n    logits = cnn(images)\n    saver = tf.train.Saver(save_relative_paths=True)\n    print(tf.global_variables())\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        saver.save(sess, ckpt)\nThen run eager code to load ckpt, note that any ckpt path can produce same error, so I think ckpt file has no problem.\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport numpy as np\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth=True\ntfe.enable_eager_execution(config=config)\nclass CNN(tfe.Network):\n    def __init__(self, name):\n        super(CNN, self).__init__(name)\n        self.fc = self.track_layer(tf.layers.Dense(10, name='fc'))\n    def call(self, x):\n        x = tf.reshape(x, [-1, 784])\n        x = self.fc(x)\n        return x\ntoy_data = np.ones((100, 784)).astype(np.float32)\ndevice = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\nnet = CNN('net')\nckpt = '/tmp/graph/test.ckpt' # any other paths produce same error\nwith tf.device(device):\n    images = tf.constant(toy_data)\n    logits = net(images)\n    tfe.restore_network_checkpoint(net, ckpt)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.6.0dev20170105\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **CUDA/cuDNN version**:9.0/7.0\r\n- **GPU model and memory**:pascal\r\n- **Exact command to reproduce**:N/A\r\n### Describe the problem\r\nWhen I want to restore tfe.Network by using tfe.restore_network_checkpoint from a graph-mode checkpoint(such as pretrained slim resnet ckpt, so need name map of tfe.restore_network_checkpoint), I get an error:\r\n```Python\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-cbde22383c9e> in <module>()\r\n     20     images = tf.constant(toy_data)\r\n     21     logits = net(images)\r\n---> 22     tf.contrib.eager.restore_network_checkpoint(net, ckpt)\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\eager\\python\\network.py in restore_network_checkpoint(network, save_path, map_func)\r\n    946       save_path=save_path,\r\n    947       map_func=map_func,\r\n--> 948       user_map_func=user_map_func)\r\n    949   # Step two is to set a custom getter which restores variables on creation,\r\n    950   # for those variables which have not been added to sub-Layers yet.\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\eager\\python\\network.py in _restore_existing_variables(network, save_path, map_func, user_map_func)\r\n    859       sess = ops.get_default_session()\r\n    860     saver_lib.Saver(var_list=existing_variables_by_checkpoint_name).restore(\r\n--> 861         sess=sess, save_path=save_path)\r\n    862   return existing_variables_by_checkpoint_name\r\n    863 \r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in restore(self, sess, save_path)\r\n   1686                {self.saver_def.filename_tensor_name: save_path})\r\n   1687     else:\r\n-> 1688       self._build_eager(save_path, build_save=False, build_restore=True)\r\n   1689 \r\n   1690   @staticmethod\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build_eager(self, checkpoint_path, build_save, build_restore)\r\n   1250   def _build_eager(self, checkpoint_path, build_save, build_restore):\r\n   1251     self._build(\r\n-> 1252         checkpoint_path, build_save=build_save, build_restore=build_restore)\r\n   1253 \r\n   1254   def _build(self, checkpoint_path, build_save, build_restore):\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build(self, checkpoint_path, build_save, build_restore)\r\n   1282           restore_sequentially=self._restore_sequentially,\r\n   1283           filename=checkpoint_path,\r\n-> 1284           build_save=build_save, build_restore=build_restore)\r\n   1285     elif self.saver_def and self._name:\r\n   1286       # Since self._name is used as a name_scope by builder(), we are\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in _build_internal(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\r\n    748                         [saveable.op for saveable in saveables]) as name:\r\n    749       # Add the Constant string tensor for the filename.\r\n--> 750       filename_tensor = constant_op.constant(filename or \"model\")\r\n    751 \r\n    752       # Add the save ops.\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in constant(value, dtype, shape, name, verify_shape)\r\n    182   ctx = context.context()\r\n    183   if not ctx.in_graph_mode():\r\n--> 184     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    185     if shape is None:\r\n    186       return t\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n    129     return t\r\n    130   else:\r\n--> 131     return ops.EagerTensor(value, context=handle, device=device, dtype=dtype)\r\n    132 \r\n    133 \r\n\r\nRuntimeError: Error copying tensor to device: /job:localhost/replica:0/task:0/device:GPU:0. Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.\r\n```\r\ncode to reproduce this error:\r\nfirst run graph code to save a ckpt:\r\n```Python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth=True\r\ndef cnn(x):\r\n    with tf.variable_scope('net'):\r\n        x = tf.layers.dense(x, 10, name='fc')\r\n        return x\r\nckpt = '/tmp/graph/test.ckpt'\r\nwith tf.Graph().as_default():\r\n    images = tf.placeholder(tf.float32, [None, 784])\r\n    logits = cnn(images)\r\n    saver = tf.train.Saver(save_relative_paths=True)\r\n    print(tf.global_variables())\r\n    with tf.Session(config=config) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        saver.save(sess, ckpt)\r\n```\r\nThen run eager code to load ckpt, note that any ckpt path can produce same error, so I think ckpt file has no problem.\r\n```Python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nimport numpy as np\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth=True\r\ntfe.enable_eager_execution(config=config)\r\nclass CNN(tfe.Network):\r\n    def __init__(self, name):\r\n        super(CNN, self).__init__(name)\r\n        self.fc = self.track_layer(tf.layers.Dense(10, name='fc'))\r\n    def call(self, x):\r\n        x = tf.reshape(x, [-1, 784])\r\n        x = self.fc(x)\r\n        return x\r\ntoy_data = np.ones((100, 784)).astype(np.float32)\r\ndevice = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\r\nnet = CNN('net')\r\nckpt = '/tmp/graph/test.ckpt' # any other paths produce same error\r\nwith tf.device(device):\r\n    images = tf.constant(toy_data)\r\n    logits = net(images)\r\n    tfe.restore_network_checkpoint(net, ckpt)\r\n```\r\n  "}