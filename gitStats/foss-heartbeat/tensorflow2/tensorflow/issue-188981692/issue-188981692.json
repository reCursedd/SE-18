{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5586", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5586/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5586/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5586/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5586", "id": 188981692, "node_id": "MDU6SXNzdWUxODg5ODE2OTI=", "number": 5586, "title": "AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'", "user": {"login": "sunxiaobiu", "id": 12237826, "node_id": "MDQ6VXNlcjEyMjM3ODI2", "avatar_url": "https://avatars3.githubusercontent.com/u/12237826?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sunxiaobiu", "html_url": "https://github.com/sunxiaobiu", "followers_url": "https://api.github.com/users/sunxiaobiu/followers", "following_url": "https://api.github.com/users/sunxiaobiu/following{/other_user}", "gists_url": "https://api.github.com/users/sunxiaobiu/gists{/gist_id}", "starred_url": "https://api.github.com/users/sunxiaobiu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sunxiaobiu/subscriptions", "organizations_url": "https://api.github.com/users/sunxiaobiu/orgs", "repos_url": "https://api.github.com/users/sunxiaobiu/repos", "events_url": "https://api.github.com/users/sunxiaobiu/events{/privacy}", "received_events_url": "https://api.github.com/users/sunxiaobiu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-11-13T17:11:58Z", "updated_at": "2016-11-14T16:41:27Z", "closed_at": "2016-11-14T16:40:44Z", "author_association": "NONE", "body_html": "<p>My code</p>\n<pre><code>cell = cell_fn(args.rnn_size)\n\n        self.cell = cell = rnn_cell.MultiRNNCell([cell] * args.num_layers, state_is_tuple=True)\n\n        self.input_data = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\n        self.targets = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\n        self.initial_state = cell.zero_state(args.batch_size, tf.float32)\n\n        with tf.variable_scope('rnnlm'):\n            softmax_w = tf.get_variable(\"softmax_w\", [args.rnn_size, args.vocab_size])\n            softmax_b = tf.get_variable(\"softmax_b\", [args.vocab_size])\n            with tf.device(\"/cpu:0\"):\n                embedding = tf.get_variable(\"embedding\", [args.vocab_size, args.rnn_size])\n                inputs = tf.split(1, args.seq_length, tf.nn.embedding_lookup(embedding, self.input_data))\n                inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n\n        def loop(prev, _):\n            prev = tf.matmul(prev, softmax_w) + softmax_b\n            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n            return tf.nn.embedding_lookup(embedding, prev_symbol)\n\n        initial_input = self.initial_state[0]\n        beam_decoder = BeamDecoder(num_classes=3, stop_token=2, beam_size=7, max_len=5)\n        _, final_state = tf.nn.seq2seq.rnn_decoder(\n                                [beam_decoder.wrap_input(initial_input)] + [None] * 4,\n                                beam_decoder.wrap_state(self.initial_state),\n                                beam_decoder.wrap_cell(cell),\n                                #loop_function = lambda prev_symbol, i: tf.reshape(prev_symbol, [-1, 1])\n                                loop_function=loop if infer else None, scope='rnnlm'\n                            )\n</code></pre>\n<p>there is a problem appeared when I try to run ,the traceback info is as follows</p>\n<pre><code>[sun ~/workspace/sunxiaobiu/word-rnn-tensorflow 20:23:05]$ python sample.py\nTraceback (most recent call last):\n  File \"sample.py\", line 42, in &lt;module&gt;\n    main()\n  File \"sample.py\", line 25, in main\n    sample(args)\n  File \"sample.py\", line 32, in sample\n    model = Model(saved_args, True)\n  File \"/Users/sun/workspace/sunxiaobiu/word-rnn-tensorflow/model.py\", line 53, in __init__\n    loop_function=loop if infer else None, scope='rnnlm'\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 146, in rnn_decoder\n    output, state = cell(inp, state)\n  File \"/Users/sun/workspace/sunxiaobiu/word-rnn-tensorflow/beam_decoder.py\", line 172, in __call__\n    cell_outputs, raw_cell_state = self.cell(cell_inputs, past_cell_state)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 813, in __call__\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 310, in __call__\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 889, in _linear\n    shapes = [a.get_shape().as_list() for a in args]\nAttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'\n</code></pre>\n<p>I have tried to put the state_is_tuple=True , but it still not work~<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=684901\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lukaszkaiser\">@lukaszkaiser</a></p>", "body_text": "My code\ncell = cell_fn(args.rnn_size)\n\n        self.cell = cell = rnn_cell.MultiRNNCell([cell] * args.num_layers, state_is_tuple=True)\n\n        self.input_data = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\n        self.targets = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\n        self.initial_state = cell.zero_state(args.batch_size, tf.float32)\n\n        with tf.variable_scope('rnnlm'):\n            softmax_w = tf.get_variable(\"softmax_w\", [args.rnn_size, args.vocab_size])\n            softmax_b = tf.get_variable(\"softmax_b\", [args.vocab_size])\n            with tf.device(\"/cpu:0\"):\n                embedding = tf.get_variable(\"embedding\", [args.vocab_size, args.rnn_size])\n                inputs = tf.split(1, args.seq_length, tf.nn.embedding_lookup(embedding, self.input_data))\n                inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n\n        def loop(prev, _):\n            prev = tf.matmul(prev, softmax_w) + softmax_b\n            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n            return tf.nn.embedding_lookup(embedding, prev_symbol)\n\n        initial_input = self.initial_state[0]\n        beam_decoder = BeamDecoder(num_classes=3, stop_token=2, beam_size=7, max_len=5)\n        _, final_state = tf.nn.seq2seq.rnn_decoder(\n                                [beam_decoder.wrap_input(initial_input)] + [None] * 4,\n                                beam_decoder.wrap_state(self.initial_state),\n                                beam_decoder.wrap_cell(cell),\n                                #loop_function = lambda prev_symbol, i: tf.reshape(prev_symbol, [-1, 1])\n                                loop_function=loop if infer else None, scope='rnnlm'\n                            )\n\nthere is a problem appeared when I try to run ,the traceback info is as follows\n[sun ~/workspace/sunxiaobiu/word-rnn-tensorflow 20:23:05]$ python sample.py\nTraceback (most recent call last):\n  File \"sample.py\", line 42, in <module>\n    main()\n  File \"sample.py\", line 25, in main\n    sample(args)\n  File \"sample.py\", line 32, in sample\n    model = Model(saved_args, True)\n  File \"/Users/sun/workspace/sunxiaobiu/word-rnn-tensorflow/model.py\", line 53, in __init__\n    loop_function=loop if infer else None, scope='rnnlm'\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 146, in rnn_decoder\n    output, state = cell(inp, state)\n  File \"/Users/sun/workspace/sunxiaobiu/word-rnn-tensorflow/beam_decoder.py\", line 172, in __call__\n    cell_outputs, raw_cell_state = self.cell(cell_inputs, past_cell_state)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 813, in __call__\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 310, in __call__\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 889, in _linear\n    shapes = [a.get_shape().as_list() for a in args]\nAttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'\n\nI have tried to put the state_is_tuple=True , but it still not work~\n@lukaszkaiser", "body": "My code \r\n```\r\ncell = cell_fn(args.rnn_size)\r\n\r\n        self.cell = cell = rnn_cell.MultiRNNCell([cell] * args.num_layers, state_is_tuple=True)\r\n\r\n        self.input_data = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\r\n        self.targets = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\r\n        self.initial_state = cell.zero_state(args.batch_size, tf.float32)\r\n\r\n        with tf.variable_scope('rnnlm'):\r\n            softmax_w = tf.get_variable(\"softmax_w\", [args.rnn_size, args.vocab_size])\r\n            softmax_b = tf.get_variable(\"softmax_b\", [args.vocab_size])\r\n            with tf.device(\"/cpu:0\"):\r\n                embedding = tf.get_variable(\"embedding\", [args.vocab_size, args.rnn_size])\r\n                inputs = tf.split(1, args.seq_length, tf.nn.embedding_lookup(embedding, self.input_data))\r\n                inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\r\n\r\n        def loop(prev, _):\r\n            prev = tf.matmul(prev, softmax_w) + softmax_b\r\n            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\r\n            return tf.nn.embedding_lookup(embedding, prev_symbol)\r\n\r\n        initial_input = self.initial_state[0]\r\n        beam_decoder = BeamDecoder(num_classes=3, stop_token=2, beam_size=7, max_len=5)\r\n        _, final_state = tf.nn.seq2seq.rnn_decoder(\r\n                                [beam_decoder.wrap_input(initial_input)] + [None] * 4,\r\n                                beam_decoder.wrap_state(self.initial_state),\r\n                                beam_decoder.wrap_cell(cell),\r\n                                #loop_function = lambda prev_symbol, i: tf.reshape(prev_symbol, [-1, 1])\r\n                                loop_function=loop if infer else None, scope='rnnlm'\r\n                            )\r\n```\r\nthere is a problem appeared when I try to run ,the traceback info is as follows\r\n```\r\n[sun ~/workspace/sunxiaobiu/word-rnn-tensorflow 20:23:05]$ python sample.py\r\nTraceback (most recent call last):\r\n  File \"sample.py\", line 42, in <module>\r\n    main()\r\n  File \"sample.py\", line 25, in main\r\n    sample(args)\r\n  File \"sample.py\", line 32, in sample\r\n    model = Model(saved_args, True)\r\n  File \"/Users/sun/workspace/sunxiaobiu/word-rnn-tensorflow/model.py\", line 53, in __init__\r\n    loop_function=loop if infer else None, scope='rnnlm'\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 146, in rnn_decoder\r\n    output, state = cell(inp, state)\r\n  File \"/Users/sun/workspace/sunxiaobiu/word-rnn-tensorflow/beam_decoder.py\", line 172, in __call__\r\n    cell_outputs, raw_cell_state = self.cell(cell_inputs, past_cell_state)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 813, in __call__\r\n    cur_inp, new_state = cell(cur_inp, cur_state)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 310, in __call__\r\n    concat = _linear([inputs, h], 4 * self._num_units, True)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 889, in _linear\r\n    shapes = [a.get_shape().as_list() for a in args]\r\nAttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'\r\n```\r\nI have tried to put the state_is_tuple=True , but it still not work~\r\n@lukaszkaiser "}