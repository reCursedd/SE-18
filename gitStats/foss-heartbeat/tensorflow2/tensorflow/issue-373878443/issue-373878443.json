{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23253", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23253/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23253/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23253/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23253", "id": 373878443, "node_id": "MDU6SXNzdWUzNzM4Nzg0NDM=", "number": 23253, "title": "TOCO failed  Batch normalization resolution requires that mean, multiplier and offset arrays be constant.", "user": {"login": "sxsxsx", "id": 16790259, "node_id": "MDQ6VXNlcjE2NzkwMjU5", "avatar_url": "https://avatars1.githubusercontent.com/u/16790259?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sxsxsx", "html_url": "https://github.com/sxsxsx", "followers_url": "https://api.github.com/users/sxsxsx/followers", "following_url": "https://api.github.com/users/sxsxsx/following{/other_user}", "gists_url": "https://api.github.com/users/sxsxsx/gists{/gist_id}", "starred_url": "https://api.github.com/users/sxsxsx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sxsxsx/subscriptions", "organizations_url": "https://api.github.com/users/sxsxsx/orgs", "repos_url": "https://api.github.com/users/sxsxsx/repos", "events_url": "https://api.github.com/users/sxsxsx/events{/privacy}", "received_events_url": "https://api.github.com/users/sxsxsx/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "liyunlu0618", "id": 9705880, "node_id": "MDQ6VXNlcjk3MDU4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9705880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liyunlu0618", "html_url": "https://github.com/liyunlu0618", "followers_url": "https://api.github.com/users/liyunlu0618/followers", "following_url": "https://api.github.com/users/liyunlu0618/following{/other_user}", "gists_url": "https://api.github.com/users/liyunlu0618/gists{/gist_id}", "starred_url": "https://api.github.com/users/liyunlu0618/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liyunlu0618/subscriptions", "organizations_url": "https://api.github.com/users/liyunlu0618/orgs", "repos_url": "https://api.github.com/users/liyunlu0618/repos", "events_url": "https://api.github.com/users/liyunlu0618/events{/privacy}", "received_events_url": "https://api.github.com/users/liyunlu0618/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "liyunlu0618", "id": 9705880, "node_id": "MDQ6VXNlcjk3MDU4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9705880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liyunlu0618", "html_url": "https://github.com/liyunlu0618", "followers_url": "https://api.github.com/users/liyunlu0618/followers", "following_url": "https://api.github.com/users/liyunlu0618/following{/other_user}", "gists_url": "https://api.github.com/users/liyunlu0618/gists{/gist_id}", "starred_url": "https://api.github.com/users/liyunlu0618/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liyunlu0618/subscriptions", "organizations_url": "https://api.github.com/users/liyunlu0618/orgs", "repos_url": "https://api.github.com/users/liyunlu0618/repos", "events_url": "https://api.github.com/users/liyunlu0618/events{/privacy}", "received_events_url": "https://api.github.com/users/liyunlu0618/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-10-25T10:26:56Z", "updated_at": "2018-11-22T18:50:31Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): 1.9 gpu</li>\n<li>Python version: 27</li>\n<li>Bazel version (if compiling from source): no use</li>\n<li>GCC/Compiler version (if compiling from source): no use</li>\n<li>CUDA/cuDNN version: CUDA9.1    CuDNN7.0</li>\n<li>GPU model and memory: GTX1070 8G</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\n<code>toco --output_file=test.tflite --graph_def_file=freeze.pb --input_arrays=Placeholder --output_arrays=logits/BatchNorm/Reshape_1 --output_format=TFLITE --inference_type=FLOAT --std_dev_values=1 --mean_values=0</code></p>\n<p>failed</p>\n<p>Traceback (most recent call last):<br>\nFile \"/home/icare/.local/bin/toco\", line 11, in <br>\nsys.exit(main())<br>\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main<br>\napp.run(main=run_main, argv=sys.argv[:1])<br>\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run<br>\n_sys.exit(main(argv))<br>\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main<br>\n_convert_model(tflite_flags)<br>\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model<br>\noutput_data = converter.convert()<br>\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert<br>\nallow_custom_ops=self.allow_custom_ops)<br>\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 225, in toco_convert<br>\ninput_data.SerializeToString())<br>\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 107, in toco_convert_protos<br>\n(stdout, stderr))<br>\nRuntimeError: TOCO failed see console for info.<br>\n2018-10-25 17:33:59.010229: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 135 operators, 224 arrays (0 quantized)<br>\n2018-10-25 17:33:59.011116: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 127 operators, 212 arrays (0 quantized)<br>\n2018-10-25 17:33:59.012209: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 127 operators, 212 arrays (0 quantized)<br>\n2018-10-25 17:33:59.012368: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op-&gt;inputs[1]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[2]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.<br>\nAborted (core dumped)</p>\n<p>None</p>\n<p><strong>Describe the expected behavior</strong></p>\n<p>I want to use toco to transform the pb file to the tflite file</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<p>I use the code below to generate graph.pb and ckpy file<br>\n<code>g = tf.get_default_graph() graph_def = g.as_graph_def() tf.train.write_graph(graph_def, \"./model\", 'graph.pb', as_text=False)  saver = tf.train.Saver() saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'mnist-conv-slim.ckpt'))</code></p>\n<p>and then I freezed the graph.pb successfullly</p>\n<p>python freeze_graph.py --input_graph=/payh/to/graph.pb --input_checkpoint=/payh/tpo/mnist-conv-slim.ckpt --output_graph=/payh/to/mobile_face/model/freeze.pb --output_node_names=logits/BatchNorm/Reshape_1 --input_binary=True</p>\n<p><strong>Other info / logs</strong><br>\nI use the code below to watch the nodes of each layer</p>\n<p><code>import tensorflow as tf gf = tf.GraphDef() #gf.ParseFromString(open('/tmp/inception_v3_quantized.pb','rb').read()) gf.ParseFromString(open('./model/freeze.pb','rb').read()) for n in gf.node: print ( n.name +' ===&gt; '+n.op )  </code></p>\n<p>result:</p>\n<p>Placeholder ===&gt; Placeholder<br>\nPlaceholder_1 ===&gt; Placeholder<br>\nPlaceholder_3 ===&gt; Placeholder<br>\nReshape/shape ===&gt; Const<br>\nReshape ===&gt; Reshape<br>\nconv1/weights ===&gt; Const<br>\nconv1/weights/read ===&gt; Identity<br>\nconv1/Conv2D ===&gt; Conv2D<br>\nconv1/BatchNorm/Const ===&gt; Const<br>\nconv1/BatchNorm/beta ===&gt; Const<br>\nconv1/BatchNorm/beta/read ===&gt; Identity<br>\nconv1/BatchNorm/moving_mean ===&gt; Const<br>\nconv1/BatchNorm/moving_mean/read ===&gt; Identity<br>\nconv1/BatchNorm/moving_variance ===&gt; Const<br>\nconv1/BatchNorm/moving_variance/read ===&gt; Identity<br>\nconv1/BatchNorm/cond/Switch ===&gt; Switch<br>\nconv1/BatchNorm/cond/switch_t ===&gt; Identity<br>\nconv1/BatchNorm/cond/pred_id ===&gt; Identity<br>\nconv1/BatchNorm/cond/Const ===&gt; Const<br>\nconv1/BatchNorm/cond/Const_1 ===&gt; Const<br>\nconv1/BatchNorm/cond/FusedBatchNorm ===&gt; FusedBatchNorm<br>\nconv1/BatchNorm/cond/FusedBatchNorm/Switch ===&gt; Switch<br>\nconv1/BatchNorm/cond/FusedBatchNorm/Switch_1 ===&gt; Switch<br>\nconv1/BatchNorm/cond/FusedBatchNorm/Switch_2 ===&gt; Switch<br>\nconv1/BatchNorm/cond/FusedBatchNorm_1 ===&gt; FusedBatchNorm<br>\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch ===&gt; Switch<br>\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===&gt; Switch<br>\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===&gt; Switch<br>\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===&gt; Switch<br>\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===&gt; Switch<br>\nconv1/BatchNorm/cond/Merge ===&gt; Merge<br>\nconv1/CRelu/Neg ===&gt; Neg<br>\nconv1/CRelu/axis ===&gt; Const<br>\nconv1/CRelu ===&gt; ConcatV2<br>\nconv1/CRelu/Relu ===&gt; Relu<br>\npool1/MaxPool ===&gt; MaxPool<br>\nconv2/weights ===&gt; Const<br>\nconv2/weights/read ===&gt; Identity<br>\nconv2/Conv2D ===&gt; Conv2D<br>\nconv2/BatchNorm/Const ===&gt; Const<br>\nconv2/BatchNorm/beta ===&gt; Const<br>\nconv2/BatchNorm/beta/read ===&gt; Identity<br>\nconv2/BatchNorm/moving_mean ===&gt; Const<br>\nconv2/BatchNorm/moving_mean/read ===&gt; Identity<br>\nconv2/BatchNorm/moving_variance ===&gt; Const<br>\nconv2/BatchNorm/moving_variance/read ===&gt; Identity<br>\nconv2/BatchNorm/cond/Switch ===&gt; Switch<br>\nconv2/BatchNorm/cond/switch_t ===&gt; Identity<br>\nconv2/BatchNorm/cond/pred_id ===&gt; Identity<br>\nconv2/BatchNorm/cond/Const ===&gt; Const<br>\nconv2/BatchNorm/cond/Const_1 ===&gt; Const<br>\nconv2/BatchNorm/cond/FusedBatchNorm ===&gt; FusedBatchNorm<br>\nconv2/BatchNorm/cond/FusedBatchNorm/Switch ===&gt; Switch<br>\nconv2/BatchNorm/cond/FusedBatchNorm/Switch_1 ===&gt; Switch<br>\nconv2/BatchNorm/cond/FusedBatchNorm/Switch_2 ===&gt; Switch<br>\nconv2/BatchNorm/cond/FusedBatchNorm_1 ===&gt; FusedBatchNorm<br>\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch ===&gt; Switch<br>\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===&gt; Switch<br>\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===&gt; Switch<br>\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===&gt; Switch<br>\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===&gt; Switch<br>\nconv2/BatchNorm/cond/Merge ===&gt; Merge<br>\nconv2/CRelu/Neg ===&gt; Neg<br>\nconv2/CRelu/axis ===&gt; Const<br>\nconv2/CRelu ===&gt; ConcatV2<br>\nconv2/CRelu/Relu ===&gt; Relu<br>\npool2/MaxPool ===&gt; MaxPool<br>\nFlatten/flatten/Shape ===&gt; Shape<br>\nFlatten/flatten/strided_slice/stack ===&gt; Const<br>\nFlatten/flatten/strided_slice/stack_1 ===&gt; Const<br>\nFlatten/flatten/strided_slice/stack_2 ===&gt; Const<br>\nFlatten/flatten/strided_slice ===&gt; StridedSlice<br>\nFlatten/flatten/Reshape/shape/1 ===&gt; Const<br>\nFlatten/flatten/Reshape/shape ===&gt; Pack<br>\nFlatten/flatten/Reshape ===&gt; Reshape<br>\nfc1/weights ===&gt; Const<br>\nfc1/weights/read ===&gt; Identity<br>\nfc1/MatMul ===&gt; MatMul<br>\nfc1/BatchNorm/Reshape/shape ===&gt; Const<br>\nfc1/BatchNorm/Reshape ===&gt; Reshape<br>\nfc1/BatchNorm/beta ===&gt; Const<br>\nfc1/BatchNorm/beta/read ===&gt; Identity<br>\nfc1/BatchNorm/Const ===&gt; Const<br>\nfc1/BatchNorm/moving_mean ===&gt; Const<br>\nfc1/BatchNorm/moving_mean/read ===&gt; Identity<br>\nfc1/BatchNorm/moving_variance ===&gt; Const<br>\nfc1/BatchNorm/moving_variance/read ===&gt; Identity<br>\nfc1/BatchNorm/cond/Switch ===&gt; Switch<br>\nfc1/BatchNorm/cond/switch_t ===&gt; Identity<br>\nfc1/BatchNorm/cond/pred_id ===&gt; Identity<br>\nfc1/BatchNorm/cond/Const ===&gt; Const<br>\nfc1/BatchNorm/cond/Const_1 ===&gt; Const<br>\nfc1/BatchNorm/cond/FusedBatchNorm ===&gt; FusedBatchNorm<br>\nfc1/BatchNorm/cond/FusedBatchNorm/Switch ===&gt; Switch<br>\nfc1/BatchNorm/cond/FusedBatchNorm/Switch_1 ===&gt; Switch<br>\nfc1/BatchNorm/cond/FusedBatchNorm/Switch_2 ===&gt; Switch<br>\nfc1/BatchNorm/cond/FusedBatchNorm_1 ===&gt; FusedBatchNorm<br>\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch ===&gt; Switch<br>\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===&gt; Switch<br>\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===&gt; Switch<br>\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===&gt; Switch<br>\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===&gt; Switch<br>\nfc1/BatchNorm/cond/Merge ===&gt; Merge<br>\nfc1/BatchNorm/Shape ===&gt; Shape<br>\nfc1/BatchNorm/Reshape_1 ===&gt; Reshape<br>\nfc1/CRelu/Neg ===&gt; Neg<br>\nfc1/CRelu/axis ===&gt; Const<br>\nfc1/CRelu ===&gt; ConcatV2<br>\nfc1/CRelu/Relu ===&gt; Relu<br>\nDropout/sub/x ===&gt; Const<br>\nDropout/sub ===&gt; Sub<br>\nDropout/sub_1/x ===&gt; Const<br>\nDropout/sub_1 ===&gt; Sub<br>\nDropout/dropout_1/Shape ===&gt; Shape<br>\nDropout/dropout_1/random_uniform/min ===&gt; Const<br>\nDropout/dropout_1/random_uniform/max ===&gt; Const<br>\nDropout/dropout_1/random_uniform/RandomUniform ===&gt; RandomUniform<br>\nDropout/dropout_1/random_uniform/sub ===&gt; Sub<br>\nDropout/dropout_1/random_uniform/mul ===&gt; Mul<br>\nDropout/dropout_1/random_uniform ===&gt; Add<br>\nDropout/dropout_1/add ===&gt; Add<br>\nDropout/dropout_1/Floor ===&gt; Floor<br>\nDropout/dropout_1/div ===&gt; RealDiv<br>\nDropout/dropout_1/mul ===&gt; Mul<br>\nlogits/weights ===&gt; Const<br>\nlogits/weights/read ===&gt; Identity<br>\nlogits/MatMul ===&gt; MatMul<br>\nlogits/BatchNorm/Reshape/shape ===&gt; Const<br>\nlogits/BatchNorm/Reshape ===&gt; Reshape<br>\nlogits/BatchNorm/beta ===&gt; Const<br>\nlogits/BatchNorm/beta/read ===&gt; Identity<br>\nlogits/BatchNorm/Const ===&gt; Const<br>\nlogits/BatchNorm/moving_mean ===&gt; Const<br>\nlogits/BatchNorm/moving_mean/read ===&gt; Identity<br>\nlogits/BatchNorm/moving_variance ===&gt; Const<br>\nlogits/BatchNorm/moving_variance/read ===&gt; Identity<br>\nlogits/BatchNorm/cond/Switch ===&gt; Switch<br>\nlogits/BatchNorm/cond/switch_t ===&gt; Identity<br>\nlogits/BatchNorm/cond/pred_id ===&gt; Identity<br>\nlogits/BatchNorm/cond/Const ===&gt; Const<br>\nlogits/BatchNorm/cond/Const_1 ===&gt; Const<br>\nlogits/BatchNorm/cond/FusedBatchNorm ===&gt; FusedBatchNorm<br>\nlogits/BatchNorm/cond/FusedBatchNorm/Switch ===&gt; Switch<br>\nlogits/BatchNorm/cond/FusedBatchNorm/Switch_1 ===&gt; Switch<br>\nlogits/BatchNorm/cond/FusedBatchNorm/Switch_2 ===&gt; Switch<br>\nlogits/BatchNorm/cond/FusedBatchNorm_1 ===&gt; FusedBatchNorm<br>\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch ===&gt; Switch<br>\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===&gt; Switch<br>\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===&gt; Switch<br>\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===&gt; Switch<br>\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===&gt; Switch<br>\nlogits/BatchNorm/cond/Merge ===&gt; Merge<br>\nlogits/BatchNorm/Shape ===&gt; Shape<br>\nlogits/BatchNorm/Reshape_1 ===&gt; Reshape</p>\n<p>It seems that the BN para are already constant</p>\n<p>what should I do to solver the problem?</p>\n<p>good luck to you thanks</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.9 gpu\nPython version: 27\nBazel version (if compiling from source): no use\nGCC/Compiler version (if compiling from source): no use\nCUDA/cuDNN version: CUDA9.1    CuDNN7.0\nGPU model and memory: GTX1070 8G\n\nDescribe the current behavior\ntoco --output_file=test.tflite --graph_def_file=freeze.pb --input_arrays=Placeholder --output_arrays=logits/BatchNorm/Reshape_1 --output_format=TFLITE --inference_type=FLOAT --std_dev_values=1 --mean_values=0\nfailed\nTraceback (most recent call last):\nFile \"/home/icare/.local/bin/toco\", line 11, in \nsys.exit(main())\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\napp.run(main=run_main, argv=sys.argv[:1])\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n_sys.exit(main(argv))\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\n_convert_model(tflite_flags)\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model\noutput_data = converter.convert()\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert\nallow_custom_ops=self.allow_custom_ops)\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 225, in toco_convert\ninput_data.SerializeToString())\nFile \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 107, in toco_convert_protos\n(stdout, stderr))\nRuntimeError: TOCO failed see console for info.\n2018-10-25 17:33:59.010229: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 135 operators, 224 arrays (0 quantized)\n2018-10-25 17:33:59.011116: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 127 operators, 212 arrays (0 quantized)\n2018-10-25 17:33:59.012209: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 127 operators, 212 arrays (0 quantized)\n2018-10-25 17:33:59.012368: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\nAborted (core dumped)\nNone\nDescribe the expected behavior\nI want to use toco to transform the pb file to the tflite file\nCode to reproduce the issue\nI use the code below to generate graph.pb and ckpy file\ng = tf.get_default_graph() graph_def = g.as_graph_def() tf.train.write_graph(graph_def, \"./model\", 'graph.pb', as_text=False)  saver = tf.train.Saver() saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'mnist-conv-slim.ckpt'))\nand then I freezed the graph.pb successfullly\npython freeze_graph.py --input_graph=/payh/to/graph.pb --input_checkpoint=/payh/tpo/mnist-conv-slim.ckpt --output_graph=/payh/to/mobile_face/model/freeze.pb --output_node_names=logits/BatchNorm/Reshape_1 --input_binary=True\nOther info / logs\nI use the code below to watch the nodes of each layer\nimport tensorflow as tf gf = tf.GraphDef() #gf.ParseFromString(open('/tmp/inception_v3_quantized.pb','rb').read()) gf.ParseFromString(open('./model/freeze.pb','rb').read()) for n in gf.node: print ( n.name +' ===> '+n.op )  \nresult:\nPlaceholder ===> Placeholder\nPlaceholder_1 ===> Placeholder\nPlaceholder_3 ===> Placeholder\nReshape/shape ===> Const\nReshape ===> Reshape\nconv1/weights ===> Const\nconv1/weights/read ===> Identity\nconv1/Conv2D ===> Conv2D\nconv1/BatchNorm/Const ===> Const\nconv1/BatchNorm/beta ===> Const\nconv1/BatchNorm/beta/read ===> Identity\nconv1/BatchNorm/moving_mean ===> Const\nconv1/BatchNorm/moving_mean/read ===> Identity\nconv1/BatchNorm/moving_variance ===> Const\nconv1/BatchNorm/moving_variance/read ===> Identity\nconv1/BatchNorm/cond/Switch ===> Switch\nconv1/BatchNorm/cond/switch_t ===> Identity\nconv1/BatchNorm/cond/pred_id ===> Identity\nconv1/BatchNorm/cond/Const ===> Const\nconv1/BatchNorm/cond/Const_1 ===> Const\nconv1/BatchNorm/cond/FusedBatchNorm ===> FusedBatchNorm\nconv1/BatchNorm/cond/FusedBatchNorm/Switch ===> Switch\nconv1/BatchNorm/cond/FusedBatchNorm/Switch_1 ===> Switch\nconv1/BatchNorm/cond/FusedBatchNorm/Switch_2 ===> Switch\nconv1/BatchNorm/cond/FusedBatchNorm_1 ===> FusedBatchNorm\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch ===> Switch\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===> Switch\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===> Switch\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===> Switch\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===> Switch\nconv1/BatchNorm/cond/Merge ===> Merge\nconv1/CRelu/Neg ===> Neg\nconv1/CRelu/axis ===> Const\nconv1/CRelu ===> ConcatV2\nconv1/CRelu/Relu ===> Relu\npool1/MaxPool ===> MaxPool\nconv2/weights ===> Const\nconv2/weights/read ===> Identity\nconv2/Conv2D ===> Conv2D\nconv2/BatchNorm/Const ===> Const\nconv2/BatchNorm/beta ===> Const\nconv2/BatchNorm/beta/read ===> Identity\nconv2/BatchNorm/moving_mean ===> Const\nconv2/BatchNorm/moving_mean/read ===> Identity\nconv2/BatchNorm/moving_variance ===> Const\nconv2/BatchNorm/moving_variance/read ===> Identity\nconv2/BatchNorm/cond/Switch ===> Switch\nconv2/BatchNorm/cond/switch_t ===> Identity\nconv2/BatchNorm/cond/pred_id ===> Identity\nconv2/BatchNorm/cond/Const ===> Const\nconv2/BatchNorm/cond/Const_1 ===> Const\nconv2/BatchNorm/cond/FusedBatchNorm ===> FusedBatchNorm\nconv2/BatchNorm/cond/FusedBatchNorm/Switch ===> Switch\nconv2/BatchNorm/cond/FusedBatchNorm/Switch_1 ===> Switch\nconv2/BatchNorm/cond/FusedBatchNorm/Switch_2 ===> Switch\nconv2/BatchNorm/cond/FusedBatchNorm_1 ===> FusedBatchNorm\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch ===> Switch\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===> Switch\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===> Switch\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===> Switch\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===> Switch\nconv2/BatchNorm/cond/Merge ===> Merge\nconv2/CRelu/Neg ===> Neg\nconv2/CRelu/axis ===> Const\nconv2/CRelu ===> ConcatV2\nconv2/CRelu/Relu ===> Relu\npool2/MaxPool ===> MaxPool\nFlatten/flatten/Shape ===> Shape\nFlatten/flatten/strided_slice/stack ===> Const\nFlatten/flatten/strided_slice/stack_1 ===> Const\nFlatten/flatten/strided_slice/stack_2 ===> Const\nFlatten/flatten/strided_slice ===> StridedSlice\nFlatten/flatten/Reshape/shape/1 ===> Const\nFlatten/flatten/Reshape/shape ===> Pack\nFlatten/flatten/Reshape ===> Reshape\nfc1/weights ===> Const\nfc1/weights/read ===> Identity\nfc1/MatMul ===> MatMul\nfc1/BatchNorm/Reshape/shape ===> Const\nfc1/BatchNorm/Reshape ===> Reshape\nfc1/BatchNorm/beta ===> Const\nfc1/BatchNorm/beta/read ===> Identity\nfc1/BatchNorm/Const ===> Const\nfc1/BatchNorm/moving_mean ===> Const\nfc1/BatchNorm/moving_mean/read ===> Identity\nfc1/BatchNorm/moving_variance ===> Const\nfc1/BatchNorm/moving_variance/read ===> Identity\nfc1/BatchNorm/cond/Switch ===> Switch\nfc1/BatchNorm/cond/switch_t ===> Identity\nfc1/BatchNorm/cond/pred_id ===> Identity\nfc1/BatchNorm/cond/Const ===> Const\nfc1/BatchNorm/cond/Const_1 ===> Const\nfc1/BatchNorm/cond/FusedBatchNorm ===> FusedBatchNorm\nfc1/BatchNorm/cond/FusedBatchNorm/Switch ===> Switch\nfc1/BatchNorm/cond/FusedBatchNorm/Switch_1 ===> Switch\nfc1/BatchNorm/cond/FusedBatchNorm/Switch_2 ===> Switch\nfc1/BatchNorm/cond/FusedBatchNorm_1 ===> FusedBatchNorm\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch ===> Switch\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===> Switch\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===> Switch\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===> Switch\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===> Switch\nfc1/BatchNorm/cond/Merge ===> Merge\nfc1/BatchNorm/Shape ===> Shape\nfc1/BatchNorm/Reshape_1 ===> Reshape\nfc1/CRelu/Neg ===> Neg\nfc1/CRelu/axis ===> Const\nfc1/CRelu ===> ConcatV2\nfc1/CRelu/Relu ===> Relu\nDropout/sub/x ===> Const\nDropout/sub ===> Sub\nDropout/sub_1/x ===> Const\nDropout/sub_1 ===> Sub\nDropout/dropout_1/Shape ===> Shape\nDropout/dropout_1/random_uniform/min ===> Const\nDropout/dropout_1/random_uniform/max ===> Const\nDropout/dropout_1/random_uniform/RandomUniform ===> RandomUniform\nDropout/dropout_1/random_uniform/sub ===> Sub\nDropout/dropout_1/random_uniform/mul ===> Mul\nDropout/dropout_1/random_uniform ===> Add\nDropout/dropout_1/add ===> Add\nDropout/dropout_1/Floor ===> Floor\nDropout/dropout_1/div ===> RealDiv\nDropout/dropout_1/mul ===> Mul\nlogits/weights ===> Const\nlogits/weights/read ===> Identity\nlogits/MatMul ===> MatMul\nlogits/BatchNorm/Reshape/shape ===> Const\nlogits/BatchNorm/Reshape ===> Reshape\nlogits/BatchNorm/beta ===> Const\nlogits/BatchNorm/beta/read ===> Identity\nlogits/BatchNorm/Const ===> Const\nlogits/BatchNorm/moving_mean ===> Const\nlogits/BatchNorm/moving_mean/read ===> Identity\nlogits/BatchNorm/moving_variance ===> Const\nlogits/BatchNorm/moving_variance/read ===> Identity\nlogits/BatchNorm/cond/Switch ===> Switch\nlogits/BatchNorm/cond/switch_t ===> Identity\nlogits/BatchNorm/cond/pred_id ===> Identity\nlogits/BatchNorm/cond/Const ===> Const\nlogits/BatchNorm/cond/Const_1 ===> Const\nlogits/BatchNorm/cond/FusedBatchNorm ===> FusedBatchNorm\nlogits/BatchNorm/cond/FusedBatchNorm/Switch ===> Switch\nlogits/BatchNorm/cond/FusedBatchNorm/Switch_1 ===> Switch\nlogits/BatchNorm/cond/FusedBatchNorm/Switch_2 ===> Switch\nlogits/BatchNorm/cond/FusedBatchNorm_1 ===> FusedBatchNorm\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch ===> Switch\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===> Switch\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===> Switch\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===> Switch\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===> Switch\nlogits/BatchNorm/cond/Merge ===> Merge\nlogits/BatchNorm/Shape ===> Shape\nlogits/BatchNorm/Reshape_1 ===> Reshape\nIt seems that the BN para are already constant\nwhat should I do to solver the problem?\ngood luck to you thanks", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.9 gpu\r\n- Python version: 27\r\n- Bazel version (if compiling from source): no use\r\n- GCC/Compiler version (if compiling from source): no use\r\n- CUDA/cuDNN version: CUDA9.1    CuDNN7.0\r\n- GPU model and memory: GTX1070 8G\r\n\r\n\r\n**Describe the current behavior**\r\n`toco --output_file=test.tflite --graph_def_file=freeze.pb --input_arrays=Placeholder --output_arrays=logits/BatchNorm/Reshape_1 --output_format=TFLITE --inference_type=FLOAT --std_dev_values=1 --mean_values=0`\r\n\r\nfailed\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/icare/.local/bin/toco\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert\r\n    allow_custom_ops=self.allow_custom_ops)\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 225, in toco_convert\r\n    input_data.SerializeToString())\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 107, in toco_convert_protos\r\n    (stdout, stderr))\r\nRuntimeError: TOCO failed see console for info.\r\n2018-10-25 17:33:59.010229: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 135 operators, 224 arrays (0 quantized)\r\n2018-10-25 17:33:59.011116: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 127 operators, 212 arrays (0 quantized)\r\n2018-10-25 17:33:59.012209: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 127 operators, 212 arrays (0 quantized)\r\n2018-10-25 17:33:59.012368: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\r\nAborted (core dumped)\r\n\r\nNone\r\n\r\n**Describe the expected behavior**\r\n\r\n I want to use toco to transform the pb file to the tflite file\r\n\r\n**Code to reproduce the issue**\r\n\r\nI use the code below to generate graph.pb and ckpy file\r\n`g = tf.get_default_graph()\r\n graph_def = g.as_graph_def()\r\n tf.train.write_graph(graph_def, \"./model\", 'graph.pb', as_text=False) \r\n saver = tf.train.Saver()\r\n saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'mnist-conv-slim.ckpt'))`\r\n\r\n  \r\n\r\nand then I freezed the graph.pb successfullly\r\n\r\n python freeze_graph.py --input_graph=/payh/to/graph.pb --input_checkpoint=/payh/tpo/mnist-conv-slim.ckpt --output_graph=/payh/to/mobile_face/model/freeze.pb --output_node_names=logits/BatchNorm/Reshape_1 --input_binary=True\r\n\r\n\r\n\r\n**Other info / logs**\r\nI use the code below to watch the nodes of each layer\r\n\r\n`import tensorflow as tf\r\ngf = tf.GraphDef()\r\n#gf.ParseFromString(open('/tmp/inception_v3_quantized.pb','rb').read())\r\ngf.ParseFromString(open('./model/freeze.pb','rb').read())\r\nfor n in gf.node:\r\n    print ( n.name +' ===> '+n.op )  `\r\n\r\nresult:\r\n\r\n\r\nPlaceholder ===> Placeholder\r\nPlaceholder_1 ===> Placeholder\r\nPlaceholder_3 ===> Placeholder\r\nReshape/shape ===> Const\r\nReshape ===> Reshape\r\nconv1/weights ===> Const\r\nconv1/weights/read ===> Identity\r\nconv1/Conv2D ===> Conv2D\r\nconv1/BatchNorm/Const ===> Const\r\nconv1/BatchNorm/beta ===> Const\r\nconv1/BatchNorm/beta/read ===> Identity\r\nconv1/BatchNorm/moving_mean ===> Const\r\nconv1/BatchNorm/moving_mean/read ===> Identity\r\nconv1/BatchNorm/moving_variance ===> Const\r\nconv1/BatchNorm/moving_variance/read ===> Identity\r\nconv1/BatchNorm/cond/Switch ===> Switch\r\nconv1/BatchNorm/cond/switch_t ===> Identity\r\nconv1/BatchNorm/cond/pred_id ===> Identity\r\nconv1/BatchNorm/cond/Const ===> Const\r\nconv1/BatchNorm/cond/Const_1 ===> Const\r\nconv1/BatchNorm/cond/FusedBatchNorm ===> FusedBatchNorm\r\nconv1/BatchNorm/cond/FusedBatchNorm/Switch ===> Switch\r\nconv1/BatchNorm/cond/FusedBatchNorm/Switch_1 ===> Switch\r\nconv1/BatchNorm/cond/FusedBatchNorm/Switch_2 ===> Switch\r\nconv1/BatchNorm/cond/FusedBatchNorm_1 ===> FusedBatchNorm\r\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch ===> Switch\r\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===> Switch\r\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===> Switch\r\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===> Switch\r\nconv1/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===> Switch\r\nconv1/BatchNorm/cond/Merge ===> Merge\r\nconv1/CRelu/Neg ===> Neg\r\nconv1/CRelu/axis ===> Const\r\nconv1/CRelu ===> ConcatV2\r\nconv1/CRelu/Relu ===> Relu\r\npool1/MaxPool ===> MaxPool\r\nconv2/weights ===> Const\r\nconv2/weights/read ===> Identity\r\nconv2/Conv2D ===> Conv2D\r\nconv2/BatchNorm/Const ===> Const\r\nconv2/BatchNorm/beta ===> Const\r\nconv2/BatchNorm/beta/read ===> Identity\r\nconv2/BatchNorm/moving_mean ===> Const\r\nconv2/BatchNorm/moving_mean/read ===> Identity\r\nconv2/BatchNorm/moving_variance ===> Const\r\nconv2/BatchNorm/moving_variance/read ===> Identity\r\nconv2/BatchNorm/cond/Switch ===> Switch\r\nconv2/BatchNorm/cond/switch_t ===> Identity\r\nconv2/BatchNorm/cond/pred_id ===> Identity\r\nconv2/BatchNorm/cond/Const ===> Const\r\nconv2/BatchNorm/cond/Const_1 ===> Const\r\nconv2/BatchNorm/cond/FusedBatchNorm ===> FusedBatchNorm\r\nconv2/BatchNorm/cond/FusedBatchNorm/Switch ===> Switch\r\nconv2/BatchNorm/cond/FusedBatchNorm/Switch_1 ===> Switch\r\nconv2/BatchNorm/cond/FusedBatchNorm/Switch_2 ===> Switch\r\nconv2/BatchNorm/cond/FusedBatchNorm_1 ===> FusedBatchNorm\r\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch ===> Switch\r\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===> Switch\r\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===> Switch\r\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===> Switch\r\nconv2/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===> Switch\r\nconv2/BatchNorm/cond/Merge ===> Merge\r\nconv2/CRelu/Neg ===> Neg\r\nconv2/CRelu/axis ===> Const\r\nconv2/CRelu ===> ConcatV2\r\nconv2/CRelu/Relu ===> Relu\r\npool2/MaxPool ===> MaxPool\r\nFlatten/flatten/Shape ===> Shape\r\nFlatten/flatten/strided_slice/stack ===> Const\r\nFlatten/flatten/strided_slice/stack_1 ===> Const\r\nFlatten/flatten/strided_slice/stack_2 ===> Const\r\nFlatten/flatten/strided_slice ===> StridedSlice\r\nFlatten/flatten/Reshape/shape/1 ===> Const\r\nFlatten/flatten/Reshape/shape ===> Pack\r\nFlatten/flatten/Reshape ===> Reshape\r\nfc1/weights ===> Const\r\nfc1/weights/read ===> Identity\r\nfc1/MatMul ===> MatMul\r\nfc1/BatchNorm/Reshape/shape ===> Const\r\nfc1/BatchNorm/Reshape ===> Reshape\r\nfc1/BatchNorm/beta ===> Const\r\nfc1/BatchNorm/beta/read ===> Identity\r\nfc1/BatchNorm/Const ===> Const\r\nfc1/BatchNorm/moving_mean ===> Const\r\nfc1/BatchNorm/moving_mean/read ===> Identity\r\nfc1/BatchNorm/moving_variance ===> Const\r\nfc1/BatchNorm/moving_variance/read ===> Identity\r\nfc1/BatchNorm/cond/Switch ===> Switch\r\nfc1/BatchNorm/cond/switch_t ===> Identity\r\nfc1/BatchNorm/cond/pred_id ===> Identity\r\nfc1/BatchNorm/cond/Const ===> Const\r\nfc1/BatchNorm/cond/Const_1 ===> Const\r\nfc1/BatchNorm/cond/FusedBatchNorm ===> FusedBatchNorm\r\nfc1/BatchNorm/cond/FusedBatchNorm/Switch ===> Switch\r\nfc1/BatchNorm/cond/FusedBatchNorm/Switch_1 ===> Switch\r\nfc1/BatchNorm/cond/FusedBatchNorm/Switch_2 ===> Switch\r\nfc1/BatchNorm/cond/FusedBatchNorm_1 ===> FusedBatchNorm\r\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch ===> Switch\r\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===> Switch\r\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===> Switch\r\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===> Switch\r\nfc1/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===> Switch\r\nfc1/BatchNorm/cond/Merge ===> Merge\r\nfc1/BatchNorm/Shape ===> Shape\r\nfc1/BatchNorm/Reshape_1 ===> Reshape\r\nfc1/CRelu/Neg ===> Neg\r\nfc1/CRelu/axis ===> Const\r\nfc1/CRelu ===> ConcatV2\r\nfc1/CRelu/Relu ===> Relu\r\nDropout/sub/x ===> Const\r\nDropout/sub ===> Sub\r\nDropout/sub_1/x ===> Const\r\nDropout/sub_1 ===> Sub\r\nDropout/dropout_1/Shape ===> Shape\r\nDropout/dropout_1/random_uniform/min ===> Const\r\nDropout/dropout_1/random_uniform/max ===> Const\r\nDropout/dropout_1/random_uniform/RandomUniform ===> RandomUniform\r\nDropout/dropout_1/random_uniform/sub ===> Sub\r\nDropout/dropout_1/random_uniform/mul ===> Mul\r\nDropout/dropout_1/random_uniform ===> Add\r\nDropout/dropout_1/add ===> Add\r\nDropout/dropout_1/Floor ===> Floor\r\nDropout/dropout_1/div ===> RealDiv\r\nDropout/dropout_1/mul ===> Mul\r\nlogits/weights ===> Const\r\nlogits/weights/read ===> Identity\r\nlogits/MatMul ===> MatMul\r\nlogits/BatchNorm/Reshape/shape ===> Const\r\nlogits/BatchNorm/Reshape ===> Reshape\r\nlogits/BatchNorm/beta ===> Const\r\nlogits/BatchNorm/beta/read ===> Identity\r\nlogits/BatchNorm/Const ===> Const\r\nlogits/BatchNorm/moving_mean ===> Const\r\nlogits/BatchNorm/moving_mean/read ===> Identity\r\nlogits/BatchNorm/moving_variance ===> Const\r\nlogits/BatchNorm/moving_variance/read ===> Identity\r\nlogits/BatchNorm/cond/Switch ===> Switch\r\nlogits/BatchNorm/cond/switch_t ===> Identity\r\nlogits/BatchNorm/cond/pred_id ===> Identity\r\nlogits/BatchNorm/cond/Const ===> Const\r\nlogits/BatchNorm/cond/Const_1 ===> Const\r\nlogits/BatchNorm/cond/FusedBatchNorm ===> FusedBatchNorm\r\nlogits/BatchNorm/cond/FusedBatchNorm/Switch ===> Switch\r\nlogits/BatchNorm/cond/FusedBatchNorm/Switch_1 ===> Switch\r\nlogits/BatchNorm/cond/FusedBatchNorm/Switch_2 ===> Switch\r\nlogits/BatchNorm/cond/FusedBatchNorm_1 ===> FusedBatchNorm\r\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch ===> Switch\r\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_1 ===> Switch\r\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_2 ===> Switch\r\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_3 ===> Switch\r\nlogits/BatchNorm/cond/FusedBatchNorm_1/Switch_4 ===> Switch\r\nlogits/BatchNorm/cond/Merge ===> Merge\r\nlogits/BatchNorm/Shape ===> Shape\r\nlogits/BatchNorm/Reshape_1 ===> Reshape\r\n\r\nIt seems that the BN para are already constant\r\n\r\nwhat should I do to solver the problem?\r\n\r\ngood luck to you thanks\r\n"}