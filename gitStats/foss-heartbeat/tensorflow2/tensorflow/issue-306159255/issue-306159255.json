{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17794", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17794/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17794/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17794/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17794", "id": 306159255, "node_id": "MDU6SXNzdWUzMDYxNTkyNTU=", "number": 17794, "title": "how to write the objectives function roc_auc_score in tflearn by keras", "user": {"login": "jiandanjinxin", "id": 15070605, "node_id": "MDQ6VXNlcjE1MDcwNjA1", "avatar_url": "https://avatars2.githubusercontent.com/u/15070605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiandanjinxin", "html_url": "https://github.com/jiandanjinxin", "followers_url": "https://api.github.com/users/jiandanjinxin/followers", "following_url": "https://api.github.com/users/jiandanjinxin/following{/other_user}", "gists_url": "https://api.github.com/users/jiandanjinxin/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiandanjinxin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiandanjinxin/subscriptions", "organizations_url": "https://api.github.com/users/jiandanjinxin/orgs", "repos_url": "https://api.github.com/users/jiandanjinxin/repos", "events_url": "https://api.github.com/users/jiandanjinxin/events{/privacy}", "received_events_url": "https://api.github.com/users/jiandanjinxin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-03-17T14:08:40Z", "updated_at": "2018-03-29T13:21:25Z", "closed_at": "2018-03-21T22:07:29Z", "author_association": "NONE", "body_html": "<p>Dear everyone,<br>\nI found the roc_auc_score function in  <a href=\"https://github.com/tflearn/tflearn/blob/master/tflearn/objectives.py\">https://github.com/tflearn/tflearn/blob/master/tflearn/objectives.py</a>. Now I want to write this function by keras. But failed. The following is the code:</p>\n<pre><code>def roc_auc_score(y_pred, y_true):\n    \"\"\" ROC AUC Score.\n    Approximates the Area Under Curve score, using approximation based on\n    the Wilcoxon-Mann-Whitney U statistic.\n    Yan, L., Dodier, R., Mozer, M. C., &amp; Wolniewicz, R. (2003).\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n    Measures overall performance for a full range of threshold levels.\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n    \"\"\"\n    with tf.name_scope(\"RocAucScore\"):\n        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n        pos = tf.expand_dims(pos, 0)\n        neg = tf.expand_dims(neg, 1)\n        # original paper suggests performance is robust to exact parameter choice\n        gamma = 0.2\n        p     = 3\n        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n        masked = tf.boolean_mask(difference, difference &lt; 0.0)\n        return tf.reduce_sum(tf.pow(-masked, p))\n</code></pre>\n<p><strong>The new code was changed to the following:</strong></p>\n<pre><code>def roc_auc_score(y_pred, y_true):\n    \"\"\" ROC AUC Score.\n    Approximates the Area Under Curve score, using approximation based on\n    the Wilcoxon-Mann-Whitney U statistic.\n    Yan, L., Dodier, R., Mozer, M. C., &amp; Wolniewicz, R. (2003).\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n    Measures overall performance for a full range of threshold levels.\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n    \"\"\"\n    pos = tf.boolean_mask(y_pred, K.cast(y_true, tf.bool))\n    neg = tf.boolean_mask(y_pred, ~K.cast(y_true, tf.bool))\n    pos = K.expand_dims(pos, 0)\n    neg = K.expand_dims(neg, 1)\n    # original paper suggests performance is robust to exact parameter choice\n    gamma = 0.2\n    p     = 3\n    difference = K.zeros_like(pos * neg) + pos - neg - gamma\n    masked = tf.boolean_mask(difference, difference &lt; 0.0)\n    return K.sum(K.pow(-masked, p))\n</code></pre>\n<p><strong>All the code are the following, it doesn't work,</strong><br>\n<strong>The data in</strong><br>\n<a href=\"https://pan.baidu.com/s/12yJCWdfvVW1tEKUfEU34RQ\" rel=\"nofollow\">https://pan.baidu.com/s/12yJCWdfvVW1tEKUfEU34RQ</a> ,  password: nu98</p>\n<pre><code># -*- coding: UTF-8 -*-\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras import optimizers\nfrom keras import applications\nfrom keras.models import Model\nimport keras\nimport numpy as np\nfrom keras import backend as K\nimport tensorflow as tf\n\n\nprint(\"---------------------------AUC----------------------------------------\")\n\n\n# def roc_auc_score(y_pred, y_true):\n#     \"\"\" ROC AUC Score.\n#     Approximates the Area Under Curve score, using approximation based on\n#     the Wilcoxon-Mann-Whitney U statistic.\n#     Yan, L., Dodier, R., Mozer, M. C., &amp; Wolniewicz, R. (2003).\n#     Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n#     Measures overall performance for a full range of threshold levels.\n#     Arguments:\n#         y_pred: `Tensor`. Predicted values.\n#         y_true: `Tensor` . Targets (labels), a probability distribution.\n#     \"\"\"\n#     with tf.name_scope(\"RocAucScore\"):\n\n#         pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n#         neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n\n#         pos = tf.expand_dims(pos, 0)\n#         neg = tf.expand_dims(neg, 1)\n\n#         # original paper suggests performance is robust to exact parameter choice\n#         gamma = 0.2\n#         p     = 3\n\n#         difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n\n#         masked = tf.boolean_mask(difference, difference &lt; 0.0)\n\n#         return tf.reduce_sum(tf.pow(-masked, p))\n\n\n\ndef roc_auc_score(y_pred, y_true):\n    \"\"\" ROC AUC Score.\n    Approximates the Area Under Curve score, using approximation based on\n    the Wilcoxon-Mann-Whitney U statistic.\n    Yan, L., Dodier, R., Mozer, M. C., &amp; Wolniewicz, R. (2003).\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n    Measures overall performance for a full range of threshold levels.\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n    \"\"\"\n    pos = tf.boolean_mask(y_pred, K.cast(y_true, tf.bool))\n    neg = tf.boolean_mask(y_pred, ~K.cast(y_true, tf.bool))\n    pos = K.expand_dims(pos, 0)\n    neg = K.expand_dims(neg, 1)\n    # original paper suggests performance is robust to exact parameter choice\n    gamma = 0.2\n    p     = 3\n    difference = K.zeros_like(pos * neg) + pos - neg - gamma\n    masked = tf.boolean_mask(difference, difference &lt; 0.0)\n    return K.sum(K.pow(-masked, p))\n\ndef roc_auc_score_loss(y_true, y_pred):\n    return roc_auc_score(y_true, y_pred)\nprint(\"---------------------------AUC----------------------------------------\")\n\n\n# dimensions of our images.\nimg_width, img_height = 512, 512\n\ntrain_data_dir = 'data/train/'\nvalidation_data_dir = 'data/validation/'\n\n\n##preprocessing\n# used to rescale the pixel values from [0, 255] to [0, 1] interval\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 32\n\n# automagically retrieve images and their classes for train and validation sets\ntrain_generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='binary')\n\nvalidation_generator = datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='binary',shuffle=False)\n\n\n\n# a simple stack of 3 convolution layers with a ReLU activation and followed by max-pooling layers.\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n# model.compile(loss='binary_crossentropy',\n#               optimizer='rmsprop',\n#               metrics=['accuracy','mae'])\n\nmodel.compile(loss=roc_auc_score_loss,\n              optimizer='rmsprop',\n              metrics=['accuracy','mae',roc_auc_score])\nepochs = 5\n\ntrain_samples = 2048\nvalidation_samples = 832\n\n\nmodel.fit_generator(\n        train_generator,\n        steps_per_epoch=train_samples // batch_size,\n        epochs=epochs,\n        validation_data=validation_generator,\n        validation_steps=validation_samples// batch_size)\n\nmodel.save_weights('models/basic_cnn_30_epochs.h5')\nprint(model.summary())\n\n\n</code></pre>\n<p><strong>The problem is the following :</strong>+1:<br>\nValueError                                Traceback (most recent call last)<br>\n in ()<br>\n149         epochs=epochs,<br>\n150         validation_data=validation_generator,<br>\n--&gt; 151         validation_steps=validation_samples// batch_size)<br>\n152<br>\n153 model.save_weights('models/basic_cnn_30_epochs.h5')</p>\n<p>/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)<br>\n85                 warnings.warn('Update your <code>' + object_name + 86                               '</code> call to the Keras 2 API: ' + signature, stacklevel=2)<br>\n---&gt; 87             return func(*args, **kwargs)<br>\n88         wrapper._original_function = func<br>\n89         return wrapper</p>\n<p>/usr/local/lib/python2.7/dist-packages/keras/models.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)<br>\n1119                                         workers=workers,<br>\n1120                                         use_multiprocessing=use_multiprocessing,<br>\n-&gt; 1121                                         initial_epoch=initial_epoch)<br>\n1122<br>\n1123     @interfaces.legacy_generator_methods_support</p>\n<p>/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)<br>\n85                 warnings.warn('Update your <code>' + object_name + 86                               '</code> call to the Keras 2 API: ' + signature, stacklevel=2)<br>\n---&gt; 87             return func(*args, **kwargs)<br>\n88         wrapper._original_function = func<br>\n89         return wrapper</p>\n<p>/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)<br>\n1924<br>\n1925         do_validation = bool(validation_data)<br>\n-&gt; 1926         self._make_train_function()<br>\n1927         if do_validation:<br>\n1928             self._make_test_function()</p>\n<p>/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in _make_train_function(self)<br>\n958                     training_updates = self.optimizer.get_updates(<br>\n959                         params=self._collected_trainable_weights,<br>\n--&gt; 960                         loss=self.total_loss)<br>\n961                 updates = self.updates + training_updates<br>\n962                 # Gets loss and metrics. Updates weights at each call.</p>\n<p>/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)<br>\n85                 warnings.warn('Update your <code>' + object_name + 86                               '</code> call to the Keras 2 API: ' + signature, stacklevel=2)<br>\n---&gt; 87             return func(*args, **kwargs)<br>\n88         wrapper._original_function = func<br>\n89         return wrapper</p>\n<p>/usr/local/lib/python2.7/dist-packages/keras/optimizers.pyc in get_updates(self, loss, params)<br>\n235         for p, g, a in zip(params, grads, accumulators):<br>\n236             # update accumulator<br>\n--&gt; 237             new_a = self.rho * a + (1. - self.rho) * K.square(g)<br>\n238             self.updates.append(K.update(a, new_a))<br>\n239             new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)</p>\n<p>/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in square(x)<br>\n1356         A tensor.<br>\n1357     \"\"\"<br>\n-&gt; 1358     return tf.square(x)<br>\n1359<br>\n1360</p>\n<p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc in square(x, name)<br>\n447           indices=x.indices, values=x_square, dense_shape=x.dense_shape)<br>\n448     else:<br>\n--&gt; 449       return gen_math_ops.square(x, name=name)<br>\n450<br>\n451</p>\n<p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc in square(x, name)<br>\n4565   if _ctx.in_graph_mode():<br>\n4566     _, _, _op = _op_def_lib._apply_op_helper(<br>\n-&gt; 4567         \"Square\", x=x, name=name)<br>\n4568     _result = _op.outputs[:]<br>\n4569     _inputs_flat = _op.inputs</p>\n<p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)<br>\n526               raise ValueError(<br>\n527                   \"Tried to convert '%s' to a tensor and failed. Error: %s\" %<br>\n--&gt; 528                   (input_name, err))<br>\n529             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %<br>\n530                       (input_name, op_type_name, observed))</p>\n<p>ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.</p>\n<p>Finally, Anyone can check this problem. Looking forward to reply. Thanks advanced!</p>\n<h3>System information</h3>\n<p>Operating System: Ubuntu 16.04 LTS<br>\nGraphics card: Tesla K40<br>\nInstalled version of CUDA: 8.0<br>\nInstalled version of cuDNN: v5 , for CUDA 8.0<br>\npip --version 9.0.1<br>\npip 9.0.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)<br>\npip install tensorflow-gpu<br>\nName: tensorflow-gpu, Version: 1.4.1</p>", "body_text": "Dear everyone,\nI found the roc_auc_score function in  https://github.com/tflearn/tflearn/blob/master/tflearn/objectives.py. Now I want to write this function by keras. But failed. The following is the code:\ndef roc_auc_score(y_pred, y_true):\n    \"\"\" ROC AUC Score.\n    Approximates the Area Under Curve score, using approximation based on\n    the Wilcoxon-Mann-Whitney U statistic.\n    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n    Measures overall performance for a full range of threshold levels.\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n    \"\"\"\n    with tf.name_scope(\"RocAucScore\"):\n        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n        pos = tf.expand_dims(pos, 0)\n        neg = tf.expand_dims(neg, 1)\n        # original paper suggests performance is robust to exact parameter choice\n        gamma = 0.2\n        p     = 3\n        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n        masked = tf.boolean_mask(difference, difference < 0.0)\n        return tf.reduce_sum(tf.pow(-masked, p))\n\nThe new code was changed to the following:\ndef roc_auc_score(y_pred, y_true):\n    \"\"\" ROC AUC Score.\n    Approximates the Area Under Curve score, using approximation based on\n    the Wilcoxon-Mann-Whitney U statistic.\n    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n    Measures overall performance for a full range of threshold levels.\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n    \"\"\"\n    pos = tf.boolean_mask(y_pred, K.cast(y_true, tf.bool))\n    neg = tf.boolean_mask(y_pred, ~K.cast(y_true, tf.bool))\n    pos = K.expand_dims(pos, 0)\n    neg = K.expand_dims(neg, 1)\n    # original paper suggests performance is robust to exact parameter choice\n    gamma = 0.2\n    p     = 3\n    difference = K.zeros_like(pos * neg) + pos - neg - gamma\n    masked = tf.boolean_mask(difference, difference < 0.0)\n    return K.sum(K.pow(-masked, p))\n\nAll the code are the following, it doesn't work,\nThe data in\nhttps://pan.baidu.com/s/12yJCWdfvVW1tEKUfEU34RQ ,  password: nu98\n# -*- coding: UTF-8 -*-\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras import optimizers\nfrom keras import applications\nfrom keras.models import Model\nimport keras\nimport numpy as np\nfrom keras import backend as K\nimport tensorflow as tf\n\n\nprint(\"---------------------------AUC----------------------------------------\")\n\n\n# def roc_auc_score(y_pred, y_true):\n#     \"\"\" ROC AUC Score.\n#     Approximates the Area Under Curve score, using approximation based on\n#     the Wilcoxon-Mann-Whitney U statistic.\n#     Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n#     Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n#     Measures overall performance for a full range of threshold levels.\n#     Arguments:\n#         y_pred: `Tensor`. Predicted values.\n#         y_true: `Tensor` . Targets (labels), a probability distribution.\n#     \"\"\"\n#     with tf.name_scope(\"RocAucScore\"):\n\n#         pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n#         neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n\n#         pos = tf.expand_dims(pos, 0)\n#         neg = tf.expand_dims(neg, 1)\n\n#         # original paper suggests performance is robust to exact parameter choice\n#         gamma = 0.2\n#         p     = 3\n\n#         difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n\n#         masked = tf.boolean_mask(difference, difference < 0.0)\n\n#         return tf.reduce_sum(tf.pow(-masked, p))\n\n\n\ndef roc_auc_score(y_pred, y_true):\n    \"\"\" ROC AUC Score.\n    Approximates the Area Under Curve score, using approximation based on\n    the Wilcoxon-Mann-Whitney U statistic.\n    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n    Measures overall performance for a full range of threshold levels.\n    Arguments:\n        y_pred: `Tensor`. Predicted values.\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n    \"\"\"\n    pos = tf.boolean_mask(y_pred, K.cast(y_true, tf.bool))\n    neg = tf.boolean_mask(y_pred, ~K.cast(y_true, tf.bool))\n    pos = K.expand_dims(pos, 0)\n    neg = K.expand_dims(neg, 1)\n    # original paper suggests performance is robust to exact parameter choice\n    gamma = 0.2\n    p     = 3\n    difference = K.zeros_like(pos * neg) + pos - neg - gamma\n    masked = tf.boolean_mask(difference, difference < 0.0)\n    return K.sum(K.pow(-masked, p))\n\ndef roc_auc_score_loss(y_true, y_pred):\n    return roc_auc_score(y_true, y_pred)\nprint(\"---------------------------AUC----------------------------------------\")\n\n\n# dimensions of our images.\nimg_width, img_height = 512, 512\n\ntrain_data_dir = 'data/train/'\nvalidation_data_dir = 'data/validation/'\n\n\n##preprocessing\n# used to rescale the pixel values from [0, 255] to [0, 1] interval\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 32\n\n# automagically retrieve images and their classes for train and validation sets\ntrain_generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='binary')\n\nvalidation_generator = datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='binary',shuffle=False)\n\n\n\n# a simple stack of 3 convolution layers with a ReLU activation and followed by max-pooling layers.\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n# model.compile(loss='binary_crossentropy',\n#               optimizer='rmsprop',\n#               metrics=['accuracy','mae'])\n\nmodel.compile(loss=roc_auc_score_loss,\n              optimizer='rmsprop',\n              metrics=['accuracy','mae',roc_auc_score])\nepochs = 5\n\ntrain_samples = 2048\nvalidation_samples = 832\n\n\nmodel.fit_generator(\n        train_generator,\n        steps_per_epoch=train_samples // batch_size,\n        epochs=epochs,\n        validation_data=validation_generator,\n        validation_steps=validation_samples// batch_size)\n\nmodel.save_weights('models/basic_cnn_30_epochs.h5')\nprint(model.summary())\n\n\n\nThe problem is the following :+1:\nValueError                                Traceback (most recent call last)\n in ()\n149         epochs=epochs,\n150         validation_data=validation_generator,\n--> 151         validation_steps=validation_samples// batch_size)\n152\n153 model.save_weights('models/basic_cnn_30_epochs.h5')\n/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)\n85                 warnings.warn('Update your ' + object_name + 86                               ' call to the Keras 2 API: ' + signature, stacklevel=2)\n---> 87             return func(*args, **kwargs)\n88         wrapper._original_function = func\n89         return wrapper\n/usr/local/lib/python2.7/dist-packages/keras/models.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\n1119                                         workers=workers,\n1120                                         use_multiprocessing=use_multiprocessing,\n-> 1121                                         initial_epoch=initial_epoch)\n1122\n1123     @interfaces.legacy_generator_methods_support\n/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)\n85                 warnings.warn('Update your ' + object_name + 86                               ' call to the Keras 2 API: ' + signature, stacklevel=2)\n---> 87             return func(*args, **kwargs)\n88         wrapper._original_function = func\n89         return wrapper\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\n1924\n1925         do_validation = bool(validation_data)\n-> 1926         self._make_train_function()\n1927         if do_validation:\n1928             self._make_test_function()\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in _make_train_function(self)\n958                     training_updates = self.optimizer.get_updates(\n959                         params=self._collected_trainable_weights,\n--> 960                         loss=self.total_loss)\n961                 updates = self.updates + training_updates\n962                 # Gets loss and metrics. Updates weights at each call.\n/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)\n85                 warnings.warn('Update your ' + object_name + 86                               ' call to the Keras 2 API: ' + signature, stacklevel=2)\n---> 87             return func(*args, **kwargs)\n88         wrapper._original_function = func\n89         return wrapper\n/usr/local/lib/python2.7/dist-packages/keras/optimizers.pyc in get_updates(self, loss, params)\n235         for p, g, a in zip(params, grads, accumulators):\n236             # update accumulator\n--> 237             new_a = self.rho * a + (1. - self.rho) * K.square(g)\n238             self.updates.append(K.update(a, new_a))\n239             new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in square(x)\n1356         A tensor.\n1357     \"\"\"\n-> 1358     return tf.square(x)\n1359\n1360\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc in square(x, name)\n447           indices=x.indices, values=x_square, dense_shape=x.dense_shape)\n448     else:\n--> 449       return gen_math_ops.square(x, name=name)\n450\n451\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc in square(x, name)\n4565   if _ctx.in_graph_mode():\n4566     _, _, _op = _op_def_lib._apply_op_helper(\n-> 4567         \"Square\", x=x, name=name)\n4568     _result = _op.outputs[:]\n4569     _inputs_flat = _op.inputs\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)\n526               raise ValueError(\n527                   \"Tried to convert '%s' to a tensor and failed. Error: %s\" %\n--> 528                   (input_name, err))\n529             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n530                       (input_name, op_type_name, observed))\nValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.\nFinally, Anyone can check this problem. Looking forward to reply. Thanks advanced!\nSystem information\nOperating System: Ubuntu 16.04 LTS\nGraphics card: Tesla K40\nInstalled version of CUDA: 8.0\nInstalled version of cuDNN: v5 , for CUDA 8.0\npip --version 9.0.1\npip 9.0.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)\npip install tensorflow-gpu\nName: tensorflow-gpu, Version: 1.4.1", "body": "Dear everyone,\r\n                     I found the roc_auc_score function in  https://github.com/tflearn/tflearn/blob/master/tflearn/objectives.py. Now I want to write this function by keras. But failed. The following is the code:\r\n```\r\ndef roc_auc_score(y_pred, y_true):\r\n    \"\"\" ROC AUC Score.\r\n    Approximates the Area Under Curve score, using approximation based on\r\n    the Wilcoxon-Mann-Whitney U statistic.\r\n    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\r\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\r\n    Measures overall performance for a full range of threshold levels.\r\n    Arguments:\r\n        y_pred: `Tensor`. Predicted values.\r\n        y_true: `Tensor` . Targets (labels), a probability distribution.\r\n    \"\"\"\r\n    with tf.name_scope(\"RocAucScore\"):\r\n        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\r\n        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\r\n        pos = tf.expand_dims(pos, 0)\r\n        neg = tf.expand_dims(neg, 1)\r\n        # original paper suggests performance is robust to exact parameter choice\r\n        gamma = 0.2\r\n        p     = 3\r\n        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\r\n        masked = tf.boolean_mask(difference, difference < 0.0)\r\n        return tf.reduce_sum(tf.pow(-masked, p))\r\n```\r\n\r\n\r\n**The new code was changed to the following:**\r\n\r\n```\r\ndef roc_auc_score(y_pred, y_true):\r\n    \"\"\" ROC AUC Score.\r\n    Approximates the Area Under Curve score, using approximation based on\r\n    the Wilcoxon-Mann-Whitney U statistic.\r\n    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\r\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\r\n    Measures overall performance for a full range of threshold levels.\r\n    Arguments:\r\n        y_pred: `Tensor`. Predicted values.\r\n        y_true: `Tensor` . Targets (labels), a probability distribution.\r\n    \"\"\"\r\n    pos = tf.boolean_mask(y_pred, K.cast(y_true, tf.bool))\r\n    neg = tf.boolean_mask(y_pred, ~K.cast(y_true, tf.bool))\r\n    pos = K.expand_dims(pos, 0)\r\n    neg = K.expand_dims(neg, 1)\r\n    # original paper suggests performance is robust to exact parameter choice\r\n    gamma = 0.2\r\n    p     = 3\r\n    difference = K.zeros_like(pos * neg) + pos - neg - gamma\r\n    masked = tf.boolean_mask(difference, difference < 0.0)\r\n    return K.sum(K.pow(-masked, p))\r\n```\r\n\r\n**All the code are the following, it doesn't work,** \r\n **The data in** \r\nhttps://pan.baidu.com/s/12yJCWdfvVW1tEKUfEU34RQ ,  password: nu98\r\n```\r\n# -*- coding: UTF-8 -*-\r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\nimport numpy as np\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Activation, Dropout, Flatten, Dense\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\r\nfrom keras import optimizers\r\nfrom keras import applications\r\nfrom keras.models import Model\r\nimport keras\r\nimport numpy as np\r\nfrom keras import backend as K\r\nimport tensorflow as tf\r\n\r\n\r\nprint(\"---------------------------AUC----------------------------------------\")\r\n\r\n\r\n# def roc_auc_score(y_pred, y_true):\r\n#     \"\"\" ROC AUC Score.\r\n#     Approximates the Area Under Curve score, using approximation based on\r\n#     the Wilcoxon-Mann-Whitney U statistic.\r\n#     Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\r\n#     Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\r\n#     Measures overall performance for a full range of threshold levels.\r\n#     Arguments:\r\n#         y_pred: `Tensor`. Predicted values.\r\n#         y_true: `Tensor` . Targets (labels), a probability distribution.\r\n#     \"\"\"\r\n#     with tf.name_scope(\"RocAucScore\"):\r\n\r\n#         pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\r\n#         neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\r\n\r\n#         pos = tf.expand_dims(pos, 0)\r\n#         neg = tf.expand_dims(neg, 1)\r\n\r\n#         # original paper suggests performance is robust to exact parameter choice\r\n#         gamma = 0.2\r\n#         p     = 3\r\n\r\n#         difference = tf.zeros_like(pos * neg) + pos - neg - gamma\r\n\r\n#         masked = tf.boolean_mask(difference, difference < 0.0)\r\n\r\n#         return tf.reduce_sum(tf.pow(-masked, p))\r\n\r\n\r\n\r\ndef roc_auc_score(y_pred, y_true):\r\n    \"\"\" ROC AUC Score.\r\n    Approximates the Area Under Curve score, using approximation based on\r\n    the Wilcoxon-Mann-Whitney U statistic.\r\n    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\r\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\r\n    Measures overall performance for a full range of threshold levels.\r\n    Arguments:\r\n        y_pred: `Tensor`. Predicted values.\r\n        y_true: `Tensor` . Targets (labels), a probability distribution.\r\n    \"\"\"\r\n    pos = tf.boolean_mask(y_pred, K.cast(y_true, tf.bool))\r\n    neg = tf.boolean_mask(y_pred, ~K.cast(y_true, tf.bool))\r\n    pos = K.expand_dims(pos, 0)\r\n    neg = K.expand_dims(neg, 1)\r\n    # original paper suggests performance is robust to exact parameter choice\r\n    gamma = 0.2\r\n    p     = 3\r\n    difference = K.zeros_like(pos * neg) + pos - neg - gamma\r\n    masked = tf.boolean_mask(difference, difference < 0.0)\r\n    return K.sum(K.pow(-masked, p))\r\n\r\ndef roc_auc_score_loss(y_true, y_pred):\r\n    return roc_auc_score(y_true, y_pred)\r\nprint(\"---------------------------AUC----------------------------------------\")\r\n\r\n\r\n# dimensions of our images.\r\nimg_width, img_height = 512, 512\r\n\r\ntrain_data_dir = 'data/train/'\r\nvalidation_data_dir = 'data/validation/'\r\n\r\n\r\n##preprocessing\r\n# used to rescale the pixel values from [0, 255] to [0, 1] interval\r\ndatagen = ImageDataGenerator(rescale=1./255)\r\nbatch_size = 32\r\n\r\n# automagically retrieve images and their classes for train and validation sets\r\ntrain_generator = datagen.flow_from_directory(\r\n        train_data_dir,\r\n        target_size=(img_width, img_height),\r\n        batch_size=batch_size,\r\n        class_mode='binary')\r\n\r\nvalidation_generator = datagen.flow_from_directory(\r\n        validation_data_dir,\r\n        target_size=(img_width, img_height),\r\n        batch_size=batch_size,\r\n        class_mode='binary',shuffle=False)\r\n\r\n\r\n\r\n# a simple stack of 3 convolution layers with a ReLU activation and followed by max-pooling layers.\r\nmodel = Sequential()\r\nmodel.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height,3)))\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\n\r\nmodel.add(Convolution2D(32, (3, 3)))\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\n\r\nmodel.add(Convolution2D(64, (3, 3)))\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(64))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(1))\r\nmodel.add(Activation('sigmoid'))\r\n\r\n# model.compile(loss='binary_crossentropy',\r\n#               optimizer='rmsprop',\r\n#               metrics=['accuracy','mae'])\r\n\r\nmodel.compile(loss=roc_auc_score_loss,\r\n              optimizer='rmsprop',\r\n              metrics=['accuracy','mae',roc_auc_score])\r\nepochs = 5\r\n\r\ntrain_samples = 2048\r\nvalidation_samples = 832\r\n\r\n\r\nmodel.fit_generator(\r\n        train_generator,\r\n        steps_per_epoch=train_samples // batch_size,\r\n        epochs=epochs,\r\n        validation_data=validation_generator,\r\n        validation_steps=validation_samples// batch_size)\r\n\r\nmodel.save_weights('models/basic_cnn_30_epochs.h5')\r\nprint(model.summary())\r\n\r\n\r\n```\r\n**The problem is the following :**+1: \r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-cc3e34fe5d20> in <module>()\r\n    149         epochs=epochs,\r\n    150         validation_data=validation_generator,\r\n--> 151         validation_steps=validation_samples// batch_size)\r\n    152 \r\n    153 model.save_weights('models/basic_cnn_30_epochs.h5')\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)\r\n     85                 warnings.warn('Update your `' + object_name +\r\n     86                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\r\n---> 87             return func(*args, **kwargs)\r\n     88         wrapper._original_function = func\r\n     89         return wrapper\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/models.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\r\n   1119                                         workers=workers,\r\n   1120                                         use_multiprocessing=use_multiprocessing,\r\n-> 1121                                         initial_epoch=initial_epoch)\r\n   1122 \r\n   1123     @interfaces.legacy_generator_methods_support\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)\r\n     85                 warnings.warn('Update your `' + object_name +\r\n     86                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\r\n---> 87             return func(*args, **kwargs)\r\n     88         wrapper._original_function = func\r\n     89         return wrapper\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1924 \r\n   1925         do_validation = bool(validation_data)\r\n-> 1926         self._make_train_function()\r\n   1927         if do_validation:\r\n   1928             self._make_test_function()\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in _make_train_function(self)\r\n    958                     training_updates = self.optimizer.get_updates(\r\n    959                         params=self._collected_trainable_weights,\r\n--> 960                         loss=self.total_loss)\r\n    961                 updates = self.updates + training_updates\r\n    962                 # Gets loss and metrics. Updates weights at each call.\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)\r\n     85                 warnings.warn('Update your `' + object_name +\r\n     86                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\r\n---> 87             return func(*args, **kwargs)\r\n     88         wrapper._original_function = func\r\n     89         return wrapper\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/optimizers.pyc in get_updates(self, loss, params)\r\n    235         for p, g, a in zip(params, grads, accumulators):\r\n    236             # update accumulator\r\n--> 237             new_a = self.rho * a + (1. - self.rho) * K.square(g)\r\n    238             self.updates.append(K.update(a, new_a))\r\n    239             new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in square(x)\r\n   1356         A tensor.\r\n   1357     \"\"\"\r\n-> 1358     return tf.square(x)\r\n   1359 \r\n   1360 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc in square(x, name)\r\n    447           indices=x.indices, values=x_square, dense_shape=x.dense_shape)\r\n    448     else:\r\n--> 449       return gen_math_ops.square(x, name=name)\r\n    450 \r\n    451 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc in square(x, name)\r\n   4565   if _ctx.in_graph_mode():\r\n   4566     _, _, _op = _op_def_lib._apply_op_helper(\r\n-> 4567         \"Square\", x=x, name=name)\r\n   4568     _result = _op.outputs[:]\r\n   4569     _inputs_flat = _op.inputs\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    526               raise ValueError(\r\n    527                   \"Tried to convert '%s' to a tensor and failed. Error: %s\" %\r\n--> 528                   (input_name, err))\r\n    529             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\r\n    530                       (input_name, op_type_name, observed))\r\n\r\nValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.\r\n\r\nFinally, Anyone can check this problem. Looking forward to reply. Thanks advanced!\r\n### System information\r\nOperating System: Ubuntu 16.04 LTS\r\nGraphics card: Tesla K40\r\nInstalled version of CUDA: 8.0 \r\nInstalled version of cuDNN: v5 , for CUDA 8.0 \r\npip --version 9.0.1\r\npip 9.0.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)\r\npip install tensorflow-gpu\r\nName: tensorflow-gpu, Version: 1.4.1"}