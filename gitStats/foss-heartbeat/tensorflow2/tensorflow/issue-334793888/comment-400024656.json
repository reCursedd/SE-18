{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/400024656", "html_url": "https://github.com/tensorflow/tensorflow/issues/20218#issuecomment-400024656", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20218", "id": 400024656, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMDAyNDY1Ng==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-25T17:05:05Z", "updated_at": "2018-06-25T17:05:05Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">Very interesting. So this is not a straightforward leak of tf variables.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Mon, Jun 25, 2018 at 1:37 AM jaye ***@***.***&gt; wrote:\n Hi alextp, thank you very much for you helping. The following is the code\n of part of my model:\n\n `import tensorflow as tf\n import tensorflow.contrib.eager as tfe\n import numpy as np\n\n class Model():\n def *init*(self,params,vocab_size):\n\n     # Hy-parameters\n     self.vocab_size = vocab_size\n     self.embedding_dim = params.embedding_dim\n     self.hidden_dim = params.hidden_dim\n     self.num_layers = params.num_layers\n     self.keep_ratio = params.keep_ratio\n     self.time_major = params.time_major\n\n     # Embeddings\n     self.embedding = Embedding(self.vocab_size,self.embedding_dim,self.time_major)\n\n     # Dynamic RNN\n     self.rnn = RNN(self.hidden_dim, self.embedding_dim,self.num_layers,\n                            self.keep_ratio,self.time_major, name='Forward')\n\n\n     # Fully Connections Layer\n     self.fc = FC(self.embedding_dim,self.vocab_size,self.time_major)\n\n     # Build all trainable variables\n     self.build()\n\n     # Add saver\n     self.saver = tfe.Saver(self.variables)\n\n def build(self):\n     # initialize trainable variables\n     self.variables = []\n\n     self.variables.append(self.embedding.embedding)\n     for variable in self.rnn.variables:\n         self.variables.append(variable)\n     self.variables.append(self.fc.weights)\n     self.variables.append(self.fc.bias)\n\n def __call__(self,inputs,training):\n     # Parallel computing\n     if self.time_major:\n         inputs = tf.transpose(inputs,(1,0))\n     # Get word embeddings for all\n     embed = self.embedding(inputs)\n     # moving\n     rnn_outputs = self.rnn(embed,training=training)\n\n     # Fully connections\n     logits = self.fc(rnn_outputs)\n     if self.time_major:\n         seq_len,batch_size,last_dim=logits.shape.as_list()\n         logits = tf.reshape(logits,(batch_size,seq_len,-1))\n\n     return logits\n\n class Embedding():\n # Embedding with different lengths.\n def *init*(self, vocab_size, embedding_dim,time_major=True):\n self.vocab_size = vocab_size\n self.embedding_dim = embedding_dim\n self.time_major = time_major\n\n     self.embedding = tfe.Variable(initial_value=tf.random_normal(shape=(vocab_size,embedding_dim)),\n                                   dtype=tf.float32,name='embedding',trainable=True)\n\n def __call__(self, x):\n     # implement word embedding\n     # whether parallel computing\n     if self.time_major:\n         #all_embedded=tf.nn.embedding_lookup(self.embedding,x)\n         seq_len, batch_size = x.shape.as_list()\n         x = tf.one_hot(x, depth=self.vocab_size)\n         flat_x = tf.reshape(x, shape=(-1,self.vocab_size))\n         all_embedded = tf.matmul(flat_x,self.embedding)\n         all_embedded = tf.reshape(all_embedded,(seq_len,batch_size,-1))\n     else:\n         all_embedded = []\n         for seq in x:\n           #embedded = tf.nn.embedding_lookup(self.embedding,seq)\n           seq = tf.one_hot(seq, depth=self.vocab_size)\n           embedded = tf.matmul(seq, self.embedding)\n           all_embedded.append(embedded)\n\n     return all_embedded\n\n class LSTMCell():\n def *init*(self,inputs_dim, hidden_dim, name):\n\n     self.inputs_dim = inputs_dim\n     self.hidden_dim = hidden_dim\n\n     with tf.name_scope(name=name):\n         # Forget gate\n         self.W_f = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n                                 dtype=tf.float32, name='forget_weights', trainable=True)\n         self.b_f = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n                                 dtype=tf.float32, name='forget_bias', trainable=True)\n         # Input gate\n         self.W_i = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n                                 dtype=tf.float32, name='input_weights', trainable=True)\n         self.b_i = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n                                 dtype=tf.float32, name='input_bias', trainable=True)\n         self.W_c = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n                                 dtype=tf.float32, name='input_filter_weights', trainable=True)\n         self.b_c = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n                                 dtype=tf.float32, name='input_filter_bias', trainable=True)\n         # Output gate\n         self.W_o = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n                                 dtype=tf.float32, name='output_weights', trainable=True)\n         self.b_o = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n                                 dtype=tf.float32, name='output_bias', trainable=True)\n\n         self.build()\n\n def build(self,):\n     # build all variables\n     self.variables = [self.W_f, self.b_f,self.W_i, self.b_i,\n                       self.W_c, self.b_c,self.W_o, self.b_o]\n\n def zero_state(self,batch_size):\n     c_t = tf.zeros(shape=(batch_size,self.hidden_dim),name='c_t')\n     h_t = tf.zeros(shape=(batch_size,self.hidden_dim),name='h_t')\n     return c_t, h_t\n\n def __call__(self,x_t,c_t,h_t):\n     # Define LSTM forward propagation\n\n     # Forget\n     f_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_f,self.b_f),name='Forget_Gate')\n     # Input\n     i_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_i,self.b_i),name='Input_Gate')\n     uc_t=tf.tanh(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_c,self.b_c),name='Input_Filter')\n     # Update Cell State\n     c_t = f_t*c_t + i_t*uc_t\n     # Output\n     o_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_o,self.b_o),name='Output_Gate')\n     h_t = o_t * tf.tanh(c_t)\n\n     return o_t,c_t,h_t\n\n class RNN():\n # A static RNN. Similar to tf.nn.static_rnn, implemented as a class.\n def *init*(self, hidden_dim,inputs_dim, num_layers,\n keep_ratio,time_major=True,name=''):\n self.keep_ratio = keep_ratio\n self.time_major = time_major\n self.inputs_dim=inputs_dim\n self.hidden_dim=hidden_dim\n\n     self.cells = [\n         LSTMCell(inputs_dim,hidden_dim,name=name+'_LSTMCell'+str(idx))\n         for idx in range(num_layers)\n     ]\n\n     self.build()\n\n def build(self):\n     # build all trainable variables\n     self.variables = []\n\n     for cell in self.cells:\n         for variable in cell.variables:\n             self.variables.append(variable)\n\n\n def __call__(self, inputs_seq, training=False):\n     # rnn with different length sequences, inputs : [batch, (embedded tensor)]\n\n     # parallel computing\n     if self.time_major:\n         seq_len,batch_size,last_dim = inputs_seq.shape.as_list()\n         for cell in self.cells:\n             c_t, h_t = cell.zero_state(batch_size)\n             outputs = []\n             for inp in inputs_seq:\n                 output, c_t, h_t = cell(inp, c_t, h_t)\n                 outputs.append(output)\n\n             inputs_seq = tf.stack(outputs, axis=0)\n             if training:\n                 inputs_seq = tf.nn.dropout(inputs_seq, self.keep_ratio)\n         batch_outputs = inputs_seq\n     # linear computing\n     else:\n         for cell in self.cells:\n             c_t,h_t = cell.zero_state(1)\n             outputs = []\n             for seq in inputs_seq:\n                 seq_outputs = []\n                 for word in seq:\n                     word = tf.reshape(word,(1,-1))\n                     output, c_t,h_t = cell(word, c_t,h_t)\n                     if training:\n                         output = tf.nn.dropout(output, self.keep_ratio)\n                     seq_outputs.append(output)\n                 outputs.append(seq_outputs)\n             inputs_seq = outputs\n         batch_outputs = inputs_seq\n     return batch_outputs\n\n class FC():\n # A Fully Connection Layer.\n def *init*(self, inputs_dim,\n outputs_dim,time_major=True,active=tf.nn.relu,name=None):\n self.inputs_dim = inputs_dim\n self.outputs_dim= outputs_dim\n self.time_major = time_major\n self.active = active\n\n     # Build trainable variables\n     self.weights = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim,outputs_dim)),\n                               dtype=tf.float32,name=name,trainable=True)\n     self.bias = tfe.Variable(initial_value=tf.random_normal(shape=(outputs_dim,)),\n                               dtype=tf.float32,name=name,trainable=True)\n\n def __call__(self, x):\n     # different length sequences, inputs : [batch, (RNN outputs tensor)]\n     # whether to parallel computing\n     if self.time_major:\n         seq_len,batch_size,last_dim = x.shape.as_list()\n         # flatten\n         flat = tf.reshape(x,(-1,last_dim))\n         fc = tf.nn.xw_plus_b(flat,self.weights,self.bias)\n         outputs = self.active(fc)\n         outputs = tf.reshape(outputs,(seq_len,batch_size,-1))\n     else:\n         outputs = []\n         for seq in x:\n             fc = tf.nn.xw_plus_b(seq, self.weights, self.bias)\n             fc = self.active(fc)\n             outputs.append(fc)\n     return outputs\n\n `\n\n Part of the training code is as follows:\n\n with tf.GradientTape() as tape: logits =\n model(batch_forward,batch_backward,training=True) loss =\n training_helper.loss_fn_time_major(batch_labels,logits,batch_lengths) # add\n loss summary tf.contrib.summary.scalar('loss', loss) grads =\n tape.gradient(loss, model.variables)\n optimizer.apply_gradients(zip(grads,model.variables)) print('loss at epoch\n %d step %d: %f' % (epoch,train_step,loss))\n\n I used your recommended settings turning log_device_placement=True, then I\n observed an interesting phenomenon. At every certain training step, there\n are three operation logs that are cycled, and the interval between the\n training steps is gradually decreasing.\n The following is the log after the setting log_device_placement=True is\n turned on. It can be seen, at the beginning, a log of three operations is\n printed every 16 training steps. As the training process progresses, a log\n of three operations is printed every three training steps until the OOM\n problem happened. I don't know why and what these three operations\n represent respectively. I hope this information will help solve the\n problem. Thank you again for your reply.\n some logs\n\n loss at epoch 0 step 805: 6.740626\n loss at epoch 0 step 806: 7.095036\n loss at epoch 0 step 807: 7.000319\n loss at epoch 0 step 808: 6.904347\n loss at epoch 0 step 809: 6.922751\n loss at epoch 0 step 810: 6.838681\n loss at epoch 0 step 811: 6.905680\n loss at epoch 0 step 812: 7.053514\n loss at epoch 0 step 813: 6.855484\n loss at epoch 0 step 814: 6.755508\n loss at epoch 0 step 815: 7.050679\n loss at epoch 0 step 816: 7.023479\n loss at epoch 0 step 817: 6.827959\n loss at epoch 0 step 818: 6.776998\n loss at epoch 0 step 819: 6.765797\n loss at epoch 0 step 820: 6.759283\n 2018-06-25 14:57:15.878743: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:15.935075: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:15.970760: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 821: 6.984869\n loss at epoch 0 step 822: 6.748662\n loss at epoch 0 step 823: 6.772003\n loss at epoch 0 step 824: 6.942709\n loss at epoch 0 step 825: 6.892979\n loss at epoch 0 step 826: 6.680350\n loss at epoch 0 step 827: 6.867269\n loss at epoch 0 step 828: 7.118308\n loss at epoch 0 step 829: 6.601588\n loss at epoch 0 step 830: 6.652170\n loss at epoch 0 step 831: 7.263901\n loss at epoch 0 step 832: 6.902826\n loss at epoch 0 step 833: 6.791662\n loss at epoch 0 step 834: 7.087551\n loss at epoch 0 step 835: 6.820101\n 2018-06-25 14:57:18.650329: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:18.710324: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:18.746490: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 836: 7.031796\n loss at epoch 0 step 837: 6.905032\n loss at epoch 0 step 838: 6.889287\n loss at epoch 0 step 839: 6.732944\n loss at epoch 0 step 840: 6.715842\n loss at epoch 0 step 841: 6.757300\n loss at epoch 0 step 842: 6.882929\n loss at epoch 0 step 843: 6.658679\n loss at epoch 0 step 844: 6.788300\n loss at epoch 0 step 845: 6.952966\n loss at epoch 0 step 846: 7.061527\n loss at epoch 0 step 847: 6.603632\n loss at epoch 0 step 848: 7.163596\n loss at epoch 0 step 849: 7.038760\n 2018-06-25 14:57:21.325933: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:21.386127: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:21.423910: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 850: 6.885034\n loss at epoch 0 step 851: 6.931499\n loss at epoch 0 step 852: 6.713628\n loss at epoch 0 step 853: 6.777599\n loss at epoch 0 step 854: 6.799969\n loss at epoch 0 step 855: 6.985339\n loss at epoch 0 step 856: 6.620006\n loss at epoch 0 step 857: 6.878152\n loss at epoch 0 step 858: 6.783222\n loss at epoch 0 step 859: 6.712417\n loss at epoch 0 step 860: 6.734530\n loss at epoch 0 step 861: 7.009552\n 2018-06-25 14:57:23.706079: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:23.769647: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:23.809172: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 862: 6.570765\n loss at epoch 0 step 863: 6.818643\n loss at epoch 0 step 864: 6.707229\n loss at epoch 0 step 865: 6.860226\n loss at epoch 0 step 866: 6.832708\n loss at epoch 0 step 867: 6.746671\n loss at epoch 0 step 868: 6.925843\n loss at epoch 0 step 869: 6.845281\n loss at epoch 0 step 870: 6.901897\n loss at epoch 0 step 871: 6.936728\n loss at epoch 0 step 872: 6.793565\n 2018-06-25 14:57:25.894904: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:25.958699: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:25.998658: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 873: 6.795174\n loss at epoch 0 step 874: 6.897914\n loss at epoch 0 step 875: 6.964663\n loss at epoch 0 step 876: 6.933444\n loss at epoch 0 step 877: 6.889087\n loss at epoch 0 step 878: 6.728238\n loss at epoch 0 step 879: 6.543335\n loss at epoch 0 step 880: 6.785100\n loss at epoch 0 step 881: 6.867868\n loss at epoch 0 step 882: 6.626728\n 2018-06-25 14:57:28.011803: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:28.078783: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:28.121272: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 883: 6.632171\n loss at epoch 0 step 884: 6.638273\n loss at epoch 0 step 885: 6.727106\n loss at epoch 0 step 886: 6.755214\n loss at epoch 0 step 887: 6.788674\n loss at epoch 0 step 888: 6.618323\n loss at epoch 0 step 889: 6.802135\n loss at epoch 0 step 890: 6.812809\n loss at epoch 0 step 891: 6.905511\n 2018-06-25 14:57:29.982565: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:30.048872: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:30.089943: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 892: 6.660409\n loss at epoch 0 step 893: 6.817567\n loss at epoch 0 step 894: 6.782594\n loss at epoch 0 step 895: 6.746886\n loss at epoch 0 step 896: 6.679479\n loss at epoch 0 step 897: 6.696771\n loss at epoch 0 step 898: 6.642287\n loss at epoch 0 step 899: 6.870078\n 2018-06-25 14:57:31.693334: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:31.761710: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:31.805339: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 900: 6.774796\n loss at epoch 0 step 901: 6.841524\n loss at epoch 0 step 902: 6.682564\n loss at epoch 0 step 903: 6.693571\n loss at epoch 0 step 904: 6.603614\n loss at epoch 0 step 905: 6.705801\n loss at epoch 0 step 906: 6.713558\n loss at epoch 0 step 907: 6.889330\n 2018-06-25 14:57:33.459800: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:33.528563: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:33.573187: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 908: 6.726191\n loss at epoch 0 step 909: 6.945642\n loss at epoch 0 step 910: 6.768640\n loss at epoch 0 step 911: 6.801554\n loss at epoch 0 step 912: 6.867862\n loss at epoch 0 step 913: 6.563491\n loss at epoch 0 step 914: 6.853379\n loss at epoch 0 step 915: 6.724048\n 2018-06-25 14:57:35.341966: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:35.412082: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:35.456774: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 916: 6.639415\n loss at epoch 0 step 917: 6.881902\n loss at epoch 0 step 918: 6.735335\n loss at epoch 0 step 919: 6.688423\n loss at epoch 0 step 920: 6.636367\n loss at epoch 0 step 921: 6.717305\n loss at epoch 0 step 922: 6.629582\n 2018-06-25 14:57:36.960963: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:37.033898: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:37.079990: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 923: 6.682681\n loss at epoch 0 step 924: 6.882014\n loss at epoch 0 step 925: 6.731138\n loss at epoch 0 step 926: 6.588252\n loss at epoch 0 step 927: 6.824276\n loss at epoch 0 step 928: 6.707603\n loss at epoch 0 step 929: 6.748030\n 2018-06-25 14:57:38.690123: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:38.767782: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:38.816409: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 930: 6.658401\n loss at epoch 0 step 931: 6.748807\n loss at epoch 0 step 932: 6.802845\n loss at epoch 0 step 933: 6.590845\n loss at epoch 0 step 934: 6.749659\n loss at epoch 0 step 935: 6.701960\n 2018-06-25 14:57:40.158598: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:40.234263: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:40.282647: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 936: 6.775355\n loss at epoch 0 step 937: 6.781133\n loss at epoch 0 step 938: 6.600548\n loss at epoch 0 step 939: 6.747424\n loss at epoch 0 step 940: 6.605201\n 2018-06-25 14:57:41.416798: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:41.496970: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:41.550523: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 941: 6.672260\n loss at epoch 0 step 942: 6.614303\n loss at epoch 0 step 943: 6.726663\n loss at epoch 0 step 944: 6.694652\n loss at epoch 0 step 945: 6.590765\n 2018-06-25 14:57:42.720835: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:42.800870: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:42.852718: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 946: 6.639668\n loss at epoch 0 step 947: 6.581154\n loss at epoch 0 step 948: 6.780156\n loss at epoch 0 step 949: 6.619957\n loss at epoch 0 step 950: 6.680293\n 2018-06-25 14:57:44.034047: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:44.116253: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:44.167625: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 951: 6.767905\n loss at epoch 0 step 952: 6.694592\n loss at epoch 0 step 953: 6.586446\n loss at epoch 0 step 954: 6.691846\n 2018-06-25 14:57:45.122539: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:45.204973: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:45.258423: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 955: 6.994371\n loss at epoch 0 step 956: 6.858140\n loss at epoch 0 step 957: 6.646007\n loss at epoch 0 step 958: 6.721205\n 2018-06-25 14:57:46.238911: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:46.325236: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:46.380011: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 959: 6.589066\n loss at epoch 0 step 960: 6.683684\n loss at epoch 0 step 961: 6.672047\n 2018-06-25 14:57:47.046723: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:47.203337: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:47.260355: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 962: 6.725653\n loss at epoch 0 step 963: 6.720684\n loss at epoch 0 step 964: 6.636925\n 2018-06-25 14:57:47.932850: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:48.021669: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:48.077942: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 965: 6.461943\n loss at epoch 0 step 966: 6.716685\n loss at epoch 0 step 967: 6.541767\n 2018-06-25 14:57:48.839285: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:58.895255: W\n tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc)\n ran out of memory trying to allocate 90.19MiB. Current allocation summary\n follows.\n 2018-06-25 14:57:58.895406: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256): Total\n Chunks: 3, Chunks in use: 3. 768B allocated for chunks. 768B in use in bin.\n 12B client-requested in use in bin.\n 2018-06-25 14:57:58.895440: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512): Total\n Chunks: 17, Chunks in use: 16. 8.5KiB allocated for chunks. 8.0KiB in use\n in bin. 8.0KiB client-requested in use in bin.\n 2018-06-25 14:57:58.895466: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024): Total\n Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in\n bin. 1.0KiB client-requested in use in bin.\n 2018-06-25 14:57:58.895488: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048): Total\n Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n client-requested in use in bin.\n 2018-06-25 14:57:58.895517: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096): Total\n Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n client-requested in use in bin.\n 2018-06-25 14:57:58.895538: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192): Total\n Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n client-requested in use in bin.\n 2018-06-25 14:57:58.895565: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384): Total\n Chunks: 5, Chunks in use: 3. 124.0KiB allocated for chunks. 79.0KiB in use\n in bin. 78.9KiB client-requested in use in bin.\n 2018-06-25 14:57:58.895592: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768): Total\n Chunks: 903, Chunks in use: 901. 28.30MiB allocated for chunks. 28.24MiB in\n use in bin. 28.15MiB client-requested in use in bin.\n 2018-06-25 14:57:58.895618: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536): Total\n Chunks: 402, Chunks in use: 402. 25.56MiB allocated for chunks. 25.56MiB in\n use in bin. 25.16MiB client-requested in use in bin.\n 2018-06-25 14:57:58.895639: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072): Total\n Chunks: 19, Chunks in use: 19. 2.51MiB allocated for chunks. 2.51MiB in use\n in bin. 2.47MiB client-requested in use in bin.\n 2018-06-25 14:57:58.895673: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144): Total\n Chunks: 8, Chunks in use: 8. 2.97MiB allocated for chunks. 2.97MiB in use\n in bin. 2.75MiB client-requested in use in bin.\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"334793888\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/20218\" href=\"https://github.com/tensorflow/tensorflow/issues/20218#issuecomment-399873140\">#20218 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAATxbOLEdJJdr-VX_sTRU0d_OFNXawVks5uAKFUgaJpZM4UzWuc\">https://github.com/notifications/unsubscribe-auth/AAATxbOLEdJJdr-VX_sTRU0d_OFNXawVks5uAKFUgaJpZM4UzWuc</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \n - Alex</div>\n</div>", "body_text": "Very interesting. So this is not a straightforward leak of tf variables.\n\u2026\nOn Mon, Jun 25, 2018 at 1:37 AM jaye ***@***.***> wrote:\n Hi alextp, thank you very much for you helping. The following is the code\n of part of my model:\n\n `import tensorflow as tf\n import tensorflow.contrib.eager as tfe\n import numpy as np\n\n class Model():\n def *init*(self,params,vocab_size):\n\n     # Hy-parameters\n     self.vocab_size = vocab_size\n     self.embedding_dim = params.embedding_dim\n     self.hidden_dim = params.hidden_dim\n     self.num_layers = params.num_layers\n     self.keep_ratio = params.keep_ratio\n     self.time_major = params.time_major\n\n     # Embeddings\n     self.embedding = Embedding(self.vocab_size,self.embedding_dim,self.time_major)\n\n     # Dynamic RNN\n     self.rnn = RNN(self.hidden_dim, self.embedding_dim,self.num_layers,\n                            self.keep_ratio,self.time_major, name='Forward')\n\n\n     # Fully Connections Layer\n     self.fc = FC(self.embedding_dim,self.vocab_size,self.time_major)\n\n     # Build all trainable variables\n     self.build()\n\n     # Add saver\n     self.saver = tfe.Saver(self.variables)\n\n def build(self):\n     # initialize trainable variables\n     self.variables = []\n\n     self.variables.append(self.embedding.embedding)\n     for variable in self.rnn.variables:\n         self.variables.append(variable)\n     self.variables.append(self.fc.weights)\n     self.variables.append(self.fc.bias)\n\n def __call__(self,inputs,training):\n     # Parallel computing\n     if self.time_major:\n         inputs = tf.transpose(inputs,(1,0))\n     # Get word embeddings for all\n     embed = self.embedding(inputs)\n     # moving\n     rnn_outputs = self.rnn(embed,training=training)\n\n     # Fully connections\n     logits = self.fc(rnn_outputs)\n     if self.time_major:\n         seq_len,batch_size,last_dim=logits.shape.as_list()\n         logits = tf.reshape(logits,(batch_size,seq_len,-1))\n\n     return logits\n\n class Embedding():\n # Embedding with different lengths.\n def *init*(self, vocab_size, embedding_dim,time_major=True):\n self.vocab_size = vocab_size\n self.embedding_dim = embedding_dim\n self.time_major = time_major\n\n     self.embedding = tfe.Variable(initial_value=tf.random_normal(shape=(vocab_size,embedding_dim)),\n                                   dtype=tf.float32,name='embedding',trainable=True)\n\n def __call__(self, x):\n     # implement word embedding\n     # whether parallel computing\n     if self.time_major:\n         #all_embedded=tf.nn.embedding_lookup(self.embedding,x)\n         seq_len, batch_size = x.shape.as_list()\n         x = tf.one_hot(x, depth=self.vocab_size)\n         flat_x = tf.reshape(x, shape=(-1,self.vocab_size))\n         all_embedded = tf.matmul(flat_x,self.embedding)\n         all_embedded = tf.reshape(all_embedded,(seq_len,batch_size,-1))\n     else:\n         all_embedded = []\n         for seq in x:\n           #embedded = tf.nn.embedding_lookup(self.embedding,seq)\n           seq = tf.one_hot(seq, depth=self.vocab_size)\n           embedded = tf.matmul(seq, self.embedding)\n           all_embedded.append(embedded)\n\n     return all_embedded\n\n class LSTMCell():\n def *init*(self,inputs_dim, hidden_dim, name):\n\n     self.inputs_dim = inputs_dim\n     self.hidden_dim = hidden_dim\n\n     with tf.name_scope(name=name):\n         # Forget gate\n         self.W_f = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n                                 dtype=tf.float32, name='forget_weights', trainable=True)\n         self.b_f = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n                                 dtype=tf.float32, name='forget_bias', trainable=True)\n         # Input gate\n         self.W_i = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n                                 dtype=tf.float32, name='input_weights', trainable=True)\n         self.b_i = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n                                 dtype=tf.float32, name='input_bias', trainable=True)\n         self.W_c = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n                                 dtype=tf.float32, name='input_filter_weights', trainable=True)\n         self.b_c = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n                                 dtype=tf.float32, name='input_filter_bias', trainable=True)\n         # Output gate\n         self.W_o = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n                                 dtype=tf.float32, name='output_weights', trainable=True)\n         self.b_o = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n                                 dtype=tf.float32, name='output_bias', trainable=True)\n\n         self.build()\n\n def build(self,):\n     # build all variables\n     self.variables = [self.W_f, self.b_f,self.W_i, self.b_i,\n                       self.W_c, self.b_c,self.W_o, self.b_o]\n\n def zero_state(self,batch_size):\n     c_t = tf.zeros(shape=(batch_size,self.hidden_dim),name='c_t')\n     h_t = tf.zeros(shape=(batch_size,self.hidden_dim),name='h_t')\n     return c_t, h_t\n\n def __call__(self,x_t,c_t,h_t):\n     # Define LSTM forward propagation\n\n     # Forget\n     f_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_f,self.b_f),name='Forget_Gate')\n     # Input\n     i_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_i,self.b_i),name='Input_Gate')\n     uc_t=tf.tanh(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_c,self.b_c),name='Input_Filter')\n     # Update Cell State\n     c_t = f_t*c_t + i_t*uc_t\n     # Output\n     o_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_o,self.b_o),name='Output_Gate')\n     h_t = o_t * tf.tanh(c_t)\n\n     return o_t,c_t,h_t\n\n class RNN():\n # A static RNN. Similar to tf.nn.static_rnn, implemented as a class.\n def *init*(self, hidden_dim,inputs_dim, num_layers,\n keep_ratio,time_major=True,name=''):\n self.keep_ratio = keep_ratio\n self.time_major = time_major\n self.inputs_dim=inputs_dim\n self.hidden_dim=hidden_dim\n\n     self.cells = [\n         LSTMCell(inputs_dim,hidden_dim,name=name+'_LSTMCell'+str(idx))\n         for idx in range(num_layers)\n     ]\n\n     self.build()\n\n def build(self):\n     # build all trainable variables\n     self.variables = []\n\n     for cell in self.cells:\n         for variable in cell.variables:\n             self.variables.append(variable)\n\n\n def __call__(self, inputs_seq, training=False):\n     # rnn with different length sequences, inputs : [batch, (embedded tensor)]\n\n     # parallel computing\n     if self.time_major:\n         seq_len,batch_size,last_dim = inputs_seq.shape.as_list()\n         for cell in self.cells:\n             c_t, h_t = cell.zero_state(batch_size)\n             outputs = []\n             for inp in inputs_seq:\n                 output, c_t, h_t = cell(inp, c_t, h_t)\n                 outputs.append(output)\n\n             inputs_seq = tf.stack(outputs, axis=0)\n             if training:\n                 inputs_seq = tf.nn.dropout(inputs_seq, self.keep_ratio)\n         batch_outputs = inputs_seq\n     # linear computing\n     else:\n         for cell in self.cells:\n             c_t,h_t = cell.zero_state(1)\n             outputs = []\n             for seq in inputs_seq:\n                 seq_outputs = []\n                 for word in seq:\n                     word = tf.reshape(word,(1,-1))\n                     output, c_t,h_t = cell(word, c_t,h_t)\n                     if training:\n                         output = tf.nn.dropout(output, self.keep_ratio)\n                     seq_outputs.append(output)\n                 outputs.append(seq_outputs)\n             inputs_seq = outputs\n         batch_outputs = inputs_seq\n     return batch_outputs\n\n class FC():\n # A Fully Connection Layer.\n def *init*(self, inputs_dim,\n outputs_dim,time_major=True,active=tf.nn.relu,name=None):\n self.inputs_dim = inputs_dim\n self.outputs_dim= outputs_dim\n self.time_major = time_major\n self.active = active\n\n     # Build trainable variables\n     self.weights = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim,outputs_dim)),\n                               dtype=tf.float32,name=name,trainable=True)\n     self.bias = tfe.Variable(initial_value=tf.random_normal(shape=(outputs_dim,)),\n                               dtype=tf.float32,name=name,trainable=True)\n\n def __call__(self, x):\n     # different length sequences, inputs : [batch, (RNN outputs tensor)]\n     # whether to parallel computing\n     if self.time_major:\n         seq_len,batch_size,last_dim = x.shape.as_list()\n         # flatten\n         flat = tf.reshape(x,(-1,last_dim))\n         fc = tf.nn.xw_plus_b(flat,self.weights,self.bias)\n         outputs = self.active(fc)\n         outputs = tf.reshape(outputs,(seq_len,batch_size,-1))\n     else:\n         outputs = []\n         for seq in x:\n             fc = tf.nn.xw_plus_b(seq, self.weights, self.bias)\n             fc = self.active(fc)\n             outputs.append(fc)\n     return outputs\n\n `\n\n Part of the training code is as follows:\n\n with tf.GradientTape() as tape: logits =\n model(batch_forward,batch_backward,training=True) loss =\n training_helper.loss_fn_time_major(batch_labels,logits,batch_lengths) # add\n loss summary tf.contrib.summary.scalar('loss', loss) grads =\n tape.gradient(loss, model.variables)\n optimizer.apply_gradients(zip(grads,model.variables)) print('loss at epoch\n %d step %d: %f' % (epoch,train_step,loss))\n\n I used your recommended settings turning log_device_placement=True, then I\n observed an interesting phenomenon. At every certain training step, there\n are three operation logs that are cycled, and the interval between the\n training steps is gradually decreasing.\n The following is the log after the setting log_device_placement=True is\n turned on. It can be seen, at the beginning, a log of three operations is\n printed every 16 training steps. As the training process progresses, a log\n of three operations is printed every three training steps until the OOM\n problem happened. I don't know why and what these three operations\n represent respectively. I hope this information will help solve the\n problem. Thank you again for your reply.\n some logs\n\n loss at epoch 0 step 805: 6.740626\n loss at epoch 0 step 806: 7.095036\n loss at epoch 0 step 807: 7.000319\n loss at epoch 0 step 808: 6.904347\n loss at epoch 0 step 809: 6.922751\n loss at epoch 0 step 810: 6.838681\n loss at epoch 0 step 811: 6.905680\n loss at epoch 0 step 812: 7.053514\n loss at epoch 0 step 813: 6.855484\n loss at epoch 0 step 814: 6.755508\n loss at epoch 0 step 815: 7.050679\n loss at epoch 0 step 816: 7.023479\n loss at epoch 0 step 817: 6.827959\n loss at epoch 0 step 818: 6.776998\n loss at epoch 0 step 819: 6.765797\n loss at epoch 0 step 820: 6.759283\n 2018-06-25 14:57:15.878743: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:15.935075: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:15.970760: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 821: 6.984869\n loss at epoch 0 step 822: 6.748662\n loss at epoch 0 step 823: 6.772003\n loss at epoch 0 step 824: 6.942709\n loss at epoch 0 step 825: 6.892979\n loss at epoch 0 step 826: 6.680350\n loss at epoch 0 step 827: 6.867269\n loss at epoch 0 step 828: 7.118308\n loss at epoch 0 step 829: 6.601588\n loss at epoch 0 step 830: 6.652170\n loss at epoch 0 step 831: 7.263901\n loss at epoch 0 step 832: 6.902826\n loss at epoch 0 step 833: 6.791662\n loss at epoch 0 step 834: 7.087551\n loss at epoch 0 step 835: 6.820101\n 2018-06-25 14:57:18.650329: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:18.710324: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:18.746490: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 836: 7.031796\n loss at epoch 0 step 837: 6.905032\n loss at epoch 0 step 838: 6.889287\n loss at epoch 0 step 839: 6.732944\n loss at epoch 0 step 840: 6.715842\n loss at epoch 0 step 841: 6.757300\n loss at epoch 0 step 842: 6.882929\n loss at epoch 0 step 843: 6.658679\n loss at epoch 0 step 844: 6.788300\n loss at epoch 0 step 845: 6.952966\n loss at epoch 0 step 846: 7.061527\n loss at epoch 0 step 847: 6.603632\n loss at epoch 0 step 848: 7.163596\n loss at epoch 0 step 849: 7.038760\n 2018-06-25 14:57:21.325933: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:21.386127: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:21.423910: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 850: 6.885034\n loss at epoch 0 step 851: 6.931499\n loss at epoch 0 step 852: 6.713628\n loss at epoch 0 step 853: 6.777599\n loss at epoch 0 step 854: 6.799969\n loss at epoch 0 step 855: 6.985339\n loss at epoch 0 step 856: 6.620006\n loss at epoch 0 step 857: 6.878152\n loss at epoch 0 step 858: 6.783222\n loss at epoch 0 step 859: 6.712417\n loss at epoch 0 step 860: 6.734530\n loss at epoch 0 step 861: 7.009552\n 2018-06-25 14:57:23.706079: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:23.769647: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:23.809172: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 862: 6.570765\n loss at epoch 0 step 863: 6.818643\n loss at epoch 0 step 864: 6.707229\n loss at epoch 0 step 865: 6.860226\n loss at epoch 0 step 866: 6.832708\n loss at epoch 0 step 867: 6.746671\n loss at epoch 0 step 868: 6.925843\n loss at epoch 0 step 869: 6.845281\n loss at epoch 0 step 870: 6.901897\n loss at epoch 0 step 871: 6.936728\n loss at epoch 0 step 872: 6.793565\n 2018-06-25 14:57:25.894904: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:25.958699: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:25.998658: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 873: 6.795174\n loss at epoch 0 step 874: 6.897914\n loss at epoch 0 step 875: 6.964663\n loss at epoch 0 step 876: 6.933444\n loss at epoch 0 step 877: 6.889087\n loss at epoch 0 step 878: 6.728238\n loss at epoch 0 step 879: 6.543335\n loss at epoch 0 step 880: 6.785100\n loss at epoch 0 step 881: 6.867868\n loss at epoch 0 step 882: 6.626728\n 2018-06-25 14:57:28.011803: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:28.078783: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:28.121272: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 883: 6.632171\n loss at epoch 0 step 884: 6.638273\n loss at epoch 0 step 885: 6.727106\n loss at epoch 0 step 886: 6.755214\n loss at epoch 0 step 887: 6.788674\n loss at epoch 0 step 888: 6.618323\n loss at epoch 0 step 889: 6.802135\n loss at epoch 0 step 890: 6.812809\n loss at epoch 0 step 891: 6.905511\n 2018-06-25 14:57:29.982565: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:30.048872: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:30.089943: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 892: 6.660409\n loss at epoch 0 step 893: 6.817567\n loss at epoch 0 step 894: 6.782594\n loss at epoch 0 step 895: 6.746886\n loss at epoch 0 step 896: 6.679479\n loss at epoch 0 step 897: 6.696771\n loss at epoch 0 step 898: 6.642287\n loss at epoch 0 step 899: 6.870078\n 2018-06-25 14:57:31.693334: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:31.761710: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:31.805339: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 900: 6.774796\n loss at epoch 0 step 901: 6.841524\n loss at epoch 0 step 902: 6.682564\n loss at epoch 0 step 903: 6.693571\n loss at epoch 0 step 904: 6.603614\n loss at epoch 0 step 905: 6.705801\n loss at epoch 0 step 906: 6.713558\n loss at epoch 0 step 907: 6.889330\n 2018-06-25 14:57:33.459800: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:33.528563: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:33.573187: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 908: 6.726191\n loss at epoch 0 step 909: 6.945642\n loss at epoch 0 step 910: 6.768640\n loss at epoch 0 step 911: 6.801554\n loss at epoch 0 step 912: 6.867862\n loss at epoch 0 step 913: 6.563491\n loss at epoch 0 step 914: 6.853379\n loss at epoch 0 step 915: 6.724048\n 2018-06-25 14:57:35.341966: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:35.412082: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:35.456774: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 916: 6.639415\n loss at epoch 0 step 917: 6.881902\n loss at epoch 0 step 918: 6.735335\n loss at epoch 0 step 919: 6.688423\n loss at epoch 0 step 920: 6.636367\n loss at epoch 0 step 921: 6.717305\n loss at epoch 0 step 922: 6.629582\n 2018-06-25 14:57:36.960963: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:37.033898: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:37.079990: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 923: 6.682681\n loss at epoch 0 step 924: 6.882014\n loss at epoch 0 step 925: 6.731138\n loss at epoch 0 step 926: 6.588252\n loss at epoch 0 step 927: 6.824276\n loss at epoch 0 step 928: 6.707603\n loss at epoch 0 step 929: 6.748030\n 2018-06-25 14:57:38.690123: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:38.767782: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:38.816409: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 930: 6.658401\n loss at epoch 0 step 931: 6.748807\n loss at epoch 0 step 932: 6.802845\n loss at epoch 0 step 933: 6.590845\n loss at epoch 0 step 934: 6.749659\n loss at epoch 0 step 935: 6.701960\n 2018-06-25 14:57:40.158598: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:40.234263: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:40.282647: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 936: 6.775355\n loss at epoch 0 step 937: 6.781133\n loss at epoch 0 step 938: 6.600548\n loss at epoch 0 step 939: 6.747424\n loss at epoch 0 step 940: 6.605201\n 2018-06-25 14:57:41.416798: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:41.496970: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:41.550523: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 941: 6.672260\n loss at epoch 0 step 942: 6.614303\n loss at epoch 0 step 943: 6.726663\n loss at epoch 0 step 944: 6.694652\n loss at epoch 0 step 945: 6.590765\n 2018-06-25 14:57:42.720835: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:42.800870: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:42.852718: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 946: 6.639668\n loss at epoch 0 step 947: 6.581154\n loss at epoch 0 step 948: 6.780156\n loss at epoch 0 step 949: 6.619957\n loss at epoch 0 step 950: 6.680293\n 2018-06-25 14:57:44.034047: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:44.116253: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:44.167625: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 951: 6.767905\n loss at epoch 0 step 952: 6.694592\n loss at epoch 0 step 953: 6.586446\n loss at epoch 0 step 954: 6.691846\n 2018-06-25 14:57:45.122539: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:45.204973: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:45.258423: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 955: 6.994371\n loss at epoch 0 step 956: 6.858140\n loss at epoch 0 step 957: 6.646007\n loss at epoch 0 step 958: 6.721205\n 2018-06-25 14:57:46.238911: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:46.325236: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:46.380011: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 959: 6.589066\n loss at epoch 0 step 960: 6.683684\n loss at epoch 0 step 961: 6.672047\n 2018-06-25 14:57:47.046723: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:47.203337: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:47.260355: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 962: 6.725653\n loss at epoch 0 step 963: 6.720684\n loss at epoch 0 step 964: 6.636925\n 2018-06-25 14:57:47.932850: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:48.021669: I tensorflow/c/eager/c_api.cc:856] Executing\n op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:48.077942: I tensorflow/c/eager/c_api.cc:856] Executing\n op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n loss at epoch 0 step 965: 6.461943\n loss at epoch 0 step 966: 6.716685\n loss at epoch 0 step 967: 6.541767\n 2018-06-25 14:57:48.839285: I tensorflow/c/eager/c_api.cc:856] Executing\n op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n 2018-06-25 14:57:58.895255: W\n tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc)\n ran out of memory trying to allocate 90.19MiB. Current allocation summary\n follows.\n 2018-06-25 14:57:58.895406: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256): Total\n Chunks: 3, Chunks in use: 3. 768B allocated for chunks. 768B in use in bin.\n 12B client-requested in use in bin.\n 2018-06-25 14:57:58.895440: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512): Total\n Chunks: 17, Chunks in use: 16. 8.5KiB allocated for chunks. 8.0KiB in use\n in bin. 8.0KiB client-requested in use in bin.\n 2018-06-25 14:57:58.895466: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024): Total\n Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in\n bin. 1.0KiB client-requested in use in bin.\n 2018-06-25 14:57:58.895488: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048): Total\n Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n client-requested in use in bin.\n 2018-06-25 14:57:58.895517: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096): Total\n Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n client-requested in use in bin.\n 2018-06-25 14:57:58.895538: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192): Total\n Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n client-requested in use in bin.\n 2018-06-25 14:57:58.895565: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384): Total\n Chunks: 5, Chunks in use: 3. 124.0KiB allocated for chunks. 79.0KiB in use\n in bin. 78.9KiB client-requested in use in bin.\n 2018-06-25 14:57:58.895592: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768): Total\n Chunks: 903, Chunks in use: 901. 28.30MiB allocated for chunks. 28.24MiB in\n use in bin. 28.15MiB client-requested in use in bin.\n 2018-06-25 14:57:58.895618: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536): Total\n Chunks: 402, Chunks in use: 402. 25.56MiB allocated for chunks. 25.56MiB in\n use in bin. 25.16MiB client-requested in use in bin.\n 2018-06-25 14:57:58.895639: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072): Total\n Chunks: 19, Chunks in use: 19. 2.51MiB allocated for chunks. 2.51MiB in use\n in bin. 2.47MiB client-requested in use in bin.\n 2018-06-25 14:57:58.895673: I\n tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144): Total\n Chunks: 8, Chunks in use: 8. 2.97MiB allocated for chunks. 2.97MiB in use\n in bin. 2.75MiB client-requested in use in bin.\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n <#20218 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AAATxbOLEdJJdr-VX_sTRU0d_OFNXawVks5uAKFUgaJpZM4UzWuc>\n .\n\n\n-- \n - Alex", "body": "Very interesting. So this is not a straightforward leak of tf variables.\n\nOn Mon, Jun 25, 2018 at 1:37 AM jaye <notifications@github.com> wrote:\n\n> Hi alextp, thank you very much for you helping. The following is the code\n> of part of my model:\n>\n> `import tensorflow as tf\n> import tensorflow.contrib.eager as tfe\n> import numpy as np\n>\n> class Model():\n> def *init*(self,params,vocab_size):\n>\n>     # Hy-parameters\n>     self.vocab_size = vocab_size\n>     self.embedding_dim = params.embedding_dim\n>     self.hidden_dim = params.hidden_dim\n>     self.num_layers = params.num_layers\n>     self.keep_ratio = params.keep_ratio\n>     self.time_major = params.time_major\n>\n>     # Embeddings\n>     self.embedding = Embedding(self.vocab_size,self.embedding_dim,self.time_major)\n>\n>     # Dynamic RNN\n>     self.rnn = RNN(self.hidden_dim, self.embedding_dim,self.num_layers,\n>                            self.keep_ratio,self.time_major, name='Forward')\n>\n>\n>     # Fully Connections Layer\n>     self.fc = FC(self.embedding_dim,self.vocab_size,self.time_major)\n>\n>     # Build all trainable variables\n>     self.build()\n>\n>     # Add saver\n>     self.saver = tfe.Saver(self.variables)\n>\n> def build(self):\n>     # initialize trainable variables\n>     self.variables = []\n>\n>     self.variables.append(self.embedding.embedding)\n>     for variable in self.rnn.variables:\n>         self.variables.append(variable)\n>     self.variables.append(self.fc.weights)\n>     self.variables.append(self.fc.bias)\n>\n> def __call__(self,inputs,training):\n>     # Parallel computing\n>     if self.time_major:\n>         inputs = tf.transpose(inputs,(1,0))\n>     # Get word embeddings for all\n>     embed = self.embedding(inputs)\n>     # moving\n>     rnn_outputs = self.rnn(embed,training=training)\n>\n>     # Fully connections\n>     logits = self.fc(rnn_outputs)\n>     if self.time_major:\n>         seq_len,batch_size,last_dim=logits.shape.as_list()\n>         logits = tf.reshape(logits,(batch_size,seq_len,-1))\n>\n>     return logits\n>\n> class Embedding():\n> # Embedding with different lengths.\n> def *init*(self, vocab_size, embedding_dim,time_major=True):\n> self.vocab_size = vocab_size\n> self.embedding_dim = embedding_dim\n> self.time_major = time_major\n>\n>     self.embedding = tfe.Variable(initial_value=tf.random_normal(shape=(vocab_size,embedding_dim)),\n>                                   dtype=tf.float32,name='embedding',trainable=True)\n>\n> def __call__(self, x):\n>     # implement word embedding\n>     # whether parallel computing\n>     if self.time_major:\n>         #all_embedded=tf.nn.embedding_lookup(self.embedding,x)\n>         seq_len, batch_size = x.shape.as_list()\n>         x = tf.one_hot(x, depth=self.vocab_size)\n>         flat_x = tf.reshape(x, shape=(-1,self.vocab_size))\n>         all_embedded = tf.matmul(flat_x,self.embedding)\n>         all_embedded = tf.reshape(all_embedded,(seq_len,batch_size,-1))\n>     else:\n>         all_embedded = []\n>         for seq in x:\n>           #embedded = tf.nn.embedding_lookup(self.embedding,seq)\n>           seq = tf.one_hot(seq, depth=self.vocab_size)\n>           embedded = tf.matmul(seq, self.embedding)\n>           all_embedded.append(embedded)\n>\n>     return all_embedded\n>\n> class LSTMCell():\n> def *init*(self,inputs_dim, hidden_dim, name):\n>\n>     self.inputs_dim = inputs_dim\n>     self.hidden_dim = hidden_dim\n>\n>     with tf.name_scope(name=name):\n>         # Forget gate\n>         self.W_f = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n>                                 dtype=tf.float32, name='forget_weights', trainable=True)\n>         self.b_f = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n>                                 dtype=tf.float32, name='forget_bias', trainable=True)\n>         # Input gate\n>         self.W_i = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n>                                 dtype=tf.float32, name='input_weights', trainable=True)\n>         self.b_i = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n>                                 dtype=tf.float32, name='input_bias', trainable=True)\n>         self.W_c = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n>                                 dtype=tf.float32, name='input_filter_weights', trainable=True)\n>         self.b_c = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n>                                 dtype=tf.float32, name='input_filter_bias', trainable=True)\n>         # Output gate\n>         self.W_o = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim + hidden_dim, hidden_dim)),\n>                                 dtype=tf.float32, name='output_weights', trainable=True)\n>         self.b_o = tfe.Variable(initial_value=tf.random_normal(shape=(hidden_dim,)),\n>                                 dtype=tf.float32, name='output_bias', trainable=True)\n>\n>         self.build()\n>\n> def build(self,):\n>     # build all variables\n>     self.variables = [self.W_f, self.b_f,self.W_i, self.b_i,\n>                       self.W_c, self.b_c,self.W_o, self.b_o]\n>\n> def zero_state(self,batch_size):\n>     c_t = tf.zeros(shape=(batch_size,self.hidden_dim),name='c_t')\n>     h_t = tf.zeros(shape=(batch_size,self.hidden_dim),name='h_t')\n>     return c_t, h_t\n>\n> def __call__(self,x_t,c_t,h_t):\n>     # Define LSTM forward propagation\n>\n>     # Forget\n>     f_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_f,self.b_f),name='Forget_Gate')\n>     # Input\n>     i_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_i,self.b_i),name='Input_Gate')\n>     uc_t=tf.tanh(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_c,self.b_c),name='Input_Filter')\n>     # Update Cell State\n>     c_t = f_t*c_t + i_t*uc_t\n>     # Output\n>     o_t=tf.sigmoid(tf.nn.xw_plus_b(tf.concat((h_t,x_t),-1),self.W_o,self.b_o),name='Output_Gate')\n>     h_t = o_t * tf.tanh(c_t)\n>\n>     return o_t,c_t,h_t\n>\n> class RNN():\n> # A static RNN. Similar to tf.nn.static_rnn, implemented as a class.\n> def *init*(self, hidden_dim,inputs_dim, num_layers,\n> keep_ratio,time_major=True,name=''):\n> self.keep_ratio = keep_ratio\n> self.time_major = time_major\n> self.inputs_dim=inputs_dim\n> self.hidden_dim=hidden_dim\n>\n>     self.cells = [\n>         LSTMCell(inputs_dim,hidden_dim,name=name+'_LSTMCell'+str(idx))\n>         for idx in range(num_layers)\n>     ]\n>\n>     self.build()\n>\n> def build(self):\n>     # build all trainable variables\n>     self.variables = []\n>\n>     for cell in self.cells:\n>         for variable in cell.variables:\n>             self.variables.append(variable)\n>\n>\n> def __call__(self, inputs_seq, training=False):\n>     # rnn with different length sequences, inputs : [batch, (embedded tensor)]\n>\n>     # parallel computing\n>     if self.time_major:\n>         seq_len,batch_size,last_dim = inputs_seq.shape.as_list()\n>         for cell in self.cells:\n>             c_t, h_t = cell.zero_state(batch_size)\n>             outputs = []\n>             for inp in inputs_seq:\n>                 output, c_t, h_t = cell(inp, c_t, h_t)\n>                 outputs.append(output)\n>\n>             inputs_seq = tf.stack(outputs, axis=0)\n>             if training:\n>                 inputs_seq = tf.nn.dropout(inputs_seq, self.keep_ratio)\n>         batch_outputs = inputs_seq\n>     # linear computing\n>     else:\n>         for cell in self.cells:\n>             c_t,h_t = cell.zero_state(1)\n>             outputs = []\n>             for seq in inputs_seq:\n>                 seq_outputs = []\n>                 for word in seq:\n>                     word = tf.reshape(word,(1,-1))\n>                     output, c_t,h_t = cell(word, c_t,h_t)\n>                     if training:\n>                         output = tf.nn.dropout(output, self.keep_ratio)\n>                     seq_outputs.append(output)\n>                 outputs.append(seq_outputs)\n>             inputs_seq = outputs\n>         batch_outputs = inputs_seq\n>     return batch_outputs\n>\n> class FC():\n> # A Fully Connection Layer.\n> def *init*(self, inputs_dim,\n> outputs_dim,time_major=True,active=tf.nn.relu,name=None):\n> self.inputs_dim = inputs_dim\n> self.outputs_dim= outputs_dim\n> self.time_major = time_major\n> self.active = active\n>\n>     # Build trainable variables\n>     self.weights = tfe.Variable(initial_value=tf.random_normal(shape=(inputs_dim,outputs_dim)),\n>                               dtype=tf.float32,name=name,trainable=True)\n>     self.bias = tfe.Variable(initial_value=tf.random_normal(shape=(outputs_dim,)),\n>                               dtype=tf.float32,name=name,trainable=True)\n>\n> def __call__(self, x):\n>     # different length sequences, inputs : [batch, (RNN outputs tensor)]\n>     # whether to parallel computing\n>     if self.time_major:\n>         seq_len,batch_size,last_dim = x.shape.as_list()\n>         # flatten\n>         flat = tf.reshape(x,(-1,last_dim))\n>         fc = tf.nn.xw_plus_b(flat,self.weights,self.bias)\n>         outputs = self.active(fc)\n>         outputs = tf.reshape(outputs,(seq_len,batch_size,-1))\n>     else:\n>         outputs = []\n>         for seq in x:\n>             fc = tf.nn.xw_plus_b(seq, self.weights, self.bias)\n>             fc = self.active(fc)\n>             outputs.append(fc)\n>     return outputs\n>\n> `\n>\n> Part of the training code is as follows:\n>\n> with tf.GradientTape() as tape: logits =\n> model(batch_forward,batch_backward,training=True) loss =\n> training_helper.loss_fn_time_major(batch_labels,logits,batch_lengths) # add\n> loss summary tf.contrib.summary.scalar('loss', loss) grads =\n> tape.gradient(loss, model.variables)\n> optimizer.apply_gradients(zip(grads,model.variables)) print('loss at epoch\n> %d step %d: %f' % (epoch,train_step,loss))\n>\n> I used your recommended settings turning log_device_placement=True, then I\n> observed an interesting phenomenon. At every certain training step, there\n> are three operation logs that are cycled, and the interval between the\n> training steps is gradually decreasing.\n> The following is the log after the setting log_device_placement=True is\n> turned on. It can be seen, at the beginning, a log of three operations is\n> printed every 16 training steps. As the training process progresses, a log\n> of three operations is printed every three training steps until the OOM\n> problem happened. I don't know why and what these three operations\n> represent respectively. I hope this information will help solve the\n> problem. Thank you again for your reply.\n> some logs\n>\n> loss at epoch 0 step 805: 6.740626\n> loss at epoch 0 step 806: 7.095036\n> loss at epoch 0 step 807: 7.000319\n> loss at epoch 0 step 808: 6.904347\n> loss at epoch 0 step 809: 6.922751\n> loss at epoch 0 step 810: 6.838681\n> loss at epoch 0 step 811: 6.905680\n> loss at epoch 0 step 812: 7.053514\n> loss at epoch 0 step 813: 6.855484\n> loss at epoch 0 step 814: 6.755508\n> loss at epoch 0 step 815: 7.050679\n> loss at epoch 0 step 816: 7.023479\n> loss at epoch 0 step 817: 6.827959\n> loss at epoch 0 step 818: 6.776998\n> loss at epoch 0 step 819: 6.765797\n> loss at epoch 0 step 820: 6.759283\n> 2018-06-25 14:57:15.878743: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:15.935075: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:15.970760: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 821: 6.984869\n> loss at epoch 0 step 822: 6.748662\n> loss at epoch 0 step 823: 6.772003\n> loss at epoch 0 step 824: 6.942709\n> loss at epoch 0 step 825: 6.892979\n> loss at epoch 0 step 826: 6.680350\n> loss at epoch 0 step 827: 6.867269\n> loss at epoch 0 step 828: 7.118308\n> loss at epoch 0 step 829: 6.601588\n> loss at epoch 0 step 830: 6.652170\n> loss at epoch 0 step 831: 7.263901\n> loss at epoch 0 step 832: 6.902826\n> loss at epoch 0 step 833: 6.791662\n> loss at epoch 0 step 834: 7.087551\n> loss at epoch 0 step 835: 6.820101\n> 2018-06-25 14:57:18.650329: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:18.710324: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:18.746490: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 836: 7.031796\n> loss at epoch 0 step 837: 6.905032\n> loss at epoch 0 step 838: 6.889287\n> loss at epoch 0 step 839: 6.732944\n> loss at epoch 0 step 840: 6.715842\n> loss at epoch 0 step 841: 6.757300\n> loss at epoch 0 step 842: 6.882929\n> loss at epoch 0 step 843: 6.658679\n> loss at epoch 0 step 844: 6.788300\n> loss at epoch 0 step 845: 6.952966\n> loss at epoch 0 step 846: 7.061527\n> loss at epoch 0 step 847: 6.603632\n> loss at epoch 0 step 848: 7.163596\n> loss at epoch 0 step 849: 7.038760\n> 2018-06-25 14:57:21.325933: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:21.386127: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:21.423910: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 850: 6.885034\n> loss at epoch 0 step 851: 6.931499\n> loss at epoch 0 step 852: 6.713628\n> loss at epoch 0 step 853: 6.777599\n> loss at epoch 0 step 854: 6.799969\n> loss at epoch 0 step 855: 6.985339\n> loss at epoch 0 step 856: 6.620006\n> loss at epoch 0 step 857: 6.878152\n> loss at epoch 0 step 858: 6.783222\n> loss at epoch 0 step 859: 6.712417\n> loss at epoch 0 step 860: 6.734530\n> loss at epoch 0 step 861: 7.009552\n> 2018-06-25 14:57:23.706079: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:23.769647: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:23.809172: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 862: 6.570765\n> loss at epoch 0 step 863: 6.818643\n> loss at epoch 0 step 864: 6.707229\n> loss at epoch 0 step 865: 6.860226\n> loss at epoch 0 step 866: 6.832708\n> loss at epoch 0 step 867: 6.746671\n> loss at epoch 0 step 868: 6.925843\n> loss at epoch 0 step 869: 6.845281\n> loss at epoch 0 step 870: 6.901897\n> loss at epoch 0 step 871: 6.936728\n> loss at epoch 0 step 872: 6.793565\n> 2018-06-25 14:57:25.894904: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:25.958699: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:25.998658: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 873: 6.795174\n> loss at epoch 0 step 874: 6.897914\n> loss at epoch 0 step 875: 6.964663\n> loss at epoch 0 step 876: 6.933444\n> loss at epoch 0 step 877: 6.889087\n> loss at epoch 0 step 878: 6.728238\n> loss at epoch 0 step 879: 6.543335\n> loss at epoch 0 step 880: 6.785100\n> loss at epoch 0 step 881: 6.867868\n> loss at epoch 0 step 882: 6.626728\n> 2018-06-25 14:57:28.011803: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:28.078783: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:28.121272: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 883: 6.632171\n> loss at epoch 0 step 884: 6.638273\n> loss at epoch 0 step 885: 6.727106\n> loss at epoch 0 step 886: 6.755214\n> loss at epoch 0 step 887: 6.788674\n> loss at epoch 0 step 888: 6.618323\n> loss at epoch 0 step 889: 6.802135\n> loss at epoch 0 step 890: 6.812809\n> loss at epoch 0 step 891: 6.905511\n> 2018-06-25 14:57:29.982565: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:30.048872: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:30.089943: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 892: 6.660409\n> loss at epoch 0 step 893: 6.817567\n> loss at epoch 0 step 894: 6.782594\n> loss at epoch 0 step 895: 6.746886\n> loss at epoch 0 step 896: 6.679479\n> loss at epoch 0 step 897: 6.696771\n> loss at epoch 0 step 898: 6.642287\n> loss at epoch 0 step 899: 6.870078\n> 2018-06-25 14:57:31.693334: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:31.761710: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:31.805339: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 900: 6.774796\n> loss at epoch 0 step 901: 6.841524\n> loss at epoch 0 step 902: 6.682564\n> loss at epoch 0 step 903: 6.693571\n> loss at epoch 0 step 904: 6.603614\n> loss at epoch 0 step 905: 6.705801\n> loss at epoch 0 step 906: 6.713558\n> loss at epoch 0 step 907: 6.889330\n> 2018-06-25 14:57:33.459800: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:33.528563: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:33.573187: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 908: 6.726191\n> loss at epoch 0 step 909: 6.945642\n> loss at epoch 0 step 910: 6.768640\n> loss at epoch 0 step 911: 6.801554\n> loss at epoch 0 step 912: 6.867862\n> loss at epoch 0 step 913: 6.563491\n> loss at epoch 0 step 914: 6.853379\n> loss at epoch 0 step 915: 6.724048\n> 2018-06-25 14:57:35.341966: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:35.412082: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:35.456774: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 916: 6.639415\n> loss at epoch 0 step 917: 6.881902\n> loss at epoch 0 step 918: 6.735335\n> loss at epoch 0 step 919: 6.688423\n> loss at epoch 0 step 920: 6.636367\n> loss at epoch 0 step 921: 6.717305\n> loss at epoch 0 step 922: 6.629582\n> 2018-06-25 14:57:36.960963: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:37.033898: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:37.079990: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 923: 6.682681\n> loss at epoch 0 step 924: 6.882014\n> loss at epoch 0 step 925: 6.731138\n> loss at epoch 0 step 926: 6.588252\n> loss at epoch 0 step 927: 6.824276\n> loss at epoch 0 step 928: 6.707603\n> loss at epoch 0 step 929: 6.748030\n> 2018-06-25 14:57:38.690123: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:38.767782: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:38.816409: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 930: 6.658401\n> loss at epoch 0 step 931: 6.748807\n> loss at epoch 0 step 932: 6.802845\n> loss at epoch 0 step 933: 6.590845\n> loss at epoch 0 step 934: 6.749659\n> loss at epoch 0 step 935: 6.701960\n> 2018-06-25 14:57:40.158598: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:40.234263: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:40.282647: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 936: 6.775355\n> loss at epoch 0 step 937: 6.781133\n> loss at epoch 0 step 938: 6.600548\n> loss at epoch 0 step 939: 6.747424\n> loss at epoch 0 step 940: 6.605201\n> 2018-06-25 14:57:41.416798: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:41.496970: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:41.550523: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 941: 6.672260\n> loss at epoch 0 step 942: 6.614303\n> loss at epoch 0 step 943: 6.726663\n> loss at epoch 0 step 944: 6.694652\n> loss at epoch 0 step 945: 6.590765\n> 2018-06-25 14:57:42.720835: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:42.800870: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:42.852718: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 946: 6.639668\n> loss at epoch 0 step 947: 6.581154\n> loss at epoch 0 step 948: 6.780156\n> loss at epoch 0 step 949: 6.619957\n> loss at epoch 0 step 950: 6.680293\n> 2018-06-25 14:57:44.034047: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:44.116253: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:44.167625: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 951: 6.767905\n> loss at epoch 0 step 952: 6.694592\n> loss at epoch 0 step 953: 6.586446\n> loss at epoch 0 step 954: 6.691846\n> 2018-06-25 14:57:45.122539: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:45.204973: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:45.258423: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 955: 6.994371\n> loss at epoch 0 step 956: 6.858140\n> loss at epoch 0 step 957: 6.646007\n> loss at epoch 0 step 958: 6.721205\n> 2018-06-25 14:57:46.238911: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:46.325236: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:46.380011: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 959: 6.589066\n> loss at epoch 0 step 960: 6.683684\n> loss at epoch 0 step 961: 6.672047\n> 2018-06-25 14:57:47.046723: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:47.203337: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:47.260355: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 962: 6.725653\n> loss at epoch 0 step 963: 6.720684\n> loss at epoch 0 step 964: 6.636925\n> 2018-06-25 14:57:47.932850: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:48.021669: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:48.077942: I tensorflow/c/eager/c_api.cc:856] Executing\n> op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n> loss at epoch 0 step 965: 6.461943\n> loss at epoch 0 step 966: 6.716685\n> loss at epoch 0 step 967: 6.541767\n> 2018-06-25 14:57:48.839285: I tensorflow/c/eager/c_api.cc:856] Executing\n> op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n> 2018-06-25 14:57:58.895255: W\n> tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc)\n> ran out of memory trying to allocate 90.19MiB. Current allocation summary\n> follows.\n> 2018-06-25 14:57:58.895406: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256): Total\n> Chunks: 3, Chunks in use: 3. 768B allocated for chunks. 768B in use in bin.\n> 12B client-requested in use in bin.\n> 2018-06-25 14:57:58.895440: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512): Total\n> Chunks: 17, Chunks in use: 16. 8.5KiB allocated for chunks. 8.0KiB in use\n> in bin. 8.0KiB client-requested in use in bin.\n> 2018-06-25 14:57:58.895466: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024): Total\n> Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in\n> bin. 1.0KiB client-requested in use in bin.\n> 2018-06-25 14:57:58.895488: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048): Total\n> Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n> client-requested in use in bin.\n> 2018-06-25 14:57:58.895517: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096): Total\n> Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n> client-requested in use in bin.\n> 2018-06-25 14:57:58.895538: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192): Total\n> Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B\n> client-requested in use in bin.\n> 2018-06-25 14:57:58.895565: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384): Total\n> Chunks: 5, Chunks in use: 3. 124.0KiB allocated for chunks. 79.0KiB in use\n> in bin. 78.9KiB client-requested in use in bin.\n> 2018-06-25 14:57:58.895592: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768): Total\n> Chunks: 903, Chunks in use: 901. 28.30MiB allocated for chunks. 28.24MiB in\n> use in bin. 28.15MiB client-requested in use in bin.\n> 2018-06-25 14:57:58.895618: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536): Total\n> Chunks: 402, Chunks in use: 402. 25.56MiB allocated for chunks. 25.56MiB in\n> use in bin. 25.16MiB client-requested in use in bin.\n> 2018-06-25 14:57:58.895639: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072): Total\n> Chunks: 19, Chunks in use: 19. 2.51MiB allocated for chunks. 2.51MiB in use\n> in bin. 2.47MiB client-requested in use in bin.\n> 2018-06-25 14:57:58.895673: I\n> tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144): Total\n> Chunks: 8, Chunks in use: 8. 2.97MiB allocated for chunks. 2.97MiB in use\n> in bin. 2.75MiB client-requested in use in bin.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/20218#issuecomment-399873140>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxbOLEdJJdr-VX_sTRU0d_OFNXawVks5uAKFUgaJpZM4UzWuc>\n> .\n>\n\n\n-- \n - Alex\n"}