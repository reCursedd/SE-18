{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/57333373", "pull_request_review_id": null, "id": 57333373, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMzMzcz", "diff_hunk": "@@ -0,0 +1,135 @@\n+#!/usr/bin/env bash\n+# Copyright 2016 Google Inc. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+#\n+# Runs benchmark tests.\n+# After the completion of each benchmark test, the script calls a hook binary,\n+# specified with the environment variable TF_BUILD_BENCHMARK_HOOK, to handle\n+# the test log file. This hook binary may perform operations such as entering\n+# the test results into a database.\n+#\n+# Usage: benchmark [-c opt]\n+# Option flags\n+#    -c opt:  Use optimized C++ build (\"-c opt\")\n+#\n+# This script obeys the following environmental variables:\n+#   TF_BUILD_BENCHMARK_HOOK:\n+#     Path to a binary / script that will handle the test log and other related\n+#     info after the completion of each benchmark test.\n+\n+echo \"\"\n+echo \"====== Benchmark tests start ======\"\n+\n+OPT_FLAG=\"\"\n+if [[ \"$1\" == \"-c\" ]] && [[ \"$2\" == \"opt\" ]]; then\n+  OPT_FLAG=\"${OPT_FLAG} -c opt\"\n+fi\n+\n+BENCHMARK_TESTS=$(bazel query \\\n+    'attr(\"tags\", \"benchmark-test\", //tensorflow/tools/test/...)')\n+\n+N_TESTS=$(echo ${BENCHMARK_TESTS} | wc -w)\n+\n+echo \"Discovered ${N_TESTS} benchmark test(s):\"\n+echo ${BENCHMARK_TESTS}\n+echo \"\"\n+\n+PASS_COUNTER=0\n+FAIL_COUNTER=0\n+FAILED_TESTS=\"\"\n+COUNTER=0\n+\n+for BENCHMARK_TEST in ${BENCHMARK_TESTS}; do\n+  ((COUNTER++))\n+\n+  echo \"\"\n+  echo \"Running benchmark test (${COUNTER} / ${N_TESTS}): ${BENCHMARK_TEST}\"\n+\n+  bazel test ${OPT_FLAG} --cache_test_results=no \"${BENCHMARK_TEST}\"\n+  TEST_RESULT=$?\n+\n+  # Hook for database\n+  # Verify that test log exists\n+  TEST_LOG=$(echo ${BENCHMARK_TEST} |  sed -e 's/:/\\//g')\n+  TEST_LOG=\"bazel-testlogs/${TEST_LOG}/test.log\"\n+  if [[ -f \"${TEST_LOG}\" ]]; then\n+    echo \"Benchmark ${BENCHMARK_TEST} done: log @ ${TEST_LOG}\"\n+\n+    # Call database hook if exists\n+    if [[ ! -z \"${TF_BUILD_BENCHMARK_HOOK}\" ]]; then\n+      # Assume that the hook binary/script takes two arguments:\n+      #   Argument 1: Compilation flags such as \"-c opt\" as a whole\n+      #   Argument 2: Test log containing the serialized TestResults proto\n+\n+      echo \"Calling database hook: ${TF_BUILD_BENCHMARK_LOG_HOOK} \"\\\n+\"${OPT_FLAG} ${TEST_LOG}\"\n+\n+      ${TF_BUILD_BENCHMARK_LOG_HOOK} \"${OPT_FLAG}\" \"${TEST_LOG}\"\n+    else\n+      echo \"WARNING: No hook binary is specified to handle test log ${TEST_LOG}\"\n+    fi\n+  else\n+    # Mark as failure if the test log file cannot be found\n+    TEST_RESULT=2\n+\n+    echo \"ERROR: Cannot find log file from benchmark ${BENCHMARK_TEST} @ \"\\", "path": "tensorflow/tools/ci_build/builds/benchmark.sh", "position": 107, "original_position": 87, "commit_id": "ddbdc3a1d5638e4e012ad28ff709e7b8ba06a5d8", "original_commit_id": "56914f4bb7dc0aa959f2355c726d435b705555e0", "user": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "body": "I think it's better to finish running all the benchmark tests even if there are some test failures. This is how other tests (e.g., bazel tests, pip test-on-install) are done. \n", "created_at": "2016-03-24T15:19:56Z", "updated_at": "2016-03-24T21:17:33Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/1603#discussion_r57333373", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1603", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/57333373"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/1603#discussion_r57333373"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1603"}}, "body_html": "<p>I think it's better to finish running all the benchmark tests even if there are some test failures. This is how other tests (e.g., bazel tests, pip test-on-install) are done.</p>", "body_text": "I think it's better to finish running all the benchmark tests even if there are some test failures. This is how other tests (e.g., bazel tests, pip test-on-install) are done."}