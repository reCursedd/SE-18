{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9917", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9917/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9917/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9917/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9917", "id": 228779127, "node_id": "MDU6SXNzdWUyMjg3NzkxMjc=", "number": 9917, "title": "Feature request: tf.nn.depthwise_conv2d_transpose", "user": {"login": "jvlmdr", "id": 224198, "node_id": "MDQ6VXNlcjIyNDE5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/224198?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jvlmdr", "html_url": "https://github.com/jvlmdr", "followers_url": "https://api.github.com/users/jvlmdr/followers", "following_url": "https://api.github.com/users/jvlmdr/following{/other_user}", "gists_url": "https://api.github.com/users/jvlmdr/gists{/gist_id}", "starred_url": "https://api.github.com/users/jvlmdr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jvlmdr/subscriptions", "organizations_url": "https://api.github.com/users/jvlmdr/orgs", "repos_url": "https://api.github.com/users/jvlmdr/repos", "events_url": "https://api.github.com/users/jvlmdr/events{/privacy}", "received_events_url": "https://api.github.com/users/jvlmdr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-05-15T16:59:18Z", "updated_at": "2018-11-14T00:16:38Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: ('v1.1.0-0-g1ec6ed5', '1.1.0')</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.4.5- (@non-git)</li>\n<li><strong>CUDA/cuDNN version</strong>: 7.5/5.1</li>\n<li><strong>GPU model and memory</strong>: NVIDIA M40, 12GB</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I would like to apply a <code>tf.nn.conv2d_transpose</code> operation to each channel of a feature image independently. There is no <code>tf.nn.depthwise_conv2d_transpose</code> operation.</p>\n<p>I tried using <code>tf.nn.depthwise_conv2d_native_backprop_input</code> however, when I try to optimize a function that involves one of these operations, it results in an error because there is no gradient operation defined:</p>\n<pre><code>LookupError: No gradient defined for operation 'DepthwiseConv2dNativeBackpropInput_1' (op type: DepthwiseConv2dNativeBackpropInput)\n</code></pre>\n<p>This is related to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"210659282\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/7934\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7934/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/7934\">#7934</a></p>\n<p>It is possible to achieve this functionality using <code>conv2d_transpose</code> by constructing a large filter with many coefficients set to zero. However, it is relatively inefficient, especially for a large number of channels.</p>", "body_text": "System information\n\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): ('v1.1.0-0-g1ec6ed5', '1.1.0')\nBazel version (if compiling from source): 0.4.5- (@non-git)\nCUDA/cuDNN version: 7.5/5.1\nGPU model and memory: NVIDIA M40, 12GB\n\nDescribe the problem\nI would like to apply a tf.nn.conv2d_transpose operation to each channel of a feature image independently. There is no tf.nn.depthwise_conv2d_transpose operation.\nI tried using tf.nn.depthwise_conv2d_native_backprop_input however, when I try to optimize a function that involves one of these operations, it results in an error because there is no gradient operation defined:\nLookupError: No gradient defined for operation 'DepthwiseConv2dNativeBackpropInput_1' (op type: DepthwiseConv2dNativeBackpropInput)\n\nThis is related to #7934\nIt is possible to achieve this functionality using conv2d_transpose by constructing a large filter with many coefficients set to zero. However, it is relatively inefficient, especially for a large number of channels.", "body": "### System information\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: ('v1.1.0-0-g1ec6ed5', '1.1.0')\r\n- **Bazel version (if compiling from source)**: 0.4.5- (@non-git)\r\n- **CUDA/cuDNN version**: 7.5/5.1\r\n- **GPU model and memory**: NVIDIA M40, 12GB\r\n\r\n### Describe the problem\r\nI would like to apply a `tf.nn.conv2d_transpose` operation to each channel of a feature image independently. There is no `tf.nn.depthwise_conv2d_transpose` operation.\r\n\r\nI tried using `tf.nn.depthwise_conv2d_native_backprop_input` however, when I try to optimize a function that involves one of these operations, it results in an error because there is no gradient operation defined:\r\n\r\n```\r\nLookupError: No gradient defined for operation 'DepthwiseConv2dNativeBackpropInput_1' (op type: DepthwiseConv2dNativeBackpropInput)\r\n```\r\n\r\nThis is related to https://github.com/tensorflow/tensorflow/issues/7934\r\n\r\nIt is possible to achieve this functionality using `conv2d_transpose` by constructing a large filter with many coefficients set to zero. However, it is relatively inefficient, especially for a large number of channels."}