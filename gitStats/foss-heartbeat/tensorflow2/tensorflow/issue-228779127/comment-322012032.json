{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/322012032", "html_url": "https://github.com/tensorflow/tensorflow/issues/9917#issuecomment-322012032", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9917", "id": 322012032, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjAxMjAzMg==", "user": {"login": "rdinse", "id": 9957215, "node_id": "MDQ6VXNlcjk5NTcyMTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/9957215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdinse", "html_url": "https://github.com/rdinse", "followers_url": "https://api.github.com/users/rdinse/followers", "following_url": "https://api.github.com/users/rdinse/following{/other_user}", "gists_url": "https://api.github.com/users/rdinse/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdinse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdinse/subscriptions", "organizations_url": "https://api.github.com/users/rdinse/orgs", "repos_url": "https://api.github.com/users/rdinse/repos", "events_url": "https://api.github.com/users/rdinse/events{/privacy}", "received_events_url": "https://api.github.com/users/rdinse/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-12T23:25:29Z", "updated_at": "2017-08-12T23:25:29Z", "author_association": "NONE", "body_html": "<pre><code>import tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.ops import array_ops\n\nNUM_ITERATIONS = 1000\n\n@ops.RegisterGradient(\"DepthwiseConv2dNativeBackpropInput\")\ndef _DepthwiseConv2DNativeBackpropInputGrad(op, grad):\n  \"\"\"The derivatives for depth-wise deconvolution.\n  Args:\n    op: the depth-wise deconvolution op.\n    grad: the tensor representing the gradient w.r.t. the output\n  Returns:\n    the gradients w.r.t. the input and the filter\n  \"\"\"\n  return [None,\n          nn_ops.depthwise_conv2d_native_backprop_filter(\n              grad,\n              array_ops.shape(op.inputs[1]),\n              op.inputs[2],\n              op.get_attr(\"strides\"),\n              op.get_attr(\"padding\"),\n              data_format=op.get_attr(\"data_format\")),\n          nn_ops.depthwise_conv2d_native(\n              grad,\n              op.inputs[1],\n              op.get_attr(\"strides\"),\n              op.get_attr(\"padding\"),\n              data_format=op.get_attr(\"data_format\"))]\n\nfilter1 = tf.Variable(np.ones((3, 3, 2, 1), dtype=np.float32))\ndeconv1 = tf.nn.depthwise_conv2d_native_backprop_input(\n  [2, 30, 30, 2],\n  filter1,\n  tf.ones([2, 28, 28, 2]),\n  [1, 1, 1, 1],\n  \"VALID\")\nfilter2 = tf.Variable(np.ones((3, 3, 2, 1), dtype=np.float32))\ndeconv2 = tf.nn.depthwise_conv2d_native_backprop_input(\n  [2, 32, 32, 2],\n  filter2,\n  deconv1,\n  [1, 1, 1, 1],\n  \"VALID\")\nloss = tf.reduce_mean(tf.square(deconv2 - 1))\ntrain_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nprint(sess.run(filter1))\nfor i in range(NUM_ITERATIONS):\n  print(sess.run([train_op, loss])[1], end=\"\\r\")\nprint(sess.run(filter1))\n</code></pre>\n<p>I have attempted to implement the gradient for <code>tf.nn.depthwise_conv2d_native_backprop_input</code> in the code above. If someone could tell me what is missing for a pull request (test cases, wrapper functions etc.), then I would gladly contribute.</p>", "body_text": "import tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.ops import array_ops\n\nNUM_ITERATIONS = 1000\n\n@ops.RegisterGradient(\"DepthwiseConv2dNativeBackpropInput\")\ndef _DepthwiseConv2DNativeBackpropInputGrad(op, grad):\n  \"\"\"The derivatives for depth-wise deconvolution.\n  Args:\n    op: the depth-wise deconvolution op.\n    grad: the tensor representing the gradient w.r.t. the output\n  Returns:\n    the gradients w.r.t. the input and the filter\n  \"\"\"\n  return [None,\n          nn_ops.depthwise_conv2d_native_backprop_filter(\n              grad,\n              array_ops.shape(op.inputs[1]),\n              op.inputs[2],\n              op.get_attr(\"strides\"),\n              op.get_attr(\"padding\"),\n              data_format=op.get_attr(\"data_format\")),\n          nn_ops.depthwise_conv2d_native(\n              grad,\n              op.inputs[1],\n              op.get_attr(\"strides\"),\n              op.get_attr(\"padding\"),\n              data_format=op.get_attr(\"data_format\"))]\n\nfilter1 = tf.Variable(np.ones((3, 3, 2, 1), dtype=np.float32))\ndeconv1 = tf.nn.depthwise_conv2d_native_backprop_input(\n  [2, 30, 30, 2],\n  filter1,\n  tf.ones([2, 28, 28, 2]),\n  [1, 1, 1, 1],\n  \"VALID\")\nfilter2 = tf.Variable(np.ones((3, 3, 2, 1), dtype=np.float32))\ndeconv2 = tf.nn.depthwise_conv2d_native_backprop_input(\n  [2, 32, 32, 2],\n  filter2,\n  deconv1,\n  [1, 1, 1, 1],\n  \"VALID\")\nloss = tf.reduce_mean(tf.square(deconv2 - 1))\ntrain_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nprint(sess.run(filter1))\nfor i in range(NUM_ITERATIONS):\n  print(sess.run([train_op, loss])[1], end=\"\\r\")\nprint(sess.run(filter1))\n\nI have attempted to implement the gradient for tf.nn.depthwise_conv2d_native_backprop_input in the code above. If someone could tell me what is missing for a pull request (test cases, wrapper functions etc.), then I would gladly contribute.", "body": "```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import nn_ops\r\nfrom tensorflow.python.ops import array_ops\r\n\r\nNUM_ITERATIONS = 1000\r\n\r\n@ops.RegisterGradient(\"DepthwiseConv2dNativeBackpropInput\")\r\ndef _DepthwiseConv2DNativeBackpropInputGrad(op, grad):\r\n  \"\"\"The derivatives for depth-wise deconvolution.\r\n  Args:\r\n    op: the depth-wise deconvolution op.\r\n    grad: the tensor representing the gradient w.r.t. the output\r\n  Returns:\r\n    the gradients w.r.t. the input and the filter\r\n  \"\"\"\r\n  return [None,\r\n          nn_ops.depthwise_conv2d_native_backprop_filter(\r\n              grad,\r\n              array_ops.shape(op.inputs[1]),\r\n              op.inputs[2],\r\n              op.get_attr(\"strides\"),\r\n              op.get_attr(\"padding\"),\r\n              data_format=op.get_attr(\"data_format\")),\r\n          nn_ops.depthwise_conv2d_native(\r\n              grad,\r\n              op.inputs[1],\r\n              op.get_attr(\"strides\"),\r\n              op.get_attr(\"padding\"),\r\n              data_format=op.get_attr(\"data_format\"))]\r\n\r\nfilter1 = tf.Variable(np.ones((3, 3, 2, 1), dtype=np.float32))\r\ndeconv1 = tf.nn.depthwise_conv2d_native_backprop_input(\r\n  [2, 30, 30, 2],\r\n  filter1,\r\n  tf.ones([2, 28, 28, 2]),\r\n  [1, 1, 1, 1],\r\n  \"VALID\")\r\nfilter2 = tf.Variable(np.ones((3, 3, 2, 1), dtype=np.float32))\r\ndeconv2 = tf.nn.depthwise_conv2d_native_backprop_input(\r\n  [2, 32, 32, 2],\r\n  filter2,\r\n  deconv1,\r\n  [1, 1, 1, 1],\r\n  \"VALID\")\r\nloss = tf.reduce_mean(tf.square(deconv2 - 1))\r\ntrain_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nprint(sess.run(filter1))\r\nfor i in range(NUM_ITERATIONS):\r\n  print(sess.run([train_op, loss])[1], end=\"\\r\")\r\nprint(sess.run(filter1))\r\n```\r\n\r\nI have attempted to implement the gradient for `tf.nn.depthwise_conv2d_native_backprop_input` in the code above. If someone could tell me what is missing for a pull request (test cases, wrapper functions etc.), then I would gladly contribute."}