{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3380", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3380/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3380/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3380/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3380", "id": 166219272, "node_id": "MDU6SXNzdWUxNjYyMTkyNzI=", "number": 3380, "title": "Multi-GPU Example only using a single GPU", "user": {"login": "zhanif3", "id": 1657111, "node_id": "MDQ6VXNlcjE2NTcxMTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1657111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhanif3", "html_url": "https://github.com/zhanif3", "followers_url": "https://api.github.com/users/zhanif3/followers", "following_url": "https://api.github.com/users/zhanif3/following{/other_user}", "gists_url": "https://api.github.com/users/zhanif3/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhanif3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhanif3/subscriptions", "organizations_url": "https://api.github.com/users/zhanif3/orgs", "repos_url": "https://api.github.com/users/zhanif3/repos", "events_url": "https://api.github.com/users/zhanif3/events{/privacy}", "received_events_url": "https://api.github.com/users/zhanif3/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-07-18T23:53:11Z", "updated_at": "2016-09-27T19:11:08Z", "closed_at": "2016-07-19T14:43:29Z", "author_association": "NONE", "body_html": "<p>When running the CIFAR-10 example, it appears like TensorFlow is only utilizing one card - despite the fact that I have 4 cards installed in this machine (it is an NVIDIA DIGITS box). The script runs fine otherwise (can complete computation on a single card), but simply refuses to use more than one card. When attempting to use the script here: <a href=\"multigpu_basics.py\">https://github.com/aymericdamien/TensorFlow-Examples/blob/master/multigpu_basics.py</a> it appears as if Tensorflow allocates memory to one card, runs the computation, then allocates memory to a second card (in reverse numerical order, no less), and then runs the computation again, on that single card. Oddly, TensorFlow seems to see my cards in reverse order - when using \"/gpu:0\", it allocates work to the 4th card in the box. This is probably unrelated, but I mention it just in case.</p>\n<p>Operating System: Ubuntu 14.04<br>\nuname -a output: <code>Linux nvidia-1 3.16.0-34-generic #47~14.04.1-Ubuntu SMP Fri Apr 10 17:49:16 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux</code><br>\nCIFAR example invocation: <code>cifar10_multi_gpu_train.py --num-gpus=2</code> - results are the same if I set that number between 2 and 4, inclusive.</p>\n<p>nvidia-smi output, before running the CIFAR example:</p>\n<pre lang=\"+------------------------------------------------------+\"><code>| NVIDIA-SMI 352.93     Driver Version: 352.93         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:05:00.0      On |                  N/A |\n| 22%   36C    P8    17W / 250W |    256MiB / 12284MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 22%   38C    P8    16W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   37C    P8    17W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   35C    P8    15W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1697    G   /usr/bin/X                                     174MiB |\n|    0      2983    G   compiz                                          55MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<p>NVIDIA-SMI under load:</p>\n<pre><code>+------------------------------------------------------+\n| NVIDIA-SMI 352.93     Driver Version: 352.93         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:05:00.0      On |                  N/A |\n| 22%   38C    P8    16W / 250W |    364MiB / 12284MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 22%   41C    P8    16W / 250W |    138MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   39C    P8    17W / 250W |    138MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   45C    P2    88W / 250W |  11767MiB / 12287MiB |     90%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1697    G   /usr/bin/X                                     174MiB |\n|    0      2983    G   compiz                                          49MiB |\n|    0     11514    C   python                                         111MiB |\n|    1     11514    C   python                                         111MiB |\n|    2     11514    C   python                                         111MiB |\n|    3     11514    C   python                                       11740MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<p>I installed TensorFlow from source.<br>\n<code>python -c \"import tensorflow; print(tensorflow.__version__)\" I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally 0.9.0</code></p>\n<p>This is the Git commit hash that I got when pulling down TensorFlow:<br>\n<code>a3f61c1d5c76339e6c9655dac426bb3822659772</code></p>", "body_text": "When running the CIFAR-10 example, it appears like TensorFlow is only utilizing one card - despite the fact that I have 4 cards installed in this machine (it is an NVIDIA DIGITS box). The script runs fine otherwise (can complete computation on a single card), but simply refuses to use more than one card. When attempting to use the script here: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/multigpu_basics.py it appears as if Tensorflow allocates memory to one card, runs the computation, then allocates memory to a second card (in reverse numerical order, no less), and then runs the computation again, on that single card. Oddly, TensorFlow seems to see my cards in reverse order - when using \"/gpu:0\", it allocates work to the 4th card in the box. This is probably unrelated, but I mention it just in case.\nOperating System: Ubuntu 14.04\nuname -a output: Linux nvidia-1 3.16.0-34-generic #47~14.04.1-Ubuntu SMP Fri Apr 10 17:49:16 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\nCIFAR example invocation: cifar10_multi_gpu_train.py --num-gpus=2 - results are the same if I set that number between 2 and 4, inclusive.\nnvidia-smi output, before running the CIFAR example:\n| NVIDIA-SMI 352.93     Driver Version: 352.93         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:05:00.0      On |                  N/A |\n| 22%   36C    P8    17W / 250W |    256MiB / 12284MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 22%   38C    P8    16W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   37C    P8    17W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   35C    P8    15W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1697    G   /usr/bin/X                                     174MiB |\n|    0      2983    G   compiz                                          55MiB |\n+-----------------------------------------------------------------------------+\n\nNVIDIA-SMI under load:\n+------------------------------------------------------+\n| NVIDIA-SMI 352.93     Driver Version: 352.93         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:05:00.0      On |                  N/A |\n| 22%   38C    P8    16W / 250W |    364MiB / 12284MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 22%   41C    P8    16W / 250W |    138MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   39C    P8    17W / 250W |    138MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   45C    P2    88W / 250W |  11767MiB / 12287MiB |     90%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1697    G   /usr/bin/X                                     174MiB |\n|    0      2983    G   compiz                                          49MiB |\n|    0     11514    C   python                                         111MiB |\n|    1     11514    C   python                                         111MiB |\n|    2     11514    C   python                                         111MiB |\n|    3     11514    C   python                                       11740MiB |\n+-----------------------------------------------------------------------------+\n\nI installed TensorFlow from source.\npython -c \"import tensorflow; print(tensorflow.__version__)\" I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally 0.9.0\nThis is the Git commit hash that I got when pulling down TensorFlow:\na3f61c1d5c76339e6c9655dac426bb3822659772", "body": "When running the CIFAR-10 example, it appears like TensorFlow is only utilizing one card - despite the fact that I have 4 cards installed in this machine (it is an NVIDIA DIGITS box). The script runs fine otherwise (can complete computation on a single card), but simply refuses to use more than one card. When attempting to use the script here: [https://github.com/aymericdamien/TensorFlow-Examples/blob/master/multigpu_basics.py](multigpu_basics.py) it appears as if Tensorflow allocates memory to one card, runs the computation, then allocates memory to a second card (in reverse numerical order, no less), and then runs the computation again, on that single card. Oddly, TensorFlow seems to see my cards in reverse order - when using \"/gpu:0\", it allocates work to the 4th card in the box. This is probably unrelated, but I mention it just in case. \n\nOperating System: Ubuntu 14.04\nuname -a output: `Linux nvidia-1 3.16.0-34-generic #47~14.04.1-Ubuntu SMP Fri Apr 10 17:49:16 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux`\nCIFAR example invocation: `cifar10_multi_gpu_train.py --num-gpus=2` - results are the same if I set that number between 2 and 4, inclusive.\n\nnvidia-smi output, before running the CIFAR example:\n\n``` +------------------------------------------------------+\n| NVIDIA-SMI 352.93     Driver Version: 352.93         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:05:00.0      On |                  N/A |\n| 22%   36C    P8    17W / 250W |    256MiB / 12284MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 22%   38C    P8    16W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   37C    P8    17W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   35C    P8    15W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1697    G   /usr/bin/X                                     174MiB |\n|    0      2983    G   compiz                                          55MiB |\n+-----------------------------------------------------------------------------+\n```\n\nNVIDIA-SMI under load:\n\n```\n+------------------------------------------------------+\n| NVIDIA-SMI 352.93     Driver Version: 352.93         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:05:00.0      On |                  N/A |\n| 22%   38C    P8    16W / 250W |    364MiB / 12284MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 22%   41C    P8    16W / 250W |    138MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   39C    P8    17W / 250W |    138MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   45C    P2    88W / 250W |  11767MiB / 12287MiB |     90%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1697    G   /usr/bin/X                                     174MiB |\n|    0      2983    G   compiz                                          49MiB |\n|    0     11514    C   python                                         111MiB |\n|    1     11514    C   python                                         111MiB |\n|    2     11514    C   python                                         111MiB |\n|    3     11514    C   python                                       11740MiB |\n+-----------------------------------------------------------------------------+\n```\n\nI installed TensorFlow from source.\n`\npython -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally\n0.9.0\n`\n\nThis is the Git commit hash that I got when pulling down TensorFlow:\n`a3f61c1d5c76339e6c9655dac426bb3822659772`\n"}