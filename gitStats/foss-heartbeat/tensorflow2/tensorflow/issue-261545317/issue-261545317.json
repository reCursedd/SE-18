{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13376", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13376/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13376/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13376/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13376", "id": 261545317, "node_id": "MDU6SXNzdWUyNjE1NDUzMTc=", "number": 13376, "title": "MatMul in TensorFlow is slower than dot product in numpy", "user": {"login": "vslobody", "id": 23069222, "node_id": "MDQ6VXNlcjIzMDY5MjIy", "avatar_url": "https://avatars1.githubusercontent.com/u/23069222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vslobody", "html_url": "https://github.com/vslobody", "followers_url": "https://api.github.com/users/vslobody/followers", "following_url": "https://api.github.com/users/vslobody/following{/other_user}", "gists_url": "https://api.github.com/users/vslobody/gists{/gist_id}", "starred_url": "https://api.github.com/users/vslobody/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vslobody/subscriptions", "organizations_url": "https://api.github.com/users/vslobody/orgs", "repos_url": "https://api.github.com/users/vslobody/repos", "events_url": "https://api.github.com/users/vslobody/events{/privacy}", "received_events_url": "https://api.github.com/users/vslobody/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-29T06:41:16Z", "updated_at": "2017-10-03T12:46:47Z", "closed_at": "2017-10-03T12:46:46Z", "author_association": "NONE", "body_html": "<p>I am observing that on my machine tf.matmul in tensorflow is running significantly slower than dot product in numpy. I have GTX 1080 GPU, and expecting tf.matmul to be at least as fast as when running the code using CPU (numpy).</p>\n<p>**Environment Info</p>\n<p>Operating System**</p>\n<pre><code>lsb_release -a\nNo LSB modules are available.\nDistributor ID:\tUbuntu\nDescription:\tUbuntu 16.10\nRelease:\t16.10\nCodename:\tyakkety\n</code></pre>\n<p><strong>Installed version of CUDA and cuDNN:</strong></p>\n<pre><code>ls -l /usr/local/cuda-8.0/lib64/libcud*\n-rw-r--r-- 1 root      root    556000 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root      root        16 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root      root        19 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.61\n-rwxr-xr-x 1 root      root    415432 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n-rw-r--r-- 1 root      root    775162 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart_static.a\nlrwxrwxrwx 1 voldemaro users       13 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so -&gt; libcudnn.so.5\nlrwxrwxrwx 1 voldemaro users       18 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.1.10\n-rwxr-xr-x 1 voldemaro users 84163560 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10\n-rw-r--r-- 1 voldemaro users 70364814 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n</code></pre>\n<p><strong>TensorFlow Setup</strong></p>\n<pre><code>python -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n1.0.0\n</code></pre>\n<p><strong>Code:</strong></p>\n<pre><code>'''\nCreated on Sep 28, 2017\n\n@author: voldemaro\n\nRunning on I7/GTX 1080\n\nno MKL\n('TF version: ', 'v1.0.0-rc2-15-g47bba63-dirty')\n('TF url: ', 'https://github.com/tensorflow/tensorflow/commit/47bba63')\nTiming in ms for 2048 x 2048 SVD of type &lt;type 'numpy.float32'&gt; and matmul for 16920 x 2048 of type &lt;type 'numpy.float32'&gt;\nnumpy default SVD    min:  3956.20, median:  4127.75, mean:  4264.41\nTF CPU SVD           min:  5926.43, median:  5951.70, mean:  5961.43\nTF GPU SVD           min:  5917.10, median:  6015.87, mean:  6039.63\nnumpy default .dot product min:  5816.97, median:  5933.43, mean:  5965.22\nTF CPU matmul        min: 21939.19, median: 22485.99, mean: 22374.69\nTF GPU matmul        min: 22026.52, median: 22109.97, mean: 22199.43\n'''\n\nfrom scipy import linalg;  # for svd\nimport numpy as np;\nimport os;\nimport sys;\nimport time;\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"  # nospam\n\nimport tensorflow as tf;\nimport gc; gc.disable();\n\nNUM_RUNS = 5;\ndtype = np.float32;\nN=2048;\nM =  16920;\n\n\ndef get_tensorflow_version_url():\n    import tensorflow as tf\n    version=tf.__version__\n    commit = tf.__git_version__\n    # commit looks like this\n    # 'v1.0.0-65-g4763edf-dirty'\n    commit = commit.replace(\"'\",\"\")\n    if commit.endswith('-dirty'):\n        dirty = True\n        commit = commit[:-len('-dirty')]\n    commit=commit.rsplit('-g', 1)[1]\n    url = 'https://github.com/tensorflow/tensorflow/commit/'+commit\n    return url\n\ndef get_mkl_version():\n    import ctypes\n    import numpy as np\n    ver = np.zeros(199, dtype=np.uint8)\n    mkl = ctypes.cdll.LoadLibrary(\"libmkl_rt.so\")\n    mkl.MKL_Get_Version_String(ver.ctypes.data_as(ctypes.c_char_p), 198)\n    return ver[ver != 0].tostring()\n\ntimeline_counter = 0\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE);\n\n\ndef benchmark(message, func):\n    time_list = []\n    for i in range(NUM_RUNS):\n        start_time = time.time();\n        func();\n        time_list.append(time.time()-start_time);\n\n    time_list = 1000*np.array(time_list);  # get seconds, convert to ms\n    if len(time_list)&gt;0:\n        min = np.min(time_list);\n        median = np.median(time_list);\n        formatted = [\"%.2f\"%(d,) for d in time_list[:10]];\n        result = \"min: %8.2f, median: %8.2f, mean: %8.2f\"%(min, median, np.mean(time_list))\n    else:\n        result = \"empty\"\n    print(\"%-20s %s\"%(message, result))\n    \n\nif np.__config__.get_info(\"lapack_mkl_info\"):\n    print(\"MKL version\", get_mkl_version())\nelse:\n    print(\"no MKL\")\n\nprint(\"TF version: \", tf.__git_version__)\nprint(\"TF url: \", get_tensorflow_version_url())\n\n\nsvd_array = np.random.random_sample((N,N)).astype(dtype);\nanother_array = np.random.random_sample((M,N)).astype(dtype);\n\ninit_OP = tf.global_variables_initializer();\n\n\nwith tf.device(\"/gpu:0\"):\n    init_holder_gpu = tf.placeholder(dtype, shape=(M,M));\n    \n    specVarGPU = tf.random_uniform((N,N), dtype=dtype);\n    S_gpu = tf.random_uniform((M,N), dtype=dtype);\n    V_gpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_gpu))), specVarGPU, ), tf.transpose(S_gpu));\n    [D2_gpu, E1_gpu,  E2_gpu] = tf.svd(specVarGPU);\n\nwith tf.device(\"/cpu:0\"):\n    init_holder_cpu = tf.placeholder(dtype, shape=(M,M));\n    specVarCPU = tf.random_uniform((N,N), dtype=dtype);\n    S_cpu = tf.random_uniform((M,N), dtype=dtype);\n    V_cpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_cpu))), specVarCPU, ), tf.transpose(S_cpu));\n    \n    \n    [D2_cpu, E1_cpu,  E2_cpu] = tf.svd(specVarCPU);\n    V_cpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_cpu))), E1_cpu), tf.transpose(S_cpu));\n\nprint(\"Timing in ms for %d x %d SVD of type %s and matmul for %d x %d of type %s\"%(N, N, dtype, M, N, dtype));\n\ndef func(): linalg.svd(svd_array)\nbenchmark(\"numpy default SVD\", func)\n\nconfig = tf.ConfigProto(allow_soft_placement = True, graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)));\nsess = tf.Session(config = config);\nsess.run(init_OP);\n\ndef func2(): sess.run([D2_cpu.op, E1_cpu.op,  E2_cpu.op]);\nbenchmark(\"TF CPU SVD\", func2);\n\ndef func3(): sess.run([D2_gpu.op, E1_gpu.op,  E2_gpu.op]);\nbenchmark(\"TF GPU SVD\", func3);\n\ndef func1(): np.transpose(np.asmatrix(another_array)).getH().dot(svd_array).dot(np.transpose(another_array));\nbenchmark(\"numpy default .dot product\", func1)\n\ndef func4(): sess.run([V_cpu]);\nbenchmark(\"TF CPU matmul\", func4)\n\ndef func5(): sess.run([V_gpu])\nbenchmark(\"TF GPU matmul\", func4)\n\n</code></pre>", "body_text": "I am observing that on my machine tf.matmul in tensorflow is running significantly slower than dot product in numpy. I have GTX 1080 GPU, and expecting tf.matmul to be at least as fast as when running the code using CPU (numpy).\n**Environment Info\nOperating System**\nlsb_release -a\nNo LSB modules are available.\nDistributor ID:\tUbuntu\nDescription:\tUbuntu 16.10\nRelease:\t16.10\nCodename:\tyakkety\n\nInstalled version of CUDA and cuDNN:\nls -l /usr/local/cuda-8.0/lib64/libcud*\n-rw-r--r-- 1 root      root    556000 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root      root        16 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root      root        19 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\n-rwxr-xr-x 1 root      root    415432 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n-rw-r--r-- 1 root      root    775162 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart_static.a\nlrwxrwxrwx 1 voldemaro users       13 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 voldemaro users       18 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10\n-rwxr-xr-x 1 voldemaro users 84163560 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10\n-rw-r--r-- 1 voldemaro users 70364814 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n\nTensorFlow Setup\npython -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n1.0.0\n\nCode:\n'''\nCreated on Sep 28, 2017\n\n@author: voldemaro\n\nRunning on I7/GTX 1080\n\nno MKL\n('TF version: ', 'v1.0.0-rc2-15-g47bba63-dirty')\n('TF url: ', 'https://github.com/tensorflow/tensorflow/commit/47bba63')\nTiming in ms for 2048 x 2048 SVD of type <type 'numpy.float32'> and matmul for 16920 x 2048 of type <type 'numpy.float32'>\nnumpy default SVD    min:  3956.20, median:  4127.75, mean:  4264.41\nTF CPU SVD           min:  5926.43, median:  5951.70, mean:  5961.43\nTF GPU SVD           min:  5917.10, median:  6015.87, mean:  6039.63\nnumpy default .dot product min:  5816.97, median:  5933.43, mean:  5965.22\nTF CPU matmul        min: 21939.19, median: 22485.99, mean: 22374.69\nTF GPU matmul        min: 22026.52, median: 22109.97, mean: 22199.43\n'''\n\nfrom scipy import linalg;  # for svd\nimport numpy as np;\nimport os;\nimport sys;\nimport time;\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"  # nospam\n\nimport tensorflow as tf;\nimport gc; gc.disable();\n\nNUM_RUNS = 5;\ndtype = np.float32;\nN=2048;\nM =  16920;\n\n\ndef get_tensorflow_version_url():\n    import tensorflow as tf\n    version=tf.__version__\n    commit = tf.__git_version__\n    # commit looks like this\n    # 'v1.0.0-65-g4763edf-dirty'\n    commit = commit.replace(\"'\",\"\")\n    if commit.endswith('-dirty'):\n        dirty = True\n        commit = commit[:-len('-dirty')]\n    commit=commit.rsplit('-g', 1)[1]\n    url = 'https://github.com/tensorflow/tensorflow/commit/'+commit\n    return url\n\ndef get_mkl_version():\n    import ctypes\n    import numpy as np\n    ver = np.zeros(199, dtype=np.uint8)\n    mkl = ctypes.cdll.LoadLibrary(\"libmkl_rt.so\")\n    mkl.MKL_Get_Version_String(ver.ctypes.data_as(ctypes.c_char_p), 198)\n    return ver[ver != 0].tostring()\n\ntimeline_counter = 0\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE);\n\n\ndef benchmark(message, func):\n    time_list = []\n    for i in range(NUM_RUNS):\n        start_time = time.time();\n        func();\n        time_list.append(time.time()-start_time);\n\n    time_list = 1000*np.array(time_list);  # get seconds, convert to ms\n    if len(time_list)>0:\n        min = np.min(time_list);\n        median = np.median(time_list);\n        formatted = [\"%.2f\"%(d,) for d in time_list[:10]];\n        result = \"min: %8.2f, median: %8.2f, mean: %8.2f\"%(min, median, np.mean(time_list))\n    else:\n        result = \"empty\"\n    print(\"%-20s %s\"%(message, result))\n    \n\nif np.__config__.get_info(\"lapack_mkl_info\"):\n    print(\"MKL version\", get_mkl_version())\nelse:\n    print(\"no MKL\")\n\nprint(\"TF version: \", tf.__git_version__)\nprint(\"TF url: \", get_tensorflow_version_url())\n\n\nsvd_array = np.random.random_sample((N,N)).astype(dtype);\nanother_array = np.random.random_sample((M,N)).astype(dtype);\n\ninit_OP = tf.global_variables_initializer();\n\n\nwith tf.device(\"/gpu:0\"):\n    init_holder_gpu = tf.placeholder(dtype, shape=(M,M));\n    \n    specVarGPU = tf.random_uniform((N,N), dtype=dtype);\n    S_gpu = tf.random_uniform((M,N), dtype=dtype);\n    V_gpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_gpu))), specVarGPU, ), tf.transpose(S_gpu));\n    [D2_gpu, E1_gpu,  E2_gpu] = tf.svd(specVarGPU);\n\nwith tf.device(\"/cpu:0\"):\n    init_holder_cpu = tf.placeholder(dtype, shape=(M,M));\n    specVarCPU = tf.random_uniform((N,N), dtype=dtype);\n    S_cpu = tf.random_uniform((M,N), dtype=dtype);\n    V_cpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_cpu))), specVarCPU, ), tf.transpose(S_cpu));\n    \n    \n    [D2_cpu, E1_cpu,  E2_cpu] = tf.svd(specVarCPU);\n    V_cpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_cpu))), E1_cpu), tf.transpose(S_cpu));\n\nprint(\"Timing in ms for %d x %d SVD of type %s and matmul for %d x %d of type %s\"%(N, N, dtype, M, N, dtype));\n\ndef func(): linalg.svd(svd_array)\nbenchmark(\"numpy default SVD\", func)\n\nconfig = tf.ConfigProto(allow_soft_placement = True, graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)));\nsess = tf.Session(config = config);\nsess.run(init_OP);\n\ndef func2(): sess.run([D2_cpu.op, E1_cpu.op,  E2_cpu.op]);\nbenchmark(\"TF CPU SVD\", func2);\n\ndef func3(): sess.run([D2_gpu.op, E1_gpu.op,  E2_gpu.op]);\nbenchmark(\"TF GPU SVD\", func3);\n\ndef func1(): np.transpose(np.asmatrix(another_array)).getH().dot(svd_array).dot(np.transpose(another_array));\nbenchmark(\"numpy default .dot product\", func1)\n\ndef func4(): sess.run([V_cpu]);\nbenchmark(\"TF CPU matmul\", func4)\n\ndef func5(): sess.run([V_gpu])\nbenchmark(\"TF GPU matmul\", func4)", "body": "I am observing that on my machine tf.matmul in tensorflow is running significantly slower than dot product in numpy. I have GTX 1080 GPU, and expecting tf.matmul to be at least as fast as when running the code using CPU (numpy).\r\n\r\n**Environment Info\r\n\r\nOperating System**\r\n\r\n```\r\nlsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 16.10\r\nRelease:\t16.10\r\nCodename:\tyakkety\r\n```\r\n**Installed version of CUDA and cuDNN:**\r\n\r\n```\r\nls -l /usr/local/cuda-8.0/lib64/libcud*\r\n-rw-r--r-- 1 root      root    556000 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root      root        16 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root      root        19 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n-rwxr-xr-x 1 root      root    415432 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n-rw-r--r-- 1 root      root    775162 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 voldemaro users       13 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 voldemaro users       18 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10\r\n-rwxr-xr-x 1 voldemaro users 84163560 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10\r\n-rw-r--r-- 1 voldemaro users 70364814 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n```\r\n**TensorFlow Setup**\r\n\r\n```\r\npython -c \"import tensorflow; print(tensorflow.__version__)\"\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n1.0.0\r\n```\r\n**Code:**\r\n\r\n```\r\n'''\r\nCreated on Sep 28, 2017\r\n\r\n@author: voldemaro\r\n\r\nRunning on I7/GTX 1080\r\n\r\nno MKL\r\n('TF version: ', 'v1.0.0-rc2-15-g47bba63-dirty')\r\n('TF url: ', 'https://github.com/tensorflow/tensorflow/commit/47bba63')\r\nTiming in ms for 2048 x 2048 SVD of type <type 'numpy.float32'> and matmul for 16920 x 2048 of type <type 'numpy.float32'>\r\nnumpy default SVD    min:  3956.20, median:  4127.75, mean:  4264.41\r\nTF CPU SVD           min:  5926.43, median:  5951.70, mean:  5961.43\r\nTF GPU SVD           min:  5917.10, median:  6015.87, mean:  6039.63\r\nnumpy default .dot product min:  5816.97, median:  5933.43, mean:  5965.22\r\nTF CPU matmul        min: 21939.19, median: 22485.99, mean: 22374.69\r\nTF GPU matmul        min: 22026.52, median: 22109.97, mean: 22199.43\r\n'''\r\n\r\nfrom scipy import linalg;  # for svd\r\nimport numpy as np;\r\nimport os;\r\nimport sys;\r\nimport time;\r\n\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"  # nospam\r\n\r\nimport tensorflow as tf;\r\nimport gc; gc.disable();\r\n\r\nNUM_RUNS = 5;\r\ndtype = np.float32;\r\nN=2048;\r\nM =  16920;\r\n\r\n\r\ndef get_tensorflow_version_url():\r\n    import tensorflow as tf\r\n    version=tf.__version__\r\n    commit = tf.__git_version__\r\n    # commit looks like this\r\n    # 'v1.0.0-65-g4763edf-dirty'\r\n    commit = commit.replace(\"'\",\"\")\r\n    if commit.endswith('-dirty'):\r\n        dirty = True\r\n        commit = commit[:-len('-dirty')]\r\n    commit=commit.rsplit('-g', 1)[1]\r\n    url = 'https://github.com/tensorflow/tensorflow/commit/'+commit\r\n    return url\r\n\r\ndef get_mkl_version():\r\n    import ctypes\r\n    import numpy as np\r\n    ver = np.zeros(199, dtype=np.uint8)\r\n    mkl = ctypes.cdll.LoadLibrary(\"libmkl_rt.so\")\r\n    mkl.MKL_Get_Version_String(ver.ctypes.data_as(ctypes.c_char_p), 198)\r\n    return ver[ver != 0].tostring()\r\n\r\ntimeline_counter = 0\r\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE);\r\n\r\n\r\ndef benchmark(message, func):\r\n    time_list = []\r\n    for i in range(NUM_RUNS):\r\n        start_time = time.time();\r\n        func();\r\n        time_list.append(time.time()-start_time);\r\n\r\n    time_list = 1000*np.array(time_list);  # get seconds, convert to ms\r\n    if len(time_list)>0:\r\n        min = np.min(time_list);\r\n        median = np.median(time_list);\r\n        formatted = [\"%.2f\"%(d,) for d in time_list[:10]];\r\n        result = \"min: %8.2f, median: %8.2f, mean: %8.2f\"%(min, median, np.mean(time_list))\r\n    else:\r\n        result = \"empty\"\r\n    print(\"%-20s %s\"%(message, result))\r\n    \r\n\r\nif np.__config__.get_info(\"lapack_mkl_info\"):\r\n    print(\"MKL version\", get_mkl_version())\r\nelse:\r\n    print(\"no MKL\")\r\n\r\nprint(\"TF version: \", tf.__git_version__)\r\nprint(\"TF url: \", get_tensorflow_version_url())\r\n\r\n\r\nsvd_array = np.random.random_sample((N,N)).astype(dtype);\r\nanother_array = np.random.random_sample((M,N)).astype(dtype);\r\n\r\ninit_OP = tf.global_variables_initializer();\r\n\r\n\r\nwith tf.device(\"/gpu:0\"):\r\n    init_holder_gpu = tf.placeholder(dtype, shape=(M,M));\r\n    \r\n    specVarGPU = tf.random_uniform((N,N), dtype=dtype);\r\n    S_gpu = tf.random_uniform((M,N), dtype=dtype);\r\n    V_gpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_gpu))), specVarGPU, ), tf.transpose(S_gpu));\r\n    [D2_gpu, E1_gpu,  E2_gpu] = tf.svd(specVarGPU);\r\n\r\nwith tf.device(\"/cpu:0\"):\r\n    init_holder_cpu = tf.placeholder(dtype, shape=(M,M));\r\n    specVarCPU = tf.random_uniform((N,N), dtype=dtype);\r\n    S_cpu = tf.random_uniform((M,N), dtype=dtype);\r\n    V_cpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_cpu))), specVarCPU, ), tf.transpose(S_cpu));\r\n    \r\n    \r\n    [D2_cpu, E1_cpu,  E2_cpu] = tf.svd(specVarCPU);\r\n    V_cpu = tf.matmul(tf.matmul(tf.transpose(tf.transpose(tf.conj(S_cpu))), E1_cpu), tf.transpose(S_cpu));\r\n\r\nprint(\"Timing in ms for %d x %d SVD of type %s and matmul for %d x %d of type %s\"%(N, N, dtype, M, N, dtype));\r\n\r\ndef func(): linalg.svd(svd_array)\r\nbenchmark(\"numpy default SVD\", func)\r\n\r\nconfig = tf.ConfigProto(allow_soft_placement = True, graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)));\r\nsess = tf.Session(config = config);\r\nsess.run(init_OP);\r\n\r\ndef func2(): sess.run([D2_cpu.op, E1_cpu.op,  E2_cpu.op]);\r\nbenchmark(\"TF CPU SVD\", func2);\r\n\r\ndef func3(): sess.run([D2_gpu.op, E1_gpu.op,  E2_gpu.op]);\r\nbenchmark(\"TF GPU SVD\", func3);\r\n\r\ndef func1(): np.transpose(np.asmatrix(another_array)).getH().dot(svd_array).dot(np.transpose(another_array));\r\nbenchmark(\"numpy default .dot product\", func1)\r\n\r\ndef func4(): sess.run([V_cpu]);\r\nbenchmark(\"TF CPU matmul\", func4)\r\n\r\ndef func5(): sess.run([V_gpu])\r\nbenchmark(\"TF GPU matmul\", func4)\r\n\r\n```\r\n"}