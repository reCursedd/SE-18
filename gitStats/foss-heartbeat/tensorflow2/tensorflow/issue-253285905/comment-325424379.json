{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/325424379", "html_url": "https://github.com/tensorflow/tensorflow/issues/12648#issuecomment-325424379", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12648", "id": 325424379, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNTQyNDM3OQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-28T17:44:53Z", "updated_at": "2017-08-28T17:44:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Using <code>tf.Variable</code> in a TensorFlow function is not supported. To make this work, you'll need to use <code>tf.get_variable(..., use_resource=True)</code> <em>before</em> defining the <code>mapf()</code> function to declare the variable in the outer scope, then simply capture the variable in your <code>mapf()</code> function. Since you're defining a stateful input pipeline, you'll also need to use an <em>initializable</em> iterator rather than a one-shot iterator.</p>\n<p>The following code illustrates how to do this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span>  tf\n<span class=\"pl-k\">from</span>  tensorflow.contrib.data <span class=\"pl-k\">import</span> Dataset\n\ndataset <span class=\"pl-k\">=</span> Dataset.range(<span class=\"pl-c1\">100</span>)\n\ntemp <span class=\"pl-k\">=</span> tf.get_variable(\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>my_var<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_uniform([<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">minval</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">maxval</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32),\n    <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n    <span class=\"pl-v\">collections</span><span class=\"pl-k\">=</span>[tf.GraphKeys.<span class=\"pl-c1\">LOCAL_VARIABLES</span>],\n    <span class=\"pl-v\">use_resource</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">mapf</span>(<span class=\"pl-smi\">v</span>):\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">NOTE</span>(mrry): I assume you didn't really intend to reinitialize the</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> variable in each call to `mapf()`, and were instead trying to</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> increment it with the `temp = temp + 1` in the original code.</span>\n  <span class=\"pl-k\">with</span> tf.control_dependencies([temp.assign_add([<span class=\"pl-c1\">1</span>]).op]):\n    <span class=\"pl-k\">return</span> temp\n\ndataset <span class=\"pl-k\">=</span> dataset.map(mapf)\ndataset <span class=\"pl-k\">=</span> dataset.batch(<span class=\"pl-c1\">1</span>)\n\niterator <span class=\"pl-k\">=</span> dataset.make_initializable_iterator()\nnext_element <span class=\"pl-k\">=</span> iterator.get_next()\nlocal_init <span class=\"pl-k\">=</span> tf.local_variables_initializer()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n  sess.run(local_init)\n  sess.run(iterator.initializer)\n  <span class=\"pl-k\">try</span>:\n    <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n      <span class=\"pl-c1\">print</span>(sess.run([next_element]))\n  <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError <span class=\"pl-k\">as</span> e:\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ending<span class=\"pl-pds\">\"</span></span>)</pre></div>", "body_text": "Using tf.Variable in a TensorFlow function is not supported. To make this work, you'll need to use tf.get_variable(..., use_resource=True) before defining the mapf() function to declare the variable in the outer scope, then simply capture the variable in your mapf() function. Since you're defining a stateful input pipeline, you'll also need to use an initializable iterator rather than a one-shot iterator.\nThe following code illustrates how to do this:\nimport tensorflow as  tf\nfrom  tensorflow.contrib.data import Dataset\n\ndataset = Dataset.range(100)\n\ntemp = tf.get_variable(\n    \"my_var\",\n    initializer=tf.random_uniform([1], minval=0, maxval=10, dtype=tf.int32),\n    trainable=False,\n    collections=[tf.GraphKeys.LOCAL_VARIABLES],\n    use_resource=True)\n\ndef mapf(v):\n  # NOTE(mrry): I assume you didn't really intend to reinitialize the\n  # variable in each call to `mapf()`, and were instead trying to\n  # increment it with the `temp = temp + 1` in the original code.\n  with tf.control_dependencies([temp.assign_add([1]).op]):\n    return temp\n\ndataset = dataset.map(mapf)\ndataset = dataset.batch(1)\n\niterator = dataset.make_initializable_iterator()\nnext_element = iterator.get_next()\nlocal_init = tf.local_variables_initializer()\n\nwith tf.Session() as sess:\n  sess.run(local_init)\n  sess.run(iterator.initializer)\n  try:\n    while True:\n      print(sess.run([next_element]))\n  except tf.errors.OutOfRangeError as e:\n    print(\"ending\")", "body": "Using `tf.Variable` in a TensorFlow function is not supported. To make this work, you'll need to use `tf.get_variable(..., use_resource=True)` *before* defining the `mapf()` function to declare the variable in the outer scope, then simply capture the variable in your `mapf()` function. Since you're defining a stateful input pipeline, you'll also need to use an *initializable* iterator rather than a one-shot iterator.\r\n\r\nThe following code illustrates how to do this:\r\n\r\n```python\r\nimport tensorflow as  tf\r\nfrom  tensorflow.contrib.data import Dataset\r\n\r\ndataset = Dataset.range(100)\r\n\r\ntemp = tf.get_variable(\r\n    \"my_var\",\r\n    initializer=tf.random_uniform([1], minval=0, maxval=10, dtype=tf.int32),\r\n    trainable=False,\r\n    collections=[tf.GraphKeys.LOCAL_VARIABLES],\r\n    use_resource=True)\r\n\r\ndef mapf(v):\r\n  # NOTE(mrry): I assume you didn't really intend to reinitialize the\r\n  # variable in each call to `mapf()`, and were instead trying to\r\n  # increment it with the `temp = temp + 1` in the original code.\r\n  with tf.control_dependencies([temp.assign_add([1]).op]):\r\n    return temp\r\n\r\ndataset = dataset.map(mapf)\r\ndataset = dataset.batch(1)\r\n\r\niterator = dataset.make_initializable_iterator()\r\nnext_element = iterator.get_next()\r\nlocal_init = tf.local_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n  sess.run(local_init)\r\n  sess.run(iterator.initializer)\r\n  try:\r\n    while True:\r\n      print(sess.run([next_element]))\r\n  except tf.errors.OutOfRangeError as e:\r\n    print(\"ending\")\r\n```"}