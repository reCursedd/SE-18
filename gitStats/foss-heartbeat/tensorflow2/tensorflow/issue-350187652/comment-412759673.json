{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412759673", "html_url": "https://github.com/tensorflow/tensorflow/issues/21584#issuecomment-412759673", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21584", "id": 412759673, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjc1OTY3Mw==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-14T05:35:14Z", "updated_at": "2018-08-14T05:35:14Z", "author_association": "MEMBER", "body_html": "<p>This question is better asked on <a href=\"http://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a> since it is not a bug or feature request. There is also a larger community that reads questions there.</p>\n<p>If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the <a href=\"https://github.com/tensorflow/tensorflow/issues/new\">issue template</a>. Thanks!</p>\n<p>That said, Short answer: Nope, this should not be a leak.</p>\n<p>Long answer: <code>total_discriminator_loss += discriminator_loss_val</code> is shorthand for <code>total_discriminator_loss = tf.add(total_discriminator_loss, discriminator_loss_val)</code>. So, the tape only records the <code>add</code> operation, furthermore the tape is cleared on each call to <code>gradient</code> (<a href=\"https://www.tensorflow.org/api_docs/python/tf/GradientTape#class_gradienttape\" rel=\"nofollow\">doc</a>).</p>\n<p>Hope that helps.</p>", "body_text": "This question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there.\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the issue template. Thanks!\nThat said, Short answer: Nope, this should not be a leak.\nLong answer: total_discriminator_loss += discriminator_loss_val is shorthand for total_discriminator_loss = tf.add(total_discriminator_loss, discriminator_loss_val). So, the tape only records the add operation, furthermore the tape is cleared on each call to gradient (doc).\nHope that helps.", "body": "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n\r\nThat said, Short answer: Nope, this should not be a leak.\r\n\r\nLong answer: `total_discriminator_loss += discriminator_loss_val` is shorthand for `total_discriminator_loss = tf.add(total_discriminator_loss, discriminator_loss_val)`. So, the tape only records the `add` operation, furthermore the tape is cleared on each call to `gradient` ([doc](https://www.tensorflow.org/api_docs/python/tf/GradientTape#class_gradienttape)).\r\n\r\nHope that helps."}