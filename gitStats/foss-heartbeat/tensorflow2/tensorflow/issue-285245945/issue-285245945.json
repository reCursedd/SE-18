{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15745", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15745/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15745/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15745/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15745", "id": 285245945, "node_id": "MDU6SXNzdWUyODUyNDU5NDU=", "number": 15745, "title": "Eager: variable created in @tfe.defun is invalid and raise error when print", "user": {"login": "traveller59", "id": 28866047, "node_id": "MDQ6VXNlcjI4ODY2MDQ3", "avatar_url": "https://avatars1.githubusercontent.com/u/28866047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/traveller59", "html_url": "https://github.com/traveller59", "followers_url": "https://api.github.com/users/traveller59/followers", "following_url": "https://api.github.com/users/traveller59/following{/other_user}", "gists_url": "https://api.github.com/users/traveller59/gists{/gist_id}", "starred_url": "https://api.github.com/users/traveller59/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/traveller59/subscriptions", "organizations_url": "https://api.github.com/users/traveller59/orgs", "repos_url": "https://api.github.com/users/traveller59/repos", "events_url": "https://api.github.com/users/traveller59/events{/privacy}", "received_events_url": "https://api.github.com/users/traveller59/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "akshayka", "id": 1994308, "node_id": "MDQ6VXNlcjE5OTQzMDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1994308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akshayka", "html_url": "https://github.com/akshayka", "followers_url": "https://api.github.com/users/akshayka/followers", "following_url": "https://api.github.com/users/akshayka/following{/other_user}", "gists_url": "https://api.github.com/users/akshayka/gists{/gist_id}", "starred_url": "https://api.github.com/users/akshayka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akshayka/subscriptions", "organizations_url": "https://api.github.com/users/akshayka/orgs", "repos_url": "https://api.github.com/users/akshayka/repos", "events_url": "https://api.github.com/users/akshayka/events{/privacy}", "received_events_url": "https://api.github.com/users/akshayka/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "akshayka", "id": 1994308, "node_id": "MDQ6VXNlcjE5OTQzMDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1994308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akshayka", "html_url": "https://github.com/akshayka", "followers_url": "https://api.github.com/users/akshayka/followers", "following_url": "https://api.github.com/users/akshayka/following{/other_user}", "gists_url": "https://api.github.com/users/akshayka/gists{/gist_id}", "starred_url": "https://api.github.com/users/akshayka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akshayka/subscriptions", "organizations_url": "https://api.github.com/users/akshayka/orgs", "repos_url": "https://api.github.com/users/akshayka/repos", "events_url": "https://api.github.com/users/akshayka/events{/privacy}", "received_events_url": "https://api.github.com/users/akshayka/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-12-31T08:13:11Z", "updated_at": "2018-01-24T00:39:08Z", "closed_at": "2018-01-24T00:39:08Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Win10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.5.0dev20171230</li>\n<li><strong>Python version</strong>: 3.6</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I want to use defun to speed up static rnn compute in eager:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">_eager_dynamic_rnn</span>(<span class=\"pl-smi\">cell</span>,\n                       <span class=\"pl-smi\">inputs</span>,\n                       <span class=\"pl-smi\">sequence_length</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                       <span class=\"pl-smi\">initial_state</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                       <span class=\"pl-smi\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                       <span class=\"pl-smi\">parallel_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                       <span class=\"pl-smi\">swap_memory</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                       <span class=\"pl-smi\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                       <span class=\"pl-smi\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    time_axis <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">if</span> time_major <span class=\"pl-k\">else</span> <span class=\"pl-c1\">1</span>\n    input_shape <span class=\"pl-k\">=</span> inputs.shape.as_list()\n    seq_len <span class=\"pl-k\">=</span> input_shape[time_axis]\n    <span class=\"pl-k\">if</span> time_major:\n        batch_size <span class=\"pl-k\">=</span> input_shape[<span class=\"pl-c1\">1</span>]\n    <span class=\"pl-k\">else</span>:\n        batch_size <span class=\"pl-k\">=</span> input_shape[<span class=\"pl-c1\">0</span>]\n    <span class=\"pl-k\">if</span> initial_state <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n        initial_state <span class=\"pl-k\">=</span> cell.zero_state(batch_size, dtype)\n    inputs <span class=\"pl-k\">=</span> tf.unstack(inputs, <span class=\"pl-v\">num</span><span class=\"pl-k\">=</span>seq_len, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span>time_axis)\n    outputs <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> inp <span class=\"pl-k\">in</span> inputs:\n        output, initial_state <span class=\"pl-k\">=</span> cell(inp, initial_state)\n        outputs.append(output)\n    outputs <span class=\"pl-k\">=</span> tf.stack(outputs, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span>time_axis)\n    <span class=\"pl-k\">return</span> outputs, initial_state\n\n\n<span class=\"pl-en\">@tfe.defun</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_eager_compiled_dynamic_rnn</span>(<span class=\"pl-smi\">cell</span>,\n                                <span class=\"pl-smi\">inputs</span>,\n                                <span class=\"pl-smi\">sequence_length</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                                <span class=\"pl-smi\">initial_state</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                                <span class=\"pl-smi\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                <span class=\"pl-smi\">parallel_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                                <span class=\"pl-smi\">swap_memory</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                                <span class=\"pl-smi\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                                <span class=\"pl-smi\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-k\">return</span> _eager_dynamic_rnn(cell, inputs, sequence_length, initial_state,\n                              dtype, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">False</span>, time_major, scope)</pre></div>\n<p>If I directly use <code>_eager_compiled_dynamic_rnn</code> in forward, because of <code>tf.layers.Layer</code> create variables in its first <strong>call</strong>, then variables created in <code>_eager_compiled_dynamic_rnn</code> is invalid, if print it, get a error:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">7</span><span class=\"pl-k\">-</span><span class=\"pl-ii\">308544234cc4</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n      <span class=\"pl-c1\">1</span> <span class=\"pl-k\">for</span> var <span class=\"pl-k\">in</span> net.variables:\n<span class=\"pl-ii\">----</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">2</span>     <span class=\"pl-c1\">print</span>(var)\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py in __repr__(self)</span>\n    <span class=\"pl-c1\">233</span>       <span class=\"pl-k\">return</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;tf.Variable '<span class=\"pl-c1\">%s</span>' shape=<span class=\"pl-c1\">%s</span> dtype=<span class=\"pl-c1\">%s</span>, numpy=<span class=\"pl-c1\">%s</span>&gt;<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (\n    <span class=\"pl-c1\">234</span>           <span class=\"pl-c1\">self</span>.name, <span class=\"pl-c1\">self</span>.get_shape(), <span class=\"pl-c1\">self</span>.dtype.name,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">235</span>           ops.numpy_text(<span class=\"pl-c1\">self</span>.read_value(), <span class=\"pl-v\">is_repr</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n    <span class=\"pl-c1\">236</span>     <span class=\"pl-k\">else</span>:\n    <span class=\"pl-c1\">237</span>       <span class=\"pl-k\">return</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;tf.Variable '<span class=\"pl-c1\">%s</span>' shape=<span class=\"pl-c1\">%s</span> dtype=<span class=\"pl-c1\">%s</span>&gt;<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py in read_value(self)</span>\n    <span class=\"pl-c1\">679</span>       <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ensure we read the variable in the same device as the handle.</span>\n    <span class=\"pl-c1\">680</span>       <span class=\"pl-k\">with</span> ops.device(<span class=\"pl-c1\">self</span>._handle_device):\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">681</span>         value = <span class=\"pl-c1\">self</span>._read_variable_op()\n    <span class=\"pl-c1\">682</span>     <span class=\"pl-c\"><span class=\"pl-c\">#</span> Return an identity so it can get placed on whatever device the context</span>\n    <span class=\"pl-c1\">683</span>     <span class=\"pl-c\"><span class=\"pl-c\">#</span> specifies instead of the device where the variable is.</span>\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py in _read_variable_op(self)</span>\n    <span class=\"pl-c1\">657</span>       tape.watch_variable(<span class=\"pl-c1\">self</span>)\n    <span class=\"pl-c1\">658</span>     <span class=\"pl-k\">return</span> gen_resource_variable_ops.read_variable_op(<span class=\"pl-c1\">self</span>._handle,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">659</span>                                                       <span class=\"pl-c1\">self</span>._dtype)\n    <span class=\"pl-c1\">660</span> \n    <span class=\"pl-c1\">661</span>   <span class=\"pl-k\">def</span> read_value(<span class=\"pl-c1\">self</span>):\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py in read_variable_op(resource, dtype, name)</span>\n    <span class=\"pl-c1\">209</span>     _attrs = (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>dtype<span class=\"pl-pds\">\"</span></span>, dtype)\n    <span class=\"pl-c1\">210</span>     _result = _execute.execute(<span class=\"pl-s\"><span class=\"pl-k\">b</span><span class=\"pl-pds\">\"</span>ReadVariableOp<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>_inputs_flat,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">211</span>                                <span class=\"pl-v\">attrs</span><span class=\"pl-k\">=</span>_attrs, <span class=\"pl-v\">ctx</span><span class=\"pl-k\">=</span>_ctx, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name)\n    <span class=\"pl-c1\">212</span>   _execute.record_gradient(\n    <span class=\"pl-c1\">213</span>       <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ReadVariableOp<span class=\"pl-pds\">\"</span></span>, _inputs_flat, _attrs, _result, name)\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)</span>\n     <span class=\"pl-c1\">58</span>     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n     <span class=\"pl-c1\">59</span>                                                op_name, inputs, attrs,\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">60</span>                                                num_outputs)\n     <span class=\"pl-c1\">61</span>   <span class=\"pl-k\">except</span> core._NotOkStatusException <span class=\"pl-k\">as</span> e:\n     <span class=\"pl-c1\">62</span>     <span class=\"pl-k\">if</span> name <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n\n<span class=\"pl-c1\">TypeError</span>: provided <span class=\"pl-c1\">list</span> of inputs contains objects other than <span class=\"pl-s\"><span class=\"pl-pds\">'</span>EagerTensor<span class=\"pl-pds\">'</span></span></pre></div>\n<p>To solve this problem, I must call function which isn't decorated by tfe.defun in first forward, then switch to <code>_eager_compiled_dynamic_rnn</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>._cell.built <span class=\"pl-k\">is</span> <span class=\"pl-c1\">True</span>:\n    func <span class=\"pl-k\">=</span> _eager_compiled_dynamic_rnn\n<span class=\"pl-k\">else</span>:\n    func <span class=\"pl-k\">=</span> _eager_dynamic_rnn\noutputs, state <span class=\"pl-k\">=</span> func(\n    <span class=\"pl-c1\">self</span>._cell,\n    inputs,\n    seq_len,\n    state,\n    <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._rnn_dtype,\n    <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._time_major, )</pre></div>\n<p>locate this error cost me much time. please consider to fix it.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Win10\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.5.0dev20171230\nPython version: 3.6\n\nDescribe the problem\nI want to use defun to speed up static rnn compute in eager:\ndef _eager_dynamic_rnn(cell,\n                       inputs,\n                       sequence_length=None,\n                       initial_state=None,\n                       dtype=tf.float32,\n                       parallel_iterations=None,\n                       swap_memory=False,\n                       time_major=False,\n                       scope=None):\n    time_axis = 0 if time_major else 1\n    input_shape = inputs.shape.as_list()\n    seq_len = input_shape[time_axis]\n    if time_major:\n        batch_size = input_shape[1]\n    else:\n        batch_size = input_shape[0]\n    if initial_state is None:\n        initial_state = cell.zero_state(batch_size, dtype)\n    inputs = tf.unstack(inputs, num=seq_len, axis=time_axis)\n    outputs = []\n    for inp in inputs:\n        output, initial_state = cell(inp, initial_state)\n        outputs.append(output)\n    outputs = tf.stack(outputs, axis=time_axis)\n    return outputs, initial_state\n\n\n@tfe.defun\ndef _eager_compiled_dynamic_rnn(cell,\n                                inputs,\n                                sequence_length=None,\n                                initial_state=None,\n                                dtype=tf.float32,\n                                parallel_iterations=None,\n                                swap_memory=False,\n                                time_major=False,\n                                scope=None):\n    return _eager_dynamic_rnn(cell, inputs, sequence_length, initial_state,\n                              dtype, None, False, time_major, scope)\nIf I directly use _eager_compiled_dynamic_rnn in forward, because of tf.layers.Layer create variables in its first call, then variables created in _eager_compiled_dynamic_rnn is invalid, if print it, get a error:\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-7-308544234cc4> in <module>()\n      1 for var in net.variables:\n----> 2     print(var)\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py in __repr__(self)\n    233       return \"<tf.Variable '%s' shape=%s dtype=%s, numpy=%s>\" % (\n    234           self.name, self.get_shape(), self.dtype.name,\n--> 235           ops.numpy_text(self.read_value(), is_repr=True))\n    236     else:\n    237       return \"<tf.Variable '%s' shape=%s dtype=%s>\" % (\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py in read_value(self)\n    679       # Ensure we read the variable in the same device as the handle.\n    680       with ops.device(self._handle_device):\n--> 681         value = self._read_variable_op()\n    682     # Return an identity so it can get placed on whatever device the context\n    683     # specifies instead of the device where the variable is.\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py in _read_variable_op(self)\n    657       tape.watch_variable(self)\n    658     return gen_resource_variable_ops.read_variable_op(self._handle,\n--> 659                                                       self._dtype)\n    660 \n    661   def read_value(self):\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py in read_variable_op(resource, dtype, name)\n    209     _attrs = (\"dtype\", dtype)\n    210     _result = _execute.execute(b\"ReadVariableOp\", 1, inputs=_inputs_flat,\n--> 211                                attrs=_attrs, ctx=_ctx, name=name)\n    212   _execute.record_gradient(\n    213       \"ReadVariableOp\", _inputs_flat, _attrs, _result, name)\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     58     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n     59                                                op_name, inputs, attrs,\n---> 60                                                num_outputs)\n     61   except core._NotOkStatusException as e:\n     62     if name is not None:\n\nTypeError: provided list of inputs contains objects other than 'EagerTensor'\nTo solve this problem, I must call function which isn't decorated by tfe.defun in first forward, then switch to _eager_compiled_dynamic_rnn:\nif self._cell.built is True:\n    func = _eager_compiled_dynamic_rnn\nelse:\n    func = _eager_dynamic_rnn\noutputs, state = func(\n    self._cell,\n    inputs,\n    seq_len,\n    state,\n    dtype=self._rnn_dtype,\n    time_major=self._time_major, )\nlocate this error cost me much time. please consider to fix it.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.5.0dev20171230\r\n- **Python version**: 3.6\r\n\r\n### Describe the problem\r\nI want to use defun to speed up static rnn compute in eager:\r\n```Python\r\ndef _eager_dynamic_rnn(cell,\r\n                       inputs,\r\n                       sequence_length=None,\r\n                       initial_state=None,\r\n                       dtype=tf.float32,\r\n                       parallel_iterations=None,\r\n                       swap_memory=False,\r\n                       time_major=False,\r\n                       scope=None):\r\n    time_axis = 0 if time_major else 1\r\n    input_shape = inputs.shape.as_list()\r\n    seq_len = input_shape[time_axis]\r\n    if time_major:\r\n        batch_size = input_shape[1]\r\n    else:\r\n        batch_size = input_shape[0]\r\n    if initial_state is None:\r\n        initial_state = cell.zero_state(batch_size, dtype)\r\n    inputs = tf.unstack(inputs, num=seq_len, axis=time_axis)\r\n    outputs = []\r\n    for inp in inputs:\r\n        output, initial_state = cell(inp, initial_state)\r\n        outputs.append(output)\r\n    outputs = tf.stack(outputs, axis=time_axis)\r\n    return outputs, initial_state\r\n\r\n\r\n@tfe.defun\r\ndef _eager_compiled_dynamic_rnn(cell,\r\n                                inputs,\r\n                                sequence_length=None,\r\n                                initial_state=None,\r\n                                dtype=tf.float32,\r\n                                parallel_iterations=None,\r\n                                swap_memory=False,\r\n                                time_major=False,\r\n                                scope=None):\r\n    return _eager_dynamic_rnn(cell, inputs, sequence_length, initial_state,\r\n                              dtype, None, False, time_major, scope)\r\n```\r\nIf I directly use `_eager_compiled_dynamic_rnn` in forward, because of `tf.layers.Layer` create variables in its first __call__, then variables created in `_eager_compiled_dynamic_rnn` is invalid, if print it, get a error:\r\n```Python\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-7-308544234cc4> in <module>()\r\n      1 for var in net.variables:\r\n----> 2     print(var)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py in __repr__(self)\r\n    233       return \"<tf.Variable '%s' shape=%s dtype=%s, numpy=%s>\" % (\r\n    234           self.name, self.get_shape(), self.dtype.name,\r\n--> 235           ops.numpy_text(self.read_value(), is_repr=True))\r\n    236     else:\r\n    237       return \"<tf.Variable '%s' shape=%s dtype=%s>\" % (\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py in read_value(self)\r\n    679       # Ensure we read the variable in the same device as the handle.\r\n    680       with ops.device(self._handle_device):\r\n--> 681         value = self._read_variable_op()\r\n    682     # Return an identity so it can get placed on whatever device the context\r\n    683     # specifies instead of the device where the variable is.\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py in _read_variable_op(self)\r\n    657       tape.watch_variable(self)\r\n    658     return gen_resource_variable_ops.read_variable_op(self._handle,\r\n--> 659                                                       self._dtype)\r\n    660 \r\n    661   def read_value(self):\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py in read_variable_op(resource, dtype, name)\r\n    209     _attrs = (\"dtype\", dtype)\r\n    210     _result = _execute.execute(b\"ReadVariableOp\", 1, inputs=_inputs_flat,\r\n--> 211                                attrs=_attrs, ctx=_ctx, name=name)\r\n    212   _execute.record_gradient(\r\n    213       \"ReadVariableOp\", _inputs_flat, _attrs, _result, name)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\r\n     59                                                op_name, inputs, attrs,\r\n---> 60                                                num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nTypeError: provided list of inputs contains objects other than 'EagerTensor'\r\n```\r\nTo solve this problem, I must call function which isn't decorated by tfe.defun in first forward, then switch to `_eager_compiled_dynamic_rnn`:\r\n```Python\r\nif self._cell.built is True:\r\n    func = _eager_compiled_dynamic_rnn\r\nelse:\r\n    func = _eager_dynamic_rnn\r\noutputs, state = func(\r\n    self._cell,\r\n    inputs,\r\n    seq_len,\r\n    state,\r\n    dtype=self._rnn_dtype,\r\n    time_major=self._time_major, )\r\n```\r\nlocate this error cost me much time. please consider to fix it."}