{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347778091", "html_url": "https://github.com/tensorflow/tensorflow/issues/14936#issuecomment-347778091", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14936", "id": 347778091, "node_id": "MDEyOklzc3VlQ29tbWVudDM0Nzc3ODA5MQ==", "user": {"login": "wpj1530882136", "id": 22251910, "node_id": "MDQ6VXNlcjIyMjUxOTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/22251910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wpj1530882136", "html_url": "https://github.com/wpj1530882136", "followers_url": "https://api.github.com/users/wpj1530882136/followers", "following_url": "https://api.github.com/users/wpj1530882136/following{/other_user}", "gists_url": "https://api.github.com/users/wpj1530882136/gists{/gist_id}", "starred_url": "https://api.github.com/users/wpj1530882136/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wpj1530882136/subscriptions", "organizations_url": "https://api.github.com/users/wpj1530882136/orgs", "repos_url": "https://api.github.com/users/wpj1530882136/repos", "events_url": "https://api.github.com/users/wpj1530882136/events{/privacy}", "received_events_url": "https://api.github.com/users/wpj1530882136/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-29T07:42:29Z", "updated_at": "2017-11-29T07:42:29Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a><br>\nWe trained a rnn model using encoder-decoder framework to implement the named entity recognition and generated the pb file from model.ckpt which produced in training steps.</p>\n<p>The main code is as follows:</p>\n<pre><code>self.chars = tf.placeholder(tf.int32, [None, self.seq_len], name='chars')\nself.chars_emb = tf.nn.embedding_lookup(self.char_emb, self.chars)\nself.chars_emb = tf.transpose(self.chars_emb, [1, 0, 2])\nself.chars_emb = tf.unstack(self.chars_emb, num=self.seq_len,\n                                        name='chars_emb')\nself.sequence_length = tf.reduce_sum(tf.sign(self.chars), axis=1)\nself.encoder_outputs, self.encoder_state_fw, self.encoder_state_bw = rnn.static_bidirectional_rnn(\n                self.encoder_cell_f,\n                self.encoder_cell_b,\n                self.chars_emb,\n                dtype=tf.float32,\n                sequence_length=self.sequence_length\n            )\nself.decoder_logits= self.decoder_unroll(self.encoder_outputs,\n                                                                                self.encoder_state, self.feas_emb,\n                                                                                self.num_cls)\nself.logits = tf.transpose(self.decoder_logits, [1, 0, 2])\nself.loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.labels, name='loss')\n\n</code></pre>\n<p>So hereby\uff0cshould I rewrite the realted function as what i've mentioned above in tf-lite to make my model work? If so, that will be a huge tuffing work. And is there any suggestions, cause we want to transfer our trained model to mobile devices. Thanks in advance .</p>", "body_text": "@aselle\nWe trained a rnn model using encoder-decoder framework to implement the named entity recognition and generated the pb file from model.ckpt which produced in training steps.\nThe main code is as follows:\nself.chars = tf.placeholder(tf.int32, [None, self.seq_len], name='chars')\nself.chars_emb = tf.nn.embedding_lookup(self.char_emb, self.chars)\nself.chars_emb = tf.transpose(self.chars_emb, [1, 0, 2])\nself.chars_emb = tf.unstack(self.chars_emb, num=self.seq_len,\n                                        name='chars_emb')\nself.sequence_length = tf.reduce_sum(tf.sign(self.chars), axis=1)\nself.encoder_outputs, self.encoder_state_fw, self.encoder_state_bw = rnn.static_bidirectional_rnn(\n                self.encoder_cell_f,\n                self.encoder_cell_b,\n                self.chars_emb,\n                dtype=tf.float32,\n                sequence_length=self.sequence_length\n            )\nself.decoder_logits= self.decoder_unroll(self.encoder_outputs,\n                                                                                self.encoder_state, self.feas_emb,\n                                                                                self.num_cls)\nself.logits = tf.transpose(self.decoder_logits, [1, 0, 2])\nself.loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.labels, name='loss')\n\n\nSo hereby\uff0cshould I rewrite the realted function as what i've mentioned above in tf-lite to make my model work? If so, that will be a huge tuffing work. And is there any suggestions, cause we want to transfer our trained model to mobile devices. Thanks in advance .", "body": "@aselle \r\nWe trained a rnn model using encoder-decoder framework to implement the named entity recognition and generated the pb file from model.ckpt which produced in training steps.\r\n\r\nThe main code is as follows:\r\n```\r\nself.chars = tf.placeholder(tf.int32, [None, self.seq_len], name='chars')\r\nself.chars_emb = tf.nn.embedding_lookup(self.char_emb, self.chars)\r\nself.chars_emb = tf.transpose(self.chars_emb, [1, 0, 2])\r\nself.chars_emb = tf.unstack(self.chars_emb, num=self.seq_len,\r\n                                        name='chars_emb')\r\nself.sequence_length = tf.reduce_sum(tf.sign(self.chars), axis=1)\r\nself.encoder_outputs, self.encoder_state_fw, self.encoder_state_bw = rnn.static_bidirectional_rnn(\r\n                self.encoder_cell_f,\r\n                self.encoder_cell_b,\r\n                self.chars_emb,\r\n                dtype=tf.float32,\r\n                sequence_length=self.sequence_length\r\n            )\r\nself.decoder_logits= self.decoder_unroll(self.encoder_outputs,\r\n                                                                                self.encoder_state, self.feas_emb,\r\n                                                                                self.num_cls)\r\nself.logits = tf.transpose(self.decoder_logits, [1, 0, 2])\r\nself.loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.labels, name='loss')\r\n\r\n```\r\nSo hereby\uff0cshould I rewrite the realted function as what i've mentioned above in tf-lite to make my model work? If so, that will be a huge tuffing work. And is there any suggestions, cause we want to transfer our trained model to mobile devices. Thanks in advance .\r\n"}