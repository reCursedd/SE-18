{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/427436224", "html_url": "https://github.com/tensorflow/tensorflow/issues/22631#issuecomment-427436224", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22631", "id": 427436224, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNzQzNjIyNA==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-05T17:13:06Z", "updated_at": "2018-10-05T17:13:06Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">This definitely looks like a placer bug.\n\nCan you find a minimal example to reproduce this?</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Fri, Oct 5, 2018 at 12:30 AM Mutian He ***@***.***&gt; wrote:\n       Resource inputs force everything to run on the correct device. We can rule this out by running the code with tf.ConfigProto(log_device_placement=True) to see where the ops are executing.\n\n I do not understand though how changing the batch size can affect whether\n resources are present or not.\n\n I've enabled allow_soft_placement, and the problem only occurs when\n colocate_gradients_with_ops=True in gradients computation. So I guess this\n colocation option breaks some ops' placement?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"365196975\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/22631\" href=\"https://github.com/tensorflow/tensorflow/issues/22631#issuecomment-427270497\">#22631 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAATxUWBOsAELwIWxkBRGWvtxPhhDNJrks5uhwp8gaJpZM4XA1f2\">https://github.com/notifications/unsubscribe-auth/AAATxUWBOsAELwIWxkBRGWvtxPhhDNJrks5uhwp8gaJpZM4XA1f2</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \n - Alex</div>\n</div>", "body_text": "This definitely looks like a placer bug.\n\nCan you find a minimal example to reproduce this?\n\u2026\nOn Fri, Oct 5, 2018 at 12:30 AM Mutian He ***@***.***> wrote:\n       Resource inputs force everything to run on the correct device. We can rule this out by running the code with tf.ConfigProto(log_device_placement=True) to see where the ops are executing.\n\n I do not understand though how changing the batch size can affect whether\n resources are present or not.\n\n I've enabled allow_soft_placement, and the problem only occurs when\n colocate_gradients_with_ops=True in gradients computation. So I guess this\n colocation option breaks some ops' placement?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#22631 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AAATxUWBOsAELwIWxkBRGWvtxPhhDNJrks5uhwp8gaJpZM4XA1f2>\n .\n\n\n-- \n - Alex", "body": "This definitely looks like a placer bug.\n\nCan you find a minimal example to reproduce this?\n\nOn Fri, Oct 5, 2018 at 12:30 AM Mutian He <notifications@github.com> wrote:\n\n>       Resource inputs force everything to run on the correct device. We can rule this out by running the code with tf.ConfigProto(log_device_placement=True) to see where the ops are executing.\n>\n> I do not understand though how changing the batch size can affect whether\n> resources are present or not.\n>\n> I've enabled allow_soft_placement, and the problem only occurs when\n> colocate_gradients_with_ops=True in gradients computation. So I guess this\n> colocation option breaks some ops' placement?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22631#issuecomment-427270497>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxUWBOsAELwIWxkBRGWvtxPhhDNJrks5uhwp8gaJpZM4XA1f2>\n> .\n>\n\n\n-- \n - Alex\n"}