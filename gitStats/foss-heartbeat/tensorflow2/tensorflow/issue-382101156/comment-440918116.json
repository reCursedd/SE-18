{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/440918116", "html_url": "https://github.com/tensorflow/tensorflow/issues/23846#issuecomment-440918116", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23846", "id": 440918116, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDkxODExNg==", "user": {"login": "formath", "id": 6040127, "node_id": "MDQ6VXNlcjYwNDAxMjc=", "avatar_url": "https://avatars3.githubusercontent.com/u/6040127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/formath", "html_url": "https://github.com/formath", "followers_url": "https://api.github.com/users/formath/followers", "following_url": "https://api.github.com/users/formath/following{/other_user}", "gists_url": "https://api.github.com/users/formath/gists{/gist_id}", "starred_url": "https://api.github.com/users/formath/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/formath/subscriptions", "organizations_url": "https://api.github.com/users/formath/orgs", "repos_url": "https://api.github.com/users/formath/repos", "events_url": "https://api.github.com/users/formath/events{/privacy}", "received_events_url": "https://api.github.com/users/formath/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-22T05:35:10Z", "updated_at": "2018-11-22T08:12:28Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a></p>\n<ul>\n<li>If setting</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre>server_config <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">inter_op_parallelism_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n                               <span class=\"pl-v\">intra_op_parallelism_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n<span class=\"pl-c1\">self</span>.server <span class=\"pl-k\">=</span> tf.train.Server(<span class=\"pl-c1\">self</span>.cluster, <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.job_name,\n                              <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.task_index, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>server_config)</pre></div>\n<p>or set <code>ps</code> num 1, the problem disappear. I reproduced it using <code>inter_op_parallelism_threads=16,intra_op_parallelism_threads=16</code> and <code>ps</code> num 5. <code>worker_2</code> hangs.<br>\nFull pstack (Sorry for so many threads):<br>\nps_0: <a href=\"https://github.com/formath/TensorFlow-Bugs/blob/master/ps0.pstack\">https://github.com/formath/TensorFlow-Bugs/blob/master/ps0.pstack</a><br>\nps_1: <a href=\"https://github.com/formath/TensorFlow-Bugs/blob/master/ps1.pstack\">https://github.com/formath/TensorFlow-Bugs/blob/master/ps1.pstack</a><br>\nps_2: <a href=\"https://github.com/formath/TensorFlow-Bugs/blob/master/ps2.pstack\">https://github.com/formath/TensorFlow-Bugs/blob/master/ps2.pstack</a><br>\nps_3: <a href=\"https://github.com/formath/TensorFlow-Bugs/blob/master/ps3.pstack\">https://github.com/formath/TensorFlow-Bugs/blob/master/ps3.pstack</a><br>\nps_4: <a href=\"https://github.com/formath/TensorFlow-Bugs/blob/master/ps4.pstack\">https://github.com/formath/TensorFlow-Bugs/blob/master/ps4.pstack</a><br>\nblocked worker_2: <a href=\"https://github.com/formath/TensorFlow-Bugs/blob/master/worker2.pstack\">https://github.com/formath/TensorFlow-Bugs/blob/master/worker2.pstack</a><br>\nchief worker: <a href=\"https://github.com/formath/TensorFlow-Bugs/blob/master/worker0.pstack\">https://github.com/formath/TensorFlow-Bugs/blob/master/worker0.pstack</a></p>\n<p>I also tested other configuration combinations and found only when setting both <code>inter_op_parallelism_threads</code> and num of <code>ps</code> bigger than 1, the problem occur. <code>intra_op_parallelism_threads</code> has no relationship with this problem.</p>\n<ul>\n<li>About <code>self.data_iter()</code>, I prefetch data from hdfs to the <code>worker</code> nodes. Worker nodes will load data from local disk so <code>ps</code> nodes have no relationship with data reading.</li>\n</ul>\n<pre><code>2018-11-22 14:20:26.003705: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/MatchingFiles: (MatchingFiles)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003748: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Shape: (Shape)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003784: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/strided_slice: (StridedSlice)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003790: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/match_not_empty: (Greater)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003796: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/ReduceJoin: (ReduceJoin)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003801: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/message: (Add)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003806: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/assert_not_empty/Assert: (Assert)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003812: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Identity: (Identity)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003829: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Shape_1: (Shape)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003834: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/strided_slice_1: (StridedSlice)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003840: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Maximum: (Maximum)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003845: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/Equal: (Equal)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003850: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/Equal_1: (Equal)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003855: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/LogicalAnd: (LogicalAnd)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003860: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2: (Select)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003867: I tensorflow/core/common_runtime/placer.cc:949] input/TensorSliceDataset: (TensorSliceDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003872: I tensorflow/core/common_runtime/placer.cc:949] input/ShuffleDataset: (ShuffleDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003878: I tensorflow/core/common_runtime/placer.cc:949] input/ParallelInterleaveDataset: (ParallelInterleaveDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003883: I tensorflow/core/common_runtime/placer.cc:949] input/PrefetchDataset: (PrefetchDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003888: I tensorflow/core/common_runtime/placer.cc:949] input/BatchDatasetV2: (BatchDatasetV2)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003893: I tensorflow/core/common_runtime/placer.cc:949] input/ParallelMapDataset: (ParallelMapDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003898: I tensorflow/core/common_runtime/placer.cc:949] input/MakeIterator: (MakeIterator)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003903: I tensorflow/core/common_runtime/placer.cc:949] input/IteratorToStringHandle: (IteratorToStringHandle)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003908: I tensorflow/core/common_runtime/placer.cc:949] IteratorGetNext: (IteratorGetNext)/job:worker/replica:0/task:1/device:CPU:0\n</code></pre>", "body_text": "@mrry\n\nIf setting\n\nserver_config = tf.ConfigProto(inter_op_parallelism_threads=1,\n                               intra_op_parallelism_threads=1)\nself.server = tf.train.Server(self.cluster, job_name=self.job_name,\n                              task_index=self.task_index, config=server_config)\nor set ps num 1, the problem disappear. I reproduced it using inter_op_parallelism_threads=16,intra_op_parallelism_threads=16 and ps num 5. worker_2 hangs.\nFull pstack (Sorry for so many threads):\nps_0: https://github.com/formath/TensorFlow-Bugs/blob/master/ps0.pstack\nps_1: https://github.com/formath/TensorFlow-Bugs/blob/master/ps1.pstack\nps_2: https://github.com/formath/TensorFlow-Bugs/blob/master/ps2.pstack\nps_3: https://github.com/formath/TensorFlow-Bugs/blob/master/ps3.pstack\nps_4: https://github.com/formath/TensorFlow-Bugs/blob/master/ps4.pstack\nblocked worker_2: https://github.com/formath/TensorFlow-Bugs/blob/master/worker2.pstack\nchief worker: https://github.com/formath/TensorFlow-Bugs/blob/master/worker0.pstack\nI also tested other configuration combinations and found only when setting both inter_op_parallelism_threads and num of ps bigger than 1, the problem occur. intra_op_parallelism_threads has no relationship with this problem.\n\nAbout self.data_iter(), I prefetch data from hdfs to the worker nodes. Worker nodes will load data from local disk so ps nodes have no relationship with data reading.\n\n2018-11-22 14:20:26.003705: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/MatchingFiles: (MatchingFiles)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003748: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Shape: (Shape)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003784: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/strided_slice: (StridedSlice)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003790: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/match_not_empty: (Greater)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003796: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/ReduceJoin: (ReduceJoin)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003801: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/message: (Add)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003806: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/assert_not_empty/Assert: (Assert)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003812: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Identity: (Identity)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003829: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Shape_1: (Shape)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003834: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/strided_slice_1: (StridedSlice)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003840: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Maximum: (Maximum)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003845: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/Equal: (Equal)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003850: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/Equal_1: (Equal)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003855: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/LogicalAnd: (LogicalAnd)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003860: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2: (Select)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003867: I tensorflow/core/common_runtime/placer.cc:949] input/TensorSliceDataset: (TensorSliceDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003872: I tensorflow/core/common_runtime/placer.cc:949] input/ShuffleDataset: (ShuffleDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003878: I tensorflow/core/common_runtime/placer.cc:949] input/ParallelInterleaveDataset: (ParallelInterleaveDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003883: I tensorflow/core/common_runtime/placer.cc:949] input/PrefetchDataset: (PrefetchDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003888: I tensorflow/core/common_runtime/placer.cc:949] input/BatchDatasetV2: (BatchDatasetV2)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003893: I tensorflow/core/common_runtime/placer.cc:949] input/ParallelMapDataset: (ParallelMapDataset)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003898: I tensorflow/core/common_runtime/placer.cc:949] input/MakeIterator: (MakeIterator)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003903: I tensorflow/core/common_runtime/placer.cc:949] input/IteratorToStringHandle: (IteratorToStringHandle)/job:worker/replica:0/task:1/device:CPU:0\n2018-11-22 14:20:26.003908: I tensorflow/core/common_runtime/placer.cc:949] IteratorGetNext: (IteratorGetNext)/job:worker/replica:0/task:1/device:CPU:0", "body": "@mrry\r\n* If setting\r\n```python\r\nserver_config = tf.ConfigProto(inter_op_parallelism_threads=1,\r\n                               intra_op_parallelism_threads=1)\r\nself.server = tf.train.Server(self.cluster, job_name=self.job_name,\r\n                              task_index=self.task_index, config=server_config)\r\n```\r\nor set `ps` num 1, the problem disappear. I reproduced it using `inter_op_parallelism_threads=16,intra_op_parallelism_threads=16` and `ps` num 5. `worker_2` hangs.\r\nFull pstack (Sorry for so many threads):\r\nps_0: https://github.com/formath/TensorFlow-Bugs/blob/master/ps0.pstack\r\nps_1: https://github.com/formath/TensorFlow-Bugs/blob/master/ps1.pstack\r\nps_2: https://github.com/formath/TensorFlow-Bugs/blob/master/ps2.pstack\r\nps_3: https://github.com/formath/TensorFlow-Bugs/blob/master/ps3.pstack\r\nps_4: https://github.com/formath/TensorFlow-Bugs/blob/master/ps4.pstack\r\nblocked worker_2: https://github.com/formath/TensorFlow-Bugs/blob/master/worker2.pstack\r\nchief worker: https://github.com/formath/TensorFlow-Bugs/blob/master/worker0.pstack\r\n\r\nI also tested other configuration combinations and found only when setting both `inter_op_parallelism_threads` and num of `ps` bigger than 1, the problem occur. `intra_op_parallelism_threads` has no relationship with this problem.\r\n\r\n* About `self.data_iter()`, I prefetch data from hdfs to the `worker` nodes. Worker nodes will load data from local disk so `ps` nodes have no relationship with data reading.\r\n```\r\n2018-11-22 14:20:26.003705: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/MatchingFiles: (MatchingFiles)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003748: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Shape: (Shape)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003784: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/strided_slice: (StridedSlice)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003790: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/match_not_empty: (Greater)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003796: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/ReduceJoin: (ReduceJoin)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003801: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/message: (Add)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003806: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/assert_not_empty/Assert: (Assert)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003812: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Identity: (Identity)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003829: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Shape_1: (Shape)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003834: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/strided_slice_1: (StridedSlice)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003840: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Maximum: (Maximum)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003845: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/Equal: (Equal)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003850: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/Equal_1: (Equal)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003855: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/LogicalAnd: (LogicalAnd)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003860: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2: (Select)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003867: I tensorflow/core/common_runtime/placer.cc:949] input/TensorSliceDataset: (TensorSliceDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003872: I tensorflow/core/common_runtime/placer.cc:949] input/ShuffleDataset: (ShuffleDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003878: I tensorflow/core/common_runtime/placer.cc:949] input/ParallelInterleaveDataset: (ParallelInterleaveDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003883: I tensorflow/core/common_runtime/placer.cc:949] input/PrefetchDataset: (PrefetchDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003888: I tensorflow/core/common_runtime/placer.cc:949] input/BatchDatasetV2: (BatchDatasetV2)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003893: I tensorflow/core/common_runtime/placer.cc:949] input/ParallelMapDataset: (ParallelMapDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003898: I tensorflow/core/common_runtime/placer.cc:949] input/MakeIterator: (MakeIterator)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003903: I tensorflow/core/common_runtime/placer.cc:949] input/IteratorToStringHandle: (IteratorToStringHandle)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003908: I tensorflow/core/common_runtime/placer.cc:949] IteratorGetNext: (IteratorGetNext)/job:worker/replica:0/task:1/device:CPU:0\r\n```\r\n"}