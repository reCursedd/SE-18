{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13773", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13773/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13773/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13773/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13773", "id": 266016973, "node_id": "MDU6SXNzdWUyNjYwMTY5NzM=", "number": 13773, "title": "ERROR:tensorflow:Exception in QueueRunner: truncated record at 935047", "user": {"login": "wengqi123", "id": 29939401, "node_id": "MDQ6VXNlcjI5OTM5NDAx", "avatar_url": "https://avatars1.githubusercontent.com/u/29939401?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wengqi123", "html_url": "https://github.com/wengqi123", "followers_url": "https://api.github.com/users/wengqi123/followers", "following_url": "https://api.github.com/users/wengqi123/following{/other_user}", "gists_url": "https://api.github.com/users/wengqi123/gists{/gist_id}", "starred_url": "https://api.github.com/users/wengqi123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wengqi123/subscriptions", "organizations_url": "https://api.github.com/users/wengqi123/orgs", "repos_url": "https://api.github.com/users/wengqi123/repos", "events_url": "https://api.github.com/users/wengqi123/events{/privacy}", "received_events_url": "https://api.github.com/users/wengqi123/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-10-17T07:16:13Z", "updated_at": "2018-01-04T19:28:52Z", "closed_at": "2018-01-04T19:28:52Z", "author_association": "NONE", "body_html": "<pre><code>###########################small data train, train_step code:\ndef run_train():\n    with tf.Graph().as_default():\n        global_step = tf.Variable(0, trainable=False)\n        images,labels=read_and_decode('./dog_train')\n        images_batch,labels_batch = add_batch(images,labels,5,5)\n        softmax_linear = cnn_model(images_batch)\n        loss = loss(softmax_linear, labels_batch)\n        train_op = train(loss, global_step)\n        saver = tf.train.Saver(tf.global_variables())\n        summary_op = tf.summary.merge_all()\n        init = tf.global_variables_initializer()\n        sess = tf.Session(config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement))\n        sess.run(init)\n        tf.train.start_queue_runners(sess=sess)\n        summary_writer = tf.summary.FileWriter(FLAGS.train_dir,graph=sess.graph)\n        for step in xrange(FLAGS.max_steps):\n            start_time = time.time()\n            _, loss_value = sess.run([train_op, loss])\n            duration = time.time() - start_time\n            assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n            if step % 10 == 0:\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f ''sec/batch)')\n                print(format_str % (datetime.now(), step, loss_value,examples_per_sec, sec_per_batch))\n            if step % 100 == 0:\n                summary_str = sess.run(summary_op)\n                summary_writer.add_summary(summary_str, step)\n            if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n                checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n                saver.save(sess,checkpoint_path, global_step=step)\n#######################################and ERROR:\n2017-10-17 15:08:31.510128: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x46f9230\nERROR:tensorflow:Exception in QueueRunner: truncated record at 935047\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\t [[Node: DecodeRaw/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_17_DecodeRaw\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\nException in thread Thread-3:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 237, in _run\n    enqueue_callable()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1060, in _single_operation_run\n    target_list_as_strings, status, None)\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n    self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\nDataLossError: truncated record at 935047\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\t [[Node: DecodeRaw/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_17_DecodeRaw\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nERROR:tensorflow:Exception in QueueRunner: truncated record at 935047\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\nException in thread Thread-2:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 237, in _run\n    enqueue_callable()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1060, in _single_operation_run\n    target_list_as_strings, status, None)\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n    self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\nDataLossError: truncated record at 935047\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\n2017-10-17 15:08:49.270117: step 0, loss = 21.79 (0.6 examples/sec; 8.205 sec/batch)\n ############ here stop \n</code></pre>\n<p>so,why this errors ?</p>", "body_text": "###########################small data train, train_step code:\ndef run_train():\n    with tf.Graph().as_default():\n        global_step = tf.Variable(0, trainable=False)\n        images,labels=read_and_decode('./dog_train')\n        images_batch,labels_batch = add_batch(images,labels,5,5)\n        softmax_linear = cnn_model(images_batch)\n        loss = loss(softmax_linear, labels_batch)\n        train_op = train(loss, global_step)\n        saver = tf.train.Saver(tf.global_variables())\n        summary_op = tf.summary.merge_all()\n        init = tf.global_variables_initializer()\n        sess = tf.Session(config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement))\n        sess.run(init)\n        tf.train.start_queue_runners(sess=sess)\n        summary_writer = tf.summary.FileWriter(FLAGS.train_dir,graph=sess.graph)\n        for step in xrange(FLAGS.max_steps):\n            start_time = time.time()\n            _, loss_value = sess.run([train_op, loss])\n            duration = time.time() - start_time\n            assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n            if step % 10 == 0:\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f ''sec/batch)')\n                print(format_str % (datetime.now(), step, loss_value,examples_per_sec, sec_per_batch))\n            if step % 100 == 0:\n                summary_str = sess.run(summary_op)\n                summary_writer.add_summary(summary_str, step)\n            if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n                checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n                saver.save(sess,checkpoint_path, global_step=step)\n#######################################and ERROR:\n2017-10-17 15:08:31.510128: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x46f9230\nERROR:tensorflow:Exception in QueueRunner: truncated record at 935047\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\t [[Node: DecodeRaw/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_17_DecodeRaw\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\nException in thread Thread-3:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 237, in _run\n    enqueue_callable()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1060, in _single_operation_run\n    target_list_as_strings, status, None)\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n    self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\nDataLossError: truncated record at 935047\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\t [[Node: DecodeRaw/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_17_DecodeRaw\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nERROR:tensorflow:Exception in QueueRunner: truncated record at 935047\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\nException in thread Thread-2:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 237, in _run\n    enqueue_callable()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1060, in _single_operation_run\n    target_list_as_strings, status, None)\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n    self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\nDataLossError: truncated record at 935047\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\n2017-10-17 15:08:49.270117: step 0, loss = 21.79 (0.6 examples/sec; 8.205 sec/batch)\n ############ here stop \n\nso,why this errors ?", "body": "```\r\n###########################small data train, train_step code:\r\ndef run_train():\r\n    with tf.Graph().as_default():\r\n        global_step = tf.Variable(0, trainable=False)\r\n        images,labels=read_and_decode('./dog_train')\r\n        images_batch,labels_batch = add_batch(images,labels,5,5)\r\n        softmax_linear = cnn_model(images_batch)\r\n        loss = loss(softmax_linear, labels_batch)\r\n        train_op = train(loss, global_step)\r\n        saver = tf.train.Saver(tf.global_variables())\r\n        summary_op = tf.summary.merge_all()\r\n        init = tf.global_variables_initializer()\r\n        sess = tf.Session(config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement))\r\n        sess.run(init)\r\n        tf.train.start_queue_runners(sess=sess)\r\n        summary_writer = tf.summary.FileWriter(FLAGS.train_dir,graph=sess.graph)\r\n        for step in xrange(FLAGS.max_steps):\r\n            start_time = time.time()\r\n            _, loss_value = sess.run([train_op, loss])\r\n            duration = time.time() - start_time\r\n            assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\r\n            if step % 10 == 0:\r\n                num_examples_per_step = FLAGS.batch_size\r\n                examples_per_sec = num_examples_per_step / duration\r\n                sec_per_batch = float(duration)\r\n\r\n                format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f ''sec/batch)')\r\n                print(format_str % (datetime.now(), step, loss_value,examples_per_sec, sec_per_batch))\r\n            if step % 100 == 0:\r\n                summary_str = sess.run(summary_op)\r\n                summary_writer.add_summary(summary_str, step)\r\n            if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\r\n                checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\r\n                saver.save(sess,checkpoint_path, global_step=step)\r\n#######################################and ERROR:\r\n2017-10-17 15:08:31.510128: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x46f9230\r\nERROR:tensorflow:Exception in QueueRunner: truncated record at 935047\r\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\r\n\t [[Node: DecodeRaw/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_17_DecodeRaw\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 237, in _run\r\n    enqueue_callable()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1060, in _single_operation_run\r\n    target_list_as_strings, status, None)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nDataLossError: truncated record at 935047\r\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\r\n\t [[Node: DecodeRaw/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_17_DecodeRaw\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nERROR:tensorflow:Exception in QueueRunner: truncated record at 935047\r\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 237, in _run\r\n    enqueue_callable()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1060, in _single_operation_run\r\n    target_list_as_strings, status, None)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nDataLossError: truncated record at 935047\r\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\r\n\r\n2017-10-17 15:08:49.270117: step 0, loss = 21.79 (0.6 examples/sec; 8.205 sec/batch)\r\n ############ here stop \r\n```\r\nso,why this errors ?\r\n\r\n\r\n"}