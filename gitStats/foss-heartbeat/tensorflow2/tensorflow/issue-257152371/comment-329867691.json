{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/329867691", "html_url": "https://github.com/tensorflow/tensorflow/issues/13002#issuecomment-329867691", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13002", "id": 329867691, "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTg2NzY5MQ==", "user": {"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-15T18:44:05Z", "updated_at": "2017-09-15T18:44:05Z", "author_association": "NONE", "body_html": "<p>You're quite right that the Udacity slides and the code in the ipynb don't match up exactly. But I don't think it matters for educational purposes.</p>\n<p>I think there are two points in what Vincent is saying:</p>\n<ol>\n<li>Having a zero mean makes it easier for the optimizer to work.</li>\n<li>Normalizing different axes to have the same scale (so circular, or standard deviations, rather than oval, as shown in slides) also makes it easier for the optimizer to work.</li>\n</ol>\n<p>I think the code gets both right. The -128 moves the mean of the [0,255] image data close to zero.<br>\nThe /255 rescales so that values will be in the range [-.5,.5]. The formulas that Vincent showed would have scaled to [-1,1]. But as long as everything rescales to the same ranges (so you get circularity across dimensions, not ovals), then the optimizer will still have an easier time. It's not the absolute magnitude of the rescaling that matters; it's the relative scales across the dimensions.</p>\n<p>Not sure if the course has gotten to batch normalization at this point, but that strives to rescale a standard deviation to have value about 1.0. Then you don't know the absolute max/min bounds, but you do have some statistical beliefs that your data are now spread out similarly in multiple dimensions.</p>\n<p>Does that make sense? <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15737127\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vincentvanhoucke\">@vincentvanhoucke</a>, feel free to amend or comment, but I'll close for now.</p>", "body_text": "You're quite right that the Udacity slides and the code in the ipynb don't match up exactly. But I don't think it matters for educational purposes.\nI think there are two points in what Vincent is saying:\n\nHaving a zero mean makes it easier for the optimizer to work.\nNormalizing different axes to have the same scale (so circular, or standard deviations, rather than oval, as shown in slides) also makes it easier for the optimizer to work.\n\nI think the code gets both right. The -128 moves the mean of the [0,255] image data close to zero.\nThe /255 rescales so that values will be in the range [-.5,.5]. The formulas that Vincent showed would have scaled to [-1,1]. But as long as everything rescales to the same ranges (so you get circularity across dimensions, not ovals), then the optimizer will still have an easier time. It's not the absolute magnitude of the rescaling that matters; it's the relative scales across the dimensions.\nNot sure if the course has gotten to batch normalization at this point, but that strives to rescale a standard deviation to have value about 1.0. Then you don't know the absolute max/min bounds, but you do have some statistical beliefs that your data are now spread out similarly in multiple dimensions.\nDoes that make sense? @vincentvanhoucke, feel free to amend or comment, but I'll close for now.", "body": "You're quite right that the Udacity slides and the code in the ipynb don't match up exactly. But I don't think it matters for educational purposes. \r\n\r\nI think there are two points in what Vincent is saying:\r\n1. Having a zero mean makes it easier for the optimizer to work. \r\n2. Normalizing different axes to have the same scale (so circular, or standard deviations, rather than oval, as shown in slides) also makes it easier for the optimizer to work. \r\n\r\nI think the code gets both right. The -128 moves the mean of the [0,255] image data close to zero. \r\nThe /255 rescales so that values will be in the range [-.5,.5]. The formulas that Vincent showed would have scaled to [-1,1]. But as long as everything rescales to the same ranges (so you get circularity across dimensions, not ovals), then the optimizer will still have an easier time. It's not the absolute magnitude of the rescaling that matters; it's the relative scales across the dimensions. \r\n\r\nNot sure if the course has gotten to batch normalization at this point, but that strives to rescale a standard deviation to have value about 1.0. Then you don't know the absolute max/min bounds, but you do have some statistical beliefs that your data are now spread out similarly in multiple dimensions. \r\n\r\nDoes that make sense? @vincentvanhoucke, feel free to amend or comment, but I'll close for now. "}