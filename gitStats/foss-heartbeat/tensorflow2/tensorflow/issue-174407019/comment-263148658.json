{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263148658", "html_url": "https://github.com/tensorflow/tensorflow/issues/4138#issuecomment-263148658", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4138", "id": 263148658, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MzE0ODY1OA==", "user": {"login": "vince62s", "id": 15141326, "node_id": "MDQ6VXNlcjE1MTQxMzI2", "avatar_url": "https://avatars3.githubusercontent.com/u/15141326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vince62s", "html_url": "https://github.com/vince62s", "followers_url": "https://api.github.com/users/vince62s/followers", "following_url": "https://api.github.com/users/vince62s/following{/other_user}", "gists_url": "https://api.github.com/users/vince62s/gists{/gist_id}", "starred_url": "https://api.github.com/users/vince62s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vince62s/subscriptions", "organizations_url": "https://api.github.com/users/vince62s/orgs", "repos_url": "https://api.github.com/users/vince62s/repos", "events_url": "https://api.github.com/users/vince62s/events{/privacy}", "received_events_url": "https://api.github.com/users/vince62s/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-27T21:25:12Z", "updated_at": "2016-11-27T21:25:12Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1544039\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cloudygoose\">@cloudygoose</a> I am doing the same thing for a proper sampled_softmax performance.<br>\nit works fine for training.<br>\nHowever, a testing time, with num_steps=1 and bat_size=1, it make a huge loop with a tf.transpose for each iter (ie word) which makes it very slow.<br>\nHow can we avoid to execute this transpose so many times at test time ?</p>", "body_text": "@cloudygoose I am doing the same thing for a proper sampled_softmax performance.\nit works fine for training.\nHowever, a testing time, with num_steps=1 and bat_size=1, it make a huge loop with a tf.transpose for each iter (ie word) which makes it very slow.\nHow can we avoid to execute this transpose so many times at test time ?", "body": "@cloudygoose I am doing the same thing for a proper sampled_softmax performance.\r\nit works fine for training.\r\nHowever, a testing time, with num_steps=1 and bat_size=1, it make a huge loop with a tf.transpose for each iter (ie word) which makes it very slow.\r\nHow can we avoid to execute this transpose so many times at test time ?\r\n"}