{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21188", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21188/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21188/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21188/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21188", "id": 345260800, "node_id": "MDU6SXNzdWUzNDUyNjA4MDA=", "number": 21188, "title": "TypeError: Cannot interpret feed_dict key as Tensor: Can not convert a NoneType into a Tensor.", "user": {"login": "ECE-Engineer", "id": 11876419, "node_id": "MDQ6VXNlcjExODc2NDE5", "avatar_url": "https://avatars2.githubusercontent.com/u/11876419?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ECE-Engineer", "html_url": "https://github.com/ECE-Engineer", "followers_url": "https://api.github.com/users/ECE-Engineer/followers", "following_url": "https://api.github.com/users/ECE-Engineer/following{/other_user}", "gists_url": "https://api.github.com/users/ECE-Engineer/gists{/gist_id}", "starred_url": "https://api.github.com/users/ECE-Engineer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ECE-Engineer/subscriptions", "organizations_url": "https://api.github.com/users/ECE-Engineer/orgs", "repos_url": "https://api.github.com/users/ECE-Engineer/repos", "events_url": "https://api.github.com/users/ECE-Engineer/events{/privacy}", "received_events_url": "https://api.github.com/users/ECE-Engineer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-07-27T15:03:34Z", "updated_at": "2018-08-03T22:44:56Z", "closed_at": "2018-08-03T22:44:56Z", "author_association": "NONE", "body_html": "<p>Error:<br>\n/usr/lib64/python3.6/site-packages/h5py/<strong>init</strong>.py:34: FutureWarning: Conversion of the second argument of issubdtype from <code>float</code> to <code>np.floating</code> is deprecated. In future, it will be treated as <code>np.float64 == np.dtype(float).type</code>.<br>\nfrom ._conv import register_converters as _register_converters<br>\n2018-07-27 08:35:51.967246: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: FMA<br>\nTraceback (most recent call last):<br>\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1075, in _run<br>\nsubfeed, allow_tensor=True, allow_operation=False)<br>\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3590, in as_graph_element<br>\nreturn self._as_graph_element_locked(obj, allow_tensor, allow_operation)<br>\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3679, in _as_graph_element_locked<br>\ntypes_str))<br>\nTypeError: Can not convert a NoneType into a Tensor.</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"--------------.py\", line 397, in <br>\ntf.app.run(main=main, argv=[sys.argv[0]] + unparsed)<br>\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 126, in run<br>\n_sys.exit(main(argv))<br>\nFile \"---------------------.py\", line 88, in main<br>\nprint(prediction(e))<br>\nFile \"---------------------.py\", line 361, in prediction<br>\nmodel_prediction = sess.run(pred_label, feed_dict={x: subject_npy, y: y_const_npy, keep_prob: 1.0})<br>\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 900, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1078, in _run<br>\n'Cannot interpret feed_dict key as Tensor: ' + e.args[0])<br>\nTypeError: Cannot interpret feed_dict key as Tensor: Can not convert a NoneType into a Tensor.</p>\n<hr>\n<p>I've tried what some stackoverflow posts recommended, e.g. keeping the feed_dict placeholder names as x and y, when either saving &amp; restoring the graph or just making new placeholders.</p>\n<p>My objective: I'm trying to restore and run an lstm.</p>\n<h2>My code:<br>\n\"\"\"setup for training-------(no issue with training)\"\"\"<br>\nout_weights = tf.Variable(tf.random_normal([num_units,n_classes]), name = \"out_weights\")<br>\nout_bias = tf.Variable(tf.random_normal([n_classes]), name = \"out_bias\")<br>\nx = tf.placeholder(\"float\",[None,time_steps,n_input])<br>\ny = tf.placeholder(\"float\",[None,n_classes])<br>\nkeep_prob = tf.placeholder(\"float\", shape=())<br>\ninput = tf.unstack(x ,time_steps,1, name = \"inputs\")<br>\nlstm_layer = rnn.BasicLSTMCell(num_units,forget_bias=1)<br>\noutputs, _ = rnn.static_rnn(lstm_layer,input,dtype=\"float32\")<br>\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))<br>\ntf.summary.scalar('cross_entrophy', loss)<br>\nopt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)<br>\npred_label = tf.argmax(prediction,1)<br>\nactual_label = tf.argmax(y,1)<br>\ncorrect_prediction = tf.equal(pred_label, actual_label)<br>\naccuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))<br>\nwith tf.Session() as sess:<br>\nsess.run(tf.global_variables_initializer())<br>\nsaver = tf.train.Saver()<br>\nfor i in range(N):<br>\nsess.run(, feed_dict = {x: batch[0], y: batch[1], keep_prob: 0.5})<br>\nif i%100==0:<br>\nsaver.save(sess, \"path/model.ckpt\")</h2>\n<p>\"\"\"LOADING  lstm\"\"\"<br>\nwith tf.Session() as sess:<br>\nfrom_saver = tf.train.import_meta_graph('path/model.ckpt.meta')<br>\nfrom_saver.restore(sess, tf.train.latest_checkpoint('path_to_summaries_dir'))<br>\nlstm_graph = tf.get_default_graph()<br>\nout_weights = lstm_graph.get_tensor_by_name(\"out_weights:0\")<br>\nout_bias = lstm_graph.get_tensor_by_name(\"out_bias:0\")<br>\nx = tf.placeholder(\"float\",[time_steps,n_input])<br>\ny = tf.placeholder(\"float\",[n_classes])<br>\nkeep_prob = keep_prob = tf.placeholder(\"float\", shape=())<br>\ninputs = lstm_graph.get_tensor_by_name(\"inputs:0\")<br>\nprediction = lstm_graph.get_tensor_by_name(\"prediction:0\") + out_bias<br>\npred_label = tf.argmax(prediction,1)</p>\n<p>\"\"\"RUNNING MODEL\"\"\"<br>\nwith tf.Session(graph=lstm_graph) as sess:<br>\nsess.run(tf.global_variables_initializer())<br>\nmodel_prediction = sess.run(pred_label, feed_dict={x: subject_npy, y: y_const_npy, keep_prob: 1.0})</p>\n<hr>\n<p>Have I written custom code:   yes<br>\nOS Platform and Distribution:    centos 6<br>\nTensorFlow installed from:    pip3<br>\nTensorFlow version:    v1.9<br>\nBazel version:    N/A<br>\nCUDA/cuDNN version:    N/A<br>\nGPU model and memory:    N/A<br>\nExact command to reproduce:    N/A<br>\nMobile device:    N/A</p>", "body_text": "Error:\n/usr/lib64/python3.6/site-packages/h5py/init.py:34: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.\nfrom ._conv import register_converters as _register_converters\n2018-07-27 08:35:51.967246: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: FMA\nTraceback (most recent call last):\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1075, in _run\nsubfeed, allow_tensor=True, allow_operation=False)\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3590, in as_graph_element\nreturn self._as_graph_element_locked(obj, allow_tensor, allow_operation)\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3679, in _as_graph_element_locked\ntypes_str))\nTypeError: Can not convert a NoneType into a Tensor.\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"--------------.py\", line 397, in \ntf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 126, in run\n_sys.exit(main(argv))\nFile \"---------------------.py\", line 88, in main\nprint(prediction(e))\nFile \"---------------------.py\", line 361, in prediction\nmodel_prediction = sess.run(pred_label, feed_dict={x: subject_npy, y: y_const_npy, keep_prob: 1.0})\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 900, in run\nrun_metadata_ptr)\nFile \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1078, in _run\n'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\nTypeError: Cannot interpret feed_dict key as Tensor: Can not convert a NoneType into a Tensor.\n\nI've tried what some stackoverflow posts recommended, e.g. keeping the feed_dict placeholder names as x and y, when either saving & restoring the graph or just making new placeholders.\nMy objective: I'm trying to restore and run an lstm.\nMy code:\n\"\"\"setup for training-------(no issue with training)\"\"\"\nout_weights = tf.Variable(tf.random_normal([num_units,n_classes]), name = \"out_weights\")\nout_bias = tf.Variable(tf.random_normal([n_classes]), name = \"out_bias\")\nx = tf.placeholder(\"float\",[None,time_steps,n_input])\ny = tf.placeholder(\"float\",[None,n_classes])\nkeep_prob = tf.placeholder(\"float\", shape=())\ninput = tf.unstack(x ,time_steps,1, name = \"inputs\")\nlstm_layer = rnn.BasicLSTMCell(num_units,forget_bias=1)\noutputs, _ = rnn.static_rnn(lstm_layer,input,dtype=\"float32\")\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\ntf.summary.scalar('cross_entrophy', loss)\nopt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\npred_label = tf.argmax(prediction,1)\nactual_label = tf.argmax(y,1)\ncorrect_prediction = tf.equal(pred_label, actual_label)\naccuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\nwith tf.Session() as sess:\nsess.run(tf.global_variables_initializer())\nsaver = tf.train.Saver()\nfor i in range(N):\nsess.run(, feed_dict = {x: batch[0], y: batch[1], keep_prob: 0.5})\nif i%100==0:\nsaver.save(sess, \"path/model.ckpt\")\n\"\"\"LOADING  lstm\"\"\"\nwith tf.Session() as sess:\nfrom_saver = tf.train.import_meta_graph('path/model.ckpt.meta')\nfrom_saver.restore(sess, tf.train.latest_checkpoint('path_to_summaries_dir'))\nlstm_graph = tf.get_default_graph()\nout_weights = lstm_graph.get_tensor_by_name(\"out_weights:0\")\nout_bias = lstm_graph.get_tensor_by_name(\"out_bias:0\")\nx = tf.placeholder(\"float\",[time_steps,n_input])\ny = tf.placeholder(\"float\",[n_classes])\nkeep_prob = keep_prob = tf.placeholder(\"float\", shape=())\ninputs = lstm_graph.get_tensor_by_name(\"inputs:0\")\nprediction = lstm_graph.get_tensor_by_name(\"prediction:0\") + out_bias\npred_label = tf.argmax(prediction,1)\n\"\"\"RUNNING MODEL\"\"\"\nwith tf.Session(graph=lstm_graph) as sess:\nsess.run(tf.global_variables_initializer())\nmodel_prediction = sess.run(pred_label, feed_dict={x: subject_npy, y: y_const_npy, keep_prob: 1.0})\n\nHave I written custom code:   yes\nOS Platform and Distribution:    centos 6\nTensorFlow installed from:    pip3\nTensorFlow version:    v1.9\nBazel version:    N/A\nCUDA/cuDNN version:    N/A\nGPU model and memory:    N/A\nExact command to reproduce:    N/A\nMobile device:    N/A", "body": "Error:\r\n/usr/lib64/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n2018-07-27 08:35:51.967246: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: FMA\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1075, in _run\r\n    subfeed, allow_tensor=True, allow_operation=False)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3590, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3679, in _as_graph_element_locked\r\n    types_str))\r\nTypeError: Can not convert a NoneType into a Tensor.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"--------------.py\", line 397, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"---------------------.py\", line 88, in main\r\n    print(prediction(e))\r\n  File \"---------------------.py\", line 361, in prediction\r\n    model_prediction = sess.run(pred_label, feed_dict={x: subject_npy, y: y_const_npy, keep_prob: 1.0})\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1078, in _run\r\n    'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\r\nTypeError: Cannot interpret feed_dict key as Tensor: Can not convert a NoneType into a Tensor.\r\n\r\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\nI've tried what some stackoverflow posts recommended, e.g. keeping the feed_dict placeholder names as x and y, when either saving & restoring the graph or just making new placeholders.\r\n\r\nMy objective: I'm trying to restore and run an lstm.\r\n\r\nMy code:\r\n\"\"\"setup for training-------(no issue with training)\"\"\"\r\n  out_weights = tf.Variable(tf.random_normal([num_units,n_classes]), name = \"out_weights\")\r\n  out_bias = tf.Variable(tf.random_normal([n_classes]), name = \"out_bias\")\r\n  x = tf.placeholder(\"float\",[None,time_steps,n_input])\r\n  y = tf.placeholder(\"float\",[None,n_classes])\r\n  keep_prob = tf.placeholder(\"float\", shape=())\r\ninput = tf.unstack(x ,time_steps,1, name = \"inputs\")\r\nlstm_layer = rnn.BasicLSTMCell(num_units,forget_bias=1)\r\noutputs, _ = rnn.static_rnn(lstm_layer,input,dtype=\"float32\")\r\n  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\r\n  tf.summary.scalar('cross_entrophy', loss)\r\n  opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\r\n  pred_label = tf.argmax(prediction,1)\r\n  actual_label = tf.argmax(y,1)\r\n  correct_prediction = tf.equal(pred_label, actual_label)\r\n  accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    saver = tf.train.Saver()\r\n    for i in range(N):\r\n        sess.run(, feed_dict = {x: batch[0], y: batch[1], keep_prob: 0.5})\r\n        if i%100==0:\r\n                    saver.save(sess, \"path/model.ckpt\")\r\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n\"\"\"LOADING  lstm\"\"\"\r\n  with tf.Session() as sess:\r\n    from_saver = tf.train.import_meta_graph('path/model.ckpt.meta')\r\n    from_saver.restore(sess, tf.train.latest_checkpoint('path_to_summaries_dir'))\r\n   lstm_graph = tf.get_default_graph()\r\n    out_weights = lstm_graph.get_tensor_by_name(\"out_weights:0\")\r\n    out_bias = lstm_graph.get_tensor_by_name(\"out_bias:0\")\r\n    x = tf.placeholder(\"float\",[time_steps,n_input])\r\n    y = tf.placeholder(\"float\",[n_classes])\r\n    keep_prob = keep_prob = tf.placeholder(\"float\", shape=())\r\n    inputs = lstm_graph.get_tensor_by_name(\"inputs:0\")\r\n    prediction = lstm_graph.get_tensor_by_name(\"prediction:0\") + out_bias\r\n    pred_label = tf.argmax(prediction,1)\r\n\r\n\"\"\"RUNNING MODEL\"\"\"\r\n  with tf.Session(graph=lstm_graph) as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    model_prediction = sess.run(pred_label, feed_dict={x: subject_npy, y: y_const_npy, keep_prob: 1.0})\r\n\r\n------------------------\r\n\r\n\r\nHave I written custom code:   yes\r\nOS Platform and Distribution:    centos 6\r\nTensorFlow installed from:    pip3\r\nTensorFlow version:    v1.9\r\nBazel version:    N/A\r\nCUDA/cuDNN version:    N/A\r\nGPU model and memory:    N/A\r\nExact command to reproduce:    N/A\r\nMobile device:    N/A"}