{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/351788641", "html_url": "https://github.com/tensorflow/tensorflow/issues/12474#issuecomment-351788641", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12474", "id": 351788641, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MTc4ODY0MQ==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-14T17:59:05Z", "updated_at": "2017-12-14T17:59:05Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1836025\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/joeyearsley\">@joeyearsley</a></p>\n<p>I would not advise FP16 on P100s for training unless it happens to work better for your situation.  It is ok for testing that it works.  I believe the issues is the V100 has the ability to do FP16 but do the accumulation in FP32.  P100 cannot do that so you have to cast and do other \"stuff\".  Apologies for being vague I am sharing what I have heard but I do not have direct experience.  I am pretty sure I am generally correct but my details are likely off in some way.  I will open an issue in the benchmark repo and link it here later today.  Maybe I can get more data from the perf team.</p>", "body_text": "@joeyearsley\nI would not advise FP16 on P100s for training unless it happens to work better for your situation.  It is ok for testing that it works.  I believe the issues is the V100 has the ability to do FP16 but do the accumulation in FP32.  P100 cannot do that so you have to cast and do other \"stuff\".  Apologies for being vague I am sharing what I have heard but I do not have direct experience.  I am pretty sure I am generally correct but my details are likely off in some way.  I will open an issue in the benchmark repo and link it here later today.  Maybe I can get more data from the perf team.", "body": "@joeyearsley \r\n\r\nI would not advise FP16 on P100s for training unless it happens to work better for your situation.  It is ok for testing that it works.  I believe the issues is the V100 has the ability to do FP16 but do the accumulation in FP32.  P100 cannot do that so you have to cast and do other \"stuff\".  Apologies for being vague I am sharing what I have heard but I do not have direct experience.  I am pretty sure I am generally correct but my details are likely off in some way.  I will open an issue in the benchmark repo and link it here later today.  Maybe I can get more data from the perf team. "}