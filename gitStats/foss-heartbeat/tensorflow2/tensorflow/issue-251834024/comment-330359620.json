{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/330359620", "html_url": "https://github.com/tensorflow/tensorflow/issues/12474#issuecomment-330359620", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12474", "id": 330359620, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDM1OTYyMA==", "user": {"login": "renganxu", "id": 3160803, "node_id": "MDQ6VXNlcjMxNjA4MDM=", "avatar_url": "https://avatars1.githubusercontent.com/u/3160803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/renganxu", "html_url": "https://github.com/renganxu", "followers_url": "https://api.github.com/users/renganxu/followers", "following_url": "https://api.github.com/users/renganxu/following{/other_user}", "gists_url": "https://api.github.com/users/renganxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/renganxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/renganxu/subscriptions", "organizations_url": "https://api.github.com/users/renganxu/orgs", "repos_url": "https://api.github.com/users/renganxu/repos", "events_url": "https://api.github.com/users/renganxu/events{/privacy}", "received_events_url": "https://api.github.com/users/renganxu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-18T21:19:42Z", "updated_at": "2017-09-18T21:19:42Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23486130\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tfboyd\">@tfboyd</a> , in the benchmark code, one way for variable update is called \"independent\". This should never not be used in real training, right? Because in real training, all GPUs have to communicate each other to update the gradient. The page <a href=\"https://www.tensorflow.org/performance/performance_models\" rel=\"nofollow\">https://www.tensorflow.org/performance/performance_models</a> also didn't mention \"independent\" variable update.</p>", "body_text": "Hi @tfboyd , in the benchmark code, one way for variable update is called \"independent\". This should never not be used in real training, right? Because in real training, all GPUs have to communicate each other to update the gradient. The page https://www.tensorflow.org/performance/performance_models also didn't mention \"independent\" variable update.", "body": "Hi @tfboyd , in the benchmark code, one way for variable update is called \"independent\". This should never not be used in real training, right? Because in real training, all GPUs have to communicate each other to update the gradient. The page https://www.tensorflow.org/performance/performance_models also didn't mention \"independent\" variable update."}