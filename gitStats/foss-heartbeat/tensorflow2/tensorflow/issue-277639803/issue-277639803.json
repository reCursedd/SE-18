{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14962", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14962/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14962/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14962/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14962", "id": 277639803, "node_id": "MDU6SXNzdWUyNzc2Mzk4MDM=", "number": 14962, "title": "Tensorflow Conv model crashes on GPU with zero size batch", "user": {"login": "hpnhxxwn", "id": 5395632, "node_id": "MDQ6VXNlcjUzOTU2MzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/5395632?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hpnhxxwn", "html_url": "https://github.com/hpnhxxwn", "followers_url": "https://api.github.com/users/hpnhxxwn/followers", "following_url": "https://api.github.com/users/hpnhxxwn/following{/other_user}", "gists_url": "https://api.github.com/users/hpnhxxwn/gists{/gist_id}", "starred_url": "https://api.github.com/users/hpnhxxwn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hpnhxxwn/subscriptions", "organizations_url": "https://api.github.com/users/hpnhxxwn/orgs", "repos_url": "https://api.github.com/users/hpnhxxwn/repos", "events_url": "https://api.github.com/users/hpnhxxwn/events{/privacy}", "received_events_url": "https://api.github.com/users/hpnhxxwn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-29T06:05:40Z", "updated_at": "2017-11-29T17:08:55Z", "closed_at": "2017-11-29T17:08:55Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes, I have created two CNN models</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: I installed tensorflow via pip install (Python 3)</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4.0</li>\n<li><strong>Python version</strong>: 3</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/6</li>\n<li><strong>GPU model and memory</strong>: NVIDIA Tesla k80 totalMemory: 11.17GiB freeMemory: 11.09GiB</li>\n<li><strong>Exact command to reproduce</strong>: See below:</li>\n</ul>\n<h3>Below is the log:</h3>\n<blockquote>\n<p>keep_dims is deprecated, use keepdims instead</p>\n<hr>\n<h1>Layer (type)                 Output Shape              Param #</h1>\n<p>input_1 (InputLayer)         (None, 7, 264)            0</p>\n<hr>\n<p>reshape_1 (Reshape)          (None, 7, 264, 1)         0</p>\n<hr>\n<p>conv2d_1 (Conv2D)            (None, 7, 264, 64)        16960</p>\n<hr>\n<p>max_pooling2d_1 (MaxPooling2 (None, 7, 132, 64)        0</p>\n<hr>\n<p>flatten_1 (Flatten)          (None, 59136)             0</p>\n<hr>\n<p>dense_1 (Dense)              (None, 1024)              60556288</p>\n<hr>\n<p>dropout_1 (Dropout)          (None, 1024)              0</p>\n<hr>\n<p>dense_2 (Dense)              (None, 512)               524800</p>\n<hr>\n<p>dropout_2 (Dropout)          (None, 512)               0</p>\n<hr>\n<h1>dense_3 (Dense)              (None, 88)                45144</h1>\n<p>Total params: 61,143,192<br>\nTrainable params: 61,143,192<br>\nNon-trainable params: 0</p>\n<hr>\n<p>/home/hpnhxxwn/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:2057: UserWarning: Using a generator with <code>use_multiprocessing=True</code> and multiple worker<br>\ns may duplicate your data. Please consider using the<code>keras.utils.Sequence class. UserWarning('Using a generator with </code>use_multiprocessing=True`'<br>\nld: learning rate is now 0.01<br>\n2017-11-29 04:58:20.964015: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX A<br>\nVX2 FMA<br>\n2017-11-29 04:58:21.094051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUM<br>\nA node, so returning NUMA node zero<br>\n2017-11-29 04:58:21.094719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties:<br>\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235<br>\npciBusID: 0000:00:04.0<br>\ntotalMemory: 11.17GiB freeMemory: 11.09GiB<br>\n2017-11-29 04:58:21.094744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0<br>\n, compute capability: 3.7)<br>\nEpoch 1/1000<br>\n5180/6944 [=====================&gt;........] - ETA: 3:43 - loss: 0.1382 - acc: 0.9637 - mean_absolute_error: 0.0715 - sparse_categorical_accuracy: 7.1640e-05switching to  ['AkPnStgb']<br>\n5212/6944 [=====================&gt;........] - ETA: 3:39 - loss: 0.1384 - acc: 0.9636 - mean_absolute_error: 0.0715 - sparse_categorical_accuracy: 7.1200e-052017-11-29 05:09:22.210897: F<br>\ntensorflow/stream_executor/cuda/cuda_dnn.cc:444] could not convert BatchDescriptor {count: 0 feature_map_count: 64 spatial: 7 264  value_min: 0.000000 value_max: 0.000000 layout: Batc<br>\nhDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM</p>\n</blockquote>\n<h3>Below is the model.</h3>\n<pre><code>def baseline_model():\n    inputs = Input(shape=input_shape)\n    reshape = Reshape(input_shape_channels)(inputs)\n    #normal convnet layer (have to do one initially to get 64 channels)\n    conv1 = Conv2D(50,(5,25),activation='tanh')(reshape)\n    do1 = Dropout(0.5)(conv1)\n    pool1 = MaxPooling2D(pool_size=(1,3))(do1)\n    conv2 = Conv2D(50,(3,5),activation='tanh')(pool1)\n    do2 = Dropout(0.5)(conv2)\n    pool2 = MaxPooling2D(pool_size=(1,3))(do2)\n    flattened = Flatten()(pool2)\n    fc1 = Dense(1000, activation='sigmoid')(flattened)\n    do3 = Dropout(0.5)(fc1)\n    fc2 = Dense(200, activation='sigmoid')(do3)\n    do4 = Dropout(0.5)(fc2)\n    outputs = Dense(note_range, activation='sigmoid')(do4)\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n</code></pre>\n<p>I have found other github issue created for the same issue, not so far seems like there is no fix yet. I heard the workaround is to use tf.cond, can someone show me how to use it in such case.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I have created two CNN models\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): I installed tensorflow via pip install (Python 3)\nTensorFlow version (use command below): 1.4.0\nPython version: 3\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 8.0/6\nGPU model and memory: NVIDIA Tesla k80 totalMemory: 11.17GiB freeMemory: 11.09GiB\nExact command to reproduce: See below:\n\nBelow is the log:\n\nkeep_dims is deprecated, use keepdims instead\n\nLayer (type)                 Output Shape              Param #\ninput_1 (InputLayer)         (None, 7, 264)            0\n\nreshape_1 (Reshape)          (None, 7, 264, 1)         0\n\nconv2d_1 (Conv2D)            (None, 7, 264, 64)        16960\n\nmax_pooling2d_1 (MaxPooling2 (None, 7, 132, 64)        0\n\nflatten_1 (Flatten)          (None, 59136)             0\n\ndense_1 (Dense)              (None, 1024)              60556288\n\ndropout_1 (Dropout)          (None, 1024)              0\n\ndense_2 (Dense)              (None, 512)               524800\n\ndropout_2 (Dropout)          (None, 512)               0\n\ndense_3 (Dense)              (None, 88)                45144\nTotal params: 61,143,192\nTrainable params: 61,143,192\nNon-trainable params: 0\n\n/home/hpnhxxwn/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:2057: UserWarning: Using a generator with use_multiprocessing=True and multiple worker\ns may duplicate your data. Please consider using thekeras.utils.Sequence class. UserWarning('Using a generator with use_multiprocessing=True`'\nld: learning rate is now 0.01\n2017-11-29 04:58:20.964015: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX A\nVX2 FMA\n2017-11-29 04:58:21.094051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUM\nA node, so returning NUMA node zero\n2017-11-29 04:58:21.094719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties:\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:04.0\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\n2017-11-29 04:58:21.094744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0\n, compute capability: 3.7)\nEpoch 1/1000\n5180/6944 [=====================>........] - ETA: 3:43 - loss: 0.1382 - acc: 0.9637 - mean_absolute_error: 0.0715 - sparse_categorical_accuracy: 7.1640e-05switching to  ['AkPnStgb']\n5212/6944 [=====================>........] - ETA: 3:39 - loss: 0.1384 - acc: 0.9636 - mean_absolute_error: 0.0715 - sparse_categorical_accuracy: 7.1200e-052017-11-29 05:09:22.210897: F\ntensorflow/stream_executor/cuda/cuda_dnn.cc:444] could not convert BatchDescriptor {count: 0 feature_map_count: 64 spatial: 7 264  value_min: 0.000000 value_max: 0.000000 layout: Batc\nhDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM\n\nBelow is the model.\ndef baseline_model():\n    inputs = Input(shape=input_shape)\n    reshape = Reshape(input_shape_channels)(inputs)\n    #normal convnet layer (have to do one initially to get 64 channels)\n    conv1 = Conv2D(50,(5,25),activation='tanh')(reshape)\n    do1 = Dropout(0.5)(conv1)\n    pool1 = MaxPooling2D(pool_size=(1,3))(do1)\n    conv2 = Conv2D(50,(3,5),activation='tanh')(pool1)\n    do2 = Dropout(0.5)(conv2)\n    pool2 = MaxPooling2D(pool_size=(1,3))(do2)\n    flattened = Flatten()(pool2)\n    fc1 = Dense(1000, activation='sigmoid')(flattened)\n    do3 = Dropout(0.5)(fc1)\n    fc2 = Dense(200, activation='sigmoid')(do3)\n    do4 = Dropout(0.5)(fc2)\n    outputs = Dense(note_range, activation='sigmoid')(do4)\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\nI have found other github issue created for the same issue, not so far seems like there is no fix yet. I heard the workaround is to use tf.cond, can someone show me how to use it in such case.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, I have created two CNN models\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: I installed tensorflow via pip install (Python 3)\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: 8.0/6\r\n- **GPU model and memory**: NVIDIA Tesla k80 totalMemory: 11.17GiB freeMemory: 11.09GiB\r\n- **Exact command to reproduce**: See below:\r\n\r\n### Below is the log:\r\n\r\n> keep_dims is deprecated, use keepdims instead\r\n> _________________________________________________________________\r\n> Layer (type)                 Output Shape              Param #   \r\n> =================================================================\r\n> input_1 (InputLayer)         (None, 7, 264)            0         \r\n> _________________________________________________________________\r\n> reshape_1 (Reshape)          (None, 7, 264, 1)         0         \r\n> _________________________________________________________________\r\n> conv2d_1 (Conv2D)            (None, 7, 264, 64)        16960     \r\n> _________________________________________________________________\r\n> max_pooling2d_1 (MaxPooling2 (None, 7, 132, 64)        0         \r\n> _________________________________________________________________\r\n> flatten_1 (Flatten)          (None, 59136)             0         \r\n> _________________________________________________________________\r\n> dense_1 (Dense)              (None, 1024)              60556288  \r\n> _________________________________________________________________\r\n> dropout_1 (Dropout)          (None, 1024)              0         \r\n> _________________________________________________________________\r\n> dense_2 (Dense)              (None, 512)               524800    \r\n> _________________________________________________________________\r\n> dropout_2 (Dropout)          (None, 512)               0         \r\n> _________________________________________________________________\r\n> dense_3 (Dense)              (None, 88)                45144     \r\n> =================================================================\r\n> Total params: 61,143,192\r\n> Trainable params: 61,143,192\r\n> Non-trainable params: 0\r\n> _________________________________________________________________\r\n> /home/hpnhxxwn/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:2057: UserWarning: Using a generator with `use_multiprocessing=True` and multiple worker\r\n> s may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n>   UserWarning('Using a generator with `use_multiprocessing=True`'\r\n> ld: learning rate is now 0.01\r\n> 2017-11-29 04:58:20.964015: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX A\r\n> VX2 FMA\r\n> 2017-11-29 04:58:21.094051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUM\r\n> A node, so returning NUMA node zero\r\n> 2017-11-29 04:58:21.094719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties: \r\n> name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\n> pciBusID: 0000:00:04.0\r\n> totalMemory: 11.17GiB freeMemory: 11.09GiB\r\n> 2017-11-29 04:58:21.094744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0\r\n> , compute capability: 3.7)\r\n> Epoch 1/1000\r\n> 5180/6944 [=====================>........] - ETA: 3:43 - loss: 0.1382 - acc: 0.9637 - mean_absolute_error: 0.0715 - sparse_categorical_accuracy: 7.1640e-05switching to  ['AkPnStgb']\r\n> 5212/6944 [=====================>........] - ETA: 3:39 - loss: 0.1384 - acc: 0.9636 - mean_absolute_error: 0.0715 - sparse_categorical_accuracy: 7.1200e-052017-11-29 05:09:22.210897: F\r\n>  tensorflow/stream_executor/cuda/cuda_dnn.cc:444] could not convert BatchDescriptor {count: 0 feature_map_count: 64 spatial: 7 264  value_min: 0.000000 value_max: 0.000000 layout: Batc\r\n> hDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM\r\n\r\n\r\n\r\n\r\n### Below is the model. \r\n```\r\ndef baseline_model():\r\n    inputs = Input(shape=input_shape)\r\n    reshape = Reshape(input_shape_channels)(inputs)\r\n    #normal convnet layer (have to do one initially to get 64 channels)\r\n    conv1 = Conv2D(50,(5,25),activation='tanh')(reshape)\r\n    do1 = Dropout(0.5)(conv1)\r\n    pool1 = MaxPooling2D(pool_size=(1,3))(do1)\r\n    conv2 = Conv2D(50,(3,5),activation='tanh')(pool1)\r\n    do2 = Dropout(0.5)(conv2)\r\n    pool2 = MaxPooling2D(pool_size=(1,3))(do2)\r\n    flattened = Flatten()(pool2)\r\n    fc1 = Dense(1000, activation='sigmoid')(flattened)\r\n    do3 = Dropout(0.5)(fc1)\r\n    fc2 = Dense(200, activation='sigmoid')(do3)\r\n    do4 = Dropout(0.5)(fc2)\r\n    outputs = Dense(note_range, activation='sigmoid')(do4)\r\n    model = Model(inputs=inputs, outputs=outputs)\r\n    return model\r\n````\r\n\r\nI have found other github issue created for the same issue, not so far seems like there is no fix yet. I heard the workaround is to use tf.cond, can someone show me how to use it in such case. "}