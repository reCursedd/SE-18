{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9613", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9613/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9613/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9613/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9613", "id": 225893851, "node_id": "MDU6SXNzdWUyMjU4OTM4NTE=", "number": 9613, "title": "ValueError:tensorflow", "user": {"login": "leenabharambe", "id": 26062446, "node_id": "MDQ6VXNlcjI2MDYyNDQ2", "avatar_url": "https://avatars2.githubusercontent.com/u/26062446?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leenabharambe", "html_url": "https://github.com/leenabharambe", "followers_url": "https://api.github.com/users/leenabharambe/followers", "following_url": "https://api.github.com/users/leenabharambe/following{/other_user}", "gists_url": "https://api.github.com/users/leenabharambe/gists{/gist_id}", "starred_url": "https://api.github.com/users/leenabharambe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leenabharambe/subscriptions", "organizations_url": "https://api.github.com/users/leenabharambe/orgs", "repos_url": "https://api.github.com/users/leenabharambe/repos", "events_url": "https://api.github.com/users/leenabharambe/events{/privacy}", "received_events_url": "https://api.github.com/users/leenabharambe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-05-03T06:27:27Z", "updated_at": "2017-06-16T21:45:54Z", "closed_at": "2017-06-16T21:45:54Z", "author_association": "NONE", "body_html": "<p>when I'm trying to run the tensorflow odel with my data generating an error as:</p>\n<p>Traceback (most recent call last):<br>\nFile \"/home/ubuntu/tensorflow/models/summarization/bazel-bin/textsum/seq2seq_attention.runfiles/<strong>main</strong>/textsum/seq2seq_attention.py\", line 214, in <br>\ntf.app.run()<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run<br>\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))<br>\nFile \"/home/ubuntu/tensorflow/models/summarization/bazel-bin/textsum/seq2seq_attention.runfiles/<strong>main</strong>/textsum/seq2seq_attention.py\", line 209, in main<br>\ndecoder = seq2seq_attention_decode.BSDecoder(model, batcher, hps, vocab)<br>\nFile \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_decode.py\", line 95, in <strong>init</strong><br>\nself._model.build_graph()<br>\nFile \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_model.py\", line 296, in build_graph<br>\nself._add_seq2seq()<br>\nFile \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_model.py\", line 224, in _add_seq2seq<br>\ntf.log(tf.nn.softmax(model_outputs[-1])), hps.batch_size*2)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1970, in top_k<br>\nreturn gen_nn_ops._top_kv2(input, k=k, sorted=sorted, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2462, in _top_kv2<br>\nname=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2397, in create_op<br>\nset_shapes_for_outputs(ret)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1757, in set_shapes_for_outputs<br>\nshapes = shape_func(op)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1707, in call_with_requiring<br>\nreturn call_cpp_shape_fn(op, require_shape_fn=True)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn<br>\ndebug_python_shape_fn, require_shape_fn)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 675, in _call_cpp_shape_fn_impl<br>\nraise ValueError(err.message)<br>\nValueError: input must have last dimension &gt;= k = 128 but is 102 for 'seq2seq/decode_output/TopKV2' (op: 'TopKV2') with input shapes: [64,102], [].</p>", "body_text": "when I'm trying to run the tensorflow odel with my data generating an error as:\nTraceback (most recent call last):\nFile \"/home/ubuntu/tensorflow/models/summarization/bazel-bin/textsum/seq2seq_attention.runfiles/main/textsum/seq2seq_attention.py\", line 214, in \ntf.app.run()\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))\nFile \"/home/ubuntu/tensorflow/models/summarization/bazel-bin/textsum/seq2seq_attention.runfiles/main/textsum/seq2seq_attention.py\", line 209, in main\ndecoder = seq2seq_attention_decode.BSDecoder(model, batcher, hps, vocab)\nFile \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_decode.py\", line 95, in init\nself._model.build_graph()\nFile \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_model.py\", line 296, in build_graph\nself._add_seq2seq()\nFile \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_model.py\", line 224, in _add_seq2seq\ntf.log(tf.nn.softmax(model_outputs[-1])), hps.batch_size*2)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1970, in top_k\nreturn gen_nn_ops._top_kv2(input, k=k, sorted=sorted, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2462, in _top_kv2\nname=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2397, in create_op\nset_shapes_for_outputs(ret)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1757, in set_shapes_for_outputs\nshapes = shape_func(op)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1707, in call_with_requiring\nreturn call_cpp_shape_fn(op, require_shape_fn=True)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\ndebug_python_shape_fn, require_shape_fn)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 675, in _call_cpp_shape_fn_impl\nraise ValueError(err.message)\nValueError: input must have last dimension >= k = 128 but is 102 for 'seq2seq/decode_output/TopKV2' (op: 'TopKV2') with input shapes: [64,102], [].", "body": "when I'm trying to run the tensorflow odel with my data generating an error as:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/tensorflow/models/summarization/bazel-bin/textsum/seq2seq_attention.runfiles/__main__/textsum/seq2seq_attention.py\", line 214, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/ubuntu/tensorflow/models/summarization/bazel-bin/textsum/seq2seq_attention.runfiles/__main__/textsum/seq2seq_attention.py\", line 209, in main\r\n    decoder = seq2seq_attention_decode.BSDecoder(model, batcher, hps, vocab)\r\n  File \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_decode.py\", line 95, in __init__\r\n    self._model.build_graph()\r\n  File \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_model.py\", line 296, in build_graph\r\n    self._add_seq2seq()\r\n  File \"/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_model.py\", line 224, in _add_seq2seq\r\n    tf.log(tf.nn.softmax(model_outputs[-1])), hps.batch_size*2)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1970, in top_k\r\n    return gen_nn_ops._top_kv2(input, k=k, sorted=sorted, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2462, in _top_kv2\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2397, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1757, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1707, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 675, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: input must have last dimension >= k = 128 but is 102 for 'seq2seq/decode_output/TopKV2' (op: 'TopKV2') with input shapes: [64,102], [].\r\n"}