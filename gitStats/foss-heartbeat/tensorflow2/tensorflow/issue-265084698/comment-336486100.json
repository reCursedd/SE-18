{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/336486100", "html_url": "https://github.com/tensorflow/tensorflow/issues/13669#issuecomment-336486100", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13669", "id": 336486100, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjQ4NjEwMA==", "user": {"login": "georgesterpu", "id": 6018251, "node_id": "MDQ6VXNlcjYwMTgyNTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/6018251?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgesterpu", "html_url": "https://github.com/georgesterpu", "followers_url": "https://api.github.com/users/georgesterpu/followers", "following_url": "https://api.github.com/users/georgesterpu/following{/other_user}", "gists_url": "https://api.github.com/users/georgesterpu/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgesterpu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgesterpu/subscriptions", "organizations_url": "https://api.github.com/users/georgesterpu/orgs", "repos_url": "https://api.github.com/users/georgesterpu/repos", "events_url": "https://api.github.com/users/georgesterpu/events{/privacy}", "received_events_url": "https://api.github.com/users/georgesterpu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-13T15:29:15Z", "updated_at": "2017-10-13T15:29:15Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi Colin,<br>\nThe vertical axis is for the speech input, and the horizontal one for the labels. The original shapes are ~[150, 45], but I resize the images to (512,512). The origin should be the top-left corner, but I am unsure. The code is quite similar to the one in the nmt tutorial:</p>\n<pre><code>outputs, states, lengths = seq2seq.dynamic_decode(\n            self._decoder_inference,\n            impute_finished=True,\n            swap_memory=False,\n            maximum_iterations=self._hparams.max_label_length)\n\nattention_alignment = states.alignment_history.stack()\nattention_images = tf.expand_dims(tf.transpose(attention_alignment, [1, 2, 0]), -1)\nattention_summary = tf.summary.image(\"attention_images\", attention_images)\n</code></pre>", "body_text": "Hi Colin,\nThe vertical axis is for the speech input, and the horizontal one for the labels. The original shapes are ~[150, 45], but I resize the images to (512,512). The origin should be the top-left corner, but I am unsure. The code is quite similar to the one in the nmt tutorial:\noutputs, states, lengths = seq2seq.dynamic_decode(\n            self._decoder_inference,\n            impute_finished=True,\n            swap_memory=False,\n            maximum_iterations=self._hparams.max_label_length)\n\nattention_alignment = states.alignment_history.stack()\nattention_images = tf.expand_dims(tf.transpose(attention_alignment, [1, 2, 0]), -1)\nattention_summary = tf.summary.image(\"attention_images\", attention_images)", "body": "Hi Colin,\r\nThe vertical axis is for the speech input, and the horizontal one for the labels. The original shapes are ~[150, 45], but I resize the images to (512,512). The origin should be the top-left corner, but I am unsure. The code is quite similar to the one in the nmt tutorial:\r\n\r\n```\r\noutputs, states, lengths = seq2seq.dynamic_decode(\r\n            self._decoder_inference,\r\n            impute_finished=True,\r\n            swap_memory=False,\r\n            maximum_iterations=self._hparams.max_label_length)\r\n\r\nattention_alignment = states.alignment_history.stack()\r\nattention_images = tf.expand_dims(tf.transpose(attention_alignment, [1, 2, 0]), -1)\r\nattention_summary = tf.summary.image(\"attention_images\", attention_images)\r\n```"}