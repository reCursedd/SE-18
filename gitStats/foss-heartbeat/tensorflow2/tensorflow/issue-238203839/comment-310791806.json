{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/310791806", "html_url": "https://github.com/tensorflow/tensorflow/issues/11017#issuecomment-310791806", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11017", "id": 310791806, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDc5MTgwNg==", "user": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-23T23:07:52Z", "updated_at": "2017-06-23T23:07:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5216553\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rubenvereecken\">@rubenvereecken</a> The workaround is based on the assumption that the train op runs on the Python main thread, while the data queues run on the child threads, which should usually be the case.</p>\n<p>You can just use the <code>thread_name_filter</code> kwarg of the wrapper's constructor to limit the debugging to the train op.</p>\n<div class=\"highlight highlight-source-python\"><pre>sess <span class=\"pl-k\">=</span> tf_debug.LocalCLIDebugWrapperSession(sess, <span class=\"pl-v\">thread_name_filter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MainThread$<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p>This is talked about in the FAQ. Doing this doesn't change the source of the input data. They still come from the queues; they just don't break into the TFDBG UI when they run.</p>", "body_text": "@rubenvereecken The workaround is based on the assumption that the train op runs on the Python main thread, while the data queues run on the child threads, which should usually be the case.\nYou can just use the thread_name_filter kwarg of the wrapper's constructor to limit the debugging to the train op.\nsess = tf_debug.LocalCLIDebugWrapperSession(sess, thread_name_filter=\"MainThread$\")\nThis is talked about in the FAQ. Doing this doesn't change the source of the input data. They still come from the queues; they just don't break into the TFDBG UI when they run.", "body": "@rubenvereecken The workaround is based on the assumption that the train op runs on the Python main thread, while the data queues run on the child threads, which should usually be the case.\r\n\r\nYou can just use the `thread_name_filter` kwarg of the wrapper's constructor to limit the debugging to the train op.\r\n\r\n```python\r\nsess = tf_debug.LocalCLIDebugWrapperSession(sess, thread_name_filter=\"MainThread$\")\r\n```\r\n\r\nThis is talked about in the FAQ. Doing this doesn't change the source of the input data. They still come from the queues; they just don't break into the TFDBG UI when they run."}