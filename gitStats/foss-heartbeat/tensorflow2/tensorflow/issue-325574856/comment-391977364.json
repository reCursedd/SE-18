{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/391977364", "html_url": "https://github.com/tensorflow/tensorflow/issues/19489#issuecomment-391977364", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19489", "id": 391977364, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTk3NzM2NA==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-25T08:13:32Z", "updated_at": "2018-05-25T08:13:32Z", "author_association": "MEMBER", "body_html": "<p>Could you provide more information - such as something to reproduce the error?</p>\n<p>As a workaround, you can do what the error message suggests, i.e., use:<br>\n<code>tf.enable_eager_execution(device_policy=tf.contrib.eager.DEVICE_PLACEMENT_SILENT)</code>. Tensors will still be copied between CPU/GPU if needed, but it won't fail. Though, that should be happening by default anyway, so are you explicitly changing the default device placement policy?</p>\n<p>That said, this seems to be coming from the gradient of a <code>tf.gather</code>. I'll be curious to dig into this further, but there is a reasonable chance that you're seeing this on the CPU because int32 tensors are often kept in host memory. <code>DEVICE_PLACEMENT_SILENT</code> mimics the behavior of TensorFlow graph execution (where tensors are copied between devices if needed).</p>", "body_text": "Could you provide more information - such as something to reproduce the error?\nAs a workaround, you can do what the error message suggests, i.e., use:\ntf.enable_eager_execution(device_policy=tf.contrib.eager.DEVICE_PLACEMENT_SILENT). Tensors will still be copied between CPU/GPU if needed, but it won't fail. Though, that should be happening by default anyway, so are you explicitly changing the default device placement policy?\nThat said, this seems to be coming from the gradient of a tf.gather. I'll be curious to dig into this further, but there is a reasonable chance that you're seeing this on the CPU because int32 tensors are often kept in host memory. DEVICE_PLACEMENT_SILENT mimics the behavior of TensorFlow graph execution (where tensors are copied between devices if needed).", "body": "Could you provide more information - such as something to reproduce the error?\r\n\r\nAs a workaround, you can do what the error message suggests, i.e., use:\r\n`tf.enable_eager_execution(device_policy=tf.contrib.eager.DEVICE_PLACEMENT_SILENT)`. Tensors will still be copied between CPU/GPU if needed, but it won't fail. Though, that should be happening by default anyway, so are you explicitly changing the default device placement policy?\r\n\r\nThat said, this seems to be coming from the gradient of a `tf.gather`. I'll be curious to dig into this further, but there is a reasonable chance that you're seeing this on the CPU because int32 tensors are often kept in host memory. `DEVICE_PLACEMENT_SILENT` mimics the behavior of TensorFlow graph execution (where tensors are copied between devices if needed)."}