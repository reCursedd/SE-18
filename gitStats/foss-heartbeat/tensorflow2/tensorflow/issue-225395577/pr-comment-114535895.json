{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114535895", "pull_request_review_id": 36009304, "id": 114535895, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExNDUzNTg5NQ==", "diff_hunk": "@@ -0,0 +1,125 @@\n+/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// See docs in ../ops/image_ops.cc\n+\n+#include <memory>\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/framework/types.pb.h\"\n+#include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+\n+namespace tensorflow {\n+\n+// Decode the contents of a BMP file\n+class DecodeBmpOp : public OpKernel {\n+ public:\n+  explicit DecodeBmpOp(OpKernelConstruction* context) : OpKernel(context) {}\n+\n+  void Compute(OpKernelContext* context) override {\n+    const Tensor& contents = context->input(0);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(contents.shape()),\n+                errors::InvalidArgument(\"contents must be scalar, got shape \",\n+                                        contents.shape().DebugString()));\n+\n+    // Start decoding image to get shape details\n+    const StringPiece input = contents.scalar<string>()();\n+\n+    // Decode image, allocating tensor once the image size is known\n+    Tensor* output = nullptr;\n+    OP_REQUIRES(\n+        context,\n+        Decode(input.data(), input.size(),\n+                    [=, &output](int width, int height,\n+                                 int channels) -> uint8* {\n+                      Status status(context->allocate_output(\n+                          0, TensorShape({height, width, channels}),\n+                          &output));\n+                      if (!status.ok()) {\n+                        VLOG(1) << status;\n+                        context->SetStatus(status);\n+                        return nullptr;\n+                      }\n+                      return output->flat<uint8>().data();\n+                    }),\n+        errors::InvalidArgument(\"Invalid BMP data, size \", input.size()));\n+  }\n+\n+  uint8* Decode(const void* srcdata, int datasize,\n+              std::function<uint8*(int, int, int)> allocate_output);\n+};\n+REGISTER_KERNEL_BUILDER(Name(\"DecodeBmp\").Device(DEVICE_CPU), DecodeBmpOp);\n+\n+uint8* DecodeBmpOp::Decode(const void* srcdata, int datasize,\n+              std::function<uint8*(int, int, int)> allocate_output) {\n+\n+  bool top_down = false;\n+  uint8* const img_bytes = (uint8 *) srcdata;\n+  const int header_size = *(reinterpret_cast<int*>(img_bytes + 10));\n+  const int width = *(reinterpret_cast<int*>(img_bytes + 18));\n+  const int height = *(reinterpret_cast<int*>(img_bytes + 22));\n+\n+  // if height is negative, data layout is top down\n+  // otherwise, it's bottom up\n+  if (height < 0)\n+    top_down = true;\n+  uint8* dstdata = allocate_output(width, abs(height), 3);\n+  uint8* const bmp_pixels = &img_bytes[header_size];\n+  int row_size = (8 * width * 3 + 31) / 32 * 4;\n+\n+#ifndef NDEBUG\n+  const int data_size = *(reinterpret_cast<int*>(img_bytes + 34));\n+  LOG(INFO) << \"header size = \" << header_size;\n+  LOG(INFO) << \"width = \" << width;\n+  LOG(INFO) << \"height = \" << height;\n+  LOG(INFO) << \"data size = \" << data_size;\n+  LOG(INFO) << \"row size = \" << row_size;\n+  LOG(INFO) << \"top down = \" << top_down;\n+#endif\n+\n+  for (int i = 0; i < abs(height); i++) {", "path": "tensorflow/core/kernels/decode_bmp_op.cc", "position": null, "original_position": 96, "commit_id": "c8bf54f0283438e297b3cb0768f77f47635f65f3", "original_commit_id": "4d5f3b329ebb61df600d513ad2ceeb8e875c4194", "user": {"login": "freedomtan", "id": 3395998, "node_id": "MDQ6VXNlcjMzOTU5OTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/3395998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/freedomtan", "html_url": "https://github.com/freedomtan", "followers_url": "https://api.github.com/users/freedomtan/followers", "following_url": "https://api.github.com/users/freedomtan/following{/other_user}", "gists_url": "https://api.github.com/users/freedomtan/gists{/gist_id}", "starred_url": "https://api.github.com/users/freedomtan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/freedomtan/subscriptions", "organizations_url": "https://api.github.com/users/freedomtan/orgs", "repos_url": "https://api.github.com/users/freedomtan/repos", "events_url": "https://api.github.com/users/freedomtan/events{/privacy}", "received_events_url": "https://api.github.com/users/freedomtan/received_events", "type": "User", "site_admin": false}, "body": "Step 0. I wrote a script to test image load + decode time. It seems bmp decoding is not slower than jpg and png decoding on my desktop machine (a 2014 iMac). Mostly because decoding bmp is simply memory copy without decompression involved. Will check on ARMv8 devices later.\r\n\r\n```python\r\n    file_reader = tf.read_file(file_name, 'file_reader')\r\n\r\n    if file_name.endswith(\".bmp\"):\r\n        image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')\r\n    elif file_name.endswith(\".png\"):\r\n        image_reader = tf.image.decode_png(file_reader, name='png_reader')\r\n    else:\r\n        image_reader = tf.image.decode_jpeg(file_reader, channels = 3, name='jpeg_reader')\r\n\r\n    graph_def = graph.as_graph_def()\r\n    stat = pywrap_tensorflow.NewStatSummarizer(graph_def.SerializeToString())\r\n\r\n    with tf.Session() as sess:\r\n        for i in range(0, 100):\r\n            run_metadata = tf.RunMetadata()\r\n            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\n            result = sess.run(image_reader, {}, run_options, run_metadata)\r\n            step_stats = run_metadata.step_stats\r\n            stat.ProcessStepStatsStr(step_stats.SerializeToString())\r\n\r\n    stat.PrintStepStats()\r\n```", "created_at": "2017-05-03T12:53:31Z", "updated_at": "2017-05-17T03:26:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/9563#discussion_r114535895", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9563", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114535895"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/9563#discussion_r114535895"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9563"}}, "body_html": "<p>Step 0. I wrote a script to test image load + decode time. It seems bmp decoding is not slower than jpg and png decoding on my desktop machine (a 2014 iMac). Mostly because decoding bmp is simply memory copy without decompression involved. Will check on ARMv8 devices later.</p>\n<div class=\"highlight highlight-source-python\"><pre>    file_reader <span class=\"pl-k\">=</span> tf.read_file(file_name, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>file_reader<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-k\">if</span> file_name.endswith(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>.bmp<span class=\"pl-pds\">\"</span></span>):\n        image_reader <span class=\"pl-k\">=</span> tf.image.decode_bmp(file_reader, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>bmp_reader<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">elif</span> file_name.endswith(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>.png<span class=\"pl-pds\">\"</span></span>):\n        image_reader <span class=\"pl-k\">=</span> tf.image.decode_png(file_reader, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>png_reader<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">else</span>:\n        image_reader <span class=\"pl-k\">=</span> tf.image.decode_jpeg(file_reader, <span class=\"pl-v\">channels</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>jpeg_reader<span class=\"pl-pds\">'</span></span>)\n\n    graph_def <span class=\"pl-k\">=</span> graph.as_graph_def()\n    stat <span class=\"pl-k\">=</span> pywrap_tensorflow.NewStatSummarizer(graph_def.SerializeToString())\n\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">100</span>):\n            run_metadata <span class=\"pl-k\">=</span> tf.RunMetadata()\n            run_options <span class=\"pl-k\">=</span> tf.RunOptions(<span class=\"pl-v\">trace_level</span><span class=\"pl-k\">=</span>tf.RunOptions.<span class=\"pl-c1\">FULL_TRACE</span>)\n            result <span class=\"pl-k\">=</span> sess.run(image_reader, {}, run_options, run_metadata)\n            step_stats <span class=\"pl-k\">=</span> run_metadata.step_stats\n            stat.ProcessStepStatsStr(step_stats.SerializeToString())\n\n    stat.PrintStepStats()</pre></div>", "body_text": "Step 0. I wrote a script to test image load + decode time. It seems bmp decoding is not slower than jpg and png decoding on my desktop machine (a 2014 iMac). Mostly because decoding bmp is simply memory copy without decompression involved. Will check on ARMv8 devices later.\n    file_reader = tf.read_file(file_name, 'file_reader')\n\n    if file_name.endswith(\".bmp\"):\n        image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')\n    elif file_name.endswith(\".png\"):\n        image_reader = tf.image.decode_png(file_reader, name='png_reader')\n    else:\n        image_reader = tf.image.decode_jpeg(file_reader, channels = 3, name='jpeg_reader')\n\n    graph_def = graph.as_graph_def()\n    stat = pywrap_tensorflow.NewStatSummarizer(graph_def.SerializeToString())\n\n    with tf.Session() as sess:\n        for i in range(0, 100):\n            run_metadata = tf.RunMetadata()\n            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n            result = sess.run(image_reader, {}, run_options, run_metadata)\n            step_stats = run_metadata.step_stats\n            stat.ProcessStepStatsStr(step_stats.SerializeToString())\n\n    stat.PrintStepStats()", "in_reply_to_id": 114450777}