{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114450777", "pull_request_review_id": 35917203, "id": 114450777, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExNDQ1MDc3Nw==", "diff_hunk": "@@ -0,0 +1,125 @@\n+/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// See docs in ../ops/image_ops.cc\n+\n+#include <memory>\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/framework/types.pb.h\"\n+#include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+\n+namespace tensorflow {\n+\n+// Decode the contents of a BMP file\n+class DecodeBmpOp : public OpKernel {\n+ public:\n+  explicit DecodeBmpOp(OpKernelConstruction* context) : OpKernel(context) {}\n+\n+  void Compute(OpKernelContext* context) override {\n+    const Tensor& contents = context->input(0);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(contents.shape()),\n+                errors::InvalidArgument(\"contents must be scalar, got shape \",\n+                                        contents.shape().DebugString()));\n+\n+    // Start decoding image to get shape details\n+    const StringPiece input = contents.scalar<string>()();\n+\n+    // Decode image, allocating tensor once the image size is known\n+    Tensor* output = nullptr;\n+    OP_REQUIRES(\n+        context,\n+        Decode(input.data(), input.size(),\n+                    [=, &output](int width, int height,\n+                                 int channels) -> uint8* {\n+                      Status status(context->allocate_output(\n+                          0, TensorShape({height, width, channels}),\n+                          &output));\n+                      if (!status.ok()) {\n+                        VLOG(1) << status;\n+                        context->SetStatus(status);\n+                        return nullptr;\n+                      }\n+                      return output->flat<uint8>().data();\n+                    }),\n+        errors::InvalidArgument(\"Invalid BMP data, size \", input.size()));\n+  }\n+\n+  uint8* Decode(const void* srcdata, int datasize,\n+              std::function<uint8*(int, int, int)> allocate_output);\n+};\n+REGISTER_KERNEL_BUILDER(Name(\"DecodeBmp\").Device(DEVICE_CPU), DecodeBmpOp);\n+\n+uint8* DecodeBmpOp::Decode(const void* srcdata, int datasize,\n+              std::function<uint8*(int, int, int)> allocate_output) {\n+\n+  bool top_down = false;\n+  uint8* const img_bytes = (uint8 *) srcdata;\n+  const int header_size = *(reinterpret_cast<int*>(img_bytes + 10));\n+  const int width = *(reinterpret_cast<int*>(img_bytes + 18));\n+  const int height = *(reinterpret_cast<int*>(img_bytes + 22));\n+\n+  // if height is negative, data layout is top down\n+  // otherwise, it's bottom up\n+  if (height < 0)\n+    top_down = true;\n+  uint8* dstdata = allocate_output(width, abs(height), 3);\n+  uint8* const bmp_pixels = &img_bytes[header_size];\n+  int row_size = (8 * width * 3 + 31) / 32 * 4;\n+\n+#ifndef NDEBUG\n+  const int data_size = *(reinterpret_cast<int*>(img_bytes + 34));\n+  LOG(INFO) << \"header size = \" << header_size;\n+  LOG(INFO) << \"width = \" << width;\n+  LOG(INFO) << \"height = \" << height;\n+  LOG(INFO) << \"data size = \" << data_size;\n+  LOG(INFO) << \"row size = \" << row_size;\n+  LOG(INFO) << \"top down = \" << top_down;\n+#endif\n+\n+  for (int i = 0; i < abs(height); i++) {", "path": "tensorflow/core/kernels/decode_bmp_op.cc", "position": null, "original_position": 96, "commit_id": "c8bf54f0283438e297b3cb0768f77f47635f65f3", "original_commit_id": "4d5f3b329ebb61df600d513ad2ceeb8e875c4194", "user": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "body": "I should have looked at this earlier on.  this looks like it's going to be super slow -- it's not using any threading, nor vector intrinsics to make this work quickly.  I'm a bit worried about accepting this because then people are going to complain about TensorFlow being slow, and if they are reading bmp files, it'll be because this op is slow.\r\n\r\nWithout making this competitive with optimized bmp libraries, I am not sure we'd want to accept this into core tensorflow, and it may be nice as an external op library.\r\n\r\nWhat do you think -- do you have time to compare against other bmp libraries and see how fast this is?  If not, would you be okay with making it an external op library?", "created_at": "2017-05-02T23:45:26Z", "updated_at": "2017-05-17T03:26:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/9563#discussion_r114450777", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9563", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114450777"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/9563#discussion_r114450777"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9563"}}, "body_html": "<p>I should have looked at this earlier on.  this looks like it's going to be super slow -- it's not using any threading, nor vector intrinsics to make this work quickly.  I'm a bit worried about accepting this because then people are going to complain about TensorFlow being slow, and if they are reading bmp files, it'll be because this op is slow.</p>\n<p>Without making this competitive with optimized bmp libraries, I am not sure we'd want to accept this into core tensorflow, and it may be nice as an external op library.</p>\n<p>What do you think -- do you have time to compare against other bmp libraries and see how fast this is?  If not, would you be okay with making it an external op library?</p>", "body_text": "I should have looked at this earlier on.  this looks like it's going to be super slow -- it's not using any threading, nor vector intrinsics to make this work quickly.  I'm a bit worried about accepting this because then people are going to complain about TensorFlow being slow, and if they are reading bmp files, it'll be because this op is slow.\nWithout making this competitive with optimized bmp libraries, I am not sure we'd want to accept this into core tensorflow, and it may be nice as an external op library.\nWhat do you think -- do you have time to compare against other bmp libraries and see how fast this is?  If not, would you be okay with making it an external op library?"}