{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/341754261", "html_url": "https://github.com/tensorflow/tensorflow/issues/6847#issuecomment-341754261", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6847", "id": 341754261, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTc1NDI2MQ==", "user": {"login": "MarvinTeichmann", "id": 2729159, "node_id": "MDQ6VXNlcjI3MjkxNTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/2729159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarvinTeichmann", "html_url": "https://github.com/MarvinTeichmann", "followers_url": "https://api.github.com/users/MarvinTeichmann/followers", "following_url": "https://api.github.com/users/MarvinTeichmann/following{/other_user}", "gists_url": "https://api.github.com/users/MarvinTeichmann/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarvinTeichmann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarvinTeichmann/subscriptions", "organizations_url": "https://api.github.com/users/MarvinTeichmann/orgs", "repos_url": "https://api.github.com/users/MarvinTeichmann/repos", "events_url": "https://api.github.com/users/MarvinTeichmann/events{/privacy}", "received_events_url": "https://api.github.com/users/MarvinTeichmann/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-03T16:23:22Z", "updated_at": "2017-11-03T16:23:22Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a>  \"2. It sounds like people want access to the gradient function of tf.extract_image_patches() without having to use it as a gradient (essentially a reduction). This is similar to people who want 'deconvolution' (the backward pass of convolution) as its own API. \"</p>\n<p>This is a quite common use-case for many ops even  beyond 'deconvolution'  and 'extract_image_patches()'. Do you think it would be possible to great a general API, which lets you (easily) evaluate any op  (or even subgraph) backwards?</p>\n<p>The api could work similar to pytorchs <code>.backward()</code> call which can be applied to subgraphs.</p>", "body_text": "@vrv  \"2. It sounds like people want access to the gradient function of tf.extract_image_patches() without having to use it as a gradient (essentially a reduction). This is similar to people who want 'deconvolution' (the backward pass of convolution) as its own API. \"\nThis is a quite common use-case for many ops even  beyond 'deconvolution'  and 'extract_image_patches()'. Do you think it would be possible to great a general API, which lets you (easily) evaluate any op  (or even subgraph) backwards?\nThe api could work similar to pytorchs .backward() call which can be applied to subgraphs.", "body": "@vrv  \"2. It sounds like people want access to the gradient function of tf.extract_image_patches() without having to use it as a gradient (essentially a reduction). This is similar to people who want 'deconvolution' (the backward pass of convolution) as its own API. \"\r\n\r\nThis is a quite common use-case for many ops even  beyond 'deconvolution'  and 'extract_image_patches()'. Do you think it would be possible to great a general API, which lets you (easily) evaluate any op  (or even subgraph) backwards? \r\n\r\nThe api could work similar to pytorchs `.backward()` call which can be applied to subgraphs. \r\n\r\n\r\n"}