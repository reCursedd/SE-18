{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/208551824", "html_url": "https://github.com/tensorflow/tensorflow/issues/1850#issuecomment-208551824", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1850", "id": 208551824, "node_id": "MDEyOklzc3VlQ29tbWVudDIwODU1MTgyNA==", "user": {"login": "VDalibard", "id": 1645888, "node_id": "MDQ6VXNlcjE2NDU4ODg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1645888?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VDalibard", "html_url": "https://github.com/VDalibard", "followers_url": "https://api.github.com/users/VDalibard/followers", "following_url": "https://api.github.com/users/VDalibard/following{/other_user}", "gists_url": "https://api.github.com/users/VDalibard/gists{/gist_id}", "starred_url": "https://api.github.com/users/VDalibard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VDalibard/subscriptions", "organizations_url": "https://api.github.com/users/VDalibard/orgs", "repos_url": "https://api.github.com/users/VDalibard/repos", "events_url": "https://api.github.com/users/VDalibard/events{/privacy}", "received_events_url": "https://api.github.com/users/VDalibard/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-11T20:40:37Z", "updated_at": "2016-04-11T20:43:12Z", "author_association": "NONE", "body_html": "<p>Hi Derek!</p>\n<p>Thanks! That makes a lot of sense. Regarding the client location, I had tried either on machine A or B with little or no change in performance. So I had always left it on machine B so that the instructions were given from 1-hop away from the computes, although the batching may be different between client&lt;-&gt;master and master&lt;-&gt;worker?</p>\n<p>I am still puzzled though because I just re-ran some experiments with a larger network (the second layer 64-&gt;2048 neurons) but I still get the same 2.5X ish drop in performance, even though the number of RPCs should be constant?</p>\n<p>Here were the results:</p>\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Connect to machine A</th>\n<th>Connect to machine B</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>128</td>\n<td>2.06s</td>\n<td>5.26s</td>\n</tr>\n<tr>\n<td>256</td>\n<td>3.76s</td>\n<td>10.17s</td>\n</tr>\n</tbody>\n</table>\n<p>The client was always on machine B again. It seemed like python was doing less work on <code>top</code>. I tried to change <code>num_preprocess_threads</code> in cifar10_input.py to 32 and 64 with no real change in performance.</p>", "body_text": "Hi Derek!\nThanks! That makes a lot of sense. Regarding the client location, I had tried either on machine A or B with little or no change in performance. So I had always left it on machine B so that the instructions were given from 1-hop away from the computes, although the batching may be different between client<->master and master<->worker?\nI am still puzzled though because I just re-ran some experiments with a larger network (the second layer 64->2048 neurons) but I still get the same 2.5X ish drop in performance, even though the number of RPCs should be constant?\nHere were the results:\n\n\n\nBatch Size\nConnect to machine A\nConnect to machine B\n\n\n\n\n128\n2.06s\n5.26s\n\n\n256\n3.76s\n10.17s\n\n\n\nThe client was always on machine B again. It seemed like python was doing less work on top. I tried to change num_preprocess_threads in cifar10_input.py to 32 and 64 with no real change in performance.", "body": "Hi Derek! \n\nThanks! That makes a lot of sense. Regarding the client location, I had tried either on machine A or B with little or no change in performance. So I had always left it on machine B so that the instructions were given from 1-hop away from the computes, although the batching may be different between client<->master and master<->worker?\n\nI am still puzzled though because I just re-ran some experiments with a larger network (the second layer 64->2048 neurons) but I still get the same 2.5X ish drop in performance, even though the number of RPCs should be constant? \n\nHere were the results:\n\n| Batch Size | Connect to machine A | Connect to machine B |\n| --- | --- | --- |\n| 128 | 2.06s | 5.26s |\n| 256 | 3.76s | 10.17s |\n\nThe client was always on machine B again. It seemed like python was doing less work on `top`. I tried to change `num_preprocess_threads` in cifar10_input.py to 32 and 64 with no real change in performance. \n"}