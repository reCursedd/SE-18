{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1850", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1850/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1850/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1850/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1850", "id": 147483921, "node_id": "MDU6SXNzdWUxNDc0ODM5MjE=", "number": 1850, "title": "Surprising behaviour with distributed Tensorflow", "user": {"login": "VDalibard", "id": 1645888, "node_id": "MDQ6VXNlcjE2NDU4ODg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1645888?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VDalibard", "html_url": "https://github.com/VDalibard", "followers_url": "https://api.github.com/users/VDalibard/followers", "following_url": "https://api.github.com/users/VDalibard/following{/other_user}", "gists_url": "https://api.github.com/users/VDalibard/gists{/gist_id}", "starred_url": "https://api.github.com/users/VDalibard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VDalibard/subscriptions", "organizations_url": "https://api.github.com/users/VDalibard/orgs", "repos_url": "https://api.github.com/users/VDalibard/repos", "events_url": "https://api.github.com/users/VDalibard/events{/privacy}", "received_events_url": "https://api.github.com/users/VDalibard/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2016-04-11T16:33:40Z", "updated_at": "2017-01-11T16:43:21Z", "closed_at": "2016-04-21T13:23:55Z", "author_association": "NONE", "body_html": "<p>Hello, I'm observing some surprising behaviour with distributed Tensorflow, in terms of performance. In short, for the exact same Graph, I get a very different performance based on the machine I connect my tf.Session to.</p>\n<p>In my experiments, I have two machines A and B in a cluster. Machine A has a GPU with cuDNN. I declare a graph that executes the cifar10 gpu example exclusively on machine A. No operators (including the variables) are declared on machine B. I log the device placement and Tensorboard does not see any operators associated with anything other device than machine A.</p>\n<p>When I execute the graph, starting my session using <code>tf.Session(\"grpc://machineA:2222\", ...</code> results in significantly better performance than using <code>tf.Session(\"grpc://machineB:2222\", ...</code>. It is also not just a constant overhead, as I increase the batch size, the difference seems to scale linearly:</p>\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Connect to machine A</th>\n<th>Connect to machine B</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>128</td>\n<td>0.19s</td>\n<td>0.50s</td>\n</tr>\n<tr>\n<td>256</td>\n<td>0.38s</td>\n<td>1.00s</td>\n</tr>\n<tr>\n<td>512</td>\n<td>0.74s</td>\n<td>1.78s</td>\n</tr>\n<tr>\n<td>1024</td>\n<td>1.42s</td>\n<td>3.38s</td>\n</tr>\n</tbody>\n</table>\n<p>(Averaged over 10 iterations not including the first two)</p>\n<p>When looking at the output of <code>top</code> on machine B, it does seem like python is doing some work when I connect to machine B as it averages around 30% CPU vs ~0% otherwise, but I cannot tell what that is/how to prevent it.</p>\n<p>I am working with Tensorflow installed from source with commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/ed1a947d5b306d74af24821110dc2eb2f36c038a/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/ed1a947d5b306d74af24821110dc2eb2f36c038a\"><tt>ed1a947</tt></a>.</p>", "body_text": "Hello, I'm observing some surprising behaviour with distributed Tensorflow, in terms of performance. In short, for the exact same Graph, I get a very different performance based on the machine I connect my tf.Session to.\nIn my experiments, I have two machines A and B in a cluster. Machine A has a GPU with cuDNN. I declare a graph that executes the cifar10 gpu example exclusively on machine A. No operators (including the variables) are declared on machine B. I log the device placement and Tensorboard does not see any operators associated with anything other device than machine A.\nWhen I execute the graph, starting my session using tf.Session(\"grpc://machineA:2222\", ... results in significantly better performance than using tf.Session(\"grpc://machineB:2222\", .... It is also not just a constant overhead, as I increase the batch size, the difference seems to scale linearly:\n\n\n\nBatch Size\nConnect to machine A\nConnect to machine B\n\n\n\n\n128\n0.19s\n0.50s\n\n\n256\n0.38s\n1.00s\n\n\n512\n0.74s\n1.78s\n\n\n1024\n1.42s\n3.38s\n\n\n\n(Averaged over 10 iterations not including the first two)\nWhen looking at the output of top on machine B, it does seem like python is doing some work when I connect to machine B as it averages around 30% CPU vs ~0% otherwise, but I cannot tell what that is/how to prevent it.\nI am working with Tensorflow installed from source with commit ed1a947.", "body": "Hello, I'm observing some surprising behaviour with distributed Tensorflow, in terms of performance. In short, for the exact same Graph, I get a very different performance based on the machine I connect my tf.Session to.\n\nIn my experiments, I have two machines A and B in a cluster. Machine A has a GPU with cuDNN. I declare a graph that executes the cifar10 gpu example exclusively on machine A. No operators (including the variables) are declared on machine B. I log the device placement and Tensorboard does not see any operators associated with anything other device than machine A. \n\nWhen I execute the graph, starting my session using `tf.Session(\"grpc://machineA:2222\", ...` results in significantly better performance than using `tf.Session(\"grpc://machineB:2222\", ...`. It is also not just a constant overhead, as I increase the batch size, the difference seems to scale linearly:\n\n| Batch Size | Connect to machine A | Connect to machine B |\n| --- | --- | --- |\n| 128 | 0.19s | 0.50s |\n| 256 | 0.38s | 1.00s |\n| 512 | 0.74s | 1.78s |\n| 1024 | 1.42s | 3.38s |\n\n(Averaged over 10 iterations not including the first two)\n\nWhen looking at the output of `top` on machine B, it does seem like python is doing some work when I connect to machine B as it averages around 30% CPU vs ~0% otherwise, but I cannot tell what that is/how to prevent it.\n\nI am working with Tensorflow installed from source with commit ed1a947d5b306d74af24821110dc2eb2f36c038a. \n"}