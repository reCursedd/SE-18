{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16914", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16914/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16914/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16914/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16914", "id": 296119298, "node_id": "MDU6SXNzdWUyOTYxMTkyOTg=", "number": 16914, "title": "Bazel can't find cudnn.h, ignores cudnn directory specified in configuration", "user": {"login": "tsoernes", "id": 6782404, "node_id": "MDQ6VXNlcjY3ODI0MDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/6782404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tsoernes", "html_url": "https://github.com/tsoernes", "followers_url": "https://api.github.com/users/tsoernes/followers", "following_url": "https://api.github.com/users/tsoernes/following{/other_user}", "gists_url": "https://api.github.com/users/tsoernes/gists{/gist_id}", "starred_url": "https://api.github.com/users/tsoernes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tsoernes/subscriptions", "organizations_url": "https://api.github.com/users/tsoernes/orgs", "repos_url": "https://api.github.com/users/tsoernes/repos", "events_url": "https://api.github.com/users/tsoernes/events{/privacy}", "received_events_url": "https://api.github.com/users/tsoernes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-10T17:51:07Z", "updated_at": "2018-02-10T21:51:27Z", "closed_at": "2018-02-10T21:51:27Z", "author_association": "NONE", "body_html": "<p><a href=\"https://github.com/tensorflow/tensorflow/files/1713644/cuda-inst.txt\">cuda-inst.txt</a></p>\n<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Fedora 27 x64</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source/Release</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.6.0-rc0</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 1.10</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 6.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.1, cudNN 7.0.5</li>\n<li><strong>GPU model and memory</strong>: GTX 1060</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p><code>bazel build --config=opt --config=cuda  --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package</code></p>\n<p>Relevant cudnn files are located at:</p>\n<pre><code>/usr/include/cuda/cudnn.h\n/usr/lib64/libcudnn.so\n/usr/lib64/libcudnn.so.7\n/usr/lib64/libcudnn.so.7.0.5\n</code></pre>\n<p>and should be included:<br>\n<code>export LD_LIBRARY_PATH=\"/usr/include/cuda/cupti:/usr/include/cuda:/usr/lib64\"</code></p>\n<h3>Describe the problem</h3>\n<pre><code>ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 1063\n\t\t_create_local_cuda_repository(repository_ctx)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 917, in _create_local_cuda_repository\n\t\t_get_cuda_config(repository_ctx)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 672, in _get_cuda_config\n\t\t_cudnn_version(repository_ctx, cudnn_install_base..., ...)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 397, in _cudnn_version\n\t\t_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 646, in _find_cudnn_header_dir\n\t\tauto_configure_fail((\"Cannot find cudnn.h under %s\" ...))\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 152, in auto_configure_fail\n\t\tfail((\"\\n%sCuda Configuration Error:%...)))\n\nCuda Configuration Error: Cannot find cudnn.h under /lib64\nWARNING: Target pattern parsing failed.\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 1063\n\t\t_create_local_cuda_repository(repository_ctx)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 917, in _create_local_cuda_repository\n\t\t_get_cuda_config(repository_ctx)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 672, in _get_cuda_config\n\t\t_cudnn_version(repository_ctx, cudnn_install_base..., ...)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 397, in _cudnn_version\n\t\t_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 646, in _find_cudnn_header_dir\n\t\tauto_configure_fail((\"Cannot find cudnn.h under %s\" ...))\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 152, in auto_configure_fail\n\t\tfail((\"\\n%sCuda Configuration Error:%...)))\n\nCuda Configuration Error: Cannot find cudnn.h under /lib64\nINFO: Elapsed time: 0.060s\nFAILED: Build did NOT complete successfully (0 packages loaded)\n    currently loading: tensorflow/tools/pip_package\n</code></pre>\n<p>I have tried specifying <code>/usr</code>, <code>/usr/include</code> and <code>/usr/include/cuda</code> as cudnn-path when running <code>./configure</code>. The configurator detects <code>cudnn.h</code> and does not complain.<br>\nIf I specify <code>/usr</code>, bazel complains it can't find cudnn.h under <code>/usr</code>.<br>\nIf I specify anything else, bazel seems intent to look under <code>lib64</code> for whatever reason and does not find it. I did bazel clean between reconfigurations. Have also tried bazel with <code>--action_env=\"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\"</code></p>\n<p>Have attached full install paths for cuda, cudnn, cupti (rpm -ql):<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/1713645/cuda-inst.txt\">cuda-inst.txt</a></p>\n<p>Configuration log:</p>\n<pre><code>WARNING: Running Bazel server needs to be killed, because the startup options are different.\nYou have bazel 0.10.0- (@non-git) installed.\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\nFound possible Python library paths:\n  /usr/lib/python3.6/site-packages\n  /usr/lib64/python3.6/site-packages\n  /usr/local/lib/python3.6/site-packages\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3.6/site-packages]\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: Y\njemalloc as malloc support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\nNo Hadoop File System support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\nNo Amazon S3 File System support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: n\nNo Apache Kafka Platform support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: n\nNo XLA JIT support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with GDR support? [y/N]: n\nNo GDR support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\nNo VERBS support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\nNo OpenCL SYCL support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1\nPlease specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: \nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr]:/usr/include/cuda\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\nNo TensorRT support will be enabled for TensorFlow.\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]6.1\nDo you want to use clang as CUDA compiler? [y/N]: n\nnvcc will be used as CUDA compiler.\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/cuda-gcc\nDo you wish to build TensorFlow with MPI support? [y/N]: n\nNo MPI support will be enabled for TensorFlow.\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\nNot configuring the WORKSPACE for Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=&lt;&gt;\" to your build command. See tools/bazel.rc for more details.\n\t--config=mkl         \t# Build with MKL support.\n\t--config=monolithic  \t# Config for mostly static monolithic build.\n\t--config=tensorrt    \t# Build with TensorRT support.\nConfiguration finished\n</code></pre>", "body_text": "cuda-inst.txt\nSystem information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 27 x64\nTensorFlow installed from (source or binary): Source/Release\nTensorFlow version (use command below): 1.6.0-rc0\nPython version: 3.6\nBazel version (if compiling from source): 1.10\nGCC/Compiler version (if compiling from source): 6.4.0\nCUDA/cuDNN version: CUDA 9.1, cudNN 7.0.5\nGPU model and memory: GTX 1060\nExact command to reproduce:\n\nbazel build --config=opt --config=cuda  --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package\nRelevant cudnn files are located at:\n/usr/include/cuda/cudnn.h\n/usr/lib64/libcudnn.so\n/usr/lib64/libcudnn.so.7\n/usr/lib64/libcudnn.so.7.0.5\n\nand should be included:\nexport LD_LIBRARY_PATH=\"/usr/include/cuda/cupti:/usr/include/cuda:/usr/lib64\"\nDescribe the problem\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 1063\n\t\t_create_local_cuda_repository(repository_ctx)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 917, in _create_local_cuda_repository\n\t\t_get_cuda_config(repository_ctx)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 672, in _get_cuda_config\n\t\t_cudnn_version(repository_ctx, cudnn_install_base..., ...)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 397, in _cudnn_version\n\t\t_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 646, in _find_cudnn_header_dir\n\t\tauto_configure_fail((\"Cannot find cudnn.h under %s\" ...))\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 152, in auto_configure_fail\n\t\tfail((\"\\n%sCuda Configuration Error:%...)))\n\nCuda Configuration Error: Cannot find cudnn.h under /lib64\nWARNING: Target pattern parsing failed.\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 1063\n\t\t_create_local_cuda_repository(repository_ctx)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 917, in _create_local_cuda_repository\n\t\t_get_cuda_config(repository_ctx)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 672, in _get_cuda_config\n\t\t_cudnn_version(repository_ctx, cudnn_install_base..., ...)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 397, in _cudnn_version\n\t\t_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 646, in _find_cudnn_header_dir\n\t\tauto_configure_fail((\"Cannot find cudnn.h under %s\" ...))\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 152, in auto_configure_fail\n\t\tfail((\"\\n%sCuda Configuration Error:%...)))\n\nCuda Configuration Error: Cannot find cudnn.h under /lib64\nINFO: Elapsed time: 0.060s\nFAILED: Build did NOT complete successfully (0 packages loaded)\n    currently loading: tensorflow/tools/pip_package\n\nI have tried specifying /usr, /usr/include and /usr/include/cuda as cudnn-path when running ./configure. The configurator detects cudnn.h and does not complain.\nIf I specify /usr, bazel complains it can't find cudnn.h under /usr.\nIf I specify anything else, bazel seems intent to look under lib64 for whatever reason and does not find it. I did bazel clean between reconfigurations. Have also tried bazel with --action_env=\"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\"\nHave attached full install paths for cuda, cudnn, cupti (rpm -ql):\ncuda-inst.txt\nConfiguration log:\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\nYou have bazel 0.10.0- (@non-git) installed.\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\nFound possible Python library paths:\n  /usr/lib/python3.6/site-packages\n  /usr/lib64/python3.6/site-packages\n  /usr/local/lib/python3.6/site-packages\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3.6/site-packages]\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: Y\njemalloc as malloc support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\nNo Hadoop File System support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\nNo Amazon S3 File System support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: n\nNo Apache Kafka Platform support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: n\nNo XLA JIT support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with GDR support? [y/N]: n\nNo GDR support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\nNo VERBS support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\nNo OpenCL SYCL support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1\nPlease specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: \nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr]:/usr/include/cuda\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\nNo TensorRT support will be enabled for TensorFlow.\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]6.1\nDo you want to use clang as CUDA compiler? [y/N]: n\nnvcc will be used as CUDA compiler.\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/cuda-gcc\nDo you wish to build TensorFlow with MPI support? [y/N]: n\nNo MPI support will be enabled for TensorFlow.\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\nNot configuring the WORKSPACE for Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\n\t--config=mkl         \t# Build with MKL support.\n\t--config=monolithic  \t# Config for mostly static monolithic build.\n\t--config=tensorrt    \t# Build with TensorRT support.\nConfiguration finished", "body": "\r\n[cuda-inst.txt](https://github.com/tensorflow/tensorflow/files/1713644/cuda-inst.txt)\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 27 x64\r\n- **TensorFlow installed from (source or binary)**: Source/Release\r\n- **TensorFlow version (use command below)**: 1.6.0-rc0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 1.10\r\n- **GCC/Compiler version (if compiling from source)**: 6.4.0\r\n- **CUDA/cuDNN version**: CUDA 9.1, cudNN 7.0.5\r\n- **GPU model and memory**: GTX 1060\r\n- **Exact command to reproduce**:\r\n\r\n`bazel build --config=opt --config=cuda  --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nRelevant cudnn files are located at:\r\n```\r\n/usr/include/cuda/cudnn.h\r\n/usr/lib64/libcudnn.so\r\n/usr/lib64/libcudnn.so.7\r\n/usr/lib64/libcudnn.so.7.0.5\r\n```\r\nand should be included:\r\n`export LD_LIBRARY_PATH=\"/usr/include/cuda/cupti:/usr/include/cuda:/usr/lib64\"`\r\n\r\n### Describe the problem\r\n```\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 1063\r\n\t\t_create_local_cuda_repository(repository_ctx)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 917, in _create_local_cuda_repository\r\n\t\t_get_cuda_config(repository_ctx)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 672, in _get_cuda_config\r\n\t\t_cudnn_version(repository_ctx, cudnn_install_base..., ...)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 397, in _cudnn_version\r\n\t\t_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 646, in _find_cudnn_header_dir\r\n\t\tauto_configure_fail((\"Cannot find cudnn.h under %s\" ...))\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 152, in auto_configure_fail\r\n\t\tfail((\"\\n%sCuda Configuration Error:%...)))\r\n\r\nCuda Configuration Error: Cannot find cudnn.h under /lib64\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 1063\r\n\t\t_create_local_cuda_repository(repository_ctx)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 917, in _create_local_cuda_repository\r\n\t\t_get_cuda_config(repository_ctx)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 672, in _get_cuda_config\r\n\t\t_cudnn_version(repository_ctx, cudnn_install_base..., ...)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 397, in _cudnn_version\r\n\t\t_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 646, in _find_cudnn_header_dir\r\n\t\tauto_configure_fail((\"Cannot find cudnn.h under %s\" ...))\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 152, in auto_configure_fail\r\n\t\tfail((\"\\n%sCuda Configuration Error:%...)))\r\n\r\nCuda Configuration Error: Cannot find cudnn.h under /lib64\r\nINFO: Elapsed time: 0.060s\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n```\r\nI have tried specifying `/usr`, `/usr/include` and `/usr/include/cuda` as cudnn-path when running `./configure`. The configurator detects `cudnn.h` and does not complain.\r\nIf I specify `/usr`, bazel complains it can't find cudnn.h under `/usr`.\r\nIf I specify anything else, bazel seems intent to look under `lib64` for whatever reason and does not find it. I did bazel clean between reconfigurations. Have also tried bazel with `--action_env=\"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\"`\r\n\r\nHave attached full install paths for cuda, cudnn, cupti (rpm -ql):\r\n[cuda-inst.txt](https://github.com/tensorflow/tensorflow/files/1713645/cuda-inst.txt)\r\n\r\nConfiguration log:\r\n```\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nYou have bazel 0.10.0- (@non-git) installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\nFound possible Python library paths:\r\n  /usr/lib/python3.6/site-packages\r\n  /usr/lib64/python3.6/site-packages\r\n  /usr/local/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3.6/site-packages]\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: Y\r\njemalloc as malloc support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\r\nNo Hadoop File System support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\r\nNo Amazon S3 File System support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: n\r\nNo Apache Kafka Platform support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with GDR support? [y/N]: n\r\nNo GDR support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\r\nNo VERBS support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1\r\nPlease specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: \r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr]:/usr/include/cuda\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]6.1\r\nDo you want to use clang as CUDA compiler? [y/N]: n\r\nnvcc will be used as CUDA compiler.\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/cuda-gcc\r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=tensorrt    \t# Build with TensorRT support.\r\nConfiguration finished\r\n```"}