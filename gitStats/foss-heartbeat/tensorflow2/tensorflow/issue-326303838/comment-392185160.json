{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/392185160", "html_url": "https://github.com/tensorflow/tensorflow/issues/19541#issuecomment-392185160", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19541", "id": 392185160, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MjE4NTE2MA==", "user": {"login": "mrezak", "id": 4903456, "node_id": "MDQ6VXNlcjQ5MDM0NTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/4903456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrezak", "html_url": "https://github.com/mrezak", "followers_url": "https://api.github.com/users/mrezak/followers", "following_url": "https://api.github.com/users/mrezak/following{/other_user}", "gists_url": "https://api.github.com/users/mrezak/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrezak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrezak/subscriptions", "organizations_url": "https://api.github.com/users/mrezak/orgs", "repos_url": "https://api.github.com/users/mrezak/repos", "events_url": "https://api.github.com/users/mrezak/events{/privacy}", "received_events_url": "https://api.github.com/users/mrezak/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-25T20:56:44Z", "updated_at": "2018-05-25T20:56:44Z", "author_association": "NONE", "body_html": "<p>Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1184671\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xiejw\">@xiejw</a> for looking into this. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1184671\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xiejw\">@xiejw</a> I see! Actually my value_op depended on the input pipeline (returning different form of loss), so as you pointed out that is the cause of this error.</p>\n<p>I have written minimal example script (A simple autoencoder) that reproduces the EndOfSequence error (If I replace <code>dummy_eval</code> with a tensor that does not depend on the input pipeline, I won't get the EndOfSequence Error) :</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\ndef data_fn(data_dict, batch_size, mode, num_epochs=10):\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        dataset = tf.data.Dataset.from_tensor_slices(data_dict['train_data'].astype(np.float32))\n        dataset = dataset.cache()\n        dataset = dataset.shuffle(buffer_size= batch_size * 10).repeat(num_epochs).batch(batch_size)\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices(data_dict['valid_data'].astype(np.float32))\n        dataset = dataset.cache()\n        dataset = dataset.batch(batch_size)\n\n    iterator = dataset.make_one_shot_iterator()\n    next_element = iterator.get_next()\n\n    return next_element, tf.convert_to_tensor('dummy_dataname')\n\ndef model_fn(features, labels, mode, params):\n    with tf.variable_scope('encoder'):\n        cell = tf.contrib.rnn.GRUCell(num_units=20)\n        _, output_latent = tf.nn.dynamic_rnn(cell=cell, inputs=features, dtype=tf.float32)\n    with tf.variable_scope('decoder'):\n        cell = tf.contrib.rnn.GRUCell(num_units=20)\n        ts = tf.shape(features)\n        #ts = tf.Print(ts, [ts])\n        z_inps = tf.zeros([ts[0], ts[1], 1])\n        output_recon, _ = tf.nn.dynamic_rnn(cell=cell, inputs=z_inps, initial_state=output_latent, dtype=tf.float32)    \n\n    output_recon = tf.contrib.layers.fully_connected(inputs=output_recon, num_outputs=params['dims'], activation_fn=None)\n    vars   = tf.trainable_variables() \n    dummy_lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in vars ]) * 0.001\n    recon_loss = tf.losses.mean_squared_error(features, output_recon)\n    loss =  recon_loss + 0.1 * dummy_lossL2\n    dummy_eval = recon_loss\n    global_step = tf.train.get_global_step()\n    train_op = tf.train.AdamOptimizer(0.01).minimize(loss, global_step)\n    eval_metric_ops = {'dummy': (dummy_eval, dummy_eval)}\n    logging_hook = tf.train.LoggingTensorHook({'step':global_step, 'loss':loss}, every_n_iter=1)\n    return tf.estimator.EstimatorSpec(mode=mode,\n                                  loss=loss,\n                                  train_op=train_op,\n                                  eval_metric_ops=eval_metric_ops,\n                                  training_hooks=[logging_hook]\n                                  )\n\ndef train_model():\n    tf.logging.set_verbosity(tf.logging.INFO)\n    config = tf.ConfigProto(allow_soft_placement=True,\n                            log_device_placement=False)\n    config.gpu_options.allow_growth = True\n    run_config = tf.contrib.learn.RunConfig(\n        save_checkpoints_steps=100,\n        keep_checkpoint_max=10,\n        session_config=config\n    )\n    hps = {'dims': 5}\n    \n    # make training and validation data: sinusoids with random phases\n    num_samp_tr = 1000\n    num_samp_val = 1000\n    ramps_tr = np.transpose(np.broadcast_to(0.1*np.arange(0,100), (num_samp_tr, hps['dims'], 100)), (0, 2, 1))\n    rand_phase = np.transpose(np.tile(np.random.randn(num_samp_tr, hps['dims']), (100,1,1)), (1, 0, 2))\n    ramps_val = np.transpose(np.broadcast_to(0.1*np.arange(0,100), (num_samp_val, hps['dims'], 100)), (0, 2, 1))\n    rand_phase_val = np.transpose(np.tile(np.random.randn(num_samp_val, hps['dims']), (100,1,1)), (1, 0, 2))\n    data = {'train_data': np.sin(ramps_tr + rand_phase),\n            'valid_data': np.sin(ramps_val + rand_phase_val)}\n\n    train_input = lambda: data_fn(data, 100, tf.estimator.ModeKeys.TRAIN, num_epochs=10)\n    eval_input = lambda: data_fn(data, 1000, tf.estimator.ModeKeys.EVAL)\n    estimator = tf.estimator.Estimator(model_fn=model_fn, params=hps, config=run_config)\n    train_spec = tf.estimator.TrainSpec(train_input, max_steps=100)\n    eval_spec = tf.estimator.EvalSpec(eval_input,\n                                      steps=None,\n                                      throttle_secs = 100)\n\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n\ntrain_model()\n</code></pre>\n<p>The problem in my actual code is that my total loss to be optimized is composed of multiple losses (reconstruction + L2 + KL) and in the evaluation part I want to get the reconstruction loss (on the validation data), which depend on the input data pipeline. My actual reconstruction cost is more complex than MSE (none of the other tf.metric functions as well), so in this case do I have to construct my reconstruction cost calculation using tf.metric basic functions to be able to use it as eval_metric_ops?</p>", "body_text": "Thanks @mrry and @xiejw for looking into this. @xiejw I see! Actually my value_op depended on the input pipeline (returning different form of loss), so as you pointed out that is the cause of this error.\nI have written minimal example script (A simple autoencoder) that reproduces the EndOfSequence error (If I replace dummy_eval with a tensor that does not depend on the input pipeline, I won't get the EndOfSequence Error) :\nimport numpy as np\nimport tensorflow as tf\n\ndef data_fn(data_dict, batch_size, mode, num_epochs=10):\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        dataset = tf.data.Dataset.from_tensor_slices(data_dict['train_data'].astype(np.float32))\n        dataset = dataset.cache()\n        dataset = dataset.shuffle(buffer_size= batch_size * 10).repeat(num_epochs).batch(batch_size)\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices(data_dict['valid_data'].astype(np.float32))\n        dataset = dataset.cache()\n        dataset = dataset.batch(batch_size)\n\n    iterator = dataset.make_one_shot_iterator()\n    next_element = iterator.get_next()\n\n    return next_element, tf.convert_to_tensor('dummy_dataname')\n\ndef model_fn(features, labels, mode, params):\n    with tf.variable_scope('encoder'):\n        cell = tf.contrib.rnn.GRUCell(num_units=20)\n        _, output_latent = tf.nn.dynamic_rnn(cell=cell, inputs=features, dtype=tf.float32)\n    with tf.variable_scope('decoder'):\n        cell = tf.contrib.rnn.GRUCell(num_units=20)\n        ts = tf.shape(features)\n        #ts = tf.Print(ts, [ts])\n        z_inps = tf.zeros([ts[0], ts[1], 1])\n        output_recon, _ = tf.nn.dynamic_rnn(cell=cell, inputs=z_inps, initial_state=output_latent, dtype=tf.float32)    \n\n    output_recon = tf.contrib.layers.fully_connected(inputs=output_recon, num_outputs=params['dims'], activation_fn=None)\n    vars   = tf.trainable_variables() \n    dummy_lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in vars ]) * 0.001\n    recon_loss = tf.losses.mean_squared_error(features, output_recon)\n    loss =  recon_loss + 0.1 * dummy_lossL2\n    dummy_eval = recon_loss\n    global_step = tf.train.get_global_step()\n    train_op = tf.train.AdamOptimizer(0.01).minimize(loss, global_step)\n    eval_metric_ops = {'dummy': (dummy_eval, dummy_eval)}\n    logging_hook = tf.train.LoggingTensorHook({'step':global_step, 'loss':loss}, every_n_iter=1)\n    return tf.estimator.EstimatorSpec(mode=mode,\n                                  loss=loss,\n                                  train_op=train_op,\n                                  eval_metric_ops=eval_metric_ops,\n                                  training_hooks=[logging_hook]\n                                  )\n\ndef train_model():\n    tf.logging.set_verbosity(tf.logging.INFO)\n    config = tf.ConfigProto(allow_soft_placement=True,\n                            log_device_placement=False)\n    config.gpu_options.allow_growth = True\n    run_config = tf.contrib.learn.RunConfig(\n        save_checkpoints_steps=100,\n        keep_checkpoint_max=10,\n        session_config=config\n    )\n    hps = {'dims': 5}\n    \n    # make training and validation data: sinusoids with random phases\n    num_samp_tr = 1000\n    num_samp_val = 1000\n    ramps_tr = np.transpose(np.broadcast_to(0.1*np.arange(0,100), (num_samp_tr, hps['dims'], 100)), (0, 2, 1))\n    rand_phase = np.transpose(np.tile(np.random.randn(num_samp_tr, hps['dims']), (100,1,1)), (1, 0, 2))\n    ramps_val = np.transpose(np.broadcast_to(0.1*np.arange(0,100), (num_samp_val, hps['dims'], 100)), (0, 2, 1))\n    rand_phase_val = np.transpose(np.tile(np.random.randn(num_samp_val, hps['dims']), (100,1,1)), (1, 0, 2))\n    data = {'train_data': np.sin(ramps_tr + rand_phase),\n            'valid_data': np.sin(ramps_val + rand_phase_val)}\n\n    train_input = lambda: data_fn(data, 100, tf.estimator.ModeKeys.TRAIN, num_epochs=10)\n    eval_input = lambda: data_fn(data, 1000, tf.estimator.ModeKeys.EVAL)\n    estimator = tf.estimator.Estimator(model_fn=model_fn, params=hps, config=run_config)\n    train_spec = tf.estimator.TrainSpec(train_input, max_steps=100)\n    eval_spec = tf.estimator.EvalSpec(eval_input,\n                                      steps=None,\n                                      throttle_secs = 100)\n\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n\ntrain_model()\n\nThe problem in my actual code is that my total loss to be optimized is composed of multiple losses (reconstruction + L2 + KL) and in the evaluation part I want to get the reconstruction loss (on the validation data), which depend on the input data pipeline. My actual reconstruction cost is more complex than MSE (none of the other tf.metric functions as well), so in this case do I have to construct my reconstruction cost calculation using tf.metric basic functions to be able to use it as eval_metric_ops?", "body": "Thanks @mrry and @xiejw for looking into this. @xiejw I see! Actually my value_op depended on the input pipeline (returning different form of loss), so as you pointed out that is the cause of this error. \r\n\r\nI have written minimal example script (A simple autoencoder) that reproduces the EndOfSequence error (If I replace `dummy_eval` with a tensor that does not depend on the input pipeline, I won't get the EndOfSequence Error) :\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef data_fn(data_dict, batch_size, mode, num_epochs=10):\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        dataset = tf.data.Dataset.from_tensor_slices(data_dict['train_data'].astype(np.float32))\r\n        dataset = dataset.cache()\r\n        dataset = dataset.shuffle(buffer_size= batch_size * 10).repeat(num_epochs).batch(batch_size)\r\n    else:\r\n        dataset = tf.data.Dataset.from_tensor_slices(data_dict['valid_data'].astype(np.float32))\r\n        dataset = dataset.cache()\r\n        dataset = dataset.batch(batch_size)\r\n\r\n    iterator = dataset.make_one_shot_iterator()\r\n    next_element = iterator.get_next()\r\n\r\n    return next_element, tf.convert_to_tensor('dummy_dataname')\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    with tf.variable_scope('encoder'):\r\n        cell = tf.contrib.rnn.GRUCell(num_units=20)\r\n        _, output_latent = tf.nn.dynamic_rnn(cell=cell, inputs=features, dtype=tf.float32)\r\n    with tf.variable_scope('decoder'):\r\n        cell = tf.contrib.rnn.GRUCell(num_units=20)\r\n        ts = tf.shape(features)\r\n        #ts = tf.Print(ts, [ts])\r\n        z_inps = tf.zeros([ts[0], ts[1], 1])\r\n        output_recon, _ = tf.nn.dynamic_rnn(cell=cell, inputs=z_inps, initial_state=output_latent, dtype=tf.float32)    \r\n\r\n    output_recon = tf.contrib.layers.fully_connected(inputs=output_recon, num_outputs=params['dims'], activation_fn=None)\r\n    vars   = tf.trainable_variables() \r\n    dummy_lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in vars ]) * 0.001\r\n    recon_loss = tf.losses.mean_squared_error(features, output_recon)\r\n    loss =  recon_loss + 0.1 * dummy_lossL2\r\n    dummy_eval = recon_loss\r\n    global_step = tf.train.get_global_step()\r\n    train_op = tf.train.AdamOptimizer(0.01).minimize(loss, global_step)\r\n    eval_metric_ops = {'dummy': (dummy_eval, dummy_eval)}\r\n    logging_hook = tf.train.LoggingTensorHook({'step':global_step, 'loss':loss}, every_n_iter=1)\r\n    return tf.estimator.EstimatorSpec(mode=mode,\r\n                                  loss=loss,\r\n                                  train_op=train_op,\r\n                                  eval_metric_ops=eval_metric_ops,\r\n                                  training_hooks=[logging_hook]\r\n                                  )\r\n\r\ndef train_model():\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    config = tf.ConfigProto(allow_soft_placement=True,\r\n                            log_device_placement=False)\r\n    config.gpu_options.allow_growth = True\r\n    run_config = tf.contrib.learn.RunConfig(\r\n        save_checkpoints_steps=100,\r\n        keep_checkpoint_max=10,\r\n        session_config=config\r\n    )\r\n    hps = {'dims': 5}\r\n    \r\n    # make training and validation data: sinusoids with random phases\r\n    num_samp_tr = 1000\r\n    num_samp_val = 1000\r\n    ramps_tr = np.transpose(np.broadcast_to(0.1*np.arange(0,100), (num_samp_tr, hps['dims'], 100)), (0, 2, 1))\r\n    rand_phase = np.transpose(np.tile(np.random.randn(num_samp_tr, hps['dims']), (100,1,1)), (1, 0, 2))\r\n    ramps_val = np.transpose(np.broadcast_to(0.1*np.arange(0,100), (num_samp_val, hps['dims'], 100)), (0, 2, 1))\r\n    rand_phase_val = np.transpose(np.tile(np.random.randn(num_samp_val, hps['dims']), (100,1,1)), (1, 0, 2))\r\n    data = {'train_data': np.sin(ramps_tr + rand_phase),\r\n            'valid_data': np.sin(ramps_val + rand_phase_val)}\r\n\r\n    train_input = lambda: data_fn(data, 100, tf.estimator.ModeKeys.TRAIN, num_epochs=10)\r\n    eval_input = lambda: data_fn(data, 1000, tf.estimator.ModeKeys.EVAL)\r\n    estimator = tf.estimator.Estimator(model_fn=model_fn, params=hps, config=run_config)\r\n    train_spec = tf.estimator.TrainSpec(train_input, max_steps=100)\r\n    eval_spec = tf.estimator.EvalSpec(eval_input,\r\n                                      steps=None,\r\n                                      throttle_secs = 100)\r\n\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n\r\ntrain_model()\r\n```\r\n\r\nThe problem in my actual code is that my total loss to be optimized is composed of multiple losses (reconstruction + L2 + KL) and in the evaluation part I want to get the reconstruction loss (on the validation data), which depend on the input data pipeline. My actual reconstruction cost is more complex than MSE (none of the other tf.metric functions as well), so in this case do I have to construct my reconstruction cost calculation using tf.metric basic functions to be able to use it as eval_metric_ops?  "}