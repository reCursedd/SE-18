{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1872", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1872/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1872/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1872/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1872", "id": 147668848, "node_id": "MDU6SXNzdWUxNDc2Njg4NDg=", "number": 1872, "title": "How to get top N results for seq2seq?", "user": {"login": "lingz", "id": 3147213, "node_id": "MDQ6VXNlcjMxNDcyMTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/3147213?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lingz", "html_url": "https://github.com/lingz", "followers_url": "https://api.github.com/users/lingz/followers", "following_url": "https://api.github.com/users/lingz/following{/other_user}", "gists_url": "https://api.github.com/users/lingz/gists{/gist_id}", "starred_url": "https://api.github.com/users/lingz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lingz/subscriptions", "organizations_url": "https://api.github.com/users/lingz/orgs", "repos_url": "https://api.github.com/users/lingz/repos", "events_url": "https://api.github.com/users/lingz/events{/privacy}", "received_events_url": "https://api.github.com/users/lingz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2016-04-12T08:10:36Z", "updated_at": "2016-04-14T03:36:39Z", "closed_at": "2016-04-14T03:36:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>In the example translate seq2seq model, mentioned in the tutorial and in the code here (reproduced below):</p>\n<pre><code>      # Get a 1-element batch to feed the sentence to the model.\n      encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n          {bucket_id: [(token_ids, [])]}, bucket_id)\n      # Get output logits for the sentence.\n      _, _, output_logits = model.step(sess, encoder_inputs, decoder_inputs,\n                                       target_weights, bucket_id, True)\n      # This is a greedy decoder - outputs are just argmaxes of output_logits.\n      outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n\n</code></pre>\n<p>It uses only a greedy decoder, and uses argmax to find the best match. I'm wondering if there's a way to get the top N results instead of just doing it greedily. I've tried argsort, but everything apart from the 0th index is just garbage results. I've also looked into tf.nn.top_k(), but because this is batched, I get the error \"List of Tensors when single Tensor expected\" and I'm not sure how to unroll the list within TF.</p>", "body_text": "In the example translate seq2seq model, mentioned in the tutorial and in the code here (reproduced below):\n      # Get a 1-element batch to feed the sentence to the model.\n      encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n          {bucket_id: [(token_ids, [])]}, bucket_id)\n      # Get output logits for the sentence.\n      _, _, output_logits = model.step(sess, encoder_inputs, decoder_inputs,\n                                       target_weights, bucket_id, True)\n      # This is a greedy decoder - outputs are just argmaxes of output_logits.\n      outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n\n\nIt uses only a greedy decoder, and uses argmax to find the best match. I'm wondering if there's a way to get the top N results instead of just doing it greedily. I've tried argsort, but everything apart from the 0th index is just garbage results. I've also looked into tf.nn.top_k(), but because this is batched, I get the error \"List of Tensors when single Tensor expected\" and I'm not sure how to unroll the list within TF.", "body": "In the example translate seq2seq model, mentioned in the tutorial and in the code here (reproduced below):\n\n```\n      # Get a 1-element batch to feed the sentence to the model.\n      encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n          {bucket_id: [(token_ids, [])]}, bucket_id)\n      # Get output logits for the sentence.\n      _, _, output_logits = model.step(sess, encoder_inputs, decoder_inputs,\n                                       target_weights, bucket_id, True)\n      # This is a greedy decoder - outputs are just argmaxes of output_logits.\n      outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n\n```\n\nIt uses only a greedy decoder, and uses argmax to find the best match. I'm wondering if there's a way to get the top N results instead of just doing it greedily. I've tried argsort, but everything apart from the 0th index is just garbage results. I've also looked into tf.nn.top_k(), but because this is batched, I get the error \"List of Tensors when single Tensor expected\" and I'm not sure how to unroll the list within TF.\n"}