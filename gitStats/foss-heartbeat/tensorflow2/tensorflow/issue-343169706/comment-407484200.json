{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/407484200", "html_url": "https://github.com/tensorflow/tensorflow/issues/20997#issuecomment-407484200", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20997", "id": 407484200, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzQ4NDIwMA==", "user": {"login": "mtiitto", "id": 26633140, "node_id": "MDQ6VXNlcjI2NjMzMTQw", "avatar_url": "https://avatars3.githubusercontent.com/u/26633140?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mtiitto", "html_url": "https://github.com/mtiitto", "followers_url": "https://api.github.com/users/mtiitto/followers", "following_url": "https://api.github.com/users/mtiitto/following{/other_user}", "gists_url": "https://api.github.com/users/mtiitto/gists{/gist_id}", "starred_url": "https://api.github.com/users/mtiitto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mtiitto/subscriptions", "organizations_url": "https://api.github.com/users/mtiitto/orgs", "repos_url": "https://api.github.com/users/mtiitto/repos", "events_url": "https://api.github.com/users/mtiitto/events{/privacy}", "received_events_url": "https://api.github.com/users/mtiitto/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-24T17:19:36Z", "updated_at": "2018-07-24T17:19:36Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">Hello,\n\nI am having trouble with the command to train a classifier (although I have\nbeen able to use this command successfully in a similar application). I am\nusing Tensorflow 1.9, and Python 3.6 (I think). I am getting ValueError:\nempty range for randrange() using the following command:\n\nmnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n\nI have copied &amp; pasted the error trace to the bottom of this email.\n\nI have attached a text file with my code that I am running in a Colab\nNotebook (I'm not sure how to share this directly so I copied &amp; pasted the\ncode and the output into the text file). I also attached a word doc where I\nhave highlighted the error message and the line where the error occurred.\n\nIs there an email address that I could use to share my notebook if this\nemail does not help clarify the problem?\n\nThank you.\n\nBelow is the error trace:\n\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-16-bd0d2bfa6c12&gt; in &lt;module&gt;()\n    137\n    138 if __name__ == \"__main__\":\n--&gt; 139   tf.app.run()\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py in\nrun(main, argv)\n    123   # Call the main function, passing through any arguments\n    124   # to the final program.\n--&gt; 125   _sys.exit(main(argv))\n    126\n\n&lt;ipython-input-16-bd0d2bfa6c12&gt; in main(unused_argv)\n    111\n    112         # Train the CNN model\n--&gt; 113\n mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n    114\n    115         # Evaluate the models and print results\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    364\n    365       saving_listeners = _check_listeners_type(saving_listeners)\n--&gt; 366       loss = self._train_model(input_fn, hooks, saving_listeners)\n    367       logging.info('Loss for final step: %s.', loss)\n    368       return self\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _train_model(self, input_fn, hooks, saving_listeners)\n   1117       return self._train_model_distributed(input_fn, hooks,\nsaving_listeners)\n   1118     else:\n-&gt; 1119       return self._train_model_default(input_fn, hooks,\nsaving_listeners)\n   1120\n   1121   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _train_model_default(self, input_fn, hooks, saving_listeners)\n   1127       features, labels, input_hooks = (\n   1128           self._get_features_and_labels_from_input_fn(\n-&gt; 1129               input_fn, model_fn_lib.ModeKeys.TRAIN))\n   1130       worker_hooks.extend(input_hooks)\n   1131       estimator_spec = self._call_model_fn(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _get_features_and_labels_from_input_fn(self, input_fn, mode)\n    983           lambda: self._call_input_fn(input_fn, mode))\n    984     else:\n--&gt; 985       result = self._call_input_fn(input_fn, mode)\n    986\n    987     return estimator_util.parse_input_fn_result(result)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _call_input_fn(self, input_fn, mode)\n   1072       kwargs['config'] = self.config\n   1073     with ops.device('/cpu:0'):\n-&gt; 1074       return input_fn(**kwargs)\n   1075\n   1076   def _call_model_fn(self, features, labels, mode, config):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/numpy_io.py\nin input_fn()\n    196         num_threads=num_threads,\n    197         enqueue_size=batch_size,\n--&gt; 198         num_epochs=num_epochs)\n    199\n    200     batch = (\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\nin _enqueue_data(data, capacity, shuffle, min_after_dequeue, num_threads,\nseed, name, enqueue_size, num_epochs, pad_value)\n    482                 random_start=shuffle,\n    483                 seed=seed_i,\n--&gt; 484                 num_epochs=num_epochs))\n    485       else:\n    486         feed_fns.append(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\nin __init__(self, placeholders, ordered_dict_of_arrays, batch_size,\nrandom_start, seed, num_epochs)\n    217     self._epoch = 0\n    218     random.seed(seed)\n--&gt; 219     self._trav = random.randrange(self._max) if random_start else 0\n    220     self._epoch_end = (self._trav - 1) % self._max\n    221\n\n/usr/lib/python3.6/random.py in randrange(self, start, stop, step, _int)\n    186             if istart &gt; 0:\n    187                 return self._randbelow(istart)\n--&gt; 188             raise ValueError(\"empty range for randrange()\")\n    189\n    190         # stop argument supplied.\n\nValueError: empty range for randrange()</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Tue, Jul 24, 2018 at 12:52 PM, Karmel Allison ***@***.***&gt; wrote:\n I apologize, but I am having a hard time understanding what the problem\n is, where the problem is, and what version it affects. What script are you\n running? What is the error trace that you are seeing?\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"343169706\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/20997\" href=\"https://github.com/tensorflow/tensorflow/issues/20997#issuecomment-407474850\">#20997 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AZZjtJIaQVKqZnLvfaO74x8cOy4bBmXgks5uJ1C2gaJpZM4VYT0n\">https://github.com/notifications/unsubscribe-auth/AZZjtJIaQVKqZnLvfaO74x8cOy4bBmXgks5uJ1C2gaJpZM4VYT0n</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \nMarkus Ville Tiitto, Pharm.D.\nPhD Student\nClinical &amp; Experimental Therapeutics\nDepartment of Pharmaceutical Sciences\nUniversity of Kentucky, College of Pharmacy\nLee Todd, Jr. Building Rm 466\n789 S. Limestone St.\nLexington, KY 40536\nVilleTiitto2@gmail.com\nmarkus.tiitto@uky.edu\n(412) 296-9192\n\nQuantitative Working Memory Model\nDate &amp; Time\n\nPurpose: This program will develop a quantitative model of the working memory deficiency. Identically-structured CNNs (lenet) will be trained with varying numbers of examples from the MNIST training set with batch size (=25) and training steps (=300) held constant. The quantitative relationship between % accuracy of identification of handwritten digits in the MNIST test set and the number of image files will be determined by non-linear regression.\n\nInputs:\n\n1) Number of ANNs per training group (set to 20 to generate a normal distribution)\n\n2) Number of images per training group (n=25, 250, 2500, 25000, 55000) Note: a unique set of training images will be used for each individual ANN in every group\n\nOutputs: N/A\n\nConclusions</div>\n<div class=\"email-signature-reply\">--------------------------------------------------------------------------------------\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Import Libraries\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport operator\nimport sys\nfrom datetime import datetime</div>\n<div class=\"email-signature-reply\">------------CNN and MNIST Function Definitions---------\n\"\"\"This section is adapted from Tensorflow 1.9 MNIST tutorial called \"Build a CNN Using Estimators\" found here: <a href=\"https://www.tensorflow.org/tutorials/layers\">https://www.tensorflow.org/tutorials/layers</a> \"\"\"\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n  # Input Layer\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a>\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=20,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a>\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  # Convolutional Layer <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115894138\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2\" href=\"https://github.com/tensorflow/tensorflow/issues/2\">#2</a> and Pooling Layer <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115894138\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2\" href=\"https://github.com/tensorflow/tensorflow/issues/2\">#2</a>\n  conv2 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=50,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n  # Dense Layer\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 50])\n  dense = tf.layers.dense(inputs=pool2_flat, units=500, activation=tf.nn.relu)\n\n  # Logits Layer\n  logits = tf.layers.dense(inputs=dense, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode) ***Learning rate = 0.001\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.AdamOptimizer()\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)</div>\n<div class=\"email-signature-reply\">----------------------Main Driver Function---------------------------------------\n\nPurpose: This function will download MNIST data, train ANNs, and evaluate these ANNs\n\ndef main(unused_argv):\n\n  #Set parameters for #ANNs to train &amp; #steps in training\n  num_ANNs = 2\n  batchsize = 25\n  train_steps = 300\n  train_set_sizes = [25,250,2500,25000,55000]\n\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n\n  <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116000652\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/55\" href=\"https://github.com/tensorflow/tensorflow/pull/55\">#55</a>,000 images in train set (28x28 grayscale)\n  train_images = mnist.train.images # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n\n  <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115914766\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/10\" href=\"https://github.com/tensorflow/tensorflow/issues/10\">#10</a>,000 images in test set (28x28 grayscale)\n  eval_data = mnist.test.images # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  #Initialize lists to hold ADHD training examples\n  train_set_examples = []\n  train_set_labels = []\n\n  #create training input function for control-ANNs &amp; evaluation input function\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n                              x={\"x\": np.asarray(train_set_examples)},\n                              y=np.asarray(train_set_labels),\n                              batch_size=25,\n                              num_epochs=None,\n                              shuffle=True)\n\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n                      x={\"x\": eval_data},\n                      y=eval_labels,\n                      num_epochs=1,\n                      shuffle=False)\n\n  #Initialize list to hold all of the accuracy data\n  all_accuracies = []\n\n  #For each training set group\n  for group_number in range(len(train_set_sizes)):\n\n      #For each ANN in training set group\n      for i in range(num_ANNs):\n\n        #Initialize group_accuracies list\n        group_accuracies = []\n\n        #--------------Generate a training set--------------------------------\n        #If size of train set &lt; 100, check to make sure there is at least one\n        #example of each digit included\n\n        if train_set_sizes[group_number] &lt;= 100:\n\n          #Initialize contains_all_digits list. This list will contain one entry per digit (n=10 entries total).\n          #The entries will be initialized with zeros, and each entry will be filled with a 1 when its corresponding\n          #digit is found in adhd_train_labels. When all entries = 1, then adhd_train set will contain all digits\n          contains_all_digits = []\n\n          for i in range(10):\n\n            contains_all_digits.append(0)\n\n          while 0 in contains_all_digits:\n\n            #Reinitialize contains_all_digits if a train set containing all digits has not been generated yet\n            for i in range(10):\n\n              contains_all_digits[i] = 0\n\n            train_set_examples = []\n            train_set_labels = []\n\n            example_select_indices = np.random.randint(0,len(train_images),size=train_set_sizes[group_number])\n\n            #randomly select examples\n            for i in range(train_set_sizes[group_number]):\n\n              random_index = example_select_indices[i]\n              train_set_examples.append(train_images[random_index])\n              train_set_labels.append(train_labels[random_index])\n\n            #check that labels contain all digits 0-9\n            for i in range(10):\n\n               if i in train_set_labels:\n                  contains_all_digits[i] = 1\n\n               else:\n                  contains_all_digits[i] = 0\n\n        else:\n\n          #Initialize train_set lists\n          train_set_examples = []\n          train_set_labels = []\n\n          #randomly select indices to pull train set examples\n          example_select_indices = np.random.randint(0,55000,size=train_set_sizes[group_number])\n\n          #For number of images in the appropriate training set group\n          for j in range(train_set_sizes[group_number]):\n\n            random_index = example_select_indices[j]\n            train_set_examples.append(train_images[random_index])\n            train_set_labels.append(train_labels[random_index])\n\n        # Create the MNIST Estimator\n        mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\n\n        # Train the CNN model\n        mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n\n        # Evaluate the models and print results\n        eval_result = mnist_classifier.evaluate(input_fn=eval_input_fn)\n        print(\"Group Number \",group_number+1,\", ANN #\",i+1,\" Accuracy: \",eval_result,\" %\")\n\n        #Record ANN accuracy\n        group_accuracies.append(eval_result)\n\n  #record group accuracies in all_accuracies\n  all_accuracies.append(group_accuracies)\n\n\n  #Print All Accuracy Results\n\n  print()\n\n  print(\"-------------------------------------Accuracy Results--------------------------------------------\")\n\n  for i in range(len(train_set_sizes)):\n\n    for j in range(numANNs):\n\n      print(\"Group #\",i+1,\", ANN #\",j+1,\" Accuracy: \",eval_result,\" %\")\n\nif __name__ == \"__main__\":\n  tf.app.run()</div>\n<div class=\"email-signature-reply\">--------------------Output--------------\nExtracting MNIST-data/train-images-idx3-ubyte.gz\nExtracting MNIST-data/train-labels-idx1-ubyte.gz\nExtracting MNIST-data/t10k-images-idx3-ubyte.gz\nExtracting MNIST-data/t10k-labels-idx1-ubyte.gz\nINFO:tensorflow:Using default config.\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpge3laept\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpge3laept', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6c08b7c88&gt;, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-16-bd0d2bfa6c12&gt; in &lt;module&gt;()\n    137\n    138 if __name__ == \"__main__\":\n--&gt; 139   tf.app.run()\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py in run(main, argv)\n    123   # Call the main function, passing through any arguments\n    124   # to the final program.\n--&gt; 125   _sys.exit(main(argv))\n    126\n\n&lt;ipython-input-16-bd0d2bfa6c12&gt; in main(unused_argv)\n    111\n    112         # Train the CNN model\n--&gt; 113         mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n    114\n    115         # Evaluate the models and print results\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    364\n    365       saving_listeners = _check_listeners_type(saving_listeners)\n--&gt; 366       loss = self._train_model(input_fn, hooks, saving_listeners)\n    367       logging.info('Loss for final step: %s.', loss)\n    368       return self\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1117       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1118     else:\n-&gt; 1119       return self._train_model_default(input_fn, hooks, saving_listeners)\n   1120\n   1121   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\n   1127       features, labels, input_hooks = (\n   1128           self._get_features_and_labels_from_input_fn(\n-&gt; 1129               input_fn, model_fn_lib.ModeKeys.TRAIN))\n   1130       worker_hooks.extend(input_hooks)\n   1131       estimator_spec = self._call_model_fn(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _get_features_and_labels_from_input_fn(self, input_fn, mode)\n    983           lambda: self._call_input_fn(input_fn, mode))\n    984     else:\n--&gt; 985       result = self._call_input_fn(input_fn, mode)\n    986\n    987     return estimator_util.parse_input_fn_result(result)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_input_fn(self, input_fn, mode)\n   1072       kwargs['config'] = self.config\n   1073     with ops.device('/cpu:0'):\n-&gt; 1074       return input_fn(**kwargs)\n   1075\n   1076   def _call_model_fn(self, features, labels, mode, config):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/numpy_io.py in input_fn()\n    196         num_threads=num_threads,\n    197         enqueue_size=batch_size,\n--&gt; 198         num_epochs=num_epochs)\n    199\n    200     batch = (\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in _enqueue_data(data, capacity, shuffle, min_after_dequeue, num_threads, seed, name, enqueue_size, num_epochs, pad_value)\n    482                 random_start=shuffle,\n    483                 seed=seed_i,\n--&gt; 484                 num_epochs=num_epochs))\n    485       else:\n    486         feed_fns.append(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in __init__(self, placeholders, ordered_dict_of_arrays, batch_size, random_start, seed, num_epochs)\n    217     self._epoch = 0\n    218     random.seed(seed)\n--&gt; 219     self._trav = random.randrange(self._max) if random_start else 0\n    220     self._epoch_end = (self._trav - 1) % self._max\n    221\n\n/usr/lib/python3.6/random.py in randrange(self, start, stop, step, _int)\n    186             if istart &gt; 0:\n    187                 return self._randbelow(istart)\n--&gt; 188             raise ValueError(\"empty range for randrange()\")\n    189\n    190         # stop argument supplied.\n\nValueError: empty range for randrange()</div>\n</div>", "body_text": "Hello,\n\nI am having trouble with the command to train a classifier (although I have\nbeen able to use this command successfully in a similar application). I am\nusing Tensorflow 1.9, and Python 3.6 (I think). I am getting ValueError:\nempty range for randrange() using the following command:\n\nmnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n\nI have copied & pasted the error trace to the bottom of this email.\n\nI have attached a text file with my code that I am running in a Colab\nNotebook (I'm not sure how to share this directly so I copied & pasted the\ncode and the output into the text file). I also attached a word doc where I\nhave highlighted the error message and the line where the error occurred.\n\nIs there an email address that I could use to share my notebook if this\nemail does not help clarify the problem?\n\nThank you.\n\nBelow is the error trace:\n\nValueError                                Traceback (most recent call last)\n<ipython-input-16-bd0d2bfa6c12> in <module>()\n    137\n    138 if __name__ == \"__main__\":\n--> 139   tf.app.run()\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py in\nrun(main, argv)\n    123   # Call the main function, passing through any arguments\n    124   # to the final program.\n--> 125   _sys.exit(main(argv))\n    126\n\n<ipython-input-16-bd0d2bfa6c12> in main(unused_argv)\n    111\n    112         # Train the CNN model\n--> 113\n mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n    114\n    115         # Evaluate the models and print results\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    364\n    365       saving_listeners = _check_listeners_type(saving_listeners)\n--> 366       loss = self._train_model(input_fn, hooks, saving_listeners)\n    367       logging.info('Loss for final step: %s.', loss)\n    368       return self\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _train_model(self, input_fn, hooks, saving_listeners)\n   1117       return self._train_model_distributed(input_fn, hooks,\nsaving_listeners)\n   1118     else:\n-> 1119       return self._train_model_default(input_fn, hooks,\nsaving_listeners)\n   1120\n   1121   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _train_model_default(self, input_fn, hooks, saving_listeners)\n   1127       features, labels, input_hooks = (\n   1128           self._get_features_and_labels_from_input_fn(\n-> 1129               input_fn, model_fn_lib.ModeKeys.TRAIN))\n   1130       worker_hooks.extend(input_hooks)\n   1131       estimator_spec = self._call_model_fn(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _get_features_and_labels_from_input_fn(self, input_fn, mode)\n    983           lambda: self._call_input_fn(input_fn, mode))\n    984     else:\n--> 985       result = self._call_input_fn(input_fn, mode)\n    986\n    987     return estimator_util.parse_input_fn_result(result)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _call_input_fn(self, input_fn, mode)\n   1072       kwargs['config'] = self.config\n   1073     with ops.device('/cpu:0'):\n-> 1074       return input_fn(**kwargs)\n   1075\n   1076   def _call_model_fn(self, features, labels, mode, config):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/numpy_io.py\nin input_fn()\n    196         num_threads=num_threads,\n    197         enqueue_size=batch_size,\n--> 198         num_epochs=num_epochs)\n    199\n    200     batch = (\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\nin _enqueue_data(data, capacity, shuffle, min_after_dequeue, num_threads,\nseed, name, enqueue_size, num_epochs, pad_value)\n    482                 random_start=shuffle,\n    483                 seed=seed_i,\n--> 484                 num_epochs=num_epochs))\n    485       else:\n    486         feed_fns.append(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\nin __init__(self, placeholders, ordered_dict_of_arrays, batch_size,\nrandom_start, seed, num_epochs)\n    217     self._epoch = 0\n    218     random.seed(seed)\n--> 219     self._trav = random.randrange(self._max) if random_start else 0\n    220     self._epoch_end = (self._trav - 1) % self._max\n    221\n\n/usr/lib/python3.6/random.py in randrange(self, start, stop, step, _int)\n    186             if istart > 0:\n    187                 return self._randbelow(istart)\n--> 188             raise ValueError(\"empty range for randrange()\")\n    189\n    190         # stop argument supplied.\n\nValueError: empty range for randrange()\n\u2026\nOn Tue, Jul 24, 2018 at 12:52 PM, Karmel Allison ***@***.***> wrote:\n I apologize, but I am having a hard time understanding what the problem\n is, where the problem is, and what version it affects. What script are you\n running? What is the error trace that you are seeing?\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#20997 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AZZjtJIaQVKqZnLvfaO74x8cOy4bBmXgks5uJ1C2gaJpZM4VYT0n>\n .\n\n\n-- \nMarkus Ville Tiitto, Pharm.D.\nPhD Student\nClinical & Experimental Therapeutics\nDepartment of Pharmaceutical Sciences\nUniversity of Kentucky, College of Pharmacy\nLee Todd, Jr. Building Rm 466\n789 S. Limestone St.\nLexington, KY 40536\nVilleTiitto2@gmail.com\nmarkus.tiitto@uky.edu\n(412) 296-9192\n\nQuantitative Working Memory Model\nDate & Time\n\nPurpose: This program will develop a quantitative model of the working memory deficiency. Identically-structured CNNs (lenet) will be trained with varying numbers of examples from the MNIST training set with batch size (=25) and training steps (=300) held constant. The quantitative relationship between % accuracy of identification of handwritten digits in the MNIST test set and the number of image files will be determined by non-linear regression.\n\nInputs:\n\n1) Number of ANNs per training group (set to 20 to generate a normal distribution)\n\n2) Number of images per training group (n=25, 250, 2500, 25000, 55000) Note: a unique set of training images will be used for each individual ANN in every group\n\nOutputs: N/A\n\nConclusions\n--------------------------------------------------------------------------------------\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Import Libraries\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport operator\nimport sys\nfrom datetime import datetime\n------------CNN and MNIST Function Definitions---------\n\"\"\"This section is adapted from Tensorflow 1.9 MNIST tutorial called \"Build a CNN Using Estimators\" found here: https://www.tensorflow.org/tutorials/layers \"\"\"\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n  # Input Layer\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer #1\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=20,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #1\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  # Convolutional Layer #2 and Pooling Layer #2\n  conv2 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=50,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n  # Dense Layer\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 50])\n  dense = tf.layers.dense(inputs=pool2_flat, units=500, activation=tf.nn.relu)\n\n  # Logits Layer\n  logits = tf.layers.dense(inputs=dense, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode) ***Learning rate = 0.001\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.AdamOptimizer()\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n----------------------Main Driver Function---------------------------------------\n\nPurpose: This function will download MNIST data, train ANNs, and evaluate these ANNs\n\ndef main(unused_argv):\n\n  #Set parameters for #ANNs to train & #steps in training\n  num_ANNs = 2\n  batchsize = 25\n  train_steps = 300\n  train_set_sizes = [25,250,2500,25000,55000]\n\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n\n  #55,000 images in train set (28x28 grayscale)\n  train_images = mnist.train.images # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n\n  #10,000 images in test set (28x28 grayscale)\n  eval_data = mnist.test.images # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  #Initialize lists to hold ADHD training examples\n  train_set_examples = []\n  train_set_labels = []\n\n  #create training input function for control-ANNs & evaluation input function\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n                              x={\"x\": np.asarray(train_set_examples)},\n                              y=np.asarray(train_set_labels),\n                              batch_size=25,\n                              num_epochs=None,\n                              shuffle=True)\n\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n                      x={\"x\": eval_data},\n                      y=eval_labels,\n                      num_epochs=1,\n                      shuffle=False)\n\n  #Initialize list to hold all of the accuracy data\n  all_accuracies = []\n\n  #For each training set group\n  for group_number in range(len(train_set_sizes)):\n\n      #For each ANN in training set group\n      for i in range(num_ANNs):\n\n        #Initialize group_accuracies list\n        group_accuracies = []\n\n        #--------------Generate a training set--------------------------------\n        #If size of train set < 100, check to make sure there is at least one\n        #example of each digit included\n\n        if train_set_sizes[group_number] <= 100:\n\n          #Initialize contains_all_digits list. This list will contain one entry per digit (n=10 entries total).\n          #The entries will be initialized with zeros, and each entry will be filled with a 1 when its corresponding\n          #digit is found in adhd_train_labels. When all entries = 1, then adhd_train set will contain all digits\n          contains_all_digits = []\n\n          for i in range(10):\n\n            contains_all_digits.append(0)\n\n          while 0 in contains_all_digits:\n\n            #Reinitialize contains_all_digits if a train set containing all digits has not been generated yet\n            for i in range(10):\n\n              contains_all_digits[i] = 0\n\n            train_set_examples = []\n            train_set_labels = []\n\n            example_select_indices = np.random.randint(0,len(train_images),size=train_set_sizes[group_number])\n\n            #randomly select examples\n            for i in range(train_set_sizes[group_number]):\n\n              random_index = example_select_indices[i]\n              train_set_examples.append(train_images[random_index])\n              train_set_labels.append(train_labels[random_index])\n\n            #check that labels contain all digits 0-9\n            for i in range(10):\n\n               if i in train_set_labels:\n                  contains_all_digits[i] = 1\n\n               else:\n                  contains_all_digits[i] = 0\n\n        else:\n\n          #Initialize train_set lists\n          train_set_examples = []\n          train_set_labels = []\n\n          #randomly select indices to pull train set examples\n          example_select_indices = np.random.randint(0,55000,size=train_set_sizes[group_number])\n\n          #For number of images in the appropriate training set group\n          for j in range(train_set_sizes[group_number]):\n\n            random_index = example_select_indices[j]\n            train_set_examples.append(train_images[random_index])\n            train_set_labels.append(train_labels[random_index])\n\n        # Create the MNIST Estimator\n        mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\n\n        # Train the CNN model\n        mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n\n        # Evaluate the models and print results\n        eval_result = mnist_classifier.evaluate(input_fn=eval_input_fn)\n        print(\"Group Number \",group_number+1,\", ANN #\",i+1,\" Accuracy: \",eval_result,\" %\")\n\n        #Record ANN accuracy\n        group_accuracies.append(eval_result)\n\n  #record group accuracies in all_accuracies\n  all_accuracies.append(group_accuracies)\n\n\n  #Print All Accuracy Results\n\n  print()\n\n  print(\"-------------------------------------Accuracy Results--------------------------------------------\")\n\n  for i in range(len(train_set_sizes)):\n\n    for j in range(numANNs):\n\n      print(\"Group #\",i+1,\", ANN #\",j+1,\" Accuracy: \",eval_result,\" %\")\n\nif __name__ == \"__main__\":\n  tf.app.run()\n--------------------Output--------------\nExtracting MNIST-data/train-images-idx3-ubyte.gz\nExtracting MNIST-data/train-labels-idx1-ubyte.gz\nExtracting MNIST-data/t10k-images-idx3-ubyte.gz\nExtracting MNIST-data/t10k-labels-idx1-ubyte.gz\nINFO:tensorflow:Using default config.\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpge3laept\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpge3laept', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6c08b7c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-16-bd0d2bfa6c12> in <module>()\n    137\n    138 if __name__ == \"__main__\":\n--> 139   tf.app.run()\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py in run(main, argv)\n    123   # Call the main function, passing through any arguments\n    124   # to the final program.\n--> 125   _sys.exit(main(argv))\n    126\n\n<ipython-input-16-bd0d2bfa6c12> in main(unused_argv)\n    111\n    112         # Train the CNN model\n--> 113         mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n    114\n    115         # Evaluate the models and print results\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    364\n    365       saving_listeners = _check_listeners_type(saving_listeners)\n--> 366       loss = self._train_model(input_fn, hooks, saving_listeners)\n    367       logging.info('Loss for final step: %s.', loss)\n    368       return self\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1117       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1118     else:\n-> 1119       return self._train_model_default(input_fn, hooks, saving_listeners)\n   1120\n   1121   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\n   1127       features, labels, input_hooks = (\n   1128           self._get_features_and_labels_from_input_fn(\n-> 1129               input_fn, model_fn_lib.ModeKeys.TRAIN))\n   1130       worker_hooks.extend(input_hooks)\n   1131       estimator_spec = self._call_model_fn(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _get_features_and_labels_from_input_fn(self, input_fn, mode)\n    983           lambda: self._call_input_fn(input_fn, mode))\n    984     else:\n--> 985       result = self._call_input_fn(input_fn, mode)\n    986\n    987     return estimator_util.parse_input_fn_result(result)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_input_fn(self, input_fn, mode)\n   1072       kwargs['config'] = self.config\n   1073     with ops.device('/cpu:0'):\n-> 1074       return input_fn(**kwargs)\n   1075\n   1076   def _call_model_fn(self, features, labels, mode, config):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/numpy_io.py in input_fn()\n    196         num_threads=num_threads,\n    197         enqueue_size=batch_size,\n--> 198         num_epochs=num_epochs)\n    199\n    200     batch = (\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in _enqueue_data(data, capacity, shuffle, min_after_dequeue, num_threads, seed, name, enqueue_size, num_epochs, pad_value)\n    482                 random_start=shuffle,\n    483                 seed=seed_i,\n--> 484                 num_epochs=num_epochs))\n    485       else:\n    486         feed_fns.append(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in __init__(self, placeholders, ordered_dict_of_arrays, batch_size, random_start, seed, num_epochs)\n    217     self._epoch = 0\n    218     random.seed(seed)\n--> 219     self._trav = random.randrange(self._max) if random_start else 0\n    220     self._epoch_end = (self._trav - 1) % self._max\n    221\n\n/usr/lib/python3.6/random.py in randrange(self, start, stop, step, _int)\n    186             if istart > 0:\n    187                 return self._randbelow(istart)\n--> 188             raise ValueError(\"empty range for randrange()\")\n    189\n    190         # stop argument supplied.\n\nValueError: empty range for randrange()", "body": "Hello,\n\nI am having trouble with the command to train a classifier (although I have\nbeen able to use this command successfully in a similar application). I am\nusing Tensorflow 1.9, and Python 3.6 (I think). I am getting ValueError:\nempty range for randrange() using the following command:\n\nmnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n\nI have copied & pasted the error trace to the bottom of this email.\n\nI have attached a text file with my code that I am running in a Colab\nNotebook (I'm not sure how to share this directly so I copied & pasted the\ncode and the output into the text file). I also attached a word doc where I\nhave highlighted the error message and the line where the error occurred.\n\nIs there an email address that I could use to share my notebook if this\nemail does not help clarify the problem?\n\nThank you.\n\nBelow is the error trace:\n\nValueError                                Traceback (most recent call last)\n<ipython-input-16-bd0d2bfa6c12> in <module>()\n    137\n    138 if __name__ == \"__main__\":\n--> 139   tf.app.run()\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py in\nrun(main, argv)\n    123   # Call the main function, passing through any arguments\n    124   # to the final program.\n--> 125   _sys.exit(main(argv))\n    126\n\n<ipython-input-16-bd0d2bfa6c12> in main(unused_argv)\n    111\n    112         # Train the CNN model\n--> 113\n mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\n    114\n    115         # Evaluate the models and print results\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    364\n    365       saving_listeners = _check_listeners_type(saving_listeners)\n--> 366       loss = self._train_model(input_fn, hooks, saving_listeners)\n    367       logging.info('Loss for final step: %s.', loss)\n    368       return self\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _train_model(self, input_fn, hooks, saving_listeners)\n   1117       return self._train_model_distributed(input_fn, hooks,\nsaving_listeners)\n   1118     else:\n-> 1119       return self._train_model_default(input_fn, hooks,\nsaving_listeners)\n   1120\n   1121   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _train_model_default(self, input_fn, hooks, saving_listeners)\n   1127       features, labels, input_hooks = (\n   1128           self._get_features_and_labels_from_input_fn(\n-> 1129               input_fn, model_fn_lib.ModeKeys.TRAIN))\n   1130       worker_hooks.extend(input_hooks)\n   1131       estimator_spec = self._call_model_fn(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _get_features_and_labels_from_input_fn(self, input_fn, mode)\n    983           lambda: self._call_input_fn(input_fn, mode))\n    984     else:\n--> 985       result = self._call_input_fn(input_fn, mode)\n    986\n    987     return estimator_util.parse_input_fn_result(result)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\nin _call_input_fn(self, input_fn, mode)\n   1072       kwargs['config'] = self.config\n   1073     with ops.device('/cpu:0'):\n-> 1074       return input_fn(**kwargs)\n   1075\n   1076   def _call_model_fn(self, features, labels, mode, config):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/numpy_io.py\nin input_fn()\n    196         num_threads=num_threads,\n    197         enqueue_size=batch_size,\n--> 198         num_epochs=num_epochs)\n    199\n    200     batch = (\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\nin _enqueue_data(data, capacity, shuffle, min_after_dequeue, num_threads,\nseed, name, enqueue_size, num_epochs, pad_value)\n    482                 random_start=shuffle,\n    483                 seed=seed_i,\n--> 484                 num_epochs=num_epochs))\n    485       else:\n    486         feed_fns.append(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\nin __init__(self, placeholders, ordered_dict_of_arrays, batch_size,\nrandom_start, seed, num_epochs)\n    217     self._epoch = 0\n    218     random.seed(seed)\n--> 219     self._trav = random.randrange(self._max) if random_start else 0\n    220     self._epoch_end = (self._trav - 1) % self._max\n    221\n\n/usr/lib/python3.6/random.py in randrange(self, start, stop, step, _int)\n    186             if istart > 0:\n    187                 return self._randbelow(istart)\n--> 188             raise ValueError(\"empty range for randrange()\")\n    189\n    190         # stop argument supplied.\n\nValueError: empty range for randrange()\n\nOn Tue, Jul 24, 2018 at 12:52 PM, Karmel Allison <notifications@github.com>\nwrote:\n\n> I apologize, but I am having a hard time understanding what the problem\n> is, where the problem is, and what version it affects. What script are you\n> running? What is the error trace that you are seeing?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/20997#issuecomment-407474850>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AZZjtJIaQVKqZnLvfaO74x8cOy4bBmXgks5uJ1C2gaJpZM4VYT0n>\n> .\n>\n\n\n\n-- \nMarkus Ville Tiitto, Pharm.D.\nPhD Student\nClinical & Experimental Therapeutics\nDepartment of Pharmaceutical Sciences\nUniversity of Kentucky, College of Pharmacy\nLee Todd, Jr. Building Rm 466\n789 S. Limestone St.\nLexington, KY 40536\nVilleTiitto2@gmail.com\nmarkus.tiitto@uky.edu\n(412) 296-9192\n\nQuantitative Working Memory Model\r\nDate & Time\r\n\r\nPurpose: This program will develop a quantitative model of the working memory deficiency. Identically-structured CNNs (lenet) will be trained with varying numbers of examples from the MNIST training set with batch size (=25) and training steps (=300) held constant. The quantitative relationship between % accuracy of identification of handwritten digits in the MNIST test set and the number of image files will be determined by non-linear regression.\r\n\r\nInputs:\r\n\r\n1) Number of ANNs per training group (set to 20 to generate a normal distribution)\r\n\r\n2) Number of images per training group (n=25, 250, 2500, 25000, 55000) Note: a unique set of training images will be used for each individual ANN in every group\r\n\r\nOutputs: N/A\r\n\r\nConclusions\r\n\r\n--------------------------------------------------------------------------------------\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\n# Import Libraries\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\nimport operator\r\nimport sys\r\nfrom datetime import datetime\r\n\r\n------------CNN and MNIST Function Definitions---------\r\n\"\"\"This section is adapted from Tensorflow 1.9 MNIST tutorial called \"Build a CNN Using Estimators\" found here: https://www.tensorflow.org/tutorials/layers \"\"\"\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\ndef cnn_model_fn(features, labels, mode):\r\n  \"\"\"Model function for CNN.\"\"\"\r\n  # Input Layer\r\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\r\n\r\n  # Convolutional Layer #1\r\n  conv1 = tf.layers.conv2d(\r\n      inputs=input_layer,\r\n      filters=20,\r\n      kernel_size=[5, 5],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n\r\n  # Pooling Layer #1\r\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\r\n\r\n  # Convolutional Layer #2 and Pooling Layer #2\r\n  conv2 = tf.layers.conv2d(\r\n      inputs=pool1,\r\n      filters=50,\r\n      kernel_size=[5, 5],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\r\n\r\n  # Dense Layer\r\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 50])\r\n  dense = tf.layers.dense(inputs=pool2_flat, units=500, activation=tf.nn.relu)\r\n\r\n  # Logits Layer\r\n  logits = tf.layers.dense(inputs=dense, units=10)\r\n\r\n  predictions = {\r\n      # Generate predictions (for PREDICT and EVAL mode)\r\n      \"classes\": tf.argmax(input=logits, axis=1),\r\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\r\n      # `logging_hook`.\r\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\r\n  }\r\n\r\n  if mode == tf.estimator.ModeKeys.PREDICT:\r\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n  # Calculate Loss (for both TRAIN and EVAL modes)\r\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\r\n\r\n  # Configure the Training Op (for TRAIN mode) ***Learning rate = 0.001\r\n  if mode == tf.estimator.ModeKeys.TRAIN:\r\n    optimizer = tf.train.AdamOptimizer()\r\n    train_op = optimizer.minimize(\r\n        loss=loss,\r\n        global_step=tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\n  # Add evaluation metrics (for EVAL mode)\r\n  eval_metric_ops = {\r\n      \"accuracy\": tf.metrics.accuracy(\r\n          labels=labels, predictions=predictions[\"classes\"])}\r\n  return tf.estimator.EstimatorSpec(\r\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n  \r\n\r\n----------------------Main Driver Function---------------------------------------\r\n\r\nPurpose: This function will download MNIST data, train ANNs, and evaluate these ANNs\r\n\r\ndef main(unused_argv):\r\n    \r\n  #Set parameters for #ANNs to train & #steps in training\r\n  num_ANNs = 2\r\n  batchsize = 25\r\n  train_steps = 300\r\n  train_set_sizes = [25,250,2500,25000,55000]\r\n  \r\n  # Load training and eval data\r\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\r\n  \r\n  #55,000 images in train set (28x28 grayscale)\r\n  train_images = mnist.train.images # Returns np.array\r\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\r\n  \r\n  #10,000 images in test set (28x28 grayscale)\r\n  eval_data = mnist.test.images # Returns np.array\r\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)  \r\n  \r\n  #Initialize lists to hold ADHD training examples\r\n  train_set_examples = []\r\n  train_set_labels = []\r\n  \r\n  #create training input function for control-ANNs & evaluation input function\r\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n                              x={\"x\": np.asarray(train_set_examples)},\r\n                              y=np.asarray(train_set_labels),\r\n                              batch_size=25,\r\n                              num_epochs=None,\r\n                              shuffle=True)\r\n  \r\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n                      x={\"x\": eval_data},\r\n                      y=eval_labels,\r\n                      num_epochs=1,\r\n                      shuffle=False)\r\n  \r\n  #Initialize list to hold all of the accuracy data\r\n  all_accuracies = []\r\n \r\n  #For each training set group\r\n  for group_number in range(len(train_set_sizes)):\r\n      \r\n      #For each ANN in training set group\r\n      for i in range(num_ANNs):\r\n        \r\n        #Initialize group_accuracies list\r\n        group_accuracies = []\r\n        \r\n        #--------------Generate a training set--------------------------------\r\n        #If size of train set < 100, check to make sure there is at least one \r\n        #example of each digit included\r\n        \r\n        if train_set_sizes[group_number] <= 100:\r\n        \r\n          #Initialize contains_all_digits list. This list will contain one entry per digit (n=10 entries total).\r\n          #The entries will be initialized with zeros, and each entry will be filled with a 1 when its corresponding\r\n          #digit is found in adhd_train_labels. When all entries = 1, then adhd_train set will contain all digits\r\n          contains_all_digits = []\r\n  \r\n          for i in range(10):\r\n      \r\n            contains_all_digits.append(0)\r\n           \r\n          while 0 in contains_all_digits:\r\n      \r\n            #Reinitialize contains_all_digits if a train set containing all digits has not been generated yet\r\n            for i in range(10):\r\n          \r\n              contains_all_digits[i] = 0\r\n    \r\n            train_set_examples = []\r\n            train_set_labels = []\r\n      \r\n            example_select_indices = np.random.randint(0,len(train_images),size=train_set_sizes[group_number])\r\n          \r\n            #randomly select examples\r\n            for i in range(train_set_sizes[group_number]):\r\n              \r\n              random_index = example_select_indices[i]\r\n              train_set_examples.append(train_images[random_index])\r\n              train_set_labels.append(train_labels[random_index])\r\n      \r\n            #check that labels contain all digits 0-9\r\n            for i in range(10):\r\n          \r\n               if i in train_set_labels:\r\n                  contains_all_digits[i] = 1\r\n          \r\n               else:\r\n                  contains_all_digits[i] = 0\r\n      \r\n        else:\r\n          \r\n          #Initialize train_set lists\r\n          train_set_examples = []\r\n          train_set_labels = []\r\n        \r\n          #randomly select indices to pull train set examples\r\n          example_select_indices = np.random.randint(0,55000,size=train_set_sizes[group_number])\r\n        \r\n          #For number of images in the appropriate training set group\r\n          for j in range(train_set_sizes[group_number]):\r\n          \r\n            random_index = example_select_indices[j]\r\n            train_set_examples.append(train_images[random_index])\r\n            train_set_labels.append(train_labels[random_index])\r\n        \r\n        # Create the MNIST Estimator\r\n        mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\r\n                                     \r\n        # Train the CNN model\r\n        mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\r\n        \r\n        # Evaluate the models and print results\r\n        eval_result = mnist_classifier.evaluate(input_fn=eval_input_fn)\r\n        print(\"Group Number \",group_number+1,\", ANN #\",i+1,\" Accuracy: \",eval_result,\" %\")\r\n      \r\n        #Record ANN accuracy\r\n        group_accuracies.append(eval_result)\r\n  \r\n  #record group accuracies in all_accuracies\r\n  all_accuracies.append(group_accuracies)\r\n  \r\n\r\n  #Print All Accuracy Results\r\n\r\n  print()\r\n\r\n  print(\"-------------------------------------Accuracy Results--------------------------------------------\")\r\n  \r\n  for i in range(len(train_set_sizes)):\r\n  \r\n    for j in range(numANNs):\r\n   \r\n      print(\"Group #\",i+1,\", ANN #\",j+1,\" Accuracy: \",eval_result,\" %\")\r\n    \r\nif __name__ == \"__main__\":\r\n  tf.app.run()\r\n\r\n--------------------Output--------------\r\nExtracting MNIST-data/train-images-idx3-ubyte.gz\r\nExtracting MNIST-data/train-labels-idx1-ubyte.gz\r\nExtracting MNIST-data/t10k-images-idx3-ubyte.gz\r\nExtracting MNIST-data/t10k-labels-idx1-ubyte.gz\r\nINFO:tensorflow:Using default config.\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpge3laept\r\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpge3laept', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6c08b7c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-16-bd0d2bfa6c12> in <module>()\r\n    137 \r\n    138 if __name__ == \"__main__\":\r\n--> 139   tf.app.run()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py in run(main, argv)\r\n    123   # Call the main function, passing through any arguments\r\n    124   # to the final program.\r\n--> 125   _sys.exit(main(argv))\r\n    126 \r\n\r\n<ipython-input-16-bd0d2bfa6c12> in main(unused_argv)\r\n    111 \r\n    112         # Train the CNN model\r\n--> 113         mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)\r\n    114 \r\n    115         # Evaluate the models and print results\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    364 \r\n    365       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 366       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    367       logging.info('Loss for final step: %s.', loss)\r\n    368       return self\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1117       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1118     else:\r\n-> 1119       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n   1120 \r\n   1121   def _train_model_default(self, input_fn, hooks, saving_listeners):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\r\n   1127       features, labels, input_hooks = (\r\n   1128           self._get_features_and_labels_from_input_fn(\r\n-> 1129               input_fn, model_fn_lib.ModeKeys.TRAIN))\r\n   1130       worker_hooks.extend(input_hooks)\r\n   1131       estimator_spec = self._call_model_fn(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _get_features_and_labels_from_input_fn(self, input_fn, mode)\r\n    983           lambda: self._call_input_fn(input_fn, mode))\r\n    984     else:\r\n--> 985       result = self._call_input_fn(input_fn, mode)\r\n    986 \r\n    987     return estimator_util.parse_input_fn_result(result)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_input_fn(self, input_fn, mode)\r\n   1072       kwargs['config'] = self.config\r\n   1073     with ops.device('/cpu:0'):\r\n-> 1074       return input_fn(**kwargs)\r\n   1075 \r\n   1076   def _call_model_fn(self, features, labels, mode, config):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/numpy_io.py in input_fn()\r\n    196         num_threads=num_threads,\r\n    197         enqueue_size=batch_size,\r\n--> 198         num_epochs=num_epochs)\r\n    199 \r\n    200     batch = (\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in _enqueue_data(data, capacity, shuffle, min_after_dequeue, num_threads, seed, name, enqueue_size, num_epochs, pad_value)\r\n    482                 random_start=shuffle,\r\n    483                 seed=seed_i,\r\n--> 484                 num_epochs=num_epochs))\r\n    485       else:\r\n    486         feed_fns.append(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in __init__(self, placeholders, ordered_dict_of_arrays, batch_size, random_start, seed, num_epochs)\r\n    217     self._epoch = 0\r\n    218     random.seed(seed)\r\n--> 219     self._trav = random.randrange(self._max) if random_start else 0\r\n    220     self._epoch_end = (self._trav - 1) % self._max\r\n    221 \r\n\r\n/usr/lib/python3.6/random.py in randrange(self, start, stop, step, _int)\r\n    186             if istart > 0:\r\n    187                 return self._randbelow(istart)\r\n--> 188             raise ValueError(\"empty range for randrange()\")\r\n    189 \r\n    190         # stop argument supplied.\r\n\r\nValueError: empty range for randrange()"}