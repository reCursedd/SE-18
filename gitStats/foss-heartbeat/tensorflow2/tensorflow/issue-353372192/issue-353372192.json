{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21828", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21828/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21828/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21828/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21828", "id": 353372192, "node_id": "MDU6SXNzdWUzNTMzNzIxOTI=", "number": 21828, "title": "I make my own Network to train machine and data is used Mnist But it's give Low accuracy and somtimes my softmax code not working as well.. so please tell me what's wrong with my code.... ", "user": {"login": "Sunil1997", "id": 26225153, "node_id": "MDQ6VXNlcjI2MjI1MTUz", "avatar_url": "https://avatars0.githubusercontent.com/u/26225153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sunil1997", "html_url": "https://github.com/Sunil1997", "followers_url": "https://api.github.com/users/Sunil1997/followers", "following_url": "https://api.github.com/users/Sunil1997/following{/other_user}", "gists_url": "https://api.github.com/users/Sunil1997/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sunil1997/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sunil1997/subscriptions", "organizations_url": "https://api.github.com/users/Sunil1997/orgs", "repos_url": "https://api.github.com/users/Sunil1997/repos", "events_url": "https://api.github.com/users/Sunil1997/events{/privacy}", "received_events_url": "https://api.github.com/users/Sunil1997/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-08-23T13:07:06Z", "updated_at": "2018-08-27T22:04:24Z", "closed_at": "2018-08-27T22:04:24Z", "author_association": "NONE", "body_html": "<p><strong>somtimes softmax give null value after updating weights so it's throw divison by zero error please check my code and tell me what's wrong with it.<br>\nUsed: python 3.6.5</strong></p>\n<p>import numpy as np<br>\nimport gzip<br>\nimport math<br>\nIMAGE_SIZE = 28</p>\n<p>def sigmoid(x):<br>\n# return (2 / (1 + np.exp(-2 * (x)))) - 1<br>\nreturn 1.0 / (1.0 + np.exp(-x))</p>\n<p>def derivation_sigmoid(x):<br>\n# return 1 - (x ** 2)<br>\nreturn x * (1.0 - x)</p>\n<p>def softmax(x):<br>\n# print np.sum(np.exp(x))<br>\nreturn (np.exp(x)) / (np.sum(np.exp(x)))</p>\n<p>def extract_data(filename, num_images):<br>\nwith gzip.open(filename) as bytestream:<br>\nbytestream.read(16)<br>\nbuf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)<br>\ndata = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)<br>\ndata = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)<br>\nreturn data</p>\n<p>def extract_labels(filename, num_images):<br>\nwith gzip.open(filename) as bytestream:<br>\nbytestream.read(8)<br>\nbuf = bytestream.read(1 * num_images)<br>\nlabels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)<br>\nreturn labels</p>\n<p>def derivation_cross(x, y):<br>\nreturn -1 * ((x * (1 / y)) + (1 - x) * (1 / (1 - y)))</p>\n<p>def derivation_softmax(x):<br>\ntem = sum(np.exp(x)) ** 2<br>\n# print tem<br>\ntem1 = sum(np.exp(x))<br>\na = []<br>\nfor i_ in range(len(x)):<br>\nt1 = (np.exp(x[i_]) * (tem1 - np.exp(x[i_]))) / tem<br>\na.append(t1)<br>\nreturn a</p>\n<p>train_data_filename = \"/home/rootpranav/Downloads/train-images-idx3-ubyte.gz\"<br>\ntrain_data = extract_data(train_data_filename, 60000)</p>\n<p>train_data_label = \"/home/rootpranav/Downloads/train-labels-idx1-ubyte.gz\"<br>\ntarin_data_label_1 = extract_labels(train_data_label, 6000)</p>\n<p>input_array = []<br>\ncounter = 0</p>\n<p>input_neurons = train_data.shape[1] * train_data.shape[1]   # Number of Feature<br>\nout_neurons = 10<br>\nhidden_layer_nurons = 15<br>\nlr = 0.1</p>\n<p>bias_hidden = np.ones((15, 1))<br>\nbias_output = np.ones((10, 1))</p>\n<p>wih = np.ones((15,784))<br>\nwho = np.ones((10, 15))</p>\n<p>def neural_network(wih, who, train_data, tarin_data_label_1):<br>\nfor e_ in range(0, 1000):<br>\nfor da_ in range(900, 980):</p>\n<pre><code>        c_error = []\n        m1 = np.matrix((train_data[da_]))\n        m2 = np.reshape(m1, (784, 1))\n        m2 = ((m2 * 1) / 255)\n        \n        hidden_sigmoid = sigmoid((np.dot(wih, m2)))\n        output = (np.dot(who, hidden_sigmoid))\n        output_softmax = softmax((np.dot(who, hidden_sigmoid)))\n\n        index = tarin_data_label_1[da_]\n        for i in range(0, 10):\n            if i != index:\n                c_error.append([0])\n            else:\n                c_error.append([1])\n        \n        a1 = np.array(c_error)\n        a2 = np.array(output_softmax)\n\n        # This is for Hidden -&gt; Output change weight\n        cross_entropy_derivation = derivation_cross(a1, a2)\n\n        # print cross_entropy_derivation\n        softmax_derivation = derivation_softmax(output)\n        sigmoid_derivation = derivation_softmax(hidden_sigmoid)\n        sigmoid_derivation = np.reshape(sigmoid_derivation, (15, 1))\n\n        m = np.reshape(softmax_derivation, (10, 1))\n        d_output = cross_entropy_derivation * m\n\n        who -= (d_output.dot(hidden_sigmoid.T))\n\n        # this is for Hidden -&gt; Input\n\n        d_hidden = who.T.dot(d_output)\n        d1 =  d_hidden * sigmoid_derivation\n        wih -= d1.dot(m2.T)\n        # print who[0]\n        test = np.argmax(output_softmax)\n        print test, index\n</code></pre>\n<p>neural_network(wih, who, train_data, tarin_data_label_1)</p>", "body_text": "somtimes softmax give null value after updating weights so it's throw divison by zero error please check my code and tell me what's wrong with it.\nUsed: python 3.6.5\nimport numpy as np\nimport gzip\nimport math\nIMAGE_SIZE = 28\ndef sigmoid(x):\n# return (2 / (1 + np.exp(-2 * (x)))) - 1\nreturn 1.0 / (1.0 + np.exp(-x))\ndef derivation_sigmoid(x):\n# return 1 - (x ** 2)\nreturn x * (1.0 - x)\ndef softmax(x):\n# print np.sum(np.exp(x))\nreturn (np.exp(x)) / (np.sum(np.exp(x)))\ndef extract_data(filename, num_images):\nwith gzip.open(filename) as bytestream:\nbytestream.read(16)\nbuf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\ndata = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\ndata = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\nreturn data\ndef extract_labels(filename, num_images):\nwith gzip.open(filename) as bytestream:\nbytestream.read(8)\nbuf = bytestream.read(1 * num_images)\nlabels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\nreturn labels\ndef derivation_cross(x, y):\nreturn -1 * ((x * (1 / y)) + (1 - x) * (1 / (1 - y)))\ndef derivation_softmax(x):\ntem = sum(np.exp(x)) ** 2\n# print tem\ntem1 = sum(np.exp(x))\na = []\nfor i_ in range(len(x)):\nt1 = (np.exp(x[i_]) * (tem1 - np.exp(x[i_]))) / tem\na.append(t1)\nreturn a\ntrain_data_filename = \"/home/rootpranav/Downloads/train-images-idx3-ubyte.gz\"\ntrain_data = extract_data(train_data_filename, 60000)\ntrain_data_label = \"/home/rootpranav/Downloads/train-labels-idx1-ubyte.gz\"\ntarin_data_label_1 = extract_labels(train_data_label, 6000)\ninput_array = []\ncounter = 0\ninput_neurons = train_data.shape[1] * train_data.shape[1]   # Number of Feature\nout_neurons = 10\nhidden_layer_nurons = 15\nlr = 0.1\nbias_hidden = np.ones((15, 1))\nbias_output = np.ones((10, 1))\nwih = np.ones((15,784))\nwho = np.ones((10, 15))\ndef neural_network(wih, who, train_data, tarin_data_label_1):\nfor e_ in range(0, 1000):\nfor da_ in range(900, 980):\n        c_error = []\n        m1 = np.matrix((train_data[da_]))\n        m2 = np.reshape(m1, (784, 1))\n        m2 = ((m2 * 1) / 255)\n        \n        hidden_sigmoid = sigmoid((np.dot(wih, m2)))\n        output = (np.dot(who, hidden_sigmoid))\n        output_softmax = softmax((np.dot(who, hidden_sigmoid)))\n\n        index = tarin_data_label_1[da_]\n        for i in range(0, 10):\n            if i != index:\n                c_error.append([0])\n            else:\n                c_error.append([1])\n        \n        a1 = np.array(c_error)\n        a2 = np.array(output_softmax)\n\n        # This is for Hidden -> Output change weight\n        cross_entropy_derivation = derivation_cross(a1, a2)\n\n        # print cross_entropy_derivation\n        softmax_derivation = derivation_softmax(output)\n        sigmoid_derivation = derivation_softmax(hidden_sigmoid)\n        sigmoid_derivation = np.reshape(sigmoid_derivation, (15, 1))\n\n        m = np.reshape(softmax_derivation, (10, 1))\n        d_output = cross_entropy_derivation * m\n\n        who -= (d_output.dot(hidden_sigmoid.T))\n\n        # this is for Hidden -> Input\n\n        d_hidden = who.T.dot(d_output)\n        d1 =  d_hidden * sigmoid_derivation\n        wih -= d1.dot(m2.T)\n        # print who[0]\n        test = np.argmax(output_softmax)\n        print test, index\n\nneural_network(wih, who, train_data, tarin_data_label_1)", "body": "**somtimes softmax give null value after updating weights so it's throw divison by zero error please check my code and tell me what's wrong with it.\r\nUsed: python 3.6.5**\r\n\r\n\r\nimport numpy as np\r\nimport gzip\r\nimport math\r\nIMAGE_SIZE = 28\r\n\r\n\r\ndef sigmoid(x):\r\n    # return (2 / (1 + np.exp(-2 * (x)))) - 1\r\n    return 1.0 / (1.0 + np.exp(-x))\r\n\r\n\r\ndef derivation_sigmoid(x):\r\n    # return 1 - (x ** 2)\r\n    return x * (1.0 - x)\r\n\r\n\r\ndef softmax(x):\r\n    # print np.sum(np.exp(x))\r\n    return (np.exp(x)) / (np.sum(np.exp(x)))\r\n\r\n\r\ndef extract_data(filename, num_images):\r\n  with gzip.open(filename) as bytestream:\r\n    bytestream.read(16)\r\n    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\r\n    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\r\n    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\r\n    return data\r\n\r\n\r\n\r\ndef extract_labels(filename, num_images):\r\n  with gzip.open(filename) as bytestream:\r\n    bytestream.read(8)\r\n    buf = bytestream.read(1 * num_images)\r\n    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\r\n  return labels\r\n\r\n\r\ndef derivation_cross(x, y):\r\n    return -1 * ((x * (1 / y)) + (1 - x) * (1 / (1 - y)))\r\n\r\ndef derivation_softmax(x):\r\n    tem = sum(np.exp(x)) ** 2\r\n    # print tem\r\n    tem1 = sum(np.exp(x))\r\n    a = []\r\n    for i_ in range(len(x)):\r\n        t1 = (np.exp(x[i_]) * (tem1 - np.exp(x[i_]))) / tem\r\n        a.append(t1)\r\n    return a\r\n\r\ntrain_data_filename = \"/home/rootpranav/Downloads/train-images-idx3-ubyte.gz\"\r\ntrain_data = extract_data(train_data_filename, 60000)\r\n\r\ntrain_data_label = \"/home/rootpranav/Downloads/train-labels-idx1-ubyte.gz\"\r\ntarin_data_label_1 = extract_labels(train_data_label, 6000)\r\n\r\ninput_array = []\r\ncounter = 0\r\n\r\n\r\ninput_neurons = train_data.shape[1] * train_data.shape[1]   # Number of Feature\r\nout_neurons = 10\r\nhidden_layer_nurons = 15\r\nlr = 0.1\r\n\r\nbias_hidden = np.ones((15, 1))\r\nbias_output = np.ones((10, 1))\r\n\r\nwih = np.ones((15,784))\r\nwho = np.ones((10, 15))\r\n\r\ndef neural_network(wih, who, train_data, tarin_data_label_1):\r\n    for e_ in range(0, 1000):\r\n        for da_ in range(900, 980):\r\n            \r\n            c_error = []\r\n            m1 = np.matrix((train_data[da_]))\r\n            m2 = np.reshape(m1, (784, 1))\r\n            m2 = ((m2 * 1) / 255)\r\n            \r\n            hidden_sigmoid = sigmoid((np.dot(wih, m2)))\r\n            output = (np.dot(who, hidden_sigmoid))\r\n            output_softmax = softmax((np.dot(who, hidden_sigmoid)))\r\n\r\n            index = tarin_data_label_1[da_]\r\n            for i in range(0, 10):\r\n                if i != index:\r\n                    c_error.append([0])\r\n                else:\r\n                    c_error.append([1])\r\n            \r\n            a1 = np.array(c_error)\r\n            a2 = np.array(output_softmax)\r\n\r\n            # This is for Hidden -> Output change weight\r\n            cross_entropy_derivation = derivation_cross(a1, a2)\r\n\r\n            # print cross_entropy_derivation\r\n            softmax_derivation = derivation_softmax(output)\r\n            sigmoid_derivation = derivation_softmax(hidden_sigmoid)\r\n            sigmoid_derivation = np.reshape(sigmoid_derivation, (15, 1))\r\n\r\n            m = np.reshape(softmax_derivation, (10, 1))\r\n            d_output = cross_entropy_derivation * m\r\n\r\n            who -= (d_output.dot(hidden_sigmoid.T))\r\n\r\n            # this is for Hidden -> Input\r\n\r\n            d_hidden = who.T.dot(d_output)\r\n            d1 =  d_hidden * sigmoid_derivation\r\n            wih -= d1.dot(m2.T)\r\n            # print who[0]\r\n            test = np.argmax(output_softmax)\r\n            print test, index\r\n\r\n\r\n\r\nneural_network(wih, who, train_data, tarin_data_label_1)"}