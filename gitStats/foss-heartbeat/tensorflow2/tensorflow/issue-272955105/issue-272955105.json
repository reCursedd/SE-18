{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14451", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14451/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14451/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14451/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14451", "id": 272955105, "node_id": "MDU6SXNzdWUyNzI5NTUxMDU=", "number": 14451, "title": "Oversampling functionality in dataset API", "user": {"login": "kmkolasinski", "id": 10145864, "node_id": "MDQ6VXNlcjEwMTQ1ODY0", "avatar_url": "https://avatars3.githubusercontent.com/u/10145864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmkolasinski", "html_url": "https://github.com/kmkolasinski", "followers_url": "https://api.github.com/users/kmkolasinski/followers", "following_url": "https://api.github.com/users/kmkolasinski/following{/other_user}", "gists_url": "https://api.github.com/users/kmkolasinski/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmkolasinski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmkolasinski/subscriptions", "organizations_url": "https://api.github.com/users/kmkolasinski/orgs", "repos_url": "https://api.github.com/users/kmkolasinski/repos", "events_url": "https://api.github.com/users/kmkolasinski/events{/privacy}", "received_events_url": "https://api.github.com/users/kmkolasinski/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-11-10T14:47:09Z", "updated_at": "2017-11-11T09:43:42Z", "closed_at": "2017-11-10T21:32:02Z", "author_association": "NONE", "body_html": "<p>Hello,<br>\nI would like to ask if current API of datasets allows for implementation of oversampling algorithm? I deal with highly imbalanced class problem. I was thinking that it would be nice to oversample specific classes during dataset parsing i.e. online generation. I've seen the implementation for <code>rejection_resample</code>  function, however this removes samples instead of duplicating them and its slows down batch generation (when target distribution is much different then initial one). The thing I would like to achieve is: to take an example, look at its class probability decide if duplicate it or not. Then call <code>dataset.shuffle(...)</code> <code>dataset.batch(...)</code> and get iterator. The best (in my opinion) approach would be to oversample low probable classes and subsample most probable ones. I would like to do it online since it's more flexible. Just wondering if this is possible with current API?</p>", "body_text": "Hello,\nI would like to ask if current API of datasets allows for implementation of oversampling algorithm? I deal with highly imbalanced class problem. I was thinking that it would be nice to oversample specific classes during dataset parsing i.e. online generation. I've seen the implementation for rejection_resample  function, however this removes samples instead of duplicating them and its slows down batch generation (when target distribution is much different then initial one). The thing I would like to achieve is: to take an example, look at its class probability decide if duplicate it or not. Then call dataset.shuffle(...) dataset.batch(...) and get iterator. The best (in my opinion) approach would be to oversample low probable classes and subsample most probable ones. I would like to do it online since it's more flexible. Just wondering if this is possible with current API?", "body": "Hello,\r\nI would like to ask if current API of datasets allows for implementation of oversampling algorithm? I deal with highly imbalanced class problem. I was thinking that it would be nice to oversample specific classes during dataset parsing i.e. online generation. I've seen the implementation for `rejection_resample`  function, however this removes samples instead of duplicating them and its slows down batch generation (when target distribution is much different then initial one). The thing I would like to achieve is: to take an example, look at its class probability decide if duplicate it or not. Then call `dataset.shuffle(...)` `dataset.batch(...)` and get iterator. The best (in my opinion) approach would be to oversample low probable classes and subsample most probable ones. I would like to do it online since it's more flexible. Just wondering if this is possible with current API? "}