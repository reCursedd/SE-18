{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10370", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10370/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10370/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10370/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10370", "id": 232869744, "node_id": "MDU6SXNzdWUyMzI4Njk3NDQ=", "number": 10370, "title": "Bug: ProtoBuf tokenizer crashes when loading single_image_random_dot_stereograms OP", "user": {"login": "MaximilianKoestler", "id": 6814304, "node_id": "MDQ6VXNlcjY4MTQzMDQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/6814304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MaximilianKoestler", "html_url": "https://github.com/MaximilianKoestler", "followers_url": "https://api.github.com/users/MaximilianKoestler/followers", "following_url": "https://api.github.com/users/MaximilianKoestler/following{/other_user}", "gists_url": "https://api.github.com/users/MaximilianKoestler/gists{/gist_id}", "starred_url": "https://api.github.com/users/MaximilianKoestler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MaximilianKoestler/subscriptions", "organizations_url": "https://api.github.com/users/MaximilianKoestler/orgs", "repos_url": "https://api.github.com/users/MaximilianKoestler/repos", "events_url": "https://api.github.com/users/MaximilianKoestler/events{/privacy}", "received_events_url": "https://api.github.com/users/MaximilianKoestler/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "josh11b", "id": 15258583, "node_id": "MDQ6VXNlcjE1MjU4NTgz", "avatar_url": "https://avatars0.githubusercontent.com/u/15258583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josh11b", "html_url": "https://github.com/josh11b", "followers_url": "https://api.github.com/users/josh11b/followers", "following_url": "https://api.github.com/users/josh11b/following{/other_user}", "gists_url": "https://api.github.com/users/josh11b/gists{/gist_id}", "starred_url": "https://api.github.com/users/josh11b/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josh11b/subscriptions", "organizations_url": "https://api.github.com/users/josh11b/orgs", "repos_url": "https://api.github.com/users/josh11b/repos", "events_url": "https://api.github.com/users/josh11b/events{/privacy}", "received_events_url": "https://api.github.com/users/josh11b/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "josh11b", "id": 15258583, "node_id": "MDQ6VXNlcjE1MjU4NTgz", "avatar_url": "https://avatars0.githubusercontent.com/u/15258583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josh11b", "html_url": "https://github.com/josh11b", "followers_url": "https://api.github.com/users/josh11b/followers", "following_url": "https://api.github.com/users/josh11b/following{/other_user}", "gists_url": "https://api.github.com/users/josh11b/gists{/gist_id}", "starred_url": "https://api.github.com/users/josh11b/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josh11b/subscriptions", "organizations_url": "https://api.github.com/users/josh11b/orgs", "repos_url": "https://api.github.com/users/josh11b/repos", "events_url": "https://api.github.com/users/josh11b/events{/privacy}", "received_events_url": "https://api.github.com/users/josh11b/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2017-06-01T12:55:17Z", "updated_at": "2018-11-17T19:38:16Z", "closed_at": "2018-11-17T19:38:15Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li>No custom code</li>\n<li>Ubuntu 17.04 (also confirmed on 16.04)</li>\n<li>TensorFlow installed from source</li>\n<li>TensorFlow version: v1.2.0-rc0-486-g95d90ab2e 1.2.0-rc1</li>\n<li>Bazel version: 0.5.0</li>\n<li>Python version: 3.5.3 (also confirmed on 2.7.12):</li>\n<li>Not tested with GPU support:</li>\n</ul>\n<h2>Reproduction</h2>\n<pre><code>import tensorflow as tf\nregressor = tf.contrib.learn.LinearRegressor(feature_columns=[])\n</code></pre>\n<p>Alternative:</p>\n<pre><code>import keras\n</code></pre>\n<p>Reference: <a href=\"https://stackoverflow.com/questions/44291072/google-protobuf-text-format-parseerror-when-instantiating-a-tensorflow-model-wit\" rel=\"nofollow\">Stackoverflow</a></p>\n<h2>Manifestation of the error</h2>\n<p>The first method to reproduce should cause an assert due to the empty <code>feature_columns</code>.<br>\nInstead, the protobuf tokenizer crashes with:</p>\n<blockquote>\n<p>Traceback (most recent call last):<br>\nFile \"\", line 1, in <br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/lazy_loader.py\", line 53, in <strong>getattr</strong><br>\nmodule = self._load()<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/lazy_loader.py\", line 42, in _load<br>\nmodule = importlib.import_module(self.<strong>name</strong>)<br>\nFile \"/usr/lib/python3.5/importlib/<strong>init</strong>.py\", line 126, in import_module<br>\nreturn _bootstrap._gcd_import(name[level:], package, level)<br>\nFile \"\", line 986, in _gcd_import<br>\nFile \"\", line 969, in _find_and_load<br>\nFile \"\", line 958, in _find_and_load_unlocked<br>\nFile \"\", line 673, in _load_unlocked<br>\nFile \"\", line 673, in exec_module<br>\nFile \"\", line 222, in _call_with_frames_removed<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/<strong>init</strong>.py\", line 35, in <br>\nfrom tensorflow.contrib import image<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/<strong>init</strong>.py\", line 40, in <br>\nfrom tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereograms<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/python/ops/single_image_random_dot_stereograms.py\", line 26, in <br>\n\"_single_image_random_dot_stereograms.so\"))<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/util/loader.py\", line 55, in load_op_library<br>\nret = load_library.load_op_library(path)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/load_library.py\", line 84, in load_op_library<br>\nexec(wrappers, module.<strong>dict</strong>)<br>\nFile \"\", line 248, in <br>\nFile \"\", line 114, in _InitOpDefLibrary<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 481, in Merge<br>\ndescriptor_pool=descriptor_pool)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 535, in MergeLines<br>\nreturn parser.MergeLines(lines, message)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 568, in MergeLines<br>\nself._ParseOrMerge(lines, message)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 583, in _ParseOrMerge<br>\nself._MergeField(tokenizer, message)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField<br>\nmerger(tokenizer, message, field)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField<br>\nself._MergeField(tokenizer, sub_message)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField<br>\nmerger(tokenizer, message, field)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField<br>\nself._MergeField(tokenizer, sub_message)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField<br>\nmerger(tokenizer, message, field)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField<br>\nself._MergeField(tokenizer, sub_message)<br>\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 652, in _MergeField<br>\n(message_descriptor.full_name, name))<br>\ngoogle.protobuf.text_format.ParseError: 48:12 : Message type \"tensorflow.AttrValue\" has no field named \"5\".</p>\n</blockquote>\n<h2>What causes this exception?</h2>\n<p>The problem is the information extracted from the <code>_single_image_random_dot_stereograms.so</code> library file from <code>/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/python/ops/</code><br>\nThis file contains encoded information passed to protobuf.</p>\n<p>The problem occurs when a line with a <code>float</code> default is parsed.</p>\n<p>In this case, it is the sequence</p>\n<pre><code>eye_separation: float = 2.5\n</code></pre>\n<p>at offset <em>0xa3b4</em> in <code>emphasized _single_image_random_dot_stereograms.so</code></p>\n<p>Somehow, the parser replaces decimal points with commas. In the end, this is created:</p>\n<pre><code>attr {\\n'\n  name: \"eye_separation\"\\n'\n  type: \"float\"\\n'\n  default_value {\\n'\n    f: 2,5\\n'\n  }\\n'\n}\\n'\n</code></pre>\n<p>The tokenizer (at <code>google/protobuf/text_format.py</code>) gets confused by the <code>,</code> in the default value and thinks that <code>5</code> is a separate field.</p>\n<h2>Root of the error</h2>\n<p>The error occurs during the execution of <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/load_library.py#L72\">load_library.py</a>.</p>\n<pre><code>op_list_str = py_tf.TF_GetOpList(lib_handle)\nop_list = op_def_pb2.OpList()\nop_list.ParseFromString(compat.as_bytes(op_list_str))\nwrappers = py_tf.GetPythonWrappers(op_list_str)\n</code></pre>\n<p><code>op_list</code> contains the correct default value of <code>2.5</code>, whereas <code>wrappers</code>, the wrapped list returned from <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/python_op_gen.cc#L762\">python_op_gen.cc</a> contains a <code>2,5</code>.</p>\n<p>This is what <code>GetPythonWrappers</code> does:</p>\n<pre><code>string GetPythonWrappers(const char* op_list_buf, size_t op_list_len) {\n  string op_list_str(op_list_buf, op_list_len);\n  OpList ops;\n  ops.ParseFromString(op_list_str);\n  return GetPythonOps(ops, {}, false);\n}\n</code></pre>\n<p>The appended files include the contents of the <code>op_list</code> and the <code>wrappers</code> variable:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/1044775/op_list.txt\">op_list.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/1044777/wrapper.txt\">wrapper.txt</a></p>", "body_text": "System information\n\nNo custom code\nUbuntu 17.04 (also confirmed on 16.04)\nTensorFlow installed from source\nTensorFlow version: v1.2.0-rc0-486-g95d90ab2e 1.2.0-rc1\nBazel version: 0.5.0\nPython version: 3.5.3 (also confirmed on 2.7.12):\nNot tested with GPU support:\n\nReproduction\nimport tensorflow as tf\nregressor = tf.contrib.learn.LinearRegressor(feature_columns=[])\n\nAlternative:\nimport keras\n\nReference: Stackoverflow\nManifestation of the error\nThe first method to reproduce should cause an assert due to the empty feature_columns.\nInstead, the protobuf tokenizer crashes with:\n\nTraceback (most recent call last):\nFile \"\", line 1, in \nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/lazy_loader.py\", line 53, in getattr\nmodule = self._load()\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/lazy_loader.py\", line 42, in _load\nmodule = importlib.import_module(self.name)\nFile \"/usr/lib/python3.5/importlib/init.py\", line 126, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\nFile \"\", line 986, in _gcd_import\nFile \"\", line 969, in _find_and_load\nFile \"\", line 958, in _find_and_load_unlocked\nFile \"\", line 673, in _load_unlocked\nFile \"\", line 673, in exec_module\nFile \"\", line 222, in _call_with_frames_removed\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/init.py\", line 35, in \nfrom tensorflow.contrib import image\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/init.py\", line 40, in \nfrom tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereograms\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/python/ops/single_image_random_dot_stereograms.py\", line 26, in \n\"_single_image_random_dot_stereograms.so\"))\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\nret = load_library.load_op_library(path)\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/load_library.py\", line 84, in load_op_library\nexec(wrappers, module.dict)\nFile \"\", line 248, in \nFile \"\", line 114, in _InitOpDefLibrary\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 481, in Merge\ndescriptor_pool=descriptor_pool)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 535, in MergeLines\nreturn parser.MergeLines(lines, message)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 568, in MergeLines\nself._ParseOrMerge(lines, message)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 583, in _ParseOrMerge\nself._MergeField(tokenizer, message)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField\nmerger(tokenizer, message, field)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField\nself._MergeField(tokenizer, sub_message)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField\nmerger(tokenizer, message, field)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField\nself._MergeField(tokenizer, sub_message)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField\nmerger(tokenizer, message, field)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField\nself._MergeField(tokenizer, sub_message)\nFile \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 652, in _MergeField\n(message_descriptor.full_name, name))\ngoogle.protobuf.text_format.ParseError: 48:12 : Message type \"tensorflow.AttrValue\" has no field named \"5\".\n\nWhat causes this exception?\nThe problem is the information extracted from the _single_image_random_dot_stereograms.so library file from /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/python/ops/\nThis file contains encoded information passed to protobuf.\nThe problem occurs when a line with a float default is parsed.\nIn this case, it is the sequence\neye_separation: float = 2.5\n\nat offset 0xa3b4 in emphasized _single_image_random_dot_stereograms.so\nSomehow, the parser replaces decimal points with commas. In the end, this is created:\nattr {\\n'\n  name: \"eye_separation\"\\n'\n  type: \"float\"\\n'\n  default_value {\\n'\n    f: 2,5\\n'\n  }\\n'\n}\\n'\n\nThe tokenizer (at google/protobuf/text_format.py) gets confused by the , in the default value and thinks that 5 is a separate field.\nRoot of the error\nThe error occurs during the execution of load_library.py.\nop_list_str = py_tf.TF_GetOpList(lib_handle)\nop_list = op_def_pb2.OpList()\nop_list.ParseFromString(compat.as_bytes(op_list_str))\nwrappers = py_tf.GetPythonWrappers(op_list_str)\n\nop_list contains the correct default value of 2.5, whereas wrappers, the wrapped list returned from python_op_gen.cc contains a 2,5.\nThis is what GetPythonWrappers does:\nstring GetPythonWrappers(const char* op_list_buf, size_t op_list_len) {\n  string op_list_str(op_list_buf, op_list_len);\n  OpList ops;\n  ops.ParseFromString(op_list_str);\n  return GetPythonOps(ops, {}, false);\n}\n\nThe appended files include the contents of the op_list and the wrappers variable:\nop_list.txt\nwrapper.txt", "body": "### System information\r\n- No custom code\r\n- Ubuntu 17.04 (also confirmed on 16.04)\r\n- TensorFlow installed from source\r\n- TensorFlow version: v1.2.0-rc0-486-g95d90ab2e 1.2.0-rc1\r\n- Bazel version: 0.5.0\r\n- Python version: 3.5.3 (also confirmed on 2.7.12):\r\n- Not tested with GPU support:\r\n\r\nReproduction\r\n------------------\r\n\r\n    import tensorflow as tf\r\n    regressor = tf.contrib.learn.LinearRegressor(feature_columns=[])\r\n\r\nAlternative:\r\n\r\n    import keras\r\n\r\nReference: [Stackoverflow](https://stackoverflow.com/questions/44291072/google-protobuf-text-format-parseerror-when-instantiating-a-tensorflow-model-wit)\r\n\r\nManifestation of the error\r\n---------------------------------\r\n\r\nThe first method to reproduce should cause an assert due to the empty `feature_columns`.\r\nInstead, the protobuf tokenizer crashes with:\r\n\r\n> Traceback (most recent call last):\r\n>  File \"<stdin>\", line 1, in <module>\r\n>  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/lazy_loader.py\", line 53, in __getattr__\r\n>    module = self._load()\r\n>  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/lazy_loader.py\", line 42, in _load\r\n>    module = importlib.import_module(self.__name__)\r\n>  File \"/usr/lib/python3.5/importlib/__init__.py\", line 126, in import_module\r\n>    return _bootstrap._gcd_import(name[level:], package, level)\r\n>  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n>  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n>  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n>  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\r\n>  File \"<frozen importlib._bootstrap_external>\", line 673, in exec_module\r\n>  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n>  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/__init__.py\", line 35, in <module>\r\n>    from tensorflow.contrib import image\r\n>  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/__init__.py\", line 40, in <module>\r\n>    from tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereograms\r\n>  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/python/ops/single_image_random_dot_stereograms.py\", line 26, in <module>\r\n>    \"_single_image_random_dot_stereograms.so\"))\r\n>  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\r\n>    ret = load_library.load_op_library(path)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/load_library.py\", line 84, in load_op_library\r\n>    exec(wrappers, module.__dict__)\r\n>  File \"<string>\", line 248, in <module>\r\n>  File \"<string>\", line 114, in _InitOpDefLibrary\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 481, in Merge\r\n>    descriptor_pool=descriptor_pool)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 535, in MergeLines\r\n>    return parser.MergeLines(lines, message)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 568, in MergeLines\r\n>    self._ParseOrMerge(lines, message)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 583, in _ParseOrMerge\r\n>    self._MergeField(tokenizer, message)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField\r\n>    merger(tokenizer, message, field)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField\r\n>    self._MergeField(tokenizer, sub_message)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField\r\n>    merger(tokenizer, message, field)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField\r\n>    self._MergeField(tokenizer, sub_message)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 684, in _MergeField\r\n>    merger(tokenizer, message, field)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 773, in _MergeMessageField\r\n>    self._MergeField(tokenizer, sub_message)\r\n>  File \"/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py\", line 652, in _MergeField\r\n>    (message_descriptor.full_name, name))\r\n>google.protobuf.text_format.ParseError: 48:12 : Message type \"tensorflow.AttrValue\" has no field named \"5\".\r\n\r\nWhat causes this exception?\r\n--------------------------------------\r\n\r\nThe problem is the information extracted from the `_single_image_random_dot_stereograms.so` library file from `/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/python/ops/`\r\nThis file contains encoded information passed to protobuf.\r\n\r\nThe problem occurs when a line with a `float` default is parsed.\r\n\r\nIn this case, it is the sequence\r\n\r\n    eye_separation: float = 2.5\r\n\r\nat offset *0xa3b4* in `emphasized _single_image_random_dot_stereograms.so`\r\n\r\nSomehow, the parser replaces decimal points with commas. In the end, this is created:\r\n\r\n    attr {\\n'\r\n      name: \"eye_separation\"\\n'\r\n      type: \"float\"\\n'\r\n      default_value {\\n'\r\n        f: 2,5\\n'\r\n      }\\n'\r\n    }\\n'\r\n\r\nThe tokenizer (at `google/protobuf/text_format.py`) gets confused by the `,` in the default value and thinks that `5` is a separate field.\r\n\r\nRoot of the error\r\n---------------------\r\n\r\nThe error occurs during the execution of [load_library.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/load_library.py#L72).\r\n\r\n    op_list_str = py_tf.TF_GetOpList(lib_handle)\r\n    op_list = op_def_pb2.OpList()\r\n    op_list.ParseFromString(compat.as_bytes(op_list_str))\r\n    wrappers = py_tf.GetPythonWrappers(op_list_str)\r\n\r\n`op_list` contains the correct default value of `2.5`, whereas `wrappers`, the wrapped list returned from [python_op_gen.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/python_op_gen.cc#L762) contains a `2,5`.\r\n\r\nThis is what `GetPythonWrappers` does:\r\n\r\n    string GetPythonWrappers(const char* op_list_buf, size_t op_list_len) {\r\n      string op_list_str(op_list_buf, op_list_len);\r\n      OpList ops;\r\n      ops.ParseFromString(op_list_str);\r\n      return GetPythonOps(ops, {}, false);\r\n    }\r\n\r\nThe appended files include the contents of the `op_list` and the `wrappers` variable:\r\n[op_list.txt](https://github.com/tensorflow/tensorflow/files/1044775/op_list.txt)\r\n[wrapper.txt](https://github.com/tensorflow/tensorflow/files/1044777/wrapper.txt)\r\n\r\n"}