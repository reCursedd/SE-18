{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7255", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7255/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7255/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7255/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7255", "id": 205300960, "node_id": "MDU6SXNzdWUyMDUzMDA5NjA=", "number": 7255, "title": "Multi-GPU training drastically slow after recent commit", "user": {"login": "rohitgirdhar", "id": 1893429, "node_id": "MDQ6VXNlcjE4OTM0Mjk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1893429?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohitgirdhar", "html_url": "https://github.com/rohitgirdhar", "followers_url": "https://api.github.com/users/rohitgirdhar/followers", "following_url": "https://api.github.com/users/rohitgirdhar/following{/other_user}", "gists_url": "https://api.github.com/users/rohitgirdhar/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohitgirdhar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohitgirdhar/subscriptions", "organizations_url": "https://api.github.com/users/rohitgirdhar/orgs", "repos_url": "https://api.github.com/users/rohitgirdhar/repos", "events_url": "https://api.github.com/users/rohitgirdhar/events{/privacy}", "received_events_url": "https://api.github.com/users/rohitgirdhar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-02-03T23:49:12Z", "updated_at": "2017-02-09T00:34:14Z", "closed_at": "2017-02-09T00:34:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I recently upgraded to the latest master, in order to fix the issues caused by this bug: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"202880401\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/7038\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7038/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/7038\">#7038</a><br>\nThough the above fix does resolve the issue of same batch being pulled from the GPU, now my model training has become drastically slow (&gt; 4x), and most time is being spent in dequeues. A timeline snapshot is here:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/1893429/22612749/be748f0c-ea40-11e6-9efb-989b9466301a.png\"><img src=\"https://cloud.githubusercontent.com/assets/1893429/22612749/be748f0c-ea40-11e6-9efb-989b9466301a.png\" alt=\"screenshot from 2017-02-03 18-43-55\" style=\"max-width:100%;\"></a></p>\n<p>Any ideas as to what might be going wrong?</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"202880401\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/7038\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7038/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/7038\">#7038</a></p>\n<h3>Environment info</h3>\n<p>Operating System: CentOS 6.5</p>\n<p>Installed version of CUDA and cuDNN: 8.0.27 and 5.1<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>): <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/084b37a00f3cf2cc89d433528ca63ec1d3b5b313/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/084b37a00f3cf2cc89d433528ca63ec1d3b5b313\"><tt>084b37a</tt></a></li>\n<li>The output of <code>bazel version</code></li>\n</ol>\n<pre><code>Build label: 0.4.3- (@non-git)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Dec 23 16:35:28 2016 (1482510928)\nBuild timestamp: 1482510928\nBuild timestamp as int: 1482510928\n</code></pre>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>My code is based on the tensorflow/models/slim interface</p>", "body_text": "I recently upgraded to the latest master, in order to fix the issues caused by this bug: #7038\nThough the above fix does resolve the issue of same batch being pulled from the GPU, now my model training has become drastically slow (> 4x), and most time is being spent in dequeues. A timeline snapshot is here:\n\nAny ideas as to what might be going wrong?\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n#7038\nEnvironment info\nOperating System: CentOS 6.5\nInstalled version of CUDA and cuDNN: 8.0.27 and 5.1\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n\nThe commit hash (git rev-parse HEAD): 084b37a\nThe output of bazel version\n\nBuild label: 0.4.3- (@non-git)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Dec 23 16:35:28 2016 (1482510928)\nBuild timestamp: 1482510928\nBuild timestamp as int: 1482510928\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nMy code is based on the tensorflow/models/slim interface", "body": "I recently upgraded to the latest master, in order to fix the issues caused by this bug: https://github.com/tensorflow/tensorflow/issues/7038\r\nThough the above fix does resolve the issue of same batch being pulled from the GPU, now my model training has become drastically slow (> 4x), and most time is being spent in dequeues. A timeline snapshot is here:\r\n\r\n![screenshot from 2017-02-03 18-43-55](https://cloud.githubusercontent.com/assets/1893429/22612749/be748f0c-ea40-11e6-9efb-989b9466301a.png)\r\n\r\nAny ideas as to what might be going wrong?\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttps://github.com/tensorflow/tensorflow/issues/7038\r\n\r\n### Environment info\r\nOperating System: CentOS 6.5\r\n\r\nInstalled version of CUDA and cuDNN: 8.0.27 and 5.1\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n1. The commit hash (`git rev-parse HEAD`): 084b37a00f3cf2cc89d433528ca63ec1d3b5b313\r\n2. The output of `bazel version`\r\n```\r\nBuild label: 0.4.3- (@non-git)\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Dec 23 16:35:28 2016 (1482510928)\r\nBuild timestamp: 1482510928\r\nBuild timestamp as int: 1482510928\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nMy code is based on the tensorflow/models/slim interface"}