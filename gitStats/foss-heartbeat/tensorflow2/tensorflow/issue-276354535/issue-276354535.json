{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14834", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14834/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14834/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14834/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14834", "id": 276354535, "node_id": "MDU6SXNzdWUyNzYzNTQ1MzU=", "number": 14834, "title": "[AUC] result of tf.metrics.auc doesnot match with sklearn's", "user": {"login": "maybeluo", "id": 5810226, "node_id": "MDQ6VXNlcjU4MTAyMjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/5810226?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maybeluo", "html_url": "https://github.com/maybeluo", "followers_url": "https://api.github.com/users/maybeluo/followers", "following_url": "https://api.github.com/users/maybeluo/following{/other_user}", "gists_url": "https://api.github.com/users/maybeluo/gists{/gist_id}", "starred_url": "https://api.github.com/users/maybeluo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maybeluo/subscriptions", "organizations_url": "https://api.github.com/users/maybeluo/orgs", "repos_url": "https://api.github.com/users/maybeluo/repos", "events_url": "https://api.github.com/users/maybeluo/events{/privacy}", "received_events_url": "https://api.github.com/users/maybeluo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-11-23T12:16:19Z", "updated_at": "2018-04-10T21:21:00Z", "closed_at": "2017-11-26T02:18:37Z", "author_association": "NONE", "body_html": "<p>My tensorflow version is ('v1.3.0-rc1-4263-gc81acfb', '1.4.0-rc1'), and the system is Rehat with gcc version 4.8.5 20150623 (Red Hat 4.8.5-16). I run the program use CPU only.</p>\n<p>I wrote a NN  use tensorflow for binary classification. I create the an <code>auc_op</code> in the following way:</p>\n<div class=\"highlight highlight-source-python\"><pre>net <span class=\"pl-k\">=</span> input_layer(features,) <span class=\"pl-c\"><span class=\"pl-c\">#</span> get dense input layer from features</span>\n<span class=\"pl-k\">for</span> layer_id <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">1</span>, num_layer):\n    net  <span class=\"pl-k\">=</span> tf.add(tf.matmul(net, <span class=\"pl-c1\">self</span>._weights[layer_id]), <span class=\"pl-c1\">self</span>._bias[layer_id])\n    <span class=\"pl-k\">if</span> layer_id <span class=\"pl-k\">&lt;</span> num_layer <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>: <span class=\"pl-c\"><span class=\"pl-c\">#</span> output layer without activation function to get `wx + b`</span>\n        net <span class=\"pl-k\">=</span>tf.nn.relu(net)\nlogits <span class=\"pl-k\">=</span> net\nlabels <span class=\"pl-k\">=</span> tf.expand_dims(tf.cast(tf.convert_to_tensor(labels), <span class=\"pl-v\">dtype</span> <span class=\"pl-k\">=</span> tf.float32), <span class=\"pl-v\">axis</span> <span class=\"pl-k\">=</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\nauc_op <span class=\"pl-k\">=</span> tf.metrics.auc(<span class=\"pl-v\">labels</span> <span class=\"pl-k\">=</span> labels, <span class=\"pl-v\">predictions</span> <span class=\"pl-k\">=</span> tf.sigmoid(logits), <span class=\"pl-v\">num_thresholds</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">102400</span>)</pre></div>\n<p>I run the <code>auc_op</code> like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">for</span> step <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>._max_steps <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>):\n    auc <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._sess.run(auc_op)</pre></div>\n<p>I also keep all the logits and labels in each step and concatenate them, then call sklearn like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> sklearn.metrics <span class=\"pl-k\">import</span> roc_auc_score\nroc_auc_score(labels, sigmoid(logits))</pre></div>\n<p>Are there anything wrong in the way I use tf.metrics.auc? When I run the <code>auc_op</code>, it returns a tuple with two values and I don't which one is the correct auc. But both of them are not equal with sklearn's.<br>\nI once wrote an program to calculate auc and it was exactly the same with sklearn's even in 1M data, thus I tend to think sklearn's result is the ground truth.</p>", "body_text": "My tensorflow version is ('v1.3.0-rc1-4263-gc81acfb', '1.4.0-rc1'), and the system is Rehat with gcc version 4.8.5 20150623 (Red Hat 4.8.5-16). I run the program use CPU only.\nI wrote a NN  use tensorflow for binary classification. I create the an auc_op in the following way:\nnet = input_layer(features,) # get dense input layer from features\nfor layer_id in xrange(1, num_layer):\n    net  = tf.add(tf.matmul(net, self._weights[layer_id]), self._bias[layer_id])\n    if layer_id < num_layer - 1: # output layer without activation function to get `wx + b`\n        net =tf.nn.relu(net)\nlogits = net\nlabels = tf.expand_dims(tf.cast(tf.convert_to_tensor(labels), dtype = tf.float32), axis = -1)\nauc_op = tf.metrics.auc(labels = labels, predictions = tf.sigmoid(logits), num_thresholds = 102400)\nI run the auc_op like this:\nfor step in xrange(1, self._max_steps + 1):\n    auc = self._sess.run(auc_op)\nI also keep all the logits and labels in each step and concatenate them, then call sklearn like this:\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(labels, sigmoid(logits))\nAre there anything wrong in the way I use tf.metrics.auc? When I run the auc_op, it returns a tuple with two values and I don't which one is the correct auc. But both of them are not equal with sklearn's.\nI once wrote an program to calculate auc and it was exactly the same with sklearn's even in 1M data, thus I tend to think sklearn's result is the ground truth.", "body": "My tensorflow version is ('v1.3.0-rc1-4263-gc81acfb', '1.4.0-rc1'), and the system is Rehat with gcc version 4.8.5 20150623 (Red Hat 4.8.5-16). I run the program use CPU only.\r\n\r\nI wrote a NN  use tensorflow for binary classification. I create the an `auc_op` in the following way:\r\n \r\n```python\r\nnet = input_layer(features,) # get dense input layer from features\r\nfor layer_id in xrange(1, num_layer):\r\n    net  = tf.add(tf.matmul(net, self._weights[layer_id]), self._bias[layer_id])\r\n    if layer_id < num_layer - 1: # output layer without activation function to get `wx + b`\r\n        net =tf.nn.relu(net)\r\nlogits = net\r\nlabels = tf.expand_dims(tf.cast(tf.convert_to_tensor(labels), dtype = tf.float32), axis = -1)\r\nauc_op = tf.metrics.auc(labels = labels, predictions = tf.sigmoid(logits), num_thresholds = 102400)\r\n```\r\n\r\nI run the `auc_op` like this:\r\n```python\r\nfor step in xrange(1, self._max_steps + 1):\r\n    auc = self._sess.run(auc_op)\r\n```\r\n\r\nI also keep all the logits and labels in each step and concatenate them, then call sklearn like this:\r\n```python\r\nfrom sklearn.metrics import roc_auc_score\r\nroc_auc_score(labels, sigmoid(logits))\r\n```\r\n\r\nAre there anything wrong in the way I use tf.metrics.auc? When I run the `auc_op`, it returns a tuple with two values and I don't which one is the correct auc. But both of them are not equal with sklearn's. \r\nI once wrote an program to calculate auc and it was exactly the same with sklearn's even in 1M data, thus I tend to think sklearn's result is the ground truth. "}