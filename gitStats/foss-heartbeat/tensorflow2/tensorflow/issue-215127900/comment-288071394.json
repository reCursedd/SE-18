{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288071394", "html_url": "https://github.com/tensorflow/tensorflow/issues/8511#issuecomment-288071394", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8511", "id": 288071394, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODA3MTM5NA==", "user": {"login": "dale-cooper", "id": 390501, "node_id": "MDQ6VXNlcjM5MDUwMQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/390501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dale-cooper", "html_url": "https://github.com/dale-cooper", "followers_url": "https://api.github.com/users/dale-cooper/followers", "following_url": "https://api.github.com/users/dale-cooper/following{/other_user}", "gists_url": "https://api.github.com/users/dale-cooper/gists{/gist_id}", "starred_url": "https://api.github.com/users/dale-cooper/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dale-cooper/subscriptions", "organizations_url": "https://api.github.com/users/dale-cooper/orgs", "repos_url": "https://api.github.com/users/dale-cooper/repos", "events_url": "https://api.github.com/users/dale-cooper/events{/privacy}", "received_events_url": "https://api.github.com/users/dale-cooper/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-21T13:03:16Z", "updated_at": "2017-03-21T13:03:16Z", "author_association": "NONE", "body_html": "<p>Hey,</p>\n<p>I'd really appreciate an answer here, as the integration between tensorflow and tensorflow serving is not really working for me. I have installed the latest python distribution with pip which says it's version 1.0.1. This version does not contain estimator/export.py so I will not be confused again by what is there and what isn't.</p>\n<p>I've created my model and exported it with export_savedmodel and this seems to be served just fine (except of course, there's no way to see what serving serves).</p>\n<p>I used the following code to create the input function</p>\n<pre><code>from tensorflow.contrib.layers.python.layers import feature_column as feature_column_lib\n\nfeature_columns = [\n      feature_column_lib.real_valued_column(\n          'pred_me', dimension=1)\n  ]\nfeature_spec = feature_column_lib.create_feature_spec_for_parsing(\n      feature_columns)\n\nserving_input_fn = tf.contrib.learn.utils.build_parsing_serving_input_fn(feature_spec)\n</code></pre>\n<p>To call this the documentation says something about tf.Examples which are nowhere defined (except inside the proto files) but I suppose this was not the right function to use. There's also build_default_serving_input_fn which would seem to be the right function to use for me but I cannot get this to work either as it is not too clear what the input should be.</p>\n<p>I did some digging around and came up with this code</p>\n<pre lang=\"from\" data-meta=\"tensorflow.python.framework import constant_op\"><code>\nfeature_spec = {'pred_me': constant_op.constant([2.0])}\nserving_input_fn = tf.contrib.learn.utils.input_fn_utils.build_default_serving_input_fn(feature_spec)```\n\nwhich comes from the documentation (well test) of a newer code base and actually uses the renamed function build_raw_serving_input_receiver_fn. But this comes back with an exception: **ValueError: 'Const_19:0' is not a valid scope name** which kind of makes sense because within build_raw_serving_input_receiver_fn there's code that transforms the tensor's name like this \n\n```# Reuse the feature tensor name for the placeholder, excluding the index\n      placeholder_name = t.name.split(':')[0]```\n\nwhich is missing in the originial tf.contrib.learn.utils.input_fn_utils.build_default_serving_input_fn\n\n```features_placeholders[name] = array_ops.placeholder(dtype=t.dtype,\n                                                          shape=shape,\n                                                          name=t.name)\n</code></pre>\n<p>So is this just a bug in the old library still distributed with pip or how is this supposed to work.</p>\n<p>I really do appreciate what you are doing here but this really needs some clarification.</p>\n<p>chris</p>", "body_text": "Hey,\nI'd really appreciate an answer here, as the integration between tensorflow and tensorflow serving is not really working for me. I have installed the latest python distribution with pip which says it's version 1.0.1. This version does not contain estimator/export.py so I will not be confused again by what is there and what isn't.\nI've created my model and exported it with export_savedmodel and this seems to be served just fine (except of course, there's no way to see what serving serves).\nI used the following code to create the input function\nfrom tensorflow.contrib.layers.python.layers import feature_column as feature_column_lib\n\nfeature_columns = [\n      feature_column_lib.real_valued_column(\n          'pred_me', dimension=1)\n  ]\nfeature_spec = feature_column_lib.create_feature_spec_for_parsing(\n      feature_columns)\n\nserving_input_fn = tf.contrib.learn.utils.build_parsing_serving_input_fn(feature_spec)\n\nTo call this the documentation says something about tf.Examples which are nowhere defined (except inside the proto files) but I suppose this was not the right function to use. There's also build_default_serving_input_fn which would seem to be the right function to use for me but I cannot get this to work either as it is not too clear what the input should be.\nI did some digging around and came up with this code\n\nfeature_spec = {'pred_me': constant_op.constant([2.0])}\nserving_input_fn = tf.contrib.learn.utils.input_fn_utils.build_default_serving_input_fn(feature_spec)```\n\nwhich comes from the documentation (well test) of a newer code base and actually uses the renamed function build_raw_serving_input_receiver_fn. But this comes back with an exception: **ValueError: 'Const_19:0' is not a valid scope name** which kind of makes sense because within build_raw_serving_input_receiver_fn there's code that transforms the tensor's name like this \n\n```# Reuse the feature tensor name for the placeholder, excluding the index\n      placeholder_name = t.name.split(':')[0]```\n\nwhich is missing in the originial tf.contrib.learn.utils.input_fn_utils.build_default_serving_input_fn\n\n```features_placeholders[name] = array_ops.placeholder(dtype=t.dtype,\n                                                          shape=shape,\n                                                          name=t.name)\n\nSo is this just a bug in the old library still distributed with pip or how is this supposed to work.\nI really do appreciate what you are doing here but this really needs some clarification.\nchris", "body": "Hey,\r\n\r\nI'd really appreciate an answer here, as the integration between tensorflow and tensorflow serving is not really working for me. I have installed the latest python distribution with pip which says it's version 1.0.1. This version does not contain estimator/export.py so I will not be confused again by what is there and what isn't.\r\n\r\nI've created my model and exported it with export_savedmodel and this seems to be served just fine (except of course, there's no way to see what serving serves).\r\n\r\nI used the following code to create the input function\r\n\r\n```\r\nfrom tensorflow.contrib.layers.python.layers import feature_column as feature_column_lib\r\n\r\nfeature_columns = [\r\n      feature_column_lib.real_valued_column(\r\n          'pred_me', dimension=1)\r\n  ]\r\nfeature_spec = feature_column_lib.create_feature_spec_for_parsing(\r\n      feature_columns)\r\n\r\nserving_input_fn = tf.contrib.learn.utils.build_parsing_serving_input_fn(feature_spec)\r\n```\r\n\r\nTo call this the documentation says something about tf.Examples which are nowhere defined (except inside the proto files) but I suppose this was not the right function to use. There's also build_default_serving_input_fn which would seem to be the right function to use for me but I cannot get this to work either as it is not too clear what the input should be.\r\n\r\nI did some digging around and came up with this code\r\n\r\n```from tensorflow.python.framework import constant_op\r\n\r\nfeature_spec = {'pred_me': constant_op.constant([2.0])}\r\nserving_input_fn = tf.contrib.learn.utils.input_fn_utils.build_default_serving_input_fn(feature_spec)```\r\n\r\nwhich comes from the documentation (well test) of a newer code base and actually uses the renamed function build_raw_serving_input_receiver_fn. But this comes back with an exception: **ValueError: 'Const_19:0' is not a valid scope name** which kind of makes sense because within build_raw_serving_input_receiver_fn there's code that transforms the tensor's name like this \r\n\r\n```# Reuse the feature tensor name for the placeholder, excluding the index\r\n      placeholder_name = t.name.split(':')[0]```\r\n\r\nwhich is missing in the originial tf.contrib.learn.utils.input_fn_utils.build_default_serving_input_fn\r\n\r\n```features_placeholders[name] = array_ops.placeholder(dtype=t.dtype,\r\n                                                          shape=shape,\r\n                                                          name=t.name)\r\n```\r\n\r\nSo is this just a bug in the old library still distributed with pip or how is this supposed to work.\r\n\r\nI really do appreciate what you are doing here but this really needs some clarification.\r\n\r\nchris "}