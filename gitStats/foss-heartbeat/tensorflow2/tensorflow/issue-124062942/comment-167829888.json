{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/167829888", "html_url": "https://github.com/tensorflow/tensorflow/issues/636#issuecomment-167829888", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/636", "id": 167829888, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NzgyOTg4OA==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-29T16:58:32Z", "updated_at": "2015-12-29T16:58:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is a subtly different issue: as far as the placer is concerned MaxPool is defined to run on GPU, so it will be placed on a GPU device if available (using hard or soft placement). However, for certain input values (in this case, where the kernel size in the depth dimension is greater than 1) it will raise an error at runtime if the op tries to execute on GPU.</p>\n<p><strong>TL;DR:</strong> For now it's necessary to annotate any depthwise max-pooling ops with a <code>with tf.device(\"/cpu:0\"):</code> block.</p>", "body_text": "This is a subtly different issue: as far as the placer is concerned MaxPool is defined to run on GPU, so it will be placed on a GPU device if available (using hard or soft placement). However, for certain input values (in this case, where the kernel size in the depth dimension is greater than 1) it will raise an error at runtime if the op tries to execute on GPU.\nTL;DR: For now it's necessary to annotate any depthwise max-pooling ops with a with tf.device(\"/cpu:0\"): block.", "body": "This is a subtly different issue: as far as the placer is concerned MaxPool is defined to run on GPU, so it will be placed on a GPU device if available (using hard or soft placement). However, for certain input values (in this case, where the kernel size in the depth dimension is greater than 1) it will raise an error at runtime if the op tries to execute on GPU.\n\n**TL;DR:** For now it's necessary to annotate any depthwise max-pooling ops with a `with tf.device(\"/cpu:0\"):` block.\n"}