{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/223199736", "html_url": "https://github.com/tensorflow/tensorflow/issues/2583#issuecomment-223199736", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2583", "id": 223199736, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMzE5OTczNg==", "user": {"login": "jihunchoi", "id": 1898501, "node_id": "MDQ6VXNlcjE4OTg1MDE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1898501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jihunchoi", "html_url": "https://github.com/jihunchoi", "followers_url": "https://api.github.com/users/jihunchoi/followers", "following_url": "https://api.github.com/users/jihunchoi/following{/other_user}", "gists_url": "https://api.github.com/users/jihunchoi/gists{/gist_id}", "starred_url": "https://api.github.com/users/jihunchoi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jihunchoi/subscriptions", "organizations_url": "https://api.github.com/users/jihunchoi/orgs", "repos_url": "https://api.github.com/users/jihunchoi/repos", "events_url": "https://api.github.com/users/jihunchoi/events{/privacy}", "received_events_url": "https://api.github.com/users/jihunchoi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-02T05:36:00Z", "updated_at": "2016-06-02T05:39:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I don't understand exactly; can't we just return two variables <code>outputs_fw</code> and <code>outputs_bw</code> separately?<br>\nis there a reason that <code>outputs</code> should be a single variable?<br>\nI think the typical usage of <code>bidirectional_rnn</code> is to multiply <code>outputs</code> with a weight matrix of shape <code>(2 * hidden_size, vocab_size)</code>, which is identical with adding two results of multiplying weight matrices of <code>(hidden_size, vocab_size)</code> to forward and backward outputs.<br>\nIn my opinion, separating two would give a performance gain and a bit more flexibility.</p>\n<h2></h2>\n<p>I didn't think of the multi-layer cases; is the issue related to multi-layer RNNs?</p>", "body_text": "I don't understand exactly; can't we just return two variables outputs_fw and outputs_bw separately?\nis there a reason that outputs should be a single variable?\nI think the typical usage of bidirectional_rnn is to multiply outputs with a weight matrix of shape (2 * hidden_size, vocab_size), which is identical with adding two results of multiplying weight matrices of (hidden_size, vocab_size) to forward and backward outputs.\nIn my opinion, separating two would give a performance gain and a bit more flexibility.\n\nI didn't think of the multi-layer cases; is the issue related to multi-layer RNNs?", "body": "I don't understand exactly; can't we just return two variables `outputs_fw` and `outputs_bw` separately?\nis there a reason that `outputs` should be a single variable?\nI think the typical usage of `bidirectional_rnn` is to multiply `outputs` with a weight matrix of shape `(2 * hidden_size, vocab_size)`, which is identical with adding two results of multiplying weight matrices of `(hidden_size, vocab_size)` to forward and backward outputs.\nIn my opinion, separating two would give a performance gain and a bit more flexibility.\n\n## \n\nI didn't think of the multi-layer cases; is the issue related to multi-layer RNNs?\n"}