{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/225314277", "html_url": "https://github.com/tensorflow/tensorflow/issues/2781#issuecomment-225314277", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2781", "id": 225314277, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNTMxNDI3Nw==", "user": {"login": "kingtaurus", "id": 2761482, "node_id": "MDQ6VXNlcjI3NjE0ODI=", "avatar_url": "https://avatars1.githubusercontent.com/u/2761482?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kingtaurus", "html_url": "https://github.com/kingtaurus", "followers_url": "https://api.github.com/users/kingtaurus/followers", "following_url": "https://api.github.com/users/kingtaurus/following{/other_user}", "gists_url": "https://api.github.com/users/kingtaurus/gists{/gist_id}", "starred_url": "https://api.github.com/users/kingtaurus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kingtaurus/subscriptions", "organizations_url": "https://api.github.com/users/kingtaurus/orgs", "repos_url": "https://api.github.com/users/kingtaurus/repos", "events_url": "https://api.github.com/users/kingtaurus/events{/privacy}", "received_events_url": "https://api.github.com/users/kingtaurus/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-10T22:50:32Z", "updated_at": "2016-06-10T22:58:13Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Its not the same model:<br>\n(1) this model uses <code>tf.train.AdamOptimize(1e-4)</code> instead of (<code>tf.train.exponential_decay</code> combined with <code>tf.train.MomentumOptimizer</code> and starts at a learning rate of <code>0.01</code>)<br>\n(2)</p>\n<pre><code>y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\ntf.reduce_mean(\n        -tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n</code></pre>\n<p>is used for loss (rather than <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code>) [this should be identical but just a minor point] ;<br>\n(3) regularization is being applied in (<code>models/image/mnist/convolutional.py</code>);<br>\n(4) <code>convolutional.py</code> does 10 epochs of batch size 64;<br>\n<code>tut.py</code> does 18 epochs of batch size 50;<br>\n(5) Finally the different size of the Full connected layers;</p>\n<p>At the end of <code>convolutional.py</code>:</p>\n<pre><code>Minibatch loss: 1.612, learning rate: 0.006302\nMinibatch error: 1.6%\nValidation error: 0.9%\nTest error: 0.8%\n</code></pre>", "body_text": "Its not the same model:\n(1) this model uses tf.train.AdamOptimize(1e-4) instead of (tf.train.exponential_decay combined with tf.train.MomentumOptimizer and starts at a learning rate of 0.01)\n(2)\ny_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\ntf.reduce_mean(\n        -tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n\nis used for loss (rather than tf.nn.sparse_softmax_cross_entropy_with_logits) [this should be identical but just a minor point] ;\n(3) regularization is being applied in (models/image/mnist/convolutional.py);\n(4) convolutional.py does 10 epochs of batch size 64;\ntut.py does 18 epochs of batch size 50;\n(5) Finally the different size of the Full connected layers;\nAt the end of convolutional.py:\nMinibatch loss: 1.612, learning rate: 0.006302\nMinibatch error: 1.6%\nValidation error: 0.9%\nTest error: 0.8%", "body": "Its not the same model:\n(1) this model uses `tf.train.AdamOptimize(1e-4)` instead of (`tf.train.exponential_decay` combined with `tf.train.MomentumOptimizer` and starts at a learning rate of `0.01`)\n(2) \n\n```\ny_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\ntf.reduce_mean(\n        -tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n```\n\nis used for loss (rather than `tf.nn.sparse_softmax_cross_entropy_with_logits`) [this should be identical but just a minor point] ;\n(3) regularization is being applied in (`models/image/mnist/convolutional.py`);\n(4) `convolutional.py` does 10 epochs of batch size 64;\n     `tut.py` does 18 epochs of batch size 50;\n(5) Finally the different size of the Full connected layers;\n\nAt the end of `convolutional.py`:\n\n```\nMinibatch loss: 1.612, learning rate: 0.006302\nMinibatch error: 1.6%\nValidation error: 0.9%\nTest error: 0.8%\n```\n"}