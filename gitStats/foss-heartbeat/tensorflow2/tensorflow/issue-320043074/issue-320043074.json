{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19066", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19066/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19066/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19066/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19066", "id": 320043074, "node_id": "MDU6SXNzdWUzMjAwNDMwNzQ=", "number": 19066, "title": "Segfault Custom Op using KenLM", "user": {"login": "thomasquintana", "id": 1891840, "node_id": "MDQ6VXNlcjE4OTE4NDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1891840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thomasquintana", "html_url": "https://github.com/thomasquintana", "followers_url": "https://api.github.com/users/thomasquintana/followers", "following_url": "https://api.github.com/users/thomasquintana/following{/other_user}", "gists_url": "https://api.github.com/users/thomasquintana/gists{/gist_id}", "starred_url": "https://api.github.com/users/thomasquintana/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thomasquintana/subscriptions", "organizations_url": "https://api.github.com/users/thomasquintana/orgs", "repos_url": "https://api.github.com/users/thomasquintana/repos", "events_url": "https://api.github.com/users/thomasquintana/events{/privacy}", "received_events_url": "https://api.github.com/users/thomasquintana/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-03T19:07:05Z", "updated_at": "2018-05-03T20:48:13Z", "closed_at": "2018-05-03T20:48:13Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.8.0</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0 / 7</li>\n<li><strong>GPU model and memory</strong>: TitanX</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>When I use KenLM in my C++ test suite it runs just fine but when I try to use it from inside a custom op I get a Segmentation Fault. Any help would be greatly appreciated. Thx!</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<div class=\"highlight highlight-source-c\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>lm/model.hh<span class=\"pl-pds\">\"</span></span>\n\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ctc_beam.hh<span class=\"pl-pds\">\"</span></span>\n\n#<span class=\"pl-k\">ifndef</span> CTC_SCORER_HH\n#<span class=\"pl-k\">define</span> <span class=\"pl-en\">CTC_SCORER_HH</span>\n\nclass CTCBeamScorer {\n    public:\n    <span class=\"pl-c1\">CTCBeamScorer</span>(std::string lm_path, <span class=\"pl-k\">float</span> alpha, <span class=\"pl-k\">float</span> beta) : <span class=\"pl-c1\">alpha_</span>(alpha), <span class=\"pl-c1\">beta_</span>(beta) {\n        model_ = <span class=\"pl-c1\">lm::ngram::LoadVirtual</span>(lm_path.<span class=\"pl-c1\">c_str</span>());\n        vocabulary_ = &amp;model_-&gt;<span class=\"pl-c1\">BaseVocabulary</span>();\n    }\n    ~<span class=\"pl-c1\">CTCBeamScorer</span>(<span class=\"pl-k\">void</span>) {\n        delete model_;\n    }\n\n    <span class=\"pl-k\">void</span> <span class=\"pl-smi\">expand_beam</span>(<span class=\"pl-k\">const</span> CTCBeam* beam, <span class=\"pl-k\">int</span> from_label, <span class=\"pl-k\">int</span> to_label) { }\n\n    <span class=\"pl-k\">void</span> <span class=\"pl-smi\">expand_beam_end</span>(CTCBeam* beam) <span class=\"pl-k\">const</span> { }\n\n    <span class=\"pl-k\">float</span> <span class=\"pl-smi\">get_beam_score</span>(<span class=\"pl-k\">const</span> CTCBeam* beam) <span class=\"pl-k\">const</span> { <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>.<span class=\"pl-c1\">0f</span>; }\n\n    <span class=\"pl-k\">void</span> <span class=\"pl-smi\">initialize_beam</span>(CTCBeam* beam) <span class=\"pl-k\">const</span> { }\n\n    private:\n    <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> alpha_ = <span class=\"pl-c1\">0.0</span>;\n    <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> beta_ = <span class=\"pl-c1\">0.0</span>;\n    lm::base::Model* model_ = nullptr;\n    <span class=\"pl-k\">const</span> lm::base::Vocabulary* vocabulary_ = nullptr;\n};\n\n#<span class=\"pl-k\">endif</span> <span class=\"pl-c\"><span class=\"pl-c\">//</span> CTC_SCORER_HH</span></pre></div>\n<p><em>THIS WORKS</em></p>\n<div class=\"highlight highlight-source-c\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"pl-pds\">&gt;</span></span>\n\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>../src/ctc_scorer.hh<span class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-en\">TEST</span>(ctc_scorer_tests, score) {\n    CTCBeamScorer* scorer = nullptr;\n    try {\n        scorer = new <span class=\"pl-c1\">CTCBeamScorer</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/tmp/test.mmap<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">0</span>.<span class=\"pl-c1\">0f</span>, <span class=\"pl-c1\">0</span>.<span class=\"pl-c1\">0f</span>);\n        <span class=\"pl-c1\">ASSERT_FALSE</span>(scorer == nullptr);\n    } catch(<span class=\"pl-k\">const</span> std::exception &amp;e) {\n        std::cerr &lt;&lt; e.<span class=\"pl-c1\">what</span>() &lt;&lt; std::endl;\n    }\n\n    delete scorer;\n}</pre></div>\n<pre><code>g++ -Wall -O3 -std=c++11 -g -I/home/thomas/projects/thomas/ops/thirdparty/kenlm -DKENLM_MAX_ORDER=6 -DHAVE_ZLIB=1 -DHAVE_BZLIB=1 -DHAVE_XZLIB=1 -o tests/test_runner tests/test_runner.cc tests/ctc_scorer_tests.cc src/ctc_scorer.cc thirdparty/kenlm/util/string_piece.o thirdparty/kenlm/util/exception.o thirdparty/kenlm/util/spaces.o thirdparty/kenlm/util/pool.o thirdparty/kenlm/util/file_piece.o thirdparty/kenlm/util/usage.o thirdparty/kenlm/util/parallel_read.o thirdparty/kenlm/util/bit_packing.o thirdparty/kenlm/util/float_to_string.o thirdparty/kenlm/util/ersatz_progress.o thirdparty/kenlm/util/integer_to_string.o thirdparty/kenlm/util/mmap.o thirdparty/kenlm/util/murmur_hash.o thirdparty/kenlm/util/read_compressed.o thirdparty/kenlm/util/scoped.o thirdparty/kenlm/util/file.o thirdparty/kenlm/lm/value_build.o thirdparty/kenlm/lm/config.o thirdparty/kenlm/lm/model.o thirdparty/kenlm/lm/trie.o thirdparty/kenlm/lm/sizes.o thirdparty/kenlm/lm/search_hashed.o thirdparty/kenlm/lm/lm_exception.o thirdparty/kenlm/lm/virtual_interface.o thirdparty/kenlm/lm/binary_format.o thirdparty/kenlm/lm/trie_sort.o thirdparty/kenlm/lm/vocab.o thirdparty/kenlm/lm/search_trie.o thirdparty/kenlm/lm/read_arpa.o thirdparty/kenlm/lm/quantize.o thirdparty/kenlm/lm/bhiksha.o thirdparty/kenlm/util/double-conversion/strtod.o thirdparty/kenlm/util/double-conversion/fast-dtoa.o thirdparty/kenlm/util/double-conversion/double-conversion.o thirdparty/kenlm/util/double-conversion/cached-powers.o thirdparty/kenlm/util/double-conversion/bignum.o thirdparty/kenlm/util/double-conversion/fixed-dtoa.o thirdparty/kenlm/util/double-conversion/bignum-dtoa.o thirdparty/kenlm/util/double-conversion/diy-fp.o -lgtest -lpthread -lboost_program_options -lboost_system -lboost_thread -lz -lbz2 -llzma\n</code></pre>\n<p><em>THIS DOES NOT WORK</em></p>\n<div class=\"highlight highlight-source-c\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/op.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/op_kernel.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/shape_inference.h<span class=\"pl-pds\">\"</span></span>\n\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ctc_scorer.hh<span class=\"pl-pds\">\"</span></span>\n\nusing namespace tensorflow;\n\n<span class=\"pl-en\">REGISTER_OP</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CTCKenLMBeamSearchDecoder<span class=\"pl-pds\">\"</span></span>)\n    .Input(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>scores: float32<span class=\"pl-pds\">\"</span></span>)\n    .Output(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>output: float32<span class=\"pl-pds\">\"</span></span>)\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* context) {\n      context-&gt;<span class=\"pl-c1\">set_output</span>(<span class=\"pl-c1\">0</span>, context-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">0</span>));\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">Status::OK</span>();\n    });\n\nclass CTCKenLMBeamSearchDecoderOp : public OpKernel {\n    public:\n    explicit <span class=\"pl-smi\">CTCKenLMBeamSearchDecoderOp</span>(OpKernelConstruction* context) : <span class=\"pl-c1\">OpKernel</span>(context) {\n        CTCBeamScorer* scorer = nullptr;\n        try {\n            scorer = new <span class=\"pl-c1\">CTCBeamScorer</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/tmp/test.mmap<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">0</span>.<span class=\"pl-c1\">0f</span>, <span class=\"pl-c1\">0</span>.<span class=\"pl-c1\">0f</span>);\n        } catch(<span class=\"pl-k\">const</span> std::exception &amp;e) {\n            std::cerr &lt;&lt; e.<span class=\"pl-c1\">what</span>() &lt;&lt; std::endl;\n        }\n\n        delete scorer;\n    }\n\n    ~<span class=\"pl-c1\">CTCKenLMBeamSearchDecoderOp</span>(<span class=\"pl-k\">void</span>) {\n        \n    }\n\n    <span class=\"pl-k\">void</span> <span class=\"pl-smi\">Compute</span>(OpKernelContext* context) override {\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> Grab the input tensor</span>\n        <span class=\"pl-k\">const</span> Tensor&amp; scores_tensor = context-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">0</span>);\n        <span class=\"pl-k\">auto</span> scores = scores_tensor.<span class=\"pl-smi\">tensor</span>&lt;<span class=\"pl-k\">float</span>, <span class=\"pl-c1\">3</span>&gt;();\n\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> Create an output tensor</span>\n        Tensor* output_tensor = <span class=\"pl-c1\">NULL</span>;\n        <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_output</span>(<span class=\"pl-c1\">0</span>, scores_tensor.<span class=\"pl-c1\">shape</span>(), &amp;output_tensor));\n        <span class=\"pl-k\">auto</span> output = output_tensor-&gt;<span class=\"pl-smi\">tensor</span>&lt;<span class=\"pl-k\">float</span>, <span class=\"pl-c1\">3</span>&gt;();\n\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> Copy the scores to the output.</span>\n        <span class=\"pl-k\">const</span> <span class=\"pl-k\">auto</span> scores_shape = scores_tensor.<span class=\"pl-c1\">shape</span>();\n        <span class=\"pl-k\">for</span> (<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> x_idx = <span class=\"pl-c1\">0</span>; x_idx &lt; scores_shape.<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">0</span>); x_idx++) {\n            <span class=\"pl-k\">for</span> (<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> y_idx = <span class=\"pl-c1\">0</span>; y_idx &lt; scores_shape.<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">1</span>); y_idx++) {\n                <span class=\"pl-k\">for</span> (<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> z_idx = <span class=\"pl-c1\">0</span>; z_idx &lt; scores_shape.<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">2</span>); z_idx++) {\n                    <span class=\"pl-c1\">output</span>(x_idx, y_idx, z_idx) = <span class=\"pl-c1\">scores</span>(x_idx, y_idx, z_idx);\n                }\n            }\n        }\n    }\n};\n\n<span class=\"pl-en\">REGISTER_KERNEL_BUILDER</span>(Name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CTCKenLMBeamSearchDecoder<span class=\"pl-pds\">\"</span></span>).Device(DEVICE_CPU), CTCKenLMBeamSearchDecoderOp);</pre></div>\n<pre><code>g++ -Wall -O3 -std=c++11 -g -I/home/thomas/projects/thomas/ops/thirdparty/kenlm -DKENLM_MAX_ORDER=6 -DHAVE_ZLIB=1 -DHAVE_BZLIB=1 -DHAVE_XZLIB=1 -I/usr/local/lib/python3.5/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -shared -o libs/ctc_decoder.so src/ctc_decoder_op.cc src/ctc_scorer.cc thirdparty/kenlm/util/string_piece.o thirdparty/kenlm/util/exception.o thirdparty/kenlm/util/spaces.o thirdparty/kenlm/util/pool.o thirdparty/kenlm/util/file_piece.o thirdparty/kenlm/util/usage.o thirdparty/kenlm/util/parallel_read.o thirdparty/kenlm/util/bit_packing.o thirdparty/kenlm/util/float_to_string.o thirdparty/kenlm/util/ersatz_progress.o thirdparty/kenlm/util/integer_to_string.o thirdparty/kenlm/util/mmap.o thirdparty/kenlm/util/murmur_hash.o thirdparty/kenlm/util/read_compressed.o thirdparty/kenlm/util/scoped.o thirdparty/kenlm/util/file.o thirdparty/kenlm/lm/value_build.o thirdparty/kenlm/lm/config.o thirdparty/kenlm/lm/model.o thirdparty/kenlm/lm/trie.o thirdparty/kenlm/lm/sizes.o thirdparty/kenlm/lm/search_hashed.o thirdparty/kenlm/lm/lm_exception.o thirdparty/kenlm/lm/virtual_interface.o thirdparty/kenlm/lm/binary_format.o thirdparty/kenlm/lm/trie_sort.o thirdparty/kenlm/lm/vocab.o thirdparty/kenlm/lm/search_trie.o thirdparty/kenlm/lm/read_arpa.o thirdparty/kenlm/lm/quantize.o thirdparty/kenlm/lm/bhiksha.o thirdparty/kenlm/util/double-conversion/strtod.o thirdparty/kenlm/util/double-conversion/fast-dtoa.o thirdparty/kenlm/util/double-conversion/double-conversion.o thirdparty/kenlm/util/double-conversion/cached-powers.o thirdparty/kenlm/util/double-conversion/bignum.o thirdparty/kenlm/util/double-conversion/fixed-dtoa.o thirdparty/kenlm/util/double-conversion/bignum-dtoa.o thirdparty/kenlm/util/double-conversion/diy-fp.o -lboost_program_options -lboost_system -lboost_thread -lz -lbz2 -llzma -L/usr/local/lib/python3.5/dist-packages/tensorflow -ltensorflow_framework\n</code></pre>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.8.0\nPython version: 3.5.2\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0 / 7\nGPU model and memory: TitanX\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nWhen I use KenLM in my C++ test suite it runs just fine but when I try to use it from inside a custom op I get a Segmentation Fault. Any help would be greatly appreciated. Thx!\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\n#include \"lm/model.hh\"\n\n#include \"ctc_beam.hh\"\n\n#ifndef CTC_SCORER_HH\n#define CTC_SCORER_HH\n\nclass CTCBeamScorer {\n    public:\n    CTCBeamScorer(std::string lm_path, float alpha, float beta) : alpha_(alpha), beta_(beta) {\n        model_ = lm::ngram::LoadVirtual(lm_path.c_str());\n        vocabulary_ = &model_->BaseVocabulary();\n    }\n    ~CTCBeamScorer(void) {\n        delete model_;\n    }\n\n    void expand_beam(const CTCBeam* beam, int from_label, int to_label) { }\n\n    void expand_beam_end(CTCBeam* beam) const { }\n\n    float get_beam_score(const CTCBeam* beam) const { return 0.0f; }\n\n    void initialize_beam(CTCBeam* beam) const { }\n\n    private:\n    const float alpha_ = 0.0;\n    const float beta_ = 0.0;\n    lm::base::Model* model_ = nullptr;\n    const lm::base::Vocabulary* vocabulary_ = nullptr;\n};\n\n#endif // CTC_SCORER_HH\nTHIS WORKS\n#include <gtest/gtest.h>\n\n#include \"../src/ctc_scorer.hh\"\n\nTEST(ctc_scorer_tests, score) {\n    CTCBeamScorer* scorer = nullptr;\n    try {\n        scorer = new CTCBeamScorer(\"/tmp/test.mmap\", 0.0f, 0.0f);\n        ASSERT_FALSE(scorer == nullptr);\n    } catch(const std::exception &e) {\n        std::cerr << e.what() << std::endl;\n    }\n\n    delete scorer;\n}\ng++ -Wall -O3 -std=c++11 -g -I/home/thomas/projects/thomas/ops/thirdparty/kenlm -DKENLM_MAX_ORDER=6 -DHAVE_ZLIB=1 -DHAVE_BZLIB=1 -DHAVE_XZLIB=1 -o tests/test_runner tests/test_runner.cc tests/ctc_scorer_tests.cc src/ctc_scorer.cc thirdparty/kenlm/util/string_piece.o thirdparty/kenlm/util/exception.o thirdparty/kenlm/util/spaces.o thirdparty/kenlm/util/pool.o thirdparty/kenlm/util/file_piece.o thirdparty/kenlm/util/usage.o thirdparty/kenlm/util/parallel_read.o thirdparty/kenlm/util/bit_packing.o thirdparty/kenlm/util/float_to_string.o thirdparty/kenlm/util/ersatz_progress.o thirdparty/kenlm/util/integer_to_string.o thirdparty/kenlm/util/mmap.o thirdparty/kenlm/util/murmur_hash.o thirdparty/kenlm/util/read_compressed.o thirdparty/kenlm/util/scoped.o thirdparty/kenlm/util/file.o thirdparty/kenlm/lm/value_build.o thirdparty/kenlm/lm/config.o thirdparty/kenlm/lm/model.o thirdparty/kenlm/lm/trie.o thirdparty/kenlm/lm/sizes.o thirdparty/kenlm/lm/search_hashed.o thirdparty/kenlm/lm/lm_exception.o thirdparty/kenlm/lm/virtual_interface.o thirdparty/kenlm/lm/binary_format.o thirdparty/kenlm/lm/trie_sort.o thirdparty/kenlm/lm/vocab.o thirdparty/kenlm/lm/search_trie.o thirdparty/kenlm/lm/read_arpa.o thirdparty/kenlm/lm/quantize.o thirdparty/kenlm/lm/bhiksha.o thirdparty/kenlm/util/double-conversion/strtod.o thirdparty/kenlm/util/double-conversion/fast-dtoa.o thirdparty/kenlm/util/double-conversion/double-conversion.o thirdparty/kenlm/util/double-conversion/cached-powers.o thirdparty/kenlm/util/double-conversion/bignum.o thirdparty/kenlm/util/double-conversion/fixed-dtoa.o thirdparty/kenlm/util/double-conversion/bignum-dtoa.o thirdparty/kenlm/util/double-conversion/diy-fp.o -lgtest -lpthread -lboost_program_options -lboost_system -lboost_thread -lz -lbz2 -llzma\n\nTHIS DOES NOT WORK\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n\n#include \"ctc_scorer.hh\"\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"CTCKenLMBeamSearchDecoder\")\n    .Input(\"scores: float32\")\n    .Output(\"output: float32\")\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* context) {\n      context->set_output(0, context->input(0));\n      return Status::OK();\n    });\n\nclass CTCKenLMBeamSearchDecoderOp : public OpKernel {\n    public:\n    explicit CTCKenLMBeamSearchDecoderOp(OpKernelConstruction* context) : OpKernel(context) {\n        CTCBeamScorer* scorer = nullptr;\n        try {\n            scorer = new CTCBeamScorer(\"/tmp/test.mmap\", 0.0f, 0.0f);\n        } catch(const std::exception &e) {\n            std::cerr << e.what() << std::endl;\n        }\n\n        delete scorer;\n    }\n\n    ~CTCKenLMBeamSearchDecoderOp(void) {\n        \n    }\n\n    void Compute(OpKernelContext* context) override {\n        // Grab the input tensor\n        const Tensor& scores_tensor = context->input(0);\n        auto scores = scores_tensor.tensor<float, 3>();\n\n        // Create an output tensor\n        Tensor* output_tensor = NULL;\n        OP_REQUIRES_OK(context, context->allocate_output(0, scores_tensor.shape(), &output_tensor));\n        auto output = output_tensor->tensor<float, 3>();\n\n        // Copy the scores to the output.\n        const auto scores_shape = scores_tensor.shape();\n        for (unsigned int x_idx = 0; x_idx < scores_shape.dim_size(0); x_idx++) {\n            for (unsigned int y_idx = 0; y_idx < scores_shape.dim_size(1); y_idx++) {\n                for (unsigned int z_idx = 0; z_idx < scores_shape.dim_size(2); z_idx++) {\n                    output(x_idx, y_idx, z_idx) = scores(x_idx, y_idx, z_idx);\n                }\n            }\n        }\n    }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CTCKenLMBeamSearchDecoder\").Device(DEVICE_CPU), CTCKenLMBeamSearchDecoderOp);\ng++ -Wall -O3 -std=c++11 -g -I/home/thomas/projects/thomas/ops/thirdparty/kenlm -DKENLM_MAX_ORDER=6 -DHAVE_ZLIB=1 -DHAVE_BZLIB=1 -DHAVE_XZLIB=1 -I/usr/local/lib/python3.5/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -shared -o libs/ctc_decoder.so src/ctc_decoder_op.cc src/ctc_scorer.cc thirdparty/kenlm/util/string_piece.o thirdparty/kenlm/util/exception.o thirdparty/kenlm/util/spaces.o thirdparty/kenlm/util/pool.o thirdparty/kenlm/util/file_piece.o thirdparty/kenlm/util/usage.o thirdparty/kenlm/util/parallel_read.o thirdparty/kenlm/util/bit_packing.o thirdparty/kenlm/util/float_to_string.o thirdparty/kenlm/util/ersatz_progress.o thirdparty/kenlm/util/integer_to_string.o thirdparty/kenlm/util/mmap.o thirdparty/kenlm/util/murmur_hash.o thirdparty/kenlm/util/read_compressed.o thirdparty/kenlm/util/scoped.o thirdparty/kenlm/util/file.o thirdparty/kenlm/lm/value_build.o thirdparty/kenlm/lm/config.o thirdparty/kenlm/lm/model.o thirdparty/kenlm/lm/trie.o thirdparty/kenlm/lm/sizes.o thirdparty/kenlm/lm/search_hashed.o thirdparty/kenlm/lm/lm_exception.o thirdparty/kenlm/lm/virtual_interface.o thirdparty/kenlm/lm/binary_format.o thirdparty/kenlm/lm/trie_sort.o thirdparty/kenlm/lm/vocab.o thirdparty/kenlm/lm/search_trie.o thirdparty/kenlm/lm/read_arpa.o thirdparty/kenlm/lm/quantize.o thirdparty/kenlm/lm/bhiksha.o thirdparty/kenlm/util/double-conversion/strtod.o thirdparty/kenlm/util/double-conversion/fast-dtoa.o thirdparty/kenlm/util/double-conversion/double-conversion.o thirdparty/kenlm/util/double-conversion/cached-powers.o thirdparty/kenlm/util/double-conversion/bignum.o thirdparty/kenlm/util/double-conversion/fixed-dtoa.o thirdparty/kenlm/util/double-conversion/bignum-dtoa.o thirdparty/kenlm/util/double-conversion/diy-fp.o -lboost_program_options -lboost_system -lboost_thread -lz -lbz2 -llzma -L/usr/local/lib/python3.5/dist-packages/tensorflow -ltensorflow_framework", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0 / 7\r\n- **GPU model and memory**: TitanX\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nWhen I use KenLM in my C++ test suite it runs just fine but when I try to use it from inside a custom op I get a Segmentation Fault. Any help would be greatly appreciated. Thx!\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```c\r\n#include \"lm/model.hh\"\r\n\r\n#include \"ctc_beam.hh\"\r\n\r\n#ifndef CTC_SCORER_HH\r\n#define CTC_SCORER_HH\r\n\r\nclass CTCBeamScorer {\r\n    public:\r\n    CTCBeamScorer(std::string lm_path, float alpha, float beta) : alpha_(alpha), beta_(beta) {\r\n        model_ = lm::ngram::LoadVirtual(lm_path.c_str());\r\n        vocabulary_ = &model_->BaseVocabulary();\r\n    }\r\n    ~CTCBeamScorer(void) {\r\n        delete model_;\r\n    }\r\n\r\n    void expand_beam(const CTCBeam* beam, int from_label, int to_label) { }\r\n\r\n    void expand_beam_end(CTCBeam* beam) const { }\r\n\r\n    float get_beam_score(const CTCBeam* beam) const { return 0.0f; }\r\n\r\n    void initialize_beam(CTCBeam* beam) const { }\r\n\r\n    private:\r\n    const float alpha_ = 0.0;\r\n    const float beta_ = 0.0;\r\n    lm::base::Model* model_ = nullptr;\r\n    const lm::base::Vocabulary* vocabulary_ = nullptr;\r\n};\r\n\r\n#endif // CTC_SCORER_HH\r\n```\r\n*THIS WORKS*\r\n```c\r\n#include <gtest/gtest.h>\r\n\r\n#include \"../src/ctc_scorer.hh\"\r\n\r\nTEST(ctc_scorer_tests, score) {\r\n    CTCBeamScorer* scorer = nullptr;\r\n    try {\r\n        scorer = new CTCBeamScorer(\"/tmp/test.mmap\", 0.0f, 0.0f);\r\n        ASSERT_FALSE(scorer == nullptr);\r\n    } catch(const std::exception &e) {\r\n        std::cerr << e.what() << std::endl;\r\n    }\r\n\r\n    delete scorer;\r\n}\r\n```\r\n\r\n```\r\ng++ -Wall -O3 -std=c++11 -g -I/home/thomas/projects/thomas/ops/thirdparty/kenlm -DKENLM_MAX_ORDER=6 -DHAVE_ZLIB=1 -DHAVE_BZLIB=1 -DHAVE_XZLIB=1 -o tests/test_runner tests/test_runner.cc tests/ctc_scorer_tests.cc src/ctc_scorer.cc thirdparty/kenlm/util/string_piece.o thirdparty/kenlm/util/exception.o thirdparty/kenlm/util/spaces.o thirdparty/kenlm/util/pool.o thirdparty/kenlm/util/file_piece.o thirdparty/kenlm/util/usage.o thirdparty/kenlm/util/parallel_read.o thirdparty/kenlm/util/bit_packing.o thirdparty/kenlm/util/float_to_string.o thirdparty/kenlm/util/ersatz_progress.o thirdparty/kenlm/util/integer_to_string.o thirdparty/kenlm/util/mmap.o thirdparty/kenlm/util/murmur_hash.o thirdparty/kenlm/util/read_compressed.o thirdparty/kenlm/util/scoped.o thirdparty/kenlm/util/file.o thirdparty/kenlm/lm/value_build.o thirdparty/kenlm/lm/config.o thirdparty/kenlm/lm/model.o thirdparty/kenlm/lm/trie.o thirdparty/kenlm/lm/sizes.o thirdparty/kenlm/lm/search_hashed.o thirdparty/kenlm/lm/lm_exception.o thirdparty/kenlm/lm/virtual_interface.o thirdparty/kenlm/lm/binary_format.o thirdparty/kenlm/lm/trie_sort.o thirdparty/kenlm/lm/vocab.o thirdparty/kenlm/lm/search_trie.o thirdparty/kenlm/lm/read_arpa.o thirdparty/kenlm/lm/quantize.o thirdparty/kenlm/lm/bhiksha.o thirdparty/kenlm/util/double-conversion/strtod.o thirdparty/kenlm/util/double-conversion/fast-dtoa.o thirdparty/kenlm/util/double-conversion/double-conversion.o thirdparty/kenlm/util/double-conversion/cached-powers.o thirdparty/kenlm/util/double-conversion/bignum.o thirdparty/kenlm/util/double-conversion/fixed-dtoa.o thirdparty/kenlm/util/double-conversion/bignum-dtoa.o thirdparty/kenlm/util/double-conversion/diy-fp.o -lgtest -lpthread -lboost_program_options -lboost_system -lboost_thread -lz -lbz2 -llzma\r\n```\r\n\r\n*THIS DOES NOT WORK*\r\n```c\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n\r\n#include \"ctc_scorer.hh\"\r\n\r\nusing namespace tensorflow;\r\n\r\nREGISTER_OP(\"CTCKenLMBeamSearchDecoder\")\r\n    .Input(\"scores: float32\")\r\n    .Output(\"output: float32\")\r\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* context) {\r\n      context->set_output(0, context->input(0));\r\n      return Status::OK();\r\n    });\r\n\r\nclass CTCKenLMBeamSearchDecoderOp : public OpKernel {\r\n    public:\r\n    explicit CTCKenLMBeamSearchDecoderOp(OpKernelConstruction* context) : OpKernel(context) {\r\n        CTCBeamScorer* scorer = nullptr;\r\n        try {\r\n            scorer = new CTCBeamScorer(\"/tmp/test.mmap\", 0.0f, 0.0f);\r\n        } catch(const std::exception &e) {\r\n            std::cerr << e.what() << std::endl;\r\n        }\r\n\r\n        delete scorer;\r\n    }\r\n\r\n    ~CTCKenLMBeamSearchDecoderOp(void) {\r\n        \r\n    }\r\n\r\n    void Compute(OpKernelContext* context) override {\r\n        // Grab the input tensor\r\n        const Tensor& scores_tensor = context->input(0);\r\n        auto scores = scores_tensor.tensor<float, 3>();\r\n\r\n        // Create an output tensor\r\n        Tensor* output_tensor = NULL;\r\n        OP_REQUIRES_OK(context, context->allocate_output(0, scores_tensor.shape(), &output_tensor));\r\n        auto output = output_tensor->tensor<float, 3>();\r\n\r\n        // Copy the scores to the output.\r\n        const auto scores_shape = scores_tensor.shape();\r\n        for (unsigned int x_idx = 0; x_idx < scores_shape.dim_size(0); x_idx++) {\r\n            for (unsigned int y_idx = 0; y_idx < scores_shape.dim_size(1); y_idx++) {\r\n                for (unsigned int z_idx = 0; z_idx < scores_shape.dim_size(2); z_idx++) {\r\n                    output(x_idx, y_idx, z_idx) = scores(x_idx, y_idx, z_idx);\r\n                }\r\n            }\r\n        }\r\n    }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"CTCKenLMBeamSearchDecoder\").Device(DEVICE_CPU), CTCKenLMBeamSearchDecoderOp);\r\n```\r\n\r\n```\r\ng++ -Wall -O3 -std=c++11 -g -I/home/thomas/projects/thomas/ops/thirdparty/kenlm -DKENLM_MAX_ORDER=6 -DHAVE_ZLIB=1 -DHAVE_BZLIB=1 -DHAVE_XZLIB=1 -I/usr/local/lib/python3.5/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -shared -o libs/ctc_decoder.so src/ctc_decoder_op.cc src/ctc_scorer.cc thirdparty/kenlm/util/string_piece.o thirdparty/kenlm/util/exception.o thirdparty/kenlm/util/spaces.o thirdparty/kenlm/util/pool.o thirdparty/kenlm/util/file_piece.o thirdparty/kenlm/util/usage.o thirdparty/kenlm/util/parallel_read.o thirdparty/kenlm/util/bit_packing.o thirdparty/kenlm/util/float_to_string.o thirdparty/kenlm/util/ersatz_progress.o thirdparty/kenlm/util/integer_to_string.o thirdparty/kenlm/util/mmap.o thirdparty/kenlm/util/murmur_hash.o thirdparty/kenlm/util/read_compressed.o thirdparty/kenlm/util/scoped.o thirdparty/kenlm/util/file.o thirdparty/kenlm/lm/value_build.o thirdparty/kenlm/lm/config.o thirdparty/kenlm/lm/model.o thirdparty/kenlm/lm/trie.o thirdparty/kenlm/lm/sizes.o thirdparty/kenlm/lm/search_hashed.o thirdparty/kenlm/lm/lm_exception.o thirdparty/kenlm/lm/virtual_interface.o thirdparty/kenlm/lm/binary_format.o thirdparty/kenlm/lm/trie_sort.o thirdparty/kenlm/lm/vocab.o thirdparty/kenlm/lm/search_trie.o thirdparty/kenlm/lm/read_arpa.o thirdparty/kenlm/lm/quantize.o thirdparty/kenlm/lm/bhiksha.o thirdparty/kenlm/util/double-conversion/strtod.o thirdparty/kenlm/util/double-conversion/fast-dtoa.o thirdparty/kenlm/util/double-conversion/double-conversion.o thirdparty/kenlm/util/double-conversion/cached-powers.o thirdparty/kenlm/util/double-conversion/bignum.o thirdparty/kenlm/util/double-conversion/fixed-dtoa.o thirdparty/kenlm/util/double-conversion/bignum-dtoa.o thirdparty/kenlm/util/double-conversion/diy-fp.o -lboost_program_options -lboost_system -lboost_thread -lz -lbz2 -llzma -L/usr/local/lib/python3.5/dist-packages/tensorflow -ltensorflow_framework\r\n```\r\n"}