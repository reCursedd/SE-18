{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/403959113", "html_url": "https://github.com/tensorflow/tensorflow/issues/20608#issuecomment-403959113", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20608", "id": 403959113, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzk1OTExMw==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-10T20:42:45Z", "updated_at": "2018-07-10T20:42:45Z", "author_association": "MEMBER", "body_html": "<p>If you can organize the \"subgraphs\" into <code>tf.keras.Model</code> objects, then object-based checkpointing (<a href=\"https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/train/Checkpoint\" rel=\"nofollow\"><code>tf.train.Checkpoint</code> in TF 1.9</a>) is hopefully the most intuitive.</p>\n<p>However, this is something that's in the early stages of being exposed and we haven't finished integration with <code>MonitoredSession</code> etc. just yet. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3731025\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/allenlavoie\">@allenlavoie</a> will have updates on that end, so assigning to him.</p>\n<p>As an example of how things might look:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nL <span class=\"pl-k\">=</span> tf.keras.layers <span class=\"pl-c\"><span class=\"pl-c\">#</span> Shorthand</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">make_shared_model</span>():\n    <span class=\"pl-k\">return</span> tf.keras.Sequential([\n        L.Conv2D(<span class=\"pl-v\">filters</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu, <span class=\"pl-v\">input_shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>]),\n        L.Conv2D(<span class=\"pl-v\">filters</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu),\n        L.MaxPool2D(<span class=\"pl-v\">pool_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>), <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)])\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">make_model1</span>():\n    <span class=\"pl-k\">return</span> tf.keras.Sequential([\n        make_shared_model(),\n        L.Conv2D(<span class=\"pl-v\">filters</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">64</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu),\n        L.Flatten(),\n        L.Dense(<span class=\"pl-c1\">10</span>)])\n\nmodel1 <span class=\"pl-k\">=</span> make_model1()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a checkpoint with just the shared portion, which is model1.layers[0]</span>\nckpt1 <span class=\"pl-k\">=</span> tf.train.Checkpoint(<span class=\"pl-v\">m</span> <span class=\"pl-k\">=</span> model1.layers[<span class=\"pl-c1\">0</span>])\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(tf.global_variables_initializer())\n    <span class=\"pl-k\">for</span> step <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">20</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Get your data and train model1</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Save a checkpoint of the shared components</span>\n        <span class=\"pl-k\">pass</span>\n    ckpt1.save(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/tmp/checkpoint<span class=\"pl-pds\">\"</span></span>)\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Could have done all this in a single graph, but demonstrating two graphs</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> just to be parallel to the code you had above</span>\ntf.reset_default_graph()\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">make_model2</span>():\n    <span class=\"pl-k\">return</span> tf.keras.Sequential([\n        make_shared_model(),\n        L.Conv2D(<span class=\"pl-v\">filters</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">64</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu),\n        L.Flatten(),\n        L.Dense(<span class=\"pl-c1\">10</span>)])\n\nmodel2 <span class=\"pl-k\">=</span> make_model2()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Since model1.layers[0] and model2.layers[0] are isomorphic objects, they can</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> save and load checkpoints compatible with each other</span>\nckpt2 <span class=\"pl-k\">=</span> tf.train.Checkpoint(<span class=\"pl-v\">m</span> <span class=\"pl-k\">=</span> model2.layers[<span class=\"pl-c1\">0</span>])\nstatus <span class=\"pl-k\">=</span> ckpt2.restore(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/tmp/checkpoint<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n  status.initialize_or_restore()\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> At this point, the weights for the common portion have been restored</span></pre></div>\n<p>Hope this is helpful while we make object based checkpointing more pervasive.</p>", "body_text": "If you can organize the \"subgraphs\" into tf.keras.Model objects, then object-based checkpointing (tf.train.Checkpoint in TF 1.9) is hopefully the most intuitive.\nHowever, this is something that's in the early stages of being exposed and we haven't finished integration with MonitoredSession etc. just yet. @allenlavoie will have updates on that end, so assigning to him.\nAs an example of how things might look:\nimport tensorflow as tf\n\nL = tf.keras.layers # Shorthand\n\ndef make_shared_model():\n    return tf.keras.Sequential([\n        L.Conv2D(filters=32, kernel_size=(5, 5), padding='same', activation=tf.nn.relu, input_shape=[28, 28, 1]),\n        L.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        L.MaxPool2D(pool_size=(2,2), strides=2)])\n\ndef make_model1():\n    return tf.keras.Sequential([\n        make_shared_model(),\n        L.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation=tf.nn.relu),\n        L.Flatten(),\n        L.Dense(10)])\n\nmodel1 = make_model1()\n# Create a checkpoint with just the shared portion, which is model1.layers[0]\nckpt1 = tf.train.Checkpoint(m = model1.layers[0])\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for step in range(20):\n        # Get your data and train model1\n        # Save a checkpoint of the shared components\n        pass\n    ckpt1.save(\"/tmp/checkpoint\")\n\n\n# Could have done all this in a single graph, but demonstrating two graphs\n# just to be parallel to the code you had above\ntf.reset_default_graph()\n\ndef make_model2():\n    return tf.keras.Sequential([\n        make_shared_model(),\n        L.Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation=tf.nn.relu),\n        L.Flatten(),\n        L.Dense(10)])\n\nmodel2 = make_model2()\n# Since model1.layers[0] and model2.layers[0] are isomorphic objects, they can\n# save and load checkpoints compatible with each other\nckpt2 = tf.train.Checkpoint(m = model2.layers[0])\nstatus = ckpt2.restore(\"/tmp/checkpoint\")\n\nwith tf.Session() as sess:\n  status.initialize_or_restore()\n  # At this point, the weights for the common portion have been restored\nHope this is helpful while we make object based checkpointing more pervasive.", "body": "If you can organize the \"subgraphs\" into `tf.keras.Model` objects, then object-based checkpointing ([`tf.train.Checkpoint` in TF 1.9](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/train/Checkpoint)) is hopefully the most intuitive.\r\n\r\nHowever, this is something that's in the early stages of being exposed and we haven't finished integration with `MonitoredSession` etc. just yet. @allenlavoie will have updates on that end, so assigning to him.\r\n\r\nAs an example of how things might look:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nL = tf.keras.layers # Shorthand\r\n\r\ndef make_shared_model():\r\n    return tf.keras.Sequential([\r\n        L.Conv2D(filters=32, kernel_size=(5, 5), padding='same', activation=tf.nn.relu, input_shape=[28, 28, 1]),\r\n        L.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\r\n        L.MaxPool2D(pool_size=(2,2), strides=2)])\r\n\r\ndef make_model1():\r\n    return tf.keras.Sequential([\r\n        make_shared_model(),\r\n        L.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation=tf.nn.relu),\r\n        L.Flatten(),\r\n        L.Dense(10)])\r\n\r\nmodel1 = make_model1()\r\n# Create a checkpoint with just the shared portion, which is model1.layers[0]\r\nckpt1 = tf.train.Checkpoint(m = model1.layers[0])\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    for step in range(20):\r\n        # Get your data and train model1\r\n        # Save a checkpoint of the shared components\r\n        pass\r\n    ckpt1.save(\"/tmp/checkpoint\")\r\n\r\n\r\n# Could have done all this in a single graph, but demonstrating two graphs\r\n# just to be parallel to the code you had above\r\ntf.reset_default_graph()\r\n\r\ndef make_model2():\r\n    return tf.keras.Sequential([\r\n        make_shared_model(),\r\n        L.Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation=tf.nn.relu),\r\n        L.Flatten(),\r\n        L.Dense(10)])\r\n\r\nmodel2 = make_model2()\r\n# Since model1.layers[0] and model2.layers[0] are isomorphic objects, they can\r\n# save and load checkpoints compatible with each other\r\nckpt2 = tf.train.Checkpoint(m = model2.layers[0])\r\nstatus = ckpt2.restore(\"/tmp/checkpoint\")\r\n\r\nwith tf.Session() as sess:\r\n  status.initialize_or_restore()\r\n  # At this point, the weights for the common portion have been restored\r\n```\r\n\r\nHope this is helpful while we make object based checkpointing more pervasive."}