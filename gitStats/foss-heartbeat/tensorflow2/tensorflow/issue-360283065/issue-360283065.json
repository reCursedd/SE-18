{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22275", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22275/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22275/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22275/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22275", "id": 360283065, "node_id": "MDU6SXNzdWUzNjAyODMwNjU=", "number": 22275, "title": "Class_weight with tf.dataset as input to model.fit will throw an error", "user": {"login": "was84san", "id": 15853008, "node_id": "MDQ6VXNlcjE1ODUzMDA4", "avatar_url": "https://avatars0.githubusercontent.com/u/15853008?v=4", "gravatar_id": "", "url": "https://api.github.com/users/was84san", "html_url": "https://github.com/was84san", "followers_url": "https://api.github.com/users/was84san/followers", "following_url": "https://api.github.com/users/was84san/following{/other_user}", "gists_url": "https://api.github.com/users/was84san/gists{/gist_id}", "starred_url": "https://api.github.com/users/was84san/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/was84san/subscriptions", "organizations_url": "https://api.github.com/users/was84san/orgs", "repos_url": "https://api.github.com/users/was84san/repos", "events_url": "https://api.github.com/users/was84san/events{/privacy}", "received_events_url": "https://api.github.com/users/was84san/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "pavithrasv", "id": 13326758, "node_id": "MDQ6VXNlcjEzMzI2NzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13326758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithrasv", "html_url": "https://github.com/pavithrasv", "followers_url": "https://api.github.com/users/pavithrasv/followers", "following_url": "https://api.github.com/users/pavithrasv/following{/other_user}", "gists_url": "https://api.github.com/users/pavithrasv/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithrasv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithrasv/subscriptions", "organizations_url": "https://api.github.com/users/pavithrasv/orgs", "repos_url": "https://api.github.com/users/pavithrasv/repos", "events_url": "https://api.github.com/users/pavithrasv/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithrasv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithrasv", "id": 13326758, "node_id": "MDQ6VXNlcjEzMzI2NzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13326758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithrasv", "html_url": "https://github.com/pavithrasv", "followers_url": "https://api.github.com/users/pavithrasv/followers", "following_url": "https://api.github.com/users/pavithrasv/following{/other_user}", "gists_url": "https://api.github.com/users/pavithrasv/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithrasv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithrasv/subscriptions", "organizations_url": "https://api.github.com/users/pavithrasv/orgs", "repos_url": "https://api.github.com/users/pavithrasv/repos", "events_url": "https://api.github.com/users/pavithrasv/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithrasv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 15, "created_at": "2018-09-14T12:24:08Z", "updated_at": "2018-11-20T07:56:02Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: No Mobile device</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.10</li>\n<li><strong>Python version</strong>:2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: ---</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:---</li>\n<li><strong>CUDA/cuDNN version</strong>: cuda-8.0</li>\n<li><strong>GPU model and memory</strong>: (Titan X and GeForce GTX 1080 )</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am using<code>tf.keras</code>in order to be able to feed the train_data using<code> tf.dataset</code> API through model.fit directly. It works fine whenever you didn't pass <code>class_weight</code>, but if you pass dict of class_weights, it will throw the following error :</p>\n<p><code>AxisError: axis 1 is out of bounds for array of dimension 1 </code></p>\n<p>When I debug the error , I found the error happened exactly at line 531 :</p>\n<pre><code>&gt; /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_utils.py(530)standardize_weights()\n    528       raise ValueError('`class_weight` not supported for '\n    529                        '3+ dimensional targets.')\n    530     if y.shape[1] &gt; 1:\n--&gt;  531       y_classes = np.argmax(y, axis=1)\n    532     elif y.shape[1] == 1:\n\n</code></pre>\n<p>The dimension of y is <code>TensorShape([Dimension(None), Dimension(8)]) </code><br>\nSo<code> y.shape[1] &gt; 1</code> , but the problem y is a <strong>tensor</strong> now not an <strong>numpy array,</strong> that is why it throws the previous error.</p>\n<p>So is there any solution to this situation?</p>\n<h3><strong>EDIT</strong>: Adding sample code to reproduce the error.</h3>\n<pre><code>import os, sys, logging\nimport numpy as np\nimport tensorflow as tf\nimport itertools as itt\nlogging.basicConfig(level=logging.INFO)\n\n\ndef _int64_feature(value):\n  return tf.train.Feature(int64_list= tf.train.Int64List(value= [value]))\n\ndef _bytes_feature(value):\n  return tf.train.Feature(bytes_list= tf.train.BytesList(value= [value]))\n\ndef _float32_feature(value):\n  return tf.train.Feature(float_list= tf.train.FloatList(value= [value]))\n\ndef tf_records_creating(tfrecord_file):\n    logging.info('Creating random tfrecord files for 100 sample')\n\n    labels = np.random.uniform(0, num_classes, total_train).astype(np.int32)\n    data = np.random.uniform(0, 255, total_train*224*224*3).reshape(total_train, 224, 224, 3).astype(np.int32)\n\n    writer = tf.python_io.TFRecordWriter(tfrecord_file)\n\n    for idx, (image, label) in enumerate(itt.izip(data, labels)):\n        image = image.tostring()\n        example = tf.train.Example(features=tf.train.Features(feature={\n            'label': _int64_feature(int(label)),\n            'image': _bytes_feature(image),\n        }))\n        writer.write(example.SerializeToString())\n    writer.close()\n    return\n\ndef decode(serialized_example):\n  features = tf.parse_single_example(\n      serialized_example,\n      features={\n          'image': tf.FixedLenFeature([], tf.string),\n          'label': tf.FixedLenFeature([], tf.int64),\n      })\n\n  image = tf.decode_raw(features['image'], tf.float32)\n  image.set_shape([224*224*3])\n\n  image=tf.reshape(image, (224,224,3))\n\n  label = tf.cast(features['label'], tf.int32)\n  label_categorical = tf.one_hot(label,depth= num_classes, on_value=1,off_value=0,dtype=tf.int32,)\n  label_categorical = tf.reshape(label_categorical, [num_classes])\n  label_categorical.set_shape([num_classes])\n\n  return image, label_categorical\n\ndef data_preparing(tfrecord_file):\n\n    logging.info('Preparing the Training tf.dataset ')\n    training_files = [tfrecord_file]\n    dataset_train = tf.data.TFRecordDataset(training_files, num_parallel_reads=1)\n    dataset_train = dataset_train.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=4 * batch_size))\n    dataset_train = dataset_train.map(decode, num_parallel_calls=1)  \n    dataset_train = dataset_train.batch(batch_size)\n    dataset_train = dataset_train.prefetch(tf.contrib.data.AUTOTUNE)\n    return dataset_train\n\ndef train_model(tfrecord_file):\n\n    base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet',\n                                                 input_shape=(224, 224, 3), pooling='avg')\n\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    logging.info('Building Our Classifier')\n    x = base_model.output\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(512, activation='relu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n\n    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n    model.summary()\n    opt = tf.keras.optimizers.Adam(lr=0.001)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=opt, metrics=['accuracy'])\n    dataset_train = data_preparing(tfrecord_file=tfrecord_file)\n\n    weighted_array_train= np.array([0.01557266,0.00867447,0.04579864,0.08275284,0.18281397,\n       0.30659676, 0.04686068, 0.31092999])\n    class_weight_dict = dict(enumerate(weighted_array_train))\n\n    if using_class_weight == True:\n        model.fit(x=dataset_train, epochs=epochs, verbose=1,class_weight = class_weight_dict,\n              steps_per_epoch=int(np.ceil(total_train / batch_size)))\n    else:\n        model.fit(x=dataset_train, epochs=epochs, verbose=1,\n              steps_per_epoch=int(np.ceil(total_train / batch_size)))\n    return\n\nif __name__== '__main__':\n\n    total_train = 100.\n    num_classes= 8\n    batch_size = 10\n    epochs = 100\n\n    #TODO (1) :Set the path to tfrecord file that we will create it.\n    tfrecord_file = '~/train.tfrecords'\n    tf_records_creating(tfrecord_file)                # Implement this only one time\n\n    using_class_weight= False                         # if you set this to True, you will produce the error\n    train_model(tfrecord_file)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No Mobile device\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.10\nPython version:2.7\nBazel version (if compiling from source): ---\nGCC/Compiler version (if compiling from source):---\nCUDA/cuDNN version: cuda-8.0\nGPU model and memory: (Titan X and GeForce GTX 1080 )\nExact command to reproduce:\n\nDescribe the problem\nI am usingtf.kerasin order to be able to feed the train_data using tf.dataset API through model.fit directly. It works fine whenever you didn't pass class_weight, but if you pass dict of class_weights, it will throw the following error :\nAxisError: axis 1 is out of bounds for array of dimension 1 \nWhen I debug the error , I found the error happened exactly at line 531 :\n> /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_utils.py(530)standardize_weights()\n    528       raise ValueError('`class_weight` not supported for '\n    529                        '3+ dimensional targets.')\n    530     if y.shape[1] > 1:\n-->  531       y_classes = np.argmax(y, axis=1)\n    532     elif y.shape[1] == 1:\n\n\nThe dimension of y is TensorShape([Dimension(None), Dimension(8)]) \nSo y.shape[1] > 1 , but the problem y is a tensor now not an numpy array, that is why it throws the previous error.\nSo is there any solution to this situation?\nEDIT: Adding sample code to reproduce the error.\nimport os, sys, logging\nimport numpy as np\nimport tensorflow as tf\nimport itertools as itt\nlogging.basicConfig(level=logging.INFO)\n\n\ndef _int64_feature(value):\n  return tf.train.Feature(int64_list= tf.train.Int64List(value= [value]))\n\ndef _bytes_feature(value):\n  return tf.train.Feature(bytes_list= tf.train.BytesList(value= [value]))\n\ndef _float32_feature(value):\n  return tf.train.Feature(float_list= tf.train.FloatList(value= [value]))\n\ndef tf_records_creating(tfrecord_file):\n    logging.info('Creating random tfrecord files for 100 sample')\n\n    labels = np.random.uniform(0, num_classes, total_train).astype(np.int32)\n    data = np.random.uniform(0, 255, total_train*224*224*3).reshape(total_train, 224, 224, 3).astype(np.int32)\n\n    writer = tf.python_io.TFRecordWriter(tfrecord_file)\n\n    for idx, (image, label) in enumerate(itt.izip(data, labels)):\n        image = image.tostring()\n        example = tf.train.Example(features=tf.train.Features(feature={\n            'label': _int64_feature(int(label)),\n            'image': _bytes_feature(image),\n        }))\n        writer.write(example.SerializeToString())\n    writer.close()\n    return\n\ndef decode(serialized_example):\n  features = tf.parse_single_example(\n      serialized_example,\n      features={\n          'image': tf.FixedLenFeature([], tf.string),\n          'label': tf.FixedLenFeature([], tf.int64),\n      })\n\n  image = tf.decode_raw(features['image'], tf.float32)\n  image.set_shape([224*224*3])\n\n  image=tf.reshape(image, (224,224,3))\n\n  label = tf.cast(features['label'], tf.int32)\n  label_categorical = tf.one_hot(label,depth= num_classes, on_value=1,off_value=0,dtype=tf.int32,)\n  label_categorical = tf.reshape(label_categorical, [num_classes])\n  label_categorical.set_shape([num_classes])\n\n  return image, label_categorical\n\ndef data_preparing(tfrecord_file):\n\n    logging.info('Preparing the Training tf.dataset ')\n    training_files = [tfrecord_file]\n    dataset_train = tf.data.TFRecordDataset(training_files, num_parallel_reads=1)\n    dataset_train = dataset_train.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=4 * batch_size))\n    dataset_train = dataset_train.map(decode, num_parallel_calls=1)  \n    dataset_train = dataset_train.batch(batch_size)\n    dataset_train = dataset_train.prefetch(tf.contrib.data.AUTOTUNE)\n    return dataset_train\n\ndef train_model(tfrecord_file):\n\n    base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet',\n                                                 input_shape=(224, 224, 3), pooling='avg')\n\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    logging.info('Building Our Classifier')\n    x = base_model.output\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(512, activation='relu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n\n    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n    model.summary()\n    opt = tf.keras.optimizers.Adam(lr=0.001)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=opt, metrics=['accuracy'])\n    dataset_train = data_preparing(tfrecord_file=tfrecord_file)\n\n    weighted_array_train= np.array([0.01557266,0.00867447,0.04579864,0.08275284,0.18281397,\n       0.30659676, 0.04686068, 0.31092999])\n    class_weight_dict = dict(enumerate(weighted_array_train))\n\n    if using_class_weight == True:\n        model.fit(x=dataset_train, epochs=epochs, verbose=1,class_weight = class_weight_dict,\n              steps_per_epoch=int(np.ceil(total_train / batch_size)))\n    else:\n        model.fit(x=dataset_train, epochs=epochs, verbose=1,\n              steps_per_epoch=int(np.ceil(total_train / batch_size)))\n    return\n\nif __name__== '__main__':\n\n    total_train = 100.\n    num_classes= 8\n    batch_size = 10\n    epochs = 100\n\n    #TODO (1) :Set the path to tfrecord file that we will create it.\n    tfrecord_file = '~/train.tfrecords'\n    tf_records_creating(tfrecord_file)                # Implement this only one time\n\n    using_class_weight= False                         # if you set this to True, you will produce the error\n    train_model(tfrecord_file)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No Mobile device\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.10\r\n- **Python version**:2.7\r\n- **Bazel version (if compiling from source)**: ---\r\n- **GCC/Compiler version (if compiling from source)**:---\r\n- **CUDA/cuDNN version**: cuda-8.0\r\n- **GPU model and memory**: (Titan X and GeForce GTX 1080 )\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI am using` tf.keras `in order to be able to feed the train_data using` tf.dataset` API through model.fit directly. It works fine whenever you didn't pass `class_weight`, but if you pass dict of class_weights, it will throw the following error :\r\n\r\n`AxisError: axis 1 is out of bounds for array of dimension 1\r\n`\r\n\r\nWhen I debug the error , I found the error happened exactly at line 531 : \r\n```\r\n> /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_utils.py(530)standardize_weights()\r\n    528       raise ValueError('`class_weight` not supported for '\r\n    529                        '3+ dimensional targets.')\r\n    530     if y.shape[1] > 1:\r\n-->  531       y_classes = np.argmax(y, axis=1)\r\n    532     elif y.shape[1] == 1:\r\n\r\n```\r\nThe dimension of y is `TensorShape([Dimension(None), Dimension(8)])\r\n`\r\nSo` y.shape[1] > 1` , but the problem y is a **tensor** now not an **numpy array,** that is why it throws the previous error.\r\n\r\nSo is there any solution to this situation? \r\n\r\n### **EDIT**: Adding sample code to reproduce the error.\r\n\r\n```\r\nimport os, sys, logging\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport itertools as itt\r\nlogging.basicConfig(level=logging.INFO)\r\n\r\n\r\ndef _int64_feature(value):\r\n  return tf.train.Feature(int64_list= tf.train.Int64List(value= [value]))\r\n\r\ndef _bytes_feature(value):\r\n  return tf.train.Feature(bytes_list= tf.train.BytesList(value= [value]))\r\n\r\ndef _float32_feature(value):\r\n  return tf.train.Feature(float_list= tf.train.FloatList(value= [value]))\r\n\r\ndef tf_records_creating(tfrecord_file):\r\n    logging.info('Creating random tfrecord files for 100 sample')\r\n\r\n    labels = np.random.uniform(0, num_classes, total_train).astype(np.int32)\r\n    data = np.random.uniform(0, 255, total_train*224*224*3).reshape(total_train, 224, 224, 3).astype(np.int32)\r\n\r\n    writer = tf.python_io.TFRecordWriter(tfrecord_file)\r\n\r\n    for idx, (image, label) in enumerate(itt.izip(data, labels)):\r\n        image = image.tostring()\r\n        example = tf.train.Example(features=tf.train.Features(feature={\r\n            'label': _int64_feature(int(label)),\r\n            'image': _bytes_feature(image),\r\n        }))\r\n        writer.write(example.SerializeToString())\r\n    writer.close()\r\n    return\r\n\r\ndef decode(serialized_example):\r\n  features = tf.parse_single_example(\r\n      serialized_example,\r\n      features={\r\n          'image': tf.FixedLenFeature([], tf.string),\r\n          'label': tf.FixedLenFeature([], tf.int64),\r\n      })\r\n\r\n  image = tf.decode_raw(features['image'], tf.float32)\r\n  image.set_shape([224*224*3])\r\n\r\n  image=tf.reshape(image, (224,224,3))\r\n\r\n  label = tf.cast(features['label'], tf.int32)\r\n  label_categorical = tf.one_hot(label,depth= num_classes, on_value=1,off_value=0,dtype=tf.int32,)\r\n  label_categorical = tf.reshape(label_categorical, [num_classes])\r\n  label_categorical.set_shape([num_classes])\r\n\r\n  return image, label_categorical\r\n\r\ndef data_preparing(tfrecord_file):\r\n\r\n    logging.info('Preparing the Training tf.dataset ')\r\n    training_files = [tfrecord_file]\r\n    dataset_train = tf.data.TFRecordDataset(training_files, num_parallel_reads=1)\r\n    dataset_train = dataset_train.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=4 * batch_size))\r\n    dataset_train = dataset_train.map(decode, num_parallel_calls=1)  \r\n    dataset_train = dataset_train.batch(batch_size)\r\n    dataset_train = dataset_train.prefetch(tf.contrib.data.AUTOTUNE)\r\n    return dataset_train\r\n\r\ndef train_model(tfrecord_file):\r\n\r\n    base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet',\r\n                                                 input_shape=(224, 224, 3), pooling='avg')\r\n\r\n    for layer in base_model.layers:\r\n        layer.trainable = False\r\n\r\n    logging.info('Building Our Classifier')\r\n    x = base_model.output\r\n    x = tf.keras.layers.Flatten()(x)\r\n    x = tf.keras.layers.Dense(512, activation='relu')(x)\r\n    x = tf.keras.layers.BatchNormalization()(x)\r\n    x = tf.keras.layers.Dropout(0.5)(x)\r\n    x = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\r\n\r\n    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\r\n    model.summary()\r\n    opt = tf.keras.optimizers.Adam(lr=0.001)\r\n    model.compile(loss='categorical_crossentropy',\r\n                  optimizer=opt, metrics=['accuracy'])\r\n    dataset_train = data_preparing(tfrecord_file=tfrecord_file)\r\n\r\n    weighted_array_train= np.array([0.01557266,0.00867447,0.04579864,0.08275284,0.18281397,\r\n       0.30659676, 0.04686068, 0.31092999])\r\n    class_weight_dict = dict(enumerate(weighted_array_train))\r\n\r\n    if using_class_weight == True:\r\n        model.fit(x=dataset_train, epochs=epochs, verbose=1,class_weight = class_weight_dict,\r\n              steps_per_epoch=int(np.ceil(total_train / batch_size)))\r\n    else:\r\n        model.fit(x=dataset_train, epochs=epochs, verbose=1,\r\n              steps_per_epoch=int(np.ceil(total_train / batch_size)))\r\n    return\r\n\r\nif __name__== '__main__':\r\n\r\n    total_train = 100.\r\n    num_classes= 8\r\n    batch_size = 10\r\n    epochs = 100\r\n\r\n    #TODO (1) :Set the path to tfrecord file that we will create it.\r\n    tfrecord_file = '~/train.tfrecords'\r\n    tf_records_creating(tfrecord_file)                # Implement this only one time\r\n\r\n    using_class_weight= False                         # if you set this to True, you will produce the error\r\n    train_model(tfrecord_file)\r\n```\r\n"}