{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/389054456", "html_url": "https://github.com/tensorflow/tensorflow/issues/19073#issuecomment-389054456", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19073", "id": 389054456, "node_id": "MDEyOklzc3VlQ29tbWVudDM4OTA1NDQ1Ng==", "user": {"login": "ghostplant", "id": 12099308, "node_id": "MDQ6VXNlcjEyMDk5MzA4", "avatar_url": "https://avatars2.githubusercontent.com/u/12099308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghostplant", "html_url": "https://github.com/ghostplant", "followers_url": "https://api.github.com/users/ghostplant/followers", "following_url": "https://api.github.com/users/ghostplant/following{/other_user}", "gists_url": "https://api.github.com/users/ghostplant/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghostplant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghostplant/subscriptions", "organizations_url": "https://api.github.com/users/ghostplant/orgs", "repos_url": "https://api.github.com/users/ghostplant/repos", "events_url": "https://api.github.com/users/ghostplant/events{/privacy}", "received_events_url": "https://api.github.com/users/ghostplant/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-15T06:13:54Z", "updated_at": "2018-05-15T15:20:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I just profiled the reason, and here is my explanation:</p>\n<p>By default, the <code>num_inter_threads</code> is 0, and my machine has 32 cores, and I found that <code>num_inter_threads</code> actually selects 32 by tensorflow's recommendation. Thus during the whole benchmark of tf_cnn_benchmark, I found 41 threads created by tensorflow in total: 1 thread for boot, 8 thread for num_intra_threads, and 32 thread for num_inter_threads.</p>\n<p>Here we only consider 32 threads for num_inter_threads which is too heavy, and what I found is that every thread within these 32 num_inter_threads are occupied with cuEventQuery calls, which seems like everyone is eager to feed data to a available cuda stream as much as possible but every thread are doing cuEventQuery all the time, so this makes quantities of cpus are wasted on each thread calling cuEventQuery.</p>\n<p>This issue can be slightly reduced by setting num_inter_threads to a small number manually since the default tensorflow recommendation is not well which makes ~3200% cpus occupation.</p>\n<p>BTW, I don't see CPU did a really heavy pipeline for input data expect for just a single batch of input data for each term of mini-batch which should be lite in terms of the number of calls of <code>cuMemcpyHtoDAsync</code>, so what makes CPU occupation 2800% larger?</p>", "body_text": "I just profiled the reason, and here is my explanation:\nBy default, the num_inter_threads is 0, and my machine has 32 cores, and I found that num_inter_threads actually selects 32 by tensorflow's recommendation. Thus during the whole benchmark of tf_cnn_benchmark, I found 41 threads created by tensorflow in total: 1 thread for boot, 8 thread for num_intra_threads, and 32 thread for num_inter_threads.\nHere we only consider 32 threads for num_inter_threads which is too heavy, and what I found is that every thread within these 32 num_inter_threads are occupied with cuEventQuery calls, which seems like everyone is eager to feed data to a available cuda stream as much as possible but every thread are doing cuEventQuery all the time, so this makes quantities of cpus are wasted on each thread calling cuEventQuery.\nThis issue can be slightly reduced by setting num_inter_threads to a small number manually since the default tensorflow recommendation is not well which makes ~3200% cpus occupation.\nBTW, I don't see CPU did a really heavy pipeline for input data expect for just a single batch of input data for each term of mini-batch which should be lite in terms of the number of calls of cuMemcpyHtoDAsync, so what makes CPU occupation 2800% larger?", "body": "I just profiled the reason, and here is my explanation:\r\n\r\nBy default, the `num_inter_threads` is 0, and my machine has 32 cores, and I found that `num_inter_threads` actually selects 32 by tensorflow's recommendation. Thus during the whole benchmark of tf_cnn_benchmark, I found 41 threads created by tensorflow in total: 1 thread for boot, 8 thread for num_intra_threads, and 32 thread for num_inter_threads.\r\n\r\nHere we only consider 32 threads for num_inter_threads which is too heavy, and what I found is that every thread within these 32 num_inter_threads are occupied with cuEventQuery calls, which seems like everyone is eager to feed data to a available cuda stream as much as possible but every thread are doing cuEventQuery all the time, so this makes quantities of cpus are wasted on each thread calling cuEventQuery.\r\n\r\nThis issue can be slightly reduced by setting num_inter_threads to a small number manually since the default tensorflow recommendation is not well which makes ~3200% cpus occupation.\r\n\r\nBTW, I don't see CPU did a really heavy pipeline for input data expect for just a single batch of input data for each term of mini-batch which should be lite in terms of the number of calls of `cuMemcpyHtoDAsync`, so what makes CPU occupation 2800% larger?\r\n"}