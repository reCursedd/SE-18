{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/415674611", "html_url": "https://github.com/tensorflow/tensorflow/issues/21831#issuecomment-415674611", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21831", "id": 415674611, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTY3NDYxMQ==", "user": {"login": "fferroni", "id": 16327442, "node_id": "MDQ6VXNlcjE2MzI3NDQy", "avatar_url": "https://avatars1.githubusercontent.com/u/16327442?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fferroni", "html_url": "https://github.com/fferroni", "followers_url": "https://api.github.com/users/fferroni/followers", "following_url": "https://api.github.com/users/fferroni/following{/other_user}", "gists_url": "https://api.github.com/users/fferroni/gists{/gist_id}", "starred_url": "https://api.github.com/users/fferroni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fferroni/subscriptions", "organizations_url": "https://api.github.com/users/fferroni/orgs", "repos_url": "https://api.github.com/users/fferroni/repos", "events_url": "https://api.github.com/users/fferroni/events{/privacy}", "received_events_url": "https://api.github.com/users/fferroni/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-24T07:20:34Z", "updated_at": "2018-08-24T07:21:28Z", "author_association": "NONE", "body_html": "<p>An update. I tried to test a smaller network below and now the native, TRT float32 and TRT float16 conversions work.</p>\n<pre><code>\ninputs = tf.keras.layers.Input((720, 640, 3), batch_size=1, name=\"input\")\n\nx = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\nx = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\n\nx = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\n\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\n\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\n\nx = tf.keras.layers.Conv2D(1, (3, 3), dilation_rate=(2, 2), activation=\"selu\")(x) # unsupported by TensorRT, example\n\nmodel = tf.keras.models.Model(inputs, x)\n\nfrom tensorflow.python.tools import optimize_for_inference_lib\nfrom tensorflow.python.framework import dtypes\nfrom typing import List\n\ndef freeze_graph(session, \n                 output_nodes: List[str], \n                 save_path: str):\n    \"\"\"\n    :param input_nodes: list of strings of input nodes in session graph\n    :param output_nodes: list of strings of output nodes in session graph\n    :param save_path: output file path\n    :param optimize: boolean flag. Will try to run some optimizations, assuming I/O is float32.\n    :return:\n    \"\"\"\n\n    output_graph_def = tf.graph_util.convert_variables_to_constants(\n        session,                                     # The session is used to retrieve the weights\n        session.graph_def,                           # The graph_def is used to retrieve the nodes\n        output_nodes                                 # The output node names are used to select the useful nodes\n    )\n\n    with tf.gfile.GFile(save_path, \"wb\") as f:\n        f.write(output_graph_def.SerializeToString())\n    print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n\nfreeze_graph(tf.keras.backend.get_session(),\n             [o.name[:-2] for o in model.outputs],\n             \"encoder.pb\")\n</code></pre>\n<p>However, I still cannot get the INT8 version working.</p>\n<pre><code>2018-08-24 09:10:12.619360: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count &gt;= 8): 0\n2018-08-24 09:10:12.649301: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2853] Segment @scope '', converted to graph\n2018-08-24 09:10:12.656973: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:724] Can't determine the device, constructing an allocator at device 0\nRunning Calibration\nINFO:tensorflow:Starting execution\n2018-08-24 09:10:28.382906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-08-24 09:10:28.382955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-08-24 09:10:28.382963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n2018-08-24 09:10:28.382968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n2018-08-24 09:10:28.384566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2020 MB memory) -&gt; physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\nINFO:tensorflow:Starting Warmup cycle\n2018-08-24 09:10:28.662523: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:567] Starting calibration thread on device 0, Calibration Resource @ 0x7f39d8084890\n2018-08-24 09:10:28.676649: W tensorflow/contrib/tensorrt/log/trt_logger.cc:34] DefaultLogger Int8 support requested on hardware without native Int8 support, performance will be negatively affected.\nINFO:tensorflow:Warmup done. Starting real timing\niter  0   0.35218316555023194\nComparison= True\nINFO:tensorflow:Timing loop done!\nCreating inference graph\n2018-08-24 09:10:54.272182: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:153] Starting Calib Conversion\n2018-08-24 09:10:54.274204: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:159] Construction of static int8 engine is not implemented yet!. Dynamic engine will be constructed\n2018-08-24 09:10:59.975683: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\n2018-08-24 09:10:59.978356: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\n2018-08-24 09:10:59.978479: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:588] Calibration failed: Internal: Failed to build TensorRT engine\nINFO:tensorflow:Starting execution\n2018-08-24 09:11:00.175254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-08-24 09:11:00.175287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-08-24 09:11:00.175312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n2018-08-24 09:11:00.175317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n2018-08-24 09:11:00.175460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2020 MB memory) -&gt; physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\nINFO:tensorflow:Starting Warmup cycle\n2018-08-24 09:11:00.435002: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:491] import/my_trt_op_0 Constructing a new engine with batch size 1\n2018-08-24 09:11:00.446641: W tensorflow/contrib/tensorrt/log/trt_logger.cc:34] DefaultLogger Int8 support requested on hardware without native Int8 support, performance will be negatively affected.\n2018-08-24 09:11:03.973151: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\n2018-08-24 09:11:03.973476: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\n2018-08-24 09:11:03.973638: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:505] Engine creation for batch size 1 failed Internal: Failed to build TensorRT engine\n2018-08-24 09:11:03.973666: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:283] Engine retrieval for batch size 1 failed Running native segment\nTraceback (most recent call last):\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\n    return fn(*args)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.InternalError: Engine creation failed!\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"tftrt_sample.py\", line 310, in &lt;module&gt;\n    f.num_loops,dummy_input,timelineName)\n  File \"tftrt_sample.py\", line 199, in timeGraph\n    valt = sess.run(outlist)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 877, in run\n    run_metadata_ptr)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\n    run_metadata)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Engine creation failed!\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\nCaused by op 'import/my_trt_op_0', defined at:\n  File \"tftrt_sample.py\", line 310, in &lt;module&gt;\n    f.num_loops,dummy_input,timelineName)\n  File \"tftrt_sample.py\", line 159, in timeGraph\n    return_elements=[\"conv2d_10/mul_1\"]\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3289, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3289, in &lt;listcomp&gt;\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3180, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Engine creation failed!\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n</code></pre>", "body_text": "An update. I tried to test a smaller network below and now the native, TRT float32 and TRT float16 conversions work.\n\ninputs = tf.keras.layers.Input((720, 640, 3), batch_size=1, name=\"input\")\n\nx = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\nx = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\n\nx = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\n\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\n\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\n\nx = tf.keras.layers.Conv2D(1, (3, 3), dilation_rate=(2, 2), activation=\"selu\")(x) # unsupported by TensorRT, example\n\nmodel = tf.keras.models.Model(inputs, x)\n\nfrom tensorflow.python.tools import optimize_for_inference_lib\nfrom tensorflow.python.framework import dtypes\nfrom typing import List\n\ndef freeze_graph(session, \n                 output_nodes: List[str], \n                 save_path: str):\n    \"\"\"\n    :param input_nodes: list of strings of input nodes in session graph\n    :param output_nodes: list of strings of output nodes in session graph\n    :param save_path: output file path\n    :param optimize: boolean flag. Will try to run some optimizations, assuming I/O is float32.\n    :return:\n    \"\"\"\n\n    output_graph_def = tf.graph_util.convert_variables_to_constants(\n        session,                                     # The session is used to retrieve the weights\n        session.graph_def,                           # The graph_def is used to retrieve the nodes\n        output_nodes                                 # The output node names are used to select the useful nodes\n    )\n\n    with tf.gfile.GFile(save_path, \"wb\") as f:\n        f.write(output_graph_def.SerializeToString())\n    print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n\nfreeze_graph(tf.keras.backend.get_session(),\n             [o.name[:-2] for o in model.outputs],\n             \"encoder.pb\")\n\nHowever, I still cannot get the INT8 version working.\n2018-08-24 09:10:12.619360: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 0\n2018-08-24 09:10:12.649301: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2853] Segment @scope '', converted to graph\n2018-08-24 09:10:12.656973: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:724] Can't determine the device, constructing an allocator at device 0\nRunning Calibration\nINFO:tensorflow:Starting execution\n2018-08-24 09:10:28.382906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-08-24 09:10:28.382955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-08-24 09:10:28.382963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n2018-08-24 09:10:28.382968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n2018-08-24 09:10:28.384566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2020 MB memory) -> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\nINFO:tensorflow:Starting Warmup cycle\n2018-08-24 09:10:28.662523: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:567] Starting calibration thread on device 0, Calibration Resource @ 0x7f39d8084890\n2018-08-24 09:10:28.676649: W tensorflow/contrib/tensorrt/log/trt_logger.cc:34] DefaultLogger Int8 support requested on hardware without native Int8 support, performance will be negatively affected.\nINFO:tensorflow:Warmup done. Starting real timing\niter  0   0.35218316555023194\nComparison= True\nINFO:tensorflow:Timing loop done!\nCreating inference graph\n2018-08-24 09:10:54.272182: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:153] Starting Calib Conversion\n2018-08-24 09:10:54.274204: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:159] Construction of static int8 engine is not implemented yet!. Dynamic engine will be constructed\n2018-08-24 09:10:59.975683: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\n2018-08-24 09:10:59.978356: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\n2018-08-24 09:10:59.978479: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:588] Calibration failed: Internal: Failed to build TensorRT engine\nINFO:tensorflow:Starting execution\n2018-08-24 09:11:00.175254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-08-24 09:11:00.175287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-08-24 09:11:00.175312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n2018-08-24 09:11:00.175317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n2018-08-24 09:11:00.175460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2020 MB memory) -> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\nINFO:tensorflow:Starting Warmup cycle\n2018-08-24 09:11:00.435002: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:491] import/my_trt_op_0 Constructing a new engine with batch size 1\n2018-08-24 09:11:00.446641: W tensorflow/contrib/tensorrt/log/trt_logger.cc:34] DefaultLogger Int8 support requested on hardware without native Int8 support, performance will be negatively affected.\n2018-08-24 09:11:03.973151: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\n2018-08-24 09:11:03.973476: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\n2018-08-24 09:11:03.973638: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:505] Engine creation for batch size 1 failed Internal: Failed to build TensorRT engine\n2018-08-24 09:11:03.973666: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:283] Engine retrieval for batch size 1 failed Running native segment\nTraceback (most recent call last):\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\n    return fn(*args)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.InternalError: Engine creation failed!\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"tftrt_sample.py\", line 310, in <module>\n    f.num_loops,dummy_input,timelineName)\n  File \"tftrt_sample.py\", line 199, in timeGraph\n    valt = sess.run(outlist)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 877, in run\n    run_metadata_ptr)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\n    run_metadata)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Engine creation failed!\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\nCaused by op 'import/my_trt_op_0', defined at:\n  File \"tftrt_sample.py\", line 310, in <module>\n    f.num_loops,dummy_input,timelineName)\n  File \"tftrt_sample.py\", line 159, in timeGraph\n    return_elements=[\"conv2d_10/mul_1\"]\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3289, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3289, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3180, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Engine creation failed!\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]", "body": "An update. I tried to test a smaller network below and now the native, TRT float32 and TRT float16 conversions work. \r\n```\r\n\r\ninputs = tf.keras.layers.Input((720, 640, 3), batch_size=1, name=\"input\")\r\n\r\nx = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\r\nx = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\r\n\r\nx = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\r\n\r\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\r\n\r\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\r\nx = tf.keras.layers.MaxPool2D(padding=\"same\")(x)\r\n\r\nx = tf.keras.layers.Conv2D(1, (3, 3), dilation_rate=(2, 2), activation=\"selu\")(x) # unsupported by TensorRT, example\r\n\r\nmodel = tf.keras.models.Model(inputs, x)\r\n\r\nfrom tensorflow.python.tools import optimize_for_inference_lib\r\nfrom tensorflow.python.framework import dtypes\r\nfrom typing import List\r\n\r\ndef freeze_graph(session, \r\n                 output_nodes: List[str], \r\n                 save_path: str):\r\n    \"\"\"\r\n    :param input_nodes: list of strings of input nodes in session graph\r\n    :param output_nodes: list of strings of output nodes in session graph\r\n    :param save_path: output file path\r\n    :param optimize: boolean flag. Will try to run some optimizations, assuming I/O is float32.\r\n    :return:\r\n    \"\"\"\r\n\r\n    output_graph_def = tf.graph_util.convert_variables_to_constants(\r\n        session,                                     # The session is used to retrieve the weights\r\n        session.graph_def,                           # The graph_def is used to retrieve the nodes\r\n        output_nodes                                 # The output node names are used to select the useful nodes\r\n    )\r\n\r\n    with tf.gfile.GFile(save_path, \"wb\") as f:\r\n        f.write(output_graph_def.SerializeToString())\r\n    print(\"%d ops in the final graph.\" % len(output_graph_def.node))\r\n\r\nfreeze_graph(tf.keras.backend.get_session(),\r\n             [o.name[:-2] for o in model.outputs],\r\n             \"encoder.pb\")\r\n```\r\n\r\nHowever, I still cannot get the INT8 version working.\r\n\r\n```\r\n2018-08-24 09:10:12.619360: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 0\r\n2018-08-24 09:10:12.649301: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2853] Segment @scope '', converted to graph\r\n2018-08-24 09:10:12.656973: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:724] Can't determine the device, constructing an allocator at device 0\r\nRunning Calibration\r\nINFO:tensorflow:Starting execution\r\n2018-08-24 09:10:28.382906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-08-24 09:10:28.382955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-24 09:10:28.382963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \r\n2018-08-24 09:10:28.382968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \r\n2018-08-24 09:10:28.384566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2020 MB memory) -> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nINFO:tensorflow:Starting Warmup cycle\r\n2018-08-24 09:10:28.662523: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:567] Starting calibration thread on device 0, Calibration Resource @ 0x7f39d8084890\r\n2018-08-24 09:10:28.676649: W tensorflow/contrib/tensorrt/log/trt_logger.cc:34] DefaultLogger Int8 support requested on hardware without native Int8 support, performance will be negatively affected.\r\nINFO:tensorflow:Warmup done. Starting real timing\r\niter  0   0.35218316555023194\r\nComparison= True\r\nINFO:tensorflow:Timing loop done!\r\nCreating inference graph\r\n2018-08-24 09:10:54.272182: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:153] Starting Calib Conversion\r\n2018-08-24 09:10:54.274204: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:159] Construction of static int8 engine is not implemented yet!. Dynamic engine will be constructed\r\n2018-08-24 09:10:59.975683: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\r\n2018-08-24 09:10:59.978356: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\r\n2018-08-24 09:10:59.978479: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:588] Calibration failed: Internal: Failed to build TensorRT engine\r\nINFO:tensorflow:Starting execution\r\n2018-08-24 09:11:00.175254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-08-24 09:11:00.175287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-24 09:11:00.175312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \r\n2018-08-24 09:11:00.175317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \r\n2018-08-24 09:11:00.175460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2020 MB memory) -> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nINFO:tensorflow:Starting Warmup cycle\r\n2018-08-24 09:11:00.435002: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:491] import/my_trt_op_0 Constructing a new engine with batch size 1\r\n2018-08-24 09:11:00.446641: W tensorflow/contrib/tensorrt/log/trt_logger.cc:34] DefaultLogger Int8 support requested on hardware without native Int8 support, performance will be negatively affected.\r\n2018-08-24 09:11:03.973151: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\r\n2018-08-24 09:11:03.973476: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger cudnnFusedConvActLayer.cpp (61) - Cuda Error in createFilterTextureFused: 11\r\n2018-08-24 09:11:03.973638: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:505] Engine creation for batch size 1 failed Internal: Failed to build TensorRT engine\r\n2018-08-24 09:11:03.973666: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:283] Engine retrieval for batch size 1 failed Running native segment\r\nTraceback (most recent call last):\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n    return fn(*args)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InternalError: Engine creation failed!\r\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"tftrt_sample.py\", line 310, in <module>\r\n    f.num_loops,dummy_input,timelineName)\r\n  File \"tftrt_sample.py\", line 199, in timeGraph\r\n    valt = sess.run(outlist)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n    run_metadata_ptr)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n    run_metadata)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Engine creation failed!\r\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\r\n\r\nCaused by op 'import/my_trt_op_0', defined at:\r\n  File \"tftrt_sample.py\", line 310, in <module>\r\n    f.num_loops,dummy_input,timelineName)\r\n  File \"tftrt_sample.py\", line 159, in timeGraph\r\n    return_elements=[\"conv2d_10/mul_1\"]\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\r\n    _ProcessNewOps(graph)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\r\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3289, in _add_new_tf_operations\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3289, in <listcomp>\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3180, in _create_op_from_tf_operation\r\n    ret = Operation(c_op, self)\r\n  File \"/home/francesco/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInternalError (see above for traceback): Engine creation failed!\r\n\t [[Node: import/my_trt_op_0 = TRTEngineOp[InT=[DT_FLOAT], OutT=[DT_FLOAT], cached_engine_batches=[1], calibration_data=\"1\\nOutputP...3d8bc23d\\n\", fixed_input_size=true, input_shapes=[[1,3,720,640]], max_cached_engines_count=1, output_shapes=[[1,256,45,40]], precision_mode=\"INT8\", segment_funcdef_name=\"my_trt_op_0_native_segment\", serialized_segment=\"\\nD\\n\\tInp...01\\002\\002\", static_engine=false, workspace_size_bytes=1073741824, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](import/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\r\n```\r\n\r\n\r\n"}