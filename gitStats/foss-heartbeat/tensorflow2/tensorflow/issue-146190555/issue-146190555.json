{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1787", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1787/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1787/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1787/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1787", "id": 146190555, "node_id": "MDU6SXNzdWUxNDYxOTA1NTU=", "number": 1787, "title": "CUDNN_STATUS_BAD_PARAM with included cifar10 model", "user": {"login": "cmcneil", "id": 865043, "node_id": "MDQ6VXNlcjg2NTA0Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/865043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cmcneil", "html_url": "https://github.com/cmcneil", "followers_url": "https://api.github.com/users/cmcneil/followers", "following_url": "https://api.github.com/users/cmcneil/following{/other_user}", "gists_url": "https://api.github.com/users/cmcneil/gists{/gist_id}", "starred_url": "https://api.github.com/users/cmcneil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cmcneil/subscriptions", "organizations_url": "https://api.github.com/users/cmcneil/orgs", "repos_url": "https://api.github.com/users/cmcneil/repos", "events_url": "https://api.github.com/users/cmcneil/events{/privacy}", "received_events_url": "https://api.github.com/users/cmcneil/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-04-06T05:28:07Z", "updated_at": "2018-06-19T14:21:49Z", "closed_at": "2016-04-06T20:19:04Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System:<br>\nDebian 3.16.7-ckt20-1+deb8u3 (2016-01-17) x86_64 GNU/Linux<br>\nPython 2.7</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.<br>\n<a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl</a></li>\n<li>The output from python -c \"import tensorflow; print(tensorflow.<strong>version</strong>)\".<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally<br>\n0.7.1</li>\n</ol>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Go to /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10</li>\n<li>Run python cifar10_train.py as root</li>\n<li>Observe output<br>\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM<br>\nAborted</li>\n</ol>\n<h3>What have you tried?</h3>\n<ol>\n<li>Messing with LD_LIBRARY_PATH and making sure all cuda packages are updated to 7.5 (and CudNN 5.0). Training the simple softmax models on GPU is possible.</li>\n</ol>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).<br>\nroot@leviathan:/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10# python cifar10_train.py<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally<br>\n... Loads other CUDA libraries as above ...<br>\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: Tesla K40c<br>\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 11.25GiB<br>\nFree memory: 11.15GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0)<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB<br>\n... and so on up to 16.00 GB:<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.60GiB bytes.<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x5047a0000 extends to 0x7aaa4019a<br>\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM<br>\nAborted</p>", "body_text": "Environment info\nOperating System:\nDebian 3.16.7-ckt20-1+deb8u3 (2016-01-17) x86_64 GNU/Linux\nPython 2.7\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.version)\".\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n0.7.1\n\nSteps to reproduce\n\nGo to /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10\nRun python cifar10_train.py as root\nObserve output\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM\nAborted\n\nWhat have you tried?\n\nMessing with LD_LIBRARY_PATH and making sure all cuda packages are updated to 7.5 (and CudNN 5.0). Training the simple softmax models on GPU is possible.\n\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).\nroot@leviathan:/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10# python cifar10_train.py\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n... Loads other CUDA libraries as above ...\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: Tesla K40c\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:01:00.0\nTotal memory: 11.25GiB\nFree memory: 11.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\n... and so on up to 16.00 GB:\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.60GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x5047a0000 extends to 0x7aaa4019a\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM\nAborted", "body": "### Environment info\n\nOperating System:\nDebian 3.16.7-ckt20-1+deb8u3 (2016-01-17) x86_64 GNU/Linux\nPython 2.7\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n   0.7.1\n### Steps to reproduce\n1. Go to /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10\n2. Run python cifar10_train.py as root\n3. Observe output \n   F tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM\n   Aborted\n### What have you tried?\n1. Messing with LD_LIBRARY_PATH and making sure all cuda packages are updated to 7.5 (and CudNN 5.0). Training the simple softmax models on GPU is possible.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\nroot@leviathan:/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10# python cifar10_train.py \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n... Loads other CUDA libraries as above ...\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K40c\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:01:00.0\nTotal memory: 11.25GiB\nFree memory: 11.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\n... and so on up to 16.00 GB:\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.60GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x5047a0000 extends to 0x7aaa4019a\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM\nAborted\n"}