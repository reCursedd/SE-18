{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6000", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6000/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6000/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6000/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6000", "id": 192741248, "node_id": "MDU6SXNzdWUxOTI3NDEyNDg=", "number": 6000, "title": "distributed seq2seq used SyncReplicasOptimizerV2 question", "user": {"login": "chengdianxuezi", "id": 10277403, "node_id": "MDQ6VXNlcjEwMjc3NDAz", "avatar_url": "https://avatars1.githubusercontent.com/u/10277403?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chengdianxuezi", "html_url": "https://github.com/chengdianxuezi", "followers_url": "https://api.github.com/users/chengdianxuezi/followers", "following_url": "https://api.github.com/users/chengdianxuezi/following{/other_user}", "gists_url": "https://api.github.com/users/chengdianxuezi/gists{/gist_id}", "starred_url": "https://api.github.com/users/chengdianxuezi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chengdianxuezi/subscriptions", "organizations_url": "https://api.github.com/users/chengdianxuezi/orgs", "repos_url": "https://api.github.com/users/chengdianxuezi/repos", "events_url": "https://api.github.com/users/chengdianxuezi/events{/privacy}", "received_events_url": "https://api.github.com/users/chengdianxuezi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-12-01T02:48:55Z", "updated_at": "2017-12-22T17:50:33Z", "closed_at": "2017-12-22T17:50:32Z", "author_association": "NONE", "body_html": "<p>Now I want to change seq2seq to distributed mode used SyncReplicasOptimizerV2. I've been trying for a few days\uff0cbut still can't work out. this is my code,one file is seq2seq_train.py,on file is seq2seq_model.py<br>\nI try to run in 1 ps and 2 worker</p>\n<p>the error is:<br>\nTraceback (most recent call last):<br>\nFile \"/home/test/replicas_seq2seq_v4/seq2seq_train.py\", line 188, in <br>\ntf.app.run()<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run<br>\nsys.exit(main(sys.argv[:1] + flags_passthrough))<br>\nFile \"/home/test/replicas_seq2seq_v4/seq2seq_train.py\", line 82, in main<br>\ntask_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)<br>\nFile \"/home/test/replicas_seq2seq_v4/seq2seq_model.py\", line 221, in <strong>init</strong><br>\nself.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 720, in prepare_or_wait_for_session<br>\ninit_feed_dict=self._init_feed_dict, init_fn=self._init_fn)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 251, in prepare_session<br>\nself._local_init_op, msg))<br>\nRuntimeError: Init operations did not make model ready.  Init op: init, init fn: None, local_init_op: name: \"sync_replicas_3/group_deps\"<br>\nop: \"NoOp\"<br>\ninput: \"^sync_replicas_3/group_deps/NoOp\"<br>\ninput: \"^sync_replicas_3/group_deps/NoOp_1\"<br>\ninput: \"^sync_replicas_3/group_deps/NoOp_2\"<br>\ndevice: \"/job:worker/task:0\"<br>\n, error: Variables not initialized: sync_rep_local_step, sync_rep_local_step_1, sync_rep_local_step_2</p>\n<p>ps:<br>\npython seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=ps --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000</p>\n<p>worker1:<br>\npython seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000</p>\n<p>worker2:<br>\npython seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=1 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000</p>\n<p>seq2seq_train.py</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n\n<span class=\"pl-k\">import</span> tempfile\n<span class=\"pl-k\">import</span> math\n<span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> random\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">import</span> json\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">from</span> six.moves <span class=\"pl-k\">import</span> <span class=\"pl-v\">xrange</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> pylint: disable=redefined-builtin</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">from</span> tensorflow.models.rnn.translate <span class=\"pl-k\">import</span> data_utils\n<span class=\"pl-k\">import</span> seq2seq_model\n\ntf.app.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps_hosts<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n                           <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Comma-separated list of hostname:port pairs<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker_hosts<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n                           <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Comma-separated list of hostname:port pairs<span class=\"pl-pds\">\"</span></span>)\n\ntf.app.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>job_name<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>One of 'ps', 'worker'<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>task_index<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Index of task within the job<span class=\"pl-pds\">\"</span></span>)\n\ntf.app.flags.DEFINE_float(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>learning_rate<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">0.5</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Learning rate.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_float(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>learning_rate_decay_factor<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">0.99</span>,\n                          <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Learning rate decays by this much.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_float(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>max_gradient_norm<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">5.0</span>,\n                          <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Clip gradients to this norm.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>batch_size<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">64</span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Batch size to use during training.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>size<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">1024</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Size of each model layer.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num_layers<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Number of layers in the model.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>en_vocab_size<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">40000</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>English vocabulary size.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>fr_vocab_size<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">40000</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>French vocabulary size.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>data_dir<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/tmp/data<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Data directory<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>train_dir<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/tmp<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Training directory.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>max_train_data_size<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">0</span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Limit on the size of training data (0: no limit).<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>steps_per_checkpoint<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">200</span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>How many training steps to do per checkpoint.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_boolean(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>decode<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">False</span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Set to True for interactive decoding.<span class=\"pl-pds\">\"</span></span>)\ntf.app.flags.DEFINE_boolean(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>self_test<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">False</span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Run a self-test if this is set to True.<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c1\">FLAGS</span> <span class=\"pl-k\">=</span> tf.app.flags.<span class=\"pl-c1\">FLAGS</span>\n\n_buckets <span class=\"pl-k\">=</span> [(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">10</span>), (<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">15</span>), (<span class=\"pl-c1\">20</span>, <span class=\"pl-c1\">25</span>), (<span class=\"pl-c1\">40</span>, <span class=\"pl-c1\">50</span>)]\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">_</span>):\n  <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.job_name <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span> <span class=\"pl-k\">or</span> <span class=\"pl-c1\">FLAGS</span>.job_name <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>:\n    <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Must specify an explicit `job_name`<span class=\"pl-pds\">\"</span></span>)\n  <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.task_index <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span> <span class=\"pl-k\">or</span> <span class=\"pl-c1\">FLAGS</span>.task_index <span class=\"pl-k\">==</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>:\n    <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Must specify an explicit `task_index`<span class=\"pl-pds\">\"</span></span>)\n\n\n  ps_hosts <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.ps_hosts.split(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>,<span class=\"pl-pds\">\"</span></span>)\n  worker_hosts <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.worker_hosts.split(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>,<span class=\"pl-pds\">\"</span></span>)\n\n  cluster <span class=\"pl-k\">=</span> tf.train.ClusterSpec({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>: ps_hosts, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>: worker_hosts})\n\n  server <span class=\"pl-k\">=</span> tf.train.Server(cluster, <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.job_name, <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.task_index)\n  num_workers <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(worker_hosts)\n\n  server <span class=\"pl-k\">=</span> tf.train.Server(cluster, <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.job_name, <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.task_index)\n  <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.job_name <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>:\n    server.join()\n    <span class=\"pl-k\">return</span>\n  is_chief <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">FLAGS</span>.task_index <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>)\n  model <span class=\"pl-k\">=</span> seq2seq_model.Seq2SeqModel(server, <span class=\"pl-c1\">FLAGS</span>.en_vocab_size, <span class=\"pl-c1\">FLAGS</span>.fr_vocab_size, _buckets,\n      <span class=\"pl-c1\">FLAGS</span>.size, <span class=\"pl-c1\">FLAGS</span>.num_layers, <span class=\"pl-c1\">FLAGS</span>.max_gradient_norm, <span class=\"pl-c1\">FLAGS</span>.batch_size,\n      <span class=\"pl-c1\">FLAGS</span>.learning_rate, <span class=\"pl-c1\">FLAGS</span>.learning_rate_decay_factor,<span class=\"pl-v\">num_workers</span> <span class=\"pl-k\">=</span> num_workers, \n      <span class=\"pl-v\">task_index</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.task_index ,<span class=\"pl-v\">replicas_to_aggregate</span><span class=\"pl-k\">=</span>num_workers, <span class=\"pl-v\">forward_only</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n  step_time, loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>\n  current_step <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n  previous_losses <span class=\"pl-k\">=</span> []\n\n  <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>query -&gt; title:<span class=\"pl-pds\">\"</span></span>)\n  en_train <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.data_dir <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/giga-fren.release2.ids40000.en<span class=\"pl-pds\">\"</span></span>\n  fr_train <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.data_dir <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/giga-fren.release2.ids40000.fr<span class=\"pl-pds\">\"</span></span>\n  en_dev <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.data_dir <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/newstest2013.ids40000.en<span class=\"pl-pds\">\"</span></span>\n  fr_dev <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.data_dir <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/newstest2013.ids40000.fr<span class=\"pl-pds\">\"</span></span>\n\n  <span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Reading development and training data (limit: <span class=\"pl-c1\">%d</span>).<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> <span class=\"pl-c1\">FLAGS</span>.max_train_data_size)\n  dev_set <span class=\"pl-k\">=</span> read_data(en_dev, fr_dev)\n  train_set <span class=\"pl-k\">=</span> read_train_data(en_train, fr_train, num_workers, <span class=\"pl-c1\">FLAGS</span>.max_train_data_size)\n  train_bucket_sizes <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">len</span>(train_set[b]) <span class=\"pl-k\">for</span> b <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(_buckets))]\n  train_total_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">float</span>(<span class=\"pl-c1\">sum</span>(train_bucket_sizes))\n\n  train_buckets_scale <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">sum</span>(train_bucket_sizes[:i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>]) <span class=\"pl-k\">/</span> train_total_size <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(train_bucket_sizes))]\n  <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>finish to load data<span class=\"pl-pds\">\"</span></span>)\n  sess <span class=\"pl-k\">=</span> model.session\n  <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n    random_number_01 <span class=\"pl-k\">=</span> np.random.random_sample()\n    bucket_id <span class=\"pl-k\">=</span> <span class=\"pl-c1\">min</span>([i <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(train_buckets_scale)) <span class=\"pl-k\">if</span> train_buckets_scale[i] <span class=\"pl-k\">&gt;</span> random_number_01])\n\n    start_time <span class=\"pl-k\">=</span> time.time()\n    encoder_inputs, decoder_inputs, target_weights <span class=\"pl-k\">=</span> model.get_batch(train_set, bucket_id)\n    _, step_loss, _ <span class=\"pl-k\">=</span> model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, <span class=\"pl-c1\">False</span>)\n    step_time <span class=\"pl-k\">+=</span> (time.time() <span class=\"pl-k\">-</span> start_time) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">FLAGS</span>.steps_per_checkpoint\n    step_time_now <span class=\"pl-k\">=</span> (time.time() <span class=\"pl-k\">-</span> start_time)\n    loss <span class=\"pl-k\">+=</span> step_loss <span class=\"pl-k\">/</span> <span class=\"pl-c1\">FLAGS</span>.steps_per_checkpoint\n    step_loss_now <span class=\"pl-k\">=</span> step_loss\n    current_step <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>step: <span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> current_step)<span class=\"pl-bu\">;</span>\n\n    <span class=\"pl-k\">if</span> (<span class=\"pl-c1\">True</span>):\n      perplexity <span class=\"pl-k\">=</span> math.exp(step_loss) <span class=\"pl-k\">if</span> step_loss <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">300</span> <span class=\"pl-k\">else</span> <span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>inf<span class=\"pl-pds\">'</span></span>)\n      <span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>global step <span class=\"pl-c1\">%d</span> learning rate <span class=\"pl-c1\">%.4f</span> step-time <span class=\"pl-c1\">%.2f</span> perplexity <span class=\"pl-pds\">\"</span></span>\n             <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-c1\">%.2f</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (model.global_step.eval(sess), model.learning_rate.eval(sess), step_time_now, perplexity))\n\n      previous_losses.append(step_loss)\n\n      checkpoint_path <span class=\"pl-k\">=</span> os.path.join(train_dir, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>translate.ckpt<span class=\"pl-pds\">\"</span></span>)\n      model.saver.save(sess, checkpoint_path, <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>model.global_step)\n      <span class=\"pl-k\">if</span> (current_step <span class=\"pl-k\">%</span>  <span class=\"pl-c1\">FLAGS</span>.steps_per_checkpoint <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>):\n        <span class=\"pl-k\">for</span> bucket_id <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(_buckets)):\n          <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(dev_set[bucket_id]) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>  eval: empty bucket <span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (bucket_id))\n            <span class=\"pl-k\">continue</span>\n          encoder_inputs, decoder_inputs, target_weights <span class=\"pl-k\">=</span> model.get_batch(dev_set, bucket_id)\n          _, eval_loss, _ <span class=\"pl-k\">=</span> model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, <span class=\"pl-c1\">True</span>)\n          eval_ppx <span class=\"pl-k\">=</span> math.exp(eval_loss) <span class=\"pl-k\">if</span> eval_loss <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">300</span> <span class=\"pl-k\">else</span> <span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>inf<span class=\"pl-pds\">'</span></span>)\n          <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>  eval: bucket <span class=\"pl-c1\">%d</span> perplexity <span class=\"pl-c1\">%.2f</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (bucket_id, eval_ppx))\n        step_time, loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>\n      sys.stdout.flush()\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">read_train_data</span>(<span class=\"pl-smi\">source_path</span>, <span class=\"pl-smi\">target_path</span>, <span class=\"pl-smi\">num_workers</span>, <span class=\"pl-smi\">max_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n  data_set <span class=\"pl-k\">=</span> [[] <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> _buckets]\n  <span class=\"pl-k\">with</span> tf.gfile.GFile(source_path, <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>r<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> source_file:\n    <span class=\"pl-k\">with</span> tf.gfile.GFile(target_path, <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>r<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> target_file:\n      source, target <span class=\"pl-k\">=</span> source_file.readline(), target_file.readline()\n      counter <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n      <span class=\"pl-k\">while</span> source <span class=\"pl-k\">and</span> target <span class=\"pl-k\">and</span> (<span class=\"pl-k\">not</span> max_size <span class=\"pl-k\">or</span> counter <span class=\"pl-k\">&lt;</span> max_size):\n        counter <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n        <span class=\"pl-k\">if</span> counter <span class=\"pl-k\">%</span> <span class=\"pl-c1\">1000000</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n          <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>  reading data line <span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> counter)\n          sys.stdout.flush()\n        source_ids <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">int</span>(x) <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> source.split()]\n        target_ids <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">int</span>(x) <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> target.split()]\n        target_ids.append(data_utils.<span class=\"pl-c1\">EOS_ID</span>)\n        <span class=\"pl-k\">if</span> (counter <span class=\"pl-k\">%</span> num_workers <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>):\n          <span class=\"pl-k\">for</span> bucket_id, (source_size, target_size) <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(_buckets):\n            <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(source_ids) <span class=\"pl-k\">&lt;</span> source_size <span class=\"pl-k\">and</span> <span class=\"pl-c1\">len</span>(target_ids) <span class=\"pl-k\">&lt;</span> target_size:\n              data_set[bucket_id].append([source_ids, target_ids])\n              <span class=\"pl-k\">break</span>\n        source, target <span class=\"pl-k\">=</span> source_file.readline(), target_file.readline()\n  <span class=\"pl-k\">return</span> data_set\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">read_data</span>(<span class=\"pl-smi\">source_path</span>, <span class=\"pl-smi\">target_path</span>, <span class=\"pl-smi\">max_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n  data_set <span class=\"pl-k\">=</span> [[] <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> _buckets]\n  <span class=\"pl-k\">with</span> tf.gfile.GFile(source_path, <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>r<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> source_file:\n    <span class=\"pl-k\">with</span> tf.gfile.GFile(target_path, <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>r<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> target_file:\n      source, target <span class=\"pl-k\">=</span> source_file.readline(), target_file.readline()\n      counter <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n      <span class=\"pl-k\">while</span> source <span class=\"pl-k\">and</span> target <span class=\"pl-k\">and</span> (<span class=\"pl-k\">not</span> max_size <span class=\"pl-k\">or</span> counter <span class=\"pl-k\">&lt;</span> max_size):\n        counter <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n        <span class=\"pl-k\">if</span> counter <span class=\"pl-k\">%</span> <span class=\"pl-c1\">100000</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n          <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>  reading data line <span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> counter)\n          sys.stdout.flush()\n        source_ids <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">int</span>(x) <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> source.split()]\n        target_ids <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">int</span>(x) <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> target.split()]\n        target_ids.append(data_utils.<span class=\"pl-c1\">EOS_ID</span>)\n        <span class=\"pl-k\">for</span> bucket_id, (source_size, target_size) <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(_buckets):\n          <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(source_ids) <span class=\"pl-k\">&lt;</span> source_size <span class=\"pl-k\">and</span> <span class=\"pl-c1\">len</span>(target_ids) <span class=\"pl-k\">&lt;</span> target_size:\n            data_set[bucket_id].append([source_ids, target_ids])\n            <span class=\"pl-k\">break</span>\n        source, target <span class=\"pl-k\">=</span> source_file.readline(), target_file.readline()\n  <span class=\"pl-k\">return</span> data_set\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n      tf.app.run()</pre></div>\n<p>seq2seq_model.py</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n\n<span class=\"pl-k\">import</span> random\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">from</span> six.moves <span class=\"pl-k\">import</span> <span class=\"pl-v\">xrange</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> pylint: disable=redefined-builtin</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">from</span> tensorflow.models.rnn.translate <span class=\"pl-k\">import</span> data_utils\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Seq2SeqModel</span>(<span class=\"pl-c1\">object</span>):\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>,\n               <span class=\"pl-smi\">server</span>,\n               <span class=\"pl-smi\">source_vocab_size</span>,\n               <span class=\"pl-smi\">target_vocab_size</span>,\n               <span class=\"pl-smi\">buckets</span>,\n               <span class=\"pl-smi\">size</span>,\n               <span class=\"pl-smi\">num_layers</span>,\n               <span class=\"pl-smi\">max_gradient_norm</span>,\n               <span class=\"pl-smi\">batch_size</span>,\n               <span class=\"pl-smi\">learning_rate</span>,\n               <span class=\"pl-smi\">learning_rate_decay_factor</span>,\n               <span class=\"pl-smi\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, \n               <span class=\"pl-smi\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>,\n               <span class=\"pl-smi\">replicas_to_aggregate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>,\n               <span class=\"pl-smi\">use_lstm</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n               <span class=\"pl-smi\">num_samples</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">512</span>,\n               <span class=\"pl-smi\">forward_only</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n               <span class=\"pl-smi\">dtype</span><span class=\"pl-k\">=</span>tf.float32):\n\n    <span class=\"pl-c1\">self</span>.graph <span class=\"pl-k\">=</span> tf.Graph()\n    <span class=\"pl-c1\">self</span>.server <span class=\"pl-k\">=</span> server\n    <span class=\"pl-c1\">self</span>.source_vocab_size <span class=\"pl-k\">=</span> source_vocab_size\n    <span class=\"pl-c1\">self</span>.target_vocab_size <span class=\"pl-k\">=</span> target_vocab_size\n    <span class=\"pl-c1\">self</span>.buckets <span class=\"pl-k\">=</span> buckets\n    <span class=\"pl-c1\">self</span>.batch_size <span class=\"pl-k\">=</span> batch_size\n    <span class=\"pl-c1\">self</span>.num_workers <span class=\"pl-k\">=</span> num_workers \n    <span class=\"pl-c1\">self</span>.task_index <span class=\"pl-k\">=</span> task_index\n    <span class=\"pl-c1\">self</span>.is_chief <span class=\"pl-k\">=</span> (task_index <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>)\n    <span class=\"pl-c1\">self</span>.num_workers <span class=\"pl-k\">=</span> num_workers\n    <span class=\"pl-c1\">self</span>.replicas_to_aggregate <span class=\"pl-k\">=</span> replicas_to_aggregate\n\n    <span class=\"pl-k\">with</span> <span class=\"pl-c1\">self</span>.graph.as_default():\n      <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:ps/task:0<span class=\"pl-pds\">\"</span></span>): \n      <span class=\"pl-c\"><span class=\"pl-c\">#</span>with tf.device(\"/cpu:0\"): </span>\n        <span class=\"pl-c1\">self</span>.global_step <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n        <span class=\"pl-c1\">self</span>.learning_rate <span class=\"pl-k\">=</span> tf.Variable(\n            <span class=\"pl-c1\">float</span>(learning_rate), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype)\n\n      output_projection <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n      softmax_loss_function <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n      <span class=\"pl-k\">if</span> num_samples <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">and</span> num_samples <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">self</span>.target_vocab_size:\n        <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:ps/task:0<span class=\"pl-pds\">\"</span></span>): \n          w_t <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>proj_w<span class=\"pl-pds\">\"</span></span>, [<span class=\"pl-c1\">self</span>.target_vocab_size, size], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype)\n          w <span class=\"pl-k\">=</span> tf.transpose(w_t)\n          b <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>proj_b<span class=\"pl-pds\">\"</span></span>, [<span class=\"pl-c1\">self</span>.target_vocab_size], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype)\n        output_projection <span class=\"pl-k\">=</span> (w, b)\n  \n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">sampled_loss</span>(<span class=\"pl-smi\">inputs</span>, <span class=\"pl-smi\">labels</span>):\n          <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:<span class=\"pl-pds\">\"</span></span><span class=\"pl-k\">+</span><span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>.task_index)):\n            labels <span class=\"pl-k\">=</span> tf.reshape(labels, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>])\n            local_w_t <span class=\"pl-k\">=</span> tf.cast(w_t, tf.float32)\n            local_b <span class=\"pl-k\">=</span> tf.cast(b, tf.float32)\n            local_inputs <span class=\"pl-k\">=</span> tf.cast(inputs, tf.float32)\n            <span class=\"pl-k\">return</span> tf.cast(\n                tf.nn.sampled_softmax_loss(local_w_t, local_b, local_inputs, labels,\n                                           num_samples, <span class=\"pl-c1\">self</span>.target_vocab_size),\n                dtype)\n        softmax_loss_function <span class=\"pl-k\">=</span> sampled_loss\n  \n      <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:<span class=\"pl-pds\">\"</span></span><span class=\"pl-k\">+</span><span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>.task_index)):\n        single_cell <span class=\"pl-k\">=</span> tf.nn.rnn_cell.GRUCell(size)\n        <span class=\"pl-k\">if</span> use_lstm:\n          single_cell <span class=\"pl-k\">=</span> tf.nn.rnn_cell.BasicLSTMCell(size)\n        cell <span class=\"pl-k\">=</span> single_cell\n        <span class=\"pl-k\">if</span> num_layers <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">1</span>:\n          cell <span class=\"pl-k\">=</span> tf.nn.rnn_cell.MultiRNNCell([single_cell] <span class=\"pl-k\">*</span> num_layers)\n  \n      <span class=\"pl-k\">def</span> <span class=\"pl-en\">seq2seq_f</span>(<span class=\"pl-smi\">encoder_inputs</span>, <span class=\"pl-smi\">decoder_inputs</span>, <span class=\"pl-smi\">do_decode</span>):\n        <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:<span class=\"pl-pds\">\"</span></span><span class=\"pl-k\">+</span><span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>.task_index)):\n          <span class=\"pl-k\">return</span> tf.nn.seq2seq.embedding_attention_seq2seq(\n              encoder_inputs,\n              decoder_inputs,\n              cell,\n              <span class=\"pl-v\">num_encoder_symbols</span><span class=\"pl-k\">=</span>source_vocab_size,\n              <span class=\"pl-v\">num_decoder_symbols</span><span class=\"pl-k\">=</span>target_vocab_size,\n              <span class=\"pl-v\">embedding_size</span><span class=\"pl-k\">=</span>size,\n              <span class=\"pl-v\">output_projection</span><span class=\"pl-k\">=</span>output_projection,\n              <span class=\"pl-v\">feed_previous</span><span class=\"pl-k\">=</span>do_decode,\n              <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype)\n\n      <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:<span class=\"pl-pds\">\"</span></span><span class=\"pl-k\">+</span><span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>.task_index)):\n        <span class=\"pl-c1\">self</span>.encoder_inputs <span class=\"pl-k\">=</span> []\n        <span class=\"pl-c1\">self</span>.decoder_inputs <span class=\"pl-k\">=</span> []\n        <span class=\"pl-c1\">self</span>.target_weights <span class=\"pl-k\">=</span> []\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(buckets[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>][<span class=\"pl-c1\">0</span>]):  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Last bucket is the biggest one.</span>\n          <span class=\"pl-c1\">self</span>.encoder_inputs.append(tf.placeholder(tf.int32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>],\n                                                    <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>encoder<span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(i)))\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(buckets[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>][<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>):\n          <span class=\"pl-c1\">self</span>.decoder_inputs.append(tf.placeholder(tf.int32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>],\n                                                    <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>decoder<span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(i)))\n          <span class=\"pl-c1\">self</span>.target_weights.append(tf.placeholder(dtype, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>],\n                                                    <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>weight<span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(i)))\n  \n        targets <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">self</span>.decoder_inputs[i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>]\n                   <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(<span class=\"pl-c1\">self</span>.decoder_inputs) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>)]\n        <span class=\"pl-k\">if</span> forward_only:\n          <span class=\"pl-c1\">self</span>.outputs, <span class=\"pl-c1\">self</span>.losses <span class=\"pl-k\">=</span> tf.nn.seq2seq.model_with_buckets(\n              <span class=\"pl-c1\">self</span>.encoder_inputs, <span class=\"pl-c1\">self</span>.decoder_inputs, targets,\n              <span class=\"pl-c1\">self</span>.target_weights, buckets, <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>: seq2seq_f(x, y, <span class=\"pl-c1\">True</span>),\n              <span class=\"pl-v\">softmax_loss_function</span><span class=\"pl-k\">=</span>softmax_loss_function)\n          <span class=\"pl-k\">if</span> output_projection <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n            <span class=\"pl-k\">for</span> b <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(buckets)):\n              <span class=\"pl-c1\">self</span>.outputs[b] <span class=\"pl-k\">=</span> [\n                  tf.matmul(output, output_projection[<span class=\"pl-c1\">0</span>]) <span class=\"pl-k\">+</span> output_projection[<span class=\"pl-c1\">1</span>]\n                  <span class=\"pl-k\">for</span> output <span class=\"pl-k\">in</span> <span class=\"pl-c1\">self</span>.outputs[b]\n              ]\n        <span class=\"pl-k\">else</span>:\n          <span class=\"pl-c1\">self</span>.outputs, <span class=\"pl-c1\">self</span>.losses <span class=\"pl-k\">=</span> tf.nn.seq2seq.model_with_buckets(\n              <span class=\"pl-c1\">self</span>.encoder_inputs, <span class=\"pl-c1\">self</span>.decoder_inputs, targets,\n              <span class=\"pl-c1\">self</span>.target_weights, buckets,\n              <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>: seq2seq_f(x, y, <span class=\"pl-c1\">False</span>),\n              <span class=\"pl-v\">softmax_loss_function</span><span class=\"pl-k\">=</span>softmax_loss_function)\n  \n      <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:<span class=\"pl-pds\">\"</span></span><span class=\"pl-k\">+</span><span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>.task_index)):\n        params <span class=\"pl-k\">=</span> tf.trainable_variables()\n        <span class=\"pl-c1\">self</span>.gradient_norms <span class=\"pl-k\">=</span> []\n        <span class=\"pl-c1\">self</span>.updates <span class=\"pl-k\">=</span> []\n        sgd_opt <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">2.0</span>)\n        sync_rep_opt <span class=\"pl-k\">=</span> tf.train.SyncReplicasOptimizerV2(\n            sgd_opt, <span class=\"pl-v\">replicas_to_aggregate</span><span class=\"pl-k\">=</span>replicas_to_aggregate,\n            <span class=\"pl-v\">total_num_replicas</span><span class=\"pl-k\">=</span>num_workers)\n        <span class=\"pl-k\">for</span> b <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(buckets)):\n          gradients <span class=\"pl-k\">=</span> tf.gradients(<span class=\"pl-c1\">self</span>.losses[b], params)\n          clipped_gradients, norm <span class=\"pl-k\">=</span> tf.clip_by_global_norm(gradients,\n                                                           max_gradient_norm)\n          <span class=\"pl-c1\">self</span>.gradient_norms.append(norm)\n          <span class=\"pl-c1\">self</span>.updates.append(sync_rep_opt.apply_gradients(\n              <span class=\"pl-c1\">zip</span>(clipped_gradients, params), <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.global_step))\n\n        init_op <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n        local_init_op <span class=\"pl-k\">=</span> sync_rep_opt.local_step_init_op\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.is_chief:\n          local_init_op <span class=\"pl-k\">=</span> sync_rep_opt.chief_init_op\n        ready_for_local_init_op <span class=\"pl-k\">=</span> sync_rep_opt.ready_for_local_init_op\n\n        chief_queue_runner <span class=\"pl-k\">=</span> sync_rep_opt.get_chief_queue_runner()\n        sync_init_op <span class=\"pl-k\">=</span> sync_rep_opt.get_init_tokens_op(num_workers)\n\n    supervisor <span class=\"pl-k\">=</span> tf.train.Supervisor(\n        <span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.graph,\n        <span class=\"pl-v\">is_chief</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.is_chief,\n        <span class=\"pl-v\">recovery_wait_secs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n        <span class=\"pl-v\">init_op</span><span class=\"pl-k\">=</span>init_op,\n        <span class=\"pl-v\">local_init_op</span><span class=\"pl-k\">=</span>local_init_op,\n        <span class=\"pl-v\">ready_for_local_init_op</span><span class=\"pl-k\">=</span>ready_for_local_init_op)\n\n    sess_config <span class=\"pl-k\">=</span> tf.ConfigProto(\n        <span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n        <span class=\"pl-v\">log_device_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n        <span class=\"pl-v\">device_filters</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:ps<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:<span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> <span class=\"pl-c1\">self</span>.task_index])\n\n\n    <span class=\"pl-c1\">self</span>.session <span class=\"pl-k\">=</span> supervisor.prepare_or_wait_for_session(<span class=\"pl-c1\">self</span>.server.target, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>sess_config)\n\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.is_chief:\n      <span class=\"pl-c1\">self</span>.session.run(sync_init_op)\n      supervisor.StartQueueRunners(<span class=\"pl-c1\">self</span>.session, [chief_queue_runner])\n\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.is_chief:\n      <span class=\"pl-c1\">self</span>.session.run(sync_init_op)\n      supervisor.StartQueueRunners(<span class=\"pl-c1\">self</span>.session, [chief_queue_runner])\n\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">step</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">session</span>, <span class=\"pl-smi\">encoder_inputs</span>, <span class=\"pl-smi\">decoder_inputs</span>, <span class=\"pl-smi\">target_weights</span>,\n           <span class=\"pl-smi\">bucket_id</span>, <span class=\"pl-smi\">forward_only</span>):\n\n    encoder_size, decoder_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.buckets[bucket_id]\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(encoder_inputs) <span class=\"pl-k\">!=</span> encoder_size:\n      <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Encoder length must be equal to the one in bucket,<span class=\"pl-pds\">\"</span></span>\n                       <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> <span class=\"pl-c1\">%d</span> != <span class=\"pl-c1\">%d</span>.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (<span class=\"pl-c1\">len</span>(encoder_inputs), encoder_size))\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(decoder_inputs) <span class=\"pl-k\">!=</span> decoder_size:\n      <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Decoder length must be equal to the one in bucket,<span class=\"pl-pds\">\"</span></span>\n                       <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> <span class=\"pl-c1\">%d</span> != <span class=\"pl-c1\">%d</span>.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (<span class=\"pl-c1\">len</span>(decoder_inputs), decoder_size))\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(target_weights) <span class=\"pl-k\">!=</span> decoder_size:\n      <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Weights length must be equal to the one in bucket,<span class=\"pl-pds\">\"</span></span>\n                       <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> <span class=\"pl-c1\">%d</span> != <span class=\"pl-c1\">%d</span>.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (<span class=\"pl-c1\">len</span>(target_weights), decoder_size))\n\n\n    input_feed <span class=\"pl-k\">=</span> {}\n    <span class=\"pl-k\">for</span> l <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(encoder_size):\n      input_feed[<span class=\"pl-c1\">self</span>.encoder_inputs[l].name] <span class=\"pl-k\">=</span> encoder_inputs[l]\n    <span class=\"pl-k\">for</span> l <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(decoder_size):\n      input_feed[<span class=\"pl-c1\">self</span>.decoder_inputs[l].name] <span class=\"pl-k\">=</span> decoder_inputs[l]\n      input_feed[<span class=\"pl-c1\">self</span>.target_weights[l].name] <span class=\"pl-k\">=</span> target_weights[l]\n\n\n    last_target <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.decoder_inputs[decoder_size].name\n    input_feed[last_target] <span class=\"pl-k\">=</span> np.zeros([<span class=\"pl-c1\">self</span>.batch_size], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.int32)\n\n\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> forward_only:\n      output_feed <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">self</span>.updates[bucket_id],  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Update Op that does SGD.</span>\n                     <span class=\"pl-c1\">self</span>.gradient_norms[bucket_id],  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Gradient norm.</span>\n                     <span class=\"pl-c1\">self</span>.losses[bucket_id]]  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Loss for this batch.</span>\n    <span class=\"pl-k\">else</span>:\n      output_feed <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">self</span>.losses[bucket_id]]  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Loss for this batch.</span>\n      <span class=\"pl-k\">for</span> l <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(decoder_size):  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Output logits.</span>\n        output_feed.append(<span class=\"pl-c1\">self</span>.outputs[bucket_id][l])\n\n    outputs <span class=\"pl-k\">=</span> session.run(output_feed, input_feed)\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> forward_only:\n      <span class=\"pl-k\">return</span> outputs[<span class=\"pl-c1\">1</span>], outputs[<span class=\"pl-c1\">2</span>], <span class=\"pl-c1\">None</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Gradient norm, loss, no outputs.</span>\n    <span class=\"pl-k\">else</span>:\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">None</span>, outputs[<span class=\"pl-c1\">0</span>], outputs[<span class=\"pl-c1\">1</span>:]  <span class=\"pl-c\"><span class=\"pl-c\">#</span> No gradient norm, loss, outputs.</span>\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">get_batch</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">data</span>, <span class=\"pl-smi\">bucket_id</span>):\n\n    encoder_size, decoder_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.buckets[bucket_id]\n    encoder_inputs, decoder_inputs <span class=\"pl-k\">=</span> [], []\n\n\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">self</span>.batch_size):\n      encoder_input, decoder_input <span class=\"pl-k\">=</span> random.choice(data[bucket_id])\n\n\n      encoder_pad <span class=\"pl-k\">=</span> [data_utils.<span class=\"pl-c1\">PAD_ID</span>] <span class=\"pl-k\">*</span> (encoder_size <span class=\"pl-k\">-</span> <span class=\"pl-c1\">len</span>(encoder_input))\n      encoder_inputs.append(<span class=\"pl-c1\">list</span>(<span class=\"pl-c1\">reversed</span>(encoder_input <span class=\"pl-k\">+</span> encoder_pad)))\n\n\n      decoder_pad_size <span class=\"pl-k\">=</span> decoder_size <span class=\"pl-k\">-</span> <span class=\"pl-c1\">len</span>(decoder_input) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>\n      decoder_inputs.append([data_utils.<span class=\"pl-c1\">GO_ID</span>] <span class=\"pl-k\">+</span> decoder_input <span class=\"pl-k\">+</span>\n                            [data_utils.<span class=\"pl-c1\">PAD_ID</span>] <span class=\"pl-k\">*</span> decoder_pad_size)\n\n\n    batch_encoder_inputs, batch_decoder_inputs, batch_weights <span class=\"pl-k\">=</span> [], [], []\n\n\n    <span class=\"pl-k\">for</span> length_idx <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(encoder_size):\n      batch_encoder_inputs.append(\n          np.array([encoder_inputs[batch_idx][length_idx]\n                    <span class=\"pl-k\">for</span> batch_idx <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">self</span>.batch_size)], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.int32))\n\n\n    <span class=\"pl-k\">for</span> length_idx <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(decoder_size):\n      batch_decoder_inputs.append(\n          np.array([decoder_inputs[batch_idx][length_idx]\n                    <span class=\"pl-k\">for</span> batch_idx <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">self</span>.batch_size)], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.int32))\n\n\n      batch_weight <span class=\"pl-k\">=</span> np.ones(<span class=\"pl-c1\">self</span>.batch_size, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\n      <span class=\"pl-k\">for</span> batch_idx <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">self</span>.batch_size):\n        <span class=\"pl-k\">if</span> length_idx <span class=\"pl-k\">&lt;</span> decoder_size <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>:\n          target <span class=\"pl-k\">=</span> decoder_inputs[batch_idx][length_idx <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>]\n        <span class=\"pl-k\">if</span> length_idx <span class=\"pl-k\">==</span> decoder_size <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span> <span class=\"pl-k\">or</span> target <span class=\"pl-k\">==</span> data_utils.<span class=\"pl-c1\">PAD_ID</span>:\n          batch_weight[batch_idx] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.0</span>\n      batch_weights.append(batch_weight)\n    <span class=\"pl-k\">return</span> batch_encoder_inputs, batch_decoder_inputs, batch_weights</pre></div>", "body_text": "Now I want to change seq2seq to distributed mode used SyncReplicasOptimizerV2. I've been trying for a few days\uff0cbut still can't work out. this is my code,one file is seq2seq_train.py,on file is seq2seq_model.py\nI try to run in 1 ps and 2 worker\nthe error is:\nTraceback (most recent call last):\nFile \"/home/test/replicas_seq2seq_v4/seq2seq_train.py\", line 188, in \ntf.app.run()\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\nsys.exit(main(sys.argv[:1] + flags_passthrough))\nFile \"/home/test/replicas_seq2seq_v4/seq2seq_train.py\", line 82, in main\ntask_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)\nFile \"/home/test/replicas_seq2seq_v4/seq2seq_model.py\", line 221, in init\nself.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 720, in prepare_or_wait_for_session\ninit_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 251, in prepare_session\nself._local_init_op, msg))\nRuntimeError: Init operations did not make model ready.  Init op: init, init fn: None, local_init_op: name: \"sync_replicas_3/group_deps\"\nop: \"NoOp\"\ninput: \"^sync_replicas_3/group_deps/NoOp\"\ninput: \"^sync_replicas_3/group_deps/NoOp_1\"\ninput: \"^sync_replicas_3/group_deps/NoOp_2\"\ndevice: \"/job:worker/task:0\"\n, error: Variables not initialized: sync_rep_local_step, sync_rep_local_step_1, sync_rep_local_step_2\nps:\npython seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=ps --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000\nworker1:\npython seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000\nworker2:\npython seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=1 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000\nseq2seq_train.py\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tempfile\nimport math\nimport os\nimport random\nimport sys\nimport time\nimport json\n\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\nfrom tensorflow.models.rnn.translate import data_utils\nimport seq2seq_model\n\ntf.app.flags.DEFINE_string(\"ps_hosts\", \"\",\n                           \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"worker_hosts\", \"\",\n                           \"Comma-separated list of hostname:port pairs\")\n\ntf.app.flags.DEFINE_string(\"job_name\", \"\", \"One of 'ps', 'worker'\")\ntf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\n\ntf.app.flags.DEFINE_float(\"learning_rate\", 0.5, \"Learning rate.\")\ntf.app.flags.DEFINE_float(\"learning_rate_decay_factor\", 0.99,\n                          \"Learning rate decays by this much.\")\ntf.app.flags.DEFINE_float(\"max_gradient_norm\", 5.0,\n                          \"Clip gradients to this norm.\")\ntf.app.flags.DEFINE_integer(\"batch_size\", 64,\n                            \"Batch size to use during training.\")\ntf.app.flags.DEFINE_integer(\"size\", 1024, \"Size of each model layer.\")\ntf.app.flags.DEFINE_integer(\"num_layers\", 3, \"Number of layers in the model.\")\ntf.app.flags.DEFINE_integer(\"en_vocab_size\", 40000, \"English vocabulary size.\")\ntf.app.flags.DEFINE_integer(\"fr_vocab_size\", 40000, \"French vocabulary size.\")\ntf.app.flags.DEFINE_string(\"data_dir\", \"/tmp/data\", \"Data directory\")\ntf.app.flags.DEFINE_string(\"train_dir\", \"/tmp\", \"Training directory.\")\ntf.app.flags.DEFINE_integer(\"max_train_data_size\", 0,\n                            \"Limit on the size of training data (0: no limit).\")\ntf.app.flags.DEFINE_integer(\"steps_per_checkpoint\", 200,\n                            \"How many training steps to do per checkpoint.\")\ntf.app.flags.DEFINE_boolean(\"decode\", False,\n                            \"Set to True for interactive decoding.\")\ntf.app.flags.DEFINE_boolean(\"self_test\", False,\n                            \"Run a self-test if this is set to True.\")\n\nFLAGS = tf.app.flags.FLAGS\n\n_buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]\n\ndef main(_):\n  if FLAGS.job_name is None or FLAGS.job_name == \"\":\n    raise ValueError(\"Must specify an explicit `job_name`\")\n  if FLAGS.task_index is None or FLAGS.task_index ==\"\":\n    raise ValueError(\"Must specify an explicit `task_index`\")\n\n\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\n  worker_hosts = FLAGS.worker_hosts.split(\",\")\n\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n\n  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n  num_workers = len(worker_hosts)\n\n  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n  if FLAGS.job_name == \"ps\":\n    server.join()\n    return\n  is_chief = (FLAGS.task_index == 0)\n  model = seq2seq_model.Seq2SeqModel(server, FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,\n      FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n      FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,num_workers = num_workers, \n      task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)\n  step_time, loss = 0.0, 0.0\n  current_step = 0\n  previous_losses = []\n\n  print(\"query -> title:\")\n  en_train = FLAGS.data_dir + \"/giga-fren.release2.ids40000.en\"\n  fr_train = FLAGS.data_dir + \"/giga-fren.release2.ids40000.fr\"\n  en_dev = FLAGS.data_dir + \"/newstest2013.ids40000.en\"\n  fr_dev = FLAGS.data_dir + \"/newstest2013.ids40000.fr\"\n\n  print (\"Reading development and training data (limit: %d).\" % FLAGS.max_train_data_size)\n  dev_set = read_data(en_dev, fr_dev)\n  train_set = read_train_data(en_train, fr_train, num_workers, FLAGS.max_train_data_size)\n  train_bucket_sizes = [len(train_set[b]) for b in xrange(len(_buckets))]\n  train_total_size = float(sum(train_bucket_sizes))\n\n  train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size for i in xrange(len(train_bucket_sizes))]\n  print(\"finish to load data\")\n  sess = model.session\n  while True:\n    random_number_01 = np.random.random_sample()\n    bucket_id = min([i for i in xrange(len(train_buckets_scale)) if train_buckets_scale[i] > random_number_01])\n\n    start_time = time.time()\n    encoder_inputs, decoder_inputs, target_weights = model.get_batch(train_set, bucket_id)\n    _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, False)\n    step_time += (time.time() - start_time) / FLAGS.steps_per_checkpoint\n    step_time_now = (time.time() - start_time)\n    loss += step_loss / FLAGS.steps_per_checkpoint\n    step_loss_now = step_loss\n    current_step += 1\n    print(\"step: %d\" % current_step);\n\n    if (True):\n      perplexity = math.exp(step_loss) if step_loss < 300 else float('inf')\n      print (\"global step %d learning rate %.4f step-time %.2f perplexity \"\n             \"%.2f\" % (model.global_step.eval(sess), model.learning_rate.eval(sess), step_time_now, perplexity))\n\n      previous_losses.append(step_loss)\n\n      checkpoint_path = os.path.join(train_dir, \"translate.ckpt\")\n      model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n      if (current_step %  FLAGS.steps_per_checkpoint == 0):\n        for bucket_id in xrange(len(_buckets)):\n          if len(dev_set[bucket_id]) == 0:\n            print(\"  eval: empty bucket %d\" % (bucket_id))\n            continue\n          encoder_inputs, decoder_inputs, target_weights = model.get_batch(dev_set, bucket_id)\n          _, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, True)\n          eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')\n          print(\"  eval: bucket %d perplexity %.2f\" % (bucket_id, eval_ppx))\n        step_time, loss = 0.0, 0.0\n      sys.stdout.flush()\n\n\ndef read_train_data(source_path, target_path, num_workers, max_size=None):\n  data_set = [[] for _ in _buckets]\n  with tf.gfile.GFile(source_path, mode=\"r\") as source_file:\n    with tf.gfile.GFile(target_path, mode=\"r\") as target_file:\n      source, target = source_file.readline(), target_file.readline()\n      counter = 0\n      while source and target and (not max_size or counter < max_size):\n        counter += 1\n        if counter % 1000000 == 0:\n          print(\"  reading data line %d\" % counter)\n          sys.stdout.flush()\n        source_ids = [int(x) for x in source.split()]\n        target_ids = [int(x) for x in target.split()]\n        target_ids.append(data_utils.EOS_ID)\n        if (counter % num_workers == 0):\n          for bucket_id, (source_size, target_size) in enumerate(_buckets):\n            if len(source_ids) < source_size and len(target_ids) < target_size:\n              data_set[bucket_id].append([source_ids, target_ids])\n              break\n        source, target = source_file.readline(), target_file.readline()\n  return data_set\n\ndef read_data(source_path, target_path, max_size=None):\n  data_set = [[] for _ in _buckets]\n  with tf.gfile.GFile(source_path, mode=\"r\") as source_file:\n    with tf.gfile.GFile(target_path, mode=\"r\") as target_file:\n      source, target = source_file.readline(), target_file.readline()\n      counter = 0\n      while source and target and (not max_size or counter < max_size):\n        counter += 1\n        if counter % 100000 == 0:\n          print(\"  reading data line %d\" % counter)\n          sys.stdout.flush()\n        source_ids = [int(x) for x in source.split()]\n        target_ids = [int(x) for x in target.split()]\n        target_ids.append(data_utils.EOS_ID)\n        for bucket_id, (source_size, target_size) in enumerate(_buckets):\n          if len(source_ids) < source_size and len(target_ids) < target_size:\n            data_set[bucket_id].append([source_ids, target_ids])\n            break\n        source, target = source_file.readline(), target_file.readline()\n  return data_set\n\nif __name__ == \"__main__\":\n      tf.app.run()\nseq2seq_model.py\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport random\n\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\nfrom tensorflow.models.rnn.translate import data_utils\n\n\nclass Seq2SeqModel(object):\n\n  def __init__(self,\n               server,\n               source_vocab_size,\n               target_vocab_size,\n               buckets,\n               size,\n               num_layers,\n               max_gradient_norm,\n               batch_size,\n               learning_rate,\n               learning_rate_decay_factor,\n               num_workers=2, \n               task_index=0,\n               replicas_to_aggregate=2,\n               use_lstm=False,\n               num_samples=512,\n               forward_only=False,\n               dtype=tf.float32):\n\n    self.graph = tf.Graph()\n    self.server = server\n    self.source_vocab_size = source_vocab_size\n    self.target_vocab_size = target_vocab_size\n    self.buckets = buckets\n    self.batch_size = batch_size\n    self.num_workers = num_workers \n    self.task_index = task_index\n    self.is_chief = (task_index == 0)\n    self.num_workers = num_workers\n    self.replicas_to_aggregate = replicas_to_aggregate\n\n    with self.graph.as_default():\n      with tf.device(\"/job:ps/task:0\"): \n      #with tf.device(\"/cpu:0\"): \n        self.global_step = tf.Variable(0, trainable=False)\n        self.learning_rate = tf.Variable(\n            float(learning_rate), trainable=False, dtype=dtype)\n\n      output_projection = None\n      softmax_loss_function = None\n      if num_samples > 0 and num_samples < self.target_vocab_size:\n        with tf.device(\"/job:ps/task:0\"): \n          w_t = tf.get_variable(\"proj_w\", [self.target_vocab_size, size], dtype=dtype)\n          w = tf.transpose(w_t)\n          b = tf.get_variable(\"proj_b\", [self.target_vocab_size], dtype=dtype)\n        output_projection = (w, b)\n  \n        def sampled_loss(inputs, labels):\n          with tf.device(\"/job:worker/task:\"+str(self.task_index)):\n            labels = tf.reshape(labels, [-1, 1])\n            local_w_t = tf.cast(w_t, tf.float32)\n            local_b = tf.cast(b, tf.float32)\n            local_inputs = tf.cast(inputs, tf.float32)\n            return tf.cast(\n                tf.nn.sampled_softmax_loss(local_w_t, local_b, local_inputs, labels,\n                                           num_samples, self.target_vocab_size),\n                dtype)\n        softmax_loss_function = sampled_loss\n  \n      with tf.device(\"/job:worker/task:\"+str(self.task_index)):\n        single_cell = tf.nn.rnn_cell.GRUCell(size)\n        if use_lstm:\n          single_cell = tf.nn.rnn_cell.BasicLSTMCell(size)\n        cell = single_cell\n        if num_layers > 1:\n          cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\n  \n      def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n        with tf.device(\"/job:worker/task:\"+str(self.task_index)):\n          return tf.nn.seq2seq.embedding_attention_seq2seq(\n              encoder_inputs,\n              decoder_inputs,\n              cell,\n              num_encoder_symbols=source_vocab_size,\n              num_decoder_symbols=target_vocab_size,\n              embedding_size=size,\n              output_projection=output_projection,\n              feed_previous=do_decode,\n              dtype=dtype)\n\n      with tf.device(\"/job:worker/task:\"+str(self.task_index)):\n        self.encoder_inputs = []\n        self.decoder_inputs = []\n        self.target_weights = []\n        for i in xrange(buckets[-1][0]):  # Last bucket is the biggest one.\n          self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n                                                    name=\"encoder{0}\".format(i)))\n        for i in xrange(buckets[-1][1] + 1):\n          self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n                                                    name=\"decoder{0}\".format(i)))\n          self.target_weights.append(tf.placeholder(dtype, shape=[None],\n                                                    name=\"weight{0}\".format(i)))\n  \n        targets = [self.decoder_inputs[i + 1]\n                   for i in xrange(len(self.decoder_inputs) - 1)]\n        if forward_only:\n          self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\n              self.encoder_inputs, self.decoder_inputs, targets,\n              self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),\n              softmax_loss_function=softmax_loss_function)\n          if output_projection is not None:\n            for b in xrange(len(buckets)):\n              self.outputs[b] = [\n                  tf.matmul(output, output_projection[0]) + output_projection[1]\n                  for output in self.outputs[b]\n              ]\n        else:\n          self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\n              self.encoder_inputs, self.decoder_inputs, targets,\n              self.target_weights, buckets,\n              lambda x, y: seq2seq_f(x, y, False),\n              softmax_loss_function=softmax_loss_function)\n  \n      with tf.device(\"/job:worker/task:\"+str(self.task_index)):\n        params = tf.trainable_variables()\n        self.gradient_norms = []\n        self.updates = []\n        sgd_opt = tf.train.GradientDescentOptimizer(2.0)\n        sync_rep_opt = tf.train.SyncReplicasOptimizerV2(\n            sgd_opt, replicas_to_aggregate=replicas_to_aggregate,\n            total_num_replicas=num_workers)\n        for b in xrange(len(buckets)):\n          gradients = tf.gradients(self.losses[b], params)\n          clipped_gradients, norm = tf.clip_by_global_norm(gradients,\n                                                           max_gradient_norm)\n          self.gradient_norms.append(norm)\n          self.updates.append(sync_rep_opt.apply_gradients(\n              zip(clipped_gradients, params), global_step=self.global_step))\n\n        init_op = tf.global_variables_initializer()\n        local_init_op = sync_rep_opt.local_step_init_op\n        if self.is_chief:\n          local_init_op = sync_rep_opt.chief_init_op\n        ready_for_local_init_op = sync_rep_opt.ready_for_local_init_op\n\n        chief_queue_runner = sync_rep_opt.get_chief_queue_runner()\n        sync_init_op = sync_rep_opt.get_init_tokens_op(num_workers)\n\n    supervisor = tf.train.Supervisor(\n        graph=self.graph,\n        is_chief=self.is_chief,\n        recovery_wait_secs=1,\n        init_op=init_op,\n        local_init_op=local_init_op,\n        ready_for_local_init_op=ready_for_local_init_op)\n\n    sess_config = tf.ConfigProto(\n        allow_soft_placement=True,\n        log_device_placement=True,\n        device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % self.task_index])\n\n\n    self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)\n\n    if self.is_chief:\n      self.session.run(sync_init_op)\n      supervisor.StartQueueRunners(self.session, [chief_queue_runner])\n\n    if self.is_chief:\n      self.session.run(sync_init_op)\n      supervisor.StartQueueRunners(self.session, [chief_queue_runner])\n\n\n  def step(self, session, encoder_inputs, decoder_inputs, target_weights,\n           bucket_id, forward_only):\n\n    encoder_size, decoder_size = self.buckets[bucket_id]\n    if len(encoder_inputs) != encoder_size:\n      raise ValueError(\"Encoder length must be equal to the one in bucket,\"\n                       \" %d != %d.\" % (len(encoder_inputs), encoder_size))\n    if len(decoder_inputs) != decoder_size:\n      raise ValueError(\"Decoder length must be equal to the one in bucket,\"\n                       \" %d != %d.\" % (len(decoder_inputs), decoder_size))\n    if len(target_weights) != decoder_size:\n      raise ValueError(\"Weights length must be equal to the one in bucket,\"\n                       \" %d != %d.\" % (len(target_weights), decoder_size))\n\n\n    input_feed = {}\n    for l in xrange(encoder_size):\n      input_feed[self.encoder_inputs[l].name] = encoder_inputs[l]\n    for l in xrange(decoder_size):\n      input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]\n      input_feed[self.target_weights[l].name] = target_weights[l]\n\n\n    last_target = self.decoder_inputs[decoder_size].name\n    input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)\n\n\n    if not forward_only:\n      output_feed = [self.updates[bucket_id],  # Update Op that does SGD.\n                     self.gradient_norms[bucket_id],  # Gradient norm.\n                     self.losses[bucket_id]]  # Loss for this batch.\n    else:\n      output_feed = [self.losses[bucket_id]]  # Loss for this batch.\n      for l in xrange(decoder_size):  # Output logits.\n        output_feed.append(self.outputs[bucket_id][l])\n\n    outputs = session.run(output_feed, input_feed)\n    if not forward_only:\n      return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n    else:\n      return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\n\n  def get_batch(self, data, bucket_id):\n\n    encoder_size, decoder_size = self.buckets[bucket_id]\n    encoder_inputs, decoder_inputs = [], []\n\n\n    for _ in xrange(self.batch_size):\n      encoder_input, decoder_input = random.choice(data[bucket_id])\n\n\n      encoder_pad = [data_utils.PAD_ID] * (encoder_size - len(encoder_input))\n      encoder_inputs.append(list(reversed(encoder_input + encoder_pad)))\n\n\n      decoder_pad_size = decoder_size - len(decoder_input) - 1\n      decoder_inputs.append([data_utils.GO_ID] + decoder_input +\n                            [data_utils.PAD_ID] * decoder_pad_size)\n\n\n    batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], []\n\n\n    for length_idx in xrange(encoder_size):\n      batch_encoder_inputs.append(\n          np.array([encoder_inputs[batch_idx][length_idx]\n                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))\n\n\n    for length_idx in xrange(decoder_size):\n      batch_decoder_inputs.append(\n          np.array([decoder_inputs[batch_idx][length_idx]\n                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))\n\n\n      batch_weight = np.ones(self.batch_size, dtype=np.float32)\n      for batch_idx in xrange(self.batch_size):\n        if length_idx < decoder_size - 1:\n          target = decoder_inputs[batch_idx][length_idx + 1]\n        if length_idx == decoder_size - 1 or target == data_utils.PAD_ID:\n          batch_weight[batch_idx] = 0.0\n      batch_weights.append(batch_weight)\n    return batch_encoder_inputs, batch_decoder_inputs, batch_weights", "body": "Now I want to change seq2seq to distributed mode used SyncReplicasOptimizerV2. I've been trying for a few days\uff0cbut still can't work out. this is my code,one file is seq2seq_train.py,on file is seq2seq_model.py\r\nI try to run in 1 ps and 2 worker\r\n\r\nthe error is:\r\nTraceback (most recent call last):\r\n  File \"/home/test/replicas_seq2seq_v4/seq2seq_train.py\", line 188, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"/home/test/replicas_seq2seq_v4/seq2seq_train.py\", line 82, in main\r\n    task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)\r\n  File \"/home/test/replicas_seq2seq_v4/seq2seq_model.py\", line 221, in __init__\r\n    self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 720, in prepare_or_wait_for_session\r\n    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 251, in prepare_session\r\n    self._local_init_op, msg))\r\nRuntimeError: Init operations did not make model ready.  Init op: init, init fn: None, local_init_op: name: \"sync_replicas_3/group_deps\"\r\nop: \"NoOp\"\r\ninput: \"^sync_replicas_3/group_deps/NoOp\"\r\ninput: \"^sync_replicas_3/group_deps/NoOp_1\"\r\ninput: \"^sync_replicas_3/group_deps/NoOp_2\"\r\ndevice: \"/job:worker/task:0\"\r\n, error: Variables not initialized: sync_rep_local_step, sync_rep_local_step_1, sync_rep_local_step_2\r\n\r\nps:\r\n python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=ps --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000\r\n\r\nworker1:\r\n python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000\r\n\r\nworker2:\r\n python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=1 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000\r\n\r\n\r\n\r\nseq2seq_train.py\r\n\r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tempfile\r\nimport math\r\nimport os\r\nimport random\r\nimport sys\r\nimport time\r\nimport json\r\n\r\nimport numpy as np\r\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.models.rnn.translate import data_utils\r\nimport seq2seq_model\r\n\r\ntf.app.flags.DEFINE_string(\"ps_hosts\", \"\",\r\n                           \"Comma-separated list of hostname:port pairs\")\r\ntf.app.flags.DEFINE_string(\"worker_hosts\", \"\",\r\n                           \"Comma-separated list of hostname:port pairs\")\r\n\r\ntf.app.flags.DEFINE_string(\"job_name\", \"\", \"One of 'ps', 'worker'\")\r\ntf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\r\n\r\ntf.app.flags.DEFINE_float(\"learning_rate\", 0.5, \"Learning rate.\")\r\ntf.app.flags.DEFINE_float(\"learning_rate_decay_factor\", 0.99,\r\n                          \"Learning rate decays by this much.\")\r\ntf.app.flags.DEFINE_float(\"max_gradient_norm\", 5.0,\r\n                          \"Clip gradients to this norm.\")\r\ntf.app.flags.DEFINE_integer(\"batch_size\", 64,\r\n                            \"Batch size to use during training.\")\r\ntf.app.flags.DEFINE_integer(\"size\", 1024, \"Size of each model layer.\")\r\ntf.app.flags.DEFINE_integer(\"num_layers\", 3, \"Number of layers in the model.\")\r\ntf.app.flags.DEFINE_integer(\"en_vocab_size\", 40000, \"English vocabulary size.\")\r\ntf.app.flags.DEFINE_integer(\"fr_vocab_size\", 40000, \"French vocabulary size.\")\r\ntf.app.flags.DEFINE_string(\"data_dir\", \"/tmp/data\", \"Data directory\")\r\ntf.app.flags.DEFINE_string(\"train_dir\", \"/tmp\", \"Training directory.\")\r\ntf.app.flags.DEFINE_integer(\"max_train_data_size\", 0,\r\n                            \"Limit on the size of training data (0: no limit).\")\r\ntf.app.flags.DEFINE_integer(\"steps_per_checkpoint\", 200,\r\n                            \"How many training steps to do per checkpoint.\")\r\ntf.app.flags.DEFINE_boolean(\"decode\", False,\r\n                            \"Set to True for interactive decoding.\")\r\ntf.app.flags.DEFINE_boolean(\"self_test\", False,\r\n                            \"Run a self-test if this is set to True.\")\r\n\r\nFLAGS = tf.app.flags.FLAGS\r\n\r\n_buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]\r\n\r\ndef main(_):\r\n  if FLAGS.job_name is None or FLAGS.job_name == \"\":\r\n    raise ValueError(\"Must specify an explicit `job_name`\")\r\n  if FLAGS.task_index is None or FLAGS.task_index ==\"\":\r\n    raise ValueError(\"Must specify an explicit `task_index`\")\r\n\r\n\r\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\r\n  worker_hosts = FLAGS.worker_hosts.split(\",\")\r\n\r\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\r\n\r\n  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\r\n  num_workers = len(worker_hosts)\r\n\r\n  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\r\n  if FLAGS.job_name == \"ps\":\r\n    server.join()\r\n    return\r\n  is_chief = (FLAGS.task_index == 0)\r\n  model = seq2seq_model.Seq2SeqModel(server, FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,\r\n      FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\r\n      FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,num_workers = num_workers, \r\n      task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)\r\n  step_time, loss = 0.0, 0.0\r\n  current_step = 0\r\n  previous_losses = []\r\n\r\n  print(\"query -> title:\")\r\n  en_train = FLAGS.data_dir + \"/giga-fren.release2.ids40000.en\"\r\n  fr_train = FLAGS.data_dir + \"/giga-fren.release2.ids40000.fr\"\r\n  en_dev = FLAGS.data_dir + \"/newstest2013.ids40000.en\"\r\n  fr_dev = FLAGS.data_dir + \"/newstest2013.ids40000.fr\"\r\n\r\n  print (\"Reading development and training data (limit: %d).\" % FLAGS.max_train_data_size)\r\n  dev_set = read_data(en_dev, fr_dev)\r\n  train_set = read_train_data(en_train, fr_train, num_workers, FLAGS.max_train_data_size)\r\n  train_bucket_sizes = [len(train_set[b]) for b in xrange(len(_buckets))]\r\n  train_total_size = float(sum(train_bucket_sizes))\r\n\r\n  train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size for i in xrange(len(train_bucket_sizes))]\r\n  print(\"finish to load data\")\r\n  sess = model.session\r\n  while True:\r\n    random_number_01 = np.random.random_sample()\r\n    bucket_id = min([i for i in xrange(len(train_buckets_scale)) if train_buckets_scale[i] > random_number_01])\r\n\r\n    start_time = time.time()\r\n    encoder_inputs, decoder_inputs, target_weights = model.get_batch(train_set, bucket_id)\r\n    _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, False)\r\n    step_time += (time.time() - start_time) / FLAGS.steps_per_checkpoint\r\n    step_time_now = (time.time() - start_time)\r\n    loss += step_loss / FLAGS.steps_per_checkpoint\r\n    step_loss_now = step_loss\r\n    current_step += 1\r\n    print(\"step: %d\" % current_step);\r\n\r\n    if (True):\r\n      perplexity = math.exp(step_loss) if step_loss < 300 else float('inf')\r\n      print (\"global step %d learning rate %.4f step-time %.2f perplexity \"\r\n             \"%.2f\" % (model.global_step.eval(sess), model.learning_rate.eval(sess), step_time_now, perplexity))\r\n\r\n      previous_losses.append(step_loss)\r\n\r\n      checkpoint_path = os.path.join(train_dir, \"translate.ckpt\")\r\n      model.saver.save(sess, checkpoint_path, global_step=model.global_step)\r\n      if (current_step %  FLAGS.steps_per_checkpoint == 0):\r\n        for bucket_id in xrange(len(_buckets)):\r\n          if len(dev_set[bucket_id]) == 0:\r\n            print(\"  eval: empty bucket %d\" % (bucket_id))\r\n            continue\r\n          encoder_inputs, decoder_inputs, target_weights = model.get_batch(dev_set, bucket_id)\r\n          _, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, True)\r\n          eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')\r\n          print(\"  eval: bucket %d perplexity %.2f\" % (bucket_id, eval_ppx))\r\n        step_time, loss = 0.0, 0.0\r\n      sys.stdout.flush()\r\n\r\n\r\ndef read_train_data(source_path, target_path, num_workers, max_size=None):\r\n  data_set = [[] for _ in _buckets]\r\n  with tf.gfile.GFile(source_path, mode=\"r\") as source_file:\r\n    with tf.gfile.GFile(target_path, mode=\"r\") as target_file:\r\n      source, target = source_file.readline(), target_file.readline()\r\n      counter = 0\r\n      while source and target and (not max_size or counter < max_size):\r\n        counter += 1\r\n        if counter % 1000000 == 0:\r\n          print(\"  reading data line %d\" % counter)\r\n          sys.stdout.flush()\r\n        source_ids = [int(x) for x in source.split()]\r\n        target_ids = [int(x) for x in target.split()]\r\n        target_ids.append(data_utils.EOS_ID)\r\n        if (counter % num_workers == 0):\r\n          for bucket_id, (source_size, target_size) in enumerate(_buckets):\r\n            if len(source_ids) < source_size and len(target_ids) < target_size:\r\n              data_set[bucket_id].append([source_ids, target_ids])\r\n              break\r\n        source, target = source_file.readline(), target_file.readline()\r\n  return data_set\r\n\r\ndef read_data(source_path, target_path, max_size=None):\r\n  data_set = [[] for _ in _buckets]\r\n  with tf.gfile.GFile(source_path, mode=\"r\") as source_file:\r\n    with tf.gfile.GFile(target_path, mode=\"r\") as target_file:\r\n      source, target = source_file.readline(), target_file.readline()\r\n      counter = 0\r\n      while source and target and (not max_size or counter < max_size):\r\n        counter += 1\r\n        if counter % 100000 == 0:\r\n          print(\"  reading data line %d\" % counter)\r\n          sys.stdout.flush()\r\n        source_ids = [int(x) for x in source.split()]\r\n        target_ids = [int(x) for x in target.split()]\r\n        target_ids.append(data_utils.EOS_ID)\r\n        for bucket_id, (source_size, target_size) in enumerate(_buckets):\r\n          if len(source_ids) < source_size and len(target_ids) < target_size:\r\n            data_set[bucket_id].append([source_ids, target_ids])\r\n            break\r\n        source, target = source_file.readline(), target_file.readline()\r\n  return data_set\r\n\r\nif __name__ == \"__main__\":\r\n      tf.app.run()\r\n```\r\n\r\nseq2seq_model.py\r\n\r\n\r\n\r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport random\r\n\r\nimport numpy as np\r\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.models.rnn.translate import data_utils\r\n\r\n\r\nclass Seq2SeqModel(object):\r\n\r\n  def __init__(self,\r\n               server,\r\n               source_vocab_size,\r\n               target_vocab_size,\r\n               buckets,\r\n               size,\r\n               num_layers,\r\n               max_gradient_norm,\r\n               batch_size,\r\n               learning_rate,\r\n               learning_rate_decay_factor,\r\n               num_workers=2, \r\n               task_index=0,\r\n               replicas_to_aggregate=2,\r\n               use_lstm=False,\r\n               num_samples=512,\r\n               forward_only=False,\r\n               dtype=tf.float32):\r\n\r\n    self.graph = tf.Graph()\r\n    self.server = server\r\n    self.source_vocab_size = source_vocab_size\r\n    self.target_vocab_size = target_vocab_size\r\n    self.buckets = buckets\r\n    self.batch_size = batch_size\r\n    self.num_workers = num_workers \r\n    self.task_index = task_index\r\n    self.is_chief = (task_index == 0)\r\n    self.num_workers = num_workers\r\n    self.replicas_to_aggregate = replicas_to_aggregate\r\n\r\n    with self.graph.as_default():\r\n      with tf.device(\"/job:ps/task:0\"): \r\n      #with tf.device(\"/cpu:0\"): \r\n        self.global_step = tf.Variable(0, trainable=False)\r\n        self.learning_rate = tf.Variable(\r\n            float(learning_rate), trainable=False, dtype=dtype)\r\n\r\n      output_projection = None\r\n      softmax_loss_function = None\r\n      if num_samples > 0 and num_samples < self.target_vocab_size:\r\n        with tf.device(\"/job:ps/task:0\"): \r\n          w_t = tf.get_variable(\"proj_w\", [self.target_vocab_size, size], dtype=dtype)\r\n          w = tf.transpose(w_t)\r\n          b = tf.get_variable(\"proj_b\", [self.target_vocab_size], dtype=dtype)\r\n        output_projection = (w, b)\r\n  \r\n        def sampled_loss(inputs, labels):\r\n          with tf.device(\"/job:worker/task:\"+str(self.task_index)):\r\n            labels = tf.reshape(labels, [-1, 1])\r\n            local_w_t = tf.cast(w_t, tf.float32)\r\n            local_b = tf.cast(b, tf.float32)\r\n            local_inputs = tf.cast(inputs, tf.float32)\r\n            return tf.cast(\r\n                tf.nn.sampled_softmax_loss(local_w_t, local_b, local_inputs, labels,\r\n                                           num_samples, self.target_vocab_size),\r\n                dtype)\r\n        softmax_loss_function = sampled_loss\r\n  \r\n      with tf.device(\"/job:worker/task:\"+str(self.task_index)):\r\n        single_cell = tf.nn.rnn_cell.GRUCell(size)\r\n        if use_lstm:\r\n          single_cell = tf.nn.rnn_cell.BasicLSTMCell(size)\r\n        cell = single_cell\r\n        if num_layers > 1:\r\n          cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\r\n  \r\n      def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\r\n        with tf.device(\"/job:worker/task:\"+str(self.task_index)):\r\n          return tf.nn.seq2seq.embedding_attention_seq2seq(\r\n              encoder_inputs,\r\n              decoder_inputs,\r\n              cell,\r\n              num_encoder_symbols=source_vocab_size,\r\n              num_decoder_symbols=target_vocab_size,\r\n              embedding_size=size,\r\n              output_projection=output_projection,\r\n              feed_previous=do_decode,\r\n              dtype=dtype)\r\n\r\n      with tf.device(\"/job:worker/task:\"+str(self.task_index)):\r\n        self.encoder_inputs = []\r\n        self.decoder_inputs = []\r\n        self.target_weights = []\r\n        for i in xrange(buckets[-1][0]):  # Last bucket is the biggest one.\r\n          self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\r\n                                                    name=\"encoder{0}\".format(i)))\r\n        for i in xrange(buckets[-1][1] + 1):\r\n          self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\r\n                                                    name=\"decoder{0}\".format(i)))\r\n          self.target_weights.append(tf.placeholder(dtype, shape=[None],\r\n                                                    name=\"weight{0}\".format(i)))\r\n  \r\n        targets = [self.decoder_inputs[i + 1]\r\n                   for i in xrange(len(self.decoder_inputs) - 1)]\r\n        if forward_only:\r\n          self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\r\n              self.encoder_inputs, self.decoder_inputs, targets,\r\n              self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),\r\n              softmax_loss_function=softmax_loss_function)\r\n          if output_projection is not None:\r\n            for b in xrange(len(buckets)):\r\n              self.outputs[b] = [\r\n                  tf.matmul(output, output_projection[0]) + output_projection[1]\r\n                  for output in self.outputs[b]\r\n              ]\r\n        else:\r\n          self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\r\n              self.encoder_inputs, self.decoder_inputs, targets,\r\n              self.target_weights, buckets,\r\n              lambda x, y: seq2seq_f(x, y, False),\r\n              softmax_loss_function=softmax_loss_function)\r\n  \r\n      with tf.device(\"/job:worker/task:\"+str(self.task_index)):\r\n        params = tf.trainable_variables()\r\n        self.gradient_norms = []\r\n        self.updates = []\r\n        sgd_opt = tf.train.GradientDescentOptimizer(2.0)\r\n        sync_rep_opt = tf.train.SyncReplicasOptimizerV2(\r\n            sgd_opt, replicas_to_aggregate=replicas_to_aggregate,\r\n            total_num_replicas=num_workers)\r\n        for b in xrange(len(buckets)):\r\n          gradients = tf.gradients(self.losses[b], params)\r\n          clipped_gradients, norm = tf.clip_by_global_norm(gradients,\r\n                                                           max_gradient_norm)\r\n          self.gradient_norms.append(norm)\r\n          self.updates.append(sync_rep_opt.apply_gradients(\r\n              zip(clipped_gradients, params), global_step=self.global_step))\r\n\r\n        init_op = tf.global_variables_initializer()\r\n        local_init_op = sync_rep_opt.local_step_init_op\r\n        if self.is_chief:\r\n          local_init_op = sync_rep_opt.chief_init_op\r\n        ready_for_local_init_op = sync_rep_opt.ready_for_local_init_op\r\n\r\n        chief_queue_runner = sync_rep_opt.get_chief_queue_runner()\r\n        sync_init_op = sync_rep_opt.get_init_tokens_op(num_workers)\r\n\r\n    supervisor = tf.train.Supervisor(\r\n        graph=self.graph,\r\n        is_chief=self.is_chief,\r\n        recovery_wait_secs=1,\r\n        init_op=init_op,\r\n        local_init_op=local_init_op,\r\n        ready_for_local_init_op=ready_for_local_init_op)\r\n\r\n    sess_config = tf.ConfigProto(\r\n        allow_soft_placement=True,\r\n        log_device_placement=True,\r\n        device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % self.task_index])\r\n\r\n\r\n    self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)\r\n\r\n    if self.is_chief:\r\n      self.session.run(sync_init_op)\r\n      supervisor.StartQueueRunners(self.session, [chief_queue_runner])\r\n\r\n    if self.is_chief:\r\n      self.session.run(sync_init_op)\r\n      supervisor.StartQueueRunners(self.session, [chief_queue_runner])\r\n\r\n\r\n  def step(self, session, encoder_inputs, decoder_inputs, target_weights,\r\n           bucket_id, forward_only):\r\n\r\n    encoder_size, decoder_size = self.buckets[bucket_id]\r\n    if len(encoder_inputs) != encoder_size:\r\n      raise ValueError(\"Encoder length must be equal to the one in bucket,\"\r\n                       \" %d != %d.\" % (len(encoder_inputs), encoder_size))\r\n    if len(decoder_inputs) != decoder_size:\r\n      raise ValueError(\"Decoder length must be equal to the one in bucket,\"\r\n                       \" %d != %d.\" % (len(decoder_inputs), decoder_size))\r\n    if len(target_weights) != decoder_size:\r\n      raise ValueError(\"Weights length must be equal to the one in bucket,\"\r\n                       \" %d != %d.\" % (len(target_weights), decoder_size))\r\n\r\n\r\n    input_feed = {}\r\n    for l in xrange(encoder_size):\r\n      input_feed[self.encoder_inputs[l].name] = encoder_inputs[l]\r\n    for l in xrange(decoder_size):\r\n      input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]\r\n      input_feed[self.target_weights[l].name] = target_weights[l]\r\n\r\n\r\n    last_target = self.decoder_inputs[decoder_size].name\r\n    input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)\r\n\r\n\r\n    if not forward_only:\r\n      output_feed = [self.updates[bucket_id],  # Update Op that does SGD.\r\n                     self.gradient_norms[bucket_id],  # Gradient norm.\r\n                     self.losses[bucket_id]]  # Loss for this batch.\r\n    else:\r\n      output_feed = [self.losses[bucket_id]]  # Loss for this batch.\r\n      for l in xrange(decoder_size):  # Output logits.\r\n        output_feed.append(self.outputs[bucket_id][l])\r\n\r\n    outputs = session.run(output_feed, input_feed)\r\n    if not forward_only:\r\n      return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\r\n    else:\r\n      return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\r\n\r\n  def get_batch(self, data, bucket_id):\r\n\r\n    encoder_size, decoder_size = self.buckets[bucket_id]\r\n    encoder_inputs, decoder_inputs = [], []\r\n\r\n\r\n    for _ in xrange(self.batch_size):\r\n      encoder_input, decoder_input = random.choice(data[bucket_id])\r\n\r\n\r\n      encoder_pad = [data_utils.PAD_ID] * (encoder_size - len(encoder_input))\r\n      encoder_inputs.append(list(reversed(encoder_input + encoder_pad)))\r\n\r\n\r\n      decoder_pad_size = decoder_size - len(decoder_input) - 1\r\n      decoder_inputs.append([data_utils.GO_ID] + decoder_input +\r\n                            [data_utils.PAD_ID] * decoder_pad_size)\r\n\r\n\r\n    batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], []\r\n\r\n\r\n    for length_idx in xrange(encoder_size):\r\n      batch_encoder_inputs.append(\r\n          np.array([encoder_inputs[batch_idx][length_idx]\r\n                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))\r\n\r\n\r\n    for length_idx in xrange(decoder_size):\r\n      batch_decoder_inputs.append(\r\n          np.array([decoder_inputs[batch_idx][length_idx]\r\n                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))\r\n\r\n\r\n      batch_weight = np.ones(self.batch_size, dtype=np.float32)\r\n      for batch_idx in xrange(self.batch_size):\r\n        if length_idx < decoder_size - 1:\r\n          target = decoder_inputs[batch_idx][length_idx + 1]\r\n        if length_idx == decoder_size - 1 or target == data_utils.PAD_ID:\r\n          batch_weight[batch_idx] = 0.0\r\n      batch_weights.append(batch_weight)\r\n    return batch_encoder_inputs, batch_decoder_inputs, batch_weights\r\n```\r\n"}