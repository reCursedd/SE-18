{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/359320008", "html_url": "https://github.com/tensorflow/tensorflow/issues/16219#issuecomment-359320008", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16219", "id": 359320008, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTMyMDAwOA==", "user": {"login": "lllidan-yuandian", "id": 34954235, "node_id": "MDQ6VXNlcjM0OTU0MjM1", "avatar_url": "https://avatars2.githubusercontent.com/u/34954235?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lllidan-yuandian", "html_url": "https://github.com/lllidan-yuandian", "followers_url": "https://api.github.com/users/lllidan-yuandian/followers", "following_url": "https://api.github.com/users/lllidan-yuandian/following{/other_user}", "gists_url": "https://api.github.com/users/lllidan-yuandian/gists{/gist_id}", "starred_url": "https://api.github.com/users/lllidan-yuandian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lllidan-yuandian/subscriptions", "organizations_url": "https://api.github.com/users/lllidan-yuandian/orgs", "repos_url": "https://api.github.com/users/lllidan-yuandian/repos", "events_url": "https://api.github.com/users/lllidan-yuandian/events{/privacy}", "received_events_url": "https://api.github.com/users/lllidan-yuandian/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-22T04:08:29Z", "updated_at": "2018-01-22T04:08:29Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a> Thank you very much! This is the code of demo.cpp :</p>\n<p>#include \"tensorflow/contrib/lite/kernels/register.h\"<br>\n#include \"tensorflow/contrib/lite/model.h\"<br>\n#include \"tensorflow/contrib/lite/string_util.h\"<br>\n#include \"tensorflow/contrib/lite/tools/mutable_op_resolver.h\"</p>\n<p>using namespace std;</p>\n<p>int main() {</p>\n<pre><code>const string graph_file=\"\";\nstd::unique_ptr&lt;tflite::FlatBufferModel&gt; model(\n        tflite::FlatBufferModel::BuildFromFile(graph_file.c_str())\n);\ntflite::ops::builtin::BuiltinOpResolver resolver;\nstd::unique_ptr&lt;tflite::Interpreter&gt; interpreter;\ntflite::InterpreterBuilder(*model, resolver)(&amp;interpreter);\n</code></pre>\n<p>// Resize input tensors, if desired.<br>\ninterpreter-&gt;AllocateTensors();<br>\nfloat* input = interpreter-&gt;typed_input_tensor(0);<br>\n// Fill <code>input</code>.<br>\ninterpreter-&gt;Invoke();<br>\n//  float* output = interpreter-&gt;type_output_tensor(0);<br>\n}</p>", "body_text": "@aselle Thank you very much! This is the code of demo.cpp :\n#include \"tensorflow/contrib/lite/kernels/register.h\"\n#include \"tensorflow/contrib/lite/model.h\"\n#include \"tensorflow/contrib/lite/string_util.h\"\n#include \"tensorflow/contrib/lite/tools/mutable_op_resolver.h\"\nusing namespace std;\nint main() {\nconst string graph_file=\"\";\nstd::unique_ptr<tflite::FlatBufferModel> model(\n        tflite::FlatBufferModel::BuildFromFile(graph_file.c_str())\n);\ntflite::ops::builtin::BuiltinOpResolver resolver;\nstd::unique_ptr<tflite::Interpreter> interpreter;\ntflite::InterpreterBuilder(*model, resolver)(&interpreter);\n\n// Resize input tensors, if desired.\ninterpreter->AllocateTensors();\nfloat* input = interpreter->typed_input_tensor(0);\n// Fill input.\ninterpreter->Invoke();\n//  float* output = interpreter->type_output_tensor(0);\n}", "body": "@aselle Thank you very much! This is the code of demo.cpp :\r\n\r\n#include \"tensorflow/contrib/lite/kernels/register.h\"\r\n#include \"tensorflow/contrib/lite/model.h\"\r\n#include \"tensorflow/contrib/lite/string_util.h\"\r\n#include \"tensorflow/contrib/lite/tools/mutable_op_resolver.h\"\r\n\r\nusing namespace std;\r\n\r\nint main() {\r\n\r\n    const string graph_file=\"\";\r\n    std::unique_ptr<tflite::FlatBufferModel> model(\r\n            tflite::FlatBufferModel::BuildFromFile(graph_file.c_str())\r\n    );\r\n    tflite::ops::builtin::BuiltinOpResolver resolver;\r\n    std::unique_ptr<tflite::Interpreter> interpreter;\r\n    tflite::InterpreterBuilder(*model, resolver)(&interpreter);\r\n// Resize input tensors, if desired.\r\n    interpreter->AllocateTensors();\r\n    float* input = interpreter->typed_input_tensor<float>(0);\r\n// Fill `input`.\r\n    interpreter->Invoke();\r\n//  float* output = interpreter->type_output_tensor<float>(0);\r\n}"}