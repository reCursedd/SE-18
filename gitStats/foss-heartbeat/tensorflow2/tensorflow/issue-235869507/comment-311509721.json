{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/311509721", "html_url": "https://github.com/tensorflow/tensorflow/pull/10700#issuecomment-311509721", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10700", "id": 311509721, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTUwOTcyMQ==", "user": {"login": "junshi15", "id": 12075848, "node_id": "MDQ6VXNlcjEyMDc1ODQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/12075848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/junshi15", "html_url": "https://github.com/junshi15", "followers_url": "https://api.github.com/users/junshi15/followers", "following_url": "https://api.github.com/users/junshi15/following{/other_user}", "gists_url": "https://api.github.com/users/junshi15/gists{/gist_id}", "starred_url": "https://api.github.com/users/junshi15/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/junshi15/subscriptions", "organizations_url": "https://api.github.com/users/junshi15/orgs", "repos_url": "https://api.github.com/users/junshi15/repos", "events_url": "https://api.github.com/users/junshi15/events{/privacy}", "received_events_url": "https://api.github.com/users/junshi15/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-27T23:00:39Z", "updated_at": "2017-06-27T23:00:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>There is one buffer per tensor, allocated in CPU memory.</p>\n<p>The original assumption was that tensor sizes (except string tensors) did not change over the course of training. It was valid for the early models, e.g. InceptionV3, VGG16, etc. As new models appear, the assumption is not valid anymore. I think we should let buffer sizes vary.</p>\n<p>We could have some kind of policy to reclaim the memory if the tensor sizes have been smaller than the buffer size for some period of time. Note the buffers are pinned and registered for RDMA. Frequent allocation and registration can slow down things. The patch is good for now due to its simplicity.</p>", "body_text": "There is one buffer per tensor, allocated in CPU memory.\nThe original assumption was that tensor sizes (except string tensors) did not change over the course of training. It was valid for the early models, e.g. InceptionV3, VGG16, etc. As new models appear, the assumption is not valid anymore. I think we should let buffer sizes vary.\nWe could have some kind of policy to reclaim the memory if the tensor sizes have been smaller than the buffer size for some period of time. Note the buffers are pinned and registered for RDMA. Frequent allocation and registration can slow down things. The patch is good for now due to its simplicity.", "body": "There is one buffer per tensor, allocated in CPU memory. \r\n\r\nThe original assumption was that tensor sizes (except string tensors) did not change over the course of training. It was valid for the early models, e.g. InceptionV3, VGG16, etc. As new models appear, the assumption is not valid anymore. I think we should let buffer sizes vary. \r\n\r\nWe could have some kind of policy to reclaim the memory if the tensor sizes have been smaller than the buffer size for some period of time. Note the buffers are pinned and registered for RDMA. Frequent allocation and registration can slow down things. The patch is good for now due to its simplicity."}