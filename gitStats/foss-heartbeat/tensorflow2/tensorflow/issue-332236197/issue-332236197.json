{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20004", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20004/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20004/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20004/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/20004", "id": 332236197, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk0NzY3NDI5", "number": 20004, "title": "New loss function for Neural Networks based on 2018 paper from Cornell ", "user": {"login": "paulobuchsbaum", "id": 30529574, "node_id": "MDQ6VXNlcjMwNTI5NTc0", "avatar_url": "https://avatars2.githubusercontent.com/u/30529574?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulobuchsbaum", "html_url": "https://github.com/paulobuchsbaum", "followers_url": "https://api.github.com/users/paulobuchsbaum/followers", "following_url": "https://api.github.com/users/paulobuchsbaum/following{/other_user}", "gists_url": "https://api.github.com/users/paulobuchsbaum/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulobuchsbaum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulobuchsbaum/subscriptions", "organizations_url": "https://api.github.com/users/paulobuchsbaum/orgs", "repos_url": "https://api.github.com/users/paulobuchsbaum/repos", "events_url": "https://api.github.com/users/paulobuchsbaum/events{/privacy}", "received_events_url": "https://api.github.com/users/paulobuchsbaum/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 390482148, "node_id": "MDU6TGFiZWwzOTA0ODIxNDg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20review", "name": "awaiting review", "color": "fef2c0", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-06-14T03:06:10Z", "updated_at": "2018-08-14T00:24:59Z", "closed_at": "2018-08-14T00:24:59Z", "author_association": "NONE", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20004", "html_url": "https://github.com/tensorflow/tensorflow/pull/20004", "diff_url": "https://github.com/tensorflow/tensorflow/pull/20004.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/20004.patch"}, "body_html": "<p>Zhilu Zhang and Mert R. Sabuncu of Cornell University (New York, United States) has submitted on May 20, 2018 a <a href=\"https://arxiv.org/abs/1805.07836\" rel=\"nofollow\">paper</a>  proposing a new error function for <code>Neural Networks</code> (including Deep Neural Networks) aimed at classification with <code>softmax</code> function in the output layer,  specially in the case of noisy labels.</p>\n<p>This new loss function has joined characteristics of <code>mean absolute error (MAE)</code> with <code>cross entropy loss</code>.</p>\n<p>According to the tests carried out, it generates a significant improvement in problems of binary classification or multiclassification with noisy labels, compared to cross entropy loss or mean absolute error (MAE)</p>\n<p>By e-mail, we exchanged ideas for some time, where I has clarified some points of this paper.</p>\n<p>Because of the promising results obtained, I've agreed with them that I would incorporate this new function into the repertoire of loss functions in <code>TensorFlow</code> to make it available to the community.</p>\n<p>So I've read the <code>contribution guidelines</code> and write Python code for new  function (that I've called  <code>gen_crossentropy</code>) and also write the testing code, following the standards of another loss error functions.</p>\n<p>In my local repository, the test have run 100% well.</p>\n<p>It's my first collaboration with this fantastic project, so any observations or guidance will be welcome.</p>", "body_text": "Zhilu Zhang and Mert R. Sabuncu of Cornell University (New York, United States) has submitted on May 20, 2018 a paper  proposing a new error function for Neural Networks (including Deep Neural Networks) aimed at classification with softmax function in the output layer,  specially in the case of noisy labels.\nThis new loss function has joined characteristics of mean absolute error (MAE) with cross entropy loss.\nAccording to the tests carried out, it generates a significant improvement in problems of binary classification or multiclassification with noisy labels, compared to cross entropy loss or mean absolute error (MAE)\nBy e-mail, we exchanged ideas for some time, where I has clarified some points of this paper.\nBecause of the promising results obtained, I've agreed with them that I would incorporate this new function into the repertoire of loss functions in TensorFlow to make it available to the community.\nSo I've read the contribution guidelines and write Python code for new  function (that I've called  gen_crossentropy) and also write the testing code, following the standards of another loss error functions.\nIn my local repository, the test have run 100% well.\nIt's my first collaboration with this fantastic project, so any observations or guidance will be welcome.", "body": "Zhilu Zhang and Mert R. Sabuncu of Cornell University (New York, United States) has submitted on May 20, 2018 a [paper](https://arxiv.org/abs/1805.07836)  proposing a new error function for `Neural Networks` (including Deep Neural Networks) aimed at classification with `softmax` function in the output layer,  specially in the case of noisy labels. \r\n\r\nThis new loss function has joined characteristics of `mean absolute error (MAE)` with `cross entropy loss`. \r\n\r\nAccording to the tests carried out, it generates a significant improvement in problems of binary classification or multiclassification with noisy labels, compared to cross entropy loss or mean absolute error (MAE) \r\n\r\nBy e-mail, we exchanged ideas for some time, where I has clarified some points of this paper. \r\n\r\nBecause of the promising results obtained, I've agreed with them that I would incorporate this new function into the repertoire of loss functions in `TensorFlow` to make it available to the community.\r\n\r\nSo I've read the `contribution guidelines` and write Python code for new  function (that I've called  `gen_crossentropy`) and also write the testing code, following the standards of another loss error functions. \r\n\r\nIn my local repository, the test have run 100% well. \r\n\r\nIt's my first collaboration with this fantastic project, so any observations or guidance will be welcome."}