{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/211433463", "pull_request_review_id": 147852742, "id": 211433463, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMTQzMzQ2Mw==", "diff_hunk": "@@ -772,33 +775,54 @@ std::pair<int, tensorflow::Allocator*> GetDeviceAndAllocator(\n     const ConversionParams& params, const EngineInfo& engine) {\n   int cuda_device_id = -1;\n   tensorflow::Allocator* dev_allocator = nullptr;\n-  if (params.cluster) {\n-    std::vector<tensorflow::Device*> devices;\n-    if (!engine.device.empty() && params.cluster->GetDeviceSet()) {\n-      DeviceNameUtils::ParsedName parsed_name;\n-      if (DeviceNameUtils::ParseFullName(engine.device, &parsed_name) &&\n-          parsed_name.has_id) {\n-        params.cluster->GetDeviceSet()->FindMatchingDevices(parsed_name,\n-                                                            &devices);\n+  if (params.cluster == nullptr || params.cluster->GetDeviceSet() == nullptr ||\n+      engine.device.empty()) {\n+    // If device is not set, use the first found GPU device for the conversion.\n+    for (int tf_gpu_id_value = 0; tf_gpu_id_value < 100; ++tf_gpu_id_value) {\n+      TfGpuId tf_gpu_id(tf_gpu_id_value);\n+      CudaGpuId cuda_gpu_id;\n+      Status s = GpuIdManager::TfToCudaGpuId(tf_gpu_id, &cuda_gpu_id);\n+      if (s.ok()) {\n+        VLOG(1) << \"Found TF GPU \" << tf_gpu_id.value() << \" at cuda device \"\n+                << cuda_gpu_id.value();\n+        cuda_device_id = cuda_gpu_id.value();\n+        GPUOptions gpu_options;\n+        // If the TF to Cuda gpu id mapping exist, the device and corresponding\n+        // allocator must have been initialized already, so the\n+        // GetGPUAllocator() call won't create a new allocator.\n+        dev_allocator = GPUProcessState::singleton()->GetGPUAllocator(\n+            gpu_options, tf_gpu_id, 1);\n+        break;\n       }\n+      VLOG(2) << \"TF GPU with id \" << tf_gpu_id_value << \" do not exist \" << s;\n     }\n-    if (!devices.empty()) {\n-      if (devices.size() > 1) {\n-        string msg = \"Found multiple matching devices using name '\";\n-        StrAppend(&msg, engine.device, \"': \");\n-        for (auto d : devices) StrAppend(&msg, d->name(), \", \");\n-        StrAppend(&msg, \". Will get the allocator from first one.\");\n-        LOG(WARNING) << msg;\n-      }\n-      tensorflow::AllocatorAttributes alloc_attr;\n-      cuda_device_id = devices[0]->tensorflow_gpu_device_info()->gpu_id;\n-      dev_allocator = devices[0]->GetAllocator(alloc_attr);\n-      VLOG(1) << \"Using allocator \" << dev_allocator->Name()\n-              << \" and cuda_device_id \" << cuda_device_id;\n-    } else {\n-      LOG(WARNING) << \"Cluster is set but device '\" << engine.device\n-                   << \"' is not found in the cluster\";\n+    return std::make_pair(cuda_device_id, dev_allocator);\n+  }\n+\n+  // Use the device requested by the engine.\n+  auto device_set = params.cluster->GetDeviceSet();\n+  std::vector<tensorflow::Device*> devices;\n+  DeviceNameUtils::ParsedName parsed_name;\n+  if (DeviceNameUtils::ParseFullName(engine.device, &parsed_name) &&\n+      parsed_name.has_id) {\n+    device_set->FindMatchingDevices(parsed_name, &devices);\n+  }\n+  if (!devices.empty()) {\n+    if (devices.size() > 1) {\n+      string msg = \"Found multiple matching devices using name '\";\n+      StrAppend(&msg, engine.device, \"': \");\n+      for (auto d : devices) StrAppend(&msg, d->name(), \", \");\n+      StrAppend(&msg, \". Will get the allocator from first one.\");\n+      LOG(WARNING) << msg;\n     }\n+    tensorflow::AllocatorAttributes alloc_attr;\n+    cuda_device_id = devices[0]->tensorflow_gpu_device_info()->gpu_id;\n+    dev_allocator = devices[0]->GetAllocator(alloc_attr);\n+    VLOG(1) << \"Using allocator \" << dev_allocator->Name()\n+            << \" and cuda_device_id \" << cuda_device_id;\n+  } else {\n+    LOG(WARNING) << \"Cluster is set but device '\" << engine.device\n+                 << \"' is not found in the cluster\";", "path": "tensorflow/contrib/tensorrt/convert/convert_graph.cc", "position": 86, "original_position": 85, "commit_id": "4684421d9aa3e63dc943074025ffdc89df1a1980", "original_commit_id": "0b31ebb51bcdd4b0675d3f2166f316d0f22266b3", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "In that case `cuda_device_id` remains -1 and `dev_allocator` is `nullptr`.", "created_at": "2018-08-20T23:01:02Z", "updated_at": "2018-08-20T23:04:43Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21508#discussion_r211433463", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21508", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/211433463"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21508#discussion_r211433463"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21508"}}, "body_html": "<p>In that case <code>cuda_device_id</code> remains -1 and <code>dev_allocator</code> is <code>nullptr</code>.</p>", "body_text": "In that case cuda_device_id remains -1 and dev_allocator is nullptr.", "in_reply_to_id": 211131832}