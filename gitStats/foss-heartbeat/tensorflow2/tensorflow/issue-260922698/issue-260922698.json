{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13338", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13338/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13338/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13338/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13338", "id": 260922698, "node_id": "MDU6SXNzdWUyNjA5MjI2OTg=", "number": 13338, "title": "Feature request: add tf.layers.Group to group multiple layers under one name", "user": {"login": "bodokaiser", "id": 1780466, "node_id": "MDQ6VXNlcjE3ODA0NjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1780466?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bodokaiser", "html_url": "https://github.com/bodokaiser", "followers_url": "https://api.github.com/users/bodokaiser/followers", "following_url": "https://api.github.com/users/bodokaiser/following{/other_user}", "gists_url": "https://api.github.com/users/bodokaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/bodokaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bodokaiser/subscriptions", "organizations_url": "https://api.github.com/users/bodokaiser/orgs", "repos_url": "https://api.github.com/users/bodokaiser/repos", "events_url": "https://api.github.com/users/bodokaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/bodokaiser/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-09-27T10:22:51Z", "updated_at": "2018-01-13T20:44:11Z", "closed_at": "2018-01-13T20:44:11Z", "author_association": "NONE", "body_html": "<p>Example usage (relevant for networks with skip connection i.e. u-net):</p>\n<div class=\"highlight highlight-source-python\"><pre>encoder1 <span class=\"pl-k\">=</span> tf.layers.Group([\n  tf.layers.Conv2d(<span class=\"pl-c1\">...</span>),\n  tf.layers.BatchNorm(),\n  ActivationLayer(),\n], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder1<span class=\"pl-pds\">'</span></span>)\n\nencoder2 <span class=\"pl-k\">=</span> tf.layers.Group([\n  tf.layers.Conv2d(<span class=\"pl-c1\">...</span>),\n  tf.layers.BatchNorm(),\n  ActivationLayer(),\n], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder1<span class=\"pl-pds\">'</span></span>)\n\ninputs <span class=\"pl-k\">=</span> outputs <span class=\"pl-k\">=</span> tf.layers.Input(<span class=\"pl-v\">tensor</span><span class=\"pl-k\">=</span>x)\n\n<span class=\"pl-k\">for</span> enc <span class=\"pl-k\">in</span> [encoder1, encoder2]:\n  outputs <span class=\"pl-k\">=</span> enc(outputs)\n\nencoders <span class=\"pl-k\">=</span> tf.layers.Network(inputs, outputs)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> same for decoders</span>\n<span class=\"pl-k\">for</span> i, dec <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(decoders):\n  outputs <span class=\"pl-k\">=</span> dec(tf.concat([encoders.get_layer(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-s\">encoder</span><span class=\"pl-c1\">{</span>i<span class=\"pl-c1\">}</span><span class=\"pl-pds\">'</span>).output, outputs], <span class=\"pl-c1\">3</span>))</pre></div>\n<p>Currently you could either</p>\n<ul>\n<li>use <code>network.get_output_at()</code> however this requires to track node indices or parse <code>network.layers</code> if encoders are not symmetric (i.e. some encoder have no batch norm / dropout)</li>\n<li>inherit from <code>tf.layers.Layer</code> however documentation is not clear on how to \"forward\" variables for example</li>\n</ul>", "body_text": "Example usage (relevant for networks with skip connection i.e. u-net):\nencoder1 = tf.layers.Group([\n  tf.layers.Conv2d(...),\n  tf.layers.BatchNorm(),\n  ActivationLayer(),\n], name='encoder1')\n\nencoder2 = tf.layers.Group([\n  tf.layers.Conv2d(...),\n  tf.layers.BatchNorm(),\n  ActivationLayer(),\n], name='encoder1')\n\ninputs = outputs = tf.layers.Input(tensor=x)\n\nfor enc in [encoder1, encoder2]:\n  outputs = enc(outputs)\n\nencoders = tf.layers.Network(inputs, outputs)\n\n# same for decoders\nfor i, dec in enumerate(decoders):\n  outputs = dec(tf.concat([encoders.get_layer(f'encoder{i}').output, outputs], 3))\nCurrently you could either\n\nuse network.get_output_at() however this requires to track node indices or parse network.layers if encoders are not symmetric (i.e. some encoder have no batch norm / dropout)\ninherit from tf.layers.Layer however documentation is not clear on how to \"forward\" variables for example", "body": "Example usage (relevant for networks with skip connection i.e. u-net):\r\n\r\n```python\r\nencoder1 = tf.layers.Group([\r\n  tf.layers.Conv2d(...),\r\n  tf.layers.BatchNorm(),\r\n  ActivationLayer(),\r\n], name='encoder1')\r\n\r\nencoder2 = tf.layers.Group([\r\n  tf.layers.Conv2d(...),\r\n  tf.layers.BatchNorm(),\r\n  ActivationLayer(),\r\n], name='encoder1')\r\n\r\ninputs = outputs = tf.layers.Input(tensor=x)\r\n\r\nfor enc in [encoder1, encoder2]:\r\n  outputs = enc(outputs)\r\n\r\nencoders = tf.layers.Network(inputs, outputs)\r\n\r\n# same for decoders\r\nfor i, dec in enumerate(decoders):\r\n  outputs = dec(tf.concat([encoders.get_layer(f'encoder{i}').output, outputs], 3))\r\n```\r\n\r\nCurrently you could either\r\n* use `network.get_output_at()` however this requires to track node indices or parse `network.layers` if encoders are not symmetric (i.e. some encoder have no batch norm / dropout)\r\n* inherit from `tf.layers.Layer` however documentation is not clear on how to \"forward\" variables for example"}