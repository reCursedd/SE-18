{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7641", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7641/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7641/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7641/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7641", "id": 208611300, "node_id": "MDU6SXNzdWUyMDg2MTEzMDA=", "number": 7641, "title": "'LookupError: No gradient defined for operation '...' (op type: ResizeBicubic)' is raised", "user": {"login": "mikigom", "id": 15151242, "node_id": "MDQ6VXNlcjE1MTUxMjQy", "avatar_url": "https://avatars1.githubusercontent.com/u/15151242?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mikigom", "html_url": "https://github.com/mikigom", "followers_url": "https://api.github.com/users/mikigom/followers", "following_url": "https://api.github.com/users/mikigom/following{/other_user}", "gists_url": "https://api.github.com/users/mikigom/gists{/gist_id}", "starred_url": "https://api.github.com/users/mikigom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mikigom/subscriptions", "organizations_url": "https://api.github.com/users/mikigom/orgs", "repos_url": "https://api.github.com/users/mikigom/repos", "events_url": "https://api.github.com/users/mikigom/events{/privacy}", "received_events_url": "https://api.github.com/users/mikigom/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-02-18T04:18:42Z", "updated_at": "2018-09-11T07:45:47Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I tried to use <a href=\"https://www.tensorflow.org/api_docs/python/tf/image/resize_images\" rel=\"nofollow\">tf.image.resize_images</a> with <code>method=ResizeMethod.BICUBIC</code>.</p>\n<p>The shorten version of my code is the following:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> module import is omitted</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> config setting is omitted</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> global variable declaration is omitted</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train</span>():\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> file queuing and reading are omitted.</span>\n    magnification <span class=\"pl-k\">=</span> tf.random_uniform([<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">minval</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>, <span class=\"pl-v\">maxval</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4</span>, <span class=\"pl-v\">dtype</span> <span class=\"pl-k\">=</span> tf.float32)\n\n    image_patches_blurred <span class=\"pl-k\">=</span> tf.image.resize_images(image_patches, [tf.to_int32(<span class=\"pl-c1\">64</span><span class=\"pl-k\">/</span>magnification[<span class=\"pl-c1\">0</span>]), tf.to_int32(<span class=\"pl-c1\">64</span><span class=\"pl-k\">/</span>magnification[<span class=\"pl-c1\">0</span>])], \\\n                                                    <span class=\"pl-v\">method</span> <span class=\"pl-k\">=</span> tf.image.ResizeMethod.<span class=\"pl-c1\">BICUBIC</span>)\n    image_patches_blurred <span class=\"pl-k\">=</span> tf.image.resize_images(image_patches_blurred, [<span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">64</span>], <span class=\"pl-v\">method</span> <span class=\"pl-k\">=</span> tf.image.ResizeMethod.<span class=\"pl-c1\">BICUBIC</span>)\n\n    <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>generator<span class=\"pl-pds\">'</span></span>):\n        G <span class=\"pl-k\">=</span> Stage_Unet_model.generator(image_patches_blurred, <span class=\"pl-v\">batch_size</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">16</span>, <span class=\"pl-v\">image_size</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>, <span class=\"pl-v\">input_channels</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>, <span class=\"pl-v\">gf_dim</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">32</span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Model Loss definition is omitted</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Summary Operation is omitted</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> tf variables loading</span>\n    all_vars <span class=\"pl-k\">=</span> tf.global_variables()\n    model_generator_vars <span class=\"pl-k\">=</span> [k <span class=\"pl-k\">for</span> k <span class=\"pl-k\">in</span> all_vars <span class=\"pl-k\">if</span> k.name.startswith(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>generator<span class=\"pl-pds\">\"</span></span>)]\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Gradient Clipping</span>\n    generator_grads <span class=\"pl-k\">=</span> tf.gradients(G_loss, model_generator_vars)\n    generator_grads, _ <span class=\"pl-k\">=</span> tf.clip_by_global_norm(generator_grads, <span class=\"pl-v\">clip_norm</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1.0</span>)\n    generator_var_pairs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">zip</span>(generator_grads, model_generator_vars)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> tf.train.Saver and global_step declaration is omitted</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> tf.train.AdamOptimizer</span>\n    Adam <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(config.learning_rate)\n    G_optim <span class=\"pl-k\">=</span> Adam.apply_gradients(generator_var_pairs, <span class=\"pl-v\">global_step</span> <span class=\"pl-k\">=</span> G_global_step)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> merge summary operation is omitted</span>\n\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>...</span>\n        <span class=\"pl-k\">for</span> epoch <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(config.epoch):\n            <span class=\"pl-k\">for</span> idx <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(config.train_data_number):\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Note that graph operations related with model D are omitted</span>\n                train_D_l, train_G_l, train_D_t_s, train_G_t_s, D_step, G_step, _, __ <span class=\"pl-k\">=</span> sess.run([D_loss, G_loss, \\\n                                                                D_tot_summary, G_tot_summary, \\\n                                                                D_global_step, G_global_step, D_optim, G_optim])\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>...</span>\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> tf.gfile.Exists(log_dir):\n        tf.gfile.MakeDirs(log_dir)\n    train()</pre></div>\n<p>Running the above code will result in the following error:</p>\n<pre><code>$ python train_stage1.py \nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nTraceback (most recent call last):\n  File \"train_stage1.py\", line 216, in &lt;module&gt;\n    train()\n  File \"train_stage1.py\", line 150, in train\n    generator_grads = tf.gradients(G_loss, model_generator_vars)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 459, in gradients\n    (op.name, op.type))\nLookupError: No gradient defined for operation 'ResizeBicubic_3' (op type: ResizeBicubic)\n</code></pre>\n<p>Thank you for any help.</p>\n<h3>Environment info</h3>\n<p>Operating System:</p>\n<p>Installed version of CUDA and cuDNN:</p>\n<pre><code>$ ls -l /usr/local/cuda-8.0/lib64/libcud*\n-rw-r--r-- 1 root root   558720 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n</code></pre>\n<p>If installed from binary pip package, provide:</p>\n<pre><code>$ python -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n1.0.0\n</code></pre>", "body_text": "I tried to use tf.image.resize_images with method=ResizeMethod.BICUBIC.\nThe shorten version of my code is the following:\n# module import is omitted\n# config setting is omitted\n# global variable declaration is omitted\n\ndef train():\n    # file queuing and reading are omitted.\n    magnification = tf.random_uniform([1], minval = 0, maxval = 4, dtype = tf.float32)\n\n    image_patches_blurred = tf.image.resize_images(image_patches, [tf.to_int32(64/magnification[0]), tf.to_int32(64/magnification[0])], \\\n                                                    method = tf.image.ResizeMethod.BICUBIC)\n    image_patches_blurred = tf.image.resize_images(image_patches_blurred, [64, 64], method = tf.image.ResizeMethod.BICUBIC)\n\n    with tf.variable_scope('generator'):\n        G = Stage_Unet_model.generator(image_patches_blurred, batch_size = 16, image_size = 64, input_channels = 3, gf_dim = 32)\n\n    # Model Loss definition is omitted\n\n    # Summary Operation is omitted\n\n    # tf variables loading\n    all_vars = tf.global_variables()\n    model_generator_vars = [k for k in all_vars if k.name.startswith(\"generator\")]\n\n    # Gradient Clipping\n    generator_grads = tf.gradients(G_loss, model_generator_vars)\n    generator_grads, _ = tf.clip_by_global_norm(generator_grads, clip_norm = 1.0)\n    generator_var_pairs = zip(generator_grads, model_generator_vars)\n\n    # tf.train.Saver and global_step declaration is omitted\n\n    # tf.train.AdamOptimizer\n    Adam = tf.train.AdamOptimizer(config.learning_rate)\n    G_optim = Adam.apply_gradients(generator_var_pairs, global_step = G_global_step)\n\n    # merge summary operation is omitted\n\n    with tf.Session() as sess:\n        #...\n        for epoch in range(config.epoch):\n            for idx in range(config.train_data_number):\n                # Note that graph operations related with model D are omitted\n                train_D_l, train_G_l, train_D_t_s, train_G_t_s, D_step, G_step, _, __ = sess.run([D_loss, G_loss, \\\n                                                                D_tot_summary, G_tot_summary, \\\n                                                                D_global_step, G_global_step, D_optim, G_optim])\n        #...\n\nif __name__ == '__main__':\n    if not tf.gfile.Exists(log_dir):\n        tf.gfile.MakeDirs(log_dir)\n    train()\nRunning the above code will result in the following error:\n$ python train_stage1.py \nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nTraceback (most recent call last):\n  File \"train_stage1.py\", line 216, in <module>\n    train()\n  File \"train_stage1.py\", line 150, in train\n    generator_grads = tf.gradients(G_loss, model_generator_vars)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 459, in gradients\n    (op.name, op.type))\nLookupError: No gradient defined for operation 'ResizeBicubic_3' (op type: ResizeBicubic)\n\nThank you for any help.\nEnvironment info\nOperating System:\nInstalled version of CUDA and cuDNN:\n$ ls -l /usr/local/cuda-8.0/lib64/libcud*\n-rw-r--r-- 1 root root   558720 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n$ python -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n1.0.0", "body": "I tried to use [tf.image.resize_images](https://www.tensorflow.org/api_docs/python/tf/image/resize_images) with ```method=ResizeMethod.BICUBIC```.\r\n\r\nThe shorten version of my code is the following:\r\n```python\r\n# module import is omitted\r\n# config setting is omitted\r\n# global variable declaration is omitted\r\n\r\ndef train():\r\n    # file queuing and reading are omitted.\r\n    magnification = tf.random_uniform([1], minval = 0, maxval = 4, dtype = tf.float32)\r\n\r\n    image_patches_blurred = tf.image.resize_images(image_patches, [tf.to_int32(64/magnification[0]), tf.to_int32(64/magnification[0])], \\\r\n                                                    method = tf.image.ResizeMethod.BICUBIC)\r\n    image_patches_blurred = tf.image.resize_images(image_patches_blurred, [64, 64], method = tf.image.ResizeMethod.BICUBIC)\r\n\r\n    with tf.variable_scope('generator'):\r\n        G = Stage_Unet_model.generator(image_patches_blurred, batch_size = 16, image_size = 64, input_channels = 3, gf_dim = 32)\r\n\r\n    # Model Loss definition is omitted\r\n\r\n    # Summary Operation is omitted\r\n\r\n    # tf variables loading\r\n    all_vars = tf.global_variables()\r\n    model_generator_vars = [k for k in all_vars if k.name.startswith(\"generator\")]\r\n\r\n    # Gradient Clipping\r\n    generator_grads = tf.gradients(G_loss, model_generator_vars)\r\n    generator_grads, _ = tf.clip_by_global_norm(generator_grads, clip_norm = 1.0)\r\n    generator_var_pairs = zip(generator_grads, model_generator_vars)\r\n\r\n    # tf.train.Saver and global_step declaration is omitted\r\n\r\n    # tf.train.AdamOptimizer\r\n    Adam = tf.train.AdamOptimizer(config.learning_rate)\r\n    G_optim = Adam.apply_gradients(generator_var_pairs, global_step = G_global_step)\r\n\r\n    # merge summary operation is omitted\r\n\r\n    with tf.Session() as sess:\r\n        #...\r\n        for epoch in range(config.epoch):\r\n            for idx in range(config.train_data_number):\r\n                # Note that graph operations related with model D are omitted\r\n                train_D_l, train_G_l, train_D_t_s, train_G_t_s, D_step, G_step, _, __ = sess.run([D_loss, G_loss, \\\r\n                                                                D_tot_summary, G_tot_summary, \\\r\n                                                                D_global_step, G_global_step, D_optim, G_optim])\r\n        #...\r\n\r\nif __name__ == '__main__':\r\n    if not tf.gfile.Exists(log_dir):\r\n        tf.gfile.MakeDirs(log_dir)\r\n    train()\r\n```\r\n\r\nRunning the above code will result in the following error:\r\n```\r\n$ python train_stage1.py \r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nTraceback (most recent call last):\r\n  File \"train_stage1.py\", line 216, in <module>\r\n    train()\r\n  File \"train_stage1.py\", line 150, in train\r\n    generator_grads = tf.gradients(G_loss, model_generator_vars)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 459, in gradients\r\n    (op.name, op.type))\r\nLookupError: No gradient defined for operation 'ResizeBicubic_3' (op type: ResizeBicubic)\r\n```\r\n\r\nThank you for any help.\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n```\r\n$ ls -l /usr/local/cuda-8.0/lib64/libcud*\r\n-rw-r--r-- 1 root root   558720 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root   415432 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart_static.a\r\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so\r\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so.5\r\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n```\r\n$ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n1.0.0\r\n```"}