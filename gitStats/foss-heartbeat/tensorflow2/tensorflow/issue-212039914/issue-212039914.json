{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8113", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8113/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8113/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8113/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8113", "id": 212039914, "node_id": "MDU6SXNzdWUyMTIwMzk5MTQ=", "number": 8113, "title": "I can not run my code Tensorflow", "user": {"login": "TesTBesTnexT", "id": 26215775, "node_id": "MDQ6VXNlcjI2MjE1Nzc1", "avatar_url": "https://avatars0.githubusercontent.com/u/26215775?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TesTBesTnexT", "html_url": "https://github.com/TesTBesTnexT", "followers_url": "https://api.github.com/users/TesTBesTnexT/followers", "following_url": "https://api.github.com/users/TesTBesTnexT/following{/other_user}", "gists_url": "https://api.github.com/users/TesTBesTnexT/gists{/gist_id}", "starred_url": "https://api.github.com/users/TesTBesTnexT/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TesTBesTnexT/subscriptions", "organizations_url": "https://api.github.com/users/TesTBesTnexT/orgs", "repos_url": "https://api.github.com/users/TesTBesTnexT/repos", "events_url": "https://api.github.com/users/TesTBesTnexT/events{/privacy}", "received_events_url": "https://api.github.com/users/TesTBesTnexT/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-03-06T07:04:20Z", "updated_at": "2017-03-06T17:40:14Z", "closed_at": "2017-03-06T17:40:14Z", "author_association": "NONE", "body_html": "<p>I working on <code>Ubuntu 14.04</code> ,i wrote a code for Recognition of letters whith <code>Tensorflow V 0.11</code> ,<br>\ni'm creat a code source for uses the model <code>LeNet5</code><br>\nmy code source :</p>\n<p>`</p>\n<blockquote>\n<pre><code>import PIL\n\nimport numpy\nimport tensorflow as tf\n# from tensorflow.examples.tutorials.mnist import input_data\nimport Input as input_data\nfrom tensorflow.python.framework.importer import import_graph_def\n\nfrom Resize import Resize_img\n\n# these functions to optimize the accurancy of the mnist training\n#from imp_image import imp_img\nimport scipy.misc\n\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n\n# ============================================================ End Functions part\n\n# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\nclass MNIST:\n\n    def __init__(self):\n\n        # Open the compuation session\n        self.sess = tf.InteractiveSession()\n        # Load the network\n        self.Deep_Network()\n\n    def Deep_Network(self):\n\n        # nodes for the input images and target output classes.\n        # supervised classifier\n        self.x = tf.placeholder(tf.float32, shape=[None, 784])\n        self.y_ = tf.placeholder(tf.float32, shape=[None, 10])\n\n        # First convolutionanal Layer =====================================\n        # It will consist of convolution, followed by max pooling\n        # The convolutional will compute 32 features for each 5x5 patch.\n        self.W_conv1 = weight_variable([5, 5, 1, 32])\n        self.b_conv1 = bias_variable([32])\n\n        # To apply the layer, we first reshape x to a 4d tensor,\n        #  with the second and third dimensions corresponding to image width and height,\n        #  and the final dimension corresponding to the number of color channels.\n        self.x_image = tf.reshape(self.x, [-1, 28, 28, 1])\n\n        # We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool.\n        self.h_conv1 = tf.nn.relu(conv2d(self.x_image, self.W_conv1) + self.b_conv1)\n        self.h_pool1 = max_pool_2x2(self.h_conv1)\n\n        # Second Convolutional Layer =====================================\n\n        # In order to build a deep network, we stack several layers of this type.\n        # The second layer will have 64 features for each 5x5 patch.\n\n        self.W_conv2 = weight_variable([5, 5, 32, 64])\n        self.b_conv2 = bias_variable([64])\n\n        self.h_conv2 = tf.nn.relu(conv2d(self.h_pool1, self.W_conv2) + self.b_conv2)\n        self.h_pool2 = max_pool_2x2(self.h_conv2)\n\n        # Densely Connected Layer\n\n        # Now that the image size has been reduced to 7x7, we add a fully-connected layer with 1024 neurons\n        # to allow processing on the entire image. We reshape the tensor from the pooling layer into\n        # a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU.\n\n        self.W_fc1 = weight_variable([7 * 7 * 64, 1024])\n        self.b_fc1 = bias_variable([1024])\n\n        self.h_pool2_flat = tf.reshape(self.h_pool2, [-1, 7 * 7 * 64])\n        self.h_fc1 = tf.nn.relu(\n            tf.matmul(self.h_pool2_flat, self.W_fc1) + self.b_fc1)  # ReLu Computes rectified linear: max(features, 0).\n\n        # Dropout\n\n        self.keep_prob = tf.placeholder(tf.float32)\n        self.h_fc1_drop = tf.nn.dropout(self.h_fc1, self.keep_prob)\n\n        # Readout Layer ========================================\n        # Finally, we add a softmax layer, just like for the one layer softmax regression above.\n\n        self.W_fc2 = weight_variable([1024, 10])\n        self.b_fc2 = bias_variable([10])\n\n        self.y_conv = tf.nn.softmax(tf.matmul(self.h_fc1_drop, self.W_fc2) + self.b_fc2)\n        self.cross_entropy = -tf.reduce_sum(self.y_ * tf.log(self.y_conv))\n        self.correct_prediction = tf.equal(tf.argmax(self.y_conv, 1), tf.argmax(self.y_, 1))\n        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n\n    def Prediction(self, imageName):\n\n        # Load the trained model\n        ' Restore the model '\n        'here i should create the model saver'\n        Saved_model_dir = '/home/brm17/Desktop/PFE/'\n        saver = tf.train.Saver()\n        ckpt = tf.train.get_checkpoint_state(Saved_model_dir)\n\n        'verifie if the saved model exists or not!'\n        if ckpt and ckpt.model_checkpoint_path:\n            saver.restore(self.sess, ckpt.model_checkpoint_path)\n        else:\n            print '# No saved model found!'\n            exit()  # exit the prgm\n\n        # image_test = 'number-3.jpg'\n        ResizedImage = Resize_img(imageName)\n\n        ImageInput = ResizedImage.mnist_image_input.reshape(1, -1)\n\n        print 'Predection &gt; ', tf.argmax(self.y_conv, 1).eval(feed_dict={self.x: ImageInput, self.keep_prob: 1.0})\n\n    # print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: myTestImg, y_: myLabel, keep_prob: 1.0}))\n\n\ndef main():\n    image = '/home/brm17/Desktop/PFE/n2.jpeg'\n    model = MNIST()\n    model.Prediction(image)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>\n</blockquote>\n<pre><code>`\n</code></pre>\n<p>if i run this code , he print the error :</p>\n<blockquote>\n<pre><code>brm17@Brahim:~/Desktop/PFE$ python LeNet5.py \nTraceback (most recent call last):\n  File \"LeNet5.py\", line 137, in &lt;module&gt;\n    model.Prediction(image)\n  File \"LeNet5.py\", line 120, in Prediction\n    saver.restore(self.sess, ckpt.model_checkpoint_path)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1129, in restore\n    {self.saver_def.filename_tensor_name: save_path})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 710, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 908, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 958, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 978, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.NotFoundError: Tensor name \"Variable_1\" not found in checkpoint files /home/brm17/Desktop/PFE/MNISTmodel-20000\n\t [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]\nCaused by op u'save/restore_slice_1', defined at:\n  File \"LeNet5.py\", line 137, in &lt;module&gt;\n    model.Prediction(image)\n  File \"LeNet5.py\", line 115, in Prediction\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 861, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 519, in build\n    filename_tensor, vars_to_save, restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 272, in _AddRestoreOps\n    values = self.restore_op(filename_tensor, vs, preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 187, in restore_op\n    preferred_shard=preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py\", line 203, in _restore_slice\n    preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n</code></pre>\n</blockquote>\n<p>what is the problem and how resolved this ?</p>", "body_text": "I working on Ubuntu 14.04 ,i wrote a code for Recognition of letters whith Tensorflow V 0.11 ,\ni'm creat a code source for uses the model LeNet5\nmy code source :\n`\n\nimport PIL\n\nimport numpy\nimport tensorflow as tf\n# from tensorflow.examples.tutorials.mnist import input_data\nimport Input as input_data\nfrom tensorflow.python.framework.importer import import_graph_def\n\nfrom Resize import Resize_img\n\n# these functions to optimize the accurancy of the mnist training\n#from imp_image import imp_img\nimport scipy.misc\n\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n\n# ============================================================ End Functions part\n\n# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\nclass MNIST:\n\n    def __init__(self):\n\n        # Open the compuation session\n        self.sess = tf.InteractiveSession()\n        # Load the network\n        self.Deep_Network()\n\n    def Deep_Network(self):\n\n        # nodes for the input images and target output classes.\n        # supervised classifier\n        self.x = tf.placeholder(tf.float32, shape=[None, 784])\n        self.y_ = tf.placeholder(tf.float32, shape=[None, 10])\n\n        # First convolutionanal Layer =====================================\n        # It will consist of convolution, followed by max pooling\n        # The convolutional will compute 32 features for each 5x5 patch.\n        self.W_conv1 = weight_variable([5, 5, 1, 32])\n        self.b_conv1 = bias_variable([32])\n\n        # To apply the layer, we first reshape x to a 4d tensor,\n        #  with the second and third dimensions corresponding to image width and height,\n        #  and the final dimension corresponding to the number of color channels.\n        self.x_image = tf.reshape(self.x, [-1, 28, 28, 1])\n\n        # We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool.\n        self.h_conv1 = tf.nn.relu(conv2d(self.x_image, self.W_conv1) + self.b_conv1)\n        self.h_pool1 = max_pool_2x2(self.h_conv1)\n\n        # Second Convolutional Layer =====================================\n\n        # In order to build a deep network, we stack several layers of this type.\n        # The second layer will have 64 features for each 5x5 patch.\n\n        self.W_conv2 = weight_variable([5, 5, 32, 64])\n        self.b_conv2 = bias_variable([64])\n\n        self.h_conv2 = tf.nn.relu(conv2d(self.h_pool1, self.W_conv2) + self.b_conv2)\n        self.h_pool2 = max_pool_2x2(self.h_conv2)\n\n        # Densely Connected Layer\n\n        # Now that the image size has been reduced to 7x7, we add a fully-connected layer with 1024 neurons\n        # to allow processing on the entire image. We reshape the tensor from the pooling layer into\n        # a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU.\n\n        self.W_fc1 = weight_variable([7 * 7 * 64, 1024])\n        self.b_fc1 = bias_variable([1024])\n\n        self.h_pool2_flat = tf.reshape(self.h_pool2, [-1, 7 * 7 * 64])\n        self.h_fc1 = tf.nn.relu(\n            tf.matmul(self.h_pool2_flat, self.W_fc1) + self.b_fc1)  # ReLu Computes rectified linear: max(features, 0).\n\n        # Dropout\n\n        self.keep_prob = tf.placeholder(tf.float32)\n        self.h_fc1_drop = tf.nn.dropout(self.h_fc1, self.keep_prob)\n\n        # Readout Layer ========================================\n        # Finally, we add a softmax layer, just like for the one layer softmax regression above.\n\n        self.W_fc2 = weight_variable([1024, 10])\n        self.b_fc2 = bias_variable([10])\n\n        self.y_conv = tf.nn.softmax(tf.matmul(self.h_fc1_drop, self.W_fc2) + self.b_fc2)\n        self.cross_entropy = -tf.reduce_sum(self.y_ * tf.log(self.y_conv))\n        self.correct_prediction = tf.equal(tf.argmax(self.y_conv, 1), tf.argmax(self.y_, 1))\n        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n\n    def Prediction(self, imageName):\n\n        # Load the trained model\n        ' Restore the model '\n        'here i should create the model saver'\n        Saved_model_dir = '/home/brm17/Desktop/PFE/'\n        saver = tf.train.Saver()\n        ckpt = tf.train.get_checkpoint_state(Saved_model_dir)\n\n        'verifie if the saved model exists or not!'\n        if ckpt and ckpt.model_checkpoint_path:\n            saver.restore(self.sess, ckpt.model_checkpoint_path)\n        else:\n            print '# No saved model found!'\n            exit()  # exit the prgm\n\n        # image_test = 'number-3.jpg'\n        ResizedImage = Resize_img(imageName)\n\n        ImageInput = ResizedImage.mnist_image_input.reshape(1, -1)\n\n        print 'Predection > ', tf.argmax(self.y_conv, 1).eval(feed_dict={self.x: ImageInput, self.keep_prob: 1.0})\n\n    # print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: myTestImg, y_: myLabel, keep_prob: 1.0}))\n\n\ndef main():\n    image = '/home/brm17/Desktop/PFE/n2.jpeg'\n    model = MNIST()\n    model.Prediction(image)\n\nif __name__ == \"__main__\":\n    main()\n\n\n`\n\nif i run this code , he print the error :\n\nbrm17@Brahim:~/Desktop/PFE$ python LeNet5.py \nTraceback (most recent call last):\n  File \"LeNet5.py\", line 137, in <module>\n    model.Prediction(image)\n  File \"LeNet5.py\", line 120, in Prediction\n    saver.restore(self.sess, ckpt.model_checkpoint_path)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1129, in restore\n    {self.saver_def.filename_tensor_name: save_path})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 710, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 908, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 958, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 978, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.NotFoundError: Tensor name \"Variable_1\" not found in checkpoint files /home/brm17/Desktop/PFE/MNISTmodel-20000\n\t [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]\nCaused by op u'save/restore_slice_1', defined at:\n  File \"LeNet5.py\", line 137, in <module>\n    model.Prediction(image)\n  File \"LeNet5.py\", line 115, in Prediction\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 861, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 519, in build\n    filename_tensor, vars_to_save, restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 272, in _AddRestoreOps\n    values = self.restore_op(filename_tensor, vs, preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 187, in restore_op\n    preferred_shard=preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py\", line 203, in _restore_slice\n    preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n\n\nwhat is the problem and how resolved this ?", "body": "I working on `Ubuntu 14.04` ,i wrote a code for Recognition of letters whith `Tensorflow V 0.11` ,\r\ni'm creat a code source for uses the model `LeNet5` \r\nmy code source : \r\n\r\n`\r\n\r\n> \r\n>     import PIL\r\n>     \r\n>     import numpy\r\n>     import tensorflow as tf\r\n>     # from tensorflow.examples.tutorials.mnist import input_data\r\n>     import Input as input_data\r\n>     from tensorflow.python.framework.importer import import_graph_def\r\n>     \r\n>     from Resize import Resize_img\r\n>     \r\n>     # these functions to optimize the accurancy of the mnist training\r\n>     #from imp_image import imp_img\r\n>     import scipy.misc\r\n>     \r\n>     \r\n>     def weight_variable(shape):\r\n>         initial = tf.truncated_normal(shape, stddev=0.1)\r\n>         return tf.Variable(initial)\r\n>     \r\n>     \r\n>     def bias_variable(shape):\r\n>         initial = tf.constant(0.1, shape=shape)\r\n>         return tf.Variable(initial)\r\n>     \r\n>     \r\n>     def conv2d(x, W):\r\n>         return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n>     \r\n>     \r\n>     def max_pool_2x2(x):\r\n>         return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n>     \r\n>     \r\n>     # ============================================================ End Functions part\r\n>     \r\n>     # mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\n>     \r\n>     class MNIST:\r\n>     \r\n>         def __init__(self):\r\n>     \r\n>             # Open the compuation session\r\n>             self.sess = tf.InteractiveSession()\r\n>             # Load the network\r\n>             self.Deep_Network()\r\n>     \r\n>         def Deep_Network(self):\r\n>     \r\n>             # nodes for the input images and target output classes.\r\n>             # supervised classifier\r\n>             self.x = tf.placeholder(tf.float32, shape=[None, 784])\r\n>             self.y_ = tf.placeholder(tf.float32, shape=[None, 10])\r\n>     \r\n>             # First convolutionanal Layer =====================================\r\n>             # It will consist of convolution, followed by max pooling\r\n>             # The convolutional will compute 32 features for each 5x5 patch.\r\n>             self.W_conv1 = weight_variable([5, 5, 1, 32])\r\n>             self.b_conv1 = bias_variable([32])\r\n>     \r\n>             # To apply the layer, we first reshape x to a 4d tensor,\r\n>             #  with the second and third dimensions corresponding to image width and height,\r\n>             #  and the final dimension corresponding to the number of color channels.\r\n>             self.x_image = tf.reshape(self.x, [-1, 28, 28, 1])\r\n>     \r\n>             # We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool.\r\n>             self.h_conv1 = tf.nn.relu(conv2d(self.x_image, self.W_conv1) + self.b_conv1)\r\n>             self.h_pool1 = max_pool_2x2(self.h_conv1)\r\n>     \r\n>             # Second Convolutional Layer =====================================\r\n>     \r\n>             # In order to build a deep network, we stack several layers of this type.\r\n>             # The second layer will have 64 features for each 5x5 patch.\r\n>     \r\n>             self.W_conv2 = weight_variable([5, 5, 32, 64])\r\n>             self.b_conv2 = bias_variable([64])\r\n>     \r\n>             self.h_conv2 = tf.nn.relu(conv2d(self.h_pool1, self.W_conv2) + self.b_conv2)\r\n>             self.h_pool2 = max_pool_2x2(self.h_conv2)\r\n>     \r\n>             # Densely Connected Layer\r\n>     \r\n>             # Now that the image size has been reduced to 7x7, we add a fully-connected layer with 1024 neurons\r\n>             # to allow processing on the entire image. We reshape the tensor from the pooling layer into\r\n>             # a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU.\r\n>     \r\n>             self.W_fc1 = weight_variable([7 * 7 * 64, 1024])\r\n>             self.b_fc1 = bias_variable([1024])\r\n>     \r\n>             self.h_pool2_flat = tf.reshape(self.h_pool2, [-1, 7 * 7 * 64])\r\n>             self.h_fc1 = tf.nn.relu(\r\n>                 tf.matmul(self.h_pool2_flat, self.W_fc1) + self.b_fc1)  # ReLu Computes rectified linear: max(features, 0).\r\n>     \r\n>             # Dropout\r\n>     \r\n>             self.keep_prob = tf.placeholder(tf.float32)\r\n>             self.h_fc1_drop = tf.nn.dropout(self.h_fc1, self.keep_prob)\r\n>     \r\n>             # Readout Layer ========================================\r\n>             # Finally, we add a softmax layer, just like for the one layer softmax regression above.\r\n>     \r\n>             self.W_fc2 = weight_variable([1024, 10])\r\n>             self.b_fc2 = bias_variable([10])\r\n>     \r\n>             self.y_conv = tf.nn.softmax(tf.matmul(self.h_fc1_drop, self.W_fc2) + self.b_fc2)\r\n>             self.cross_entropy = -tf.reduce_sum(self.y_ * tf.log(self.y_conv))\r\n>             self.correct_prediction = tf.equal(tf.argmax(self.y_conv, 1), tf.argmax(self.y_, 1))\r\n>             self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\r\n>     \r\n>         def Prediction(self, imageName):\r\n>     \r\n>             # Load the trained model\r\n>             ' Restore the model '\r\n>             'here i should create the model saver'\r\n>             Saved_model_dir = '/home/brm17/Desktop/PFE/'\r\n>             saver = tf.train.Saver()\r\n>             ckpt = tf.train.get_checkpoint_state(Saved_model_dir)\r\n>     \r\n>             'verifie if the saved model exists or not!'\r\n>             if ckpt and ckpt.model_checkpoint_path:\r\n>                 saver.restore(self.sess, ckpt.model_checkpoint_path)\r\n>             else:\r\n>                 print '# No saved model found!'\r\n>                 exit()  # exit the prgm\r\n>     \r\n>             # image_test = 'number-3.jpg'\r\n>             ResizedImage = Resize_img(imageName)\r\n>     \r\n>             ImageInput = ResizedImage.mnist_image_input.reshape(1, -1)\r\n>     \r\n>             print 'Predection > ', tf.argmax(self.y_conv, 1).eval(feed_dict={self.x: ImageInput, self.keep_prob: 1.0})\r\n>     \r\n>         # print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: myTestImg, y_: myLabel, keep_prob: 1.0}))\r\n>     \r\n>     \r\n>     def main():\r\n>         image = '/home/brm17/Desktop/PFE/n2.jpeg'\r\n>         model = MNIST()\r\n>         model.Prediction(image)\r\n>     \r\n>     if __name__ == \"__main__\":\r\n>         main()\r\n>     \r\n\r\n    `\r\n    \r\nif i run this code , he print the error :\r\n\r\n>     brm17@Brahim:~/Desktop/PFE$ python LeNet5.py \r\n>     Traceback (most recent call last):\r\n>       File \"LeNet5.py\", line 137, in <module>\r\n>         model.Prediction(image)\r\n>       File \"LeNet5.py\", line 120, in Prediction\r\n>         saver.restore(self.sess, ckpt.model_checkpoint_path)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1129, in restore\r\n>         {self.saver_def.filename_tensor_name: save_path})\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 710, in run\r\n>         run_metadata_ptr)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 908, in _run\r\n>         feed_dict_string, options, run_metadata)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 958, in _do_run\r\n>         target_list, options, run_metadata)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 978, in _do_call\r\n>         raise type(e)(node_def, op, message)\r\n>     tensorflow.python.framework.errors.NotFoundError: Tensor name \"Variable_1\" not found in checkpoint files /home/brm17/Desktop/PFE/MNISTmodel-20000\r\n>     \t [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]\r\n>     Caused by op u'save/restore_slice_1', defined at:\r\n>       File \"LeNet5.py\", line 137, in <module>\r\n>         model.Prediction(image)\r\n>       File \"LeNet5.py\", line 115, in Prediction\r\n>         saver = tf.train.Saver()\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 861, in __init__\r\n>         restore_sequentially=restore_sequentially)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 519, in build\r\n>         filename_tensor, vars_to_save, restore_sequentially, reshape)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 272, in _AddRestoreOps\r\n>         values = self.restore_op(filename_tensor, vs, preferred_shard)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 187, in restore_op\r\n>         preferred_shard=preferred_shard)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py\", line 203, in _restore_slice\r\n>         preferred_shard, name=name)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\r\n>         preferred_shard=preferred_shard, name=name)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\r\n>         op_def=op_def)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\r\n>         original_op=self._default_original_op, op_def=op_def)\r\n>       File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\r\n>         self._traceback = _extract_stack()\r\n>     \r\n>      \r\n> \r\n\r\nwhat is the problem and how resolved this ? "}