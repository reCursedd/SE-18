{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/292133098", "html_url": "https://github.com/tensorflow/tensorflow/issues/5609#issuecomment-292133098", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5609", "id": 292133098, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjEzMzA5OA==", "user": {"login": "randomrandom", "id": 1579822, "node_id": "MDQ6VXNlcjE1Nzk4MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1579822?v=4", "gravatar_id": "", "url": "https://api.github.com/users/randomrandom", "html_url": "https://github.com/randomrandom", "followers_url": "https://api.github.com/users/randomrandom/followers", "following_url": "https://api.github.com/users/randomrandom/following{/other_user}", "gists_url": "https://api.github.com/users/randomrandom/gists{/gist_id}", "starred_url": "https://api.github.com/users/randomrandom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/randomrandom/subscriptions", "organizations_url": "https://api.github.com/users/randomrandom/orgs", "repos_url": "https://api.github.com/users/randomrandom/repos", "events_url": "https://api.github.com/users/randomrandom/events{/privacy}", "received_events_url": "https://api.github.com/users/randomrandom/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-06T10:28:02Z", "updated_at": "2017-04-06T10:42:48Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=505333\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/AndreasMadsen\">@AndreasMadsen</a><br>\nI gave it a shot to do this with a queuerunner, however I got stuck at some point, this is my current code</p>\n<pre><code>    BUCKET_BOUNDARIES = [2,4]\n    MAX_LEN = 6\n\n    def _to_sparse_tensor(self, sequences):\n \n          sp_indices = []\n          sp_vals = []\n          sp_shape = [len(sequences), self.MAX_LEN]\n \n          for i in range(0, len(sequences)):\n              for j in range(0, len(sequences[i])):\n                  sp_indices.append([i, j])\n                  sp_vals.append(sequences[i][j])\n \n          return tf.SparseTensor(indices=sp_indices, values=sp_vals, shape=sp_shape)\n\n      def __init__(self, batch_size=32, name='x-train'):\n \n          # load train corpus\n          sources, targets, lengths, validation_sources, validation_targets, validation_lengths = self._load_corpus()\n \n          print(\"Finished corpus loading\")\n          # to a constant tensor\n          source = self._to_sparse_tensor(sources)\n          target = self._to_sparse_tensor(targets)\n          length = tf.convert_to_tensor(np.asarray(lengths, dtype=np.int32))\n \n          input_queue = tf.train.shuffle_batch([length, source, target], batch_size,\n                                              batch_size*64, # capacity\n                                              batch_size*32, # min_after_dequeue\n                                              num_threads=32,\n                                              allow_smaller_final_batch=False, name=name)\n \n          lengths_t, sources_t, targets_t = input_queue\n\n          source_batch, target_batch = self.shuffle_bucket_batch(\n              lengths_t, [sources_t, targets_t],\n              batch_size=batch_size,\n              bucket_boundaries=self.BUCKET_BOUNDARIES,\n              # this will pad the source_batch and target_batch independently\n              dynamic_pad=True,\n              capacity=batch_size*64,\n              num_threads=32,\n              allow_smaller_final_batch=False, name=name\n          )\n</code></pre>\n<p>where <code>shuffle_bucket_batch</code> looks like this:</p>\n<pre><code>def shuffle_bucket_batch(input_length, tensors, shuffle=True, **kwargs):\n    # the first argument is the sequence length specifed in the input_length\n    # I did not find a ue for it.\n    _, batch_tensors = tf.contrib.training.bucket_by_sequence_length(\n        input_length=input_length,\n        tensors=tensors,\n        **kwargs\n    )\n    return tuple(batch_tensors)\n</code></pre>\n<p>I've put the sources and targets into SparseArray (doing it manually, since I couldn't find a tf method similar to <code>convert_to_tensor</code> but for sparse data) so I can feed them into <code>shuffle_batch</code> queue (it can operate on SparseArrays), then I pass the outputs to the shuffle_bucket_batch.</p>\n<p>The problem that I've hit is that I get some sort of dimension mismatch between the input_length and the amounts of buckets:<br>\n<code>ValueError: Dimensions must be equal, but are 3 and 31978 for 'x-train_1/LessEqual' (op:'LessEqual') with input shapes: [3], [32,31978].</code></p>\n<p>the error happens at line 346 in this file: <a href=\"http://git.hiddenunit.com/hakan/tersorflow/blob/42d26aa7001dda6928771db8b4244067c7924a01/tensorflow/contrib/training/python/training/bucket_ops.py\" rel=\"nofollow\">http://git.hiddenunit.com/hakan/tersorflow/blob/42d26aa7001dda6928771db8b4244067c7924a01/tensorflow/contrib/training/python/training/bucket_ops.py</a></p>\n<p>The main difference with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=505333\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/AndreasMadsen\">@AndreasMadsen</a> is that I don't use <code>range_input_produce</code> since the input_lengths, sources and targets are batched together.</p>\n<p>Is it reasonable to use <code>SparseArray</code>, <code>shuffle_batch</code> and <code>bucket_by_sequence_length</code>? Any ideas why the dimension don't fit together?</p>", "body_text": "@ebrevdo @AndreasMadsen\nI gave it a shot to do this with a queuerunner, however I got stuck at some point, this is my current code\n    BUCKET_BOUNDARIES = [2,4]\n    MAX_LEN = 6\n\n    def _to_sparse_tensor(self, sequences):\n \n          sp_indices = []\n          sp_vals = []\n          sp_shape = [len(sequences), self.MAX_LEN]\n \n          for i in range(0, len(sequences)):\n              for j in range(0, len(sequences[i])):\n                  sp_indices.append([i, j])\n                  sp_vals.append(sequences[i][j])\n \n          return tf.SparseTensor(indices=sp_indices, values=sp_vals, shape=sp_shape)\n\n      def __init__(self, batch_size=32, name='x-train'):\n \n          # load train corpus\n          sources, targets, lengths, validation_sources, validation_targets, validation_lengths = self._load_corpus()\n \n          print(\"Finished corpus loading\")\n          # to a constant tensor\n          source = self._to_sparse_tensor(sources)\n          target = self._to_sparse_tensor(targets)\n          length = tf.convert_to_tensor(np.asarray(lengths, dtype=np.int32))\n \n          input_queue = tf.train.shuffle_batch([length, source, target], batch_size,\n                                              batch_size*64, # capacity\n                                              batch_size*32, # min_after_dequeue\n                                              num_threads=32,\n                                              allow_smaller_final_batch=False, name=name)\n \n          lengths_t, sources_t, targets_t = input_queue\n\n          source_batch, target_batch = self.shuffle_bucket_batch(\n              lengths_t, [sources_t, targets_t],\n              batch_size=batch_size,\n              bucket_boundaries=self.BUCKET_BOUNDARIES,\n              # this will pad the source_batch and target_batch independently\n              dynamic_pad=True,\n              capacity=batch_size*64,\n              num_threads=32,\n              allow_smaller_final_batch=False, name=name\n          )\n\nwhere shuffle_bucket_batch looks like this:\ndef shuffle_bucket_batch(input_length, tensors, shuffle=True, **kwargs):\n    # the first argument is the sequence length specifed in the input_length\n    # I did not find a ue for it.\n    _, batch_tensors = tf.contrib.training.bucket_by_sequence_length(\n        input_length=input_length,\n        tensors=tensors,\n        **kwargs\n    )\n    return tuple(batch_tensors)\n\nI've put the sources and targets into SparseArray (doing it manually, since I couldn't find a tf method similar to convert_to_tensor but for sparse data) so I can feed them into shuffle_batch queue (it can operate on SparseArrays), then I pass the outputs to the shuffle_bucket_batch.\nThe problem that I've hit is that I get some sort of dimension mismatch between the input_length and the amounts of buckets:\nValueError: Dimensions must be equal, but are 3 and 31978 for 'x-train_1/LessEqual' (op:'LessEqual') with input shapes: [3], [32,31978].\nthe error happens at line 346 in this file: http://git.hiddenunit.com/hakan/tersorflow/blob/42d26aa7001dda6928771db8b4244067c7924a01/tensorflow/contrib/training/python/training/bucket_ops.py\nThe main difference with @AndreasMadsen is that I don't use range_input_produce since the input_lengths, sources and targets are batched together.\nIs it reasonable to use SparseArray, shuffle_batch and bucket_by_sequence_length? Any ideas why the dimension don't fit together?", "body": "@ebrevdo @AndreasMadsen \r\nI gave it a shot to do this with a queuerunner, however I got stuck at some point, this is my current code\r\n```\r\n    BUCKET_BOUNDARIES = [2,4]\r\n    MAX_LEN = 6\r\n\r\n    def _to_sparse_tensor(self, sequences):\r\n \r\n          sp_indices = []\r\n          sp_vals = []\r\n          sp_shape = [len(sequences), self.MAX_LEN]\r\n \r\n          for i in range(0, len(sequences)):\r\n              for j in range(0, len(sequences[i])):\r\n                  sp_indices.append([i, j])\r\n                  sp_vals.append(sequences[i][j])\r\n \r\n          return tf.SparseTensor(indices=sp_indices, values=sp_vals, shape=sp_shape)\r\n\r\n      def __init__(self, batch_size=32, name='x-train'):\r\n \r\n          # load train corpus\r\n          sources, targets, lengths, validation_sources, validation_targets, validation_lengths = self._load_corpus()\r\n \r\n          print(\"Finished corpus loading\")\r\n          # to a constant tensor\r\n          source = self._to_sparse_tensor(sources)\r\n          target = self._to_sparse_tensor(targets)\r\n          length = tf.convert_to_tensor(np.asarray(lengths, dtype=np.int32))\r\n \r\n          input_queue = tf.train.shuffle_batch([length, source, target], batch_size,\r\n                                              batch_size*64, # capacity\r\n                                              batch_size*32, # min_after_dequeue\r\n                                              num_threads=32,\r\n                                              allow_smaller_final_batch=False, name=name)\r\n \r\n          lengths_t, sources_t, targets_t = input_queue\r\n\r\n          source_batch, target_batch = self.shuffle_bucket_batch(\r\n              lengths_t, [sources_t, targets_t],\r\n              batch_size=batch_size,\r\n              bucket_boundaries=self.BUCKET_BOUNDARIES,\r\n              # this will pad the source_batch and target_batch independently\r\n              dynamic_pad=True,\r\n              capacity=batch_size*64,\r\n              num_threads=32,\r\n              allow_smaller_final_batch=False, name=name\r\n          )\r\n```\r\n\r\nwhere `shuffle_bucket_batch` looks like this:\r\n```\r\ndef shuffle_bucket_batch(input_length, tensors, shuffle=True, **kwargs):\r\n    # the first argument is the sequence length specifed in the input_length\r\n    # I did not find a ue for it.\r\n    _, batch_tensors = tf.contrib.training.bucket_by_sequence_length(\r\n        input_length=input_length,\r\n        tensors=tensors,\r\n        **kwargs\r\n    )\r\n    return tuple(batch_tensors)\r\n```\r\nI've put the sources and targets into SparseArray (doing it manually, since I couldn't find a tf method similar to `convert_to_tensor` but for sparse data) so I can feed them into `shuffle_batch` queue (it can operate on SparseArrays), then I pass the outputs to the shuffle_bucket_batch.\r\n\r\nThe problem that I've hit is that I get some sort of dimension mismatch between the input_length and the amounts of buckets:\r\n`ValueError: Dimensions must be equal, but are 3 and 31978 for 'x-train_1/LessEqual' (op:'LessEqual') with input shapes: [3], [32,31978].`\r\n\r\nthe error happens at line 346 in this file: http://git.hiddenunit.com/hakan/tersorflow/blob/42d26aa7001dda6928771db8b4244067c7924a01/tensorflow/contrib/training/python/training/bucket_ops.py\r\n\r\nThe main difference with @AndreasMadsen is that I don't use `range_input_produce` since the input_lengths, sources and targets are batched together. \r\n\r\nIs it reasonable to use `SparseArray`, `shuffle_batch` and `bucket_by_sequence_length`? Any ideas why the dimension don't fit together?"}