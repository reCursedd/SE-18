{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260716613", "html_url": "https://github.com/tensorflow/tensorflow/issues/5609#issuecomment-260716613", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5609", "id": 260716613, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDcxNjYxMw==", "user": {"login": "sonalgupta", "id": 4138767, "node_id": "MDQ6VXNlcjQxMzg3Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/4138767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sonalgupta", "html_url": "https://github.com/sonalgupta", "followers_url": "https://api.github.com/users/sonalgupta/followers", "following_url": "https://api.github.com/users/sonalgupta/following{/other_user}", "gists_url": "https://api.github.com/users/sonalgupta/gists{/gist_id}", "starred_url": "https://api.github.com/users/sonalgupta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sonalgupta/subscriptions", "organizations_url": "https://api.github.com/users/sonalgupta/orgs", "repos_url": "https://api.github.com/users/sonalgupta/repos", "events_url": "https://api.github.com/users/sonalgupta/events{/privacy}", "received_events_url": "https://api.github.com/users/sonalgupta/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-15T17:58:45Z", "updated_at": "2016-11-15T19:18:43Z", "author_association": "NONE", "body_html": "<p>Also, the following code doesn't function as I would expect. I'm sure I am missing something, which is not clear from the documentation. Update: seems like the function is meant to bucket one input at a time? the documentation says <code>The list or dictionary of tensors, representing a single element, to bucket</code> .. I don't understand, when would I want to bucket/batch a single input? Also, for bucketing/batching multiple inputs (e.g. multiple sentences), do I call the function multiple times with different inputs?</p>\n<p>For the following code:</p>\n<pre><code>seq_lengths = np.array([6, 3, 2])\ninputs = []\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3])))\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\ninputs.append(tf.convert_to_tensor(np.array([3, 4])))\n\nsequences, output = bucket_by_sequence_length(input_length=seq_lengths, tensors= inputs, batch_size=2, bucket_boundaries =[1, 2], allow_smaller_final_batch=True,\n                                              dynamic_pad=True, capacity=2)\n\ninit_op = tf.initialize_all_variables()\n\nsess = tf.Session()\n\nsess.run(init_op)\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\ntry:\n    while not coord.should_stop():\n        s, o= sess.run([sequences, output])\n\nexcept tf.errors.OutOfRangeError:\n    print('Done training -- epoch limit reached')\nfinally:\n    coord.request_stop()\n\ncoord.join(threads)\nsess.close()\n</code></pre>\n<p><code>o</code> is <code>[array([[2, 3, 3, 3, 3, 3], [2, 3, 3, 3, 3, 3]]), array([[2, 3, 4], [2, 3, 4]]), array([[3, 4], [3, 4]])]</code> however, I was expecting the tensors of lengths 3 and 6 to be in the same bucket.</p>", "body_text": "Also, the following code doesn't function as I would expect. I'm sure I am missing something, which is not clear from the documentation. Update: seems like the function is meant to bucket one input at a time? the documentation says The list or dictionary of tensors, representing a single element, to bucket .. I don't understand, when would I want to bucket/batch a single input? Also, for bucketing/batching multiple inputs (e.g. multiple sentences), do I call the function multiple times with different inputs?\nFor the following code:\nseq_lengths = np.array([6, 3, 2])\ninputs = []\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3])))\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\ninputs.append(tf.convert_to_tensor(np.array([3, 4])))\n\nsequences, output = bucket_by_sequence_length(input_length=seq_lengths, tensors= inputs, batch_size=2, bucket_boundaries =[1, 2], allow_smaller_final_batch=True,\n                                              dynamic_pad=True, capacity=2)\n\ninit_op = tf.initialize_all_variables()\n\nsess = tf.Session()\n\nsess.run(init_op)\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\ntry:\n    while not coord.should_stop():\n        s, o= sess.run([sequences, output])\n\nexcept tf.errors.OutOfRangeError:\n    print('Done training -- epoch limit reached')\nfinally:\n    coord.request_stop()\n\ncoord.join(threads)\nsess.close()\n\no is [array([[2, 3, 3, 3, 3, 3], [2, 3, 3, 3, 3, 3]]), array([[2, 3, 4], [2, 3, 4]]), array([[3, 4], [3, 4]])] however, I was expecting the tensors of lengths 3 and 6 to be in the same bucket.", "body": "Also, the following code doesn't function as I would expect. I'm sure I am missing something, which is not clear from the documentation. Update: seems like the function is meant to bucket one input at a time? the documentation says `The list or dictionary of tensors, representing a single element, to bucket` .. I don't understand, when would I want to bucket/batch a single input? Also, for bucketing/batching multiple inputs (e.g. multiple sentences), do I call the function multiple times with different inputs?\n\nFor the following code:\n\n```\nseq_lengths = np.array([6, 3, 2])\ninputs = []\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3])))\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\ninputs.append(tf.convert_to_tensor(np.array([3, 4])))\n\nsequences, output = bucket_by_sequence_length(input_length=seq_lengths, tensors= inputs, batch_size=2, bucket_boundaries =[1, 2], allow_smaller_final_batch=True,\n                                              dynamic_pad=True, capacity=2)\n\ninit_op = tf.initialize_all_variables()\n\nsess = tf.Session()\n\nsess.run(init_op)\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\ntry:\n    while not coord.should_stop():\n        s, o= sess.run([sequences, output])\n\nexcept tf.errors.OutOfRangeError:\n    print('Done training -- epoch limit reached')\nfinally:\n    coord.request_stop()\n\ncoord.join(threads)\nsess.close()\n```\n\n`o` is `[array([[2, 3, 3, 3, 3, 3],\n       [2, 3, 3, 3, 3, 3]]), array([[2, 3, 4],\n       [2, 3, 4]]), array([[3, 4],\n       [3, 4]])]` however, I was expecting the tensors of lengths 3 and 6 to be in the same bucket.\n"}