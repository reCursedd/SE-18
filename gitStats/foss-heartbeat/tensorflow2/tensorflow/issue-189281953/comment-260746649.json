{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260746649", "html_url": "https://github.com/tensorflow/tensorflow/issues/5609#issuecomment-260746649", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5609", "id": 260746649, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDc0NjY0OQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-15T19:47:48Z", "updated_at": "2016-11-15T19:47:48Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Looking at the docs for the bucket_by_sequence_length function:</p>\n<p>bucket_boundaries: int list, <em>increasing</em> non-negative numbers. The edges<br>\nof the buckets to use when bucketing tensors. Two extra buckets are<br>\ncreated, one for input_length &lt; bucket_boundaries[0] and one for<br>\ninput_length &gt;= bucket_boundaries[-1].</p>\n<p>In your case if you had sequence_lengths [2, 3, 6] then you get 5 buckets:</p>\n<p>[len &lt; 2, 2 &lt;= len &lt; 3, 3 &lt;= len &lt; 6, len &gt;= 6]</p>\n<p>either way, you would need to set the last of the lengths to 7 in order to<br>\nget 3 and 6 in the same bucket.</p>\n<p>On Tue, Nov 15, 2016 at 9:59 AM, Sonal Gupta <a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\nwrote:</p>\n<blockquote>\n<p>Also, the following code doesn't function as I would expect. I'm sure I am<br>\nmissing something, which is not clear from the documentation.</p>\n<p>For the following code:</p>\n<p>`seq_lengths = np.array([6, 3, 2])<br>\ninputs = []<br>\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3])))<br>\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))<br>\ninputs.append(tf.convert_to_tensor(np.array([3, 4])))</p>\n<p>sequences, output = bucket_by_sequence_length(input_length=seq_lengths,<br>\ntensors= inputs, batch_size=2, bucket_boundaries =[1, 2],<br>\nallow_smaller_final_batch=True,<br>\ndynamic_pad=True, capacity=2)<br>\nCreate the graph, etc.</p>\n<p>init_op = tf.initialize_all_variables()<br>\nCreate a session for running operations in the Graph.</p>\n<p>sess = tf.Session()<br>\nInitialize the variables (like the epoch counter).</p>\n<p>sess.run(init_op)<br>\nStart input enqueue threads.</p>\n<p>coord = tf.train.Coordinator()<br>\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)</p>\n<p>try:<br>\nwhile not coord.should_stop():</p>\n<h1>Run training steps or whatever</h1>\n<p>s, o= sess.run([sequences, output])</p>\n<p>except tf.errors.OutOfRangeError:<br>\nprint('Done training -- epoch limit reached')<br>\nfinally:</p>\n<h1>When done, ask the threads to stop.</h1>\n<p>coord.request_stop()<br>\nWait for threads to finish.</p>\n<p>coord.join(threads)<br>\nsess.close()<br>\n`</p>\n<p>o is [array([[2, 3, 3, 3, 3, 3],<br>\n[2, 3, 3, 3, 3, 3]]), array([[2, 3, 4],<br>\n[2, 3, 4]]), array([[3, 4],<br>\n[3, 4]])] however, I was expecting the tensors of lengths 3 and 6 to be<br>\nin the same bucket.</p>\n<p>\u2014<br>\nYou are receiving this because you were mentioned.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"189281953\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5609\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5609/hovercard?comment_id=260716613&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/5609#issuecomment-260716613\">#5609 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim8hi_DovDpG7cHR4h5ba_mikNts_ks5q-fL5gaJpZM4KyDNA\">https://github.com/notifications/unsubscribe-auth/ABtim8hi_DovDpG7cHR4h5ba_mikNts_ks5q-fL5gaJpZM4KyDNA</a><br>\n.</p>\n</blockquote>", "body_text": "Looking at the docs for the bucket_by_sequence_length function:\nbucket_boundaries: int list, increasing non-negative numbers. The edges\nof the buckets to use when bucketing tensors. Two extra buckets are\ncreated, one for input_length < bucket_boundaries[0] and one for\ninput_length >= bucket_boundaries[-1].\nIn your case if you had sequence_lengths [2, 3, 6] then you get 5 buckets:\n[len < 2, 2 <= len < 3, 3 <= len < 6, len >= 6]\neither way, you would need to set the last of the lengths to 7 in order to\nget 3 and 6 in the same bucket.\nOn Tue, Nov 15, 2016 at 9:59 AM, Sonal Gupta notifications@github.com\nwrote:\n\nAlso, the following code doesn't function as I would expect. I'm sure I am\nmissing something, which is not clear from the documentation.\nFor the following code:\n`seq_lengths = np.array([6, 3, 2])\ninputs = []\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3])))\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\ninputs.append(tf.convert_to_tensor(np.array([3, 4])))\nsequences, output = bucket_by_sequence_length(input_length=seq_lengths,\ntensors= inputs, batch_size=2, bucket_boundaries =[1, 2],\nallow_smaller_final_batch=True,\ndynamic_pad=True, capacity=2)\nCreate the graph, etc.\ninit_op = tf.initialize_all_variables()\nCreate a session for running operations in the Graph.\nsess = tf.Session()\nInitialize the variables (like the epoch counter).\nsess.run(init_op)\nStart input enqueue threads.\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\ntry:\nwhile not coord.should_stop():\nRun training steps or whatever\ns, o= sess.run([sequences, output])\nexcept tf.errors.OutOfRangeError:\nprint('Done training -- epoch limit reached')\nfinally:\nWhen done, ask the threads to stop.\ncoord.request_stop()\nWait for threads to finish.\ncoord.join(threads)\nsess.close()\n`\no is [array([[2, 3, 3, 3, 3, 3],\n[2, 3, 3, 3, 3, 3]]), array([[2, 3, 4],\n[2, 3, 4]]), array([[3, 4],\n[3, 4]])] however, I was expecting the tensors of lengths 3 and 6 to be\nin the same bucket.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n#5609 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABtim8hi_DovDpG7cHR4h5ba_mikNts_ks5q-fL5gaJpZM4KyDNA\n.", "body": "Looking at the docs for the bucket_by_sequence_length function:\n\nbucket_boundaries: int list, _increasing_ non-negative numbers. The edges\nof the buckets to use when bucketing tensors. Two extra buckets are\ncreated, one for input_length < bucket_boundaries[0] and one for\ninput_length >= bucket_boundaries[-1].\n\nIn your case if you had sequence_lengths [2, 3, 6] then you get 5 buckets:\n\n[len < 2, 2 <= len < 3, 3 <= len < 6, len >= 6]\n\neither way, you would need to set the last of the lengths to 7 in order to\nget 3 and 6 in the same bucket.\n\nOn Tue, Nov 15, 2016 at 9:59 AM, Sonal Gupta notifications@github.com\nwrote:\n\n> Also, the following code doesn't function as I would expect. I'm sure I am\n> missing something, which is not clear from the documentation.\n> \n> For the following code:\n> \n> `seq_lengths = np.array([6, 3, 2])\n> inputs = []\n> inputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3])))\n> inputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\n> inputs.append(tf.convert_to_tensor(np.array([3, 4])))\n> \n> sequences, output = bucket_by_sequence_length(input_length=seq_lengths,\n> tensors= inputs, batch_size=2, bucket_boundaries =[1, 2],\n> allow_smaller_final_batch=True,\n> dynamic_pad=True, capacity=2)\n> Create the graph, etc.\n> \n> init_op = tf.initialize_all_variables()\n> Create a session for running operations in the Graph.\n> \n> sess = tf.Session()\n> Initialize the variables (like the epoch counter).\n> \n> sess.run(init_op)\n> Start input enqueue threads.\n> \n> coord = tf.train.Coordinator()\n> threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n> \n> try:\n> while not coord.should_stop():\n> \n> # Run training steps or whatever\n> \n> s, o= sess.run([sequences, output])\n> \n> except tf.errors.OutOfRangeError:\n> print('Done training -- epoch limit reached')\n> finally:\n> \n> # When done, ask the threads to stop.\n> \n> coord.request_stop()\n> Wait for threads to finish.\n> \n> coord.join(threads)\n> sess.close()\n> `\n> \n> o is [array([[2, 3, 3, 3, 3, 3],\n> [2, 3, 3, 3, 3, 3]]), array([[2, 3, 4],\n> [2, 3, 4]]), array([[3, 4],\n> [3, 4]])] however, I was expecting the tensors of lengths 3 and 6 to be\n> in the same bucket.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/5609#issuecomment-260716613,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim8hi_DovDpG7cHR4h5ba_mikNts_ks5q-fL5gaJpZM4KyDNA\n> .\n"}