{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/310998192", "html_url": "https://github.com/tensorflow/tensorflow/issues/10961#issuecomment-310998192", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10961", "id": 310998192, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDk5ODE5Mg==", "user": {"login": "Vargeel", "id": 7975891, "node_id": "MDQ6VXNlcjc5NzU4OTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/7975891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Vargeel", "html_url": "https://github.com/Vargeel", "followers_url": "https://api.github.com/users/Vargeel/followers", "following_url": "https://api.github.com/users/Vargeel/following{/other_user}", "gists_url": "https://api.github.com/users/Vargeel/gists{/gist_id}", "starred_url": "https://api.github.com/users/Vargeel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Vargeel/subscriptions", "organizations_url": "https://api.github.com/users/Vargeel/orgs", "repos_url": "https://api.github.com/users/Vargeel/repos", "events_url": "https://api.github.com/users/Vargeel/events{/privacy}", "received_events_url": "https://api.github.com/users/Vargeel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-26T08:40:54Z", "updated_at": "2017-06-26T08:40:54Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5453737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tatatodd\">@tatatodd</a> , sorry if my issue is confusing, I wrote it after quite a long few days of hitting that problem so I might have been a bit unclear.</p>\n<p><strong>### System information</strong><br>\n2 machines have been tested with this code and raised similar issues :</p>\n<ul>\n<li>\n<p>64Gb RAM/ Intel i7 6800K CPu / 2 x Geforce GTX 1080 / Ubuntu 16.04 64 bits</p>\n</li>\n<li>\n<p>64Gb RAM/ Intel(R) Core(TM) i7-6850K CPU / 4 x Geforce GTX 1080ti / Ubuntu 16.04 64 bits</p>\n</li>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes, I have written a large part of the code, some of it comes from external sources as well.</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nUbuntu 16.04 64 bits</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\ntried from pip version and from sources. Problem remained on both.</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\n('v1.2.0-1126-gb7acb6a', '1.2.0') and ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\nBuild label: 0.5.1</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nCUDA : 8.0<br>\ncuDNN : tested both 5.1 / 6.0</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:<br>\nGTX 1080 and GTX 1080ti</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\ndifficult to provide as this stems from my code.</p>\n</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The problem arose while I was trying to make my training process take advantage of the multi GPU systems I have. Initially, my model was running on GPU 0 with no problems even after 500k iterations. I used the CIFAR10 example to build the model on each GPU but was met with the error : \"cudaCheckError() failed : invalid resource handle\".<br>\nAfter more testing I realized that even if I ran the training on a single GPU, as long as that GPU was not GPU 0, it would crash eventually with a similar error.<br>\nThe errors I have observed are not always consistent, but they always appear when GPU 1 ( or any GPU other than 0) is being used.<br>\nAfter more testing I have narrowed down the part of the code that seems to cause the crash to the line :<br>\n<code>tf.reshape(tf.py_func(proposal_layer_py,[input[0],input[1],input[2], cfg_key, _feat_stride, anchor_scales], [tf.float32]),[-1,5],name =name)</code></p>\n<p>I have put every other operation of the graph on different GPUs without problems but when I do not force this one to be computed on GPU 0 it seems to cause the crash.</p>\n<h3>Source code / logs</h3>\n<p>included in the previous message.</p>\n<p>I hope this clarifies my problem. If you need more, I could try to build a very lightweight model that demonstrates the same issue. I have not done so yet.</p>", "body_text": "Hi @tatatodd , sorry if my issue is confusing, I wrote it after quite a long few days of hitting that problem so I might have been a bit unclear.\n### System information\n2 machines have been tested with this code and raised similar issues :\n\n\n64Gb RAM/ Intel i7 6800K CPu / 2 x Geforce GTX 1080 / Ubuntu 16.04 64 bits\n\n\n64Gb RAM/ Intel(R) Core(TM) i7-6850K CPU / 4 x Geforce GTX 1080ti / Ubuntu 16.04 64 bits\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes, I have written a large part of the code, some of it comes from external sources as well.\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nUbuntu 16.04 64 bits\n\n\nTensorFlow installed from (source or binary):\ntried from pip version and from sources. Problem remained on both.\n\n\nTensorFlow version (use command below):\n('v1.2.0-1126-gb7acb6a', '1.2.0') and ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\n\n\nBazel version (if compiling from source):\nBuild label: 0.5.1\n\n\nCUDA/cuDNN version:\nCUDA : 8.0\ncuDNN : tested both 5.1 / 6.0\n\n\nGPU model and memory:\nGTX 1080 and GTX 1080ti\n\n\nExact command to reproduce:\ndifficult to provide as this stems from my code.\n\n\nDescribe the problem\nThe problem arose while I was trying to make my training process take advantage of the multi GPU systems I have. Initially, my model was running on GPU 0 with no problems even after 500k iterations. I used the CIFAR10 example to build the model on each GPU but was met with the error : \"cudaCheckError() failed : invalid resource handle\".\nAfter more testing I realized that even if I ran the training on a single GPU, as long as that GPU was not GPU 0, it would crash eventually with a similar error.\nThe errors I have observed are not always consistent, but they always appear when GPU 1 ( or any GPU other than 0) is being used.\nAfter more testing I have narrowed down the part of the code that seems to cause the crash to the line :\ntf.reshape(tf.py_func(proposal_layer_py,[input[0],input[1],input[2], cfg_key, _feat_stride, anchor_scales], [tf.float32]),[-1,5],name =name)\nI have put every other operation of the graph on different GPUs without problems but when I do not force this one to be computed on GPU 0 it seems to cause the crash.\nSource code / logs\nincluded in the previous message.\nI hope this clarifies my problem. If you need more, I could try to build a very lightweight model that demonstrates the same issue. I have not done so yet.", "body": "Hi @tatatodd , sorry if my issue is confusing, I wrote it after quite a long few days of hitting that problem so I might have been a bit unclear. \r\n\r\n\r\n**### System information**\r\n2 machines have been tested with this code and raised similar issues : \r\n\r\n- 64Gb RAM/ Intel i7 6800K CPu / 2 x Geforce GTX 1080 / Ubuntu 16.04 64 bits \r\n- 64Gb RAM/ Intel(R) Core(TM) i7-6850K CPU / 4 x Geforce GTX 1080ti / Ubuntu 16.04 64 bits \r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes, I have written a large part of the code, some of it comes from external sources as well. \r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04 64 bits\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\ntried from pip version and from sources. Problem remained on both.\r\n\r\n- **TensorFlow version (use command below)**:\r\n('v1.2.0-1126-gb7acb6a', '1.2.0') and ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\r\n\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.5.1\r\n\r\n- **CUDA/cuDNN version**:\r\nCUDA : 8.0 \r\ncuDNN : tested both 5.1 / 6.0 \r\n\r\n- **GPU model and memory**:\r\nGTX 1080 and GTX 1080ti\r\n\r\n- **Exact command to reproduce**:\r\ndifficult to provide as this stems from my code.\r\n\r\n### Describe the problem\r\nThe problem arose while I was trying to make my training process take advantage of the multi GPU systems I have. Initially, my model was running on GPU 0 with no problems even after 500k iterations. I used the CIFAR10 example to build the model on each GPU but was met with the error : \"cudaCheckError() failed : invalid resource handle\".\r\nAfter more testing I realized that even if I ran the training on a single GPU, as long as that GPU was not GPU 0, it would crash eventually with a similar error. \r\nThe errors I have observed are not always consistent, but they always appear when GPU 1 ( or any GPU other than 0) is being used. \r\nAfter more testing I have narrowed down the part of the code that seems to cause the crash to the line : \r\n`tf.reshape(tf.py_func(proposal_layer_py,[input[0],input[1],input[2], cfg_key, _feat_stride, anchor_scales], [tf.float32]),[-1,5],name =name)`\r\n \r\nI have put every other operation of the graph on different GPUs without problems but when I do not force this one to be computed on GPU 0 it seems to cause the crash. \r\n\r\n\r\n### Source code / logs\r\nincluded in the previous message. \r\n\r\nI hope this clarifies my problem. If you need more, I could try to build a very lightweight model that demonstrates the same issue. I have not done so yet. \r\n\r\n"}