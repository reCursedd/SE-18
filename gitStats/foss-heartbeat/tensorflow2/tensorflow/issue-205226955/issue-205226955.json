{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7246", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7246/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7246/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7246/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7246", "id": 205226955, "node_id": "MDU6SXNzdWUyMDUyMjY5NTU=", "number": 7246, "title": "Pool Allocator Problem", "user": {"login": "nitintarget", "id": 25534683, "node_id": "MDQ6VXNlcjI1NTM0Njgz", "avatar_url": "https://avatars1.githubusercontent.com/u/25534683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nitintarget", "html_url": "https://github.com/nitintarget", "followers_url": "https://api.github.com/users/nitintarget/followers", "following_url": "https://api.github.com/users/nitintarget/following{/other_user}", "gists_url": "https://api.github.com/users/nitintarget/gists{/gist_id}", "starred_url": "https://api.github.com/users/nitintarget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nitintarget/subscriptions", "organizations_url": "https://api.github.com/users/nitintarget/orgs", "repos_url": "https://api.github.com/users/nitintarget/repos", "events_url": "https://api.github.com/users/nitintarget/events{/privacy}", "received_events_url": "https://api.github.com/users/nitintarget/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-02-03T18:00:21Z", "updated_at": "2018-02-08T01:03:20Z", "closed_at": "2018-02-08T01:03:20Z", "author_association": "NONE", "body_html": "<p>I was running LSTM having 2 layers and 64 nodes in each layer running in batch mode with small data size. I am unable to figure out the problem. I am getting warning like</p>\n<p>tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1323 get requests, put_count=2336 evicted_count=1000 eviction_rate=0.428082 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 6326 get requests, put_count=5369 evicted_count=2000 eviction_rate=0.372509 and unsatisfied allocation rate=0.470123<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 193 to 212<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1415 get requests, put_count=2440 evicted_count=1000 eviction_rate=0.409836 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1590 get requests, put_count=3623 evicted_count=2000 eviction_rate=0.552029 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1137 get requests, put_count=2186 evicted_count=1000 eviction_rate=0.457457 and unsatisfied allocation rate=0</p>\n<p>Because of which code runs very slow.</p>\n<p><strong>Machine 1</strong><br>\nConfiguration as follows:<br>\nEnvironment Information (we've tried several different permutations):<br>\nOS: CentOS 7.2<br>\nCUDA: 8.0.44 and 7.5.17<br>\nCUDNN: 5.1 and 5.0<br>\nTensorflow: 0.11.0rc0, 0.11.0, 0.12.1, 1.0.0rc0<br>\nNvidia drivers: 352.39, 367.48<br>\nGPU:Tesla k80<br>\nservers with 2 K80 cards each (2 GPUs per card, for a total of 4 GPUs per machine).</p>\n<p>If I run the same code on different machine the code runs fine without any warning:<br>\n<strong>Machine 2</strong><br>\nOS:Ubuntu 16.04.1 LTS<br>\nCUDA: 8.0<br>\nCUDNN: 5.0<br>\nTensorflow:0.12.1<br>\nNvidia drivers: 367.48<br>\nGPU:GeForce GTX TITAN.</p>", "body_text": "I was running LSTM having 2 layers and 64 nodes in each layer running in batch mode with small data size. I am unable to figure out the problem. I am getting warning like\ntensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1323 get requests, put_count=2336 evicted_count=1000 eviction_rate=0.428082 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 6326 get requests, put_count=5369 evicted_count=2000 eviction_rate=0.372509 and unsatisfied allocation rate=0.470123\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 193 to 212\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1415 get requests, put_count=2440 evicted_count=1000 eviction_rate=0.409836 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1590 get requests, put_count=3623 evicted_count=2000 eviction_rate=0.552029 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1137 get requests, put_count=2186 evicted_count=1000 eviction_rate=0.457457 and unsatisfied allocation rate=0\nBecause of which code runs very slow.\nMachine 1\nConfiguration as follows:\nEnvironment Information (we've tried several different permutations):\nOS: CentOS 7.2\nCUDA: 8.0.44 and 7.5.17\nCUDNN: 5.1 and 5.0\nTensorflow: 0.11.0rc0, 0.11.0, 0.12.1, 1.0.0rc0\nNvidia drivers: 352.39, 367.48\nGPU:Tesla k80\nservers with 2 K80 cards each (2 GPUs per card, for a total of 4 GPUs per machine).\nIf I run the same code on different machine the code runs fine without any warning:\nMachine 2\nOS:Ubuntu 16.04.1 LTS\nCUDA: 8.0\nCUDNN: 5.0\nTensorflow:0.12.1\nNvidia drivers: 367.48\nGPU:GeForce GTX TITAN.", "body": "I was running LSTM having 2 layers and 64 nodes in each layer running in batch mode with small data size. I am unable to figure out the problem. I am getting warning like \r\n\r\n tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1323 get requests, put_count=2336 evicted_count=1000 eviction_rate=0.428082 and unsatisfied allocation rate=0\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 6326 get requests, put_count=5369 evicted_count=2000 eviction_rate=0.372509 and unsatisfied allocation rate=0.470123\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 193 to 212\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1415 get requests, put_count=2440 evicted_count=1000 eviction_rate=0.409836 and unsatisfied allocation rate=0\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1590 get requests, put_count=3623 evicted_count=2000 eviction_rate=0.552029 and unsatisfied allocation rate=0\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1137 get requests, put_count=2186 evicted_count=1000 eviction_rate=0.457457 and unsatisfied allocation rate=0\r\n\r\nBecause of which code runs very slow.\r\n\r\n**Machine 1**\r\nConfiguration as follows:\r\nEnvironment Information (we've tried several different permutations):\r\nOS: CentOS 7.2\r\nCUDA: 8.0.44 and 7.5.17\r\nCUDNN: 5.1 and 5.0\r\nTensorflow: 0.11.0rc0, 0.11.0, 0.12.1, 1.0.0rc0\r\nNvidia drivers: 352.39, 367.48\r\nGPU:Tesla k80\r\nservers with 2 K80 cards each (2 GPUs per card, for a total of 4 GPUs per machine).\r\n\r\nIf I run the same code on different machine the code runs fine without any warning:\r\n**Machine 2**\r\nOS:Ubuntu 16.04.1 LTS\r\nCUDA: 8.0\r\nCUDNN: 5.0\r\nTensorflow:0.12.1\r\nNvidia drivers: 367.48\r\nGPU:GeForce GTX TITAN.\r\n"}