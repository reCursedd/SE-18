{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/419639306", "html_url": "https://github.com/tensorflow/tensorflow/issues/22108#issuecomment-419639306", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22108", "id": 419639306, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTYzOTMwNg==", "user": {"login": "Q82822", "id": 36806042, "node_id": "MDQ6VXNlcjM2ODA2MDQy", "avatar_url": "https://avatars2.githubusercontent.com/u/36806042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Q82822", "html_url": "https://github.com/Q82822", "followers_url": "https://api.github.com/users/Q82822/followers", "following_url": "https://api.github.com/users/Q82822/following{/other_user}", "gists_url": "https://api.github.com/users/Q82822/gists{/gist_id}", "starred_url": "https://api.github.com/users/Q82822/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Q82822/subscriptions", "organizations_url": "https://api.github.com/users/Q82822/orgs", "repos_url": "https://api.github.com/users/Q82822/repos", "events_url": "https://api.github.com/users/Q82822/events{/privacy}", "received_events_url": "https://api.github.com/users/Q82822/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-08T12:41:29Z", "updated_at": "2018-09-09T04:21:25Z", "author_association": "NONE", "body_html": "<p>the minimal code at  here , it is just part of my project code. the inpout is word_index.<br>\nthe batch size = 64<br>\nuse tf-nightly-gpu.<br>\nplatform = jupyter notebook.<br>\nin first batch size was worked, but in next batch train will be \"nan\". but this problem only happen in \"tf-nightly-gpu\"</p>\n<pre><code>class  RNN_Decoder(tf.keras.Model):\n    def __init__(self, embedding_dim, units, vocab_size):\n        super(RNN_Decoder, self).__init__()\n        self.units = units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    def call(self, x, features, hidden):\n        print('embedding_input:  ', x)\n        x = self.embedding(x)\n        print('embedding_output:  ', x)\n\ndecoder = RNN_Decoder(embedding_dim, units, vocab_size)\n\nfor epoch in range(20):\n    hidden = decoder.reset_state(batch_size=64)\n    dec_input = tf.expand_dims([tokenizer.word_index['&lt;start&gt;']] * BATCH_SIZE, 1)\n        with tf.GradientTape() as tape:\n            features = encoder(img_tensor)\n            for i in range(1, target.shape[1])\n            predictions, hidden, _ = decoder(dec_input, features, hidden)\n</code></pre>", "body_text": "the minimal code at  here , it is just part of my project code. the inpout is word_index.\nthe batch size = 64\nuse tf-nightly-gpu.\nplatform = jupyter notebook.\nin first batch size was worked, but in next batch train will be \"nan\". but this problem only happen in \"tf-nightly-gpu\"\nclass  RNN_Decoder(tf.keras.Model):\n    def __init__(self, embedding_dim, units, vocab_size):\n        super(RNN_Decoder, self).__init__()\n        self.units = units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    def call(self, x, features, hidden):\n        print('embedding_input:  ', x)\n        x = self.embedding(x)\n        print('embedding_output:  ', x)\n\ndecoder = RNN_Decoder(embedding_dim, units, vocab_size)\n\nfor epoch in range(20):\n    hidden = decoder.reset_state(batch_size=64)\n    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n        with tf.GradientTape() as tape:\n            features = encoder(img_tensor)\n            for i in range(1, target.shape[1])\n            predictions, hidden, _ = decoder(dec_input, features, hidden)", "body": "the minimal code at  here , it is just part of my project code. the inpout is word_index.\r\nthe batch size = 64  \r\nuse tf-nightly-gpu.\r\nplatform = jupyter notebook.\r\nin first batch size was worked, but in next batch train will be \"nan\". but this problem only happen in \"tf-nightly-gpu\"\r\n```\r\nclass  RNN_Decoder(tf.keras.Model):\r\n    def __init__(self, embedding_dim, units, vocab_size):\r\n        super(RNN_Decoder, self).__init__()\r\n        self.units = units\r\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n    def call(self, x, features, hidden):\r\n        print('embedding_input:  ', x)\r\n        x = self.embedding(x)\r\n        print('embedding_output:  ', x)\r\n\r\ndecoder = RNN_Decoder(embedding_dim, units, vocab_size)\r\n\r\nfor epoch in range(20):\r\n    hidden = decoder.reset_state(batch_size=64)\r\n    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\r\n        with tf.GradientTape() as tape:\r\n            features = encoder(img_tensor)\r\n            for i in range(1, target.shape[1])\r\n            predictions, hidden, _ = decoder(dec_input, features, hidden)\r\n```"}