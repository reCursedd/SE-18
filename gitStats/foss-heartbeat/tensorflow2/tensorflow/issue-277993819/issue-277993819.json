{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14985", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14985/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14985/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14985/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14985", "id": 277993819, "node_id": "MDU6SXNzdWUyNzc5OTM4MTk=", "number": 14985, "title": "tf.nn.fractional_max_pool output have same batch size when feed with different input batch size", "user": {"login": "balconychy", "id": 7106367, "node_id": "MDQ6VXNlcjcxMDYzNjc=", "avatar_url": "https://avatars1.githubusercontent.com/u/7106367?v=4", "gravatar_id": "", "url": "https://api.github.com/users/balconychy", "html_url": "https://github.com/balconychy", "followers_url": "https://api.github.com/users/balconychy/followers", "following_url": "https://api.github.com/users/balconychy/following{/other_user}", "gists_url": "https://api.github.com/users/balconychy/gists{/gist_id}", "starred_url": "https://api.github.com/users/balconychy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/balconychy/subscriptions", "organizations_url": "https://api.github.com/users/balconychy/orgs", "repos_url": "https://api.github.com/users/balconychy/repos", "events_url": "https://api.github.com/users/balconychy/events{/privacy}", "received_events_url": "https://api.github.com/users/balconychy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-11-30T04:20:21Z", "updated_at": "2018-01-09T21:37:07Z", "closed_at": "2018-01-05T14:05:19Z", "author_association": "NONE", "body_html": "<h3>Describe the problem</h3>\n<p>tf.nn.fractional_max_pool output have same batch size when feed with different input batch size.<br>\nAttached is test code I write. 2 different input is feed in with different batch size , outputs get same batch size.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/1516498/pool_test.py.txt\">pool_test.py.txt</a></p>\n<p>###code result<br>\nshape of input_a (3, 32, 32, 3)<br>\nshape of output_a (3, 21, 21, 3)<br>\nshape of input_b <strong>(4, 32, 32, 3)</strong><br>\nshape of output_b <strong>(3, 21, 21, 3)</strong></p>\n<h3>System information</h3>\n<p>== cat /etc/issue ===============================================<br>\nLinux c-1080u 4.10.0-40-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115981575\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/44\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/44/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/44\">#44</a>~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux c-1080u 4.10.0-40-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115981575\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/44\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/44/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/44\">#44</a>~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy (1.13.3)<br>\nnumpydoc (0.7.0)</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\nTraceback (most recent call last):<br>\nFile \"\", line 1, in <br>\nModuleNotFoundError: No module named 'tensorflow'</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nThu Nov 30 11:55:40 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |<br>\n|  0%   51C    P8    21W / 280W |    860MiB / 11169MiB |      9%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |<br>\n|    0      1540      G   compiz                                       315MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61</p>\n<p>== cat /etc/issue ===============================================<br>\nLinux c-1080u 4.10.0-40-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115981575\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/44\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/44/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/44\">#44</a>~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux c-1080u 4.10.0-40-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115981575\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/44\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/44/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/44\">#44</a>~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy (1.13.3)<br>\nprotobuf (3.5.0.post1)<br>\ntensorflow-gpu (1.4.0)<br>\ntensorflow-tensorboard (0.4.0rc3)</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.4.0<br>\ntf.GIT_VERSION = v1.4.0-rc1-11-g130a514<br>\ntf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nThu Nov 30 11:56:18 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |<br>\n|  0%   51C    P0    80W / 280W |    860MiB / 11169MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |<br>\n|    0      1540      G   compiz                                       315MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61</p>", "body_text": "Describe the problem\ntf.nn.fractional_max_pool output have same batch size when feed with different input batch size.\nAttached is test code I write. 2 different input is feed in with different batch size , outputs get same batch size.\npool_test.py.txt\n###code result\nshape of input_a (3, 32, 32, 3)\nshape of output_a (3, 21, 21, 3)\nshape of input_b (4, 32, 32, 3)\nshape of output_b (3, 21, 21, 3)\nSystem information\n== cat /etc/issue ===============================================\nLinux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy (1.13.3)\nnumpydoc (0.7.0)\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\nTraceback (most recent call last):\nFile \"\", line 1, in \nModuleNotFoundError: No module named 'tensorflow'\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nThu Nov 30 11:55:40 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\n|  0%   51C    P8    21W / 280W |    860MiB / 11169MiB |      9%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |\n|    0      1540      G   compiz                                       315MiB |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n== cat /etc/issue ===============================================\nLinux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy (1.13.3)\nprotobuf (3.5.0.post1)\ntensorflow-gpu (1.4.0)\ntensorflow-tensorboard (0.4.0rc3)\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.4.0\ntf.GIT_VERSION = v1.4.0-rc1-11-g130a514\ntf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nThu Nov 30 11:56:18 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\n|  0%   51C    P0    80W / 280W |    860MiB / 11169MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |\n|    0      1540      G   compiz                                       315MiB |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61", "body": "\r\n### Describe the problem\r\ntf.nn.fractional_max_pool output have same batch size when feed with different input batch size.\r\nAttached is test code I write. 2 different input is feed in with different batch size , outputs get same batch size.\r\n[pool_test.py.txt](https://github.com/tensorflow/tensorflow/files/1516498/pool_test.py.txt)\r\n\r\n###code result\r\nshape of input_a (3, 32, 32, 3)\r\nshape of output_a (3, 21, 21, 3)\r\nshape of input_b **(4, 32, 32, 3)**\r\nshape of output_b **(3, 21, 21, 3)**\r\n\r\n### System information\r\n\r\n== cat /etc/issue ===============================================\r\nLinux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nnumpydoc (0.7.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow'\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nThu Nov 30 11:55:40 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\r\n|  0%   51C    P8    21W / 280W |    860MiB / 11169MiB |      9%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |\r\n|    0      1540      G   compiz                                       315MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n\r\n== cat /etc/issue ===============================================\r\nLinux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.5.0.post1)\r\ntensorflow-gpu (1.4.0)\r\ntensorflow-tensorboard (0.4.0rc3)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.4.0\r\ntf.GIT_VERSION = v1.4.0-rc1-11-g130a514\r\ntf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nThu Nov 30 11:56:18 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\r\n|  0%   51C    P0    80W / 280W |    860MiB / 11169MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |\r\n|    0      1540      G   compiz                                       315MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n\r\n\r\n\r\n\r\n"}