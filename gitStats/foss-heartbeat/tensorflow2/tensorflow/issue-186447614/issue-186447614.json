{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5316", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5316/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5316/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5316/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5316", "id": 186447614, "node_id": "MDU6SXNzdWUxODY0NDc2MTQ=", "number": 5316, "title": "Invalid argument when accessing HDFS", "user": {"login": "tobegit3hub", "id": 2715000, "node_id": "MDQ6VXNlcjI3MTUwMDA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2715000?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tobegit3hub", "html_url": "https://github.com/tobegit3hub", "followers_url": "https://api.github.com/users/tobegit3hub/followers", "following_url": "https://api.github.com/users/tobegit3hub/following{/other_user}", "gists_url": "https://api.github.com/users/tobegit3hub/gists{/gist_id}", "starred_url": "https://api.github.com/users/tobegit3hub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tobegit3hub/subscriptions", "organizations_url": "https://api.github.com/users/tobegit3hub/orgs", "repos_url": "https://api.github.com/users/tobegit3hub/repos", "events_url": "https://api.github.com/users/tobegit3hub/events{/privacy}", "received_events_url": "https://api.github.com/users/tobegit3hub/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jhseu", "id": 170179, "node_id": "MDQ6VXNlcjE3MDE3OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/170179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhseu", "html_url": "https://github.com/jhseu", "followers_url": "https://api.github.com/users/jhseu/followers", "following_url": "https://api.github.com/users/jhseu/following{/other_user}", "gists_url": "https://api.github.com/users/jhseu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhseu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhseu/subscriptions", "organizations_url": "https://api.github.com/users/jhseu/orgs", "repos_url": "https://api.github.com/users/jhseu/repos", "events_url": "https://api.github.com/users/jhseu/events{/privacy}", "received_events_url": "https://api.github.com/users/jhseu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jhseu", "id": 170179, "node_id": "MDQ6VXNlcjE3MDE3OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/170179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhseu", "html_url": "https://github.com/jhseu", "followers_url": "https://api.github.com/users/jhseu/followers", "following_url": "https://api.github.com/users/jhseu/following{/other_user}", "gists_url": "https://api.github.com/users/jhseu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhseu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhseu/subscriptions", "organizations_url": "https://api.github.com/users/jhseu/orgs", "repos_url": "https://api.github.com/users/jhseu/repos", "events_url": "https://api.github.com/users/jhseu/events{/privacy}", "received_events_url": "https://api.github.com/users/jhseu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2016-11-01T02:18:23Z", "updated_at": "2016-11-03T07:36:46Z", "closed_at": "2016-11-03T01:59:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p>We have installed pseudo-distributed HDFS in local and use the default port, 9000. We follow the example code from <code>https://github.com/tensorflow/tensorflow/issues/2218</code> but it throws <code>InvalidArgumentError</code>.</p>\n<p>Our code looks like this and it works if we change to local filesystem.</p>\n<pre><code>hdfs_path = \"hdfs://127.0.0.1:9000/cancer_train.csv.tfrecords\"\nfilename_queue = tf.train.string_input_producer(\n    tf.train.match_filenames_once(hdfs_path),\n    num_epochs=epoch_number)\nlabel, features = read_and_decode(filename_queue)\nbatch_labels, batch_features = tf.train.shuffle_batch(\n    [label, features],\n    batch_size=batch_size,\n    num_threads=thread_number,\n    capacity=capacity,\n    min_after_dequeue=min_after_dequeue)\n</code></pre>\n<p>And the error log looks like this.</p>\n<pre><code>hdfsGetPathInfo(): constructNewObjectOfPath error:\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\n        at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:134)\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\nhdfsGetPathInfo(): constructNewObjectOfPath error:\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\n        at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:134)\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\nhdfsGetPathInfo(): constructNewObjectOfPath error:\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\n        at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:134)\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\nhdfsGetPathInfo(): constructNewObjectOfPath error:\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\n        at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:134)\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\nTraceback (most recent call last):\n  File \"./hdfs.py\", line 237, in &lt;module&gt;\n    sess.run(init_op)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: hdfs://127.0.0.1:9000\n         [[Node: matching_filenames/MatchingFiles = MatchingFiles[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](matching_filenames/MatchingFiles/pattern)]]\n         [[Node: matching_filenames_1/Assign/_6 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send\n_device_incarnation=1, tensor_name=\"edge_117_matching_filenames_1/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n</code></pre>\n<h3>Environment info</h3>\n<p>Operating System: CentOS 7.0<br>\nTensorFlow: 0.11.0rc1</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>", "body_text": "We have installed pseudo-distributed HDFS in local and use the default port, 9000. We follow the example code from https://github.com/tensorflow/tensorflow/issues/2218 but it throws InvalidArgumentError.\nOur code looks like this and it works if we change to local filesystem.\nhdfs_path = \"hdfs://127.0.0.1:9000/cancer_train.csv.tfrecords\"\nfilename_queue = tf.train.string_input_producer(\n    tf.train.match_filenames_once(hdfs_path),\n    num_epochs=epoch_number)\nlabel, features = read_and_decode(filename_queue)\nbatch_labels, batch_features = tf.train.shuffle_batch(\n    [label, features],\n    batch_size=batch_size,\n    num_threads=thread_number,\n    capacity=capacity,\n    min_after_dequeue=min_after_dequeue)\n\nAnd the error log looks like this.\nhdfsGetPathInfo(): constructNewObjectOfPath error:\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\n        at org.apache.hadoop.fs.Path.<init>(Path.java:134)\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\nhdfsGetPathInfo(): constructNewObjectOfPath error:\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\n        at org.apache.hadoop.fs.Path.<init>(Path.java:134)\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\nhdfsGetPathInfo(): constructNewObjectOfPath error:\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\n        at org.apache.hadoop.fs.Path.<init>(Path.java:134)\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\nhdfsGetPathInfo(): constructNewObjectOfPath error:\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\n        at org.apache.hadoop.fs.Path.<init>(Path.java:134)\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\nTraceback (most recent call last):\n  File \"./hdfs.py\", line 237, in <module>\n    sess.run(init_op)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: hdfs://127.0.0.1:9000\n         [[Node: matching_filenames/MatchingFiles = MatchingFiles[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](matching_filenames/MatchingFiles/pattern)]]\n         [[Node: matching_filenames_1/Assign/_6 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send\n_device_incarnation=1, tensor_name=\"edge_117_matching_filenames_1/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nEnvironment info\nOperating System: CentOS 7.0\nTensorFlow: 0.11.0rc1\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).", "body": "We have installed pseudo-distributed HDFS in local and use the default port, 9000. We follow the example code from `https://github.com/tensorflow/tensorflow/issues/2218` but it throws `InvalidArgumentError`.\r\n\r\nOur code looks like this and it works if we change to local filesystem.\r\n\r\n```\r\nhdfs_path = \"hdfs://127.0.0.1:9000/cancer_train.csv.tfrecords\"\r\nfilename_queue = tf.train.string_input_producer(\r\n    tf.train.match_filenames_once(hdfs_path),\r\n    num_epochs=epoch_number)\r\nlabel, features = read_and_decode(filename_queue)\r\nbatch_labels, batch_features = tf.train.shuffle_batch(\r\n    [label, features],\r\n    batch_size=batch_size,\r\n    num_threads=thread_number,\r\n    capacity=capacity,\r\n    min_after_dequeue=min_after_dequeue)\r\n```\r\n\r\nAnd the error log looks like this.\r\n\r\n```\r\nhdfsGetPathInfo(): constructNewObjectOfPath error:\r\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\r\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\r\n        at org.apache.hadoop.fs.Path.<init>(Path.java:134)\r\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\r\nhdfsGetPathInfo(): constructNewObjectOfPath error:\r\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\r\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\r\n        at org.apache.hadoop.fs.Path.<init>(Path.java:134)\r\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\r\nhdfsGetPathInfo(): constructNewObjectOfPath error:\r\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\r\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\r\n        at org.apache.hadoop.fs.Path.<init>(Path.java:134)\r\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\r\nhdfsGetPathInfo(): constructNewObjectOfPath error:\r\njava.lang.IllegalArgumentException: Can not create a Path from an empty string\r\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)\r\n        at org.apache.hadoop.fs.Path.<init>(Path.java:134)\r\nW tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000\r\nTraceback (most recent call last):\r\n  File \"./hdfs.py\", line 237, in <module>\r\n    sess.run(init_op)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors.InvalidArgumentError: hdfs://127.0.0.1:9000\r\n         [[Node: matching_filenames/MatchingFiles = MatchingFiles[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](matching_filenames/MatchingFiles/pattern)]]\r\n         [[Node: matching_filenames_1/Assign/_6 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send\r\n_device_incarnation=1, tensor_name=\"edge_117_matching_filenames_1/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n```\r\n\r\n### Environment info\r\nOperating System: CentOS 7.0\r\nTensorFlow: 0.11.0rc1\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n"}