{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335078496", "html_url": "https://github.com/tensorflow/tensorflow/issues/13461#issuecomment-335078496", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13461", "id": 335078496, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTA3ODQ5Ng==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-09T07:00:59Z", "updated_at": "2017-10-09T07:00:59Z", "author_association": "MEMBER", "body_html": "<p>The checkpoint should certainly be loadable. The provided snippet isn't sufficient to help reproduce the problem. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=22005397\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/DarcyCode\">@DarcyCode</a> could you please fill in the complete issue template, including instructions to reproduce the problem?</p>\n<p>Simply using the <code>batch_norm</code> function you've provided above and with the following snippet, I do not see any difference in variables names with or without GPU:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">batch_norm</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">beta</span>, <span class=\"pl-smi\">gamma</span>, <span class=\"pl-smi\">train_phase</span>, <span class=\"pl-smi\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>bn<span class=\"pl-pds\">'</span></span>, <span class=\"pl-smi\">decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.9</span>, <span class=\"pl-smi\">eps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-5</span>):\n    <span class=\"pl-k\">with</span> tf.variable_scope(scope):        \n        batch_mean, batch_var <span class=\"pl-k\">=</span> tf.nn.moments(x, [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>moments<span class=\"pl-pds\">'</span></span>)\n        ema <span class=\"pl-k\">=</span> tf.train.ExponentialMovingAverage(<span class=\"pl-v\">decay</span><span class=\"pl-k\">=</span>decay)\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">mean_var_with_update</span>():\n            ema_apply_op <span class=\"pl-k\">=</span> ema.apply([batch_mean, batch_var])\n            <span class=\"pl-k\">with</span> tf.control_dependencies([ema_apply_op]):\n                <span class=\"pl-k\">return</span> tf.identity(batch_mean), tf.identity(batch_var)\n\n        mean, var <span class=\"pl-k\">=</span> tf.cond(train_phase, mean_var_with_update, <span class=\"pl-k\">lambda</span>: (ema.average(batch_mean), ema.average(batch_var)))\n        normed <span class=\"pl-k\">=</span> tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)\n    <span class=\"pl-k\">return</span> normed\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">build_graph</span>():\n  x <span class=\"pl-k\">=</span> tf.ones([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>])\n  train_phase <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">True</span>)\n  batch_norm(x, <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., train_phase)\n  <span class=\"pl-c1\">print</span>(tf.global_variables())\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n  <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/device:CPU:0<span class=\"pl-pds\">'</span></span>):\n    build_graph()\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>-----<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n  <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/device:GPU:0<span class=\"pl-pds\">'</span></span>):\n    build_graph()</pre></div>", "body_text": "The checkpoint should certainly be loadable. The provided snippet isn't sufficient to help reproduce the problem. @DarcyCode could you please fill in the complete issue template, including instructions to reproduce the problem?\nSimply using the batch_norm function you've provided above and with the following snippet, I do not see any difference in variables names with or without GPU:\nimport tensorflow as tf\n\ndef batch_norm(x, beta, gamma, train_phase, scope='bn', decay=0.9, eps=1e-5):\n    with tf.variable_scope(scope):        \n        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')\n        ema = tf.train.ExponentialMovingAverage(decay=decay)\n\n        def mean_var_with_update():\n            ema_apply_op = ema.apply([batch_mean, batch_var])\n            with tf.control_dependencies([ema_apply_op]):\n                return tf.identity(batch_mean), tf.identity(batch_var)\n\n        mean, var = tf.cond(train_phase, mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\n        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)\n    return normed\n\ndef build_graph():\n  x = tf.ones([1, 1, 1])\n  train_phase = tf.constant(True)\n  batch_norm(x, 1., 1., train_phase)\n  print(tf.global_variables())\n\nwith tf.Graph().as_default():\n  with tf.device('/device:CPU:0'):\n    build_graph()\n\nprint('-----')\n\nwith tf.Graph().as_default():\n  with tf.device('/device:GPU:0'):\n    build_graph()", "body": "The checkpoint should certainly be loadable. The provided snippet isn't sufficient to help reproduce the problem. @DarcyCode could you please fill in the complete issue template, including instructions to reproduce the problem?\r\n\r\nSimply using the `batch_norm` function you've provided above and with the following snippet, I do not see any difference in variables names with or without GPU:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef batch_norm(x, beta, gamma, train_phase, scope='bn', decay=0.9, eps=1e-5):\r\n    with tf.variable_scope(scope):        \r\n        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')\r\n        ema = tf.train.ExponentialMovingAverage(decay=decay)\r\n\r\n        def mean_var_with_update():\r\n            ema_apply_op = ema.apply([batch_mean, batch_var])\r\n            with tf.control_dependencies([ema_apply_op]):\r\n                return tf.identity(batch_mean), tf.identity(batch_var)\r\n\r\n        mean, var = tf.cond(train_phase, mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\r\n        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)\r\n    return normed\r\n\r\ndef build_graph():\r\n  x = tf.ones([1, 1, 1])\r\n  train_phase = tf.constant(True)\r\n  batch_norm(x, 1., 1., train_phase)\r\n  print(tf.global_variables())\r\n\r\nwith tf.Graph().as_default():\r\n  with tf.device('/device:CPU:0'):\r\n    build_graph()\r\n\r\nprint('-----')\r\n\r\nwith tf.Graph().as_default():\r\n  with tf.device('/device:GPU:0'):\r\n    build_graph()\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"}