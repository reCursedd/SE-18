{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/164660353", "html_url": "https://github.com/tensorflow/tensorflow/issues/464#issuecomment-164660353", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/464", "id": 164660353, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NDY2MDM1Mw==", "user": {"login": "fabiencro", "id": 6006273, "node_id": "MDQ6VXNlcjYwMDYyNzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6006273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fabiencro", "html_url": "https://github.com/fabiencro", "followers_url": "https://api.github.com/users/fabiencro/followers", "following_url": "https://api.github.com/users/fabiencro/following{/other_user}", "gists_url": "https://api.github.com/users/fabiencro/gists{/gist_id}", "starred_url": "https://api.github.com/users/fabiencro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fabiencro/subscriptions", "organizations_url": "https://api.github.com/users/fabiencro/orgs", "repos_url": "https://api.github.com/users/fabiencro/repos", "events_url": "https://api.github.com/users/fabiencro/events{/privacy}", "received_events_url": "https://api.github.com/users/fabiencro/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-15T06:39:09Z", "updated_at": "2015-12-15T06:39:09Z", "author_association": "NONE", "body_html": "<p>After checking bug <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"121969451\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/505\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/505/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/505\">#505</a>, it seems that there are actually two bugs going on here. One has to do with tf.reshape + Adagrad/Momentum , and the other has to do with RMSPropOptimizer not handling sparse gradient updates (which happens in cases of embeddings or sampled loss, I guess). Here is a self-contained example demonstrating the RMSProp error (just a slight modification of the one I posted for bug <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"121969451\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/505\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/505/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/505\">#505</a>):</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\ndef device_for_node(n):\n    if n.type == \"MatMul\":\n        return \"/gpu:1\"\n    else:\n        return \"/cpu:0\"\n\nminibatch_size = 128\nhidden_size = 64\nembedding_size = 256\ninput_layer_size = 3\nvocab_size_input = 32\nvocab_size_output = 64\nnce_num_sampled = 16\nlearning_rate = 0.1\n\ndummy_input = np.zeros((minibatch_size, input_layer_size), dtype = np.int32)\ndummy_target = np.zeros((minibatch_size, 1), dtype = np.int32)\n\ninput_layer_flattened_size = input_layer_size * embedding_size\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n    with graph.device(device_for_node):\n        input_layer = tf.placeholder(tf.int32, shape = (minibatch_size, input_layer_size), name = \"input_layer\")       \n        ref_input = tf.placeholder(tf.int32, shape = (minibatch_size, 1), name = \"ref_input\")\n\n        # Parameters\n\n        input_embeddings = tf.Variable(tf.random_normal([vocab_size_input, embedding_size]), name = \"i_embeddings\")\n\n        Wh_i = tf.Variable(tf.random_normal((input_layer_flattened_size, hidden_size), stddev = 0.2), name = \"Wh_i\")\n        bh_i = tf.Variable(tf.random_normal((hidden_size,), stddev = 0.2), name = \"bh_i\")\n\n        Wh_o = tf.Variable(tf.random_normal((vocab_size_output, hidden_size), stddev = 0.2), name = \"Wh_o\")\n        bh_o = tf.Variable(tf.random_normal((vocab_size_output,), stddev = 0.2), name = \"bh_o\")\n\n        # Layers\n\n        i_embedded = tf.nn.embedding_lookup(input_embeddings, input_layer)\n        i_embedded_flattened = tf.reshape(i_embedded, \n                        (\n                         (minibatch_size if minibatch_size is not None else -1), \n                         input_layer_flattened_size ) \n                        )\n\n        h = tf.tanh(tf.matmul(i_embedded_flattened, Wh_i) + bh_i)\n        nce_loss = tf.reduce_mean(tf.nn.nce_loss(Wh_o, bh_o, h, ref_input, nce_num_sampled, \n                                                     num_classes = vocab_size_output, name = \"nce\"))\n        optimizer = tf.train.RMSPropOptimizer(learning_rate, decay = 0.9).minimize(nce_loss)\n\n        init_op = tf.initialize_all_variables()\n\n\nwith tf.Session(graph=graph) as session:\n\n    feed_dict = {input_layer : dummy_input, ref_input : dummy_target}\n    _, loss_val = session.run([optimizer, nce_loss], feed_dict=feed_dict)\n\n\n</code></pre>", "body_text": "After checking bug #505, it seems that there are actually two bugs going on here. One has to do with tf.reshape + Adagrad/Momentum , and the other has to do with RMSPropOptimizer not handling sparse gradient updates (which happens in cases of embeddings or sampled loss, I guess). Here is a self-contained example demonstrating the RMSProp error (just a slight modification of the one I posted for bug #505):\nimport numpy as np\nimport tensorflow as tf\n\ndef device_for_node(n):\n    if n.type == \"MatMul\":\n        return \"/gpu:1\"\n    else:\n        return \"/cpu:0\"\n\nminibatch_size = 128\nhidden_size = 64\nembedding_size = 256\ninput_layer_size = 3\nvocab_size_input = 32\nvocab_size_output = 64\nnce_num_sampled = 16\nlearning_rate = 0.1\n\ndummy_input = np.zeros((minibatch_size, input_layer_size), dtype = np.int32)\ndummy_target = np.zeros((minibatch_size, 1), dtype = np.int32)\n\ninput_layer_flattened_size = input_layer_size * embedding_size\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n    with graph.device(device_for_node):\n        input_layer = tf.placeholder(tf.int32, shape = (minibatch_size, input_layer_size), name = \"input_layer\")       \n        ref_input = tf.placeholder(tf.int32, shape = (minibatch_size, 1), name = \"ref_input\")\n\n        # Parameters\n\n        input_embeddings = tf.Variable(tf.random_normal([vocab_size_input, embedding_size]), name = \"i_embeddings\")\n\n        Wh_i = tf.Variable(tf.random_normal((input_layer_flattened_size, hidden_size), stddev = 0.2), name = \"Wh_i\")\n        bh_i = tf.Variable(tf.random_normal((hidden_size,), stddev = 0.2), name = \"bh_i\")\n\n        Wh_o = tf.Variable(tf.random_normal((vocab_size_output, hidden_size), stddev = 0.2), name = \"Wh_o\")\n        bh_o = tf.Variable(tf.random_normal((vocab_size_output,), stddev = 0.2), name = \"bh_o\")\n\n        # Layers\n\n        i_embedded = tf.nn.embedding_lookup(input_embeddings, input_layer)\n        i_embedded_flattened = tf.reshape(i_embedded, \n                        (\n                         (minibatch_size if minibatch_size is not None else -1), \n                         input_layer_flattened_size ) \n                        )\n\n        h = tf.tanh(tf.matmul(i_embedded_flattened, Wh_i) + bh_i)\n        nce_loss = tf.reduce_mean(tf.nn.nce_loss(Wh_o, bh_o, h, ref_input, nce_num_sampled, \n                                                     num_classes = vocab_size_output, name = \"nce\"))\n        optimizer = tf.train.RMSPropOptimizer(learning_rate, decay = 0.9).minimize(nce_loss)\n\n        init_op = tf.initialize_all_variables()\n\n\nwith tf.Session(graph=graph) as session:\n\n    feed_dict = {input_layer : dummy_input, ref_input : dummy_target}\n    _, loss_val = session.run([optimizer, nce_loss], feed_dict=feed_dict)", "body": "After checking bug #505, it seems that there are actually two bugs going on here. One has to do with tf.reshape + Adagrad/Momentum , and the other has to do with RMSPropOptimizer not handling sparse gradient updates (which happens in cases of embeddings or sampled loss, I guess). Here is a self-contained example demonstrating the RMSProp error (just a slight modification of the one I posted for bug #505):\n\n```\nimport numpy as np\nimport tensorflow as tf\n\ndef device_for_node(n):\n    if n.type == \"MatMul\":\n        return \"/gpu:1\"\n    else:\n        return \"/cpu:0\"\n\nminibatch_size = 128\nhidden_size = 64\nembedding_size = 256\ninput_layer_size = 3\nvocab_size_input = 32\nvocab_size_output = 64\nnce_num_sampled = 16\nlearning_rate = 0.1\n\ndummy_input = np.zeros((minibatch_size, input_layer_size), dtype = np.int32)\ndummy_target = np.zeros((minibatch_size, 1), dtype = np.int32)\n\ninput_layer_flattened_size = input_layer_size * embedding_size\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n    with graph.device(device_for_node):\n        input_layer = tf.placeholder(tf.int32, shape = (minibatch_size, input_layer_size), name = \"input_layer\")       \n        ref_input = tf.placeholder(tf.int32, shape = (minibatch_size, 1), name = \"ref_input\")\n\n        # Parameters\n\n        input_embeddings = tf.Variable(tf.random_normal([vocab_size_input, embedding_size]), name = \"i_embeddings\")\n\n        Wh_i = tf.Variable(tf.random_normal((input_layer_flattened_size, hidden_size), stddev = 0.2), name = \"Wh_i\")\n        bh_i = tf.Variable(tf.random_normal((hidden_size,), stddev = 0.2), name = \"bh_i\")\n\n        Wh_o = tf.Variable(tf.random_normal((vocab_size_output, hidden_size), stddev = 0.2), name = \"Wh_o\")\n        bh_o = tf.Variable(tf.random_normal((vocab_size_output,), stddev = 0.2), name = \"bh_o\")\n\n        # Layers\n\n        i_embedded = tf.nn.embedding_lookup(input_embeddings, input_layer)\n        i_embedded_flattened = tf.reshape(i_embedded, \n                        (\n                         (minibatch_size if minibatch_size is not None else -1), \n                         input_layer_flattened_size ) \n                        )\n\n        h = tf.tanh(tf.matmul(i_embedded_flattened, Wh_i) + bh_i)\n        nce_loss = tf.reduce_mean(tf.nn.nce_loss(Wh_o, bh_o, h, ref_input, nce_num_sampled, \n                                                     num_classes = vocab_size_output, name = \"nce\"))\n        optimizer = tf.train.RMSPropOptimizer(learning_rate, decay = 0.9).minimize(nce_loss)\n\n        init_op = tf.initialize_all_variables()\n\n\nwith tf.Session(graph=graph) as session:\n\n    feed_dict = {input_layer : dummy_input, ref_input : dummy_target}\n    _, loss_val = session.run([optimizer, nce_loss], feed_dict=feed_dict)\n\n\n```\n"}