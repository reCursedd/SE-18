{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/374852731", "html_url": "https://github.com/tensorflow/tensorflow/issues/13895#issuecomment-374852731", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895", "id": 374852731, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NDg1MjczMQ==", "user": {"login": "nxphi47", "id": 19323568, "node_id": "MDQ6VXNlcjE5MzIzNTY4", "avatar_url": "https://avatars3.githubusercontent.com/u/19323568?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nxphi47", "html_url": "https://github.com/nxphi47", "followers_url": "https://api.github.com/users/nxphi47/followers", "following_url": "https://api.github.com/users/nxphi47/following{/other_user}", "gists_url": "https://api.github.com/users/nxphi47/gists{/gist_id}", "starred_url": "https://api.github.com/users/nxphi47/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nxphi47/subscriptions", "organizations_url": "https://api.github.com/users/nxphi47/orgs", "repos_url": "https://api.github.com/users/nxphi47/repos", "events_url": "https://api.github.com/users/nxphi47/events{/privacy}", "received_events_url": "https://api.github.com/users/nxphi47/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-21T07:32:25Z", "updated_at": "2018-03-21T07:37:43Z", "author_association": "NONE", "body_html": "<p>I agree with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15908060\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/FrancescoSaverioZuppichini\">@FrancescoSaverioZuppichini</a> . I read the docstring and the implementation itself, <code>train_and_evaluate</code> is just simply a for loop iterating between estimator.train and estimator.evaluate.</p>\n<p>I never try distributed training cos I can't afford it. By doing train and evaluate with estimators is painful even though it does offer many other good features.</p>\n<p>Each restoring from checkpoint and kick start the session takes ridiculously long time. Unless you are training ImageNet with millions images on models of tens of layers which consumes your whole weekend just for one epoch, re-build the graph every time is so time consuming. In my case, it takes about 5-10% training time cos my dataset is small.</p>\n<p>What many peoples here want is (I try to summarize again):<br>\nfor e in range(epochs):<br>\ntrain for whole training set.<br>\nevaluate on train set, save loss, accuracy, metrics... to tensorboard at ./summary_train/<br>\nevaluate on val set, save loss, accuracy, metrics... to tensorboard at ./summary_val/</p>\n<p>At the end of the day, we will have a trained model, a chart indicates the loss and accuracy of both train and val metrics to measures overfitting and so on.</p>\n<p>Estimator does this with 2 or 3 times re-building the graph and loading checkpoints.</p>\n<p>About graph consistency between training and evaluation, one can simply build a 2-in-1 graph with a <code>is_training</code> placeholder indicating when should the graph execute in which mode. <code>tf.layers.barch_norm</code> does allow passing <code>training</code> with a bool tensor. Or we can use <code>tf.cond</code> to branch between each mode. But estimators do not allow this anyway.</p>\n<p>It is OK to keep \"training things\" like gradients, optimizer parameters in validation mode instead of release them and re-build the graph again.</p>\n<p>I like estimators cos it helps aggregation of metrics and predictions. You can't just tell people to do it their own if they are not satisfied, what's the purpose of estimators except from distributed training anyway?</p>", "body_text": "I agree with @FrancescoSaverioZuppichini . I read the docstring and the implementation itself, train_and_evaluate is just simply a for loop iterating between estimator.train and estimator.evaluate.\nI never try distributed training cos I can't afford it. By doing train and evaluate with estimators is painful even though it does offer many other good features.\nEach restoring from checkpoint and kick start the session takes ridiculously long time. Unless you are training ImageNet with millions images on models of tens of layers which consumes your whole weekend just for one epoch, re-build the graph every time is so time consuming. In my case, it takes about 5-10% training time cos my dataset is small.\nWhat many peoples here want is (I try to summarize again):\nfor e in range(epochs):\ntrain for whole training set.\nevaluate on train set, save loss, accuracy, metrics... to tensorboard at ./summary_train/\nevaluate on val set, save loss, accuracy, metrics... to tensorboard at ./summary_val/\nAt the end of the day, we will have a trained model, a chart indicates the loss and accuracy of both train and val metrics to measures overfitting and so on.\nEstimator does this with 2 or 3 times re-building the graph and loading checkpoints.\nAbout graph consistency between training and evaluation, one can simply build a 2-in-1 graph with a is_training placeholder indicating when should the graph execute in which mode. tf.layers.barch_norm does allow passing training with a bool tensor. Or we can use tf.cond to branch between each mode. But estimators do not allow this anyway.\nIt is OK to keep \"training things\" like gradients, optimizer parameters in validation mode instead of release them and re-build the graph again.\nI like estimators cos it helps aggregation of metrics and predictions. You can't just tell people to do it their own if they are not satisfied, what's the purpose of estimators except from distributed training anyway?", "body": "I agree with @FrancescoSaverioZuppichini . I read the docstring and the implementation itself, `train_and_evaluate` is just simply a for loop iterating between estimator.train and estimator.evaluate. \r\n\r\nI never try distributed training cos I can't afford it. By doing train and evaluate with estimators is painful even though it does offer many other good features. \r\n\r\nEach restoring from checkpoint and kick start the session takes ridiculously long time. Unless you are training ImageNet with millions images on models of tens of layers which consumes your whole weekend just for one epoch, re-build the graph every time is so time consuming. In my case, it takes about 5-10% training time cos my dataset is small.\r\n\r\nWhat many peoples here want is (I try to summarize again):\r\nfor e in range(epochs):\r\n      train for whole training set.\r\n      evaluate on train set, save loss, accuracy, metrics... to tensorboard at ./summary_train/\r\n      evaluate on val set, save loss, accuracy, metrics... to tensorboard at ./summary_val/\r\n\r\nAt the end of the day, we will have a trained model, a chart indicates the loss and accuracy of both train and val metrics to measures overfitting and so on.\r\n\r\nEstimator does this with 2 or 3 times re-building the graph and loading checkpoints.\r\n\r\nAbout graph consistency between training and evaluation, one can simply build a 2-in-1 graph with a `is_training` placeholder indicating when should the graph execute in which mode. `tf.layers.barch_norm` does allow passing `training` with a bool tensor. Or we can use `tf.cond` to branch between each mode. But estimators do not allow this anyway.\r\n\r\nIt is OK to keep \"training things\" like gradients, optimizer parameters in validation mode instead of release them and re-build the graph again.\r\n\r\nI like estimators cos it helps aggregation of metrics and predictions. You can't just tell people to do it their own if they are not satisfied, what's the purpose of estimators except from distributed training anyway?"}