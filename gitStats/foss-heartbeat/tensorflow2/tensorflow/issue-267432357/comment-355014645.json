{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/355014645", "html_url": "https://github.com/tensorflow/tensorflow/issues/13895#issuecomment-355014645", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895", "id": 355014645, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTAxNDY0NQ==", "user": {"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-03T13:43:41Z", "updated_at": "2018-01-03T14:13:17Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>So I am forced to use the layer library?</p>\n</blockquote>\n<p>No, we encourage you to use <code>layers</code> to wrap trainable state, but whether or not you use <code>layers</code> has no effect on the checkpoint reloading logic.</p>\n<blockquote>\n<p>I have to first call <code>.train</code> and then <code>.evaluate</code> that will re-build the graph slowing everything.</p>\n</blockquote>\n<p>If you want to run repeated evaluations while training, consider the <a href=\"https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate\" rel=\"nofollow\">train_and_evaluate</a> function.</p>\n<p>If you're working outside of estimators, <a href=\"https://www.tensorflow.org/programmers_guide/datasets\" rel=\"nofollow\"><code>Datasets</code></a> do have advanced iterator types that allow you to swap input pipelines without rebuilding the graph. But often the changes you want to make to the graph between <code>train</code>, <code>evaluate</code>, and <code>predict</code> are more extensive than just the input stream.</p>", "body_text": "So I am forced to use the layer library?\n\nNo, we encourage you to use layers to wrap trainable state, but whether or not you use layers has no effect on the checkpoint reloading logic.\n\nI have to first call .train and then .evaluate that will re-build the graph slowing everything.\n\nIf you want to run repeated evaluations while training, consider the train_and_evaluate function.\nIf you're working outside of estimators, Datasets do have advanced iterator types that allow you to swap input pipelines without rebuilding the graph. But often the changes you want to make to the graph between train, evaluate, and predict are more extensive than just the input stream.", "body": "> So I am forced to use the layer library?\r\n\r\nNo, we encourage you to use `layers` to wrap trainable state, but whether or not you use `layers` has no effect on the checkpoint reloading logic.\r\n\r\n> I have to first call `.train` and then `.evaluate` that will re-build the graph slowing everything.\r\n\r\nIf you want to run repeated evaluations while training, consider the [train_and_evaluate](https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate) function. \r\n\r\nIf you're working outside of estimators, [`Datasets`](https://www.tensorflow.org/programmers_guide/datasets) do have advanced iterator types that allow you to swap input pipelines without rebuilding the graph. But often the changes you want to make to the graph between `train`, `evaluate`, and `predict` are more extensive than just the input stream."}