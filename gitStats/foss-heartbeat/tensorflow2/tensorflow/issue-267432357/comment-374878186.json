{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/374878186", "html_url": "https://github.com/tensorflow/tensorflow/issues/13895#issuecomment-374878186", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895", "id": 374878186, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NDg3ODE4Ng==", "user": {"login": "janpfeifer", "id": 7460115, "node_id": "MDQ6VXNlcjc0NjAxMTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/7460115?v=4", "gravatar_id": "", "url": "https://api.github.com/users/janpfeifer", "html_url": "https://github.com/janpfeifer", "followers_url": "https://api.github.com/users/janpfeifer/followers", "following_url": "https://api.github.com/users/janpfeifer/following{/other_user}", "gists_url": "https://api.github.com/users/janpfeifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/janpfeifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/janpfeifer/subscriptions", "organizations_url": "https://api.github.com/users/janpfeifer/orgs", "repos_url": "https://api.github.com/users/janpfeifer/repos", "events_url": "https://api.github.com/users/janpfeifer/events{/privacy}", "received_events_url": "https://api.github.com/users/janpfeifer/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-21T09:32:29Z", "updated_at": "2018-03-21T09:32:29Z", "author_association": "NONE", "body_html": "<p>A little bit orthogonal, but I thought it may address one of <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15908060\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/FrancescoSaverioZuppichini\">@FrancescoSaverioZuppichini</a> 's issue of reloading the model for evaluation at each epoch (or whatever frequency you configure):</p>\n<p>I often run things locally (if data is not huge), but most of the time I run different processes (both locally) for training and evaluating.</p>\n<p>So one would run with \"--train\" for the 100 (?) epochs, saving checkpoints at every X time/epochs.</p>\n<p>And the evaluation process would monitor for new checkpoints, load and evaluate them in parallel, without stopping the training. This can be done with <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment\" rel=\"nofollow\">tf.contrib.Experiment</a> -- see <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment#continuous_eval\" rel=\"nofollow\">continuous_eval()</a> -- and <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/learn/learn_runner/run\" rel=\"nofollow\">tf.contrib.learn_runner</a> -- with <code>schedule=\"continuous_eval\"</code> -- with not many extra lines of code.</p>\n<p>I hope it helps.</p>\n<p>Btw, how big are your checkpoints ? When you say it takes a long time to load, how much is it roughly ? (10s, 1min, 10min, 30min, 1hour?)</p>\n<p>Oh, also, how are you doing cross-validation ? Sorry I didn't figure from the code/description ...</p>\n<p>cheers</p>", "body_text": "A little bit orthogonal, but I thought it may address one of @FrancescoSaverioZuppichini 's issue of reloading the model for evaluation at each epoch (or whatever frequency you configure):\nI often run things locally (if data is not huge), but most of the time I run different processes (both locally) for training and evaluating.\nSo one would run with \"--train\" for the 100 (?) epochs, saving checkpoints at every X time/epochs.\nAnd the evaluation process would monitor for new checkpoints, load and evaluate them in parallel, without stopping the training. This can be done with tf.contrib.Experiment -- see continuous_eval() -- and tf.contrib.learn_runner -- with schedule=\"continuous_eval\" -- with not many extra lines of code.\nI hope it helps.\nBtw, how big are your checkpoints ? When you say it takes a long time to load, how much is it roughly ? (10s, 1min, 10min, 30min, 1hour?)\nOh, also, how are you doing cross-validation ? Sorry I didn't figure from the code/description ...\ncheers", "body": "A little bit orthogonal, but I thought it may address one of @FrancescoSaverioZuppichini 's issue of reloading the model for evaluation at each epoch (or whatever frequency you configure):\r\n\r\nI often run things locally (if data is not huge), but most of the time I run different processes (both locally) for training and evaluating.\r\n\r\nSo one would run with \"--train\" for the 100 (?) epochs, saving checkpoints at every X time/epochs.\r\n\r\nAnd the evaluation process would monitor for new checkpoints, load and evaluate them in parallel, without stopping the training. This can be done with [tf.contrib.Experiment](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment) -- see [continuous_eval()](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment#continuous_eval) -- and [tf.contrib.learn_runner](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/learn_runner/run) -- with `schedule=\"continuous_eval\"` -- with not many extra lines of code.\r\n\r\nI hope it helps.\r\n\r\nBtw, how big are your checkpoints ? When you say it takes a long time to load, how much is it roughly ? (10s, 1min, 10min, 30min, 1hour?)\r\n\r\nOh, also, how are you doing cross-validation ? Sorry I didn't figure from the code/description ... \r\n\r\ncheers \r\n\r\n"}