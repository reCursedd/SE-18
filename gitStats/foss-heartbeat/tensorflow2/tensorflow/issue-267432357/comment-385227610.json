{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385227610", "html_url": "https://github.com/tensorflow/tensorflow/issues/13895#issuecomment-385227610", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895", "id": 385227610, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTIyNzYxMA==", "user": {"login": "formigone", "id": 852234, "node_id": "MDQ6VXNlcjg1MjIzNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/852234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/formigone", "html_url": "https://github.com/formigone", "followers_url": "https://api.github.com/users/formigone/followers", "following_url": "https://api.github.com/users/formigone/following{/other_user}", "gists_url": "https://api.github.com/users/formigone/gists{/gist_id}", "starred_url": "https://api.github.com/users/formigone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/formigone/subscriptions", "organizations_url": "https://api.github.com/users/formigone/orgs", "repos_url": "https://api.github.com/users/formigone/repos", "events_url": "https://api.github.com/users/formigone/events{/privacy}", "received_events_url": "https://api.github.com/users/formigone/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-29T05:43:11Z", "updated_at": "2018-04-29T05:45:19Z", "author_association": "CONTRIBUTOR", "body_html": "<p>To clarify:</p>\n<blockquote>\n<p>train_and_evaluate will just evaluate after the train is done. Meaning, that it will first train for, following our example, 100 epochs and then run the evaluation one once!</p>\n</blockquote>\n<p>That is incorrect. <code>train_and_evaluate</code> trains for a configurable amount of iterations, then runs an evaluation until the specified <code>input_fn</code> finishes. Then it starts training again by restoring the weights that were used for the eval, and consuming the input stream from where it left off. There might be some minor technicalities in my summarized explanation, but it is conceptually accurate.</p>\n<p>I've been training reasonably large models on a single laptop using <code>train_and_evaluate</code> since version 1.2, and I think it works extremely well. The time it takes to rebuild the graph and restore parameters is negligible when you take into account all the time that's spent actually training.</p>", "body_text": "To clarify:\n\ntrain_and_evaluate will just evaluate after the train is done. Meaning, that it will first train for, following our example, 100 epochs and then run the evaluation one once!\n\nThat is incorrect. train_and_evaluate trains for a configurable amount of iterations, then runs an evaluation until the specified input_fn finishes. Then it starts training again by restoring the weights that were used for the eval, and consuming the input stream from where it left off. There might be some minor technicalities in my summarized explanation, but it is conceptually accurate.\nI've been training reasonably large models on a single laptop using train_and_evaluate since version 1.2, and I think it works extremely well. The time it takes to rebuild the graph and restore parameters is negligible when you take into account all the time that's spent actually training.", "body": "To clarify:\r\n\r\n> train_and_evaluate will just evaluate after the train is done. Meaning, that it will first train for, following our example, 100 epochs and then run the evaluation one once!\r\n\r\nThat is incorrect. `train_and_evaluate` trains for a configurable amount of iterations, then runs an evaluation until the specified `input_fn` finishes. Then it starts training again by restoring the weights that were used for the eval, and consuming the input stream from where it left off. There might be some minor technicalities in my summarized explanation, but it is conceptually accurate. \r\n\r\nI've been training reasonably large models on a single laptop using `train_and_evaluate` since version 1.2, and I think it works extremely well. The time it takes to rebuild the graph and restore parameters is negligible when you take into account all the time that's spent actually training."}