{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/374734296", "html_url": "https://github.com/tensorflow/tensorflow/issues/13895#issuecomment-374734296", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895", "id": 374734296, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NDczNDI5Ng==", "user": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-20T19:52:32Z", "updated_at": "2018-03-20T19:52:32Z", "author_association": "MEMBER", "body_html": "<p>It would be hard to do in <code>Estimator</code>, but you could probably do it in <code>train_and_evaluate</code>, changing how it evaluates in local mode. We had actually discussed this, and it would be feasible for <code>train_and_evaluate</code> to build both train and eval graphs against the same set of variables, not load checkpoints, and switch between training and evaluation in memory. This would still not share the graphs (which wouldn't be a good idea given the distribution concerns), but it would avoid reloading.</p>\n<p>We never prioritized this since it's unclear to me how much you gain from this. For small models, checkpoint loading isn't a huge cost, and for large models, checkpoint loading again isn't a huge cost compared to the cost of training.</p>", "body_text": "It would be hard to do in Estimator, but you could probably do it in train_and_evaluate, changing how it evaluates in local mode. We had actually discussed this, and it would be feasible for train_and_evaluate to build both train and eval graphs against the same set of variables, not load checkpoints, and switch between training and evaluation in memory. This would still not share the graphs (which wouldn't be a good idea given the distribution concerns), but it would avoid reloading.\nWe never prioritized this since it's unclear to me how much you gain from this. For small models, checkpoint loading isn't a huge cost, and for large models, checkpoint loading again isn't a huge cost compared to the cost of training.", "body": "It would be hard to do in `Estimator`, but you could probably do it in `train_and_evaluate`, changing how it evaluates in local mode. We had actually discussed this, and it would be feasible for `train_and_evaluate` to build both train and eval graphs against the same set of variables, not load checkpoints, and switch between training and evaluation in memory. This would still not share the graphs (which wouldn't be a good idea given the distribution concerns), but it would avoid reloading. \r\n\r\nWe never prioritized this since it's unclear to me how much you gain from this. For small models, checkpoint loading isn't a huge cost, and for large models, checkpoint loading again isn't a huge cost compared to the cost of training. "}