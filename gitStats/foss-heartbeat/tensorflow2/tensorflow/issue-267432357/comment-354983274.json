{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/354983274", "html_url": "https://github.com/tensorflow/tensorflow/issues/13895#issuecomment-354983274", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895", "id": 354983274, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDk4MzI3NA==", "user": {"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-03T10:46:39Z", "updated_at": "2018-01-03T10:46:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15908060\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/FrancescoSaverioZuppichini\">@FrancescoSaverioZuppichini</a>: The updated docs will be available in 1.5, but drafts are already in the repo, <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/checkpoints.md\">this doc</a> describes how checkpointing works with estimators.</p>\n<p>In the mean time, let me summarize:</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=922081\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hanfeisun\">@hanfeisun</a>: Yes, each (<code>train</code>, <code>evaluate</code>, <code>predict</code>) method rebuilds the <code>graph</code>. But the estimator <strong>always</strong> loads the checkpoints from the <code>model_dir</code> into the graph before doing anything. In fact <code>evaluate</code> and <code>predict</code> can't be used until after you've called <code>train</code> at least once, so that there is a checkpoint to load.</p>\n<p>The <code>reuse</code> layer argument does something different. It's an outdated way to use the same layer on two different inputs. A much better way to have this effect is to use the layer classes, and just reuse the layer object. I believe the following two code blocks are equivalent:</p>\n<pre><code>out0 = tf.layers.dense(x, 10)\nout1= tf.layers.dense(y,10, reuse=True)\n</code></pre>\n<pre><code>my_layer = tf.layers.Dense(10)\nout0 = my_layer(x)\nout1 = my_layer(y)\n</code></pre>\n<p>I hope this helps, but in the future this sort of question is probably better suited for stack overflow.</p>", "body_text": "@FrancescoSaverioZuppichini: The updated docs will be available in 1.5, but drafts are already in the repo, this doc describes how checkpointing works with estimators.\nIn the mean time, let me summarize:\n@hanfeisun: Yes, each (train, evaluate, predict) method rebuilds the graph. But the estimator always loads the checkpoints from the model_dir into the graph before doing anything. In fact evaluate and predict can't be used until after you've called train at least once, so that there is a checkpoint to load.\nThe reuse layer argument does something different. It's an outdated way to use the same layer on two different inputs. A much better way to have this effect is to use the layer classes, and just reuse the layer object. I believe the following two code blocks are equivalent:\nout0 = tf.layers.dense(x, 10)\nout1= tf.layers.dense(y,10, reuse=True)\n\nmy_layer = tf.layers.Dense(10)\nout0 = my_layer(x)\nout1 = my_layer(y)\n\nI hope this helps, but in the future this sort of question is probably better suited for stack overflow.", "body": "@FrancescoSaverioZuppichini: The updated docs will be available in 1.5, but drafts are already in the repo, [this doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/checkpoints.md\r\n) describes how checkpointing works with estimators.\r\n\r\nIn the mean time, let me summarize:\r\n\r\n@hanfeisun: Yes, each (`train`, `evaluate`, `predict`) method rebuilds the `graph`. But the estimator **always** loads the checkpoints from the `model_dir` into the graph before doing anything. In fact `evaluate` and `predict` can't be used until after you've called `train` at least once, so that there is a checkpoint to load. \r\n\r\n\r\nThe `reuse` layer argument does something different. It's an outdated way to use the same layer on two different inputs. A much better way to have this effect is to use the layer classes, and just reuse the layer object. I believe the following two code blocks are equivalent:\r\n\r\n```\r\nout0 = tf.layers.dense(x, 10)\r\nout1= tf.layers.dense(y,10, reuse=True)\r\n```\r\n\r\n```\r\nmy_layer = tf.layers.Dense(10)\r\nout0 = my_layer(x)\r\nout1 = my_layer(y)\r\n```\r\n\r\nI hope this helps, but in the future this sort of question is probably better suited for stack overflow.\r\n"}