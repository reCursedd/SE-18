{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13895/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13895", "id": 267432357, "node_id": "MDU6SXNzdWUyNjc0MzIzNTc=", "number": 13895, "title": "In the estimator of Tensorflow, how does it work when model_fn is called multiple times?", "user": {"login": "hanfeisun", "id": 922081, "node_id": "MDQ6VXNlcjkyMjA4MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/922081?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hanfeisun", "html_url": "https://github.com/hanfeisun", "followers_url": "https://api.github.com/users/hanfeisun/followers", "following_url": "https://api.github.com/users/hanfeisun/following{/other_user}", "gists_url": "https://api.github.com/users/hanfeisun/gists{/gist_id}", "starred_url": "https://api.github.com/users/hanfeisun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hanfeisun/subscriptions", "organizations_url": "https://api.github.com/users/hanfeisun/orgs", "repos_url": "https://api.github.com/users/hanfeisun/repos", "events_url": "https://api.github.com/users/hanfeisun/events{/privacy}", "received_events_url": "https://api.github.com/users/hanfeisun/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284443156, "node_id": "MDU6TGFiZWwyODQ0NDMxNTY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 62, "created_at": "2017-10-22T03:27:24Z", "updated_at": "2018-08-14T03:10:29Z", "closed_at": "2017-10-23T16:55:59Z", "author_association": "NONE", "body_html": "<pre><code>def model_fn(features, labels, mode, params):\n  \"\"\"Model function for Estimator.\"\"\"\n\n  # Connect the first hidden layer to input layer\n  # (features[\"x\"]) with relu activation\n  first_hidden_layer = tf.layers.dense(features[\"x\"], 10, activation=tf.nn.relu)\n\n  # Connect the second hidden layer to first hidden layer with relu\n  second_hidden_layer = tf.layers.dense(\n      first_hidden_layer, 10, activation=tf.nn.relu)\n\n  # Connect the output layer to second hidden layer (no activation fn)\n  output_layer = tf.layers.dense(second_hidden_layer, 1)\n\n  # Reshape output layer to 1-dim Tensor to return predictions\n  predictions = tf.reshape(output_layer, [-1])\n\n  # Provide an estimator spec for `ModeKeys.PREDICT`.\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions={\"ages\": predictions})\n\n  # Calculate loss using mean squared error\n  loss = tf.losses.mean_squared_error(labels, predictions)\n\n  # Calculate root mean squared error as additional eval metric\n  eval_metric_ops = {\n      \"rmse\": tf.metrics.root_mean_squared_error(\n          tf.cast(labels, tf.float64), predictions)\n  }\n\n  optimizer = tf.train.GradientDescentOptimizer(\n      learning_rate=params[\"learning_rate\"])\n  train_op = optimizer.minimize(\n      loss=loss, global_step=tf.train.get_global_step())\n\n  # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\n  return tf.estimator.EstimatorSpec(\n      mode=mode,\n      loss=loss,\n      train_op=train_op,\n      eval_metric_ops=eval_metric_ops)\n</code></pre>\n<p>Above is an example of the model_fn used by Tensorflow's <a href=\"https://www.tensorflow.org/extend/estimators\" rel=\"nofollow\">Estimator</a>.</p>\n<p>As mentioned in the tutorial, this model_fn could be called in different context (train, predict, evaluate). However, I'm a bit confused, because each time the model_fn is called, <strong>instead of reusing existing graph, it seems to create a new graph.(or create new node in the graph)</strong></p>\n<p>For example, firstly I called model_fn under TRAIN mode, then I called model_fn with PREDICT mode. How can I make sure the PREDICT one is reusing the weight of the trained values?</p>", "body_text": "def model_fn(features, labels, mode, params):\n  \"\"\"Model function for Estimator.\"\"\"\n\n  # Connect the first hidden layer to input layer\n  # (features[\"x\"]) with relu activation\n  first_hidden_layer = tf.layers.dense(features[\"x\"], 10, activation=tf.nn.relu)\n\n  # Connect the second hidden layer to first hidden layer with relu\n  second_hidden_layer = tf.layers.dense(\n      first_hidden_layer, 10, activation=tf.nn.relu)\n\n  # Connect the output layer to second hidden layer (no activation fn)\n  output_layer = tf.layers.dense(second_hidden_layer, 1)\n\n  # Reshape output layer to 1-dim Tensor to return predictions\n  predictions = tf.reshape(output_layer, [-1])\n\n  # Provide an estimator spec for `ModeKeys.PREDICT`.\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions={\"ages\": predictions})\n\n  # Calculate loss using mean squared error\n  loss = tf.losses.mean_squared_error(labels, predictions)\n\n  # Calculate root mean squared error as additional eval metric\n  eval_metric_ops = {\n      \"rmse\": tf.metrics.root_mean_squared_error(\n          tf.cast(labels, tf.float64), predictions)\n  }\n\n  optimizer = tf.train.GradientDescentOptimizer(\n      learning_rate=params[\"learning_rate\"])\n  train_op = optimizer.minimize(\n      loss=loss, global_step=tf.train.get_global_step())\n\n  # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\n  return tf.estimator.EstimatorSpec(\n      mode=mode,\n      loss=loss,\n      train_op=train_op,\n      eval_metric_ops=eval_metric_ops)\n\nAbove is an example of the model_fn used by Tensorflow's Estimator.\nAs mentioned in the tutorial, this model_fn could be called in different context (train, predict, evaluate). However, I'm a bit confused, because each time the model_fn is called, instead of reusing existing graph, it seems to create a new graph.(or create new node in the graph)\nFor example, firstly I called model_fn under TRAIN mode, then I called model_fn with PREDICT mode. How can I make sure the PREDICT one is reusing the weight of the trained values?", "body": "    def model_fn(features, labels, mode, params):\r\n      \"\"\"Model function for Estimator.\"\"\"\r\n    \r\n      # Connect the first hidden layer to input layer\r\n      # (features[\"x\"]) with relu activation\r\n      first_hidden_layer = tf.layers.dense(features[\"x\"], 10, activation=tf.nn.relu)\r\n    \r\n      # Connect the second hidden layer to first hidden layer with relu\r\n      second_hidden_layer = tf.layers.dense(\r\n          first_hidden_layer, 10, activation=tf.nn.relu)\r\n    \r\n      # Connect the output layer to second hidden layer (no activation fn)\r\n      output_layer = tf.layers.dense(second_hidden_layer, 1)\r\n    \r\n      # Reshape output layer to 1-dim Tensor to return predictions\r\n      predictions = tf.reshape(output_layer, [-1])\r\n    \r\n      # Provide an estimator spec for `ModeKeys.PREDICT`.\r\n      if mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            predictions={\"ages\": predictions})\r\n    \r\n      # Calculate loss using mean squared error\r\n      loss = tf.losses.mean_squared_error(labels, predictions)\r\n    \r\n      # Calculate root mean squared error as additional eval metric\r\n      eval_metric_ops = {\r\n          \"rmse\": tf.metrics.root_mean_squared_error(\r\n              tf.cast(labels, tf.float64), predictions)\r\n      }\r\n    \r\n      optimizer = tf.train.GradientDescentOptimizer(\r\n          learning_rate=params[\"learning_rate\"])\r\n      train_op = optimizer.minimize(\r\n          loss=loss, global_step=tf.train.get_global_step())\r\n    \r\n      # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\r\n      return tf.estimator.EstimatorSpec(\r\n          mode=mode,\r\n          loss=loss,\r\n          train_op=train_op,\r\n          eval_metric_ops=eval_metric_ops)\r\n\r\nAbove is an example of the model_fn used by Tensorflow's [Estimator][1].\r\n\r\nAs mentioned in the tutorial, this model_fn could be called in different context (train, predict, evaluate). However, I'm a bit confused, because each time the model_fn is called, **instead of reusing existing graph, it seems to create a new graph.(or create new node in the graph)**\r\n\r\nFor example, firstly I called model_fn under TRAIN mode, then I called model_fn with PREDICT mode. How can I make sure the PREDICT one is reusing the weight of the trained values?\r\n\r\n  [1]: https://www.tensorflow.org/extend/estimators"}