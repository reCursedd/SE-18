{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10518", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10518/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10518/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10518/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10518", "id": 234397768, "node_id": "MDU6SXNzdWUyMzQzOTc3Njg=", "number": 10518, "title": "some op frequently disappears in the log of tfprof", "user": {"login": "linearhit", "id": 8992445, "node_id": "MDQ6VXNlcjg5OTI0NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/8992445?v=4", "gravatar_id": "", "url": "https://api.github.com/users/linearhit", "html_url": "https://github.com/linearhit", "followers_url": "https://api.github.com/users/linearhit/followers", "following_url": "https://api.github.com/users/linearhit/following{/other_user}", "gists_url": "https://api.github.com/users/linearhit/gists{/gist_id}", "starred_url": "https://api.github.com/users/linearhit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/linearhit/subscriptions", "organizations_url": "https://api.github.com/users/linearhit/orgs", "repos_url": "https://api.github.com/users/linearhit/repos", "events_url": "https://api.github.com/users/linearhit/events{/privacy}", "received_events_url": "https://api.github.com/users/linearhit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "panyx0718", "id": 2887803, "node_id": "MDQ6VXNlcjI4ODc4MDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2887803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/panyx0718", "html_url": "https://github.com/panyx0718", "followers_url": "https://api.github.com/users/panyx0718/followers", "following_url": "https://api.github.com/users/panyx0718/following{/other_user}", "gists_url": "https://api.github.com/users/panyx0718/gists{/gist_id}", "starred_url": "https://api.github.com/users/panyx0718/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/panyx0718/subscriptions", "organizations_url": "https://api.github.com/users/panyx0718/orgs", "repos_url": "https://api.github.com/users/panyx0718/repos", "events_url": "https://api.github.com/users/panyx0718/events{/privacy}", "received_events_url": "https://api.github.com/users/panyx0718/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "panyx0718", "id": 2887803, "node_id": "MDQ6VXNlcjI4ODc4MDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2887803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/panyx0718", "html_url": "https://github.com/panyx0718", "followers_url": "https://api.github.com/users/panyx0718/followers", "following_url": "https://api.github.com/users/panyx0718/following{/other_user}", "gists_url": "https://api.github.com/users/panyx0718/gists{/gist_id}", "starred_url": "https://api.github.com/users/panyx0718/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/panyx0718/subscriptions", "organizations_url": "https://api.github.com/users/panyx0718/orgs", "repos_url": "https://api.github.com/users/panyx0718/repos", "events_url": "https://api.github.com/users/panyx0718/events{/privacy}", "received_events_url": "https://api.github.com/users/panyx0718/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2017-06-08T02:55:18Z", "updated_at": "2017-12-21T20:38:53Z", "closed_at": "2017-12-21T20:38:53Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Red Hat 4.8.3-9</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.4.5</li>\n<li><strong>CUDA/cuDNN version</strong>: N.A   the code is runned with CPU</li>\n<li><strong>GPU model and memory</strong>: N.A</li>\n<li><strong>Exact command to reproduce</strong>: python the_source_code.py</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>I tried to use the scripts below to profile the running time of tf.matmul(). But, with each different runs, some ops frequently disappear from the log of tfprof. I tried to add time stamp in the Compute() method of the underlying op, and it shows that the running time is quite stable for different runs. The same problem also happens with larger networks. I'm using CPU other than GPU in this case.</p>\n<p>sometimes the log is like this, MatMul reports 0us, which is definitely not true:</p>\n<p>==================Model Analysis Report======================<br>\n_TFProfRoot (0B/47.32MB, 0us/104.00ms)<br>\n<strong>MatMul (6.76MB/6.76MB, 0us/0us)</strong><br>\nrandom_normal (6.76MB/20.28MB, 1.20ms/52.71ms)<br>\nrandom_normal/RandomStandardNormal (6.76MB/6.76MB, 50.20ms/50.20ms)<br>\nrandom_normal/mean (4B/4B, 0us/0us)<br>\nrandom_normal/mul (6.76MB/6.76MB, 1.30ms/1.30ms)<br>\nrandom_normal/shape (8B/8B, 2us/2us)<br>\nrandom_normal/stddev (4B/4B, 0us/0us)<br>\nrandom_normal_1 (6.76MB/20.28MB, 0us/51.29ms)<br>\nrandom_normal_1/RandomStandardNormal (6.76MB/6.76MB, 51.29ms/51.29ms)<br>\nrandom_normal_1/mean (0B/0B, 0us/0us)<br>\nrandom_normal_1/mul (6.76MB/6.76MB, 0us/0us)<br>\nrandom_normal_1/shape (0B/0B, 0us/0us)<br>\nrandom_normal_1/stddev (0B/0B, 0us/0us)</p>\n<p>some times like this, which is expected:</p>\n<p>==================Model Analysis Report======================<br>\n_TFProfRoot (0B/47.32MB, 0us/82.61ms)<br>\n<strong>MatMul (6.76MB/6.76MB, 36.83ms/36.83ms)</strong><br>\nrandom_normal (6.76MB/20.28MB, 2.21ms/41.42ms)<br>\nrandom_normal/RandomStandardNormal (6.76MB/6.76MB, 37.09ms/37.09ms)<br>\nrandom_normal/mean (4B/4B, 0us/0us)<br>\nrandom_normal/mul (6.76MB/6.76MB, 2.13ms/2.13ms)<br>\nrandom_normal/shape (8B/8B, 0us/0us)<br>\nrandom_normal/stddev (4B/4B, 0us/0us)<br>\nrandom_normal_1 (6.76MB/20.28MB, 2.17ms/4.36ms)<br>\nrandom_normal_1/RandomStandardNormal (6.76MB/6.76MB, 0us/0us)<br>\nrandom_normal_1/mean (0B/0B, 0us/0us)<br>\nrandom_normal_1/mul (6.76MB/6.76MB, 2.19ms/2.19ms)<br>\nrandom_normal_1/shape (0B/0B, 0us/0us)<br>\nrandom_normal_1/stddev (0B/0B, 0us/0us)</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<pre><code>import tensorflow as tf\nimport time\n\nsize = 1300\n\ndef main():\n  x = tf.random_normal(shape = [1, size])\n  w = tf.random_normal(shape = [size, 2*size])\n  y = tf.matmul(x,w)\n\n  with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0, 'CPU': 1}, \\\n    inter_op_parallelism_threads = 1, intra_op_parallelism_threads = 1, \\\n    log_device_placement=True)) as sess:\n\n    run_metadata = tf.RunMetadata()\n    opts = tf.contrib.tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY\n    opts['min_micros'] = 0\n    opts['min_bytes'] = 0\n    predictions = sess.run(y,\n                         options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n                         run_metadata=run_metadata)\n    tf.contrib.tfprof.model_analyzer.print_model_analysis(\n                        tf.get_default_graph(),\n                        run_meta=run_metadata,\n                        tfprof_options=opts)\n \nif __name__ == '__main__':\n  main()\n\n\n</code></pre>", "body_text": "Please go to Stack Overflow for help and support:\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Red Hat 4.8.3-9\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.0\nBazel version (if compiling from source): 0.4.5\nCUDA/cuDNN version: N.A   the code is runned with CPU\nGPU model and memory: N.A\nExact command to reproduce: python the_source_code.py\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nI tried to use the scripts below to profile the running time of tf.matmul(). But, with each different runs, some ops frequently disappear from the log of tfprof. I tried to add time stamp in the Compute() method of the underlying op, and it shows that the running time is quite stable for different runs. The same problem also happens with larger networks. I'm using CPU other than GPU in this case.\nsometimes the log is like this, MatMul reports 0us, which is definitely not true:\n==================Model Analysis Report======================\n_TFProfRoot (0B/47.32MB, 0us/104.00ms)\nMatMul (6.76MB/6.76MB, 0us/0us)\nrandom_normal (6.76MB/20.28MB, 1.20ms/52.71ms)\nrandom_normal/RandomStandardNormal (6.76MB/6.76MB, 50.20ms/50.20ms)\nrandom_normal/mean (4B/4B, 0us/0us)\nrandom_normal/mul (6.76MB/6.76MB, 1.30ms/1.30ms)\nrandom_normal/shape (8B/8B, 2us/2us)\nrandom_normal/stddev (4B/4B, 0us/0us)\nrandom_normal_1 (6.76MB/20.28MB, 0us/51.29ms)\nrandom_normal_1/RandomStandardNormal (6.76MB/6.76MB, 51.29ms/51.29ms)\nrandom_normal_1/mean (0B/0B, 0us/0us)\nrandom_normal_1/mul (6.76MB/6.76MB, 0us/0us)\nrandom_normal_1/shape (0B/0B, 0us/0us)\nrandom_normal_1/stddev (0B/0B, 0us/0us)\nsome times like this, which is expected:\n==================Model Analysis Report======================\n_TFProfRoot (0B/47.32MB, 0us/82.61ms)\nMatMul (6.76MB/6.76MB, 36.83ms/36.83ms)\nrandom_normal (6.76MB/20.28MB, 2.21ms/41.42ms)\nrandom_normal/RandomStandardNormal (6.76MB/6.76MB, 37.09ms/37.09ms)\nrandom_normal/mean (4B/4B, 0us/0us)\nrandom_normal/mul (6.76MB/6.76MB, 2.13ms/2.13ms)\nrandom_normal/shape (8B/8B, 0us/0us)\nrandom_normal/stddev (4B/4B, 0us/0us)\nrandom_normal_1 (6.76MB/20.28MB, 2.17ms/4.36ms)\nrandom_normal_1/RandomStandardNormal (6.76MB/6.76MB, 0us/0us)\nrandom_normal_1/mean (0B/0B, 0us/0us)\nrandom_normal_1/mul (6.76MB/6.76MB, 2.19ms/2.19ms)\nrandom_normal_1/shape (0B/0B, 0us/0us)\nrandom_normal_1/stddev (0B/0B, 0us/0us)\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\nimport tensorflow as tf\nimport time\n\nsize = 1300\n\ndef main():\n  x = tf.random_normal(shape = [1, size])\n  w = tf.random_normal(shape = [size, 2*size])\n  y = tf.matmul(x,w)\n\n  with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0, 'CPU': 1}, \\\n    inter_op_parallelism_threads = 1, intra_op_parallelism_threads = 1, \\\n    log_device_placement=True)) as sess:\n\n    run_metadata = tf.RunMetadata()\n    opts = tf.contrib.tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY\n    opts['min_micros'] = 0\n    opts['min_bytes'] = 0\n    predictions = sess.run(y,\n                         options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n                         run_metadata=run_metadata)\n    tf.contrib.tfprof.model_analyzer.print_model_analysis(\n                        tf.get_default_graph(),\n                        run_meta=run_metadata,\n                        tfprof_options=opts)\n \nif __name__ == '__main__':\n  main()", "body": "Please go to Stack Overflow for help and support:\r\n\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat 4.8.3-9\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.0\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: N.A   the code is runned with CPU\r\n- **GPU model and memory**: N.A\r\n- **Exact command to reproduce**: python the_source_code.py\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI tried to use the scripts below to profile the running time of tf.matmul(). But, with each different runs, some ops frequently disappear from the log of tfprof. I tried to add time stamp in the Compute() method of the underlying op, and it shows that the running time is quite stable for different runs. The same problem also happens with larger networks. I'm using CPU other than GPU in this case.\r\n\r\nsometimes the log is like this, MatMul reports 0us, which is definitely not true:\r\n\r\n==================Model Analysis Report======================\r\n_TFProfRoot (0B/47.32MB, 0us/104.00ms)\r\n  **MatMul (6.76MB/6.76MB, 0us/0us)**\r\n  random_normal (6.76MB/20.28MB, 1.20ms/52.71ms)\r\n    random_normal/RandomStandardNormal (6.76MB/6.76MB, 50.20ms/50.20ms)\r\n    random_normal/mean (4B/4B, 0us/0us)\r\n    random_normal/mul (6.76MB/6.76MB, 1.30ms/1.30ms)\r\n    random_normal/shape (8B/8B, 2us/2us)\r\n    random_normal/stddev (4B/4B, 0us/0us)\r\n  random_normal_1 (6.76MB/20.28MB, 0us/51.29ms)\r\n    random_normal_1/RandomStandardNormal (6.76MB/6.76MB, 51.29ms/51.29ms)\r\n    random_normal_1/mean (0B/0B, 0us/0us)\r\n    random_normal_1/mul (6.76MB/6.76MB, 0us/0us)\r\n    random_normal_1/shape (0B/0B, 0us/0us)\r\n    random_normal_1/stddev (0B/0B, 0us/0us)\r\n\r\n\r\n\r\nsome times like this, which is expected:\r\n\r\n==================Model Analysis Report======================\r\n_TFProfRoot (0B/47.32MB, 0us/82.61ms)\r\n  **MatMul (6.76MB/6.76MB, 36.83ms/36.83ms)**\r\n  random_normal (6.76MB/20.28MB, 2.21ms/41.42ms)\r\n    random_normal/RandomStandardNormal (6.76MB/6.76MB, 37.09ms/37.09ms)\r\n    random_normal/mean (4B/4B, 0us/0us)\r\n    random_normal/mul (6.76MB/6.76MB, 2.13ms/2.13ms)\r\n    random_normal/shape (8B/8B, 0us/0us)\r\n    random_normal/stddev (4B/4B, 0us/0us)\r\n  random_normal_1 (6.76MB/20.28MB, 2.17ms/4.36ms)\r\n    random_normal_1/RandomStandardNormal (6.76MB/6.76MB, 0us/0us)\r\n    random_normal_1/mean (0B/0B, 0us/0us)\r\n    random_normal_1/mul (6.76MB/6.76MB, 2.19ms/2.19ms)\r\n    random_normal_1/shape (0B/0B, 0us/0us)\r\n    random_normal_1/stddev (0B/0B, 0us/0us)\r\n\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nimport time\r\n\r\nsize = 1300\r\n\r\ndef main():\r\n  x = tf.random_normal(shape = [1, size])\r\n  w = tf.random_normal(shape = [size, 2*size])\r\n  y = tf.matmul(x,w)\r\n\r\n  with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0, 'CPU': 1}, \\\r\n    inter_op_parallelism_threads = 1, intra_op_parallelism_threads = 1, \\\r\n    log_device_placement=True)) as sess:\r\n\r\n    run_metadata = tf.RunMetadata()\r\n    opts = tf.contrib.tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY\r\n    opts['min_micros'] = 0\r\n    opts['min_bytes'] = 0\r\n    predictions = sess.run(y,\r\n                         options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\r\n                         run_metadata=run_metadata)\r\n    tf.contrib.tfprof.model_analyzer.print_model_analysis(\r\n                        tf.get_default_graph(),\r\n                        run_meta=run_metadata,\r\n                        tfprof_options=opts)\r\n \r\nif __name__ == '__main__':\r\n  main()\r\n\r\n\r\n```"}