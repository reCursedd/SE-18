{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9916", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9916/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9916/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9916/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9916", "id": 228772125, "node_id": "MDU6SXNzdWUyMjg3NzIxMjU=", "number": 9916, "title": "tf.self_adjoint_eig doesn't behave the same way with float32 and float64", "user": {"login": "jrabary", "id": 1025387, "node_id": "MDQ6VXNlcjEwMjUzODc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1025387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrabary", "html_url": "https://github.com/jrabary", "followers_url": "https://api.github.com/users/jrabary/followers", "following_url": "https://api.github.com/users/jrabary/following{/other_user}", "gists_url": "https://api.github.com/users/jrabary/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrabary/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrabary/subscriptions", "organizations_url": "https://api.github.com/users/jrabary/orgs", "repos_url": "https://api.github.com/users/jrabary/repos", "events_url": "https://api.github.com/users/jrabary/events{/privacy}", "received_events_url": "https://api.github.com/users/jrabary/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-05-15T16:31:50Z", "updated_at": "2017-05-16T16:57:17Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Here is an example to reproduce the problem</p>\n<pre><code>l = tf.constant([[10., -4., -4., -2.],\n                  [-4., 10., -2., -4.],\n                  [-4., -2., 6., 0.],\n                  [-2., -4., 0., 6.]], dtype=tf.float64)\ne, v = tf.self_adjoint_eig(tf.expand_dims(l, 0))\n</code></pre>\n<p>When I set <code>dtype=tf.float64</code> the output is</p>\n<pre><code>// Eigen values\n[[ -2.31986627e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]]\n\n// Eigen vectors\n[[-0.5        -0.16245985  0.5        -0.68819096]\n [-0.5         0.16245985  0.5         0.68819096]\n [-0.5        -0.68819096 -0.5         0.16245985]\n [-0.5         0.68819096 -0.5        -0.16245985]]\n</code></pre>\n<p>When <code>dtype=tf.float32</code> the output is</p>\n<pre><code>// Eigen values\n[[ -1.02379988e-06   5.52786446e+00   1.20000019e+01   1.44721375e+01]]\n\n// Eigen vectors\n[[ 0.49999985  0.16245979  0.49999985 -0.68819106]\n [ 0.5        -0.16246006  0.50000018  0.68819082]\n [ 0.5         0.68819106 -0.49999988  0.16246004]\n [ 0.49999991 -0.68819088 -0.50000012 -0.16245979]]\n</code></pre>\n<p>In this case the sign of the second eigen vector changed.</p>\n<p>The numpy equivalent of this code always give the same result (in float or float32) and is similar to the result I got with the tf.float64 version</p>\n<pre><code>L = np.array([[10., -4., -4., -2.],\n                  [-4., 10., -2., -4.],\n                  [-4., -2., 6., 0.],\n                  [-2., -4., 0., 6.]])\nD, V =np.linalg.eigh(L)\n</code></pre>\n<pre><code>// numpy eigen values\n[  1.11716192e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]\n\n// numpy eigen vectors\n[[ 0.5        -0.16245985  0.5        -0.68819096]\n [ 0.5         0.16245985  0.5         0.68819096]\n [ 0.5        -0.68819096 -0.5         0.16245985]\n [ 0.5         0.68819096 -0.5        -0.16245985]]\n</code></pre>", "body_text": "Here is an example to reproduce the problem\nl = tf.constant([[10., -4., -4., -2.],\n                  [-4., 10., -2., -4.],\n                  [-4., -2., 6., 0.],\n                  [-2., -4., 0., 6.]], dtype=tf.float64)\ne, v = tf.self_adjoint_eig(tf.expand_dims(l, 0))\n\nWhen I set dtype=tf.float64 the output is\n// Eigen values\n[[ -2.31986627e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]]\n\n// Eigen vectors\n[[-0.5        -0.16245985  0.5        -0.68819096]\n [-0.5         0.16245985  0.5         0.68819096]\n [-0.5        -0.68819096 -0.5         0.16245985]\n [-0.5         0.68819096 -0.5        -0.16245985]]\n\nWhen dtype=tf.float32 the output is\n// Eigen values\n[[ -1.02379988e-06   5.52786446e+00   1.20000019e+01   1.44721375e+01]]\n\n// Eigen vectors\n[[ 0.49999985  0.16245979  0.49999985 -0.68819106]\n [ 0.5        -0.16246006  0.50000018  0.68819082]\n [ 0.5         0.68819106 -0.49999988  0.16246004]\n [ 0.49999991 -0.68819088 -0.50000012 -0.16245979]]\n\nIn this case the sign of the second eigen vector changed.\nThe numpy equivalent of this code always give the same result (in float or float32) and is similar to the result I got with the tf.float64 version\nL = np.array([[10., -4., -4., -2.],\n                  [-4., 10., -2., -4.],\n                  [-4., -2., 6., 0.],\n                  [-2., -4., 0., 6.]])\nD, V =np.linalg.eigh(L)\n\n// numpy eigen values\n[  1.11716192e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]\n\n// numpy eigen vectors\n[[ 0.5        -0.16245985  0.5        -0.68819096]\n [ 0.5         0.16245985  0.5         0.68819096]\n [ 0.5        -0.68819096 -0.5         0.16245985]\n [ 0.5         0.68819096 -0.5        -0.16245985]]", "body": "Here is an example to reproduce the problem\r\n\r\n```\r\nl = tf.constant([[10., -4., -4., -2.],\r\n                  [-4., 10., -2., -4.],\r\n                  [-4., -2., 6., 0.],\r\n                  [-2., -4., 0., 6.]], dtype=tf.float64)\r\ne, v = tf.self_adjoint_eig(tf.expand_dims(l, 0))\r\n```\r\n\r\nWhen I set `dtype=tf.float64` the output is\r\n\r\n```\r\n// Eigen values\r\n[[ -2.31986627e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]]\r\n\r\n// Eigen vectors\r\n[[-0.5        -0.16245985  0.5        -0.68819096]\r\n [-0.5         0.16245985  0.5         0.68819096]\r\n [-0.5        -0.68819096 -0.5         0.16245985]\r\n [-0.5         0.68819096 -0.5        -0.16245985]]\r\n```\r\n\r\nWhen `dtype=tf.float32` the output is\r\n\r\n```\r\n// Eigen values\r\n[[ -1.02379988e-06   5.52786446e+00   1.20000019e+01   1.44721375e+01]]\r\n\r\n// Eigen vectors\r\n[[ 0.49999985  0.16245979  0.49999985 -0.68819106]\r\n [ 0.5        -0.16246006  0.50000018  0.68819082]\r\n [ 0.5         0.68819106 -0.49999988  0.16246004]\r\n [ 0.49999991 -0.68819088 -0.50000012 -0.16245979]]\r\n```\r\nIn this case the sign of the second eigen vector changed.\r\n\r\nThe numpy equivalent of this code always give the same result (in float or float32) and is similar to the result I got with the tf.float64 version\r\n\r\n```\r\nL = np.array([[10., -4., -4., -2.],\r\n                  [-4., 10., -2., -4.],\r\n                  [-4., -2., 6., 0.],\r\n                  [-2., -4., 0., 6.]])\r\nD, V =np.linalg.eigh(L)\r\n```\r\n\r\n\r\n```\r\n// numpy eigen values\r\n[  1.11716192e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]\r\n\r\n// numpy eigen vectors\r\n[[ 0.5        -0.16245985  0.5        -0.68819096]\r\n [ 0.5         0.16245985  0.5         0.68819096]\r\n [ 0.5        -0.68819096 -0.5         0.16245985]\r\n [ 0.5         0.68819096 -0.5        -0.16245985]]\r\n```\r\n\r\n"}