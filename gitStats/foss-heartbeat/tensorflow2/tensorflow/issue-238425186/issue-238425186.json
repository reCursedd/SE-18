{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11051", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11051/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11051/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11051/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11051", "id": 238425186, "node_id": "MDU6SXNzdWUyMzg0MjUxODY=", "number": 11051, "title": "tensorflow inference in iOS produces EXC_BAD_ACCESS error when memory mapped graph is used", "user": {"login": "stmkjp", "id": 5444842, "node_id": "MDQ6VXNlcjU0NDQ4NDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5444842?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stmkjp", "html_url": "https://github.com/stmkjp", "followers_url": "https://api.github.com/users/stmkjp/followers", "following_url": "https://api.github.com/users/stmkjp/following{/other_user}", "gists_url": "https://api.github.com/users/stmkjp/gists{/gist_id}", "starred_url": "https://api.github.com/users/stmkjp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stmkjp/subscriptions", "organizations_url": "https://api.github.com/users/stmkjp/orgs", "repos_url": "https://api.github.com/users/stmkjp/repos", "events_url": "https://api.github.com/users/stmkjp/events{/privacy}", "received_events_url": "https://api.github.com/users/stmkjp/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-06-26T02:06:56Z", "updated_at": "2017-09-29T01:00:35Z", "closed_at": "2017-09-29T01:00:24Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: OSX Sierra (10.12.5)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source &amp; binary (tested both)</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.1.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.5.1-homebrew</li>\n<li><strong>CUDA/cuDNN version</strong>: CPU version used</li>\n<li><strong>GPU model and memory</strong>: CPU version used</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>Apologies if I posted an issue not appropriate here.<br>\nI asked this issue on stackoverflow a week ago but seems that no one interested in this issue.</p>\n<p>===========<br>\nI tested both iOS simple and camera example in tensorflow GitHub repo and they worked well.</p>\n<p>I checked those projects and recognized that camera example can use memory mapped graph if I modify constant variable \"model_uses_memory_mapping\" to true, while simple example cannot.</p>\n<p>So I modified simple example source to implement same function as camera example, and it seems that the mmapped graph loaded without problem, but when I run inference with session-&gt;Run method, the app gave me EXE_BAD_ACCESS error.</p>\n<p>I think I've done everything what I can do but still same error.</p>\n<p>No idea what else I can do for I'm not good at iOS nor tensorflow core functions.</p>\n<p>Could someone guide me how can I resolve this?</p>\n<p>FYI, run inference with optimized or quantized graph (with model_uses_memory_mapping set to false) works well.</p>\n<p>a) here's message I get when i execute session-&gt;Run method:</p>\n<pre><code>tf_ios_makefile_example`tensorflow::Env::NewReadOnlyMemoryRegionFromFile:\n    0x103157ad0 &lt;+0&gt;:  pushq  %rbp\n    0x103157ad1 &lt;+1&gt;:  movq   %rsp, %rbp\n    0x103157ad4 &lt;+4&gt;:  pushq  %r15\n    0x103157ad6 &lt;+6&gt;:  pushq  %r14\n    0x103157ad8 &lt;+8&gt;:  pushq  %rbx\n    0x103157ad9 &lt;+9&gt;:  pushq  %rax\n    0x103157ada &lt;+10&gt;: movq   %rcx, %r14\n    0x103157add &lt;+13&gt;: movq   %rdx, %r15\n    0x103157ae0 &lt;+16&gt;: movq   %rdi, %rbx\n    0x103157ae3 &lt;+19&gt;: movq   (%rsi), %rax\n    0x103157ae6 &lt;+22&gt;: leaq   -0x20(%rbp), %rcx\n-&gt;  0x103157aea &lt;+26&gt;: callq  *0x10(%rax)  \n    0x103157aed &lt;+29&gt;: cmpq   $0x0, (%rbx)\n    0x103157af1 &lt;+33&gt;: jne    0x103157b06               ; &lt;+54&gt;\n    0x103157af3 &lt;+35&gt;: movq   -0x20(%rbp), %rsi\n    0x103157af7 &lt;+39&gt;: movq   (%rsi), %rax\n    0x103157afa &lt;+42&gt;: movq   %rbx, %rdi\n    0x103157afd &lt;+45&gt;: movq   %r15, %rdx\n    0x103157b00 &lt;+48&gt;: movq   %r14, %rcx\n    0x103157b03 &lt;+51&gt;: callq  *0x18(%rax)\n    0x103157b06 &lt;+54&gt;: movq   %rbx, %rax\n    0x103157b09 &lt;+57&gt;: addq   $0x8, %rsp\n    0x103157b0d &lt;+61&gt;: popq   %rbx\n    0x103157b0e &lt;+62&gt;: popq   %r14\n    0x103157b10 &lt;+64&gt;: popq   %r15\n    0x103157b12 &lt;+66&gt;: popq   %rbp\n    0x103157b13 &lt;+67&gt;: retq   \n    0x103157b14 &lt;+68&gt;: nopw   %cs:(%rax,%rax)\n</code></pre>\n<p>and the error message shown on the line was: <strong>Thread19: EXC_BAD_ACCESS(code=EXC_I386_GPFLT)</strong></p>\n<p>b) and here's some of code I added/modified/used in simple example:</p>\n<p><strong>global variable declaration:</strong></p>\n<pre><code>static NSString* model_file_name = @\"mmapped_graph\";\nstatic NSString* model_file_type = @\"pb\";\nconst bool model_uses_memory_mapping = true;  //use memory mapped graph\n\nstatic NSString* labels_file_name = @\"retrained_labels\";\nstatic NSString* labels_file_type = @\"txt\";\n\nconst int wanted_width = 299;\nconst int wanted_height = 299;\nconst int wanted_channels = 3;\nconst float input_mean = 128.0f;\nconst float input_std = 128.0f;\nconst std::string input_layer = \"Mul\";\nconst std::string output_layer = \"final_result\";\n</code></pre>\n<p>method definition to read mmapped graph</p>\n<p>( referenced from camera example)</p>\n<pre><code>tensorflow::Status LoadMemoryMappedModel(\n    NSString* file_name, NSString* file_type,\n    std::unique_ptr&lt;tensorflow::Session&gt;* session,\n    std::unique_ptr&lt;tensorflow::MemmappedEnv&gt;* memmapped_env) {\n    NSString* network_path = FilePathForResourceName(file_name, file_type);\n    memmapped_env-&gt;reset(\n        new tensorflow::MemmappedEnv(tensorflow::Env::Default())\n    );\n    tensorflow::Status mmap_status =\n    (memmapped_env-&gt;get())-&gt;InitializeFromFile([network_path UTF8String]);\n    if (!mmap_status.ok()) {\n        LOG(ERROR) &lt;&lt; \"MMap failed with \" &lt;&lt; mmap_status.error_message();\n        return mmap_status;\n    }\n\n    tensorflow::GraphDef tensorflow_graph;\n    tensorflow::Status load_graph_status = ReadBinaryProto(\n                                                           memmapped_env-&gt;get(),\n                                                           tensorflow::MemmappedFileSystem::kMemmappedPackageDefaultGraphDef,\n                                                           &amp;tensorflow_graph);\n    if (!load_graph_status.ok()) {\n        LOG(ERROR) &lt;&lt; \"MMap load graph failed with \"\n        &lt;&lt; load_graph_status.error_message();\n        return load_graph_status;\n    }\n\n    tensorflow::SessionOptions options;\n    // Disable optimizations on this graph so that constant folding doesn't\n    // increase the memory footprint by creating new constant copies of the weight\n    // parameters.\n    options.config.mutable_graph_options()\n    -&gt;mutable_optimizer_options()\n    -&gt;set_opt_level(::tensorflow::OptimizerOptions::L0);\n    options.env = memmapped_env-&gt;get();\n\n    tensorflow::Session* session_pointer = nullptr;\n    tensorflow::Status session_status =\n    tensorflow::NewSession(options, &amp;session_pointer);\n    if (!session_status.ok()) {\n        LOG(ERROR) &lt;&lt; \"Could not create TensorFlow Session: \" &lt;&lt; session_status;\n        return session_status;\n    }\n\n    tensorflow::Status create_status = session_pointer-&gt;Create(tensorflow_graph);\n    //tensorflow::Status create_status = session_pointer-&gt;Create(*(tensorflow::GraphDef *)tensorflow_graph);\n\n    if (!create_status.ok()) {\n        LOG(ERROR) &lt;&lt; \"Could not create TensorFlow Graph: \" &lt;&lt; create_status;\n        return create_status;\n    }\n\n    session-&gt;reset(session_pointer);\n\n\n    return tensorflow::Status::OK();\n}\n</code></pre>\n<p><strong>and I load the graph and run inference like this</strong></p>\n<pre><code>NSString* RunInferenceOnImage() {\n  tensorflow::SessionOptions options;\n    std::unique_ptr&lt;tensorflow::Session&gt; session;\n\n  tensorflow::GraphDef tensorflow_graph;\n  LOG(INFO) &lt;&lt; \"Graph created.\";\n\n    tensorflow::Status load_status;\n\n    if (model_uses_memory_mapping) {\n        //use memmapped graph - gives me an error\n        std::unique_ptr&lt;tensorflow::MemmappedEnv&gt;  tf_memmapped_env;\n        load_status = LoadMemoryMappedModel(model_file_name, model_file_type, &amp;session, &amp;tf_memmapped_env);\n    } else {\n        // use optimized or quantized graph - this works well\n        NSString* network_path = FilePathForResourceName(model_file_name, model_file_type);\n        load_status = PortableReadFileToProto([network_path UTF8String],&amp;session, &amp;tensorflow_graph);\n    }\n\n    if (!load_status.ok()) {\n        LOG(FATAL) &lt;&lt; \"Couldn't load model: \" &lt;&lt; load_status;\n    }\n\n  // Read the label list\n  NSString* labels_path = FilePathForResourceName(@\"retrained_labels\", @\"txt\");\n  std::vector&lt;std::string&gt; label_strings;\n  std::ifstream t;\n  t.open([labels_path UTF8String]);\n  std::string line;\n  while(t){\n    std::getline(t, line);\n    label_strings.push_back(line);\n  }\n  t.close();\n\n  // Read the image.\n  NSString* image_path = FilePathForResourceName(@\"testimage\", @\"jpg\");\n  int image_width;\n  int image_height;\n  int image_channels;\n  std::vector&lt;tensorflow::uint8&gt; image_data = LoadImageFromFile(\n    [image_path UTF8String], &amp;image_width, &amp;image_height, &amp;image_channels);\n    LOG(INFO) &lt;&lt; \"Graph created5.\";\n\n  // image_channel is set to 4 from LoadImageFromFile method (not modified)\n\n  assert(image_channels &gt;= wanted_channels);\n  tensorflow::Tensor image_tensor(\n      tensorflow::DT_FLOAT,\n      tensorflow::TensorShape({\n          1, wanted_height, wanted_width, wanted_channels}));\n  auto image_tensor_mapped = image_tensor.tensor&lt;float, 4&gt;();\n\n  tensorflow::uint8* in = image_data.data();\n  tensorflow::uint8* in_end = (in + (image_height * image_width * image_channels));\n  float* out = image_tensor_mapped.data();\n  for (int y = 0; y &lt; wanted_height; ++y) {\n    const int in_y = (y * image_height) / wanted_height;\n    tensorflow::uint8* in_row = in + (in_y * image_width * image_channels);\n    float* out_row = out + (y * wanted_width * wanted_channels);\n    for (int x = 0; x &lt; wanted_width; ++x) {\n      const int in_x = (x * image_width) / wanted_width;\n      tensorflow::uint8* in_pixel = in_row + (in_x * image_channels);\n      float* out_pixel = out_row + (x * wanted_channels);\n      for (int c = 0; c &lt; wanted_channels; ++c) {\n        out_pixel[c] = (in_pixel[c] - input_mean) / input_std;\n      }\n    }\n  }\n    NSString* result = @\" Graph loaded!\";\n  result = [NSString stringWithFormat: @\"%@ - %d, %s - %dx%d\", result,\n    label_strings.size(), label_strings[0].c_str(), image_width, image_height];\n\n  std::vector&lt;tensorflow::Tensor&gt; outputs;\n    if(session.get()) {\n        LOG(INFO) &lt;&lt; \"SESSION OK!!!!!!\";\n    }\n\n\n  tensorflow::Status run_status = session-&gt;Run({{input_layer, image_tensor}},\n                               {output_layer}, {}, &amp;outputs);\n  // EXC_BAD_ACCESS error occur when session Run method called\n\n  if (!run_status.ok()) {\n  //  LOG(ERROR) &lt;&lt; \"Running model failed: \" &lt;&lt; run_status;\n    tensorflow::LogAllRegisteredKernels();\n    result = @\"Error running model\";\n    return result;\n  }\n  tensorflow::string status_string = run_status.ToString();\n  result = [NSString stringWithFormat: @\"%@ - %s\", result,\n    status_string.c_str()];\n\n  tensorflow::Tensor* output = &amp;outputs[0];\n  const int kNumResults = 5;\n  const float kThreshold = 0.1f;\n  std::vector&lt;std::pair&lt;float, int&gt; &gt; top_results;\n  GetTopN(output-&gt;flat&lt;float&gt;(), kNumResults, kThreshold, &amp;top_results);\n\n  std::stringstream ss;\n  ss.precision(3);\n  for (const auto&amp; result : top_results) {\n    const float confidence = result.first;\n    const int index = result.second;\n\n    ss &lt;&lt; index &lt;&lt; \" \" &lt;&lt; confidence &lt;&lt; \"  \";\n\n    // Write out the result as a string\n    if (index &lt; label_strings.size()) {\n      // just for safety: theoretically, the output is under 1000 unless there\n      // is some numerical issues leading to a wrong prediction.\n      ss &lt;&lt; label_strings[index];\n    } else {\n      ss &lt;&lt; \"Prediction: \" &lt;&lt; index;\n    }\n\n    ss &lt;&lt; \"\\n\";\n  }\n\n  LOG(INFO) &lt;&lt; \"Predictions: \" &lt;&lt; ss.str();\n\n  tensorflow::string predictions = ss.str();\n  result = [NSString stringWithFormat: @\"%@ - %s\", result,\n    predictions.c_str()];\n\n  return result;\n}\n</code></pre>\n<p>You can find original (unmodified) simple example project here: <a href=\"https://github.com/tensorflow/tensorflow/tree/v1.1.0/tensorflow/contrib/ios_examples/simple\">https://github.com/tensorflow/tensorflow/tree/v1.1.0/tensorflow/contrib/ios_examples/simple</a></p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm\">https://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm</a></p>\n<p>also you can find LoadImageFromFile method here: <a href=\"https://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/ios_image_load.mm\">https://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/ios_image_load.mm</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX Sierra (10.12.5)\nTensorFlow installed from (source or binary): source & binary (tested both)\nTensorFlow version (use command below): 1.1.0\nBazel version (if compiling from source): 0.5.1-homebrew\nCUDA/cuDNN version: CPU version used\nGPU model and memory: CPU version used\nExact command to reproduce:\n\nApologies if I posted an issue not appropriate here.\nI asked this issue on stackoverflow a week ago but seems that no one interested in this issue.\n===========\nI tested both iOS simple and camera example in tensorflow GitHub repo and they worked well.\nI checked those projects and recognized that camera example can use memory mapped graph if I modify constant variable \"model_uses_memory_mapping\" to true, while simple example cannot.\nSo I modified simple example source to implement same function as camera example, and it seems that the mmapped graph loaded without problem, but when I run inference with session->Run method, the app gave me EXE_BAD_ACCESS error.\nI think I've done everything what I can do but still same error.\nNo idea what else I can do for I'm not good at iOS nor tensorflow core functions.\nCould someone guide me how can I resolve this?\nFYI, run inference with optimized or quantized graph (with model_uses_memory_mapping set to false) works well.\na) here's message I get when i execute session->Run method:\ntf_ios_makefile_example`tensorflow::Env::NewReadOnlyMemoryRegionFromFile:\n    0x103157ad0 <+0>:  pushq  %rbp\n    0x103157ad1 <+1>:  movq   %rsp, %rbp\n    0x103157ad4 <+4>:  pushq  %r15\n    0x103157ad6 <+6>:  pushq  %r14\n    0x103157ad8 <+8>:  pushq  %rbx\n    0x103157ad9 <+9>:  pushq  %rax\n    0x103157ada <+10>: movq   %rcx, %r14\n    0x103157add <+13>: movq   %rdx, %r15\n    0x103157ae0 <+16>: movq   %rdi, %rbx\n    0x103157ae3 <+19>: movq   (%rsi), %rax\n    0x103157ae6 <+22>: leaq   -0x20(%rbp), %rcx\n->  0x103157aea <+26>: callq  *0x10(%rax)  \n    0x103157aed <+29>: cmpq   $0x0, (%rbx)\n    0x103157af1 <+33>: jne    0x103157b06               ; <+54>\n    0x103157af3 <+35>: movq   -0x20(%rbp), %rsi\n    0x103157af7 <+39>: movq   (%rsi), %rax\n    0x103157afa <+42>: movq   %rbx, %rdi\n    0x103157afd <+45>: movq   %r15, %rdx\n    0x103157b00 <+48>: movq   %r14, %rcx\n    0x103157b03 <+51>: callq  *0x18(%rax)\n    0x103157b06 <+54>: movq   %rbx, %rax\n    0x103157b09 <+57>: addq   $0x8, %rsp\n    0x103157b0d <+61>: popq   %rbx\n    0x103157b0e <+62>: popq   %r14\n    0x103157b10 <+64>: popq   %r15\n    0x103157b12 <+66>: popq   %rbp\n    0x103157b13 <+67>: retq   \n    0x103157b14 <+68>: nopw   %cs:(%rax,%rax)\n\nand the error message shown on the line was: Thread19: EXC_BAD_ACCESS(code=EXC_I386_GPFLT)\nb) and here's some of code I added/modified/used in simple example:\nglobal variable declaration:\nstatic NSString* model_file_name = @\"mmapped_graph\";\nstatic NSString* model_file_type = @\"pb\";\nconst bool model_uses_memory_mapping = true;  //use memory mapped graph\n\nstatic NSString* labels_file_name = @\"retrained_labels\";\nstatic NSString* labels_file_type = @\"txt\";\n\nconst int wanted_width = 299;\nconst int wanted_height = 299;\nconst int wanted_channels = 3;\nconst float input_mean = 128.0f;\nconst float input_std = 128.0f;\nconst std::string input_layer = \"Mul\";\nconst std::string output_layer = \"final_result\";\n\nmethod definition to read mmapped graph\n( referenced from camera example)\ntensorflow::Status LoadMemoryMappedModel(\n    NSString* file_name, NSString* file_type,\n    std::unique_ptr<tensorflow::Session>* session,\n    std::unique_ptr<tensorflow::MemmappedEnv>* memmapped_env) {\n    NSString* network_path = FilePathForResourceName(file_name, file_type);\n    memmapped_env->reset(\n        new tensorflow::MemmappedEnv(tensorflow::Env::Default())\n    );\n    tensorflow::Status mmap_status =\n    (memmapped_env->get())->InitializeFromFile([network_path UTF8String]);\n    if (!mmap_status.ok()) {\n        LOG(ERROR) << \"MMap failed with \" << mmap_status.error_message();\n        return mmap_status;\n    }\n\n    tensorflow::GraphDef tensorflow_graph;\n    tensorflow::Status load_graph_status = ReadBinaryProto(\n                                                           memmapped_env->get(),\n                                                           tensorflow::MemmappedFileSystem::kMemmappedPackageDefaultGraphDef,\n                                                           &tensorflow_graph);\n    if (!load_graph_status.ok()) {\n        LOG(ERROR) << \"MMap load graph failed with \"\n        << load_graph_status.error_message();\n        return load_graph_status;\n    }\n\n    tensorflow::SessionOptions options;\n    // Disable optimizations on this graph so that constant folding doesn't\n    // increase the memory footprint by creating new constant copies of the weight\n    // parameters.\n    options.config.mutable_graph_options()\n    ->mutable_optimizer_options()\n    ->set_opt_level(::tensorflow::OptimizerOptions::L0);\n    options.env = memmapped_env->get();\n\n    tensorflow::Session* session_pointer = nullptr;\n    tensorflow::Status session_status =\n    tensorflow::NewSession(options, &session_pointer);\n    if (!session_status.ok()) {\n        LOG(ERROR) << \"Could not create TensorFlow Session: \" << session_status;\n        return session_status;\n    }\n\n    tensorflow::Status create_status = session_pointer->Create(tensorflow_graph);\n    //tensorflow::Status create_status = session_pointer->Create(*(tensorflow::GraphDef *)tensorflow_graph);\n\n    if (!create_status.ok()) {\n        LOG(ERROR) << \"Could not create TensorFlow Graph: \" << create_status;\n        return create_status;\n    }\n\n    session->reset(session_pointer);\n\n\n    return tensorflow::Status::OK();\n}\n\nand I load the graph and run inference like this\nNSString* RunInferenceOnImage() {\n  tensorflow::SessionOptions options;\n    std::unique_ptr<tensorflow::Session> session;\n\n  tensorflow::GraphDef tensorflow_graph;\n  LOG(INFO) << \"Graph created.\";\n\n    tensorflow::Status load_status;\n\n    if (model_uses_memory_mapping) {\n        //use memmapped graph - gives me an error\n        std::unique_ptr<tensorflow::MemmappedEnv>  tf_memmapped_env;\n        load_status = LoadMemoryMappedModel(model_file_name, model_file_type, &session, &tf_memmapped_env);\n    } else {\n        // use optimized or quantized graph - this works well\n        NSString* network_path = FilePathForResourceName(model_file_name, model_file_type);\n        load_status = PortableReadFileToProto([network_path UTF8String],&session, &tensorflow_graph);\n    }\n\n    if (!load_status.ok()) {\n        LOG(FATAL) << \"Couldn't load model: \" << load_status;\n    }\n\n  // Read the label list\n  NSString* labels_path = FilePathForResourceName(@\"retrained_labels\", @\"txt\");\n  std::vector<std::string> label_strings;\n  std::ifstream t;\n  t.open([labels_path UTF8String]);\n  std::string line;\n  while(t){\n    std::getline(t, line);\n    label_strings.push_back(line);\n  }\n  t.close();\n\n  // Read the image.\n  NSString* image_path = FilePathForResourceName(@\"testimage\", @\"jpg\");\n  int image_width;\n  int image_height;\n  int image_channels;\n  std::vector<tensorflow::uint8> image_data = LoadImageFromFile(\n    [image_path UTF8String], &image_width, &image_height, &image_channels);\n    LOG(INFO) << \"Graph created5.\";\n\n  // image_channel is set to 4 from LoadImageFromFile method (not modified)\n\n  assert(image_channels >= wanted_channels);\n  tensorflow::Tensor image_tensor(\n      tensorflow::DT_FLOAT,\n      tensorflow::TensorShape({\n          1, wanted_height, wanted_width, wanted_channels}));\n  auto image_tensor_mapped = image_tensor.tensor<float, 4>();\n\n  tensorflow::uint8* in = image_data.data();\n  tensorflow::uint8* in_end = (in + (image_height * image_width * image_channels));\n  float* out = image_tensor_mapped.data();\n  for (int y = 0; y < wanted_height; ++y) {\n    const int in_y = (y * image_height) / wanted_height;\n    tensorflow::uint8* in_row = in + (in_y * image_width * image_channels);\n    float* out_row = out + (y * wanted_width * wanted_channels);\n    for (int x = 0; x < wanted_width; ++x) {\n      const int in_x = (x * image_width) / wanted_width;\n      tensorflow::uint8* in_pixel = in_row + (in_x * image_channels);\n      float* out_pixel = out_row + (x * wanted_channels);\n      for (int c = 0; c < wanted_channels; ++c) {\n        out_pixel[c] = (in_pixel[c] - input_mean) / input_std;\n      }\n    }\n  }\n    NSString* result = @\" Graph loaded!\";\n  result = [NSString stringWithFormat: @\"%@ - %d, %s - %dx%d\", result,\n    label_strings.size(), label_strings[0].c_str(), image_width, image_height];\n\n  std::vector<tensorflow::Tensor> outputs;\n    if(session.get()) {\n        LOG(INFO) << \"SESSION OK!!!!!!\";\n    }\n\n\n  tensorflow::Status run_status = session->Run({{input_layer, image_tensor}},\n                               {output_layer}, {}, &outputs);\n  // EXC_BAD_ACCESS error occur when session Run method called\n\n  if (!run_status.ok()) {\n  //  LOG(ERROR) << \"Running model failed: \" << run_status;\n    tensorflow::LogAllRegisteredKernels();\n    result = @\"Error running model\";\n    return result;\n  }\n  tensorflow::string status_string = run_status.ToString();\n  result = [NSString stringWithFormat: @\"%@ - %s\", result,\n    status_string.c_str()];\n\n  tensorflow::Tensor* output = &outputs[0];\n  const int kNumResults = 5;\n  const float kThreshold = 0.1f;\n  std::vector<std::pair<float, int> > top_results;\n  GetTopN(output->flat<float>(), kNumResults, kThreshold, &top_results);\n\n  std::stringstream ss;\n  ss.precision(3);\n  for (const auto& result : top_results) {\n    const float confidence = result.first;\n    const int index = result.second;\n\n    ss << index << \" \" << confidence << \"  \";\n\n    // Write out the result as a string\n    if (index < label_strings.size()) {\n      // just for safety: theoretically, the output is under 1000 unless there\n      // is some numerical issues leading to a wrong prediction.\n      ss << label_strings[index];\n    } else {\n      ss << \"Prediction: \" << index;\n    }\n\n    ss << \"\\n\";\n  }\n\n  LOG(INFO) << \"Predictions: \" << ss.str();\n\n  tensorflow::string predictions = ss.str();\n  result = [NSString stringWithFormat: @\"%@ - %s\", result,\n    predictions.c_str()];\n\n  return result;\n}\n\nYou can find original (unmodified) simple example project here: https://github.com/tensorflow/tensorflow/tree/v1.1.0/tensorflow/contrib/ios_examples/simple\nhttps://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm\nalso you can find LoadImageFromFile method here: https://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/ios_image_load.mm", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX Sierra (10.12.5)\r\n- **TensorFlow installed from (source or binary)**: source & binary (tested both)\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Bazel version (if compiling from source)**: 0.5.1-homebrew\r\n- **CUDA/cuDNN version**: CPU version used\r\n- **GPU model and memory**: CPU version used\r\n- **Exact command to reproduce**: \r\n\r\nApologies if I posted an issue not appropriate here.\r\nI asked this issue on stackoverflow a week ago but seems that no one interested in this issue.\r\n\r\n===========\r\nI tested both iOS simple and camera example in tensorflow GitHub repo and they worked well.\r\n\r\nI checked those projects and recognized that camera example can use memory mapped graph if I modify constant variable \"model_uses_memory_mapping\" to true, while simple example cannot.\r\n\r\nSo I modified simple example source to implement same function as camera example, and it seems that the mmapped graph loaded without problem, but when I run inference with session->Run method, the app gave me EXE_BAD_ACCESS error.\r\n\r\nI think I've done everything what I can do but still same error.\r\n\r\nNo idea what else I can do for I'm not good at iOS nor tensorflow core functions.\r\n\r\nCould someone guide me how can I resolve this?\r\n\r\nFYI, run inference with optimized or quantized graph (with model_uses_memory_mapping set to false) works well.\r\n\r\na) here's message I get when i execute session->Run method:\r\n\r\n```\r\ntf_ios_makefile_example`tensorflow::Env::NewReadOnlyMemoryRegionFromFile:\r\n    0x103157ad0 <+0>:  pushq  %rbp\r\n    0x103157ad1 <+1>:  movq   %rsp, %rbp\r\n    0x103157ad4 <+4>:  pushq  %r15\r\n    0x103157ad6 <+6>:  pushq  %r14\r\n    0x103157ad8 <+8>:  pushq  %rbx\r\n    0x103157ad9 <+9>:  pushq  %rax\r\n    0x103157ada <+10>: movq   %rcx, %r14\r\n    0x103157add <+13>: movq   %rdx, %r15\r\n    0x103157ae0 <+16>: movq   %rdi, %rbx\r\n    0x103157ae3 <+19>: movq   (%rsi), %rax\r\n    0x103157ae6 <+22>: leaq   -0x20(%rbp), %rcx\r\n->  0x103157aea <+26>: callq  *0x10(%rax)  \r\n    0x103157aed <+29>: cmpq   $0x0, (%rbx)\r\n    0x103157af1 <+33>: jne    0x103157b06               ; <+54>\r\n    0x103157af3 <+35>: movq   -0x20(%rbp), %rsi\r\n    0x103157af7 <+39>: movq   (%rsi), %rax\r\n    0x103157afa <+42>: movq   %rbx, %rdi\r\n    0x103157afd <+45>: movq   %r15, %rdx\r\n    0x103157b00 <+48>: movq   %r14, %rcx\r\n    0x103157b03 <+51>: callq  *0x18(%rax)\r\n    0x103157b06 <+54>: movq   %rbx, %rax\r\n    0x103157b09 <+57>: addq   $0x8, %rsp\r\n    0x103157b0d <+61>: popq   %rbx\r\n    0x103157b0e <+62>: popq   %r14\r\n    0x103157b10 <+64>: popq   %r15\r\n    0x103157b12 <+66>: popq   %rbp\r\n    0x103157b13 <+67>: retq   \r\n    0x103157b14 <+68>: nopw   %cs:(%rax,%rax)\r\n```\r\nand the error message shown on the line was: **Thread19: EXC_BAD_ACCESS(code=EXC_I386_GPFLT)**\r\n\r\nb) and here's some of code I added/modified/used in simple example:\r\n\r\n**global variable declaration:**\r\n\r\n```\r\nstatic NSString* model_file_name = @\"mmapped_graph\";\r\nstatic NSString* model_file_type = @\"pb\";\r\nconst bool model_uses_memory_mapping = true;  //use memory mapped graph\r\n\r\nstatic NSString* labels_file_name = @\"retrained_labels\";\r\nstatic NSString* labels_file_type = @\"txt\";\r\n\r\nconst int wanted_width = 299;\r\nconst int wanted_height = 299;\r\nconst int wanted_channels = 3;\r\nconst float input_mean = 128.0f;\r\nconst float input_std = 128.0f;\r\nconst std::string input_layer = \"Mul\";\r\nconst std::string output_layer = \"final_result\";\r\n```\r\nmethod definition to read mmapped graph\r\n\r\n( referenced from camera example)\r\n\r\n```\r\ntensorflow::Status LoadMemoryMappedModel(\r\n    NSString* file_name, NSString* file_type,\r\n    std::unique_ptr<tensorflow::Session>* session,\r\n    std::unique_ptr<tensorflow::MemmappedEnv>* memmapped_env) {\r\n    NSString* network_path = FilePathForResourceName(file_name, file_type);\r\n    memmapped_env->reset(\r\n        new tensorflow::MemmappedEnv(tensorflow::Env::Default())\r\n    );\r\n    tensorflow::Status mmap_status =\r\n    (memmapped_env->get())->InitializeFromFile([network_path UTF8String]);\r\n    if (!mmap_status.ok()) {\r\n        LOG(ERROR) << \"MMap failed with \" << mmap_status.error_message();\r\n        return mmap_status;\r\n    }\r\n\r\n    tensorflow::GraphDef tensorflow_graph;\r\n    tensorflow::Status load_graph_status = ReadBinaryProto(\r\n                                                           memmapped_env->get(),\r\n                                                           tensorflow::MemmappedFileSystem::kMemmappedPackageDefaultGraphDef,\r\n                                                           &tensorflow_graph);\r\n    if (!load_graph_status.ok()) {\r\n        LOG(ERROR) << \"MMap load graph failed with \"\r\n        << load_graph_status.error_message();\r\n        return load_graph_status;\r\n    }\r\n\r\n    tensorflow::SessionOptions options;\r\n    // Disable optimizations on this graph so that constant folding doesn't\r\n    // increase the memory footprint by creating new constant copies of the weight\r\n    // parameters.\r\n    options.config.mutable_graph_options()\r\n    ->mutable_optimizer_options()\r\n    ->set_opt_level(::tensorflow::OptimizerOptions::L0);\r\n    options.env = memmapped_env->get();\r\n\r\n    tensorflow::Session* session_pointer = nullptr;\r\n    tensorflow::Status session_status =\r\n    tensorflow::NewSession(options, &session_pointer);\r\n    if (!session_status.ok()) {\r\n        LOG(ERROR) << \"Could not create TensorFlow Session: \" << session_status;\r\n        return session_status;\r\n    }\r\n\r\n    tensorflow::Status create_status = session_pointer->Create(tensorflow_graph);\r\n    //tensorflow::Status create_status = session_pointer->Create(*(tensorflow::GraphDef *)tensorflow_graph);\r\n\r\n    if (!create_status.ok()) {\r\n        LOG(ERROR) << \"Could not create TensorFlow Graph: \" << create_status;\r\n        return create_status;\r\n    }\r\n\r\n    session->reset(session_pointer);\r\n\r\n\r\n    return tensorflow::Status::OK();\r\n}\r\n```\r\n**and I load the graph and run inference like this**\r\n\r\n```\r\nNSString* RunInferenceOnImage() {\r\n  tensorflow::SessionOptions options;\r\n    std::unique_ptr<tensorflow::Session> session;\r\n\r\n  tensorflow::GraphDef tensorflow_graph;\r\n  LOG(INFO) << \"Graph created.\";\r\n\r\n    tensorflow::Status load_status;\r\n\r\n    if (model_uses_memory_mapping) {\r\n        //use memmapped graph - gives me an error\r\n        std::unique_ptr<tensorflow::MemmappedEnv>  tf_memmapped_env;\r\n        load_status = LoadMemoryMappedModel(model_file_name, model_file_type, &session, &tf_memmapped_env);\r\n    } else {\r\n        // use optimized or quantized graph - this works well\r\n        NSString* network_path = FilePathForResourceName(model_file_name, model_file_type);\r\n        load_status = PortableReadFileToProto([network_path UTF8String],&session, &tensorflow_graph);\r\n    }\r\n\r\n    if (!load_status.ok()) {\r\n        LOG(FATAL) << \"Couldn't load model: \" << load_status;\r\n    }\r\n\r\n  // Read the label list\r\n  NSString* labels_path = FilePathForResourceName(@\"retrained_labels\", @\"txt\");\r\n  std::vector<std::string> label_strings;\r\n  std::ifstream t;\r\n  t.open([labels_path UTF8String]);\r\n  std::string line;\r\n  while(t){\r\n    std::getline(t, line);\r\n    label_strings.push_back(line);\r\n  }\r\n  t.close();\r\n\r\n  // Read the image.\r\n  NSString* image_path = FilePathForResourceName(@\"testimage\", @\"jpg\");\r\n  int image_width;\r\n  int image_height;\r\n  int image_channels;\r\n  std::vector<tensorflow::uint8> image_data = LoadImageFromFile(\r\n    [image_path UTF8String], &image_width, &image_height, &image_channels);\r\n    LOG(INFO) << \"Graph created5.\";\r\n\r\n  // image_channel is set to 4 from LoadImageFromFile method (not modified)\r\n\r\n  assert(image_channels >= wanted_channels);\r\n  tensorflow::Tensor image_tensor(\r\n      tensorflow::DT_FLOAT,\r\n      tensorflow::TensorShape({\r\n          1, wanted_height, wanted_width, wanted_channels}));\r\n  auto image_tensor_mapped = image_tensor.tensor<float, 4>();\r\n\r\n  tensorflow::uint8* in = image_data.data();\r\n  tensorflow::uint8* in_end = (in + (image_height * image_width * image_channels));\r\n  float* out = image_tensor_mapped.data();\r\n  for (int y = 0; y < wanted_height; ++y) {\r\n    const int in_y = (y * image_height) / wanted_height;\r\n    tensorflow::uint8* in_row = in + (in_y * image_width * image_channels);\r\n    float* out_row = out + (y * wanted_width * wanted_channels);\r\n    for (int x = 0; x < wanted_width; ++x) {\r\n      const int in_x = (x * image_width) / wanted_width;\r\n      tensorflow::uint8* in_pixel = in_row + (in_x * image_channels);\r\n      float* out_pixel = out_row + (x * wanted_channels);\r\n      for (int c = 0; c < wanted_channels; ++c) {\r\n        out_pixel[c] = (in_pixel[c] - input_mean) / input_std;\r\n      }\r\n    }\r\n  }\r\n    NSString* result = @\" Graph loaded!\";\r\n  result = [NSString stringWithFormat: @\"%@ - %d, %s - %dx%d\", result,\r\n    label_strings.size(), label_strings[0].c_str(), image_width, image_height];\r\n\r\n  std::vector<tensorflow::Tensor> outputs;\r\n    if(session.get()) {\r\n        LOG(INFO) << \"SESSION OK!!!!!!\";\r\n    }\r\n\r\n\r\n  tensorflow::Status run_status = session->Run({{input_layer, image_tensor}},\r\n                               {output_layer}, {}, &outputs);\r\n  // EXC_BAD_ACCESS error occur when session Run method called\r\n\r\n  if (!run_status.ok()) {\r\n  //  LOG(ERROR) << \"Running model failed: \" << run_status;\r\n    tensorflow::LogAllRegisteredKernels();\r\n    result = @\"Error running model\";\r\n    return result;\r\n  }\r\n  tensorflow::string status_string = run_status.ToString();\r\n  result = [NSString stringWithFormat: @\"%@ - %s\", result,\r\n    status_string.c_str()];\r\n\r\n  tensorflow::Tensor* output = &outputs[0];\r\n  const int kNumResults = 5;\r\n  const float kThreshold = 0.1f;\r\n  std::vector<std::pair<float, int> > top_results;\r\n  GetTopN(output->flat<float>(), kNumResults, kThreshold, &top_results);\r\n\r\n  std::stringstream ss;\r\n  ss.precision(3);\r\n  for (const auto& result : top_results) {\r\n    const float confidence = result.first;\r\n    const int index = result.second;\r\n\r\n    ss << index << \" \" << confidence << \"  \";\r\n\r\n    // Write out the result as a string\r\n    if (index < label_strings.size()) {\r\n      // just for safety: theoretically, the output is under 1000 unless there\r\n      // is some numerical issues leading to a wrong prediction.\r\n      ss << label_strings[index];\r\n    } else {\r\n      ss << \"Prediction: \" << index;\r\n    }\r\n\r\n    ss << \"\\n\";\r\n  }\r\n\r\n  LOG(INFO) << \"Predictions: \" << ss.str();\r\n\r\n  tensorflow::string predictions = ss.str();\r\n  result = [NSString stringWithFormat: @\"%@ - %s\", result,\r\n    predictions.c_str()];\r\n\r\n  return result;\r\n}\r\n```\r\n\r\nYou can find original (unmodified) simple example project here: https://github.com/tensorflow/tensorflow/tree/v1.1.0/tensorflow/contrib/ios_examples/simple\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm\r\n\r\nalso you can find LoadImageFromFile method here: https://github.com/tensorflow/tensorflow/blob/v1.1.0/tensorflow/contrib/ios_examples/simple/ios_image_load.mm"}