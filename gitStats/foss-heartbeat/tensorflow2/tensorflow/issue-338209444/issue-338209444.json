{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20543", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20543/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20543/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20543/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20543", "id": 338209444, "node_id": "MDU6SXNzdWUzMzgyMDk0NDQ=", "number": 20543, "title": "how to run multiple models parallel in different graph?", "user": {"login": "githubgsq", "id": 23164715, "node_id": "MDQ6VXNlcjIzMTY0NzE1", "avatar_url": "https://avatars3.githubusercontent.com/u/23164715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/githubgsq", "html_url": "https://github.com/githubgsq", "followers_url": "https://api.github.com/users/githubgsq/followers", "following_url": "https://api.github.com/users/githubgsq/following{/other_user}", "gists_url": "https://api.github.com/users/githubgsq/gists{/gist_id}", "starred_url": "https://api.github.com/users/githubgsq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/githubgsq/subscriptions", "organizations_url": "https://api.github.com/users/githubgsq/orgs", "repos_url": "https://api.github.com/users/githubgsq/repos", "events_url": "https://api.github.com/users/githubgsq/events{/privacy}", "received_events_url": "https://api.github.com/users/githubgsq/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-07-04T09:56:15Z", "updated_at": "2018-07-06T19:26:15Z", "closed_at": "2018-07-06T19:26:14Z", "author_association": "NONE", "body_html": "<p>hi, all:<br>\nI have a machine with 2 GPUs. How could I train 2 models parallel with 2 sub-processes in seperable graphs please?<br>\nI tried this:</p>\n<div class=\"highlight highlight-source-python\"><pre>loaded_data <span class=\"pl-k\">=</span> load_data(dir_name)\n<span class=\"pl-c1\">GPU_NUM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">GPU_NUM</span>):\n    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(i)):\n        <span class=\"pl-k\">with</span> tf.Graph().as_default():\n            sub_process <span class=\"pl-k\">=</span> multiprocessing.Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>func, <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>(loaded_data))</pre></div>\n<p>I called nvidia-smi, but only one GPU is running.<br>\nAny suggestions would be appreciated.<br>\nThanks a lot:)</p>", "body_text": "hi, all:\nI have a machine with 2 GPUs. How could I train 2 models parallel with 2 sub-processes in seperable graphs please?\nI tried this:\nloaded_data = load_data(dir_name)\nGPU_NUM = 2\nfor i in range(GPU_NUM):\n    with tf.device('/gpu:{}'.format(i)):\n        with tf.Graph().as_default():\n            sub_process = multiprocessing.Process(target=func, args=(loaded_data))\nI called nvidia-smi, but only one GPU is running.\nAny suggestions would be appreciated.\nThanks a lot:)", "body": "hi, all:\r\n  I have a machine with 2 GPUs. How could I train 2 models parallel with 2 sub-processes in seperable graphs please?\r\n  I tried this:\r\n\r\n```python\r\nloaded_data = load_data(dir_name)\r\nGPU_NUM = 2\r\nfor i in range(GPU_NUM):\r\n    with tf.device('/gpu:{}'.format(i)):\r\n        with tf.Graph().as_default():\r\n            sub_process = multiprocessing.Process(target=func, args=(loaded_data))\r\n```\r\n \r\n  I called nvidia-smi, but only one GPU is running.\r\n  Any suggestions would be appreciated. \r\n  Thanks a lot:)"}