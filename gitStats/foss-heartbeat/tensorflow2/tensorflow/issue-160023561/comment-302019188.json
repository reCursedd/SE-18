{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302019188", "html_url": "https://github.com/tensorflow/tensorflow/issues/2838#issuecomment-302019188", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2838", "id": 302019188, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjAxOTE4OA==", "user": {"login": "carlthome", "id": 1595907, "node_id": "MDQ6VXNlcjE1OTU5MDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1595907?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carlthome", "html_url": "https://github.com/carlthome", "followers_url": "https://api.github.com/users/carlthome/followers", "following_url": "https://api.github.com/users/carlthome/following{/other_user}", "gists_url": "https://api.github.com/users/carlthome/gists{/gist_id}", "starred_url": "https://api.github.com/users/carlthome/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carlthome/subscriptions", "organizations_url": "https://api.github.com/users/carlthome/orgs", "repos_url": "https://api.github.com/users/carlthome/repos", "events_url": "https://api.github.com/users/carlthome/events{/privacy}", "received_events_url": "https://api.github.com/users/carlthome/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-17T08:15:25Z", "updated_at": "2018-05-23T08:40:23Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I now do something like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> tensorflow.contrib.framework <span class=\"pl-k\">import</span> nest\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">rnn_placeholders</span>(<span class=\"pl-smi\">state</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Convert RNN state tensors to placeholders with the zero state as default.<span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(state, tf.contrib.rnn.LSTMStateTuple):\n        c, h <span class=\"pl-k\">=</span> state\n        c <span class=\"pl-k\">=</span> tf.placeholder_with_default(c, c.shape, c.op.name)\n        h <span class=\"pl-k\">=</span> tf.placeholder_with_default(h, h.shape, h.op.name)\n        <span class=\"pl-k\">return</span> tf.contrib.rnn.LSTMStateTuple(c, h)\n    <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(state, tf.Tensor):\n        h <span class=\"pl-k\">=</span> state\n        h <span class=\"pl-k\">=</span> tf.placeholder_with_default(h, h.shape, h.op.name)\n        <span class=\"pl-k\">return</span> h\n    <span class=\"pl-k\">else</span>:\n        structure <span class=\"pl-k\">=</span> [rnn_placeholders(x) <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> state]\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">tuple</span>(structure)\n\n\nstate <span class=\"pl-k\">=</span> rnn_placeholders(cell.zero_state(batch_size, tf.float32))\n\n<span class=\"pl-k\">for</span> tensor <span class=\"pl-k\">in</span> nest.flatten(state):\n    tf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>rnn_state_input<span class=\"pl-pds\">'</span></span>, tensor)\n\nx, new_state <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(<span class=\"pl-c1\">...</span>)\n\n<span class=\"pl-k\">for</span> tensor <span class=\"pl-k\">in</span> nest.flatten(new_state):\n    tf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>rnn_state_output<span class=\"pl-pds\">'</span></span>, tensor)</pre></div>\n<p>which works with arbitrarily nested RNN structures and works well enough (although fetching seems wasteful) until the state managing stuff <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> seems to be working on in the seq2seq stuff (it's hinted at in around the RNN documentation, anyway) becomes available.</p>\n<p>I could do a pull request to contrib if an utility function like this would be of interest, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a>.</p>", "body_text": "I now do something like this:\nfrom tensorflow.contrib.framework import nest\n\n\ndef rnn_placeholders(state):\n    \"\"\"Convert RNN state tensors to placeholders with the zero state as default.\"\"\"\n    if isinstance(state, tf.contrib.rnn.LSTMStateTuple):\n        c, h = state\n        c = tf.placeholder_with_default(c, c.shape, c.op.name)\n        h = tf.placeholder_with_default(h, h.shape, h.op.name)\n        return tf.contrib.rnn.LSTMStateTuple(c, h)\n    elif isinstance(state, tf.Tensor):\n        h = state\n        h = tf.placeholder_with_default(h, h.shape, h.op.name)\n        return h\n    else:\n        structure = [rnn_placeholders(x) for x in state]\n        return tuple(structure)\n\n\nstate = rnn_placeholders(cell.zero_state(batch_size, tf.float32))\n\nfor tensor in nest.flatten(state):\n    tf.add_to_collection('rnn_state_input', tensor)\n\nx, new_state = tf.nn.dynamic_rnn(...)\n\nfor tensor in nest.flatten(new_state):\n    tf.add_to_collection('rnn_state_output', tensor)\nwhich works with arbitrarily nested RNN structures and works well enough (although fetching seems wasteful) until the state managing stuff @ebrevdo seems to be working on in the seq2seq stuff (it's hinted at in around the RNN documentation, anyway) becomes available.\nI could do a pull request to contrib if an utility function like this would be of interest, @ebrevdo.", "body": "I now do something like this:\r\n\r\n```python\r\nfrom tensorflow.contrib.framework import nest\r\n\r\n\r\ndef rnn_placeholders(state):\r\n    \"\"\"Convert RNN state tensors to placeholders with the zero state as default.\"\"\"\r\n    if isinstance(state, tf.contrib.rnn.LSTMStateTuple):\r\n        c, h = state\r\n        c = tf.placeholder_with_default(c, c.shape, c.op.name)\r\n        h = tf.placeholder_with_default(h, h.shape, h.op.name)\r\n        return tf.contrib.rnn.LSTMStateTuple(c, h)\r\n    elif isinstance(state, tf.Tensor):\r\n        h = state\r\n        h = tf.placeholder_with_default(h, h.shape, h.op.name)\r\n        return h\r\n    else:\r\n        structure = [rnn_placeholders(x) for x in state]\r\n        return tuple(structure)\r\n\r\n\r\nstate = rnn_placeholders(cell.zero_state(batch_size, tf.float32))\r\n\r\nfor tensor in nest.flatten(state):\r\n    tf.add_to_collection('rnn_state_input', tensor)\r\n\r\nx, new_state = tf.nn.dynamic_rnn(...)\r\n\r\nfor tensor in nest.flatten(new_state):\r\n    tf.add_to_collection('rnn_state_output', tensor)\r\n```\r\nwhich works with arbitrarily nested RNN structures and works well enough (although fetching seems wasteful) until the state managing stuff @ebrevdo seems to be working on in the seq2seq stuff (it's hinted at in around the RNN documentation, anyway) becomes available.\r\n\r\nI could do a pull request to contrib if an utility function like this would be of interest, @ebrevdo."}