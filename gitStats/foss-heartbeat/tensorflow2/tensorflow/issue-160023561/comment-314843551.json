{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/314843551", "html_url": "https://github.com/tensorflow/tensorflow/issues/2838#issuecomment-314843551", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2838", "id": 314843551, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNDg0MzU1MQ==", "user": {"login": "RylanSchaeffer", "id": 8942987, "node_id": "MDQ6VXNlcjg5NDI5ODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/8942987?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RylanSchaeffer", "html_url": "https://github.com/RylanSchaeffer", "followers_url": "https://api.github.com/users/RylanSchaeffer/followers", "following_url": "https://api.github.com/users/RylanSchaeffer/following{/other_user}", "gists_url": "https://api.github.com/users/RylanSchaeffer/gists{/gist_id}", "starred_url": "https://api.github.com/users/RylanSchaeffer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RylanSchaeffer/subscriptions", "organizations_url": "https://api.github.com/users/RylanSchaeffer/orgs", "repos_url": "https://api.github.com/users/RylanSchaeffer/repos", "events_url": "https://api.github.com/users/RylanSchaeffer/events{/privacy}", "received_events_url": "https://api.github.com/users/RylanSchaeffer/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-12T17:42:08Z", "updated_at": "2017-07-12T17:42:08Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> , does <code>tf.contrib.training.batch_sequences_with_states</code> work with sequence to sequence models, and if so, how?</p>\n<p>My guess is that I need to create two <code>batch_sequences_with_state</code>, one for the input sequence and the other for the output sequence, and then feed one into my encoder and the other into my decoder. Is that correct?</p>", "body_text": "@ebrevdo , does tf.contrib.training.batch_sequences_with_states work with sequence to sequence models, and if so, how?\nMy guess is that I need to create two batch_sequences_with_state, one for the input sequence and the other for the output sequence, and then feed one into my encoder and the other into my decoder. Is that correct?", "body": "@ebrevdo , does `tf.contrib.training.batch_sequences_with_states` work with sequence to sequence models, and if so, how?\r\n\r\nMy guess is that I need to create two `batch_sequences_with_state`, one for the input sequence and the other for the output sequence, and then feed one into my encoder and the other into my decoder. Is that correct?\r\n"}