{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14572", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14572/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14572/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14572/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14572", "id": 274071531, "node_id": "MDU6SXNzdWUyNzQwNzE1MzE=", "number": 14572, "title": "it's slow to train model when loading dataset and checkpoints from S3", "user": {"login": "kwin-wang", "id": 11596805, "node_id": "MDQ6VXNlcjExNTk2ODA1", "avatar_url": "https://avatars0.githubusercontent.com/u/11596805?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kwin-wang", "html_url": "https://github.com/kwin-wang", "followers_url": "https://api.github.com/users/kwin-wang/followers", "following_url": "https://api.github.com/users/kwin-wang/following{/other_user}", "gists_url": "https://api.github.com/users/kwin-wang/gists{/gist_id}", "starred_url": "https://api.github.com/users/kwin-wang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kwin-wang/subscriptions", "organizations_url": "https://api.github.com/users/kwin-wang/orgs", "repos_url": "https://api.github.com/users/kwin-wang/repos", "events_url": "https://api.github.com/users/kwin-wang/events{/privacy}", "received_events_url": "https://api.github.com/users/kwin-wang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 17, "created_at": "2017-11-15T08:25:55Z", "updated_at": "2018-08-01T17:53:48Z", "closed_at": "2018-08-01T17:53:48Z", "author_association": "NONE", "body_html": "<h1>System information</h1>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):</strong>  No</p>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04):</strong> Amazon Linux, P2 Instance</p>\n<p><strong>TensorFlow installed from (source or binary):</strong> pip</p>\n<p><strong>TensorFlow version (use command below):</strong> 1.5.0.dev20171113</p>\n<p><strong>Python version:</strong> 2.7</p>\n<p><strong>CUDA/cuDNN version:</strong> CUDA 8.0 / cuDNN 6.0</p>\n<p><strong>GPU model and memory:</strong> Tesla K80 12GB</p>\n<h1>Describe the problem</h1>\n<p>The dataset and checkpoints are stored in S3 filesystem. It's slowly when training model. Howevery, The structure of network is simple and the speed is fast when load dataset and checkpoints from local filesystem</p>\n<h1>Source code / logs</h1>\n<p>some code like</p>\n<div class=\"highlight highlight-source-shell\"><pre>def input_fn(mode):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span> Input callback for Estimator</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Arguments</span>\n<span class=\"pl-s\">    ----</span>\n<span class=\"pl-s\">    mode: str, tf.estimator.ModelKey</span>\n<span class=\"pl-s\">    file_pattern: tensorflow file pattern, refer to <span class=\"pl-s\"><span class=\"pl-pds\">`</span>tf.gfile.Glob<span class=\"pl-pds\">`</span></span></span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Return</span>\n<span class=\"pl-s\">    ---</span>\n<span class=\"pl-s\">    features: dict of Tensor, the input features for model</span>\n<span class=\"pl-s\">    label: single Tensor, the input label for model, must be integeral</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>\n    is_train = tf.estimator.ModeKeys.TRAIN == mode\n\n    vocab_dir = hparams.vocab_dir\n\n    ds_dir = <span class=\"pl-s\"><span class=\"pl-pds\">'</span>train<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">if</span> is_train <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>test<span class=\"pl-pds\">'</span></span>\n    file_pattern = os.path.join(hparams.dataset_dir, ds_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>part-<span class=\"pl-pds\">'</span></span>)\n\n    tfrecords_files = [] \n    <span class=\"pl-k\">if</span> file_pattern.startswith(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>s3<span class=\"pl-pds\">'</span></span>):\n        tfrecords_files = list_s3_file(file_pattern)\n    else:\n        tfrecords_files = tf.gfile.Glob(file_pattern)\n\n    example = create_example(vocab_dir)\n    example_spec = tf.feature_column.make_parse_example_spec(feature_columns=example)\n\n    batch_size = hparams.batch_size\n    num_epochs = hparams.num_epochs <span class=\"pl-k\">if</span> is_train <span class=\"pl-k\">else</span> 1\n    example_parsed = tf.contrib.learn.read_batch_record_features(file_pattern=tfrecords_files,\n                            batch_size=batch_size,\n                            num_epochs=num_epochs,\n                            features=example_spec)\n\n    label = example_parsed.pop(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>label<span class=\"pl-pds\">'</span></span>)\n    features = example_parsed\n\n    <span class=\"pl-k\">return</span> features, label</pre></div>\n<p>The log</p>\n<div class=\"highlight highlight-source-shell\"><pre>INFO:tensorflow:Into main function\nINFO:tensorflow:vocab_dir: s3://experiements/yajun/youtube-match/data/raw/vocab\nINFO:tensorflow:Create Estimator\nINFO:tensorflow:Using config: {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>_save_checkpoints_secs<span class=\"pl-pds\">'</span></span>: 600, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_session_config<span class=\"pl-pds\">'</span></span>: None, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_keep_checkpoint_max<span class=\"pl-pds\">'</span></span>: 5, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_tf_random_seed<span class=\"pl-pds\">'</span></span>: None, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_task_type<span class=\"pl-pds\">'</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_is_chief<span class=\"pl-pds\">'</span></span>: True, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_cluster_spec<span class=\"pl-pds\">'</span></span>: <span class=\"pl-k\">&lt;</span>tensorflow.python.training.server_lib.ClusterSpec object at 0x7efcfa4bff<span class=\"pl-k\">90&gt;</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_model_dir<span class=\"pl-pds\">'</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>s3://experiements/yajun/youtube-match/data/model<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_num_worker_replicas<span class=\"pl-pds\">'</span></span>: 1, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_task_id<span class=\"pl-pds\">'</span></span>: 0, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_log_step_count_steps<span class=\"pl-pds\">'</span></span>: 100, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_master<span class=\"pl-pds\">'</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_save_checkpoints_steps<span class=\"pl-pds\">'</span></span>: None, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_keep_checkpoint_every_n_hours<span class=\"pl-pds\">'</span></span>: 10000, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_service<span class=\"pl-pds\">'</span></span>: None, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_save_summary_steps<span class=\"pl-pds\">'</span></span>: 100, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_num_ps_replicas<span class=\"pl-pds\">'</span></span>: 0}\nINFO:tensorflow:Begin to train model\nINFO:tensorflow:List files <span class=\"pl-k\">in</span> S3 according to the file pattern: s3://experiements/yajun/youtube-match/data/raw/train/part-\nINFO:tensorflow:Create CheckpointSaverHook.\n2017-11-15 03:03:41.798030: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-11-15 03:03:45.623759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node <span class=\"pl-c1\">read</span> from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-11-15 03:03:45.624258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties:\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:1e.0\ntotalMemory: 11.17GiB freeMemory: 11.11GiB\n2017-11-15 03:03:45.624285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -<span class=\"pl-k\">&gt;</span> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\nINFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1400\n^[[O^[[I\n^[[OINFO:tensorflow:Saving checkpoints <span class=\"pl-k\">for</span> 1401 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.\nINFO:tensorflow:loss <span class=\"pl-k\">=</span> 4.90536, step <span class=\"pl-k\">=</span> 1401\nINFO:tensorflow:global_step/sec: 188.871\nINFO:tensorflow:loss <span class=\"pl-k\">=</span> 7.86743, step <span class=\"pl-k\">=</span> 1501 (0.530 sec)\nINFO:tensorflow:global_step/sec: 219.692\nINFO:tensorflow:loss <span class=\"pl-k\">=</span> 2.34025, step <span class=\"pl-k\">=</span> 1601 (0.455 sec)\nINFO:tensorflow:global_step/sec: 224.707\nINFO:tensorflow:loss <span class=\"pl-k\">=</span> 2.32145, step <span class=\"pl-k\">=</span> 1701 (0.445 sec)\n2017-11-15 03:14:24.980234: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_4_dequeue_record_examples/fifo_queue<span class=\"pl-pds\">'</span></span> is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: dequeue_record_examples/fifo_queue_Dequeue <span class=\"pl-k\">=</span> QueueDequeueV2[component_types<span class=\"pl-k\">=</span>[DT_INT64, DT_INT64, DT_STRING, DT_INT64, DT_STRING], timeout_ms<span class=\"pl-k\">=</span>-1, _device<span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/device:CPU:0<span class=\"pl-pds\">\"</span></span>](dequeue_record_examples/fifo_queue)]]\nINFO:tensorflow:Saving checkpoints <span class=\"pl-k\">for</span> 1750 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.\nINFO:tensorflow:Loss <span class=\"pl-k\">for</span> final step: 6.49392.\nINFO:tensorflow:Begin to <span class=\"pl-k\">export</span> model to s3://experiements/yajun/youtube-match/data/model/exports\n2017-11-15 03:14:29.600289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -<span class=\"pl-k\">&gt;</span> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\nINFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1750\nINFO:tensorflow:Assets added to graph.\nINFO:tensorflow:No assets to write.\nINFO:tensorflow:SavedModel written to: s3://experiements/yajun/youtube-match/data/model/exports/temp-1510715669/saved_model.pb\nINFO:tensorflow:Finish to run</pre></div>", "body_text": "System information\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):  No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux, P2 Instance\nTensorFlow installed from (source or binary): pip\nTensorFlow version (use command below): 1.5.0.dev20171113\nPython version: 2.7\nCUDA/cuDNN version: CUDA 8.0 / cuDNN 6.0\nGPU model and memory: Tesla K80 12GB\nDescribe the problem\nThe dataset and checkpoints are stored in S3 filesystem. It's slowly when training model. Howevery, The structure of network is simple and the speed is fast when load dataset and checkpoints from local filesystem\nSource code / logs\nsome code like\ndef input_fn(mode):\n    \"\"\" Input callback for Estimator\n    \n    Arguments\n    ----\n    mode: str, tf.estimator.ModelKey\n    file_pattern: tensorflow file pattern, refer to `tf.gfile.Glob`\n\n    Return\n    ---\n    features: dict of Tensor, the input features for model\n    label: single Tensor, the input label for model, must be integeral\n    \"\"\"\n    is_train = tf.estimator.ModeKeys.TRAIN == mode\n\n    vocab_dir = hparams.vocab_dir\n\n    ds_dir = 'train' if is_train else 'test'\n    file_pattern = os.path.join(hparams.dataset_dir, ds_dir, 'part-')\n\n    tfrecords_files = [] \n    if file_pattern.startswith('s3'):\n        tfrecords_files = list_s3_file(file_pattern)\n    else:\n        tfrecords_files = tf.gfile.Glob(file_pattern)\n\n    example = create_example(vocab_dir)\n    example_spec = tf.feature_column.make_parse_example_spec(feature_columns=example)\n\n    batch_size = hparams.batch_size\n    num_epochs = hparams.num_epochs if is_train else 1\n    example_parsed = tf.contrib.learn.read_batch_record_features(file_pattern=tfrecords_files,\n                            batch_size=batch_size,\n                            num_epochs=num_epochs,\n                            features=example_spec)\n\n    label = example_parsed.pop('label')\n    features = example_parsed\n\n    return features, label\nThe log\nINFO:tensorflow:Into main function\nINFO:tensorflow:vocab_dir: s3://experiements/yajun/youtube-match/data/raw/vocab\nINFO:tensorflow:Create Estimator\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efcfa4bff90>, '_model_dir': 's3://experiements/yajun/youtube-match/data/model', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\nINFO:tensorflow:Begin to train model\nINFO:tensorflow:List files in S3 according to the file pattern: s3://experiements/yajun/youtube-match/data/raw/train/part-\nINFO:tensorflow:Create CheckpointSaverHook.\n2017-11-15 03:03:41.798030: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-11-15 03:03:45.623759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-11-15 03:03:45.624258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties:\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:1e.0\ntotalMemory: 11.17GiB freeMemory: 11.11GiB\n2017-11-15 03:03:45.624285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\nINFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1400\n^[[O^[[I\n^[[OINFO:tensorflow:Saving checkpoints for 1401 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.\nINFO:tensorflow:loss = 4.90536, step = 1401\nINFO:tensorflow:global_step/sec: 188.871\nINFO:tensorflow:loss = 7.86743, step = 1501 (0.530 sec)\nINFO:tensorflow:global_step/sec: 219.692\nINFO:tensorflow:loss = 2.34025, step = 1601 (0.455 sec)\nINFO:tensorflow:global_step/sec: 224.707\nINFO:tensorflow:loss = 2.32145, step = 1701 (0.445 sec)\n2017-11-15 03:14:24.980234: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue '_4_dequeue_record_examples/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: dequeue_record_examples/fifo_queue_Dequeue = QueueDequeueV2[component_types=[DT_INT64, DT_INT64, DT_STRING, DT_INT64, DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dequeue_record_examples/fifo_queue)]]\nINFO:tensorflow:Saving checkpoints for 1750 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.\nINFO:tensorflow:Loss for final step: 6.49392.\nINFO:tensorflow:Begin to export model to s3://experiements/yajun/youtube-match/data/model/exports\n2017-11-15 03:14:29.600289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\nINFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1750\nINFO:tensorflow:Assets added to graph.\nINFO:tensorflow:No assets to write.\nINFO:tensorflow:SavedModel written to: s3://experiements/yajun/youtube-match/data/model/exports/temp-1510715669/saved_model.pb\nINFO:tensorflow:Finish to run", "body": "# System information\r\n\r\n**Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**  No\r\n\r\n**OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Amazon Linux, P2 Instance\r\n\r\n**TensorFlow installed from (source or binary):** pip\r\n\r\n**TensorFlow version (use command below):** 1.5.0.dev20171113\r\n\r\n**Python version:** 2.7\r\n\r\n**CUDA/cuDNN version:** CUDA 8.0 / cuDNN 6.0\r\n\r\n**GPU model and memory:** Tesla K80 12GB\r\n\r\n# Describe the problem\r\n\r\nThe dataset and checkpoints are stored in S3 filesystem. It's slowly when training model. Howevery, The structure of network is simple and the speed is fast when load dataset and checkpoints from local filesystem\r\n\r\n# Source code / logs\r\n\r\nsome code like \r\n\r\n```bash\r\ndef input_fn(mode):\r\n    \"\"\" Input callback for Estimator\r\n    \r\n    Arguments\r\n    ----\r\n    mode: str, tf.estimator.ModelKey\r\n    file_pattern: tensorflow file pattern, refer to `tf.gfile.Glob`\r\n\r\n    Return\r\n    ---\r\n    features: dict of Tensor, the input features for model\r\n    label: single Tensor, the input label for model, must be integeral\r\n    \"\"\"\r\n    is_train = tf.estimator.ModeKeys.TRAIN == mode\r\n\r\n    vocab_dir = hparams.vocab_dir\r\n\r\n    ds_dir = 'train' if is_train else 'test'\r\n    file_pattern = os.path.join(hparams.dataset_dir, ds_dir, 'part-')\r\n\r\n    tfrecords_files = [] \r\n    if file_pattern.startswith('s3'):\r\n        tfrecords_files = list_s3_file(file_pattern)\r\n    else:\r\n        tfrecords_files = tf.gfile.Glob(file_pattern)\r\n\r\n    example = create_example(vocab_dir)\r\n    example_spec = tf.feature_column.make_parse_example_spec(feature_columns=example)\r\n\r\n    batch_size = hparams.batch_size\r\n    num_epochs = hparams.num_epochs if is_train else 1\r\n    example_parsed = tf.contrib.learn.read_batch_record_features(file_pattern=tfrecords_files,\r\n                            batch_size=batch_size,\r\n                            num_epochs=num_epochs,\r\n                            features=example_spec)\r\n\r\n    label = example_parsed.pop('label')\r\n    features = example_parsed\r\n\r\n    return features, label\r\n```\r\n\r\nThe log \r\n\r\n```bash\r\n\r\nINFO:tensorflow:Into main function\r\nINFO:tensorflow:vocab_dir: s3://experiements/yajun/youtube-match/data/raw/vocab\r\nINFO:tensorflow:Create Estimator\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efcfa4bff90>, '_model_dir': 's3://experiements/yajun/youtube-match/data/model', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\r\nINFO:tensorflow:Begin to train model\r\nINFO:tensorflow:List files in S3 according to the file pattern: s3://experiements/yajun/youtube-match/data/raw/train/part-\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\n2017-11-15 03:03:41.798030: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-11-15 03:03:45.623759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-11-15 03:03:45.624258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:1e.0\r\ntotalMemory: 11.17GiB freeMemory: 11.11GiB\r\n2017-11-15 03:03:45.624285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\nINFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1400\r\n^[[O^[[I\r\n^[[OINFO:tensorflow:Saving checkpoints for 1401 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.\r\nINFO:tensorflow:loss = 4.90536, step = 1401\r\nINFO:tensorflow:global_step/sec: 188.871\r\nINFO:tensorflow:loss = 7.86743, step = 1501 (0.530 sec)\r\nINFO:tensorflow:global_step/sec: 219.692\r\nINFO:tensorflow:loss = 2.34025, step = 1601 (0.455 sec)\r\nINFO:tensorflow:global_step/sec: 224.707\r\nINFO:tensorflow:loss = 2.32145, step = 1701 (0.445 sec)\r\n2017-11-15 03:14:24.980234: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue '_4_dequeue_record_examples/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\r\n\t [[Node: dequeue_record_examples/fifo_queue_Dequeue = QueueDequeueV2[component_types=[DT_INT64, DT_INT64, DT_STRING, DT_INT64, DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dequeue_record_examples/fifo_queue)]]\r\nINFO:tensorflow:Saving checkpoints for 1750 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.\r\nINFO:tensorflow:Loss for final step: 6.49392.\r\nINFO:tensorflow:Begin to export model to s3://experiements/yajun/youtube-match/data/model/exports\r\n2017-11-15 03:14:29.600289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\nINFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1750\r\nINFO:tensorflow:Assets added to graph.\r\nINFO:tensorflow:No assets to write.\r\nINFO:tensorflow:SavedModel written to: s3://experiements/yajun/youtube-match/data/model/exports/temp-1510715669/saved_model.pb\r\nINFO:tensorflow:Finish to run\r\n```"}