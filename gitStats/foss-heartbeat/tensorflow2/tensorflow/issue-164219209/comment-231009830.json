{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231009830", "html_url": "https://github.com/tensorflow/tensorflow/issues/3212#issuecomment-231009830", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3212", "id": 231009830, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTAwOTgzMA==", "user": {"login": "benwu232", "id": 3946864, "node_id": "MDQ6VXNlcjM5NDY4NjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/3946864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benwu232", "html_url": "https://github.com/benwu232", "followers_url": "https://api.github.com/users/benwu232/followers", "following_url": "https://api.github.com/users/benwu232/following{/other_user}", "gists_url": "https://api.github.com/users/benwu232/gists{/gist_id}", "starred_url": "https://api.github.com/users/benwu232/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benwu232/subscriptions", "organizations_url": "https://api.github.com/users/benwu232/orgs", "repos_url": "https://api.github.com/users/benwu232/repos", "events_url": "https://api.github.com/users/benwu232/events{/privacy}", "received_events_url": "https://api.github.com/users/benwu232/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-07T08:01:21Z", "updated_at": "2016-07-07T08:01:21Z", "author_association": "NONE", "body_html": "<p>Thank you for your reply! <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a></p>\n<p>Here is a snapshot of my current training.<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/3946864/16645430/77269270-4456-11e6-8a0b-e12b471ebaaf.png\"><img src=\"https://cloud.githubusercontent.com/assets/3946864/16645430/77269270-4456-11e6-8a0b-e12b471ebaaf.png\" alt=\"image\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/3946864/16645457/ae73702c-4456-11e6-97af-4848a62e357d.png\"><img src=\"https://cloud.githubusercontent.com/assets/3946864/16645457/ae73702c-4456-11e6-97af-4848a62e357d.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>I turned off the writing summary so that the training can continue. If it is turned on, the program will crash in about 4 or 5 epochs.</p>\n<p>There are many NaNs in val_acc. I agree that the learning rate is too big (I use adadelta(0.1)), because the curve is not smooth, which shows the energy is too high. Although there are many NaNs in val_acc, the process is still going on, the acc is going up and the loss is going down.  I am not sure if it is normal or not.</p>\n<p>Another question is because I use adadelta, I can't get the real learning rate. I read some papers which said that they just use vanilla SGD with a learning rate scheduler. So which one is better, SGD with lr scheduler or other optimizers(Adam, Adadelta, Rmsprop...)?</p>", "body_text": "Thank you for your reply! @aselle\nHere is a snapshot of my current training.\n\n\nI turned off the writing summary so that the training can continue. If it is turned on, the program will crash in about 4 or 5 epochs.\nThere are many NaNs in val_acc. I agree that the learning rate is too big (I use adadelta(0.1)), because the curve is not smooth, which shows the energy is too high. Although there are many NaNs in val_acc, the process is still going on, the acc is going up and the loss is going down.  I am not sure if it is normal or not.\nAnother question is because I use adadelta, I can't get the real learning rate. I read some papers which said that they just use vanilla SGD with a learning rate scheduler. So which one is better, SGD with lr scheduler or other optimizers(Adam, Adadelta, Rmsprop...)?", "body": "Thank you for your reply! @aselle \n\nHere is a snapshot of my current training.\n![image](https://cloud.githubusercontent.com/assets/3946864/16645430/77269270-4456-11e6-8a0b-e12b471ebaaf.png)\n![image](https://cloud.githubusercontent.com/assets/3946864/16645457/ae73702c-4456-11e6-97af-4848a62e357d.png)\n\nI turned off the writing summary so that the training can continue. If it is turned on, the program will crash in about 4 or 5 epochs.\n\nThere are many NaNs in val_acc. I agree that the learning rate is too big (I use adadelta(0.1)), because the curve is not smooth, which shows the energy is too high. Although there are many NaNs in val_acc, the process is still going on, the acc is going up and the loss is going down.  I am not sure if it is normal or not.\n\nAnother question is because I use adadelta, I can't get the real learning rate. I read some papers which said that they just use vanilla SGD with a learning rate scheduler. So which one is better, SGD with lr scheduler or other optimizers(Adam, Adadelta, Rmsprop...)?\n"}