{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21009", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21009/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21009/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21009/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21009", "id": 343281341, "node_id": "MDU6SXNzdWUzNDMyODEzNDE=", "number": 21009, "title": "Fine-Grained Control Over TOCO Quantization", "user": {"login": "deepconvneuralnet", "id": 41493788, "node_id": "MDQ6VXNlcjQxNDkzNzg4", "avatar_url": "https://avatars3.githubusercontent.com/u/41493788?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepconvneuralnet", "html_url": "https://github.com/deepconvneuralnet", "followers_url": "https://api.github.com/users/deepconvneuralnet/followers", "following_url": "https://api.github.com/users/deepconvneuralnet/following{/other_user}", "gists_url": "https://api.github.com/users/deepconvneuralnet/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepconvneuralnet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepconvneuralnet/subscriptions", "organizations_url": "https://api.github.com/users/deepconvneuralnet/orgs", "repos_url": "https://api.github.com/users/deepconvneuralnet/repos", "events_url": "https://api.github.com/users/deepconvneuralnet/events{/privacy}", "received_events_url": "https://api.github.com/users/deepconvneuralnet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-07-21T00:32:23Z", "updated_at": "2018-11-21T19:00:29Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Our (Syntiant Corp\u2019s) neural network inference chips use quantized weights and biases in order to minimize storage and energy consumption. The new Tensorflow experimental quantization feature <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/quantize/experimental_create_training_graph\" rel=\"nofollow\">tf.contrib.quantize.experimental_create_training_graph</a> supports quantizing weights to between 2 and n bits, but the <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/lite/toco_convert\" rel=\"nofollow\">tf.contrib.lite.toco_convert</a> tool currently only supports 8 bit quantization. As a result, we have to internally fork the TFLite pipeline before generating the Flatbuffer.</p>\n<p>Feature request: Update TOCO to support arbitrary (i.e., 2 to n bit) signed fixed point quantization of weights and biases for both symmetric and asymmetric quantization. Our desired solution would process the quantization <a href=\"https://github.com/tensorflow/tensorflow/issues/21008\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/21008/hovercard\">specified at the op or Keras layer level</a> and not involve quantization specification within the TOCO tool API.</p>", "body_text": "Our (Syntiant Corp\u2019s) neural network inference chips use quantized weights and biases in order to minimize storage and energy consumption. The new Tensorflow experimental quantization feature tf.contrib.quantize.experimental_create_training_graph supports quantizing weights to between 2 and n bits, but the tf.contrib.lite.toco_convert tool currently only supports 8 bit quantization. As a result, we have to internally fork the TFLite pipeline before generating the Flatbuffer.\nFeature request: Update TOCO to support arbitrary (i.e., 2 to n bit) signed fixed point quantization of weights and biases for both symmetric and asymmetric quantization. Our desired solution would process the quantization specified at the op or Keras layer level and not involve quantization specification within the TOCO tool API.", "body": "Our (Syntiant Corp\u2019s) neural network inference chips use quantized weights and biases in order to minimize storage and energy consumption. The new Tensorflow experimental quantization feature [tf.contrib.quantize.experimental_create_training_graph](https://www.tensorflow.org/api_docs/python/tf/contrib/quantize/experimental_create_training_graph) supports quantizing weights to between 2 and n bits, but the [tf.contrib.lite.toco_convert](https://www.tensorflow.org/api_docs/python/tf/contrib/lite/toco_convert) tool currently only supports 8 bit quantization. As a result, we have to internally fork the TFLite pipeline before generating the Flatbuffer.\r\n\r\nFeature request: Update TOCO to support arbitrary (i.e., 2 to n bit) signed fixed point quantization of weights and biases for both symmetric and asymmetric quantization. Our desired solution would process the quantization [specified at the op or Keras layer level](https://github.com/tensorflow/tensorflow/issues/21008) and not involve quantization specification within the TOCO tool API.\r\n"}