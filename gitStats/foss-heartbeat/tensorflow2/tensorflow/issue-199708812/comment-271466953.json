{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/271466953", "html_url": "https://github.com/tensorflow/tensorflow/issues/6752#issuecomment-271466953", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6752", "id": 271466953, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MTQ2Njk1Mw==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-10T02:12:48Z", "updated_at": "2017-01-10T02:12:48Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Here's a better benchmark that removes the cost of data transfer. It seems CPU usage is indeed quite low and it won't break 6 G ops/sec on Xeon. However, this problem is bandwidth limited so you are going to spend most of the time transferring data between RAM and CPU, so I'm not sure if this performance can be improved much. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6969686\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/benoitsteiner\">@benoitsteiner</a></p>\n<pre><code>import os\nimport sys\n#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\nimport tensorflow as tf\nimport time\n\nn = 8*8192\nwith tf.device(\"/cpu:0\"):\n    matrix1 = tf.ones((n, n))\n    matrix2 = tf.ones((n, 1))\n    product1 = tf.matmul(matrix1, matrix2)\n\ngraph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0))\nsess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=int(sys.argv[1]), graph_options=graph_options))\n\n# pre-warming\nsess.run(product1.op)\n\nstart = time.time()\nsess.run(product1.op)\nend = time.time()\nops = n**2 + n*(n-1) # n*(n-1) additions, n^2 multiplications\nelapsed = (end - start)\nrate = ops/elapsed/10**9\nprint('\\n Approach 1 took: %.2f sec, %.2f G ops/sec' % (elapsed, rate,))\n\n</code></pre>", "body_text": "Here's a better benchmark that removes the cost of data transfer. It seems CPU usage is indeed quite low and it won't break 6 G ops/sec on Xeon. However, this problem is bandwidth limited so you are going to spend most of the time transferring data between RAM and CPU, so I'm not sure if this performance can be improved much. @benoitsteiner\nimport os\nimport sys\n#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\nimport tensorflow as tf\nimport time\n\nn = 8*8192\nwith tf.device(\"/cpu:0\"):\n    matrix1 = tf.ones((n, n))\n    matrix2 = tf.ones((n, 1))\n    product1 = tf.matmul(matrix1, matrix2)\n\ngraph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0))\nsess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=int(sys.argv[1]), graph_options=graph_options))\n\n# pre-warming\nsess.run(product1.op)\n\nstart = time.time()\nsess.run(product1.op)\nend = time.time()\nops = n**2 + n*(n-1) # n*(n-1) additions, n^2 multiplications\nelapsed = (end - start)\nrate = ops/elapsed/10**9\nprint('\\n Approach 1 took: %.2f sec, %.2f G ops/sec' % (elapsed, rate,))", "body": "Here's a better benchmark that removes the cost of data transfer. It seems CPU usage is indeed quite low and it won't break 6 G ops/sec on Xeon. However, this problem is bandwidth limited so you are going to spend most of the time transferring data between RAM and CPU, so I'm not sure if this performance can be improved much. @benoitsteiner \r\n\r\n\r\n```\r\nimport os\r\nimport sys\r\n#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\r\nimport tensorflow as tf\r\nimport time\r\n\r\nn = 8*8192\r\nwith tf.device(\"/cpu:0\"):\r\n    matrix1 = tf.ones((n, n))\r\n    matrix2 = tf.ones((n, 1))\r\n    product1 = tf.matmul(matrix1, matrix2)\r\n\r\ngraph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0))\r\nsess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=int(sys.argv[1]), graph_options=graph_options))\r\n\r\n# pre-warming\r\nsess.run(product1.op)\r\n\r\nstart = time.time()\r\nsess.run(product1.op)\r\nend = time.time()\r\nops = n**2 + n*(n-1) # n*(n-1) additions, n^2 multiplications\r\nelapsed = (end - start)\r\nrate = ops/elapsed/10**9\r\nprint('\\n Approach 1 took: %.2f sec, %.2f G ops/sec' % (elapsed, rate,))\r\n\r\n```"}