{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6752", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6752/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6752/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6752/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6752", "id": 199708812, "node_id": "MDU6SXNzdWUxOTk3MDg4MTI=", "number": 6752, "title": "Matrix Vector multiply not parallelized.", "user": {"login": "bowu", "id": 725765, "node_id": "MDQ6VXNlcjcyNTc2NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/725765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bowu", "html_url": "https://github.com/bowu", "followers_url": "https://api.github.com/users/bowu/followers", "following_url": "https://api.github.com/users/bowu/following{/other_user}", "gists_url": "https://api.github.com/users/bowu/gists{/gist_id}", "starred_url": "https://api.github.com/users/bowu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bowu/subscriptions", "organizations_url": "https://api.github.com/users/bowu/orgs", "repos_url": "https://api.github.com/users/bowu/repos", "events_url": "https://api.github.com/users/bowu/events{/privacy}", "received_events_url": "https://api.github.com/users/bowu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2017-01-10T01:23:37Z", "updated_at": "2017-01-10T23:39:30Z", "closed_at": "2017-01-10T23:39:30Z", "author_association": "NONE", "body_html": "<h3>What is the problem?</h3>\n<p>Matrix vector multiply is not parallelized. Please see my example code. No matter how I change the intra_op_parallelism_threads, the running time is always similar. I used \"top\" to confirm that only one thread was used. However, the parallel speedups for square matrix matrix multiply are quite noticeable. Again, \"top\" confirmed that multiple threads were used.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 16.04</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)<br>\n<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/2e22f1b20fdfa77b1332c518617391dc32359c5b/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/2e22f1b20fdfa77b1332c518617391dc32359c5b\"><tt>2e22f1b</tt></a></li>\n<li>The output of <code>bazel version</code><br>\n0.4.3</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>import tensorflow as tf<br>\nimport numpy as np<br>\nimport time</p>\n<p>n = 10000</p>\n<p>#approach 1:</p>\n<p>matrix1 = tf.constant(np.ones(n<em>n), shape = [n,n])<br>\nmatrix2 = tf.constant(np.ones(n</em>1), shape = [n,1])</p>\n<p>product1 = tf.matmul(matrix1, matrix2)</p>\n<p>start = time.time()<br>\nsess = tf.Session(config=tf.ConfigProto(<br>\ninter_op_parallelism_threads=1,<br>\nintra_op_parallelism_threads=12))<br>\nsess.run(product1)<br>\nend = time.time()<br>\nprint('\\n Approach 1 took: %s%%' % (end - start))</p>\n<h3>What other attempted solutions have you tried?</h3>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>", "body_text": "What is the problem?\nMatrix vector multiply is not parallelized. Please see my example code. No matter how I change the intra_op_parallelism_threads, the running time is always similar. I used \"top\" to confirm that only one thread was used. However, the parallel speedups for square matrix matrix multiply are quite noticeable. Again, \"top\" confirmed that multiple threads were used.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nEnvironment info\nOperating System: Ubuntu 16.04\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD)\n2e22f1b\nThe output of bazel version\n0.4.3\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nimport tensorflow as tf\nimport numpy as np\nimport time\nn = 10000\n#approach 1:\nmatrix1 = tf.constant(np.ones(nn), shape = [n,n])\nmatrix2 = tf.constant(np.ones(n1), shape = [n,1])\nproduct1 = tf.matmul(matrix1, matrix2)\nstart = time.time()\nsess = tf.Session(config=tf.ConfigProto(\ninter_op_parallelism_threads=1,\nintra_op_parallelism_threads=12))\nsess.run(product1)\nend = time.time()\nprint('\\n Approach 1 took: %s%%' % (end - start))\nWhat other attempted solutions have you tried?\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).", "body": "### What is the problem?\r\n\r\nMatrix vector multiply is not parallelized. Please see my example code. No matter how I change the intra_op_parallelism_threads, the running time is always similar. I used \"top\" to confirm that only one thread was used. However, the parallel speedups for square matrix matrix multiply are quite noticeable. Again, \"top\" confirmed that multiple threads were used.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04 \r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2e22f1b20fdfa77b1332c518617391dc32359c5b\r\n2. The output of `bazel version`\r\n0.4.3\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\nn = 10000\r\n\r\n#approach 1:\r\n\r\nmatrix1 = tf.constant(np.ones(n*n), shape = [n,n])\r\nmatrix2 = tf.constant(np.ones(n*1), shape = [n,1])\r\n\r\nproduct1 = tf.matmul(matrix1, matrix2)\r\n\r\nstart = time.time()\r\nsess = tf.Session(config=tf.ConfigProto(\r\n    inter_op_parallelism_threads=1,\r\n    intra_op_parallelism_threads=12))\r\nsess.run(product1)\r\nend = time.time()\r\nprint('\\n Approach 1 took: %s%%' % (end - start))\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n"}