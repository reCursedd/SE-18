{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4067", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4067/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4067/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4067/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4067", "id": 173546704, "node_id": "MDU6SXNzdWUxNzM1NDY3MDQ=", "number": 4067, "title": "GPU usage level and training speed is very different for different tensorflow version", "user": {"login": "perhapszzy", "id": 7953637, "node_id": "MDQ6VXNlcjc5NTM2Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7953637?v=4", "gravatar_id": "", "url": "https://api.github.com/users/perhapszzy", "html_url": "https://github.com/perhapszzy", "followers_url": "https://api.github.com/users/perhapszzy/followers", "following_url": "https://api.github.com/users/perhapszzy/following{/other_user}", "gists_url": "https://api.github.com/users/perhapszzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/perhapszzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/perhapszzy/subscriptions", "organizations_url": "https://api.github.com/users/perhapszzy/orgs", "repos_url": "https://api.github.com/users/perhapszzy/repos", "events_url": "https://api.github.com/users/perhapszzy/events{/privacy}", "received_events_url": "https://api.github.com/users/perhapszzy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-08-26T21:25:04Z", "updated_at": "2016-08-26T21:43:29Z", "closed_at": "2016-08-26T21:43:29Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04, AWS g2.2xlarge</p>\n<p>Installed version of CUDA and cuDNN:  CUDA 7.5, cuDNN 4</p>\n<p>Tried 3 different version using pip package:<br>\n0.8.0:<br>\nsudo pip install --upgrade <a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl</a></p>\n<p>0.9.0:<br>\nsudo pip install --upgrade <a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl</a></p>\n<p>0.10.0 rc<br>\nsudo pip install --upgrade <a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl</a></p>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>On the same machine, install different version of tf and run the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py\">cifar10_train.py</a></p>\n<h3>Logs or other output that would be helpful</h3>\n<p>For version 0.8.0 and 0.9.0, the GPU usage is about 30%</p>\n<pre><code>+------------------------------------------------------+                       \n| NVIDIA-SMI 352.99     Driver Version: 352.99         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   37C    P0    51W / 125W |   3854MiB /  4095MiB |     35%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     16558    C   python                                        3841MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<p>But the speed is about ~0.24 sec/batch for version 0.8.0 and ~0.22 sec/batch for version 0.9.0</p>\n<pre><code>2016-08-26 21:20:41.309814: step 230, loss = 4.28 (522.0 examples/sec; 0.245 sec/batch)\n2016-08-26 21:20:43.625017: step 240, loss = 4.26 (582.3 examples/sec; 0.220 sec/batch)\n2016-08-26 21:20:45.953772: step 250, loss = 4.24 (544.4 examples/sec; 0.235 sec/batch)\n2016-08-26 21:20:48.302202: step 260, loss = 4.23 (540.1 examples/sec; 0.237 sec/batch)\n2016-08-26 21:20:50.643760: step 270, loss = 4.21 (554.6 examples/sec; 0.231 sec/batch)\n2016-08-26 21:20:52.955326: step 280, loss = 4.20 (545.6 examples/sec; 0.235 sec/batch)\n2016-08-26 21:20:55.399758: step 290, loss = 4.18 (476.4 examples/sec; 0.269 sec/batch)\n2016-08-26 21:20:57.825254: step 300, loss = 4.17 (548.0 examples/sec; 0.234 sec/batch)\n2016-08-26 21:21:00.453533: step 310, loss = 4.15 (543.6 examples/sec; 0.235 sec/batch)\n2016-08-26 21:21:02.876055: step 320, loss = 4.14 (513.9 examples/sec; 0.249 sec/batch)\n2016-08-26 21:21:05.229421: step 330, loss = 4.13 (580.3 examples/sec; 0.221 sec/batch)\n2016-08-26 21:21:07.614095: step 340, loss = 4.11 (528.6 examples/sec; 0.242 sec/batch)\n</code></pre>\n<hr>\n<p>For 0.10.0.rc0, the GPU usage is ~90\uff05\uff1a</p>\n<pre><code>+------------------------------------------------------+                       \n| NVIDIA-SMI 352.99     Driver Version: 352.99         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   35C    P0    46W / 125W |   3818MiB /  4095MiB |     90%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     16702    C   python                                        3805MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<p>But the speed is only ~0.34 sec/batch:</p>\n<pre><code>016-08-26 21:24:11.512601: step 30, loss = 4.38 (371.3 examples/sec; 0.345 sec/batch)\n2016-08-26 21:24:14.875387: step 40, loss = 4.42 (379.0 examples/sec; 0.338 sec/batch)\n2016-08-26 21:24:18.248093: step 50, loss = 4.27 (368.0 examples/sec; 0.348 sec/batch)\n2016-08-26 21:24:21.609797: step 60, loss = 4.24 (379.8 examples/sec; 0.337 sec/batch)\n2016-08-26 21:24:24.987058: step 70, loss = 4.25 (376.4 examples/sec; 0.340 sec/batch)\n2016-08-26 21:24:28.387080: step 80, loss = 4.38 (381.0 examples/sec; 0.336 sec/batch)\n2016-08-26 21:24:31.775519: step 90, loss = 4.18 (377.8 examples/sec; 0.339 sec/batch)\n</code></pre>", "body_text": "Environment info\nOperating System: Ubuntu 14.04, AWS g2.2xlarge\nInstalled version of CUDA and cuDNN:  CUDA 7.5, cuDNN 4\nTried 3 different version using pip package:\n0.8.0:\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n0.9.0:\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl\n0.10.0 rc\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nOn the same machine, install different version of tf and run the cifar10_train.py\nLogs or other output that would be helpful\nFor version 0.8.0 and 0.9.0, the GPU usage is about 30%\n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.99     Driver Version: 352.99         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   37C    P0    51W / 125W |   3854MiB /  4095MiB |     35%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     16558    C   python                                        3841MiB |\n+-----------------------------------------------------------------------------+\n\nBut the speed is about ~0.24 sec/batch for version 0.8.0 and ~0.22 sec/batch for version 0.9.0\n2016-08-26 21:20:41.309814: step 230, loss = 4.28 (522.0 examples/sec; 0.245 sec/batch)\n2016-08-26 21:20:43.625017: step 240, loss = 4.26 (582.3 examples/sec; 0.220 sec/batch)\n2016-08-26 21:20:45.953772: step 250, loss = 4.24 (544.4 examples/sec; 0.235 sec/batch)\n2016-08-26 21:20:48.302202: step 260, loss = 4.23 (540.1 examples/sec; 0.237 sec/batch)\n2016-08-26 21:20:50.643760: step 270, loss = 4.21 (554.6 examples/sec; 0.231 sec/batch)\n2016-08-26 21:20:52.955326: step 280, loss = 4.20 (545.6 examples/sec; 0.235 sec/batch)\n2016-08-26 21:20:55.399758: step 290, loss = 4.18 (476.4 examples/sec; 0.269 sec/batch)\n2016-08-26 21:20:57.825254: step 300, loss = 4.17 (548.0 examples/sec; 0.234 sec/batch)\n2016-08-26 21:21:00.453533: step 310, loss = 4.15 (543.6 examples/sec; 0.235 sec/batch)\n2016-08-26 21:21:02.876055: step 320, loss = 4.14 (513.9 examples/sec; 0.249 sec/batch)\n2016-08-26 21:21:05.229421: step 330, loss = 4.13 (580.3 examples/sec; 0.221 sec/batch)\n2016-08-26 21:21:07.614095: step 340, loss = 4.11 (528.6 examples/sec; 0.242 sec/batch)\n\n\nFor 0.10.0.rc0, the GPU usage is ~90\uff05\uff1a\n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.99     Driver Version: 352.99         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   35C    P0    46W / 125W |   3818MiB /  4095MiB |     90%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     16702    C   python                                        3805MiB |\n+-----------------------------------------------------------------------------+\n\nBut the speed is only ~0.34 sec/batch:\n016-08-26 21:24:11.512601: step 30, loss = 4.38 (371.3 examples/sec; 0.345 sec/batch)\n2016-08-26 21:24:14.875387: step 40, loss = 4.42 (379.0 examples/sec; 0.338 sec/batch)\n2016-08-26 21:24:18.248093: step 50, loss = 4.27 (368.0 examples/sec; 0.348 sec/batch)\n2016-08-26 21:24:21.609797: step 60, loss = 4.24 (379.8 examples/sec; 0.337 sec/batch)\n2016-08-26 21:24:24.987058: step 70, loss = 4.25 (376.4 examples/sec; 0.340 sec/batch)\n2016-08-26 21:24:28.387080: step 80, loss = 4.38 (381.0 examples/sec; 0.336 sec/batch)\n2016-08-26 21:24:31.775519: step 90, loss = 4.18 (377.8 examples/sec; 0.339 sec/batch)", "body": "### Environment info\n\nOperating System: Ubuntu 14.04, AWS g2.2xlarge\n\nInstalled version of CUDA and cuDNN:  CUDA 7.5, cuDNN 4\n\nTried 3 different version using pip package:\n0.8.0:\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n\n0.9.0:\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl\n\n0.10.0 rc\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nOn the same machine, install different version of tf and run the [cifar10_train.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py)\n### Logs or other output that would be helpful\n\nFor version 0.8.0 and 0.9.0, the GPU usage is about 30%\n\n```\n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.99     Driver Version: 352.99         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   37C    P0    51W / 125W |   3854MiB /  4095MiB |     35%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     16558    C   python                                        3841MiB |\n+-----------------------------------------------------------------------------+\n```\n\nBut the speed is about ~0.24 sec/batch for version 0.8.0 and ~0.22 sec/batch for version 0.9.0\n\n```\n2016-08-26 21:20:41.309814: step 230, loss = 4.28 (522.0 examples/sec; 0.245 sec/batch)\n2016-08-26 21:20:43.625017: step 240, loss = 4.26 (582.3 examples/sec; 0.220 sec/batch)\n2016-08-26 21:20:45.953772: step 250, loss = 4.24 (544.4 examples/sec; 0.235 sec/batch)\n2016-08-26 21:20:48.302202: step 260, loss = 4.23 (540.1 examples/sec; 0.237 sec/batch)\n2016-08-26 21:20:50.643760: step 270, loss = 4.21 (554.6 examples/sec; 0.231 sec/batch)\n2016-08-26 21:20:52.955326: step 280, loss = 4.20 (545.6 examples/sec; 0.235 sec/batch)\n2016-08-26 21:20:55.399758: step 290, loss = 4.18 (476.4 examples/sec; 0.269 sec/batch)\n2016-08-26 21:20:57.825254: step 300, loss = 4.17 (548.0 examples/sec; 0.234 sec/batch)\n2016-08-26 21:21:00.453533: step 310, loss = 4.15 (543.6 examples/sec; 0.235 sec/batch)\n2016-08-26 21:21:02.876055: step 320, loss = 4.14 (513.9 examples/sec; 0.249 sec/batch)\n2016-08-26 21:21:05.229421: step 330, loss = 4.13 (580.3 examples/sec; 0.221 sec/batch)\n2016-08-26 21:21:07.614095: step 340, loss = 4.11 (528.6 examples/sec; 0.242 sec/batch)\n```\n\n---\n\nFor 0.10.0.rc0, the GPU usage is ~90\uff05\uff1a\n\n```\n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.99     Driver Version: 352.99         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   35C    P0    46W / 125W |   3818MiB /  4095MiB |     90%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     16702    C   python                                        3805MiB |\n+-----------------------------------------------------------------------------+\n```\n\nBut the speed is only ~0.34 sec/batch:\n\n```\n016-08-26 21:24:11.512601: step 30, loss = 4.38 (371.3 examples/sec; 0.345 sec/batch)\n2016-08-26 21:24:14.875387: step 40, loss = 4.42 (379.0 examples/sec; 0.338 sec/batch)\n2016-08-26 21:24:18.248093: step 50, loss = 4.27 (368.0 examples/sec; 0.348 sec/batch)\n2016-08-26 21:24:21.609797: step 60, loss = 4.24 (379.8 examples/sec; 0.337 sec/batch)\n2016-08-26 21:24:24.987058: step 70, loss = 4.25 (376.4 examples/sec; 0.340 sec/batch)\n2016-08-26 21:24:28.387080: step 80, loss = 4.38 (381.0 examples/sec; 0.336 sec/batch)\n2016-08-26 21:24:31.775519: step 90, loss = 4.18 (377.8 examples/sec; 0.339 sec/batch)\n```\n"}