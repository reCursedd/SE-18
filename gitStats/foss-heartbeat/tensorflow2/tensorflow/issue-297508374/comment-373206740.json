{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/373206740", "html_url": "https://github.com/tensorflow/tensorflow/issues/17048#issuecomment-373206740", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17048", "id": 373206740, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MzIwNjc0MA==", "user": {"login": "androidbeepboop", "id": 37384864, "node_id": "MDQ6VXNlcjM3Mzg0ODY0", "avatar_url": "https://avatars0.githubusercontent.com/u/37384864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/androidbeepboop", "html_url": "https://github.com/androidbeepboop", "followers_url": "https://api.github.com/users/androidbeepboop/followers", "following_url": "https://api.github.com/users/androidbeepboop/following{/other_user}", "gists_url": "https://api.github.com/users/androidbeepboop/gists{/gist_id}", "starred_url": "https://api.github.com/users/androidbeepboop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/androidbeepboop/subscriptions", "organizations_url": "https://api.github.com/users/androidbeepboop/orgs", "repos_url": "https://api.github.com/users/androidbeepboop/repos", "events_url": "https://api.github.com/users/androidbeepboop/events{/privacy}", "received_events_url": "https://api.github.com/users/androidbeepboop/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-14T23:18:14Z", "updated_at": "2018-03-14T23:18:14Z", "author_association": "NONE", "body_html": "<p>I'm having a similar issue. I want to run indefinite training cycles back to back, because I'm using an evolutionary algorithm to optimize the hyperparameters. However, over time, the GPU \"waits\" for greater and greater times between training cycles (afterburner visualization):</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/37384864/37435942-dffbfd7c-27bb-11e8-8e83-7b6b2c0dbc3e.png\"><img src=\"https://user-images.githubusercontent.com/37384864/37435942-dffbfd7c-27bb-11e8-8e83-7b6b2c0dbc3e.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>I assume this is a memory issue in a similar vein. Any ideas of a workaround? I found an attempt at a solution using Keras to reset GPU memory after each run, and have tried this, but it has not solved the problem (it may have somewhat shortened the lag between training runs, but not enough to constitute a fix). <a href=\"http://forums.fast.ai/t/tip-clear-tensorflow-gpu-memory/1979\" rel=\"nofollow\">Keras \"fix\"</a><br>\nWhat do you suppose is going on here? I.e. what may be the source of the problem, and resources that could help me address it?</p>\n<p>Thanks!</p>", "body_text": "I'm having a similar issue. I want to run indefinite training cycles back to back, because I'm using an evolutionary algorithm to optimize the hyperparameters. However, over time, the GPU \"waits\" for greater and greater times between training cycles (afterburner visualization):\n\nI assume this is a memory issue in a similar vein. Any ideas of a workaround? I found an attempt at a solution using Keras to reset GPU memory after each run, and have tried this, but it has not solved the problem (it may have somewhat shortened the lag between training runs, but not enough to constitute a fix). Keras \"fix\"\nWhat do you suppose is going on here? I.e. what may be the source of the problem, and resources that could help me address it?\nThanks!", "body": "I'm having a similar issue. I want to run indefinite training cycles back to back, because I'm using an evolutionary algorithm to optimize the hyperparameters. However, over time, the GPU \"waits\" for greater and greater times between training cycles (afterburner visualization):\r\n\r\n![image](https://user-images.githubusercontent.com/37384864/37435942-dffbfd7c-27bb-11e8-8e83-7b6b2c0dbc3e.png)\r\n\r\nI assume this is a memory issue in a similar vein. Any ideas of a workaround? I found an attempt at a solution using Keras to reset GPU memory after each run, and have tried this, but it has not solved the problem (it may have somewhat shortened the lag between training runs, but not enough to constitute a fix). [Keras \"fix\"](http://forums.fast.ai/t/tip-clear-tensorflow-gpu-memory/1979)\r\nWhat do you suppose is going on here? I.e. what may be the source of the problem, and resources that could help me address it?\r\n\r\nThanks!"}