{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/368082470", "html_url": "https://github.com/tensorflow/tensorflow/issues/17048#issuecomment-368082470", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17048", "id": 368082470, "node_id": "MDEyOklzc3VlQ29tbWVudDM2ODA4MjQ3MA==", "user": {"login": "nathandouglas", "id": 10602509, "node_id": "MDQ6VXNlcjEwNjAyNTA5", "avatar_url": "https://avatars3.githubusercontent.com/u/10602509?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nathandouglas", "html_url": "https://github.com/nathandouglas", "followers_url": "https://api.github.com/users/nathandouglas/followers", "following_url": "https://api.github.com/users/nathandouglas/following{/other_user}", "gists_url": "https://api.github.com/users/nathandouglas/gists{/gist_id}", "starred_url": "https://api.github.com/users/nathandouglas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nathandouglas/subscriptions", "organizations_url": "https://api.github.com/users/nathandouglas/orgs", "repos_url": "https://api.github.com/users/nathandouglas/repos", "events_url": "https://api.github.com/users/nathandouglas/events{/privacy}", "received_events_url": "https://api.github.com/users/nathandouglas/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-23T17:38:18Z", "updated_at": "2018-02-23T17:39:03Z", "author_association": "NONE", "body_html": "<p>I'm currently building out a workflow using Celery to perform a set of image analytics in parallel. I ran into this issues since the celery daemon, once started, never released GPU resources after it completed processing images that used TensorFlow. As a result, I quickly depleted all of my GPU resources. My interim solution to the problem was to wrap my analytic in a Pool that spawns a single Process. It's not pretty, but it at least solves the problem in releasing GPU resources if you have a long running process like a celery daemon.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">from</span> multiprocessing <span class=\"pl-k\">import</span> Pool\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_process</span>(<span class=\"pl-smi\">image</span>):\n    sess <span class=\"pl-k\">=</span> tf.Session()\n    sess.close()\n\n   \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">process_image</span>(<span class=\"pl-smi\">image</span>):\n    <span class=\"pl-k\">with</span> Pool(<span class=\"pl-c1\">1</span>) <span class=\"pl-k\">as</span> p:\n        <span class=\"pl-k\">return</span> p.apply(_process, (image,))</pre></div>", "body_text": "I'm currently building out a workflow using Celery to perform a set of image analytics in parallel. I ran into this issues since the celery daemon, once started, never released GPU resources after it completed processing images that used TensorFlow. As a result, I quickly depleted all of my GPU resources. My interim solution to the problem was to wrap my analytic in a Pool that spawns a single Process. It's not pretty, but it at least solves the problem in releasing GPU resources if you have a long running process like a celery daemon.\nimport tensorflow as tf\n\nfrom multiprocessing import Pool\n\n\ndef _process(image):\n    sess = tf.Session()\n    sess.close()\n\n   \ndef process_image(image):\n    with Pool(1) as p:\n        return p.apply(_process, (image,))", "body": "I'm currently building out a workflow using Celery to perform a set of image analytics in parallel. I ran into this issues since the celery daemon, once started, never released GPU resources after it completed processing images that used TensorFlow. As a result, I quickly depleted all of my GPU resources. My interim solution to the problem was to wrap my analytic in a Pool that spawns a single Process. It's not pretty, but it at least solves the problem in releasing GPU resources if you have a long running process like a celery daemon.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nfrom multiprocessing import Pool\r\n\r\n\r\ndef _process(image):\r\n    sess = tf.Session()\r\n    sess.close()\r\n\r\n   \r\ndef process_image(image):\r\n    with Pool(1) as p:\r\n        return p.apply(_process, (image,))\r\n```\r\n\r\n"}