{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285446801", "html_url": "https://github.com/tensorflow/tensorflow/issues/8227#issuecomment-285446801", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8227", "id": 285446801, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTQ0NjgwMQ==", "user": {"login": "taion", "id": 3112159, "node_id": "MDQ6VXNlcjMxMTIxNTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/3112159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taion", "html_url": "https://github.com/taion", "followers_url": "https://api.github.com/users/taion/followers", "following_url": "https://api.github.com/users/taion/following{/other_user}", "gists_url": "https://api.github.com/users/taion/gists{/gist_id}", "starred_url": "https://api.github.com/users/taion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taion/subscriptions", "organizations_url": "https://api.github.com/users/taion/orgs", "repos_url": "https://api.github.com/users/taion/repos", "events_url": "https://api.github.com/users/taion/events{/privacy}", "received_events_url": "https://api.github.com/users/taion/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-09T19:00:56Z", "updated_at": "2017-03-09T19:00:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Inference-time models need to be different from training-time models regardless, no? You want to build them with <code>training</code> or <code>is_training</code> set to <code>False</code> to drop unnecessary stuff for batch norm, dropout, &amp;c.</p>\n<p>I guess these can be handled in optimization passes, but at least that's not how we're handling it right now. We rebuild our graphs for inference with <code>training=False</code> before passing them through optimization.</p>", "body_text": "Inference-time models need to be different from training-time models regardless, no? You want to build them with training or is_training set to False to drop unnecessary stuff for batch norm, dropout, &c.\nI guess these can be handled in optimization passes, but at least that's not how we're handling it right now. We rebuild our graphs for inference with training=False before passing them through optimization.", "body": "Inference-time models need to be different from training-time models regardless, no? You want to build them with `training` or `is_training` set to `False` to drop unnecessary stuff for batch norm, dropout, &c.\r\n\r\nI guess these can be handled in optimization passes, but at least that's not how we're handling it right now. We rebuild our graphs for inference with `training=False` before passing them through optimization."}