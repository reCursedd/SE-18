{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/408046598", "html_url": "https://github.com/tensorflow/tensorflow/issues/20509#issuecomment-408046598", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20509", "id": 408046598, "node_id": "MDEyOklzc3VlQ29tbWVudDQwODA0NjU5OA==", "user": {"login": "carlthome", "id": 1595907, "node_id": "MDQ6VXNlcjE1OTU5MDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1595907?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carlthome", "html_url": "https://github.com/carlthome", "followers_url": "https://api.github.com/users/carlthome/followers", "following_url": "https://api.github.com/users/carlthome/following{/other_user}", "gists_url": "https://api.github.com/users/carlthome/gists{/gist_id}", "starred_url": "https://api.github.com/users/carlthome/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carlthome/subscriptions", "organizations_url": "https://api.github.com/users/carlthome/orgs", "repos_url": "https://api.github.com/users/carlthome/repos", "events_url": "https://api.github.com/users/carlthome/events{/privacy}", "received_events_url": "https://api.github.com/users/carlthome/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-26T10:04:20Z", "updated_at": "2018-07-26T10:04:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks for the clarification <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=14104855\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/guptapriya\">@guptapriya</a>!</p>\n<p>I'm using <code>train_and_evaluate</code> because I'd like to do <a href=\"https://en.wikipedia.org/wiki/Early_stopping\" rel=\"nofollow\">early stopping</a> (checking loss on a validation set every now and then during training, and stopping the training loop when the model stops improving on the validation data). I'm currently doing this with <code>tf.contrib.estimator.stop_if_no_decrease_hook</code>. This also crashes with the same stack trace:</p>\n<div class=\"highlight highlight-source-python\"><pre>eval_hook <span class=\"pl-k\">=</span> tf.contrib.estimator.InMemoryEvaluatorHook(estimator, validation_input_fn)\nestimator.train(training_input_fn, <span class=\"pl-v\">hooks</span><span class=\"pl-k\">=</span>[early_stopping, eval_hook])\nmetrics <span class=\"pl-k\">=</span> estimator.evaluate(test_input_fn)</pre></div>\n<p>I guess this is a workaround at the moment for local training:</p>\n<div class=\"highlight highlight-source-python\"><pre>best <span class=\"pl-k\">=</span> <span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>inf<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">for</span> epoch <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">100</span>):\n    estimator.train(training_input_fn)\n    metrics <span class=\"pl-k\">=</span> estimator.evaluate(validation_input_fn)\n    <span class=\"pl-k\">if</span> metrics[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>loss<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">&lt;</span> best:\n        best <span class=\"pl-k\">=</span> metrics[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>loss<span class=\"pl-pds\">'</span></span>]\n    <span class=\"pl-k\">else</span>:\n        tf.logging.info(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-s\">Early stopping after </span><span class=\"pl-c1\">{</span>epoch<span class=\"pl-c1\">}</span><span class=\"pl-s\"> epochs.</span><span class=\"pl-pds\">'</span>)\n        <span class=\"pl-k\">break</span></pre></div>\n<p>but it would be nice to have asynchronous training and validation loops via some high-level construct like <code>train_and_evaluate</code> eventually! The dream would be to write high-level TensorFlow code once, and have that working in any hardware configuration (multi-machine, single-machine, multi-GPU, CPU-only, etc.).</p>", "body_text": "Thanks for the clarification @guptapriya!\nI'm using train_and_evaluate because I'd like to do early stopping (checking loss on a validation set every now and then during training, and stopping the training loop when the model stops improving on the validation data). I'm currently doing this with tf.contrib.estimator.stop_if_no_decrease_hook. This also crashes with the same stack trace:\neval_hook = tf.contrib.estimator.InMemoryEvaluatorHook(estimator, validation_input_fn)\nestimator.train(training_input_fn, hooks=[early_stopping, eval_hook])\nmetrics = estimator.evaluate(test_input_fn)\nI guess this is a workaround at the moment for local training:\nbest = float('inf')\nfor epoch in range(100):\n    estimator.train(training_input_fn)\n    metrics = estimator.evaluate(validation_input_fn)\n    if metrics['loss'] < best:\n        best = metrics['loss']\n    else:\n        tf.logging.info(f'Early stopping after {epoch} epochs.')\n        break\nbut it would be nice to have asynchronous training and validation loops via some high-level construct like train_and_evaluate eventually! The dream would be to write high-level TensorFlow code once, and have that working in any hardware configuration (multi-machine, single-machine, multi-GPU, CPU-only, etc.).", "body": "Thanks for the clarification @guptapriya!\r\n\r\nI'm using `train_and_evaluate` because I'd like to do [early stopping](https://en.wikipedia.org/wiki/Early_stopping) (checking loss on a validation set every now and then during training, and stopping the training loop when the model stops improving on the validation data). I'm currently doing this with `tf.contrib.estimator.stop_if_no_decrease_hook`. This also crashes with the same stack trace:\r\n```py\r\neval_hook = tf.contrib.estimator.InMemoryEvaluatorHook(estimator, validation_input_fn)\r\nestimator.train(training_input_fn, hooks=[early_stopping, eval_hook])\r\nmetrics = estimator.evaluate(test_input_fn)\r\n```\r\n\r\nI guess this is a workaround at the moment for local training:\r\n```py\r\nbest = float('inf')\r\nfor epoch in range(100):\r\n    estimator.train(training_input_fn)\r\n    metrics = estimator.evaluate(validation_input_fn)\r\n    if metrics['loss'] < best:\r\n        best = metrics['loss']\r\n    else:\r\n        tf.logging.info(f'Early stopping after {epoch} epochs.')\r\n        break\r\n```\r\nbut it would be nice to have asynchronous training and validation loops via some high-level construct like `train_and_evaluate` eventually! The dream would be to write high-level TensorFlow code once, and have that working in any hardware configuration (multi-machine, single-machine, multi-GPU, CPU-only, etc.)."}