{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/406518253", "html_url": "https://github.com/tensorflow/tensorflow/issues/20509#issuecomment-406518253", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20509", "id": 406518253, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNjUxODI1Mw==", "user": {"login": "carlthome", "id": 1595907, "node_id": "MDQ6VXNlcjE1OTU5MDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1595907?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carlthome", "html_url": "https://github.com/carlthome", "followers_url": "https://api.github.com/users/carlthome/followers", "following_url": "https://api.github.com/users/carlthome/following{/other_user}", "gists_url": "https://api.github.com/users/carlthome/gists{/gist_id}", "starred_url": "https://api.github.com/users/carlthome/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carlthome/subscriptions", "organizations_url": "https://api.github.com/users/carlthome/orgs", "repos_url": "https://api.github.com/users/carlthome/repos", "events_url": "https://api.github.com/users/carlthome/events{/privacy}", "received_events_url": "https://api.github.com/users/carlthome/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-20T07:50:36Z", "updated_at": "2018-07-20T07:54:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This seems to reproduce the error consistently:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">input_fn</span>():\n    dataset <span class=\"pl-k\">=</span> (\n        tf.data.Dataset\n        .range(<span class=\"pl-c1\">100</span>)\n        .map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: tf.random_normal([<span class=\"pl-c1\">100</span>]))\n        .batch(<span class=\"pl-c1\">32</span>)\n        .map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: ({<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>: x}, {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>: x}))\n        .repeat()\n    )\n    <span class=\"pl-k\">return</span> dataset\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>, <span class=\"pl-smi\">params</span>):\n\n    units <span class=\"pl-k\">=</span> features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>].shape[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\n    predictions <span class=\"pl-k\">=</span> tf.layers.dense(features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>], units)\n    labels <span class=\"pl-k\">=</span> labels[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>]\n\n    loss <span class=\"pl-k\">=</span> tf.losses.mean_squared_error(labels, predictions)\n    tf.losses.add_loss(loss)\n    loss <span class=\"pl-k\">=</span> tf.losses.get_total_loss()\n\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">EVAL</span>:\n        metrics <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>mse<span class=\"pl-pds\">'</span></span>: tf.metrics.mean_squared_error(labels, predictions)}\n\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(\n            mode,\n            <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss,\n            <span class=\"pl-v\">eval_metric_ops</span><span class=\"pl-k\">=</span>metrics,\n        )\n\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>:\n        step <span class=\"pl-k\">=</span> tf.train.get_or_create_global_step()\n        optimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer()\n        train_op <span class=\"pl-k\">=</span> optimizer.minimize(loss, step)\n\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(\n            mode,\n            <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss,\n            <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>train_op,\n        )\n\n\nestimator <span class=\"pl-k\">=</span> tf.estimator.Estimator(\n    model_fn,\n    <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>tf.estimator.RunConfig(\n        <span class=\"pl-v\">save_checkpoints_steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>,\n        <span class=\"pl-v\">train_distribute</span><span class=\"pl-k\">=</span>tf.contrib.distribute.MirroredStrategy()),\n)\n\ntf.estimator.train_and_evaluate(\n    estimator,\n    <span class=\"pl-v\">train_spec</span><span class=\"pl-k\">=</span>tf.estimator.TrainSpec(input_fn),\n    <span class=\"pl-v\">eval_spec</span><span class=\"pl-k\">=</span>tf.estimator.EvalSpec(input_fn),\n)</pre></div>\n<p>Am I doing something wrong? All GPUs are utilized during training but this stack trace pops up upon evaluation:</p>\n<pre><code>---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-2-b27091873f02&gt; in &lt;module&gt;()\n     56     estimator,\n     57     train_spec=tf.estimator.TrainSpec(input_fn),\n---&gt; 58     eval_spec=tf.estimator.EvalSpec(input_fn),\n     59 )\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)\n    449         '(with task id 0).  Given task id {}'.format(config.task_id))\n    450 \n--&gt; 451   return executor.run()\n    452 \n    453 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run(self)\n    588         config.task_type != run_config_lib.TaskType.EVALUATOR):\n    589       logging.info('Running training and evaluation locally (non-distributed).')\n--&gt; 590       return self.run_local()\n    591 \n    592     # Distributed case.\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run_local(self)\n    689         max_steps=self._train_spec.max_steps,\n    690         hooks=train_hooks,\n--&gt; 691         saving_listeners=saving_listeners)\n    692 \n    693     eval_result = listener_for_eval.eval_result or _EvalResult(\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    374 \n    375       saving_listeners = _check_listeners_type(saving_listeners)\n--&gt; 376       loss = self._train_model(input_fn, hooks, saving_listeners)\n    377       logging.info('Loss for final step: %s.', loss)\n    378       return self\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1141   def _train_model(self, input_fn, hooks, saving_listeners):\n   1142     if self._distribution:\n-&gt; 1143       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1144     else:\n   1145       return self._train_model_default(input_fn, hooks, saving_listeners)\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model_distributed(self, input_fn, hooks, saving_listeners)\n   1366         return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n   1367                                                hooks, global_step_tensor,\n-&gt; 1368                                                saving_listeners)\n   1369 \n   1370   def _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks,\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\n   1449       loss = None\n   1450       while not mon_sess.should_stop():\n-&gt; 1451         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n   1452     return loss\n   1453 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n    581                           feed_dict=feed_dict,\n    582                           options=options,\n--&gt; 583                           run_metadata=run_metadata)\n    584 \n    585   def run_step_fn(self, step_fn):\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n   1057                               feed_dict=feed_dict,\n   1058                               options=options,\n-&gt; 1059                               run_metadata=run_metadata)\n   1060       except _PREEMPTION_ERRORS as e:\n   1061         logging.info('An error was raised. This may be due to a preemption in '\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n   1148         raise six.reraise(*original_exc_info)\n   1149       else:\n-&gt; 1150         raise six.reraise(*original_exc_info)\n   1151 \n   1152 \n\n~/.miniconda3/lib/python3.6/site-packages/six.py in reraise(tp, value, tb)\n    691             if value.__traceback__ is not tb:\n    692                 raise value.with_traceback(tb)\n--&gt; 693             raise value\n    694         finally:\n    695             value = None\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n   1133   def run(self, *args, **kwargs):\n   1134     try:\n-&gt; 1135       return self._sess.run(*args, **kwargs)\n   1136     except _PREEMPTION_ERRORS:\n   1137       raise\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n   1213               results=outputs[hook] if hook in outputs else None,\n   1214               options=options,\n-&gt; 1215               run_metadata=run_metadata))\n   1216     self._should_stop = self._should_stop or run_context.stop_requested\n   1217 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py in after_run(self, run_context, run_values)\n    462       if self._timer.should_trigger_for_step(global_step):\n    463         self._timer.update_last_triggered_step(global_step)\n--&gt; 464         if self._save(run_context.session, global_step):\n    465           run_context.request_stop()\n    466 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py in _save(self, session, step)\n    487     should_stop = False\n    488     for l in self._listeners:\n--&gt; 489       if l.after_save(session, step):\n    490         logging.info(\n    491             \"A CheckpointSaverListener requested that training be stopped. \"\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in after_save(***failed resolving arguments***)\n    495       return True\n    496     if self._timer.should_trigger_for_step(global_step_value):\n--&gt; 497       self._evaluate(global_step_value)  # updates self.eval_result\n    498       if not self._continuous_eval_listener.after_eval(self.eval_result):\n    499         logging.info('Exiting evaluation, as requested by '\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in _evaluate(self, global_step_value)\n    515     self._timer.update_last_triggered_step(global_step_value)\n    516     self.eval_result, self.export_results = (\n--&gt; 517         self._evaluator.evaluate_and_export())\n    518     if self.eval_result.status != _EvalStatus.EVALUATED:\n    519       #  This is unexpected; should never happen.\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in evaluate_and_export(self)\n    882           name=self._eval_spec.name,\n    883           checkpoint_path=latest_ckpt_path,\n--&gt; 884           hooks=self._eval_spec.hooks)\n    885 \n    886       # _EvalResult validates the metrics.\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in evaluate(self, input_fn, steps, hooks, checkpoint_path, name)\n    461         (scaffold, update_op,\n    462          eval_dict, all_hooks) = self._evaluate_build_graph(\n--&gt; 463              input_fn, hooks, checkpoint_path)\n    464         return self._evaluate_run(\n    465             checkpoint_path=checkpoint_path,\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _evaluate_build_graph(self, input_fn, hooks, checkpoint_path)\n   1461                                                     model_fn_lib.ModeKeys.EVAL))\n   1462     estimator_spec = self._call_model_fn(\n-&gt; 1463         features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n   1464 \n   1465     # Call to warm_start has to be after model_fn is called.\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\n   1131 \n   1132     logging.info('Calling model_fn.')\n-&gt; 1133     model_fn_results = self._model_fn(features=features, **kwargs)\n   1134     logging.info('Done calling model_fn.')\n   1135 \n\n&lt;ipython-input-2-b27091873f02&gt; in model_fn(features, labels, mode, params)\n     26 \n     27     if mode == tf.estimator.ModeKeys.EVAL:\n---&gt; 28         metrics = {'mse': tf.metrics.mean_squared_error(labels, predictions)}\n     29 \n     30         return tf.estimator.EstimatorSpec(\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in mean_squared_error(labels, predictions, weights, metrics_collections, updates_collections, name)\n   1297   squared_error = math_ops.square(labels - predictions)\n   1298   return mean(squared_error, weights, metrics_collections, updates_collections,\n-&gt; 1299               name or 'mean_squared_error')\n   1300 \n   1301 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in mean(values, weights, metrics_collections, updates_collections, name)\n    374       return mean_t\n    375 \n--&gt; 376     mean_t = distribute_lib.get_tower_context().merge_call(\n    377         aggregate_across_towers, total, count)\n    378     update_op = _safe_div(update_total_op, update_count_op, 'update_op')\n\nAttributeError: 'NoneType' object has no attribute 'merge_call'\n</code></pre>", "body_text": "This seems to reproduce the error consistently:\nimport tensorflow as tf\n\n\ndef input_fn():\n    dataset = (\n        tf.data.Dataset\n        .range(100)\n        .map(lambda x: tf.random_normal([100]))\n        .batch(32)\n        .map(lambda x: ({'input': x}, {'output': x}))\n        .repeat()\n    )\n    return dataset\n\n\ndef model_fn(features, labels, mode, params):\n\n    units = features['input'].shape[-1]\n    predictions = tf.layers.dense(features['input'], units)\n    labels = labels['output']\n\n    loss = tf.losses.mean_squared_error(labels, predictions)\n    tf.losses.add_loss(loss)\n    loss = tf.losses.get_total_loss()\n\n    if mode == tf.estimator.ModeKeys.EVAL:\n        metrics = {'mse': tf.metrics.mean_squared_error(labels, predictions)}\n\n        return tf.estimator.EstimatorSpec(\n            mode,\n            loss=loss,\n            eval_metric_ops=metrics,\n        )\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        step = tf.train.get_or_create_global_step()\n        optimizer = tf.train.AdamOptimizer()\n        train_op = optimizer.minimize(loss, step)\n\n        return tf.estimator.EstimatorSpec(\n            mode,\n            loss=loss,\n            train_op=train_op,\n        )\n\n\nestimator = tf.estimator.Estimator(\n    model_fn,\n    config=tf.estimator.RunConfig(\n        save_checkpoints_steps=100,\n        train_distribute=tf.contrib.distribute.MirroredStrategy()),\n)\n\ntf.estimator.train_and_evaluate(\n    estimator,\n    train_spec=tf.estimator.TrainSpec(input_fn),\n    eval_spec=tf.estimator.EvalSpec(input_fn),\n)\nAm I doing something wrong? All GPUs are utilized during training but this stack trace pops up upon evaluation:\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n<ipython-input-2-b27091873f02> in <module>()\n     56     estimator,\n     57     train_spec=tf.estimator.TrainSpec(input_fn),\n---> 58     eval_spec=tf.estimator.EvalSpec(input_fn),\n     59 )\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)\n    449         '(with task id 0).  Given task id {}'.format(config.task_id))\n    450 \n--> 451   return executor.run()\n    452 \n    453 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run(self)\n    588         config.task_type != run_config_lib.TaskType.EVALUATOR):\n    589       logging.info('Running training and evaluation locally (non-distributed).')\n--> 590       return self.run_local()\n    591 \n    592     # Distributed case.\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run_local(self)\n    689         max_steps=self._train_spec.max_steps,\n    690         hooks=train_hooks,\n--> 691         saving_listeners=saving_listeners)\n    692 \n    693     eval_result = listener_for_eval.eval_result or _EvalResult(\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    374 \n    375       saving_listeners = _check_listeners_type(saving_listeners)\n--> 376       loss = self._train_model(input_fn, hooks, saving_listeners)\n    377       logging.info('Loss for final step: %s.', loss)\n    378       return self\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1141   def _train_model(self, input_fn, hooks, saving_listeners):\n   1142     if self._distribution:\n-> 1143       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1144     else:\n   1145       return self._train_model_default(input_fn, hooks, saving_listeners)\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model_distributed(self, input_fn, hooks, saving_listeners)\n   1366         return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n   1367                                                hooks, global_step_tensor,\n-> 1368                                                saving_listeners)\n   1369 \n   1370   def _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks,\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\n   1449       loss = None\n   1450       while not mon_sess.should_stop():\n-> 1451         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n   1452     return loss\n   1453 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n    581                           feed_dict=feed_dict,\n    582                           options=options,\n--> 583                           run_metadata=run_metadata)\n    584 \n    585   def run_step_fn(self, step_fn):\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n   1057                               feed_dict=feed_dict,\n   1058                               options=options,\n-> 1059                               run_metadata=run_metadata)\n   1060       except _PREEMPTION_ERRORS as e:\n   1061         logging.info('An error was raised. This may be due to a preemption in '\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n   1148         raise six.reraise(*original_exc_info)\n   1149       else:\n-> 1150         raise six.reraise(*original_exc_info)\n   1151 \n   1152 \n\n~/.miniconda3/lib/python3.6/site-packages/six.py in reraise(tp, value, tb)\n    691             if value.__traceback__ is not tb:\n    692                 raise value.with_traceback(tb)\n--> 693             raise value\n    694         finally:\n    695             value = None\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n   1133   def run(self, *args, **kwargs):\n   1134     try:\n-> 1135       return self._sess.run(*args, **kwargs)\n   1136     except _PREEMPTION_ERRORS:\n   1137       raise\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n   1213               results=outputs[hook] if hook in outputs else None,\n   1214               options=options,\n-> 1215               run_metadata=run_metadata))\n   1216     self._should_stop = self._should_stop or run_context.stop_requested\n   1217 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py in after_run(self, run_context, run_values)\n    462       if self._timer.should_trigger_for_step(global_step):\n    463         self._timer.update_last_triggered_step(global_step)\n--> 464         if self._save(run_context.session, global_step):\n    465           run_context.request_stop()\n    466 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py in _save(self, session, step)\n    487     should_stop = False\n    488     for l in self._listeners:\n--> 489       if l.after_save(session, step):\n    490         logging.info(\n    491             \"A CheckpointSaverListener requested that training be stopped. \"\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in after_save(***failed resolving arguments***)\n    495       return True\n    496     if self._timer.should_trigger_for_step(global_step_value):\n--> 497       self._evaluate(global_step_value)  # updates self.eval_result\n    498       if not self._continuous_eval_listener.after_eval(self.eval_result):\n    499         logging.info('Exiting evaluation, as requested by '\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in _evaluate(self, global_step_value)\n    515     self._timer.update_last_triggered_step(global_step_value)\n    516     self.eval_result, self.export_results = (\n--> 517         self._evaluator.evaluate_and_export())\n    518     if self.eval_result.status != _EvalStatus.EVALUATED:\n    519       #  This is unexpected; should never happen.\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in evaluate_and_export(self)\n    882           name=self._eval_spec.name,\n    883           checkpoint_path=latest_ckpt_path,\n--> 884           hooks=self._eval_spec.hooks)\n    885 \n    886       # _EvalResult validates the metrics.\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in evaluate(self, input_fn, steps, hooks, checkpoint_path, name)\n    461         (scaffold, update_op,\n    462          eval_dict, all_hooks) = self._evaluate_build_graph(\n--> 463              input_fn, hooks, checkpoint_path)\n    464         return self._evaluate_run(\n    465             checkpoint_path=checkpoint_path,\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _evaluate_build_graph(self, input_fn, hooks, checkpoint_path)\n   1461                                                     model_fn_lib.ModeKeys.EVAL))\n   1462     estimator_spec = self._call_model_fn(\n-> 1463         features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n   1464 \n   1465     # Call to warm_start has to be after model_fn is called.\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\n   1131 \n   1132     logging.info('Calling model_fn.')\n-> 1133     model_fn_results = self._model_fn(features=features, **kwargs)\n   1134     logging.info('Done calling model_fn.')\n   1135 \n\n<ipython-input-2-b27091873f02> in model_fn(features, labels, mode, params)\n     26 \n     27     if mode == tf.estimator.ModeKeys.EVAL:\n---> 28         metrics = {'mse': tf.metrics.mean_squared_error(labels, predictions)}\n     29 \n     30         return tf.estimator.EstimatorSpec(\n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in mean_squared_error(labels, predictions, weights, metrics_collections, updates_collections, name)\n   1297   squared_error = math_ops.square(labels - predictions)\n   1298   return mean(squared_error, weights, metrics_collections, updates_collections,\n-> 1299               name or 'mean_squared_error')\n   1300 \n   1301 \n\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in mean(values, weights, metrics_collections, updates_collections, name)\n    374       return mean_t\n    375 \n--> 376     mean_t = distribute_lib.get_tower_context().merge_call(\n    377         aggregate_across_towers, total, count)\n    378     update_op = _safe_div(update_total_op, update_count_op, 'update_op')\n\nAttributeError: 'NoneType' object has no attribute 'merge_call'", "body": "This seems to reproduce the error consistently:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ndef input_fn():\r\n    dataset = (\r\n        tf.data.Dataset\r\n        .range(100)\r\n        .map(lambda x: tf.random_normal([100]))\r\n        .batch(32)\r\n        .map(lambda x: ({'input': x}, {'output': x}))\r\n        .repeat()\r\n    )\r\n    return dataset\r\n\r\n\r\ndef model_fn(features, labels, mode, params):\r\n\r\n    units = features['input'].shape[-1]\r\n    predictions = tf.layers.dense(features['input'], units)\r\n    labels = labels['output']\r\n\r\n    loss = tf.losses.mean_squared_error(labels, predictions)\r\n    tf.losses.add_loss(loss)\r\n    loss = tf.losses.get_total_loss()\r\n\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        metrics = {'mse': tf.metrics.mean_squared_error(labels, predictions)}\r\n\r\n        return tf.estimator.EstimatorSpec(\r\n            mode,\r\n            loss=loss,\r\n            eval_metric_ops=metrics,\r\n        )\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        step = tf.train.get_or_create_global_step()\r\n        optimizer = tf.train.AdamOptimizer()\r\n        train_op = optimizer.minimize(loss, step)\r\n\r\n        return tf.estimator.EstimatorSpec(\r\n            mode,\r\n            loss=loss,\r\n            train_op=train_op,\r\n        )\r\n\r\n\r\nestimator = tf.estimator.Estimator(\r\n    model_fn,\r\n    config=tf.estimator.RunConfig(\r\n        save_checkpoints_steps=100,\r\n        train_distribute=tf.contrib.distribute.MirroredStrategy()),\r\n)\r\n\r\ntf.estimator.train_and_evaluate(\r\n    estimator,\r\n    train_spec=tf.estimator.TrainSpec(input_fn),\r\n    eval_spec=tf.estimator.EvalSpec(input_fn),\r\n)\r\n```\r\n\r\nAm I doing something wrong? All GPUs are utilized during training but this stack trace pops up upon evaluation:\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-b27091873f02> in <module>()\r\n     56     estimator,\r\n     57     train_spec=tf.estimator.TrainSpec(input_fn),\r\n---> 58     eval_spec=tf.estimator.EvalSpec(input_fn),\r\n     59 )\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)\r\n    449         '(with task id 0).  Given task id {}'.format(config.task_id))\r\n    450 \r\n--> 451   return executor.run()\r\n    452 \r\n    453 \r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run(self)\r\n    588         config.task_type != run_config_lib.TaskType.EVALUATOR):\r\n    589       logging.info('Running training and evaluation locally (non-distributed).')\r\n--> 590       return self.run_local()\r\n    591 \r\n    592     # Distributed case.\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run_local(self)\r\n    689         max_steps=self._train_spec.max_steps,\r\n    690         hooks=train_hooks,\r\n--> 691         saving_listeners=saving_listeners)\r\n    692 \r\n    693     eval_result = listener_for_eval.eval_result or _EvalResult(\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    374 \r\n    375       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 376       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    377       logging.info('Loss for final step: %s.', loss)\r\n    378       return self\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1141   def _train_model(self, input_fn, hooks, saving_listeners):\r\n   1142     if self._distribution:\r\n-> 1143       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1144     else:\r\n   1145       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model_distributed(self, input_fn, hooks, saving_listeners)\r\n   1366         return self._train_with_estimator_spec(estimator_spec, worker_hooks,\r\n   1367                                                hooks, global_step_tensor,\r\n-> 1368                                                saving_listeners)\r\n   1369 \r\n   1370   def _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks,\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\r\n   1449       loss = None\r\n   1450       while not mon_sess.should_stop():\r\n-> 1451         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n   1452     return loss\r\n   1453 \r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    581                           feed_dict=feed_dict,\r\n    582                           options=options,\r\n--> 583                           run_metadata=run_metadata)\r\n    584 \r\n    585   def run_step_fn(self, step_fn):\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n   1057                               feed_dict=feed_dict,\r\n   1058                               options=options,\r\n-> 1059                               run_metadata=run_metadata)\r\n   1060       except _PREEMPTION_ERRORS as e:\r\n   1061         logging.info('An error was raised. This may be due to a preemption in '\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\r\n   1148         raise six.reraise(*original_exc_info)\r\n   1149       else:\r\n-> 1150         raise six.reraise(*original_exc_info)\r\n   1151 \r\n   1152 \r\n\r\n~/.miniconda3/lib/python3.6/site-packages/six.py in reraise(tp, value, tb)\r\n    691             if value.__traceback__ is not tb:\r\n    692                 raise value.with_traceback(tb)\r\n--> 693             raise value\r\n    694         finally:\r\n    695             value = None\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\r\n   1133   def run(self, *args, **kwargs):\r\n   1134     try:\r\n-> 1135       return self._sess.run(*args, **kwargs)\r\n   1136     except _PREEMPTION_ERRORS:\r\n   1137       raise\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n   1213               results=outputs[hook] if hook in outputs else None,\r\n   1214               options=options,\r\n-> 1215               run_metadata=run_metadata))\r\n   1216     self._should_stop = self._should_stop or run_context.stop_requested\r\n   1217 \r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py in after_run(self, run_context, run_values)\r\n    462       if self._timer.should_trigger_for_step(global_step):\r\n    463         self._timer.update_last_triggered_step(global_step)\r\n--> 464         if self._save(run_context.session, global_step):\r\n    465           run_context.request_stop()\r\n    466 \r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py in _save(self, session, step)\r\n    487     should_stop = False\r\n    488     for l in self._listeners:\r\n--> 489       if l.after_save(session, step):\r\n    490         logging.info(\r\n    491             \"A CheckpointSaverListener requested that training be stopped. \"\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in after_save(***failed resolving arguments***)\r\n    495       return True\r\n    496     if self._timer.should_trigger_for_step(global_step_value):\r\n--> 497       self._evaluate(global_step_value)  # updates self.eval_result\r\n    498       if not self._continuous_eval_listener.after_eval(self.eval_result):\r\n    499         logging.info('Exiting evaluation, as requested by '\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in _evaluate(self, global_step_value)\r\n    515     self._timer.update_last_triggered_step(global_step_value)\r\n    516     self.eval_result, self.export_results = (\r\n--> 517         self._evaluator.evaluate_and_export())\r\n    518     if self.eval_result.status != _EvalStatus.EVALUATED:\r\n    519       #  This is unexpected; should never happen.\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in evaluate_and_export(self)\r\n    882           name=self._eval_spec.name,\r\n    883           checkpoint_path=latest_ckpt_path,\r\n--> 884           hooks=self._eval_spec.hooks)\r\n    885 \r\n    886       # _EvalResult validates the metrics.\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in evaluate(self, input_fn, steps, hooks, checkpoint_path, name)\r\n    461         (scaffold, update_op,\r\n    462          eval_dict, all_hooks) = self._evaluate_build_graph(\r\n--> 463              input_fn, hooks, checkpoint_path)\r\n    464         return self._evaluate_run(\r\n    465             checkpoint_path=checkpoint_path,\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _evaluate_build_graph(self, input_fn, hooks, checkpoint_path)\r\n   1461                                                     model_fn_lib.ModeKeys.EVAL))\r\n   1462     estimator_spec = self._call_model_fn(\r\n-> 1463         features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\r\n   1464 \r\n   1465     # Call to warm_start has to be after model_fn is called.\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\r\n   1131 \r\n   1132     logging.info('Calling model_fn.')\r\n-> 1133     model_fn_results = self._model_fn(features=features, **kwargs)\r\n   1134     logging.info('Done calling model_fn.')\r\n   1135 \r\n\r\n<ipython-input-2-b27091873f02> in model_fn(features, labels, mode, params)\r\n     26 \r\n     27     if mode == tf.estimator.ModeKeys.EVAL:\r\n---> 28         metrics = {'mse': tf.metrics.mean_squared_error(labels, predictions)}\r\n     29 \r\n     30         return tf.estimator.EstimatorSpec(\r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in mean_squared_error(labels, predictions, weights, metrics_collections, updates_collections, name)\r\n   1297   squared_error = math_ops.square(labels - predictions)\r\n   1298   return mean(squared_error, weights, metrics_collections, updates_collections,\r\n-> 1299               name or 'mean_squared_error')\r\n   1300 \r\n   1301 \r\n\r\n~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in mean(values, weights, metrics_collections, updates_collections, name)\r\n    374       return mean_t\r\n    375 \r\n--> 376     mean_t = distribute_lib.get_tower_context().merge_call(\r\n    377         aggregate_across_towers, total, count)\r\n    378     update_op = _safe_div(update_total_op, update_count_op, 'update_op')\r\n\r\nAttributeError: 'NoneType' object has no attribute 'merge_call'\r\n```"}