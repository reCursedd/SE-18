{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/424113801", "html_url": "https://github.com/tensorflow/tensorflow/issues/22465#issuecomment-424113801", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22465", "id": 424113801, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDExMzgwMQ==", "user": {"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-24T20:29:15Z", "updated_at": "2018-09-24T20:29:15Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3927162\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fanshiqing\">@fanshiqing</a></p>\n<p>Re (1): <code>tf.data.Dataset.prefetch()</code> buffer size auto-tuning is indeed one-way but this autotuning is currently not related to the performance model related autotuning of parallelism. <code>tf.data.Dataset.interleave()</code> and <code>tf.data.Dataset.map()</code> parallelism auto-tuning is not one-way. As you pointed out, this mechanism is meant to help users create pipelines that are expected to work across different environments (and data patterns). Adding support for default value provided by the user is certainly something that we could consider but at the moment we do not see need for it.</p>\n<p>Re (2): We plan to soon introduce a mechanism to allow users to configure the CPU budget to be used by the performance modeling for the parallelism auto-tuning.</p>\n<p>In other words, we are aware of the limitations you have pointed out and are working on addressing some of them. Since your request does not describe a concrete issue and steps how to reproduce it, I am going to close this issue.</p>", "body_text": "@fanshiqing\nRe (1): tf.data.Dataset.prefetch() buffer size auto-tuning is indeed one-way but this autotuning is currently not related to the performance model related autotuning of parallelism. tf.data.Dataset.interleave() and tf.data.Dataset.map() parallelism auto-tuning is not one-way. As you pointed out, this mechanism is meant to help users create pipelines that are expected to work across different environments (and data patterns). Adding support for default value provided by the user is certainly something that we could consider but at the moment we do not see need for it.\nRe (2): We plan to soon introduce a mechanism to allow users to configure the CPU budget to be used by the performance modeling for the parallelism auto-tuning.\nIn other words, we are aware of the limitations you have pointed out and are working on addressing some of them. Since your request does not describe a concrete issue and steps how to reproduce it, I am going to close this issue.", "body": "@fanshiqing \r\n\r\nRe (1): `tf.data.Dataset.prefetch()` buffer size auto-tuning is indeed one-way but this autotuning is currently not related to the performance model related autotuning of parallelism. `tf.data.Dataset.interleave()` and `tf.data.Dataset.map()` parallelism auto-tuning is not one-way. As you pointed out, this mechanism is meant to help users create pipelines that are expected to work across different environments (and data patterns). Adding support for default value provided by the user is certainly something that we could consider but at the moment we do not see need for it.\r\n\r\nRe (2): We plan to soon introduce a mechanism to allow users to configure the CPU budget to be used by the performance modeling for the parallelism auto-tuning.\r\n\r\nIn other words, we are aware of the limitations you have pointed out and are working on addressing some of them. Since your request does not describe a concrete issue and steps how to reproduce it, I am going to close this issue.\r\n"}