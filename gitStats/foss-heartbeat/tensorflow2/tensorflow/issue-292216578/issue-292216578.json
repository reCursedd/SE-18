{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16517", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16517/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16517/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16517/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16517", "id": 292216578, "node_id": "MDU6SXNzdWUyOTIyMTY1Nzg=", "number": 16517, "title": "ou must feed a value for placeholder tensor 'import/Placeholder when i test my frozen model", "user": {"login": "programowalny", "id": 10115910, "node_id": "MDQ6VXNlcjEwMTE1OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/10115910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/programowalny", "html_url": "https://github.com/programowalny", "followers_url": "https://api.github.com/users/programowalny/followers", "following_url": "https://api.github.com/users/programowalny/following{/other_user}", "gists_url": "https://api.github.com/users/programowalny/gists{/gist_id}", "starred_url": "https://api.github.com/users/programowalny/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/programowalny/subscriptions", "organizations_url": "https://api.github.com/users/programowalny/orgs", "repos_url": "https://api.github.com/users/programowalny/repos", "events_url": "https://api.github.com/users/programowalny/events{/privacy}", "received_events_url": "https://api.github.com/users/programowalny/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-28T16:15:22Z", "updated_at": "2018-01-30T19:10:44Z", "closed_at": "2018-01-30T19:10:44Z", "author_association": "NONE", "body_html": "<p>Hello , I trying create mobile app for object recognition for my own created model. I fallow this tutorial <a href=\"https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2/#2\" rel=\"nofollow\">https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2/#2</a><br>\nBut when i even get a testing model from step 3 i get error</p>\n<pre><code>InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'import/Placeholder' with dtype float\n\t [[Node: import/Placeholder = Placeholder[dtype=DT_FLOAT, shape=&lt;unknown&gt;, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n</code></pre>\n<p>I'm aware that is wrong node problem, but i trying with other and always i get failure</p>\n<p>My code for model creation</p>\n<pre><code>\nx = tf.placeholder(tf.float32,\n                   shape=[None, cons.IMAGE_SIZE, cons.IMAGE_SIZE, 3], name=\"x\")\ny_ = tf.placeholder(tf.float32, shape=[None, cons.LABELS_NUMB], name=\"labels\")\n\nK = 4\nL = 8\nM = 12\nN = 200\n\nx_image = tf.reshape(x, [-1, cons.IMAGE_SIZE, cons.IMAGE_SIZE, 3])\ntf.summary.image('input', x_image, 3)\nprint(\"X image \")\nprint(tf.shape(x_image))\n\n################## first ##############\n\nW_conv1 = weight_variable([5, 5, 3, 32], \"weight1\")\nb_conv1 = bias_variable([32], \"bias1\")\n\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\nprint(\"W_conv1 \")\nprint(tf.shape(W_conv1))\nprint(\"b_conv1 \")\nprint(tf.shape(b_conv1))\nprint(\"h_conv1 \")\nprint(tf.shape(h_conv1))\nprint(\"h_pool1 \")\nprint(tf.shape(h_pool1))\n\n################## second ##############\n\nW_conv2 = weight_variable([5, 5, 32, 64], \"weight2\")\nb_conv2 = bias_variable([64], \"bias2\")\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\ntf.summary.histogram(\"activations\", h_conv2)\n\n\nh_pool2 = max_pool_2x2(h_conv2)\n\nprint(\"W_conv2 \")\nprint(tf.shape(W_conv2))\nprint(\"b_conv2 \")\nprint(tf.shape(b_conv2))\nprint(\"h_conv2 \")\nprint(tf.shape(h_conv2))\nprint(\"h_pool2 \")\nprint(tf.shape(h_pool2))\n\n################## fully connected 3 ##############\n\nW_fc1 = weight_variable([8 * 8 * 64, 1024], \"Weight3\")\nb_fc1 = bias_variable([1024], \"bias3\")\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 8 * 8 * 64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\nprint(\"W_fc1 \")\nprint(tf.shape(W_fc1))\nprint(\"b_fc1 \")\nprint(tf.shape(b_fc1))\nprint(\"h_pool2_flat \")\nprint(tf.shape(h_pool2_flat))\nprint(\"h_fc1 \")\nprint(tf.shape(h_fc1))\n\n################ dropout  4 #################\n\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n################## fully connected 5 ##############\n\nW_fc2 = weight_variable([1024, cons.LABELS_NUMB], \"weight5\")\nb_fc2 = bias_variable([cons.LABELS_NUMB], \"bias5\")\n\nY = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\ntf.summary.histogram(\"final\", Y)\n\n\nprint(\"W_fc2 \")\nprint(tf.shape(W_fc2))\nprint(\"b_fc2 \")\nprint(tf.shape(b_fc2))\nprint(\"Y \")\nprint(tf.shape(Y))\n\nwith tf.name_scope(\"cross_entropy\"):\n    cross_entropy = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Y))\n    tf.summary.scalar(\"xent\", cross_entropy)\n\nwith tf.name_scope(\"train_step\"):\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\nwith tf.name_scope(\"Acuracy\"):\n    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    tf.summary.scalar(\"accuracy\", accuracy)\n\nsumm = tf.summary.merge_all()\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    writer = tf.summary.FileWriter(\"/home/damian/api/mnist_demo/10\")\n    writer.add_graph(sess.graph)\n    for i in range(1000):\n        img, lb = fileCreation.next_batch(100, images32, labels)\n        if i % 5 == 0:\n            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 1.0})\n        writer.add_summary(s, i)\n        if i % 100 == 0:\n            saver.save(sess, '/home/damian/api/checkpoint/my_test_model', global_step=i)\n            train_accuracy = accuracy.eval(feed_dict={\n                x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 1.0})\n            print('step %d, training accuracy %g' % (i, train_accuracy))\n        train_step.run(feed_dict={x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 0.5})\n\n    print('test accuracy %g' % accuracy.eval(feed_dict={x: test_images32,\n                                                        y_: fileCreation.dense_to_one_hot(test_labels,\n                                                                                          cons.LABELS_NUMB),\n                                                        keep_prob: 0.1}))\n</code></pre>\n<p>I'm freeze this model with and i point output_node to 'final'<br>\nnext i call script from tutorial</p>\n<pre><code>python -m scripts.label_image \\\n  --graph=tf_files/frozen_model3.pb  \\\n  --input_layer=x \\\n  --output_layer=final \\\n  --image=tf_files/stop.png  \\\n  --input_height=32 \\\n  --input_width=32 \\\n  --input_mean=16  \\\n  --input_std=16  \n</code></pre>", "body_text": "Hello , I trying create mobile app for object recognition for my own created model. I fallow this tutorial https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2/#2\nBut when i even get a testing model from step 3 i get error\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'import/Placeholder' with dtype float\n\t [[Node: import/Placeholder = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nI'm aware that is wrong node problem, but i trying with other and always i get failure\nMy code for model creation\n\nx = tf.placeholder(tf.float32,\n                   shape=[None, cons.IMAGE_SIZE, cons.IMAGE_SIZE, 3], name=\"x\")\ny_ = tf.placeholder(tf.float32, shape=[None, cons.LABELS_NUMB], name=\"labels\")\n\nK = 4\nL = 8\nM = 12\nN = 200\n\nx_image = tf.reshape(x, [-1, cons.IMAGE_SIZE, cons.IMAGE_SIZE, 3])\ntf.summary.image('input', x_image, 3)\nprint(\"X image \")\nprint(tf.shape(x_image))\n\n################## first ##############\n\nW_conv1 = weight_variable([5, 5, 3, 32], \"weight1\")\nb_conv1 = bias_variable([32], \"bias1\")\n\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\nprint(\"W_conv1 \")\nprint(tf.shape(W_conv1))\nprint(\"b_conv1 \")\nprint(tf.shape(b_conv1))\nprint(\"h_conv1 \")\nprint(tf.shape(h_conv1))\nprint(\"h_pool1 \")\nprint(tf.shape(h_pool1))\n\n################## second ##############\n\nW_conv2 = weight_variable([5, 5, 32, 64], \"weight2\")\nb_conv2 = bias_variable([64], \"bias2\")\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\ntf.summary.histogram(\"activations\", h_conv2)\n\n\nh_pool2 = max_pool_2x2(h_conv2)\n\nprint(\"W_conv2 \")\nprint(tf.shape(W_conv2))\nprint(\"b_conv2 \")\nprint(tf.shape(b_conv2))\nprint(\"h_conv2 \")\nprint(tf.shape(h_conv2))\nprint(\"h_pool2 \")\nprint(tf.shape(h_pool2))\n\n################## fully connected 3 ##############\n\nW_fc1 = weight_variable([8 * 8 * 64, 1024], \"Weight3\")\nb_fc1 = bias_variable([1024], \"bias3\")\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 8 * 8 * 64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\nprint(\"W_fc1 \")\nprint(tf.shape(W_fc1))\nprint(\"b_fc1 \")\nprint(tf.shape(b_fc1))\nprint(\"h_pool2_flat \")\nprint(tf.shape(h_pool2_flat))\nprint(\"h_fc1 \")\nprint(tf.shape(h_fc1))\n\n################ dropout  4 #################\n\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n################## fully connected 5 ##############\n\nW_fc2 = weight_variable([1024, cons.LABELS_NUMB], \"weight5\")\nb_fc2 = bias_variable([cons.LABELS_NUMB], \"bias5\")\n\nY = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\ntf.summary.histogram(\"final\", Y)\n\n\nprint(\"W_fc2 \")\nprint(tf.shape(W_fc2))\nprint(\"b_fc2 \")\nprint(tf.shape(b_fc2))\nprint(\"Y \")\nprint(tf.shape(Y))\n\nwith tf.name_scope(\"cross_entropy\"):\n    cross_entropy = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Y))\n    tf.summary.scalar(\"xent\", cross_entropy)\n\nwith tf.name_scope(\"train_step\"):\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\nwith tf.name_scope(\"Acuracy\"):\n    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    tf.summary.scalar(\"accuracy\", accuracy)\n\nsumm = tf.summary.merge_all()\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    writer = tf.summary.FileWriter(\"/home/damian/api/mnist_demo/10\")\n    writer.add_graph(sess.graph)\n    for i in range(1000):\n        img, lb = fileCreation.next_batch(100, images32, labels)\n        if i % 5 == 0:\n            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 1.0})\n        writer.add_summary(s, i)\n        if i % 100 == 0:\n            saver.save(sess, '/home/damian/api/checkpoint/my_test_model', global_step=i)\n            train_accuracy = accuracy.eval(feed_dict={\n                x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 1.0})\n            print('step %d, training accuracy %g' % (i, train_accuracy))\n        train_step.run(feed_dict={x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 0.5})\n\n    print('test accuracy %g' % accuracy.eval(feed_dict={x: test_images32,\n                                                        y_: fileCreation.dense_to_one_hot(test_labels,\n                                                                                          cons.LABELS_NUMB),\n                                                        keep_prob: 0.1}))\n\nI'm freeze this model with and i point output_node to 'final'\nnext i call script from tutorial\npython -m scripts.label_image \\\n  --graph=tf_files/frozen_model3.pb  \\\n  --input_layer=x \\\n  --output_layer=final \\\n  --image=tf_files/stop.png  \\\n  --input_height=32 \\\n  --input_width=32 \\\n  --input_mean=16  \\\n  --input_std=16", "body": "Hello , I trying create mobile app for object recognition for my own created model. I fallow this tutorial https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2/#2\r\nBut when i even get a testing model from step 3 i get error \r\n\r\n```\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'import/Placeholder' with dtype float\r\n\t [[Node: import/Placeholder = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```\r\n\r\nI'm aware that is wrong node problem, but i trying with other and always i get failure \r\n\r\nMy code for model creation \r\n```\r\n\r\nx = tf.placeholder(tf.float32,\r\n                   shape=[None, cons.IMAGE_SIZE, cons.IMAGE_SIZE, 3], name=\"x\")\r\ny_ = tf.placeholder(tf.float32, shape=[None, cons.LABELS_NUMB], name=\"labels\")\r\n\r\nK = 4\r\nL = 8\r\nM = 12\r\nN = 200\r\n\r\nx_image = tf.reshape(x, [-1, cons.IMAGE_SIZE, cons.IMAGE_SIZE, 3])\r\ntf.summary.image('input', x_image, 3)\r\nprint(\"X image \")\r\nprint(tf.shape(x_image))\r\n\r\n################## first ##############\r\n\r\nW_conv1 = weight_variable([5, 5, 3, 32], \"weight1\")\r\nb_conv1 = bias_variable([32], \"bias1\")\r\n\r\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\r\nh_pool1 = max_pool_2x2(h_conv1)\r\nprint(\"W_conv1 \")\r\nprint(tf.shape(W_conv1))\r\nprint(\"b_conv1 \")\r\nprint(tf.shape(b_conv1))\r\nprint(\"h_conv1 \")\r\nprint(tf.shape(h_conv1))\r\nprint(\"h_pool1 \")\r\nprint(tf.shape(h_pool1))\r\n\r\n################## second ##############\r\n\r\nW_conv2 = weight_variable([5, 5, 32, 64], \"weight2\")\r\nb_conv2 = bias_variable([64], \"bias2\")\r\n\r\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\r\ntf.summary.histogram(\"activations\", h_conv2)\r\n\r\n\r\nh_pool2 = max_pool_2x2(h_conv2)\r\n\r\nprint(\"W_conv2 \")\r\nprint(tf.shape(W_conv2))\r\nprint(\"b_conv2 \")\r\nprint(tf.shape(b_conv2))\r\nprint(\"h_conv2 \")\r\nprint(tf.shape(h_conv2))\r\nprint(\"h_pool2 \")\r\nprint(tf.shape(h_pool2))\r\n\r\n################## fully connected 3 ##############\r\n\r\nW_fc1 = weight_variable([8 * 8 * 64, 1024], \"Weight3\")\r\nb_fc1 = bias_variable([1024], \"bias3\")\r\n\r\nh_pool2_flat = tf.reshape(h_pool2, [-1, 8 * 8 * 64])\r\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\r\n\r\nprint(\"W_fc1 \")\r\nprint(tf.shape(W_fc1))\r\nprint(\"b_fc1 \")\r\nprint(tf.shape(b_fc1))\r\nprint(\"h_pool2_flat \")\r\nprint(tf.shape(h_pool2_flat))\r\nprint(\"h_fc1 \")\r\nprint(tf.shape(h_fc1))\r\n\r\n################ dropout  4 #################\r\n\r\nkeep_prob = tf.placeholder(tf.float32)\r\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\r\n\r\n################## fully connected 5 ##############\r\n\r\nW_fc2 = weight_variable([1024, cons.LABELS_NUMB], \"weight5\")\r\nb_fc2 = bias_variable([cons.LABELS_NUMB], \"bias5\")\r\n\r\nY = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\r\ntf.summary.histogram(\"final\", Y)\r\n\r\n\r\nprint(\"W_fc2 \")\r\nprint(tf.shape(W_fc2))\r\nprint(\"b_fc2 \")\r\nprint(tf.shape(b_fc2))\r\nprint(\"Y \")\r\nprint(tf.shape(Y))\r\n\r\nwith tf.name_scope(\"cross_entropy\"):\r\n    cross_entropy = tf.reduce_mean(\r\n        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Y))\r\n    tf.summary.scalar(\"xent\", cross_entropy)\r\n\r\nwith tf.name_scope(\"train_step\"):\r\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\r\n\r\nwith tf.name_scope(\"Acuracy\"):\r\n    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(y_, 1))\r\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n    tf.summary.scalar(\"accuracy\", accuracy)\r\n\r\nsumm = tf.summary.merge_all()\r\nsaver = tf.train.Saver()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    writer = tf.summary.FileWriter(\"/home/damian/api/mnist_demo/10\")\r\n    writer.add_graph(sess.graph)\r\n    for i in range(1000):\r\n        img, lb = fileCreation.next_batch(100, images32, labels)\r\n        if i % 5 == 0:\r\n            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 1.0})\r\n        writer.add_summary(s, i)\r\n        if i % 100 == 0:\r\n            saver.save(sess, '/home/damian/api/checkpoint/my_test_model', global_step=i)\r\n            train_accuracy = accuracy.eval(feed_dict={\r\n                x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 1.0})\r\n            print('step %d, training accuracy %g' % (i, train_accuracy))\r\n        train_step.run(feed_dict={x: img, y_: fileCreation.dense_to_one_hot(lb, cons.LABELS_NUMB), keep_prob: 0.5})\r\n\r\n    print('test accuracy %g' % accuracy.eval(feed_dict={x: test_images32,\r\n                                                        y_: fileCreation.dense_to_one_hot(test_labels,\r\n                                                                                          cons.LABELS_NUMB),\r\n                                                        keep_prob: 0.1}))\r\n```\r\n\r\n\r\nI'm freeze this model with and i point output_node to 'final'\r\nnext i call script from tutorial\r\n\r\n\r\n```\r\npython -m scripts.label_image \\\r\n  --graph=tf_files/frozen_model3.pb  \\\r\n  --input_layer=x \\\r\n  --output_layer=final \\\r\n  --image=tf_files/stop.png  \\\r\n  --input_height=32 \\\r\n  --input_width=32 \\\r\n  --input_mean=16  \\\r\n  --input_std=16  \r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"}