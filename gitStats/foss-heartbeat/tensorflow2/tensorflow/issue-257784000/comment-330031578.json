{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/330031578", "html_url": "https://github.com/tensorflow/tensorflow/issues/13044#issuecomment-330031578", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13044", "id": 330031578, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDAzMTU3OA==", "user": {"login": "Coderx7", "id": 5382892, "node_id": "MDQ6VXNlcjUzODI4OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5382892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Coderx7", "html_url": "https://github.com/Coderx7", "followers_url": "https://api.github.com/users/Coderx7/followers", "following_url": "https://api.github.com/users/Coderx7/following{/other_user}", "gists_url": "https://api.github.com/users/Coderx7/gists{/gist_id}", "starred_url": "https://api.github.com/users/Coderx7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Coderx7/subscriptions", "organizations_url": "https://api.github.com/users/Coderx7/orgs", "repos_url": "https://api.github.com/users/Coderx7/repos", "events_url": "https://api.github.com/users/Coderx7/events{/privacy}", "received_events_url": "https://api.github.com/users/Coderx7/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-17T09:21:20Z", "updated_at": "2017-09-17T09:21:20Z", "author_association": "NONE", "body_html": "<p>I tried two more scenarios,<br>\nI randomly selected 10K images from the existing 300K images and ran the training again.(re-annotated each image,created new tfrecords and ran the training). still the same error ,<br>\nand I need to add that, there is not a single image with the depth of 4, nor the dimensions reported in this and former error messages exist.<br>\nHere is the error message :</p>\n<pre><code>INFO:tensorflow:global step 2310: loss = 0.5332 (0.459 sec/step)\nINFO:tensorflow:global step 2311: loss = 0.3647 (0.444 sec/step)\nINFO:tensorflow:global step 2312: loss = 0.5550 (0.447 sec/step)\n2017-09-17 12:42:02.975898: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\nINFO:tensorflow:Error reported to Coordinator: &lt;class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'&gt;, Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\n\t [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_7, SparseToDense_4, Shape_9, Merge_1, Shape_1, Merge_2, Shape_4, SparseToDense_1, Shape_10, SparseToDense_2, Shape_6, Cast_1, Shape_3, Cast_2, Shape_8, ExpandDims_5, Shape_2, Reshape_5, Shape, Reshape_6, Shape_5)]]\nINFO:tensorflow:global step 2313: loss = 0.5081 (0.481 sec/step)\nINFO:tensorflow:Finished training! Saving model to disk.\nTraceback (most recent call last):\n  File \"train.py\", line 195, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"train.py\", line 191, in main\n    worker_job_name, is_chief, FLAGS.train_dir)\n  File \"/media/hossein/tmpstore/models-master/object_detection/trainer.py\", line 296, in train\n    saver=saver)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 767, in train\n    sv.stop(threads, close_summary_writer=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/supervisor.py\", line 792, in stop\n    stop_grace_period_secs=self._stop_grace_secs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 686, in reraise\n    raise value\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\n    enqueue_callable()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1235, in _single_operation_run\n    target_list_as_strings, status, None)\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\n\t [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_7, SparseToDense_4, Shape_9, Merge_1, Shape_1, Merge_2, Shape_4, SparseToDense_1, Shape_10, SparseToDense_2, Shape_6, Cast_1, Shape_3, Cast_2, Shape_8, ExpandDims_5, Shape_2, Reshape_5, Shape, Reshape_6, Shape_5)]]\n(tensorflow_vp3) hossein@hossein-pc:/media/hossein/tmpstore/models-master/object_detection$ \n\n</code></pre>\n<p>And by the way this is the config file</p>\n<pre><code># SSD with Mobilenet v1, configured for Oxford-IIIT Pets Dataset.\n# Users should configure the fine_tune_checkpoint field in the train config as\n# well as the label_map_path and input_path fields in the train_input_reader and\n# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n# should be configured.\n\nmodel {\n  ssd {\n    num_classes: 2\n    box_coder {\n      faster_rcnn_box_coder {\n        y_scale: 10.0\n        x_scale: 10.0\n        height_scale: 5.0\n        width_scale: 5.0\n      }\n    }\n    matcher {\n      argmax_matcher {\n        matched_threshold: 0.5\n        unmatched_threshold: 0.5\n        ignore_thresholds: false\n        negatives_lower_than_unmatched: true\n        force_match_for_each_row: true\n      }\n    }\n    similarity_calculator {\n      iou_similarity {\n      }\n    }\n    anchor_generator {\n      ssd_anchor_generator {\n        num_layers: 6\n        min_scale: 0.2\n        max_scale: 0.95\n        aspect_ratios: 1.0\n        aspect_ratios: 2.0\n        aspect_ratios: 0.5\n        aspect_ratios: 3.0\n        aspect_ratios: 0.3333\n      }\n    }\n    image_resizer {\n      fixed_shape_resizer {\n        height: 300\n        width: 300\n      }\n    }\n    box_predictor {\n      convolutional_box_predictor {\n        min_depth: 0\n        max_depth: 0\n        num_layers_before_predictor: 0\n        use_dropout: false\n        dropout_keep_probability: 0.8\n        kernel_size: 1\n        box_code_size: 4\n        apply_sigmoid_to_scores: false\n        conv_hyperparams {\n          activation: RELU_6,\n          regularizer {\n            l2_regularizer {\n              weight: 0.00004\n            }\n          }\n          initializer {\n            truncated_normal_initializer {\n              stddev: 0.03\n              mean: 0.0\n            }\n          }\n          batch_norm {\n            train: true,\n            scale: true,\n            center: true,\n            decay: 0.9997,\n            epsilon: 0.001,\n          }\n        }\n      }\n    }\n    feature_extractor {\n      type: 'ssd_mobilenet_v1'\n      min_depth: 16\n      depth_multiplier: 1.0\n      conv_hyperparams {\n        activation: RELU_6,\n        regularizer {\n          l2_regularizer {\n            weight: 0.00004\n          }\n        }\n        initializer {\n          truncated_normal_initializer {\n            stddev: 0.03\n            mean: 0.0\n          }\n        }\n        batch_norm {\n          train: true,\n          scale: true,\n          center: true,\n          decay: 0.9997,\n          epsilon: 0.001,\n        }\n      }\n    }\n    loss {\n      classification_loss {\n        weighted_sigmoid {\n          anchorwise_output: true\n        }\n      }\n      localization_loss {\n        weighted_smooth_l1 {\n          anchorwise_output: true\n        }\n      }\n      hard_example_miner {\n        num_hard_examples: 3000\n        iou_threshold: 0.99\n        loss_type: CLASSIFICATION\n        max_negatives_per_positive: 3\n        min_negatives_per_image: 0\n      }\n      classification_weight: 1.0\n      localization_weight: 1.0\n    }\n    normalize_loss_by_num_matches: true\n    post_processing {\n      batch_non_max_suppression {\n        score_threshold: 1e-8\n        iou_threshold: 0.6\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SIGMOID\n    }\n  }\n}\n\ntrain_config: {\n  batch_size: 24\n  optimizer {\n    rms_prop_optimizer: {\n      learning_rate: {\n        exponential_decay_learning_rate {\n          initial_learning_rate: 0.004\n          decay_steps: 800720\n          decay_factor: 0.95\n        }\n      }\n      momentum_optimizer_value: 0.9\n      decay: 0.9\n      epsilon: 1.0\n    }\n  }\n  fine_tune_checkpoint: \"ssd_mobilenet_v1_coco_11_06_2017/model.ckpt\"\n  from_detection_checkpoint: true\n  # Note: The below line limits the training process to 200K steps, which we\n  # empirically found to be sufficient enough to train the pets dataset. This\n  # effectively bypasses the learning rate schedule (the learning rate will\n  # never decay). Remove the below line to train indefinitely.\n  num_steps: 200000\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n  data_augmentation_options {\n    ssd_random_crop {\n    }\n  }\n}\n\ntrain_input_reader: {\n  tf_record_input_reader {\n    input_path: \"train.record\"\n  }\n  label_map_path: \"obj_detection_label_map.pbtxt\"\n}\n\neval_config: {\n  num_examples: 101\n  # Note: The below line limits the evaluation process to 10 evaluations.\n  # Remove the below line to evaluate indefinitely.\n  max_evals: 10\n}\n\neval_input_reader: {\n  tf_record_input_reader {\n    input_path: \"test.record\"\n  }\n  label_map_path: \"obj_detection_label_map.pbtxt\"\n  shuffle: false\n  num_readers: 1\n}\n</code></pre>\n<p>Any idea how I myself can dig and find the culprit to this? I'd be greatful if anyone could suggest even a slight thing to do. I'm out of options here!</p>", "body_text": "I tried two more scenarios,\nI randomly selected 10K images from the existing 300K images and ran the training again.(re-annotated each image,created new tfrecords and ran the training). still the same error ,\nand I need to add that, there is not a single image with the depth of 4, nor the dimensions reported in this and former error messages exist.\nHere is the error message :\nINFO:tensorflow:global step 2310: loss = 0.5332 (0.459 sec/step)\nINFO:tensorflow:global step 2311: loss = 0.3647 (0.444 sec/step)\nINFO:tensorflow:global step 2312: loss = 0.5550 (0.447 sec/step)\n2017-09-17 12:42:02.975898: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\n\t [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_7, SparseToDense_4, Shape_9, Merge_1, Shape_1, Merge_2, Shape_4, SparseToDense_1, Shape_10, SparseToDense_2, Shape_6, Cast_1, Shape_3, Cast_2, Shape_8, ExpandDims_5, Shape_2, Reshape_5, Shape, Reshape_6, Shape_5)]]\nINFO:tensorflow:global step 2313: loss = 0.5081 (0.481 sec/step)\nINFO:tensorflow:Finished training! Saving model to disk.\nTraceback (most recent call last):\n  File \"train.py\", line 195, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"train.py\", line 191, in main\n    worker_job_name, is_chief, FLAGS.train_dir)\n  File \"/media/hossein/tmpstore/models-master/object_detection/trainer.py\", line 296, in train\n    saver=saver)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 767, in train\n    sv.stop(threads, close_summary_writer=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/supervisor.py\", line 792, in stop\n    stop_grace_period_secs=self._stop_grace_secs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 686, in reraise\n    raise value\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\n    enqueue_callable()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1235, in _single_operation_run\n    target_list_as_strings, status, None)\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\n\t [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_7, SparseToDense_4, Shape_9, Merge_1, Shape_1, Merge_2, Shape_4, SparseToDense_1, Shape_10, SparseToDense_2, Shape_6, Cast_1, Shape_3, Cast_2, Shape_8, ExpandDims_5, Shape_2, Reshape_5, Shape, Reshape_6, Shape_5)]]\n(tensorflow_vp3) hossein@hossein-pc:/media/hossein/tmpstore/models-master/object_detection$ \n\n\nAnd by the way this is the config file\n# SSD with Mobilenet v1, configured for Oxford-IIIT Pets Dataset.\n# Users should configure the fine_tune_checkpoint field in the train config as\n# well as the label_map_path and input_path fields in the train_input_reader and\n# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n# should be configured.\n\nmodel {\n  ssd {\n    num_classes: 2\n    box_coder {\n      faster_rcnn_box_coder {\n        y_scale: 10.0\n        x_scale: 10.0\n        height_scale: 5.0\n        width_scale: 5.0\n      }\n    }\n    matcher {\n      argmax_matcher {\n        matched_threshold: 0.5\n        unmatched_threshold: 0.5\n        ignore_thresholds: false\n        negatives_lower_than_unmatched: true\n        force_match_for_each_row: true\n      }\n    }\n    similarity_calculator {\n      iou_similarity {\n      }\n    }\n    anchor_generator {\n      ssd_anchor_generator {\n        num_layers: 6\n        min_scale: 0.2\n        max_scale: 0.95\n        aspect_ratios: 1.0\n        aspect_ratios: 2.0\n        aspect_ratios: 0.5\n        aspect_ratios: 3.0\n        aspect_ratios: 0.3333\n      }\n    }\n    image_resizer {\n      fixed_shape_resizer {\n        height: 300\n        width: 300\n      }\n    }\n    box_predictor {\n      convolutional_box_predictor {\n        min_depth: 0\n        max_depth: 0\n        num_layers_before_predictor: 0\n        use_dropout: false\n        dropout_keep_probability: 0.8\n        kernel_size: 1\n        box_code_size: 4\n        apply_sigmoid_to_scores: false\n        conv_hyperparams {\n          activation: RELU_6,\n          regularizer {\n            l2_regularizer {\n              weight: 0.00004\n            }\n          }\n          initializer {\n            truncated_normal_initializer {\n              stddev: 0.03\n              mean: 0.0\n            }\n          }\n          batch_norm {\n            train: true,\n            scale: true,\n            center: true,\n            decay: 0.9997,\n            epsilon: 0.001,\n          }\n        }\n      }\n    }\n    feature_extractor {\n      type: 'ssd_mobilenet_v1'\n      min_depth: 16\n      depth_multiplier: 1.0\n      conv_hyperparams {\n        activation: RELU_6,\n        regularizer {\n          l2_regularizer {\n            weight: 0.00004\n          }\n        }\n        initializer {\n          truncated_normal_initializer {\n            stddev: 0.03\n            mean: 0.0\n          }\n        }\n        batch_norm {\n          train: true,\n          scale: true,\n          center: true,\n          decay: 0.9997,\n          epsilon: 0.001,\n        }\n      }\n    }\n    loss {\n      classification_loss {\n        weighted_sigmoid {\n          anchorwise_output: true\n        }\n      }\n      localization_loss {\n        weighted_smooth_l1 {\n          anchorwise_output: true\n        }\n      }\n      hard_example_miner {\n        num_hard_examples: 3000\n        iou_threshold: 0.99\n        loss_type: CLASSIFICATION\n        max_negatives_per_positive: 3\n        min_negatives_per_image: 0\n      }\n      classification_weight: 1.0\n      localization_weight: 1.0\n    }\n    normalize_loss_by_num_matches: true\n    post_processing {\n      batch_non_max_suppression {\n        score_threshold: 1e-8\n        iou_threshold: 0.6\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SIGMOID\n    }\n  }\n}\n\ntrain_config: {\n  batch_size: 24\n  optimizer {\n    rms_prop_optimizer: {\n      learning_rate: {\n        exponential_decay_learning_rate {\n          initial_learning_rate: 0.004\n          decay_steps: 800720\n          decay_factor: 0.95\n        }\n      }\n      momentum_optimizer_value: 0.9\n      decay: 0.9\n      epsilon: 1.0\n    }\n  }\n  fine_tune_checkpoint: \"ssd_mobilenet_v1_coco_11_06_2017/model.ckpt\"\n  from_detection_checkpoint: true\n  # Note: The below line limits the training process to 200K steps, which we\n  # empirically found to be sufficient enough to train the pets dataset. This\n  # effectively bypasses the learning rate schedule (the learning rate will\n  # never decay). Remove the below line to train indefinitely.\n  num_steps: 200000\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n  data_augmentation_options {\n    ssd_random_crop {\n    }\n  }\n}\n\ntrain_input_reader: {\n  tf_record_input_reader {\n    input_path: \"train.record\"\n  }\n  label_map_path: \"obj_detection_label_map.pbtxt\"\n}\n\neval_config: {\n  num_examples: 101\n  # Note: The below line limits the evaluation process to 10 evaluations.\n  # Remove the below line to evaluate indefinitely.\n  max_evals: 10\n}\n\neval_input_reader: {\n  tf_record_input_reader {\n    input_path: \"test.record\"\n  }\n  label_map_path: \"obj_detection_label_map.pbtxt\"\n  shuffle: false\n  num_readers: 1\n}\n\nAny idea how I myself can dig and find the culprit to this? I'd be greatful if anyone could suggest even a slight thing to do. I'm out of options here!", "body": "I tried two more scenarios,\r\nI randomly selected 10K images from the existing 300K images and ran the training again.(re-annotated each image,created new tfrecords and ran the training). still the same error ,\r\nand I need to add that, there is not a single image with the depth of 4, nor the dimensions reported in this and former error messages exist. \r\nHere is the error message : \r\n```\r\nINFO:tensorflow:global step 2310: loss = 0.5332 (0.459 sec/step)\r\nINFO:tensorflow:global step 2311: loss = 0.3647 (0.444 sec/step)\r\nINFO:tensorflow:global step 2312: loss = 0.5550 (0.447 sec/step)\r\n2017-09-17 12:42:02.975898: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\r\n\t [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_7, SparseToDense_4, Shape_9, Merge_1, Shape_1, Merge_2, Shape_4, SparseToDense_1, Shape_10, SparseToDense_2, Shape_6, Cast_1, Shape_3, Cast_2, Shape_8, ExpandDims_5, Shape_2, Reshape_5, Shape, Reshape_6, Shape_5)]]\r\nINFO:tensorflow:global step 2313: loss = 0.5081 (0.481 sec/step)\r\nINFO:tensorflow:Finished training! Saving model to disk.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 195, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"train.py\", line 191, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/media/hossein/tmpstore/models-master/object_detection/trainer.py\", line 296, in train\r\n    saver=saver)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 767, in train\r\n    sv.stop(threads, close_summary_writer=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/supervisor.py\", line 792, in stop\r\n    stop_grace_period_secs=self._stop_grace_secs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 686, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\r\n    enqueue_callable()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1235, in _single_operation_run\r\n    target_list_as_strings, status, None)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\r\n\t [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_7, SparseToDense_4, Shape_9, Merge_1, Shape_1, Merge_2, Shape_4, SparseToDense_1, Shape_10, SparseToDense_2, Shape_6, Cast_1, Shape_3, Cast_2, Shape_8, ExpandDims_5, Shape_2, Reshape_5, Shape, Reshape_6, Shape_5)]]\r\n(tensorflow_vp3) hossein@hossein-pc:/media/hossein/tmpstore/models-master/object_detection$ \r\n\r\n```\r\nAnd by the way this is the config file\r\n```\r\n# SSD with Mobilenet v1, configured for Oxford-IIIT Pets Dataset.\r\n# Users should configure the fine_tune_checkpoint field in the train config as\r\n# well as the label_map_path and input_path fields in the train_input_reader and\r\n# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n# should be configured.\r\n\r\nmodel {\r\n  ssd {\r\n    num_classes: 2\r\n    box_coder {\r\n      faster_rcnn_box_coder {\r\n        y_scale: 10.0\r\n        x_scale: 10.0\r\n        height_scale: 5.0\r\n        width_scale: 5.0\r\n      }\r\n    }\r\n    matcher {\r\n      argmax_matcher {\r\n        matched_threshold: 0.5\r\n        unmatched_threshold: 0.5\r\n        ignore_thresholds: false\r\n        negatives_lower_than_unmatched: true\r\n        force_match_for_each_row: true\r\n      }\r\n    }\r\n    similarity_calculator {\r\n      iou_similarity {\r\n      }\r\n    }\r\n    anchor_generator {\r\n      ssd_anchor_generator {\r\n        num_layers: 6\r\n        min_scale: 0.2\r\n        max_scale: 0.95\r\n        aspect_ratios: 1.0\r\n        aspect_ratios: 2.0\r\n        aspect_ratios: 0.5\r\n        aspect_ratios: 3.0\r\n        aspect_ratios: 0.3333\r\n      }\r\n    }\r\n    image_resizer {\r\n      fixed_shape_resizer {\r\n        height: 300\r\n        width: 300\r\n      }\r\n    }\r\n    box_predictor {\r\n      convolutional_box_predictor {\r\n        min_depth: 0\r\n        max_depth: 0\r\n        num_layers_before_predictor: 0\r\n        use_dropout: false\r\n        dropout_keep_probability: 0.8\r\n        kernel_size: 1\r\n        box_code_size: 4\r\n        apply_sigmoid_to_scores: false\r\n        conv_hyperparams {\r\n          activation: RELU_6,\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.00004\r\n            }\r\n          }\r\n          initializer {\r\n            truncated_normal_initializer {\r\n              stddev: 0.03\r\n              mean: 0.0\r\n            }\r\n          }\r\n          batch_norm {\r\n            train: true,\r\n            scale: true,\r\n            center: true,\r\n            decay: 0.9997,\r\n            epsilon: 0.001,\r\n          }\r\n        }\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'ssd_mobilenet_v1'\r\n      min_depth: 16\r\n      depth_multiplier: 1.0\r\n      conv_hyperparams {\r\n        activation: RELU_6,\r\n        regularizer {\r\n          l2_regularizer {\r\n            weight: 0.00004\r\n          }\r\n        }\r\n        initializer {\r\n          truncated_normal_initializer {\r\n            stddev: 0.03\r\n            mean: 0.0\r\n          }\r\n        }\r\n        batch_norm {\r\n          train: true,\r\n          scale: true,\r\n          center: true,\r\n          decay: 0.9997,\r\n          epsilon: 0.001,\r\n        }\r\n      }\r\n    }\r\n    loss {\r\n      classification_loss {\r\n        weighted_sigmoid {\r\n          anchorwise_output: true\r\n        }\r\n      }\r\n      localization_loss {\r\n        weighted_smooth_l1 {\r\n          anchorwise_output: true\r\n        }\r\n      }\r\n      hard_example_miner {\r\n        num_hard_examples: 3000\r\n        iou_threshold: 0.99\r\n        loss_type: CLASSIFICATION\r\n        max_negatives_per_positive: 3\r\n        min_negatives_per_image: 0\r\n      }\r\n      classification_weight: 1.0\r\n      localization_weight: 1.0\r\n    }\r\n    normalize_loss_by_num_matches: true\r\n    post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 1e-8\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SIGMOID\r\n    }\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 24\r\n  optimizer {\r\n    rms_prop_optimizer: {\r\n      learning_rate: {\r\n        exponential_decay_learning_rate {\r\n          initial_learning_rate: 0.004\r\n          decay_steps: 800720\r\n          decay_factor: 0.95\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n      decay: 0.9\r\n      epsilon: 1.0\r\n    }\r\n  }\r\n  fine_tune_checkpoint: \"ssd_mobilenet_v1_coco_11_06_2017/model.ckpt\"\r\n  from_detection_checkpoint: true\r\n  # Note: The below line limits the training process to 200K steps, which we\r\n  # empirically found to be sufficient enough to train the pets dataset. This\r\n  # effectively bypasses the learning rate schedule (the learning rate will\r\n  # never decay). Remove the below line to train indefinitely.\r\n  num_steps: 200000\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    ssd_random_crop {\r\n    }\r\n  }\r\n}\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"train.record\"\r\n  }\r\n  label_map_path: \"obj_detection_label_map.pbtxt\"\r\n}\r\n\r\neval_config: {\r\n  num_examples: 101\r\n  # Note: The below line limits the evaluation process to 10 evaluations.\r\n  # Remove the below line to evaluate indefinitely.\r\n  max_evals: 10\r\n}\r\n\r\neval_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"test.record\"\r\n  }\r\n  label_map_path: \"obj_detection_label_map.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n}\r\n```\r\nAny idea how I myself can dig and find the culprit to this? I'd be greatful if anyone could suggest even a slight thing to do. I'm out of options here!"}