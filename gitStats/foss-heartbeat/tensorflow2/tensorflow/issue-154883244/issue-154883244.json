{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2367", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2367/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2367/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2367/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2367", "id": 154883244, "node_id": "MDU6SXNzdWUxNTQ4ODMyNDQ=", "number": 2367, "title": "Incorrect gradients for scatter_add", "user": {"login": "altaetran", "id": 6753285, "node_id": "MDQ6VXNlcjY3NTMyODU=", "avatar_url": "https://avatars1.githubusercontent.com/u/6753285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/altaetran", "html_url": "https://github.com/altaetran", "followers_url": "https://api.github.com/users/altaetran/followers", "following_url": "https://api.github.com/users/altaetran/following{/other_user}", "gists_url": "https://api.github.com/users/altaetran/gists{/gist_id}", "starred_url": "https://api.github.com/users/altaetran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/altaetran/subscriptions", "organizations_url": "https://api.github.com/users/altaetran/orgs", "repos_url": "https://api.github.com/users/altaetran/repos", "events_url": "https://api.github.com/users/altaetran/events{/privacy}", "received_events_url": "https://api.github.com/users/altaetran/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-05-15T00:42:11Z", "updated_at": "2016-05-16T15:38:33Z", "closed_at": "2016-05-16T15:38:33Z", "author_association": "NONE", "body_html": "<p>Hi Tensorflow Development Team,</p>\n<p>Thank you so much for being so patient with me. I am currently working with scatter_add, and have encountered a None gradient where I believe there should be gradients.</p>\n<h3>Environment info</h3>\n<p>Operating System: CentOS</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):<br>\nCUDA version 7.5<br>\ncuDNN version 7.0 (64 bit)<br>\ntensorflow/0.8.0-gpu version</p>\n<h3>Steps to reproduce</h3>\n<p><code>N_rows = 10</code><br>\n<code>N_cols = 3</code></p>\n<p><code>X_ph = tf.placeholder(tf.float32, shape=(None, N_cols))</code><br>\n<code>ind_ph = tf.placeholder(tf.int32, shape=(None))</code></p>\n<p><code>Z = tf.Variable(tf.zeros([N_rows, N_cols]))</code><br>\n<code>Z = Z.assign(tf.zeros([N_rows, N_cols]))</code><br>\n<code>Z_add = tf.scatter_add(Z, ind_ph, X_ph)</code><br>\n<code>Z_sum = tf.reduce_sum(Z_add)</code></p>\n<p><code>grad_op = tf.gradients(Z_sum, X_ph)</code></p>\n<p><code>X = np.array([[1,0,1],[2,2,1]])</code></p>\n<p><code>ind = [0, 1]</code></p>\n<h3>What have you tried?</h3>\n<p>If you try to differentiate Z_sum with respect to Z_add, you get a nonzero gradient, as expected. However, It seems that if you differentiate Z_sum with respect to Z or X_ph, you get a None, indicating no connection between Z_sum and X_ph or Z. I would definitely expect there to be a connection between Z_add and X_ph/Z. Do you think you could take a look at this and tell me how I might be able to circumvent this issue? Thank you so much for your help!</p>\n<p>Best,<br>\nHan</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).</p>\n<p>The output given by tensorflow when evaluating grad_op is<br>\nFile \"scatter_update_grad_test.py\", line 34, in <br>\nout = sess.run(grad_op, feed_dict={X_ph : X, ind_ph : ind})<br>\nFile \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 340, in run<br>\nrun_metadata_ptr)<br>\nFile \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 523, in _run<br>\nprocessed_fetches = self._process_fetches(fetches)<br>\nFile \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 493, in _process_fetches<br>\n% (subfetch, fetch, type(subfetch), str(e)))<br>\nTypeError: Fetch argument None of None has invalid type &lt;type 'NoneType'&gt;, must be a string or Tensor. (Can not convert a NoneType into a Tensor or Operation.)</p>\n<p>If I take grad_op = tf.gradients(Z_sum, Z_add), I obtain<br>\narray([[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.],<br>\n[ 1.,  1.,  1.]], dtype=float32)]</p>\n<p>as expected since we are using reduce sum.</p>", "body_text": "Hi Tensorflow Development Team,\nThank you so much for being so patient with me. I am currently working with scatter_add, and have encountered a None gradient where I believe there should be gradients.\nEnvironment info\nOperating System: CentOS\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nCUDA version 7.5\ncuDNN version 7.0 (64 bit)\ntensorflow/0.8.0-gpu version\nSteps to reproduce\nN_rows = 10\nN_cols = 3\nX_ph = tf.placeholder(tf.float32, shape=(None, N_cols))\nind_ph = tf.placeholder(tf.int32, shape=(None))\nZ = tf.Variable(tf.zeros([N_rows, N_cols]))\nZ = Z.assign(tf.zeros([N_rows, N_cols]))\nZ_add = tf.scatter_add(Z, ind_ph, X_ph)\nZ_sum = tf.reduce_sum(Z_add)\ngrad_op = tf.gradients(Z_sum, X_ph)\nX = np.array([[1,0,1],[2,2,1]])\nind = [0, 1]\nWhat have you tried?\nIf you try to differentiate Z_sum with respect to Z_add, you get a nonzero gradient, as expected. However, It seems that if you differentiate Z_sum with respect to Z or X_ph, you get a None, indicating no connection between Z_sum and X_ph or Z. I would definitely expect there to be a connection between Z_add and X_ph/Z. Do you think you could take a look at this and tell me how I might be able to circumvent this issue? Thank you so much for your help!\nBest,\nHan\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).\nThe output given by tensorflow when evaluating grad_op is\nFile \"scatter_update_grad_test.py\", line 34, in \nout = sess.run(grad_op, feed_dict={X_ph : X, ind_ph : ind})\nFile \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 340, in run\nrun_metadata_ptr)\nFile \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 523, in _run\nprocessed_fetches = self._process_fetches(fetches)\nFile \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 493, in _process_fetches\n% (subfetch, fetch, type(subfetch), str(e)))\nTypeError: Fetch argument None of None has invalid type <type 'NoneType'>, must be a string or Tensor. (Can not convert a NoneType into a Tensor or Operation.)\nIf I take grad_op = tf.gradients(Z_sum, Z_add), I obtain\narray([[ 1.,  1.,  1.],\n[ 1.,  1.,  1.],\n[ 1.,  1.,  1.],\n[ 1.,  1.,  1.],\n[ 1.,  1.,  1.],\n[ 1.,  1.,  1.],\n[ 1.,  1.,  1.],\n[ 1.,  1.,  1.],\n[ 1.,  1.,  1.],\n[ 1.,  1.,  1.]], dtype=float32)]\nas expected since we are using reduce sum.", "body": "Hi Tensorflow Development Team,\n\nThank you so much for being so patient with me. I am currently working with scatter_add, and have encountered a None gradient where I believe there should be gradients.\n### Environment info\n\nOperating System: CentOS\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nCUDA version 7.5\ncuDNN version 7.0 (64 bit)\ntensorflow/0.8.0-gpu version\n### Steps to reproduce\n\n`N_rows = 10`\n`N_cols = 3`\n\n`X_ph = tf.placeholder(tf.float32, shape=(None, N_cols))`\n`ind_ph = tf.placeholder(tf.int32, shape=(None))`\n\n`Z = tf.Variable(tf.zeros([N_rows, N_cols]))`\n`Z = Z.assign(tf.zeros([N_rows, N_cols]))`\n`Z_add = tf.scatter_add(Z, ind_ph, X_ph)`\n`Z_sum = tf.reduce_sum(Z_add)`\n\n`grad_op = tf.gradients(Z_sum, X_ph)`\n\n`X = np.array([[1,0,1],[2,2,1]])`\n\n`ind = [0, 1]`\n### What have you tried?\n\nIf you try to differentiate Z_sum with respect to Z_add, you get a nonzero gradient, as expected. However, It seems that if you differentiate Z_sum with respect to Z or X_ph, you get a None, indicating no connection between Z_sum and X_ph or Z. I would definitely expect there to be a connection between Z_add and X_ph/Z. Do you think you could take a look at this and tell me how I might be able to circumvent this issue? Thank you so much for your help!\n\nBest,\nHan\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nThe output given by tensorflow when evaluating grad_op is\n  File \"scatter_update_grad_test.py\", line 34, in <module>\n    out = sess.run(grad_op, feed_dict={X_ph : X, ind_ph : ind})\n  File \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 523, in _run\n    processed_fetches = self._process_fetches(fetches)\n  File \"/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py\", line 493, in _process_fetches\n    % (subfetch, fetch, type(subfetch), str(e)))\nTypeError: Fetch argument None of None has invalid type <type 'NoneType'>, must be a string or Tensor. (Can not convert a NoneType into a Tensor or Operation.)\n\nIf I take grad_op = tf.gradients(Z_sum, Z_add), I obtain\narray([[ 1.,  1.,  1.],\n       [ 1.,  1.,  1.],\n       [ 1.,  1.,  1.],\n       [ 1.,  1.,  1.],\n       [ 1.,  1.,  1.],\n       [ 1.,  1.,  1.],\n       [ 1.,  1.,  1.],\n       [ 1.,  1.,  1.],\n       [ 1.,  1.,  1.],\n       [ 1.,  1.,  1.]], dtype=float32)]\n\nas expected since we are using reduce sum.\n"}