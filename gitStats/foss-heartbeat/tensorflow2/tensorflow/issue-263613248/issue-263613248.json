{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13546", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13546/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13546/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13546/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13546", "id": 263613248, "node_id": "MDU6SXNzdWUyNjM2MTMyNDg=", "number": 13546, "title": "Feature request: RMSProp without momentum variables", "user": {"login": "netheril96", "id": 836839, "node_id": "MDQ6VXNlcjgzNjgzOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/836839?v=4", "gravatar_id": "", "url": "https://api.github.com/users/netheril96", "html_url": "https://github.com/netheril96", "followers_url": "https://api.github.com/users/netheril96/followers", "following_url": "https://api.github.com/users/netheril96/following{/other_user}", "gists_url": "https://api.github.com/users/netheril96/gists{/gist_id}", "starred_url": "https://api.github.com/users/netheril96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/netheril96/subscriptions", "organizations_url": "https://api.github.com/users/netheril96/orgs", "repos_url": "https://api.github.com/users/netheril96/repos", "events_url": "https://api.github.com/users/netheril96/events{/privacy}", "received_events_url": "https://api.github.com/users/netheril96/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-10-07T03:28:28Z", "updated_at": "2017-12-20T19:34:20Z", "closed_at": "2017-12-20T19:34:20Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: macOS High Sierra</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.3.0-24-g658866597 1.3.0</li>\n<li><strong>Python version</strong>: 3.6.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.6.1</li>\n<li><strong>CUDA/cuDNN version</strong>: None</li>\n<li><strong>GPU model and memory</strong>: None</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The current <code>RMSPropOptimizer</code> always allocates momentum variables, even though the default (and probably 99% of people) never make use of it. In fact, if one wishes to combine momentum and adaptive gradient descent, he/she will most likely instantiate an <code>AdamOptimizer</code> instead. The extra variables waste precious GPU/CPU memory as well as disk space (when saved as checkpoints) while providing minimal utility.</p>\n<p>Suggestion: introduce a new version of <code>ApplyRMSProp</code> operations that doesn't use momentum variables at all, and dynamically choose which implementation to use in <code>RMSPropOptimizer</code> constructor depending on whether the <code>momentum</code> argument is constant zero.</p>\n<p>Alternative solution: change the current <code>ApplyRMSProp</code> operations so that it doesn't use momentum variables, and direct the minority users who currently need momentum with RMSProp to Adam instead.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS High Sierra\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): v1.3.0-24-g658866597 1.3.0\nPython version: 3.6.3\nBazel version (if compiling from source): 0.6.1\nCUDA/cuDNN version: None\nGPU model and memory: None\nExact command to reproduce:\n\nDescribe the problem\nThe current RMSPropOptimizer always allocates momentum variables, even though the default (and probably 99% of people) never make use of it. In fact, if one wishes to combine momentum and adaptive gradient descent, he/she will most likely instantiate an AdamOptimizer instead. The extra variables waste precious GPU/CPU memory as well as disk space (when saved as checkpoints) while providing minimal utility.\nSuggestion: introduce a new version of ApplyRMSProp operations that doesn't use momentum variables at all, and dynamically choose which implementation to use in RMSPropOptimizer constructor depending on whether the momentum argument is constant zero.\nAlternative solution: change the current ApplyRMSProp operations so that it doesn't use momentum variables, and direct the minority users who currently need momentum with RMSProp to Adam instead.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: v1.3.0-24-g658866597 1.3.0\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: 0.6.1\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nThe current `RMSPropOptimizer` always allocates momentum variables, even though the default (and probably 99% of people) never make use of it. In fact, if one wishes to combine momentum and adaptive gradient descent, he/she will most likely instantiate an `AdamOptimizer` instead. The extra variables waste precious GPU/CPU memory as well as disk space (when saved as checkpoints) while providing minimal utility. \r\n\r\nSuggestion: introduce a new version of `ApplyRMSProp` operations that doesn't use momentum variables at all, and dynamically choose which implementation to use in `RMSPropOptimizer` constructor depending on whether the `momentum` argument is constant zero.\r\n\r\nAlternative solution: change the current `ApplyRMSProp` operations so that it doesn't use momentum variables, and direct the minority users who currently need momentum with RMSProp to Adam instead.\r\n\r\n"}