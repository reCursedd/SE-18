{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2283", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2283/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2283/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2283/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2283", "id": 153718470, "node_id": "MDU6SXNzdWUxNTM3MTg0NzA=", "number": 2283, "title": "IndexedSlices problem on porting ptb_word_lm.py to multi-GPU-towers", "user": {"login": "smartcat2010", "id": 10429114, "node_id": "MDQ6VXNlcjEwNDI5MTE0", "avatar_url": "https://avatars1.githubusercontent.com/u/10429114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smartcat2010", "html_url": "https://github.com/smartcat2010", "followers_url": "https://api.github.com/users/smartcat2010/followers", "following_url": "https://api.github.com/users/smartcat2010/following{/other_user}", "gists_url": "https://api.github.com/users/smartcat2010/gists{/gist_id}", "starred_url": "https://api.github.com/users/smartcat2010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smartcat2010/subscriptions", "organizations_url": "https://api.github.com/users/smartcat2010/orgs", "repos_url": "https://api.github.com/users/smartcat2010/repos", "events_url": "https://api.github.com/users/smartcat2010/events{/privacy}", "received_events_url": "https://api.github.com/users/smartcat2010/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2016-05-09T07:33:30Z", "updated_at": "2016-10-26T17:07:00Z", "closed_at": "2016-10-26T17:07:00Z", "author_association": "NONE", "body_html": "<p>I try to port RNN model in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py\">ptb_word_lm.py</a> to multi-GPU cards. I follow the multi-tower style in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py\">cifar10_multi_gpu_train.py</a><br>\nHowever, I found the \"grads\" returned by <code>tf.clip_by_global_norm(tf.gradients(cost, tvars), config.max_grad_norm)</code> is not list of Tensor type. It is a list of type <code>tensorflow.python.framework.ops.IndexedSlices</code>.  Now I need to sum &amp; average the lists of \"grads\" returned by multiple GPU towers into one list of IndexedSlices or Tensor, in order to pass it into <code>self._train_op = optimizer.apply_gradients(zip(grads, tvars))</code><br>\nI've tried the <code>tf.convert_to_tensor</code> to conver IndexedSlices to Tensor, but it failed with the following errors:</p>\n<p>File \"ptb_word_lm.py\", line 328, in <br>\ntf.app.run()<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run<br>\nsys.exit(main(sys.argv))<br>\nFile \"ptb_word_lm.py\", line 305, in main<br>\nm = PTBModel(is_training=True, config=config)<br>\nFile \"ptb_word_lm.py\", line 152, in <strong>init</strong><br>\ngrads_0_tensor = tf.convert_to_tensor(grads[0])<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor<br>\nret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 77, in _IndexedSlicesToTensor<br>\n% str(value))<br>\nValueError: Tensor conversion requested for IndexedSlices without dense_shape: IndexedSlices(indices=Tensor(\"model/gradients/concat_1:0\", shape=(400,), dtype=int32), values=Tensor(\"model/clip_by_global_norm/model/clip_by_global_norm/_0:0\", shape=(?, 200), dtype=float32))</p>\n<p>Is it a bug?<br>\nHow could I reduce_mean these IndexedSlices(reduce_mean seems only accept \"Tensor\" as input)? Or is there any existing code that parallelize RNN in multi-GPU-towers style?</p>\n<p>Thanks a lot in advance!</p>", "body_text": "I try to port RNN model in ptb_word_lm.py to multi-GPU cards. I follow the multi-tower style in cifar10_multi_gpu_train.py\nHowever, I found the \"grads\" returned by tf.clip_by_global_norm(tf.gradients(cost, tvars), config.max_grad_norm) is not list of Tensor type. It is a list of type tensorflow.python.framework.ops.IndexedSlices.  Now I need to sum & average the lists of \"grads\" returned by multiple GPU towers into one list of IndexedSlices or Tensor, in order to pass it into self._train_op = optimizer.apply_gradients(zip(grads, tvars))\nI've tried the tf.convert_to_tensor to conver IndexedSlices to Tensor, but it failed with the following errors:\nFile \"ptb_word_lm.py\", line 328, in \ntf.app.run()\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\nsys.exit(main(sys.argv))\nFile \"ptb_word_lm.py\", line 305, in main\nm = PTBModel(is_training=True, config=config)\nFile \"ptb_word_lm.py\", line 152, in init\ngrads_0_tensor = tf.convert_to_tensor(grads[0])\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\nret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 77, in _IndexedSlicesToTensor\n% str(value))\nValueError: Tensor conversion requested for IndexedSlices without dense_shape: IndexedSlices(indices=Tensor(\"model/gradients/concat_1:0\", shape=(400,), dtype=int32), values=Tensor(\"model/clip_by_global_norm/model/clip_by_global_norm/_0:0\", shape=(?, 200), dtype=float32))\nIs it a bug?\nHow could I reduce_mean these IndexedSlices(reduce_mean seems only accept \"Tensor\" as input)? Or is there any existing code that parallelize RNN in multi-GPU-towers style?\nThanks a lot in advance!", "body": "I try to port RNN model in [ptb_word_lm.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py) to multi-GPU cards. I follow the multi-tower style in [cifar10_multi_gpu_train.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py) \nHowever, I found the \"grads\" returned by `tf.clip_by_global_norm(tf.gradients(cost, tvars), config.max_grad_norm)` is not list of Tensor type. It is a list of type `tensorflow.python.framework.ops.IndexedSlices`.  Now I need to sum & average the lists of \"grads\" returned by multiple GPU towers into one list of IndexedSlices or Tensor, in order to pass it into `self._train_op = optimizer.apply_gradients(zip(grads, tvars))`\n I've tried the `tf.convert_to_tensor` to conver IndexedSlices to Tensor, but it failed with the following errors:\n\n  File \"ptb_word_lm.py\", line 328, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"ptb_word_lm.py\", line 305, in main\n    m = PTBModel(is_training=True, config=config)\n  File \"ptb_word_lm.py\", line 152, in __init__\n    grads_0_tensor = tf.convert_to_tensor(grads[0])\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 77, in _IndexedSlicesToTensor\n    % str(value))\nValueError: Tensor conversion requested for IndexedSlices without dense_shape: IndexedSlices(indices=Tensor(\"model/gradients/concat_1:0\", shape=(400,), dtype=int32), values=Tensor(\"model/clip_by_global_norm/model/clip_by_global_norm/_0:0\", shape=(?, 200), dtype=float32))\n\nIs it a bug?\nHow could I reduce_mean these IndexedSlices(reduce_mean seems only accept \"Tensor\" as input)? Or is there any existing code that parallelize RNN in multi-GPU-towers style?\n\nThanks a lot in advance!\n"}