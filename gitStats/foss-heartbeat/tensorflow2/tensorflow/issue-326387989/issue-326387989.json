{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19551", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19551/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19551/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19551/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19551", "id": 326387989, "node_id": "MDU6SXNzdWUzMjYzODc5ODk=", "number": 19551, "title": "Cannot use AdagradOptimizer with MirroredStrategy", "user": {"login": "ed-alertedh", "id": 24605895, "node_id": "MDQ6VXNlcjI0NjA1ODk1", "avatar_url": "https://avatars1.githubusercontent.com/u/24605895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ed-alertedh", "html_url": "https://github.com/ed-alertedh", "followers_url": "https://api.github.com/users/ed-alertedh/followers", "following_url": "https://api.github.com/users/ed-alertedh/following{/other_user}", "gists_url": "https://api.github.com/users/ed-alertedh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ed-alertedh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ed-alertedh/subscriptions", "organizations_url": "https://api.github.com/users/ed-alertedh/orgs", "repos_url": "https://api.github.com/users/ed-alertedh/repos", "events_url": "https://api.github.com/users/ed-alertedh/events{/privacy}", "received_events_url": "https://api.github.com/users/ed-alertedh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 996845227, "node_id": "MDU6TGFiZWw5OTY4NDUyMjc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:dist-strat", "name": "comp:dist-strat", "color": "0052cc", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "anj-s", "id": 32556631, "node_id": "MDQ6VXNlcjMyNTU2NjMx", "avatar_url": "https://avatars1.githubusercontent.com/u/32556631?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anj-s", "html_url": "https://github.com/anj-s", "followers_url": "https://api.github.com/users/anj-s/followers", "following_url": "https://api.github.com/users/anj-s/following{/other_user}", "gists_url": "https://api.github.com/users/anj-s/gists{/gist_id}", "starred_url": "https://api.github.com/users/anj-s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anj-s/subscriptions", "organizations_url": "https://api.github.com/users/anj-s/orgs", "repos_url": "https://api.github.com/users/anj-s/repos", "events_url": "https://api.github.com/users/anj-s/events{/privacy}", "received_events_url": "https://api.github.com/users/anj-s/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "anj-s", "id": 32556631, "node_id": "MDQ6VXNlcjMyNTU2NjMx", "avatar_url": "https://avatars1.githubusercontent.com/u/32556631?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anj-s", "html_url": "https://github.com/anj-s", "followers_url": "https://api.github.com/users/anj-s/followers", "following_url": "https://api.github.com/users/anj-s/following{/other_user}", "gists_url": "https://api.github.com/users/anj-s/gists{/gist_id}", "starred_url": "https://api.github.com/users/anj-s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anj-s/subscriptions", "organizations_url": "https://api.github.com/users/anj-s/orgs", "repos_url": "https://api.github.com/users/anj-s/repos", "events_url": "https://api.github.com/users/anj-s/events{/privacy}", "received_events_url": "https://api.github.com/users/anj-s/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-25T05:39:45Z", "updated_at": "2018-08-17T19:05:29Z", "closed_at": "2018-08-17T19:05:29Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 18.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.8.0-0-g93bc2e2072 1.8.0</li>\n<li><strong>Python version</strong>: 3.6.3 64-bit</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0 / 6.0</li>\n<li><strong>GPU model and memory</strong>: Nvidia GTX 1080 8 GB</li>\n<li><strong>Exact command to reproduce</strong>: <code>python train_model.py</code></li>\n</ul>\n<h3>Describe the problem</h3>\n<p>It took me a while to work out what was going on, but it seems that  tf.train.AdagradOptimizer has some specific implementation detail that causes an error when used with MirroredStrategy. I did a spot check with GradientDescentOptimizer and RMSPropOptimizer and they both appear to work in my environment. I'm happy to use a different optimizer as a workaround but I thought at the very least this might save others some time hunting down the cause of the error!</p>\n<h3>Source code / logs</h3>\n<p>This is almost exactly copied from the example at <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute\">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute</a> (except for the choice of optimizer)</p>\n<pre><code>import tensorflow as tf\n\ndef model_fn(features, labels, mode):\n    layer = tf.layers.Dense(1)\n    logits = layer(features)\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        predictions = {\"logits\": logits}\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n    loss = tf.losses.mean_squared_error(\n            labels=labels, predictions=tf.reshape(logits, []))\n\n    if mode == tf.estimator.ModeKeys.EVAL:\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_op = tf.train.AdagradOptimizer(0.2).minimize(loss)\n        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\ndef input_fn():\n    features = tf.data.Dataset.from_tensors([[1.]]).repeat(100)\n    labels = tf.data.Dataset.from_tensors(1.).repeat(100)\n    return tf.data.Dataset.zip((features, labels))\n\ndistribution = tf.contrib.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\nclassifier = tf.estimator.Estimator(model_fn=model_fn, config=config)\nclassifier.train(input_fn=input_fn)\n</code></pre>\n<p>Log output:</p>\n<pre><code>2018-05-25 15:30:12.300908: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-05-25 15:30:14.231174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.898\npciBusID: 0000:03:00.0\ntotalMemory: 7.93GiB freeMemory: 7.81GiB\n2018-05-25 15:30:14.557081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: \nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.898\npciBusID: 0000:81:00.0\ntotalMemory: 7.93GiB freeMemory: 7.81GiB\n2018-05-25 15:30:14.557174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1\n2018-05-25 15:30:15.198082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-25 15:30:15.198134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 \n2018-05-25 15:30:15.198142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N N \n2018-05-25 15:30:15.198145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N N \n2018-05-25 15:30:15.198488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7542 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\n2018-05-25 15:30:15.324510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7543 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:81:00.0, compute capability: 6.1)\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqglycjzk\n2018-05-25 15:30:15.455314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1\n2018-05-25 15:30:15.455414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-25 15:30:15.455423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 \n2018-05-25 15:30:15.455427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N N \n2018-05-25 15:30:15.455431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N N \n2018-05-25 15:30:15.455615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 7542 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\n2018-05-25 15:30:15.455720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 7543 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:81:00.0, compute capability: 6.1)\nTraceback (most recent call last):\n  File \"train_model.py\", line 62, in &lt;module&gt;\n    classifier.train(input_fn=input_fn)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 841, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 884, in _train_model_distributed\n    self.config)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 756, in call_for_each_tower\n    return self._call_for_each_tower(fn, *args, **kwargs)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 254, in _call_for_each_tower\n    coord.join(threads)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/six.py\", line 693, in reraise\n    raise value\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower\n    self, *merge_args, **merge_kwargs)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 671, in _distributed_apply\n    self._create_slots(var_list)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py\", line 66, in _create_slots\n    with ops.colocate_with(v):\n  File \"/home/aeiq/.pyenv/versions/3.6.3/lib/python3.6/contextlib.py\", line 81, in __enter__\n    return next(self.gen)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4186, in _colocate_with_for_gradient\n    with self.colocate_with(op, ignore_existing):\n  File \"/home/aeiq/.pyenv/versions/3.6.3/lib/python3.6/contextlib.py\", line 81, in __enter__\n    return next(self.gen)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4239, in colocate_with\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1262, in internal_convert_to_tensor_or_indexed_slices\n    value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1104, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/values.py\", line 243, in _tensor_conversion\n    assert not as_ref\nAssertionError\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): v1.8.0-0-g93bc2e2072 1.8.0\nPython version: 3.6.3 64-bit\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0 / 6.0\nGPU model and memory: Nvidia GTX 1080 8 GB\nExact command to reproduce: python train_model.py\n\nDescribe the problem\nIt took me a while to work out what was going on, but it seems that  tf.train.AdagradOptimizer has some specific implementation detail that causes an error when used with MirroredStrategy. I did a spot check with GradientDescentOptimizer and RMSPropOptimizer and they both appear to work in my environment. I'm happy to use a different optimizer as a workaround but I thought at the very least this might save others some time hunting down the cause of the error!\nSource code / logs\nThis is almost exactly copied from the example at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute (except for the choice of optimizer)\nimport tensorflow as tf\n\ndef model_fn(features, labels, mode):\n    layer = tf.layers.Dense(1)\n    logits = layer(features)\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        predictions = {\"logits\": logits}\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n    loss = tf.losses.mean_squared_error(\n            labels=labels, predictions=tf.reshape(logits, []))\n\n    if mode == tf.estimator.ModeKeys.EVAL:\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_op = tf.train.AdagradOptimizer(0.2).minimize(loss)\n        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\ndef input_fn():\n    features = tf.data.Dataset.from_tensors([[1.]]).repeat(100)\n    labels = tf.data.Dataset.from_tensors(1.).repeat(100)\n    return tf.data.Dataset.zip((features, labels))\n\ndistribution = tf.contrib.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\nclassifier = tf.estimator.Estimator(model_fn=model_fn, config=config)\nclassifier.train(input_fn=input_fn)\n\nLog output:\n2018-05-25 15:30:12.300908: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-05-25 15:30:14.231174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.898\npciBusID: 0000:03:00.0\ntotalMemory: 7.93GiB freeMemory: 7.81GiB\n2018-05-25 15:30:14.557081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: \nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.898\npciBusID: 0000:81:00.0\ntotalMemory: 7.93GiB freeMemory: 7.81GiB\n2018-05-25 15:30:14.557174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1\n2018-05-25 15:30:15.198082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-25 15:30:15.198134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 \n2018-05-25 15:30:15.198142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N N \n2018-05-25 15:30:15.198145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N N \n2018-05-25 15:30:15.198488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7542 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\n2018-05-25 15:30:15.324510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7543 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:81:00.0, compute capability: 6.1)\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqglycjzk\n2018-05-25 15:30:15.455314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1\n2018-05-25 15:30:15.455414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-25 15:30:15.455423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 \n2018-05-25 15:30:15.455427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N N \n2018-05-25 15:30:15.455431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N N \n2018-05-25 15:30:15.455615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 7542 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\n2018-05-25 15:30:15.455720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 7543 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:81:00.0, compute capability: 6.1)\nTraceback (most recent call last):\n  File \"train_model.py\", line 62, in <module>\n    classifier.train(input_fn=input_fn)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 841, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 884, in _train_model_distributed\n    self.config)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 756, in call_for_each_tower\n    return self._call_for_each_tower(fn, *args, **kwargs)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 254, in _call_for_each_tower\n    coord.join(threads)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/six.py\", line 693, in reraise\n    raise value\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower\n    self, *merge_args, **merge_kwargs)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 671, in _distributed_apply\n    self._create_slots(var_list)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py\", line 66, in _create_slots\n    with ops.colocate_with(v):\n  File \"/home/aeiq/.pyenv/versions/3.6.3/lib/python3.6/contextlib.py\", line 81, in __enter__\n    return next(self.gen)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4186, in _colocate_with_for_gradient\n    with self.colocate_with(op, ignore_existing):\n  File \"/home/aeiq/.pyenv/versions/3.6.3/lib/python3.6/contextlib.py\", line 81, in __enter__\n    return next(self.gen)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4239, in colocate_with\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1262, in internal_convert_to_tensor_or_indexed_slices\n    value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1104, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/values.py\", line 243, in _tensor_conversion\n    assert not as_ref\nAssertionError", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0\r\n- **Python version**: 3.6.3 64-bit\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0 / 6.0\r\n- **GPU model and memory**: Nvidia GTX 1080 8 GB \r\n- **Exact command to reproduce**: `python train_model.py`\r\n\r\n### Describe the problem\r\nIt took me a while to work out what was going on, but it seems that  tf.train.AdagradOptimizer has some specific implementation detail that causes an error when used with MirroredStrategy. I did a spot check with GradientDescentOptimizer and RMSPropOptimizer and they both appear to work in my environment. I'm happy to use a different optimizer as a workaround but I thought at the very least this might save others some time hunting down the cause of the error!\r\n\r\n### Source code / logs\r\nThis is almost exactly copied from the example at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute (except for the choice of optimizer)\r\n\r\n    import tensorflow as tf\r\n\r\n    def model_fn(features, labels, mode):\r\n        layer = tf.layers.Dense(1)\r\n        logits = layer(features)\r\n\r\n        if mode == tf.estimator.ModeKeys.PREDICT:\r\n            predictions = {\"logits\": logits}\r\n            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n        loss = tf.losses.mean_squared_error(\r\n                labels=labels, predictions=tf.reshape(logits, []))\r\n\r\n        if mode == tf.estimator.ModeKeys.EVAL:\r\n            return tf.estimator.EstimatorSpec(mode, loss=loss)\r\n\r\n        if mode == tf.estimator.ModeKeys.TRAIN:\r\n            train_op = tf.train.AdagradOptimizer(0.2).minimize(loss)\r\n            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n    def input_fn():\r\n        features = tf.data.Dataset.from_tensors([[1.]]).repeat(100)\r\n        labels = tf.data.Dataset.from_tensors(1.).repeat(100)\r\n        return tf.data.Dataset.zip((features, labels))\r\n\r\n    distribution = tf.contrib.distribute.MirroredStrategy()\r\n    config = tf.estimator.RunConfig(train_distribute=distribution)\r\n    classifier = tf.estimator.Estimator(model_fn=model_fn, config=config)\r\n    classifier.train(input_fn=input_fn)\r\n\r\nLog output:\r\n\r\n    2018-05-25 15:30:12.300908: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n    2018-05-25 15:30:14.231174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \r\n    name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.898\r\n    pciBusID: 0000:03:00.0\r\n    totalMemory: 7.93GiB freeMemory: 7.81GiB\r\n    2018-05-25 15:30:14.557081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: \r\n    name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.898\r\n    pciBusID: 0000:81:00.0\r\n    totalMemory: 7.93GiB freeMemory: 7.81GiB\r\n    2018-05-25 15:30:14.557174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1\r\n    2018-05-25 15:30:15.198082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-05-25 15:30:15.198134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 \r\n    2018-05-25 15:30:15.198142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N N \r\n    2018-05-25 15:30:15.198145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N N \r\n    2018-05-25 15:30:15.198488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7542 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n    2018-05-25 15:30:15.324510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7543 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:81:00.0, compute capability: 6.1)\r\n    WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqglycjzk\r\n    2018-05-25 15:30:15.455314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1\r\n    2018-05-25 15:30:15.455414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-05-25 15:30:15.455423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 \r\n    2018-05-25 15:30:15.455427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N N \r\n    2018-05-25 15:30:15.455431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N N \r\n    2018-05-25 15:30:15.455615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 7542 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n    2018-05-25 15:30:15.455720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 7543 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:81:00.0, compute capability: 6.1)\r\n    Traceback (most recent call last):\r\n      File \"train_model.py\", line 62, in <module>\r\n        classifier.train(input_fn=input_fn)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\r\n        loss = self._train_model(input_fn, hooks, saving_listeners)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 841, in _train_model\r\n        return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 884, in _train_model_distributed\r\n        self.config)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 756, in call_for_each_tower\r\n        return self._call_for_each_tower(fn, *args, **kwargs)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 254, in _call_for_each_tower\r\n        coord.join(threads)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n        six.reraise(*self._exc_info_to_raise)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n        raise value\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n        yield\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower\r\n        self, *merge_args, **merge_kwargs)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 671, in _distributed_apply\r\n        self._create_slots(var_list)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py\", line 66, in _create_slots\r\n        with ops.colocate_with(v):\r\n      File \"/home/aeiq/.pyenv/versions/3.6.3/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n        return next(self.gen)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4186, in _colocate_with_for_gradient\r\n        with self.colocate_with(op, ignore_existing):\r\n      File \"/home/aeiq/.pyenv/versions/3.6.3/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n        return next(self.gen)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4239, in colocate_with\r\n        op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1262, in internal_convert_to_tensor_or_indexed_slices\r\n        value, dtype=dtype, name=name, as_ref=as_ref)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1104, in internal_convert_to_tensor\r\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n      File \"/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/values.py\", line 243, in _tensor_conversion\r\n        assert not as_ref\r\n    AssertionError\r\n\r\n"}