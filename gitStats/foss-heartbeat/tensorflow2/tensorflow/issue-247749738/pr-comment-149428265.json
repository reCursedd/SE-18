{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/149428265", "pull_request_review_id": 74818855, "id": 149428265, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0OTQyODI2NQ==", "diff_hunk": "@@ -187,9 +187,12 @@ def __init__(self,\n           \"memory_layer is not a Layer: %s\" % type(memory_layer).__name__)\n     self._query_layer = query_layer\n     self._memory_layer = memory_layer\n+    self.dtype = memory_layer.dtype\n     if not callable(probability_fn):\n       raise TypeError(\"probability_fn must be callable, saw type: %s\" %\n                       type(probability_fn).__name__)\n+    if score_mask_value is None:\n+      score_mask_value = self._memory_layer.dtype.as_numpy_dtype(-np.inf)", "path": "tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py", "position": null, "original_position": 18, "commit_id": "675287e27b25adde1c8bd43c6d1d7c99ece5e032", "original_commit_id": "3a7859ba1fee54c1948352dba65e37a6b0b380ce", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "looks like self._memory_layer.dtype is a string, when it should be a tf dtype object.  looks like you need to use `dtypes.as_dtype(self._memory_layer.dtype).as_numpy_dtype(-np.inf)`\r\nwhere `dtypes` is a module in python.framework.\r\n\r\nsorry.", "created_at": "2017-11-07T16:33:15Z", "updated_at": "2017-11-09T10:26:24Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/12007#discussion_r149428265", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12007", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/149428265"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/12007#discussion_r149428265"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12007"}}, "body_html": "<p>looks like self._memory_layer.dtype is a string, when it should be a tf dtype object.  looks like you need to use <code>dtypes.as_dtype(self._memory_layer.dtype).as_numpy_dtype(-np.inf)</code><br>\nwhere <code>dtypes</code> is a module in python.framework.</p>\n<p>sorry.</p>", "body_text": "looks like self._memory_layer.dtype is a string, when it should be a tf dtype object.  looks like you need to use dtypes.as_dtype(self._memory_layer.dtype).as_numpy_dtype(-np.inf)\nwhere dtypes is a module in python.framework.\nsorry."}