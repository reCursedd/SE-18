{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11637", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11637/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11637/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11637/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11637", "id": 244299682, "node_id": "MDU6SXNzdWUyNDQyOTk2ODI=", "number": 11637, "title": "when i train a GAN model AdamOptimizer get ValueError ", "user": {"login": "liguanlin", "id": 23256131, "node_id": "MDQ6VXNlcjIzMjU2MTMx", "avatar_url": "https://avatars1.githubusercontent.com/u/23256131?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liguanlin", "html_url": "https://github.com/liguanlin", "followers_url": "https://api.github.com/users/liguanlin/followers", "following_url": "https://api.github.com/users/liguanlin/following{/other_user}", "gists_url": "https://api.github.com/users/liguanlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/liguanlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liguanlin/subscriptions", "organizations_url": "https://api.github.com/users/liguanlin/orgs", "repos_url": "https://api.github.com/users/liguanlin/repos", "events_url": "https://api.github.com/users/liguanlin/events{/privacy}", "received_events_url": "https://api.github.com/users/liguanlin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-07-20T09:30:25Z", "updated_at": "2017-07-25T02:02:36Z", "closed_at": "2017-07-25T02:02:36Z", "author_association": "NONE", "body_html": "<pre><code>with tf.variable_scope(tf.get_variable_scope(),reuse=None):\n    d_optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5).minimize(d_loss, var_list=d_vars, global_step=global_step)\n    g_optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5).minimize(g_loss, var_list=g_vars, global_step=global_step)\n</code></pre>\n<p>i set reuse=None but it still has ValueError: Variable d_bn2/beta/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?<br>\ni even tried set it to False ,but it still has the error<br>\nis that a bug in version r1.2?</p>", "body_text": "with tf.variable_scope(tf.get_variable_scope(),reuse=None):\n    d_optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5).minimize(d_loss, var_list=d_vars, global_step=global_step)\n    g_optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5).minimize(g_loss, var_list=g_vars, global_step=global_step)\n\ni set reuse=None but it still has ValueError: Variable d_bn2/beta/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\ni even tried set it to False ,but it still has the error\nis that a bug in version r1.2?", "body": "    with tf.variable_scope(tf.get_variable_scope(),reuse=None):\r\n        d_optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5).minimize(d_loss, var_list=d_vars, global_step=global_step)\r\n        g_optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5).minimize(g_loss, var_list=g_vars, global_step=global_step)\r\n\r\ni set reuse=None but it still has ValueError: Variable d_bn2/beta/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\r\ni even tried set it to False ,but it still has the error\r\nis that a bug in version r1.2?"}