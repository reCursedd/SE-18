{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/147537137", "pull_request_review_id": 72653478, "id": 147537137, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NzUzNzEzNw==", "diff_hunk": "@@ -56,11 +56,13 @@ struct DenseUpdate<GPUDevice, T, SUB> {\n #define DEFINE_GPU_KERNELS(T)                              \\\n   template struct functor::DenseUpdate<GPUDevice, T, ADD>; \\\n   template struct functor::DenseUpdate<GPUDevice, T, SUB>;\n+TF_CALL_int32(DEFINE_GPU_KERNELS);", "path": "tensorflow/core/kernels/dense_update_functor_gpu.cu.cc", "position": 4, "original_position": 4, "commit_id": "5333bbeb3142af2a06f1ebd971061fc4e28da743", "original_commit_id": "e149ed106993b3e8b3ea9f366f59bcd08e82243b", "user": {"login": "dantkz", "id": 5220571, "node_id": "MDQ6VXNlcjUyMjA1NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5220571?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dantkz", "html_url": "https://github.com/dantkz", "followers_url": "https://api.github.com/users/dantkz/followers", "following_url": "https://api.github.com/users/dantkz/following{/other_user}", "gists_url": "https://api.github.com/users/dantkz/gists{/gist_id}", "starred_url": "https://api.github.com/users/dantkz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dantkz/subscriptions", "organizations_url": "https://api.github.com/users/dantkz/orgs", "repos_url": "https://api.github.com/users/dantkz/repos", "events_url": "https://api.github.com/users/dantkz/events{/privacy}", "received_events_url": "https://api.github.com/users/dantkz/received_events", "type": "User", "site_admin": false}, "body": "@zheng-xq \r\nI don't know when you would do gather or scatter on shapes and ranks, but I understand if the default option shouldn't be on GPU.\r\n1. Neither uint32 nor int64 are supported. This PR adds int32 and int64. Furthermore, operations like tf.unique return int32/int64 as indices, instead of uint32/uint64.\r\n2. Wouldn't new type imply explicit casting? \r\n3. Seems ok. Could it be an option of the op, instead? Something like gather_nd(params, indices, prefer_device=True/False, name)?\r\n\r\nI've submitted the issue and the pull request as I need to do a few gather/scatter_nd operations on int64 tensors for blur/convolution operations on graphs. So, I fetch(gather) vertices on a graph by the index of the vertex and update values on a graph with scatter_nd operation. The structure of the graph is conditioned on the elements of the batch, so it makes sense to run it on the GPU. ", "created_at": "2017-10-27T23:45:10Z", "updated_at": "2017-12-01T13:36:35Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13382#discussion_r147537137", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13382", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/147537137"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13382#discussion_r147537137"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13382"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a><br>\nI don't know when you would do gather or scatter on shapes and ranks, but I understand if the default option shouldn't be on GPU.</p>\n<ol>\n<li>Neither uint32 nor int64 are supported. This PR adds int32 and int64. Furthermore, operations like tf.unique return int32/int64 as indices, instead of uint32/uint64.</li>\n<li>Wouldn't new type imply explicit casting?</li>\n<li>Seems ok. Could it be an option of the op, instead? Something like gather_nd(params, indices, prefer_device=True/False, name)?</li>\n</ol>\n<p>I've submitted the issue and the pull request as I need to do a few gather/scatter_nd operations on int64 tensors for blur/convolution operations on graphs. So, I fetch(gather) vertices on a graph by the index of the vertex and update values on a graph with scatter_nd operation. The structure of the graph is conditioned on the elements of the batch, so it makes sense to run it on the GPU.</p>", "body_text": "@zheng-xq\nI don't know when you would do gather or scatter on shapes and ranks, but I understand if the default option shouldn't be on GPU.\n\nNeither uint32 nor int64 are supported. This PR adds int32 and int64. Furthermore, operations like tf.unique return int32/int64 as indices, instead of uint32/uint64.\nWouldn't new type imply explicit casting?\nSeems ok. Could it be an option of the op, instead? Something like gather_nd(params, indices, prefer_device=True/False, name)?\n\nI've submitted the issue and the pull request as I need to do a few gather/scatter_nd operations on int64 tensors for blur/convolution operations on graphs. So, I fetch(gather) vertices on a graph by the index of the vertex and update values on a graph with scatter_nd operation. The structure of the graph is conditioned on the elements of the batch, so it makes sense to run it on the GPU.", "in_reply_to_id": 143081981}