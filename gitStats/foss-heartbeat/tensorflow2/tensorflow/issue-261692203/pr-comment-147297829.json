{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/147297829", "pull_request_review_id": 72375081, "id": 147297829, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NzI5NzgyOQ==", "diff_hunk": "@@ -56,11 +56,13 @@ struct DenseUpdate<GPUDevice, T, SUB> {\n #define DEFINE_GPU_KERNELS(T)                              \\\n   template struct functor::DenseUpdate<GPUDevice, T, ADD>; \\\n   template struct functor::DenseUpdate<GPUDevice, T, SUB>;\n+TF_CALL_int32(DEFINE_GPU_KERNELS);", "path": "tensorflow/core/kernels/dense_update_functor_gpu.cu.cc", "position": 4, "original_position": 4, "commit_id": "5333bbeb3142af2a06f1ebd971061fc4e28da743", "original_commit_id": "e149ed106993b3e8b3ea9f366f59bcd08e82243b", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "body": "I agree with ebrevdo@ here. The current TF convention is that most int32 operations are for shapes and ranks. Even if they are explicitly placed on GPU, they should be done on CPU. Many users and models are unconsciously using that assumption. Since so many models do that today, it's difficult to change that without causing major performance regressions.\r\n\r\nThere are a few discussions on how to better address them. A few options: \r\n\r\n1. Use uint32 or int64 to work around. In general, they should be on device. \r\n2. Add a new type to indicate that they should be on device. zffchen78@ had a prototype and can comment on whether that is a good idea.\r\n3. Add a label to this new kernel, and use a scope to indicate that this label should be preferred within this scope. Similar to _kernel_label_map in the graph.\r\n\r\nWe may have to reach a consensus on which direction we should head down.\r\n", "created_at": "2017-10-27T00:03:40Z", "updated_at": "2017-12-01T13:36:35Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13382#discussion_r147297829", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13382", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/147297829"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13382#discussion_r147297829"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13382"}}, "body_html": "<p>I agree with ebrevdo@ here. The current TF convention is that most int32 operations are for shapes and ranks. Even if they are explicitly placed on GPU, they should be done on CPU. Many users and models are unconsciously using that assumption. Since so many models do that today, it's difficult to change that without causing major performance regressions.</p>\n<p>There are a few discussions on how to better address them. A few options:</p>\n<ol>\n<li>Use uint32 or int64 to work around. In general, they should be on device.</li>\n<li>Add a new type to indicate that they should be on device. zffchen78@ had a prototype and can comment on whether that is a good idea.</li>\n<li>Add a label to this new kernel, and use a scope to indicate that this label should be preferred within this scope. Similar to _kernel_label_map in the graph.</li>\n</ol>\n<p>We may have to reach a consensus on which direction we should head down.</p>", "body_text": "I agree with ebrevdo@ here. The current TF convention is that most int32 operations are for shapes and ranks. Even if they are explicitly placed on GPU, they should be done on CPU. Many users and models are unconsciously using that assumption. Since so many models do that today, it's difficult to change that without causing major performance regressions.\nThere are a few discussions on how to better address them. A few options:\n\nUse uint32 or int64 to work around. In general, they should be on device.\nAdd a new type to indicate that they should be on device. zffchen78@ had a prototype and can comment on whether that is a good idea.\nAdd a label to this new kernel, and use a scope to indicate that this label should be preferred within this scope. Similar to _kernel_label_map in the graph.\n\nWe may have to reach a consensus on which direction we should head down.", "in_reply_to_id": 143081981}