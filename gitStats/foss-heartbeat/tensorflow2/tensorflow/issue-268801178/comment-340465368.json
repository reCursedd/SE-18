{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/340465368", "html_url": "https://github.com/tensorflow/tensorflow/issues/14000#issuecomment-340465368", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14000", "id": 340465368, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MDQ2NTM2OA==", "user": {"login": "183amir", "id": 5738695, "node_id": "MDQ6VXNlcjU3Mzg2OTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/5738695?v=4", "gravatar_id": "", "url": "https://api.github.com/users/183amir", "html_url": "https://github.com/183amir", "followers_url": "https://api.github.com/users/183amir/followers", "following_url": "https://api.github.com/users/183amir/following{/other_user}", "gists_url": "https://api.github.com/users/183amir/gists{/gist_id}", "starred_url": "https://api.github.com/users/183amir/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/183amir/subscriptions", "organizations_url": "https://api.github.com/users/183amir/orgs", "repos_url": "https://api.github.com/users/183amir/repos", "events_url": "https://api.github.com/users/183amir/events{/privacy}", "received_events_url": "https://api.github.com/users/183amir/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-30T14:42:57Z", "updated_at": "2017-10-30T14:42:57Z", "author_association": "NONE", "body_html": "<p>Thank you for looking into this issue.<br>\nI think (this is my guess) this happens during saving and restoring the model.<br>\nSomething like below would also trigger this issue:</p>\n<div class=\"highlight highlight-source-python\"><pre>data_format <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_first<span class=\"pl-pds\">'</span></span>\ninput_layer <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>data<span class=\"pl-pds\">\"</span></span>)\nconv1 <span class=\"pl-k\">=</span> tf.layers.conv2d(\n            <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>input_layer,\n            <span class=\"pl-v\">filters</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>,\n            <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>),\n            <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>same<span class=\"pl-pds\">\"</span></span>,\n            <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu,\n            <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> assign something like range(3*3*3*32) to conv layer kernel variables</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> print out kernel variables' values as reference</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> save the conv layer into a checkpoint</span></pre></div>\n<p>in a new python process:</p>\n<div class=\"highlight highlight-source-python\"><pre>data_format <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_last<span class=\"pl-pds\">'</span></span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> change to channels last format</span>\ninput_layer <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">3</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>data<span class=\"pl-pds\">\"</span></span>)\nconv1 <span class=\"pl-k\">=</span> tf.layers.conv2d(\n            <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>input_layer,\n            <span class=\"pl-v\">filters</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>,\n            <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>),\n            <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>same<span class=\"pl-pds\">\"</span></span>,\n            <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu,\n            <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> restore checkpoint</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> check if the loaded kernel values are the same still.</span></pre></div>", "body_text": "Thank you for looking into this issue.\nI think (this is my guess) this happens during saving and restoring the model.\nSomething like below would also trigger this issue:\ndata_format = 'channels_first'\ninput_layer = tf.placeholder(tf.float32, shape=[3, 28, 28], name=\"data\")\nconv1 = tf.layers.conv2d(\n            inputs=input_layer,\n            filters=32,\n            kernel_size=(3,3),\n            padding=\"same\",\n            activation=tf.nn.relu,\n            data_format=data_format)\n# assign something like range(3*3*3*32) to conv layer kernel variables\n# print out kernel variables' values as reference\n# save the conv layer into a checkpoint\nin a new python process:\ndata_format = 'channels_last'  # change to channels last format\ninput_layer = tf.placeholder(tf.float32, shape=[28, 28, 3], name=\"data\")\nconv1 = tf.layers.conv2d(\n            inputs=input_layer,\n            filters=32,\n            kernel_size=(3,3),\n            padding=\"same\",\n            activation=tf.nn.relu,\n            data_format=data_format)\n# restore checkpoint\n# check if the loaded kernel values are the same still.", "body": "Thank you for looking into this issue.\r\nI think (this is my guess) this happens during saving and restoring the model.\r\nSomething like below would also trigger this issue:\r\n```python\r\ndata_format = 'channels_first'\r\ninput_layer = tf.placeholder(tf.float32, shape=[3, 28, 28], name=\"data\")\r\nconv1 = tf.layers.conv2d(\r\n            inputs=input_layer,\r\n            filters=32,\r\n            kernel_size=(3,3),\r\n            padding=\"same\",\r\n            activation=tf.nn.relu,\r\n            data_format=data_format)\r\n# assign something like range(3*3*3*32) to conv layer kernel variables\r\n# print out kernel variables' values as reference\r\n# save the conv layer into a checkpoint\r\n```\r\nin a new python process:\r\n```python\r\ndata_format = 'channels_last'  # change to channels last format\r\ninput_layer = tf.placeholder(tf.float32, shape=[28, 28, 3], name=\"data\")\r\nconv1 = tf.layers.conv2d(\r\n            inputs=input_layer,\r\n            filters=32,\r\n            kernel_size=(3,3),\r\n            padding=\"same\",\r\n            activation=tf.nn.relu,\r\n            data_format=data_format)\r\n# restore checkpoint\r\n# check if the loaded kernel values are the same still.\r\n```\r\n"}