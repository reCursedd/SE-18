{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/427854668", "html_url": "https://github.com/tensorflow/tensorflow/issues/18232#issuecomment-427854668", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18232", "id": 427854668, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNzg1NDY2OA==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-08T14:23:18Z", "updated_at": "2018-10-08T14:23:18Z", "author_association": "MEMBER", "body_html": "<p>There should now be a full working preliminary version of collective ops using gRPC for the RPC transport of the new RecvBuf method on the Worker interface.  It works similarly to RecvTensor with a few differences.  First, the payload is an untyped byte field.  Second it uses a BufRendezvous instead of a Rendezvous, so the key space is distinct (and less constrained) and the runtime handling on client and server side is a bit different. It is intended to be usable between processes that are running different graphs, rather than only partitions of a single large graph.</p>\n<p>The simplest way to speed this up using gdr would be simply to add the RecvBuf method to GdrWorker, similarly to how RecvTensor is overridden.   We can discuss more ambitious strategies later.</p>\n<p>The TF team does not want collective ops to be part of the official API, but rather to be an internal tool of the new distribution strategies.  However, for testing purposes the tf_cnn_benchmark suit illustrates how to use the current versions of broadcast and all-reduce, the details of which are subject to change without notice.</p>", "body_text": "There should now be a full working preliminary version of collective ops using gRPC for the RPC transport of the new RecvBuf method on the Worker interface.  It works similarly to RecvTensor with a few differences.  First, the payload is an untyped byte field.  Second it uses a BufRendezvous instead of a Rendezvous, so the key space is distinct (and less constrained) and the runtime handling on client and server side is a bit different. It is intended to be usable between processes that are running different graphs, rather than only partitions of a single large graph.\nThe simplest way to speed this up using gdr would be simply to add the RecvBuf method to GdrWorker, similarly to how RecvTensor is overridden.   We can discuss more ambitious strategies later.\nThe TF team does not want collective ops to be part of the official API, but rather to be an internal tool of the new distribution strategies.  However, for testing purposes the tf_cnn_benchmark suit illustrates how to use the current versions of broadcast and all-reduce, the details of which are subject to change without notice.", "body": "There should now be a full working preliminary version of collective ops using gRPC for the RPC transport of the new RecvBuf method on the Worker interface.  It works similarly to RecvTensor with a few differences.  First, the payload is an untyped byte field.  Second it uses a BufRendezvous instead of a Rendezvous, so the key space is distinct (and less constrained) and the runtime handling on client and server side is a bit different. It is intended to be usable between processes that are running different graphs, rather than only partitions of a single large graph.  \r\n\r\nThe simplest way to speed this up using gdr would be simply to add the RecvBuf method to GdrWorker, similarly to how RecvTensor is overridden.   We can discuss more ambitious strategies later.\r\n\r\nThe TF team does not want collective ops to be part of the official API, but rather to be an internal tool of the new distribution strategies.  However, for testing purposes the tf_cnn_benchmark suit illustrates how to use the current versions of broadcast and all-reduce, the details of which are subject to change without notice. "}