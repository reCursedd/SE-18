{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21870", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21870/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21870/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21870/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21870", "id": 354006382, "node_id": "MDU6SXNzdWUzNTQwMDYzODI=", "number": 21870, "title": "Missing quantized implementation of TopK_V2", "user": {"login": "Turakar", "id": 3958680, "node_id": "MDQ6VXNlcjM5NTg2ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/3958680?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Turakar", "html_url": "https://github.com/Turakar", "followers_url": "https://api.github.com/users/Turakar/followers", "following_url": "https://api.github.com/users/Turakar/following{/other_user}", "gists_url": "https://api.github.com/users/Turakar/gists{/gist_id}", "starred_url": "https://api.github.com/users/Turakar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Turakar/subscriptions", "organizations_url": "https://api.github.com/users/Turakar/orgs", "repos_url": "https://api.github.com/users/Turakar/repos", "events_url": "https://api.github.com/users/Turakar/events{/privacy}", "received_events_url": "https://api.github.com/users/Turakar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-08-25T11:46:14Z", "updated_at": "2018-09-06T21:58:41Z", "closed_at": "2018-09-06T21:58:41Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Fedora 27</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: <code>pip install tensorflow-gpu</code></li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.9.0-0-g25c197e023</li>\n<li><strong>Python version</strong>: 3.6.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0 / 7.1.4</li>\n<li><strong>GPU model and memory</strong>: 940MX, 2GB VRAM</li>\n<li><strong>Exact command to reproduce</strong>: see code below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am trying to quantize my network.<br>\nThere is a special logic in one layer which takes the k highest activations and sets all other to zero.<br>\nIt is implemented using the following code:</p>\n<div class=\"highlight highlight-source-python\"><pre>top <span class=\"pl-k\">=</span> tf.nn.top_k(intermediate, k, <span class=\"pl-v\">sorted</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nmin_indices <span class=\"pl-k\">=</span> top.indices[<span class=\"pl-c1\">...</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\nbatch_indices <span class=\"pl-k\">=</span> tf.range(intermediate.shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\ntotal_indices <span class=\"pl-k\">=</span> tf.stack([batch_indices, min_indices], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\nmins <span class=\"pl-k\">=</span> tf.reshape(tf.gather_nd(intermediate, total_indices), [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>])\nselection <span class=\"pl-k\">=</span> intermediate <span class=\"pl-k\">&gt;=</span> mins\nzeros <span class=\"pl-k\">=</span> tf.zeros(intermediate.shape, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>intermediate.dtype)\nintermediate <span class=\"pl-k\">=</span> tf.where(selection, <span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>intermediate, <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>zeros)</pre></div>\n<p>Where <code>k</code> is a <code>int32</code> placeholder and <code>intermediate</code> a Tensor containing the activations of a fully connected layer. It is shaped <code>[batch_size, nodes]</code>.</p>\n<p>I then call <code>tf.contrib.quantize.create_training_graph()</code>, train using Adam and save the weights as a checkpoint. After a reset of the graph I create the eval graph and rewrite it using <code>tf.contrib.quantize.create_eval_graph()</code>. That one is saved to a graph definition file. After that I run the following commands:</p>\n<pre><code>freeze_graph --input_graph definition.pb --input_checkpoint lastcheckpoint --output_graph frozen_graph.pb --output_node=out\n</code></pre>\n<pre><code>tflite_convert --output_file model.tflite --graph_def_file frozen_graph.pb --inference_type QUANTIZED_UINT8 --input_arrays input/in,density --output_arrays out --mean_values 1,1 --std_dev_values 1,1\n</code></pre>\n<p>The second command fails with the following log:</p>\n<pre><code>2018-08-25 12:39:14.510582: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-08-25 12:39:14.605698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-08-25 12:39:14.606404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \nname: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 0.8605\npciBusID: 0000:01:00.0\ntotalMemory: 1.96GiB freeMemory: 1.71GiB\n2018-08-25 12:39:14.606429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n2018-08-25 12:39:15.293534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-08-25 12:39:15.293568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n2018-08-25 12:39:15.293576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n2018-08-25 12:39:15.293738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1465 MB memory) -&gt; physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)\nTraceback (most recent call last):\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/bin/tflite_convert\", line 11, in &lt;module&gt;\n    sys.exit(main())\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\n    _convert_model(tflite_flags)\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model\n    output_data = converter.convert()\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert\n    allow_custom_ops=self.allow_custom_ops)\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 225, in toco_convert\n    input_data.SerializeToString())\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 107, in toco_convert_protos\n    (stdout, stderr))\nRuntimeError: TOCO failed see console for info.\nb'2018-08-25 12:39:18.308856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: GatherNd\n2018-08-25 12:39:18.308926: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Round\n2018-08-25 12:39:18.309390: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 57 operators, 96 arrays (0 quantized)\n2018-08-25 12:39:18.309831: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 57 operators, 96 arrays (0 quantized)\n2018-08-25 12:39:18.312078: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 28 operators, 55 arrays (1 quantized)\n2018-08-25 12:39:18.312642: W tensorflow/contrib/lite/toco/tooling_util.cc:1639] Dropping MinMax information in array model/conv1/weights_quant/FakeQuantWithMinMaxVars. Expect inaccuracy in quantized inference.\n2018-08-25 12:39:18.312788: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 26 operators, 51 arrays (1 quantized)\n2018-08-25 12:39:18.312907: W tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1304] Skipping StridedSlice op with output \"model/sparsity/strided_slice_1\". ellipsis_mask is not supported (mask=1)\n2018-08-25 12:39:18.313073: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 25 operators, 49 arrays (1 quantized)\n2018-08-25 12:39:18.313173: W tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1304] Skipping StridedSlice op with output \"model/sparsity/strided_slice_1\". ellipsis_mask is not supported (mask=1)\n2018-08-25 12:39:18.313322: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 25 operators, 49 arrays (1 quantized)\n2018-08-25 12:39:18.313431: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 22 operators, 46 arrays (1 quantized)\n2018-08-25 12:39:18.313573: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 22 operators, 46 arrays (1 quantized)\n2018-08-25 12:39:18.313591: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array model/conv1/weights_quant/FakeQuantWithMinMaxVars lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\n2018-08-25 12:39:18.315866: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:456] Unimplemented: this graph contains an operator of type TopK_V2 for which the quantized form is not yet implemented. Sorry, and patches welcome (that\\'s a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\\n'\nNone\n</code></pre>\n<p>The main problem seems to be the missing implementation of TopK_V2. Although it is suggested as a \"fun patch to write\", I only have little knowledge of C/C++ and don't know the tensorflow internals. So I'm opening this issue here to show the need for a quantized implementation of TopK_V2. Maybe somebody can help with that.</p>\n<p>I'm unsure if the other warnings are coming from this issue, too.<br>\nIf you know why they show up, please tell me.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 27\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): pip install tensorflow-gpu\nTensorFlow version (use command below): v1.9.0-0-g25c197e023\nPython version: 3.6.6\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 9.0 / 7.1.4\nGPU model and memory: 940MX, 2GB VRAM\nExact command to reproduce: see code below\n\nDescribe the problem\nI am trying to quantize my network.\nThere is a special logic in one layer which takes the k highest activations and sets all other to zero.\nIt is implemented using the following code:\ntop = tf.nn.top_k(intermediate, k, sorted=True)\nmin_indices = top.indices[..., -1]\nbatch_indices = tf.range(intermediate.shape[0], dtype=tf.int32)\ntotal_indices = tf.stack([batch_indices, min_indices], axis=1)\nmins = tf.reshape(tf.gather_nd(intermediate, total_indices), [-1, 1])\nselection = intermediate >= mins\nzeros = tf.zeros(intermediate.shape, dtype=intermediate.dtype)\nintermediate = tf.where(selection, x=intermediate, y=zeros)\nWhere k is a int32 placeholder and intermediate a Tensor containing the activations of a fully connected layer. It is shaped [batch_size, nodes].\nI then call tf.contrib.quantize.create_training_graph(), train using Adam and save the weights as a checkpoint. After a reset of the graph I create the eval graph and rewrite it using tf.contrib.quantize.create_eval_graph(). That one is saved to a graph definition file. After that I run the following commands:\nfreeze_graph --input_graph definition.pb --input_checkpoint lastcheckpoint --output_graph frozen_graph.pb --output_node=out\n\ntflite_convert --output_file model.tflite --graph_def_file frozen_graph.pb --inference_type QUANTIZED_UINT8 --input_arrays input/in,density --output_arrays out --mean_values 1,1 --std_dev_values 1,1\n\nThe second command fails with the following log:\n2018-08-25 12:39:14.510582: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-08-25 12:39:14.605698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-08-25 12:39:14.606404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \nname: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 0.8605\npciBusID: 0000:01:00.0\ntotalMemory: 1.96GiB freeMemory: 1.71GiB\n2018-08-25 12:39:14.606429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n2018-08-25 12:39:15.293534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-08-25 12:39:15.293568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n2018-08-25 12:39:15.293576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n2018-08-25 12:39:15.293738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1465 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)\nTraceback (most recent call last):\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/bin/tflite_convert\", line 11, in <module>\n    sys.exit(main())\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\n    _convert_model(tflite_flags)\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model\n    output_data = converter.convert()\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert\n    allow_custom_ops=self.allow_custom_ops)\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 225, in toco_convert\n    input_data.SerializeToString())\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 107, in toco_convert_protos\n    (stdout, stderr))\nRuntimeError: TOCO failed see console for info.\nb'2018-08-25 12:39:18.308856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: GatherNd\n2018-08-25 12:39:18.308926: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Round\n2018-08-25 12:39:18.309390: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 57 operators, 96 arrays (0 quantized)\n2018-08-25 12:39:18.309831: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 57 operators, 96 arrays (0 quantized)\n2018-08-25 12:39:18.312078: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 28 operators, 55 arrays (1 quantized)\n2018-08-25 12:39:18.312642: W tensorflow/contrib/lite/toco/tooling_util.cc:1639] Dropping MinMax information in array model/conv1/weights_quant/FakeQuantWithMinMaxVars. Expect inaccuracy in quantized inference.\n2018-08-25 12:39:18.312788: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 26 operators, 51 arrays (1 quantized)\n2018-08-25 12:39:18.312907: W tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1304] Skipping StridedSlice op with output \"model/sparsity/strided_slice_1\". ellipsis_mask is not supported (mask=1)\n2018-08-25 12:39:18.313073: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 25 operators, 49 arrays (1 quantized)\n2018-08-25 12:39:18.313173: W tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1304] Skipping StridedSlice op with output \"model/sparsity/strided_slice_1\". ellipsis_mask is not supported (mask=1)\n2018-08-25 12:39:18.313322: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 25 operators, 49 arrays (1 quantized)\n2018-08-25 12:39:18.313431: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 22 operators, 46 arrays (1 quantized)\n2018-08-25 12:39:18.313573: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 22 operators, 46 arrays (1 quantized)\n2018-08-25 12:39:18.313591: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array model/conv1/weights_quant/FakeQuantWithMinMaxVars lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\n2018-08-25 12:39:18.315866: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:456] Unimplemented: this graph contains an operator of type TopK_V2 for which the quantized form is not yet implemented. Sorry, and patches welcome (that\\'s a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\\n'\nNone\n\nThe main problem seems to be the missing implementation of TopK_V2. Although it is suggested as a \"fun patch to write\", I only have little knowledge of C/C++ and don't know the tensorflow internals. So I'm opening this issue here to show the need for a quantized implementation of TopK_V2. Maybe somebody can help with that.\nI'm unsure if the other warnings are coming from this issue, too.\nIf you know why they show up, please tell me.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Fedora 27\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: `pip install tensorflow-gpu`\r\n- **TensorFlow version (use command below)**: v1.9.0-0-g25c197e023\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0 / 7.1.4\r\n- **GPU model and memory**: 940MX, 2GB VRAM\r\n- **Exact command to reproduce**: see code below\r\n\r\n### Describe the problem\r\nI am trying to quantize my network.\r\nThere is a special logic in one layer which takes the k highest activations and sets all other to zero.\r\nIt is implemented using the following code:\r\n```python\r\ntop = tf.nn.top_k(intermediate, k, sorted=True)\r\nmin_indices = top.indices[..., -1]\r\nbatch_indices = tf.range(intermediate.shape[0], dtype=tf.int32)\r\ntotal_indices = tf.stack([batch_indices, min_indices], axis=1)\r\nmins = tf.reshape(tf.gather_nd(intermediate, total_indices), [-1, 1])\r\nselection = intermediate >= mins\r\nzeros = tf.zeros(intermediate.shape, dtype=intermediate.dtype)\r\nintermediate = tf.where(selection, x=intermediate, y=zeros)\r\n```\r\nWhere `k` is a `int32` placeholder and `intermediate` a Tensor containing the activations of a fully connected layer. It is shaped `[batch_size, nodes]`.\r\n\r\nI then call `tf.contrib.quantize.create_training_graph()`, train using Adam and save the weights as a checkpoint. After a reset of the graph I create the eval graph and rewrite it using `tf.contrib.quantize.create_eval_graph()`. That one is saved to a graph definition file. After that I run the following commands:\r\n\r\n```\r\nfreeze_graph --input_graph definition.pb --input_checkpoint lastcheckpoint --output_graph frozen_graph.pb --output_node=out\r\n```\r\n\r\n```\r\ntflite_convert --output_file model.tflite --graph_def_file frozen_graph.pb --inference_type QUANTIZED_UINT8 --input_arrays input/in,density --output_arrays out --mean_values 1,1 --std_dev_values 1,1\r\n```\r\n\r\nThe second command fails with the following log:\r\n\r\n```\r\n2018-08-25 12:39:14.510582: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-08-25 12:39:14.605698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-08-25 12:39:14.606404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \r\nname: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 0.8605\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 1.96GiB freeMemory: 1.71GiB\r\n2018-08-25 12:39:14.606429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\r\n2018-08-25 12:39:15.293534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-25 12:39:15.293568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \r\n2018-08-25 12:39:15.293576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \r\n2018-08-25 12:39:15.293738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1465 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nTraceback (most recent call last):\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/bin/tflite_convert\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert\r\n    allow_custom_ops=self.allow_custom_ops)\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 225, in toco_convert\r\n    input_data.SerializeToString())\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 107, in toco_convert_protos\r\n    (stdout, stderr))\r\nRuntimeError: TOCO failed see console for info.\r\nb'2018-08-25 12:39:18.308856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: GatherNd\r\n2018-08-25 12:39:18.308926: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Round\r\n2018-08-25 12:39:18.309390: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 57 operators, 96 arrays (0 quantized)\r\n2018-08-25 12:39:18.309831: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 57 operators, 96 arrays (0 quantized)\r\n2018-08-25 12:39:18.312078: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 28 operators, 55 arrays (1 quantized)\r\n2018-08-25 12:39:18.312642: W tensorflow/contrib/lite/toco/tooling_util.cc:1639] Dropping MinMax information in array model/conv1/weights_quant/FakeQuantWithMinMaxVars. Expect inaccuracy in quantized inference.\r\n2018-08-25 12:39:18.312788: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 26 operators, 51 arrays (1 quantized)\r\n2018-08-25 12:39:18.312907: W tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1304] Skipping StridedSlice op with output \"model/sparsity/strided_slice_1\". ellipsis_mask is not supported (mask=1)\r\n2018-08-25 12:39:18.313073: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 25 operators, 49 arrays (1 quantized)\r\n2018-08-25 12:39:18.313173: W tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1304] Skipping StridedSlice op with output \"model/sparsity/strided_slice_1\". ellipsis_mask is not supported (mask=1)\r\n2018-08-25 12:39:18.313322: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 25 operators, 49 arrays (1 quantized)\r\n2018-08-25 12:39:18.313431: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 22 operators, 46 arrays (1 quantized)\r\n2018-08-25 12:39:18.313573: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 22 operators, 46 arrays (1 quantized)\r\n2018-08-25 12:39:18.313591: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array model/conv1/weights_quant/FakeQuantWithMinMaxVars lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-08-25 12:39:18.315866: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:456] Unimplemented: this graph contains an operator of type TopK_V2 for which the quantized form is not yet implemented. Sorry, and patches welcome (that\\'s a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\\n'\r\nNone\r\n```\r\nThe main problem seems to be the missing implementation of TopK_V2. Although it is suggested as a \"fun patch to write\", I only have little knowledge of C/C++ and don't know the tensorflow internals. So I'm opening this issue here to show the need for a quantized implementation of TopK_V2. Maybe somebody can help with that.\r\n\r\nI'm unsure if the other warnings are coming from this issue, too.\r\nIf you know why they show up, please tell me."}