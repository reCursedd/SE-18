{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13099", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13099/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13099/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13099/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13099", "id": 258308777, "node_id": "MDU6SXNzdWUyNTgzMDg3Nzc=", "number": 13099, "title": "Weights and biases not being updated.", "user": {"login": "ParmuSingh", "id": 22577208, "node_id": "MDQ6VXNlcjIyNTc3MjA4", "avatar_url": "https://avatars2.githubusercontent.com/u/22577208?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ParmuSingh", "html_url": "https://github.com/ParmuSingh", "followers_url": "https://api.github.com/users/ParmuSingh/followers", "following_url": "https://api.github.com/users/ParmuSingh/following{/other_user}", "gists_url": "https://api.github.com/users/ParmuSingh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ParmuSingh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ParmuSingh/subscriptions", "organizations_url": "https://api.github.com/users/ParmuSingh/orgs", "repos_url": "https://api.github.com/users/ParmuSingh/repos", "events_url": "https://api.github.com/users/ParmuSingh/events{/privacy}", "received_events_url": "https://api.github.com/users/ParmuSingh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-17T14:48:10Z", "updated_at": "2017-10-07T00:49:04Z", "closed_at": "2017-10-07T00:40:41Z", "author_association": "NONE", "body_html": "<p>(I've already tried stackoverflow)</p>\n<p>I've made this neural net to figure out whether a house is a good buy or a bad buy. For some reasons the code is not updating weights and biases. My loss stays same. This is my code:</p>\n<pre><code>import pandas as pd\nimport tensorflow as tf\n\ndata = pd.read_csv(\"E:/workspace_py/datasets/good_bad_buy.csv\")\n\nfeatures = data.drop(['index', 'good buy'], axis = 1)\nlbls = data.drop(['index', 'area', 'bathrooms', 'price', 'sq_price'], axis = 1)\n\nfeatures = features[0:20]\nlbls = lbls[0:20]\n\nprint(features)\nprint(lbls)\nn_examples = len(lbls)\n\n# Model\n\n# Hyper parameters\n\nepochs = 100\nlearning_rate = 0.1\nbatch_size = 1\n\ninput_data = tf.placeholder('float', [None, 4])\nlabels = tf.placeholder('float', [None, 1])\n\nweights = {\n\t\t\t'hl1': tf.Variable(tf.random_normal([4, 10])),\n\t\t\t'hl2': tf.Variable(tf.random_normal([10, 10])),\n\t\t\t'hl3': tf.Variable(tf.random_normal([10, 4])),\n\t\t\t'ol': tf.Variable(tf.random_normal([4, 1]))\n\t\t\t}\n\nbiases = {\n\t\t\t'hl1': tf.Variable(tf.random_normal([10])),\n\t\t\t'hl2': tf.Variable(tf.random_normal([10])),\n\t\t\t'hl3': tf.Variable(tf.random_normal([4])),\n\t\t\t'ol': tf.Variable(tf.random_normal([1]))\n\t\t\t}\n\nhl1 = tf.nn.relu(tf.add(tf.matmul(input_data, weights['hl1']), biases['hl1']))\nhl2 = tf.nn.relu(tf.add(tf.matmul(hl1, weights['hl2']), biases['hl2']))\nhl3 = tf.nn.relu(tf.add(tf.matmul(hl2, weights['hl3']), biases['hl3']))\nol = tf.nn.sigmoid(tf.add(tf.matmul(hl3, weights['ol']), biases['ol']))\n\nloss = tf.reduce_mean((labels - ol)**2)\ntrain = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\niterations = int(n_examples/batch_size)\n\n\nfor epoch_no in range(epochs):\n    ptr = 0\n\tfor iteration_no in range(iterations):\n\t\tepoch_input = features[ptr:ptr+batch_size]\n\t\tepoch_label = lbls[ptr: ptr+batch_size]\n\t\tptr = ptr + batch_size\n\t\t_, err = sess.run([train, loss], feed_dict={input_data: features, labels: lbls})\n\tprint(\"Error at epoch \", epoch_no, \": \", err)\n\nprint(sess.run(ol, feed_dict={input_data: [[2104, 3, 399900, 190.0665]]}))\n</code></pre>\n<p>This is the dataset:</p>\n<pre><code>Features:\n\n    area  bathrooms   price    sq_price\n0   2104          3  399900  190.066540\n1   1600          3  329900  206.187500\n2   2400          3  369000  153.750000\n3   1416          2  232000  163.841808\n4   3000          4  539900  179.966667\n5   1985          4  299900  151.083123\n6   1534          3  314900  205.280313\n7   1427          3  198999  139.452698\n8   1380          3  212000  153.623188\n9   1494          3  242500  162.315930\n10  1940          4  239999  123.710825\n11  2000          3  347000  173.500000\n12  1890          3  329999  174.602645\n13  4478          5  699900  156.297454\n14  1268          3  259900  204.968454\n15  2300          4  449900  195.608696\n16  1320          2  299900  227.196970\n17  1236          3  199900  161.731392\n18  2609          4  499998  191.643542\n19  3031          4  599000  197.624546\n\nlabels:\n\n    good buy\n0        1.0\n1        0.0\n2        1.0\n3        0.0\n4        1.0\n5        0.0\n6        0.0\n7        1.0\n8        0.0\n9        0.0\n10       1.0\n11       1.0\n12       1.0\n13       1.0\n14       0.0\n15       1.0\n16       0.0\n17       1.0\n18       1.0\n19       1.0\n</code></pre>\n<p>Any suggestions on how to fix this?</p>", "body_text": "(I've already tried stackoverflow)\nI've made this neural net to figure out whether a house is a good buy or a bad buy. For some reasons the code is not updating weights and biases. My loss stays same. This is my code:\nimport pandas as pd\nimport tensorflow as tf\n\ndata = pd.read_csv(\"E:/workspace_py/datasets/good_bad_buy.csv\")\n\nfeatures = data.drop(['index', 'good buy'], axis = 1)\nlbls = data.drop(['index', 'area', 'bathrooms', 'price', 'sq_price'], axis = 1)\n\nfeatures = features[0:20]\nlbls = lbls[0:20]\n\nprint(features)\nprint(lbls)\nn_examples = len(lbls)\n\n# Model\n\n# Hyper parameters\n\nepochs = 100\nlearning_rate = 0.1\nbatch_size = 1\n\ninput_data = tf.placeholder('float', [None, 4])\nlabels = tf.placeholder('float', [None, 1])\n\nweights = {\n\t\t\t'hl1': tf.Variable(tf.random_normal([4, 10])),\n\t\t\t'hl2': tf.Variable(tf.random_normal([10, 10])),\n\t\t\t'hl3': tf.Variable(tf.random_normal([10, 4])),\n\t\t\t'ol': tf.Variable(tf.random_normal([4, 1]))\n\t\t\t}\n\nbiases = {\n\t\t\t'hl1': tf.Variable(tf.random_normal([10])),\n\t\t\t'hl2': tf.Variable(tf.random_normal([10])),\n\t\t\t'hl3': tf.Variable(tf.random_normal([4])),\n\t\t\t'ol': tf.Variable(tf.random_normal([1]))\n\t\t\t}\n\nhl1 = tf.nn.relu(tf.add(tf.matmul(input_data, weights['hl1']), biases['hl1']))\nhl2 = tf.nn.relu(tf.add(tf.matmul(hl1, weights['hl2']), biases['hl2']))\nhl3 = tf.nn.relu(tf.add(tf.matmul(hl2, weights['hl3']), biases['hl3']))\nol = tf.nn.sigmoid(tf.add(tf.matmul(hl3, weights['ol']), biases['ol']))\n\nloss = tf.reduce_mean((labels - ol)**2)\ntrain = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\niterations = int(n_examples/batch_size)\n\n\nfor epoch_no in range(epochs):\n    ptr = 0\n\tfor iteration_no in range(iterations):\n\t\tepoch_input = features[ptr:ptr+batch_size]\n\t\tepoch_label = lbls[ptr: ptr+batch_size]\n\t\tptr = ptr + batch_size\n\t\t_, err = sess.run([train, loss], feed_dict={input_data: features, labels: lbls})\n\tprint(\"Error at epoch \", epoch_no, \": \", err)\n\nprint(sess.run(ol, feed_dict={input_data: [[2104, 3, 399900, 190.0665]]}))\n\nThis is the dataset:\nFeatures:\n\n    area  bathrooms   price    sq_price\n0   2104          3  399900  190.066540\n1   1600          3  329900  206.187500\n2   2400          3  369000  153.750000\n3   1416          2  232000  163.841808\n4   3000          4  539900  179.966667\n5   1985          4  299900  151.083123\n6   1534          3  314900  205.280313\n7   1427          3  198999  139.452698\n8   1380          3  212000  153.623188\n9   1494          3  242500  162.315930\n10  1940          4  239999  123.710825\n11  2000          3  347000  173.500000\n12  1890          3  329999  174.602645\n13  4478          5  699900  156.297454\n14  1268          3  259900  204.968454\n15  2300          4  449900  195.608696\n16  1320          2  299900  227.196970\n17  1236          3  199900  161.731392\n18  2609          4  499998  191.643542\n19  3031          4  599000  197.624546\n\nlabels:\n\n    good buy\n0        1.0\n1        0.0\n2        1.0\n3        0.0\n4        1.0\n5        0.0\n6        0.0\n7        1.0\n8        0.0\n9        0.0\n10       1.0\n11       1.0\n12       1.0\n13       1.0\n14       0.0\n15       1.0\n16       0.0\n17       1.0\n18       1.0\n19       1.0\n\nAny suggestions on how to fix this?", "body": "(I've already tried stackoverflow)\r\n\r\nI've made this neural net to figure out whether a house is a good buy or a bad buy. For some reasons the code is not updating weights and biases. My loss stays same. This is my code:\r\n\r\n    import pandas as pd\r\n    import tensorflow as tf\r\n    \r\n    data = pd.read_csv(\"E:/workspace_py/datasets/good_bad_buy.csv\")\r\n    \r\n    features = data.drop(['index', 'good buy'], axis = 1)\r\n    lbls = data.drop(['index', 'area', 'bathrooms', 'price', 'sq_price'], axis = 1)\r\n    \r\n    features = features[0:20]\r\n    lbls = lbls[0:20]\r\n    \r\n    print(features)\r\n    print(lbls)\r\n    n_examples = len(lbls)\r\n    \r\n    # Model\r\n    \r\n    # Hyper parameters\r\n    \r\n    epochs = 100\r\n    learning_rate = 0.1\r\n    batch_size = 1\r\n    \r\n    input_data = tf.placeholder('float', [None, 4])\r\n    labels = tf.placeholder('float', [None, 1])\r\n    \r\n    weights = {\r\n    \t\t\t'hl1': tf.Variable(tf.random_normal([4, 10])),\r\n    \t\t\t'hl2': tf.Variable(tf.random_normal([10, 10])),\r\n    \t\t\t'hl3': tf.Variable(tf.random_normal([10, 4])),\r\n    \t\t\t'ol': tf.Variable(tf.random_normal([4, 1]))\r\n    \t\t\t}\r\n    \r\n    biases = {\r\n    \t\t\t'hl1': tf.Variable(tf.random_normal([10])),\r\n    \t\t\t'hl2': tf.Variable(tf.random_normal([10])),\r\n    \t\t\t'hl3': tf.Variable(tf.random_normal([4])),\r\n    \t\t\t'ol': tf.Variable(tf.random_normal([1]))\r\n    \t\t\t}\r\n    \r\n    hl1 = tf.nn.relu(tf.add(tf.matmul(input_data, weights['hl1']), biases['hl1']))\r\n    hl2 = tf.nn.relu(tf.add(tf.matmul(hl1, weights['hl2']), biases['hl2']))\r\n    hl3 = tf.nn.relu(tf.add(tf.matmul(hl2, weights['hl3']), biases['hl3']))\r\n    ol = tf.nn.sigmoid(tf.add(tf.matmul(hl3, weights['ol']), biases['ol']))\r\n    \r\n    loss = tf.reduce_mean((labels - ol)**2)\r\n    train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\r\n    \r\n    sess = tf.Session()\r\n    sess.run(tf.global_variables_initializer())\r\n    \r\n    iterations = int(n_examples/batch_size)\r\n    \r\n    \r\n    for epoch_no in range(epochs):\r\n        ptr = 0\r\n    \tfor iteration_no in range(iterations):\r\n    \t\tepoch_input = features[ptr:ptr+batch_size]\r\n    \t\tepoch_label = lbls[ptr: ptr+batch_size]\r\n    \t\tptr = ptr + batch_size\r\n    \t\t_, err = sess.run([train, loss], feed_dict={input_data: features, labels: lbls})\r\n    \tprint(\"Error at epoch \", epoch_no, \": \", err)\r\n    \r\n    print(sess.run(ol, feed_dict={input_data: [[2104, 3, 399900, 190.0665]]}))\r\n\r\n\r\nThis is the dataset:\r\n\r\n    Features:\r\n\r\n        area  bathrooms   price    sq_price\r\n    0   2104          3  399900  190.066540\r\n    1   1600          3  329900  206.187500\r\n    2   2400          3  369000  153.750000\r\n    3   1416          2  232000  163.841808\r\n    4   3000          4  539900  179.966667\r\n    5   1985          4  299900  151.083123\r\n    6   1534          3  314900  205.280313\r\n    7   1427          3  198999  139.452698\r\n    8   1380          3  212000  153.623188\r\n    9   1494          3  242500  162.315930\r\n    10  1940          4  239999  123.710825\r\n    11  2000          3  347000  173.500000\r\n    12  1890          3  329999  174.602645\r\n    13  4478          5  699900  156.297454\r\n    14  1268          3  259900  204.968454\r\n    15  2300          4  449900  195.608696\r\n    16  1320          2  299900  227.196970\r\n    17  1236          3  199900  161.731392\r\n    18  2609          4  499998  191.643542\r\n    19  3031          4  599000  197.624546\r\n\r\n    labels:\r\n\r\n        good buy\r\n    0        1.0\r\n    1        0.0\r\n    2        1.0\r\n    3        0.0\r\n    4        1.0\r\n    5        0.0\r\n    6        0.0\r\n    7        1.0\r\n    8        0.0\r\n    9        0.0\r\n    10       1.0\r\n    11       1.0\r\n    12       1.0\r\n    13       1.0\r\n    14       0.0\r\n    15       1.0\r\n    16       0.0\r\n    17       1.0\r\n    18       1.0\r\n    19       1.0\r\n\r\nAny suggestions on how to fix this?"}