{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/170779459", "pull_request_review_id": 99518064, "id": 170779459, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MDc3OTQ1OQ==", "diff_hunk": "@@ -1928,6 +1928,126 @@ inline void Div(const float* input1_data, const Dims<4>& input1_dims,\n   }\n }\n \n+// TODO(jiawen): We can implement BroadcastDiv on buffers of arbitrary\n+// dimensionality if the runtime code does a single loop over one dimension\n+// that handles broadcasting as the base case. The code generator would then\n+// generate max(D1, D2) nested for loops.\n+// TODO(benoitjacob): BroadcastDiv is intentionally duplicated from\n+// reference_ops.h. Once an optimized version is implemented and NdArrayDesc<T>\n+// is no longer referenced in this file, move NdArrayDesc<T> from types.h to\n+// reference_ops.h.\n+template <typename T>\n+void BroadcastDiv(const T* input1_data, const Dims<4>& input1_dims,\n+                  const T* input2_data, const Dims<4>& input2_dims,\n+                  T output_activation_min, T output_activation_max,\n+                  T* output_data, const Dims<4>& output_dims) {\n+  gemmlowp::ScopedProfilingLabel label(\"BroadcastDiv\");\n+\n+  NdArrayDesc<4> desc1;\n+  NdArrayDesc<4> desc2;\n+  NdArrayDescsForElementwiseBroadcast(input1_dims, input2_dims, &desc1, &desc2);\n+\n+  // In Tensorflow, the dimensions are canonically named (batch_number, row,\n+  // col, channel), with extents (batches, height, width, depth), with the\n+  // trailing dimension changing most rapidly (channels has the smallest stride,\n+  // typically 1 element).\n+  //\n+  // In generated C code, we store arrays with the dimensions reversed. The\n+  // first dimension has smallest stride.\n+  //\n+  // We name our variables by their Tensorflow convention, but generate C code\n+  // nesting loops such that the innermost loop has the smallest stride for the\n+  // best cache behavior.\n+  for (int b = 0; b < ArraySize(output_dims, 3); ++b) {\n+    for (int y = 0; y < ArraySize(output_dims, 2); ++y) {\n+      for (int x = 0; x < ArraySize(output_dims, 1); ++x) {\n+        for (int c = 0; c < ArraySize(output_dims, 0); ++c) {\n+          output_data[Offset(output_dims, c, x, y, b)] =\n+              ActivationFunctionWithMinMax(\n+                  input1_data[SubscriptToIndex(desc1, c, x, y, b)] /\n+                      input2_data[SubscriptToIndex(desc2, c, x, y, b)],\n+                  output_activation_min, output_activation_max);\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+// legacy, for compatibility with old checked-in code\n+template <FusedActivationFunctionType Ac, typename T>\n+void BroadcastDiv(const T* input1_data, const Dims<4>& input1_dims,\n+                  const T* input2_data, const Dims<4>& input2_dims,\n+                  T* output_data, const Dims<4>& output_dims) {\n+  T output_activation_min, output_activation_max;\n+  GetActivationMinMax(Ac, &output_activation_min, &output_activation_max);\n+\n+  BroadcastDiv(input1_data, input1_dims, input2_data, input2_dims,\n+               output_activation_min, output_activation_max, output_data,\n+               output_dims);\n+}\n+\n+inline void BroadcastDiv(const uint8* input1_data, const Dims<4>& input1_dims,\n+                         int32 input1_offset, const uint8* input2_data,\n+                         const Dims<4>& input2_dims, int32 input2_offset,\n+                         int32 output_offset, int32 output_multiplier,\n+                         int output_shift, int32 output_activation_min,\n+                         int32 output_activation_max, uint8* output_data,\n+                         const Dims<4>& output_dims) {\n+  gemmlowp::ScopedProfilingLabel label(\"BroadcastDiv/8bit\");\n+\n+  NdArrayDesc<4> desc1;\n+  NdArrayDesc<4> desc2;\n+  NdArrayDescsForElementwiseBroadcast(input1_dims, input2_dims, &desc1, &desc2);\n+\n+  // In Tensorflow, the dimensions are canonically named (batch_number, row,\n+  // col, channel), with extents (batches, height, width, depth), with the\n+  // trailing dimension changing most rapidly (channels has the smallest stride,\n+  // typically 1 element).\n+  //\n+  // In generated C code, we store arrays with the dimensions reversed. The\n+  // first dimension has smallest stride.\n+  //\n+  // We name our variables by their Tensorflow convention, but generate C code\n+  // nesting loops such that the innermost loop has the smallest stride for the\n+  // best cache behavior.\n+  for (int b = 0; b < ArraySize(output_dims, 3); ++b) {\n+    for (int y = 0; y < ArraySize(output_dims, 2); ++y) {\n+      for (int x = 0; x < ArraySize(output_dims, 1); ++x) {\n+        for (int c = 0; c < ArraySize(output_dims, 0); ++c) {\n+          const int32 input1_val =\n+              input1_offset + input1_data[SubscriptToIndex(desc1, c, x, y, b)];\n+          const int32 input2_val =\n+              input2_offset + input2_data[SubscriptToIndex(desc2, c, x, y, b)];\n+          const int32 unclamped_result =\n+              output_offset +\n+              MultiplyByQuantizedMultiplierSmallerThanOne(\n+                  input1_val / input2_val, output_multiplier, output_shift);", "path": "tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h", "position": null, "original_position": 97, "commit_id": "09ab7fc83e3b2b66a2d1ff68ac6ad1b56a61fcd6", "original_commit_id": "672ec270f96144bca5e1d75d002421c1e9b49921", "user": {"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}, "body": "The quantization scheme used in TF Lite is similar to gemmlowp's: https://github.com/google/gemmlowp/blob/master/doc/quantization.md\r\n\r\nMaybe we can leave the quantization for a separate PR? I'd be happy to approve the other changes, and then we can have someone with more quantization experience review the other PR.", "created_at": "2018-02-27T00:15:50Z", "updated_at": "2018-04-12T06:55:13Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/17123#discussion_r170779459", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17123", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/170779459"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/17123#discussion_r170779459"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17123"}}, "body_html": "<p>The quantization scheme used in TF Lite is similar to gemmlowp's: <a href=\"https://github.com/google/gemmlowp/blob/master/doc/quantization.md\">https://github.com/google/gemmlowp/blob/master/doc/quantization.md</a></p>\n<p>Maybe we can leave the quantization for a separate PR? I'd be happy to approve the other changes, and then we can have someone with more quantization experience review the other PR.</p>", "body_text": "The quantization scheme used in TF Lite is similar to gemmlowp's: https://github.com/google/gemmlowp/blob/master/doc/quantization.md\nMaybe we can leave the quantization for a separate PR? I'd be happy to approve the other changes, and then we can have someone with more quantization experience review the other PR.", "in_reply_to_id": 170039033}