{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/170614157", "pull_request_review_id": 99325354, "id": 170614157, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MDYxNDE1Nw==", "diff_hunk": "@@ -1928,6 +1928,126 @@ inline void Div(const float* input1_data, const Dims<4>& input1_dims,\n   }\n }\n \n+// TODO(jiawen): We can implement BroadcastDiv on buffers of arbitrary\n+// dimensionality if the runtime code does a single loop over one dimension\n+// that handles broadcasting as the base case. The code generator would then\n+// generate max(D1, D2) nested for loops.\n+// TODO(benoitjacob): BroadcastDiv is intentionally duplicated from\n+// reference_ops.h. Once an optimized version is implemented and NdArrayDesc<T>\n+// is no longer referenced in this file, move NdArrayDesc<T> from types.h to\n+// reference_ops.h.\n+template <typename T>\n+void BroadcastDiv(const T* input1_data, const Dims<4>& input1_dims,\n+                  const T* input2_data, const Dims<4>& input2_dims,\n+                  T output_activation_min, T output_activation_max,\n+                  T* output_data, const Dims<4>& output_dims) {\n+  gemmlowp::ScopedProfilingLabel label(\"BroadcastDiv\");\n+\n+  NdArrayDesc<4> desc1;\n+  NdArrayDesc<4> desc2;\n+  NdArrayDescsForElementwiseBroadcast(input1_dims, input2_dims, &desc1, &desc2);\n+\n+  // In Tensorflow, the dimensions are canonically named (batch_number, row,\n+  // col, channel), with extents (batches, height, width, depth), with the\n+  // trailing dimension changing most rapidly (channels has the smallest stride,\n+  // typically 1 element).\n+  //\n+  // In generated C code, we store arrays with the dimensions reversed. The\n+  // first dimension has smallest stride.\n+  //\n+  // We name our variables by their Tensorflow convention, but generate C code\n+  // nesting loops such that the innermost loop has the smallest stride for the\n+  // best cache behavior.\n+  for (int b = 0; b < ArraySize(output_dims, 3); ++b) {\n+    for (int y = 0; y < ArraySize(output_dims, 2); ++y) {\n+      for (int x = 0; x < ArraySize(output_dims, 1); ++x) {\n+        for (int c = 0; c < ArraySize(output_dims, 0); ++c) {\n+          output_data[Offset(output_dims, c, x, y, b)] =\n+              ActivationFunctionWithMinMax(\n+                  input1_data[SubscriptToIndex(desc1, c, x, y, b)] /\n+                      input2_data[SubscriptToIndex(desc2, c, x, y, b)],\n+                  output_activation_min, output_activation_max);\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+// legacy, for compatibility with old checked-in code\n+template <FusedActivationFunctionType Ac, typename T>\n+void BroadcastDiv(const T* input1_data, const Dims<4>& input1_dims,\n+                  const T* input2_data, const Dims<4>& input2_dims,\n+                  T* output_data, const Dims<4>& output_dims) {\n+  T output_activation_min, output_activation_max;\n+  GetActivationMinMax(Ac, &output_activation_min, &output_activation_max);\n+\n+  BroadcastDiv(input1_data, input1_dims, input2_data, input2_dims,\n+               output_activation_min, output_activation_max, output_data,\n+               output_dims);\n+}\n+\n+inline void BroadcastDiv(const uint8* input1_data, const Dims<4>& input1_dims,\n+                         int32 input1_offset, const uint8* input2_data,\n+                         const Dims<4>& input2_dims, int32 input2_offset,\n+                         int32 output_offset, int32 output_multiplier,\n+                         int output_shift, int32 output_activation_min,\n+                         int32 output_activation_max, uint8* output_data,\n+                         const Dims<4>& output_dims) {\n+  gemmlowp::ScopedProfilingLabel label(\"BroadcastDiv/8bit\");\n+\n+  NdArrayDesc<4> desc1;\n+  NdArrayDesc<4> desc2;\n+  NdArrayDescsForElementwiseBroadcast(input1_dims, input2_dims, &desc1, &desc2);\n+\n+  // In Tensorflow, the dimensions are canonically named (batch_number, row,\n+  // col, channel), with extents (batches, height, width, depth), with the\n+  // trailing dimension changing most rapidly (channels has the smallest stride,\n+  // typically 1 element).\n+  //\n+  // In generated C code, we store arrays with the dimensions reversed. The\n+  // first dimension has smallest stride.\n+  //\n+  // We name our variables by their Tensorflow convention, but generate C code\n+  // nesting loops such that the innermost loop has the smallest stride for the\n+  // best cache behavior.\n+  for (int b = 0; b < ArraySize(output_dims, 3); ++b) {\n+    for (int y = 0; y < ArraySize(output_dims, 2); ++y) {\n+      for (int x = 0; x < ArraySize(output_dims, 1); ++x) {\n+        for (int c = 0; c < ArraySize(output_dims, 0); ++c) {\n+          const int32 input1_val =\n+              input1_offset + input1_data[SubscriptToIndex(desc1, c, x, y, b)];\n+          const int32 input2_val =\n+              input2_offset + input2_data[SubscriptToIndex(desc2, c, x, y, b)];\n+          const int32 unclamped_result =\n+              output_offset +\n+              MultiplyByQuantizedMultiplierSmallerThanOne(\n+                  input1_val / input2_val, output_multiplier, output_shift);", "path": "tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h", "position": null, "original_position": 97, "commit_id": "09ab7fc83e3b2b66a2d1ff68ac6ad1b56a61fcd6", "original_commit_id": "672ec270f96144bca5e1d75d002421c1e9b49921", "user": {"login": "hovhannesgithub", "id": 8985082, "node_id": "MDQ6VXNlcjg5ODUwODI=", "avatar_url": "https://avatars1.githubusercontent.com/u/8985082?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hovhannesgithub", "html_url": "https://github.com/hovhannesgithub", "followers_url": "https://api.github.com/users/hovhannesgithub/followers", "following_url": "https://api.github.com/users/hovhannesgithub/following{/other_user}", "gists_url": "https://api.github.com/users/hovhannesgithub/gists{/gist_id}", "starred_url": "https://api.github.com/users/hovhannesgithub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hovhannesgithub/subscriptions", "organizations_url": "https://api.github.com/users/hovhannesgithub/orgs", "repos_url": "https://api.github.com/users/hovhannesgithub/repos", "events_url": "https://api.github.com/users/hovhannesgithub/events{/privacy}", "received_events_url": "https://api.github.com/users/hovhannesgithub/received_events", "type": "User", "site_admin": false}, "body": "Please can you provide more details or link to docs so I can understand quantized ops better.\r\n", "created_at": "2018-02-26T14:48:08Z", "updated_at": "2018-04-12T06:55:13Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/17123#discussion_r170614157", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17123", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/170614157"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/17123#discussion_r170614157"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17123"}}, "body_html": "<p>Please can you provide more details or link to docs so I can understand quantized ops better.</p>", "body_text": "Please can you provide more details or link to docs so I can understand quantized ops better.", "in_reply_to_id": 170039033}