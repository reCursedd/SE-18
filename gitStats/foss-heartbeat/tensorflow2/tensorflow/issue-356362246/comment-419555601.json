{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/419555601", "html_url": "https://github.com/tensorflow/tensorflow/pull/22017#issuecomment-419555601", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22017", "id": 419555601, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTU1NTYwMQ==", "user": {"login": "nfelt", "id": 710113, "node_id": "MDQ6VXNlcjcxMDExMw==", "avatar_url": "https://avatars0.githubusercontent.com/u/710113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nfelt", "html_url": "https://github.com/nfelt", "followers_url": "https://api.github.com/users/nfelt/followers", "following_url": "https://api.github.com/users/nfelt/following{/other_user}", "gists_url": "https://api.github.com/users/nfelt/gists{/gist_id}", "starred_url": "https://api.github.com/users/nfelt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nfelt/subscriptions", "organizations_url": "https://api.github.com/users/nfelt/orgs", "repos_url": "https://api.github.com/users/nfelt/repos", "events_url": "https://api.github.com/users/nfelt/events{/privacy}", "received_events_url": "https://api.github.com/users/nfelt/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-07T20:23:41Z", "updated_at": "2018-09-07T20:23:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5057740\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/feihugis\">@feihugis</a> Thank you for sending the PR.  Unfortunately, there was a miscommunication on our part - our plans for the <code>tf.summary.image()</code> op are actually to keep it narrowly focused on the minimum necessary for summary export (i.e. PNG conversion), and thus not add further normalization controls.</p>\n<p>In fact, for TF 2.0, we are planning on reducing the normalization provided by the op to just do <a href=\"https://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype\" rel=\"nofollow\"><code>tf.image.convert_image_dtype(tensor, tf.uint8, saturate=True)</code></a>.  With that change, float tensors will always be scaled according to an expected range of <code>[0.0, 1.0)</code>, so it will no longer adjust the scaling range based on the input data max and min values.  This brings it into consistency with all the various <code>tf.image.*</code> ops which only support <code>tf.image.convert_image_dtype()</code> as an input conversion.</p>\n<p>I understand that it adds some convenience to be able to use the op's built-in normalization for a wider range of numerical inputs, but ultimately it doesn't scale well to parameterize the op so that the normalization can be fine-tuned.  So for TF 2.0 we're doing only the most minimal conversion and recommending that users who need more than that do their own explicit normalization.</p>", "body_text": "@feihugis Thank you for sending the PR.  Unfortunately, there was a miscommunication on our part - our plans for the tf.summary.image() op are actually to keep it narrowly focused on the minimum necessary for summary export (i.e. PNG conversion), and thus not add further normalization controls.\nIn fact, for TF 2.0, we are planning on reducing the normalization provided by the op to just do tf.image.convert_image_dtype(tensor, tf.uint8, saturate=True).  With that change, float tensors will always be scaled according to an expected range of [0.0, 1.0), so it will no longer adjust the scaling range based on the input data max and min values.  This brings it into consistency with all the various tf.image.* ops which only support tf.image.convert_image_dtype() as an input conversion.\nI understand that it adds some convenience to be able to use the op's built-in normalization for a wider range of numerical inputs, but ultimately it doesn't scale well to parameterize the op so that the normalization can be fine-tuned.  So for TF 2.0 we're doing only the most minimal conversion and recommending that users who need more than that do their own explicit normalization.", "body": "@feihugis Thank you for sending the PR.  Unfortunately, there was a miscommunication on our part - our plans for the `tf.summary.image()` op are actually to keep it narrowly focused on the minimum necessary for summary export (i.e. PNG conversion), and thus not add further normalization controls.\r\n\r\nIn fact, for TF 2.0, we are planning on reducing the normalization provided by the op to just do [`tf.image.convert_image_dtype(tensor, tf.uint8, saturate=True)`](https://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype).  With that change, float tensors will always be scaled according to an expected range of `[0.0, 1.0)`, so it will no longer adjust the scaling range based on the input data max and min values.  This brings it into consistency with all the various `tf.image.*` ops which only support `tf.image.convert_image_dtype()` as an input conversion.\r\n\r\nI understand that it adds some convenience to be able to use the op's built-in normalization for a wider range of numerical inputs, but ultimately it doesn't scale well to parameterize the op so that the normalization can be fine-tuned.  So for TF 2.0 we're doing only the most minimal conversion and recommending that users who need more than that do their own explicit normalization."}