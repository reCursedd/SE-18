{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19337", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19337/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19337/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19337/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19337", "id": 323805320, "node_id": "MDU6SXNzdWUzMjM4MDUzMjA=", "number": 19337, "title": "tf.clip_by_value crashes for empty tensors on GPU", "user": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-05-16T22:08:35Z", "updated_at": "2018-05-18T23:37:28Z", "closed_at": "2018-05-18T23:37:28Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04.4 LTS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: <code>b'v1.8.0-0-g93bc2e2' 1.8.0</code></li>\n<li><strong>Python version</strong>: <code>Python 3.6.1 :: Continuum Analytics, Inc.</code></li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.0, cuDNN 7.0.5</li>\n<li><strong>GPU model and memory</strong>: Tesla K80, 12 GB</li>\n<li><strong>Exact command to reproduce</strong>: <code>./bug.py</code></li>\n</ul>\n<h3>Describe the problem</h3>\n<p><code>tf.clip_by_value</code> has four different kernel code paths for different shape inputs.  None of them check for empty inputs, which is necessary before calling into a cuda kernel since the infinite wisdom of cuda is that zero length loops should crash horribly.  One of the four places a check is necessary:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cwise_op_clip.cc#L48\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cwise_op_clip.cc#L48</a></p>\n<p>It ran across this in real code, but it's slightly delicate to reproduce this crash.  Therefore, I'm not sure that the check is technically necessary before all of the paths.  But it's necessary in at least one, as exhibited by the code below.  Also the code should probably be restructured: currently the same error code is repeated three times.  With that restructuring, there would also only need to be one emptiness check.</p>\n<h3>Source code / logs</h3>\n<p>This code reproduces the bug for me.  Note that it runs fine on CPU, since zero length loops on CPUs do not crash horribly:</p>\n<pre><code>#!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\n\nz = tf.placeholder(dtype=tf.float32, shape=None)\nx = tf.clip_by_value(z, 1, z)\nwith tf.Session():\n  print(x.eval(feed_dict={z: np.zeros((7,0))}).shape)\n</code></pre>\n<p>Resulting output:</p>\n<pre><code>root@azero-bug:~/tmp$ ./bug.py \n/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n2018-05-16 22:07:46.191147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 4761:00:00.0\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\n2018-05-16 22:07:46.191226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\n2018-05-16 22:07:46.514559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-16 22:07:46.514640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \n2018-05-16 22:07:46.514661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \n2018-05-16 22:07:46.514923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10755 MB memory) -&gt; physical GPU (device: 0, name: Tesla K80, pci bus id: 4761:00:00.0, compute capability: 3.7)\n2018-05-16 22:07:46.631461: F ./tensorflow/core/util/cuda_launch_config.h:127] Check failed: work_element_count &gt; 0 (0 vs. 0)\nAborted (core dumped)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.4 LTS\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): b'v1.8.0-0-g93bc2e2' 1.8.0\nPython version: Python 3.6.1 :: Continuum Analytics, Inc.\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: CUDA 9.0, cuDNN 7.0.5\nGPU model and memory: Tesla K80, 12 GB\nExact command to reproduce: ./bug.py\n\nDescribe the problem\ntf.clip_by_value has four different kernel code paths for different shape inputs.  None of them check for empty inputs, which is necessary before calling into a cuda kernel since the infinite wisdom of cuda is that zero length loops should crash horribly.  One of the four places a check is necessary:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cwise_op_clip.cc#L48\nIt ran across this in real code, but it's slightly delicate to reproduce this crash.  Therefore, I'm not sure that the check is technically necessary before all of the paths.  But it's necessary in at least one, as exhibited by the code below.  Also the code should probably be restructured: currently the same error code is repeated three times.  With that restructuring, there would also only need to be one emptiness check.\nSource code / logs\nThis code reproduces the bug for me.  Note that it runs fine on CPU, since zero length loops on CPUs do not crash horribly:\n#!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\n\nz = tf.placeholder(dtype=tf.float32, shape=None)\nx = tf.clip_by_value(z, 1, z)\nwith tf.Session():\n  print(x.eval(feed_dict={z: np.zeros((7,0))}).shape)\n\nResulting output:\nroot@azero-bug:~/tmp$ ./bug.py \n/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n2018-05-16 22:07:46.191147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 4761:00:00.0\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\n2018-05-16 22:07:46.191226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\n2018-05-16 22:07:46.514559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-16 22:07:46.514640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \n2018-05-16 22:07:46.514661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \n2018-05-16 22:07:46.514923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10755 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 4761:00:00.0, compute capability: 3.7)\n2018-05-16 22:07:46.631461: F ./tensorflow/core/util/cuda_launch_config.h:127] Check failed: work_element_count > 0 (0 vs. 0)\nAborted (core dumped)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.4 LTS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: `b'v1.8.0-0-g93bc2e2' 1.8.0`\r\n- **Python version**: `Python 3.6.1 :: Continuum Analytics, Inc.`\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA 9.0, cuDNN 7.0.5\r\n- **GPU model and memory**: Tesla K80, 12 GB\r\n- **Exact command to reproduce**: `./bug.py`\r\n\r\n### Describe the problem\r\n`tf.clip_by_value` has four different kernel code paths for different shape inputs.  None of them check for empty inputs, which is necessary before calling into a cuda kernel since the infinite wisdom of cuda is that zero length loops should crash horribly.  One of the four places a check is necessary:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cwise_op_clip.cc#L48\r\n\r\nIt ran across this in real code, but it's slightly delicate to reproduce this crash.  Therefore, I'm not sure that the check is technically necessary before all of the paths.  But it's necessary in at least one, as exhibited by the code below.  Also the code should probably be restructured: currently the same error code is repeated three times.  With that restructuring, there would also only need to be one emptiness check.\r\n\r\n### Source code / logs\r\n\r\nThis code reproduces the bug for me.  Note that it runs fine on CPU, since zero length loops on CPUs do not crash horribly:\r\n\r\n```\r\n#!/usr/bin/env python3\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nz = tf.placeholder(dtype=tf.float32, shape=None)\r\nx = tf.clip_by_value(z, 1, z)\r\nwith tf.Session():\r\n  print(x.eval(feed_dict={z: np.zeros((7,0))}).shape)\r\n```\r\n\r\nResulting output:\r\n\r\n```\r\nroot@azero-bug:~/tmp$ ./bug.py \r\n/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n2018-05-16 22:07:46.191147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 4761:00:00.0\r\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\r\n2018-05-16 22:07:46.191226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2018-05-16 22:07:46.514559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-05-16 22:07:46.514640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \r\n2018-05-16 22:07:46.514661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \r\n2018-05-16 22:07:46.514923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10755 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 4761:00:00.0, compute capability: 3.7)\r\n2018-05-16 22:07:46.631461: F ./tensorflow/core/util/cuda_launch_config.h:127] Check failed: work_element_count > 0 (0 vs. 0)\r\nAborted (core dumped)\r\n```"}