{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/305119829", "html_url": "https://github.com/tensorflow/tensorflow/issues/7664#issuecomment-305119829", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7664", "id": 305119829, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNTExOTgyOQ==", "user": {"login": "michal-kierzynka", "id": 26143310, "node_id": "MDQ6VXNlcjI2MTQzMzEw", "avatar_url": "https://avatars1.githubusercontent.com/u/26143310?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michal-kierzynka", "html_url": "https://github.com/michal-kierzynka", "followers_url": "https://api.github.com/users/michal-kierzynka/followers", "following_url": "https://api.github.com/users/michal-kierzynka/following{/other_user}", "gists_url": "https://api.github.com/users/michal-kierzynka/gists{/gist_id}", "starred_url": "https://api.github.com/users/michal-kierzynka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michal-kierzynka/subscriptions", "organizations_url": "https://api.github.com/users/michal-kierzynka/orgs", "repos_url": "https://api.github.com/users/michal-kierzynka/repos", "events_url": "https://api.github.com/users/michal-kierzynka/events{/privacy}", "received_events_url": "https://api.github.com/users/michal-kierzynka/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-31T08:19:35Z", "updated_at": "2017-05-31T08:25:58Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nI'm trying to move my LSTM network from TF v0.12 to v1.1, but its learning capabilities are very different:<br>\nin v0.12 I had:</p>\n<p>cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden, state_is_tuple=True)<br>\ncell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers)<br>\ncell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=dropout)</p>\n<p>in my TFv1.1 code I have now:</p>\n<p>cell = []<br>\nfor _ in range(num_layers):<br>\ncell.append(tf.contrib.rnn.BasicLSTMCell(num_units=n_hidden, state_is_tuple=True) )</p>\n<p>multicell = tf.contrib.rnn.MultiRNNCell([cell[i] for i in range(num_layers)])<br>\nmulticell = tf.contrib.rnn.DropoutWrapper(multicell, output_keep_prob=dropout)</p>\n<p>And these are not equivalent. The 0.12 version was learning much better than the one in 1.1. What is the reason? Did I move my code to 1.1 correctly?</p>", "body_text": "Hi,\nI'm trying to move my LSTM network from TF v0.12 to v1.1, but its learning capabilities are very different:\nin v0.12 I had:\ncell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden, state_is_tuple=True)\ncell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers)\ncell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=dropout)\nin my TFv1.1 code I have now:\ncell = []\nfor _ in range(num_layers):\ncell.append(tf.contrib.rnn.BasicLSTMCell(num_units=n_hidden, state_is_tuple=True) )\nmulticell = tf.contrib.rnn.MultiRNNCell([cell[i] for i in range(num_layers)])\nmulticell = tf.contrib.rnn.DropoutWrapper(multicell, output_keep_prob=dropout)\nAnd these are not equivalent. The 0.12 version was learning much better than the one in 1.1. What is the reason? Did I move my code to 1.1 correctly?", "body": "Hi,\r\nI'm trying to move my LSTM network from TF v0.12 to v1.1, but its learning capabilities are very different:\r\nin v0.12 I had:\r\n\r\ncell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden, state_is_tuple=True)\r\ncell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers)\r\ncell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=dropout)\r\n\r\nin my TFv1.1 code I have now:\r\n\r\ncell = []\r\nfor _ in range(num_layers):\r\n    cell.append(tf.contrib.rnn.BasicLSTMCell(num_units=n_hidden, state_is_tuple=True) )\r\n\r\nmulticell = tf.contrib.rnn.MultiRNNCell([cell[i] for i in range(num_layers)])\r\nmulticell = tf.contrib.rnn.DropoutWrapper(multicell, output_keep_prob=dropout)\r\n\r\nAnd these are not equivalent. The 0.12 version was learning much better than the one in 1.1. What is the reason? Did I move my code to 1.1 correctly?\r\n"}