{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21162", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21162/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21162/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21162/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21162", "id": 344811228, "node_id": "MDU6SXNzdWUzNDQ4MTEyMjg=", "number": 21162, "title": "Eager execution support in tf.keras fit_generator breaks Keras callbacks", "user": {"login": "smatzek", "id": 13350259, "node_id": "MDQ6VXNlcjEzMzUwMjU5", "avatar_url": "https://avatars1.githubusercontent.com/u/13350259?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smatzek", "html_url": "https://github.com/smatzek", "followers_url": "https://api.github.com/users/smatzek/followers", "following_url": "https://api.github.com/users/smatzek/following{/other_user}", "gists_url": "https://api.github.com/users/smatzek/gists{/gist_id}", "starred_url": "https://api.github.com/users/smatzek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smatzek/subscriptions", "organizations_url": "https://api.github.com/users/smatzek/orgs", "repos_url": "https://api.github.com/users/smatzek/repos", "events_url": "https://api.github.com/users/smatzek/events{/privacy}", "received_events_url": "https://api.github.com/users/smatzek/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-07-26T11:50:27Z", "updated_at": "2018-10-15T13:39:50Z", "closed_at": "2018-10-15T13:39:49Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: RHEL 7.5 ppc64le but would occur on others</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.8</li>\n<li><strong>Python version</strong>: Anaconda3, Python 3.6.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>:  N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.2</li>\n<li><strong>GPU model and memory</strong>: NVIDIA Volta V100</li>\n<li><strong>Exact command to reproduce</strong>: complicated, see below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When using tf.keras fit_generator with Keras callbacks the backward phase of the model is not present when the set_model, set_params, and on_train_begin callback methods are called.  This breaks any callback what needs the gradients, ops, etc present in the model before training begins.</p>\n<p>This change was injected by this commit for eager execution support:<br>\n<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/1b67ccbe8006eacffd268553abd01310e8b187d6#diff-abfd39a5a5f655f8d92c482e91081f8c/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/1b67ccbe8006eacffd268553abd01310e8b187d6#diff-abfd39a5a5f655f8d92c482e91081f8c\"><tt>1b67ccb</tt>#diff-abfd39a5a5f655f8d92c482e91081f8c</a></p>\n<p>The _make_train_function that was removed calls the optimizer's get_updates() method which adds all the operations under the training// scope.</p>\n<p>Once possible solution to this may be to put the calls back in but guard them with <code>if context.executing_eagerly()</code> as is done here:<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/939237af1479cf61a7c16ad4a1ead521da65a3a6/tensorflow/python/keras/engine/training.py#L1640-L1650\">tensorflow/tensorflow/python/keras/engine/training.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 1640 to 1650\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/939237af1479cf61a7c16ad4a1ead521da65a3a6\">939237a</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L1640\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1640\"></td>\n          <td id=\"LC1640\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">if</span> context.executing_eagerly(): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1641\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1641\"></td>\n          <td id=\"LC1641\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   outputs <span class=\"pl-k\">=</span> training_eager.train_on_batch( </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1642\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1642\"></td>\n          <td id=\"LC1642\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">       <span class=\"pl-c1\">self</span>, x, y, <span class=\"pl-v\">sample_weights</span><span class=\"pl-k\">=</span>sample_weights) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1643\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1643\"></td>\n          <td id=\"LC1643\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">else</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1644\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1644\"></td>\n          <td id=\"LC1644\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.uses_learning_phase <span class=\"pl-k\">and</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(K.learning_phase(), <span class=\"pl-c1\">int</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1645\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1645\"></td>\n          <td id=\"LC1645\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     ins <span class=\"pl-k\">=</span> x <span class=\"pl-k\">+</span> y <span class=\"pl-k\">+</span> sample_weights <span class=\"pl-k\">+</span> [<span class=\"pl-c1\">1</span>] </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1646\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1646\"></td>\n          <td id=\"LC1646\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-k\">else</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1647\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1647\"></td>\n          <td id=\"LC1647\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     ins <span class=\"pl-k\">=</span> x <span class=\"pl-k\">+</span> y <span class=\"pl-k\">+</span> sample_weights </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1648\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1648\"></td>\n          <td id=\"LC1648\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1649\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1649\"></td>\n          <td id=\"LC1649\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-c1\">self</span>._make_train_function() </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1650\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1650\"></td>\n          <td id=\"LC1650\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   outputs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.train_function(ins) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<h3>Source code / logs</h3>\n<p>An example of a Keras callback that depends on the full model being present when the set_model function is called is this model graph analysis / rewriting callback:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/pull/19845/files#diff-ae5805990d1ab77911507c9ae0b1cda2\">https://github.com/tensorflow/tensorflow/pull/19845/files#diff-ae5805990d1ab77911507c9ae0b1cda2</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.5 ppc64le but would occur on others\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.8\nPython version: Anaconda3, Python 3.6.4\nBazel version (if compiling from source):  N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 9.2\nGPU model and memory: NVIDIA Volta V100\nExact command to reproduce: complicated, see below\n\nDescribe the problem\nWhen using tf.keras fit_generator with Keras callbacks the backward phase of the model is not present when the set_model, set_params, and on_train_begin callback methods are called.  This breaks any callback what needs the gradients, ops, etc present in the model before training begins.\nThis change was injected by this commit for eager execution support:\n1b67ccb#diff-abfd39a5a5f655f8d92c482e91081f8c\nThe _make_train_function that was removed calls the optimizer's get_updates() method which adds all the operations under the training// scope.\nOnce possible solution to this may be to put the calls back in but guard them with if context.executing_eagerly() as is done here:\n\n  \n    \n      tensorflow/tensorflow/python/keras/engine/training.py\n    \n    \n        Lines 1640 to 1650\n      in\n      939237a\n    \n    \n    \n    \n\n        \n          \n           if context.executing_eagerly(): \n        \n\n        \n          \n             outputs = training_eager.train_on_batch( \n        \n\n        \n          \n                 self, x, y, sample_weights=sample_weights) \n        \n\n        \n          \n           else: \n        \n\n        \n          \n             if self.uses_learning_phase and not isinstance(K.learning_phase(), int): \n        \n\n        \n          \n               ins = x + y + sample_weights + [1] \n        \n\n        \n          \n             else: \n        \n\n        \n          \n               ins = x + y + sample_weights \n        \n\n        \n          \n            \n        \n\n        \n          \n             self._make_train_function() \n        \n\n        \n          \n             outputs = self.train_function(ins) \n        \n    \n  \n\n\nSource code / logs\nAn example of a Keras callback that depends on the full model being present when the set_model function is called is this model graph analysis / rewriting callback:\nhttps://github.com/tensorflow/tensorflow/pull/19845/files#diff-ae5805990d1ab77911507c9ae0b1cda2", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7.5 ppc64le but would occur on others\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: Anaconda3, Python 3.6.4\r\n- **Bazel version (if compiling from source)**:  N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.2\r\n- **GPU model and memory**: NVIDIA Volta V100\r\n- **Exact command to reproduce**: complicated, see below\r\n\r\n### Describe the problem\r\nWhen using tf.keras fit_generator with Keras callbacks the backward phase of the model is not present when the set_model, set_params, and on_train_begin callback methods are called.  This breaks any callback what needs the gradients, ops, etc present in the model before training begins.\r\n\r\nThis change was injected by this commit for eager execution support:\r\nhttps://github.com/tensorflow/tensorflow/commit/1b67ccbe8006eacffd268553abd01310e8b187d6#diff-abfd39a5a5f655f8d92c482e91081f8c\r\n\r\nThe _make_train_function that was removed calls the optimizer's get_updates() method which adds all the operations under the training/<optimizer class name>/ scope. \r\n\r\nOnce possible solution to this may be to put the calls back in but guard them with `if context.executing_eagerly()` as is done here:\r\nhttps://github.com/tensorflow/tensorflow/blob/939237af1479cf61a7c16ad4a1ead521da65a3a6/tensorflow/python/keras/engine/training.py#L1640-L1650\r\n\r\n### Source code / logs\r\nAn example of a Keras callback that depends on the full model being present when the set_model function is called is this model graph analysis / rewriting callback:\r\nhttps://github.com/tensorflow/tensorflow/pull/19845/files#diff-ae5805990d1ab77911507c9ae0b1cda2"}