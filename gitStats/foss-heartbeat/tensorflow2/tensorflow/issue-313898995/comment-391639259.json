{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/391639259", "html_url": "https://github.com/tensorflow/tensorflow/issues/18473#issuecomment-391639259", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18473", "id": 391639259, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTYzOTI1OQ==", "user": {"login": "ilya-edrenkin", "id": 13562803, "node_id": "MDQ6VXNlcjEzNTYyODAz", "avatar_url": "https://avatars2.githubusercontent.com/u/13562803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilya-edrenkin", "html_url": "https://github.com/ilya-edrenkin", "followers_url": "https://api.github.com/users/ilya-edrenkin/followers", "following_url": "https://api.github.com/users/ilya-edrenkin/following{/other_user}", "gists_url": "https://api.github.com/users/ilya-edrenkin/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilya-edrenkin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilya-edrenkin/subscriptions", "organizations_url": "https://api.github.com/users/ilya-edrenkin/orgs", "repos_url": "https://api.github.com/users/ilya-edrenkin/repos", "events_url": "https://api.github.com/users/ilya-edrenkin/events{/privacy}", "received_events_url": "https://api.github.com/users/ilya-edrenkin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-24T08:50:58Z", "updated_at": "2018-05-25T09:27:51Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi Igor <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=234070\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/isaprykin\">@isaprykin</a> ,</p>\n<p>Seems like I have hit the same problem on stock tensorflow-gpu==1.8.0rc0 on a 8-GPU machine.</p>\n<pre><code>Traceback (most recent call last):\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\n    return fn(*args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Creating a partition for /device:CPU:3 which doesn't exist in the list of available devices. Available devices: /device:CPU:0,/device:GPU:0,/device:GPU:1,/device:GPU:2,/device:GPU:3,/device:GPU:4,/device:GPU:5,/device:GPU:6,/device:GPU:7\n</code></pre>\n<p>I am using very straightforward multi-GPU setup. The relevant code fragments:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">get_available_gpus</span>():\n    local_device_protos <span class=\"pl-k\">=</span> device_lib.list_local_devices()\n    <span class=\"pl-k\">return</span> [x.name <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> local_device_protos <span class=\"pl-k\">if</span> x.device_type <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>GPU<span class=\"pl-pds\">'</span></span>]\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">build_subgraphs</span>(<span class=\"pl-smi\">net</span>, <span class=\"pl-smi\">filtered_uttids</span>, <span class=\"pl-smi\">subgraph_batch_size</span>, <span class=\"pl-smi\">chunk_size</span>, <span class=\"pl-smi\">examples</span>, <span class=\"pl-smi\">args</span>, <span class=\"pl-smi\">training</span>, <span class=\"pl-smi\">dependencies</span>):\n    iterator_initializers <span class=\"pl-k\">=</span> []\n    discriminative_objf_losses <span class=\"pl-k\">=</span> []\n    kl_losses <span class=\"pl-k\">=</span> []\n    top1_accuracies <span class=\"pl-k\">=</span> []\n    valid_examples <span class=\"pl-k\">=</span> []\n\n    gpu_devices <span class=\"pl-k\">=</span> get_available_gpus()\n    <span class=\"pl-k\">for</span> gpu_device_id, device <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(gpu_devices):\n        <span class=\"pl-c1\">READ_SIZE</span> <span class=\"pl-k\">=</span> subgraph_batch_size <span class=\"pl-k\">*</span> <span class=\"pl-c1\">PREFETCH_MULITPLIER</span>\n        dataset <span class=\"pl-k\">=</span> (tf.data.Dataset.from_tensor_slices(filtered_uttids)\n                   .shard(\n                       <span class=\"pl-v\">num_shards</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">len</span>(gpu_devices),\n                       <span class=\"pl-v\">index</span><span class=\"pl-k\">=</span>gpu_device_id)\n                   .repeat(args.num_epochs <span class=\"pl-k\">if</span> training <span class=\"pl-k\">else</span> <span class=\"pl-c1\">1</span>)\n                   .batch(subgraph_batch_size)\n                   .map(<span class=\"pl-v\">map_func</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">uttids_batch</span>:\n                        vibetflib.read_examples(\n                            <span class=\"pl-v\">examples</span><span class=\"pl-k\">=</span>examples,\n                            <span class=\"pl-v\">feature_dim</span><span class=\"pl-k\">=</span>args.feature_dim,\n                            <span class=\"pl-v\">utterance_ids</span><span class=\"pl-k\">=</span>uttids_batch,\n                            <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>chunk_size,\n                            <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>ceg_reader_chunk_<span class=\"pl-c1\">{}</span>_gpu_<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(chunk_size, gpu_device_id)),\n                        <span class=\"pl-v\">num_parallel_calls</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">PREFETCH_MULITPLIER</span>))\n\t<span class=\"pl-k\">if</span> training:\n            dataset <span class=\"pl-k\">=</span> (dataset\n                       .shuffle(\n                           <span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">READ_SIZE</span>,\n                           <span class=\"pl-v\">reshuffle_each_iteration</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n\t<span class=\"pl-k\">else</span>:\n            dataset <span class=\"pl-k\">=</span> (dataset\n                       .cache())  <span class=\"pl-c\"><span class=\"pl-c\">#</span> in memory                                                                                                                                                                      </span>\n\n\titerator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator() <span class=\"pl-k\">if</span> training <span class=\"pl-k\">else</span> dataset.make_initializable_iterator()\n        <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> training:\n            iterator_initializers.append(iterator.initializer)\n        mats, targets, expected_output_seqlen <span class=\"pl-k\">=</span> iterator.get_next()\n        mats.set_shape([<span class=\"pl-c1\">None</span>, chunk_size, args.feature_dim])\n        <span class=\"pl-k\">with</span> tf.device(device):\n            discriminative_outputs, xent_outputs <span class=\"pl-k\">=</span> net(mats, expected_output_seqlen, args, <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span>training)\n                discriminative_objf, _, posteriors <span class=\"pl-k\">=</span> vibetflib.compute_loss(\n                    <span class=\"pl-v\">targets</span><span class=\"pl-k\">=</span>targets,\n                    <span class=\"pl-v\">discriminative_outputs</span><span class=\"pl-k\">=</span>discriminative_outputs,\n                    <span class=\"pl-v\">num_nnet_outputs</span><span class=\"pl-k\">=</span>args.num_nnet_outputs)\n            <span class=\"pl-c1\">...</span></pre></div>\n<p>So I basically just iterate over GPUs and create subgraphs. <code>net</code> is a subgraph template.</p>\n<p>This problem didn't arise on 1-GPU and 2-GPU machines.</p>\n<p>My case can be complicated by the fact that <code>vibetflib</code> is an in-house tensorflow extension which also uses GPU. However, it doesn't seem to be the case for <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=28333746\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/advaza\">@advaza</a> -- so the problem could indeed lie within tensorflow itself.</p>\n<p>Thanks!</p>", "body_text": "Hi Igor @isaprykin ,\nSeems like I have hit the same problem on stock tensorflow-gpu==1.8.0rc0 on a 8-GPU machine.\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\n    return fn(*args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Creating a partition for /device:CPU:3 which doesn't exist in the list of available devices. Available devices: /device:CPU:0,/device:GPU:0,/device:GPU:1,/device:GPU:2,/device:GPU:3,/device:GPU:4,/device:GPU:5,/device:GPU:6,/device:GPU:7\n\nI am using very straightforward multi-GPU setup. The relevant code fragments:\ndef get_available_gpus():\n    local_device_protos = device_lib.list_local_devices()\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n\ndef build_subgraphs(net, filtered_uttids, subgraph_batch_size, chunk_size, examples, args, training, dependencies):\n    iterator_initializers = []\n    discriminative_objf_losses = []\n    kl_losses = []\n    top1_accuracies = []\n    valid_examples = []\n\n    gpu_devices = get_available_gpus()\n    for gpu_device_id, device in enumerate(gpu_devices):\n        READ_SIZE = subgraph_batch_size * PREFETCH_MULITPLIER\n        dataset = (tf.data.Dataset.from_tensor_slices(filtered_uttids)\n                   .shard(\n                       num_shards=len(gpu_devices),\n                       index=gpu_device_id)\n                   .repeat(args.num_epochs if training else 1)\n                   .batch(subgraph_batch_size)\n                   .map(map_func=lambda uttids_batch:\n                        vibetflib.read_examples(\n                            examples=examples,\n                            feature_dim=args.feature_dim,\n                            utterance_ids=uttids_batch,\n                            sequence_length=chunk_size,\n                            name='ceg_reader_chunk_{}_gpu_{}'.format(chunk_size, gpu_device_id)),\n                        num_parallel_calls=PREFETCH_MULITPLIER))\n\tif training:\n            dataset = (dataset\n                       .shuffle(\n                           buffer_size=READ_SIZE,\n                           reshuffle_each_iteration=True))\n\telse:\n            dataset = (dataset\n                       .cache())  # in memory                                                                                                                                                                      \n\n\titerator = dataset.make_one_shot_iterator() if training else dataset.make_initializable_iterator()\n        if not training:\n            iterator_initializers.append(iterator.initializer)\n        mats, targets, expected_output_seqlen = iterator.get_next()\n        mats.set_shape([None, chunk_size, args.feature_dim])\n        with tf.device(device):\n            discriminative_outputs, xent_outputs = net(mats, expected_output_seqlen, args, training=training)\n                discriminative_objf, _, posteriors = vibetflib.compute_loss(\n                    targets=targets,\n                    discriminative_outputs=discriminative_outputs,\n                    num_nnet_outputs=args.num_nnet_outputs)\n            ...\nSo I basically just iterate over GPUs and create subgraphs. net is a subgraph template.\nThis problem didn't arise on 1-GPU and 2-GPU machines.\nMy case can be complicated by the fact that vibetflib is an in-house tensorflow extension which also uses GPU. However, it doesn't seem to be the case for @advaza -- so the problem could indeed lie within tensorflow itself.\nThanks!", "body": "Hi Igor @isaprykin ,\r\n\r\nSeems like I have hit the same problem on stock tensorflow-gpu==1.8.0rc0 on a 8-GPU machine.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Creating a partition for /device:CPU:3 which doesn't exist in the list of available devices. Available devices: /device:CPU:0,/device:GPU:0,/device:GPU:1,/device:GPU:2,/device:GPU:3,/device:GPU:4,/device:GPU:5,/device:GPU:6,/device:GPU:7\r\n```\r\n\r\nI am using very straightforward multi-GPU setup. The relevant code fragments:\r\n\r\n```python\r\ndef get_available_gpus():\r\n    local_device_protos = device_lib.list_local_devices()\r\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\r\n\r\ndef build_subgraphs(net, filtered_uttids, subgraph_batch_size, chunk_size, examples, args, training, dependencies):\r\n    iterator_initializers = []\r\n    discriminative_objf_losses = []\r\n    kl_losses = []\r\n    top1_accuracies = []\r\n    valid_examples = []\r\n\r\n    gpu_devices = get_available_gpus()\r\n    for gpu_device_id, device in enumerate(gpu_devices):\r\n        READ_SIZE = subgraph_batch_size * PREFETCH_MULITPLIER\r\n        dataset = (tf.data.Dataset.from_tensor_slices(filtered_uttids)\r\n                   .shard(\r\n                       num_shards=len(gpu_devices),\r\n                       index=gpu_device_id)\r\n                   .repeat(args.num_epochs if training else 1)\r\n                   .batch(subgraph_batch_size)\r\n                   .map(map_func=lambda uttids_batch:\r\n                        vibetflib.read_examples(\r\n                            examples=examples,\r\n                            feature_dim=args.feature_dim,\r\n                            utterance_ids=uttids_batch,\r\n                            sequence_length=chunk_size,\r\n                            name='ceg_reader_chunk_{}_gpu_{}'.format(chunk_size, gpu_device_id)),\r\n                        num_parallel_calls=PREFETCH_MULITPLIER))\r\n\tif training:\r\n            dataset = (dataset\r\n                       .shuffle(\r\n                           buffer_size=READ_SIZE,\r\n                           reshuffle_each_iteration=True))\r\n\telse:\r\n            dataset = (dataset\r\n                       .cache())  # in memory                                                                                                                                                                      \r\n\r\n\titerator = dataset.make_one_shot_iterator() if training else dataset.make_initializable_iterator()\r\n        if not training:\r\n            iterator_initializers.append(iterator.initializer)\r\n        mats, targets, expected_output_seqlen = iterator.get_next()\r\n        mats.set_shape([None, chunk_size, args.feature_dim])\r\n        with tf.device(device):\r\n            discriminative_outputs, xent_outputs = net(mats, expected_output_seqlen, args, training=training)\r\n                discriminative_objf, _, posteriors = vibetflib.compute_loss(\r\n                    targets=targets,\r\n                    discriminative_outputs=discriminative_outputs,\r\n                    num_nnet_outputs=args.num_nnet_outputs)\r\n            ...\r\n```\r\n\r\nSo I basically just iterate over GPUs and create subgraphs. `net` is a subgraph template.\r\n\r\nThis problem didn't arise on 1-GPU and 2-GPU machines.\r\n\r\nMy case can be complicated by the fact that `vibetflib` is an in-house tensorflow extension which also uses GPU. However, it doesn't seem to be the case for @advaza -- so the problem could indeed lie within tensorflow itself.\r\n\r\nThanks!"}