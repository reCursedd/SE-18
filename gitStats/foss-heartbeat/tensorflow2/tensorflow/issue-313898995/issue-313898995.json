{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18473", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18473/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18473/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18473/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18473", "id": 313898995, "node_id": "MDU6SXNzdWUzMTM4OTg5OTU=", "number": 18473, "title": "Error when trying to use tf.contrib.distribute.MirroredStrategy in tf.estimator", "user": {"login": "advaza", "id": 28333746, "node_id": "MDQ6VXNlcjI4MzMzNzQ2", "avatar_url": "https://avatars3.githubusercontent.com/u/28333746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/advaza", "html_url": "https://github.com/advaza", "followers_url": "https://api.github.com/users/advaza/followers", "following_url": "https://api.github.com/users/advaza/following{/other_user}", "gists_url": "https://api.github.com/users/advaza/gists{/gist_id}", "starred_url": "https://api.github.com/users/advaza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/advaza/subscriptions", "organizations_url": "https://api.github.com/users/advaza/orgs", "repos_url": "https://api.github.com/users/advaza/repos", "events_url": "https://api.github.com/users/advaza/events{/privacy}", "received_events_url": "https://api.github.com/users/advaza/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "isaprykin", "id": 234070, "node_id": "MDQ6VXNlcjIzNDA3MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/234070?v=4", "gravatar_id": "", "url": "https://api.github.com/users/isaprykin", "html_url": "https://github.com/isaprykin", "followers_url": "https://api.github.com/users/isaprykin/followers", "following_url": "https://api.github.com/users/isaprykin/following{/other_user}", "gists_url": "https://api.github.com/users/isaprykin/gists{/gist_id}", "starred_url": "https://api.github.com/users/isaprykin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/isaprykin/subscriptions", "organizations_url": "https://api.github.com/users/isaprykin/orgs", "repos_url": "https://api.github.com/users/isaprykin/repos", "events_url": "https://api.github.com/users/isaprykin/events{/privacy}", "received_events_url": "https://api.github.com/users/isaprykin/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "isaprykin", "id": 234070, "node_id": "MDQ6VXNlcjIzNDA3MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/234070?v=4", "gravatar_id": "", "url": "https://api.github.com/users/isaprykin", "html_url": "https://github.com/isaprykin", "followers_url": "https://api.github.com/users/isaprykin/followers", "following_url": "https://api.github.com/users/isaprykin/following{/other_user}", "gists_url": "https://api.github.com/users/isaprykin/gists{/gist_id}", "starred_url": "https://api.github.com/users/isaprykin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/isaprykin/subscriptions", "organizations_url": "https://api.github.com/users/isaprykin/orgs", "repos_url": "https://api.github.com/users/isaprykin/repos", "events_url": "https://api.github.com/users/isaprykin/events{/privacy}", "received_events_url": "https://api.github.com/users/isaprykin/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 18, "created_at": "2018-04-12T21:46:46Z", "updated_at": "2018-05-25T09:27:51Z", "closed_at": "2018-05-24T19:02:03Z", "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li><strong>OS Platform and Distribution</strong>:  Linux Ubuntu 16.04.2</li>\n<li><strong>TensorFlow installed from</strong>: source</li>\n<li><strong>TensorFlow version</strong>: 1.7</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version</strong>: 0.11.1</li>\n<li><strong>GCC/Compiler version</strong>: 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: 9/7</li>\n<li><strong>GPU model and memory</strong>: TITAN X (Pascal) 11170 MB memory</li>\n</ul>\n<p>I'm trying to add multi-gpu support to my tensorflow training code using tf.contrib.distribute.MirroredStrategy as a parameter to tf.estimator.RunConfig.<br>\nI get the following error message:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower\n    self, *merge_args, **merge_kwargs)\n  File \"python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 667, in _distributed_apply\n    reduced_grads = distribution.batch_reduce(\"sum\", grads_and_vars)\n  File \"python3.5/site-packages/tensorflow/python/training/distribute.py\", line 801, in batch_reduce\n    return self._batch_reduce(method_string, value_destination_pairs)\n  File \"python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 295, in _batch_reduce\n    value_destination_pairs)\n  File \"python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 169, in batch_reduce\n    raise ValueError(\"`value_destination_pairs` must be a list or a tuple of \"\nValueError: `value_destination_pairs` must be a list or a tuple of tuples of PerDevice objects and destinations \n</code></pre>\n<p>The following code produces the error (I omitted the code for parsing the tfrecord to image tensor as I don't believe this code effects the error, but I can add it if necessary):</p>\n\n<pre><code>import glob, os\nimport tensorflow as tf\nslim = tf.contrib.slim\n\n# Initialization of args - arguments parser.\ndef init():\n    pass\n\n\ndef input_fn():\n\n    dataset = tf.data.TFRecordDataset(glob.glob(os.path.join(args.train_data_dir, 'train*')))\n    dataset = dataset.map(\n                lambda x: parse_and_preprocess_image(x, args.image_size),\n                num_parallel_calls=2,\n    )\n    dataset = dataset.repeat()\n    dataset = dataset.batch(batch_size=4)\n    dataset = dataset.prefetch(1)\n\n    return dataset\n\n\ndef model_fn(features, labels=None, mode=tf.estimator.ModeKeys.TRAIN, params=None):\n\n    train_images_batch = features\n    res = slim.conv2d(inputs=train_images_batch, kernel_size=9, stride=1, num_outputs=3, scope='conv1')\n    loss = tf.reduce_mean((train_images_batch - res) ** 2)\n    optimizer = tf.train.AdamOptimizer(0.001)\n    train_op = slim.learning.create_train_op(loss, optimizer)\n    return tf.estimator.EstimatorSpec(\n        mode=tf.estimator.ModeKeys.TRAIN,\n        loss=loss, train_op=train_op)\n\n\ndef train():\n\n    init()\n\n    distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=args.num_gpus)\n\n    config = tf.estimator.RunConfig(\n        model_dir=args.log_dir,\n        train_distribute=distribution,\n    )\n\n    estimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\n    estimator.train(\n            input_fn=input_fn,\n            max_steps=args.train_steps,\n        )\n\n\ndef main():\n    train()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n<p>Thank you!<br>\nAdva</p>", "body_text": "System information\n\nOS Platform and Distribution:  Linux Ubuntu 16.04.2\nTensorFlow installed from: source\nTensorFlow version: 1.7\nPython version: 3.5\nBazel version: 0.11.1\nGCC/Compiler version: 5.4.0\nCUDA/cuDNN version: 9/7\nGPU model and memory: TITAN X (Pascal) 11170 MB memory\n\nI'm trying to add multi-gpu support to my tensorflow training code using tf.contrib.distribute.MirroredStrategy as a parameter to tf.estimator.RunConfig.\nI get the following error message:\n\nTraceback (most recent call last):\n  File \"python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower\n    self, *merge_args, **merge_kwargs)\n  File \"python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 667, in _distributed_apply\n    reduced_grads = distribution.batch_reduce(\"sum\", grads_and_vars)\n  File \"python3.5/site-packages/tensorflow/python/training/distribute.py\", line 801, in batch_reduce\n    return self._batch_reduce(method_string, value_destination_pairs)\n  File \"python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 295, in _batch_reduce\n    value_destination_pairs)\n  File \"python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 169, in batch_reduce\n    raise ValueError(\"`value_destination_pairs` must be a list or a tuple of \"\nValueError: `value_destination_pairs` must be a list or a tuple of tuples of PerDevice objects and destinations \n\nThe following code produces the error (I omitted the code for parsing the tfrecord to image tensor as I don't believe this code effects the error, but I can add it if necessary):\n\nimport glob, os\nimport tensorflow as tf\nslim = tf.contrib.slim\n\n# Initialization of args - arguments parser.\ndef init():\n    pass\n\n\ndef input_fn():\n\n    dataset = tf.data.TFRecordDataset(glob.glob(os.path.join(args.train_data_dir, 'train*')))\n    dataset = dataset.map(\n                lambda x: parse_and_preprocess_image(x, args.image_size),\n                num_parallel_calls=2,\n    )\n    dataset = dataset.repeat()\n    dataset = dataset.batch(batch_size=4)\n    dataset = dataset.prefetch(1)\n\n    return dataset\n\n\ndef model_fn(features, labels=None, mode=tf.estimator.ModeKeys.TRAIN, params=None):\n\n    train_images_batch = features\n    res = slim.conv2d(inputs=train_images_batch, kernel_size=9, stride=1, num_outputs=3, scope='conv1')\n    loss = tf.reduce_mean((train_images_batch - res) ** 2)\n    optimizer = tf.train.AdamOptimizer(0.001)\n    train_op = slim.learning.create_train_op(loss, optimizer)\n    return tf.estimator.EstimatorSpec(\n        mode=tf.estimator.ModeKeys.TRAIN,\n        loss=loss, train_op=train_op)\n\n\ndef train():\n\n    init()\n\n    distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=args.num_gpus)\n\n    config = tf.estimator.RunConfig(\n        model_dir=args.log_dir,\n        train_distribute=distribution,\n    )\n\n    estimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\n    estimator.train(\n            input_fn=input_fn,\n            max_steps=args.train_steps,\n        )\n\n\ndef main():\n    train()\n\n\nif __name__ == '__main__':\n    main()\n\nThank you!\nAdva", "body": "**System information**\r\n- **OS Platform and Distribution**:  Linux Ubuntu 16.04.2\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: 1.7\r\n- **Python version**: 3.5\r\n- **Bazel version**: 0.11.1\r\n- **GCC/Compiler version**: 5.4.0\r\n- **CUDA/cuDNN version**: 9/7\r\n- **GPU model and memory**: TITAN X (Pascal) 11170 MB memory\r\n\r\nI'm trying to add multi-gpu support to my tensorflow training code using tf.contrib.distribute.MirroredStrategy as a parameter to tf.estimator.RunConfig. \r\nI get the following error message: \r\n\r\n<!-- language: python -->\r\n\r\n    Traceback (most recent call last):\r\n      File \"python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n        yield\r\n      File \"python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower\r\n        self, *merge_args, **merge_kwargs)\r\n      File \"python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 667, in _distributed_apply\r\n        reduced_grads = distribution.batch_reduce(\"sum\", grads_and_vars)\r\n      File \"python3.5/site-packages/tensorflow/python/training/distribute.py\", line 801, in batch_reduce\r\n        return self._batch_reduce(method_string, value_destination_pairs)\r\n      File \"python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 295, in _batch_reduce\r\n        value_destination_pairs)\r\n      File \"python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 169, in batch_reduce\r\n        raise ValueError(\"`value_destination_pairs` must be a list or a tuple of \"\r\n    ValueError: `value_destination_pairs` must be a list or a tuple of tuples of PerDevice objects and destinations \r\n\r\nThe following code produces the error (I omitted the code for parsing the tfrecord to image tensor as I don't believe this code effects the error, but I can add it if necessary):\r\n\r\n<!-- language: python -->\r\n    \r\n    import glob, os\r\n    import tensorflow as tf\r\n    slim = tf.contrib.slim\r\n    \r\n    # Initialization of args - arguments parser.\r\n    def init():\r\n        pass\r\n \r\n\r\n    def input_fn():\r\n    \r\n        dataset = tf.data.TFRecordDataset(glob.glob(os.path.join(args.train_data_dir, 'train*')))\r\n        dataset = dataset.map(\r\n                    lambda x: parse_and_preprocess_image(x, args.image_size),\r\n                    num_parallel_calls=2,\r\n        )\r\n        dataset = dataset.repeat()\r\n        dataset = dataset.batch(batch_size=4)\r\n        dataset = dataset.prefetch(1)\r\n    \r\n        return dataset\r\n    \r\n    \r\n    def model_fn(features, labels=None, mode=tf.estimator.ModeKeys.TRAIN, params=None):\r\n    \r\n        train_images_batch = features\r\n        res = slim.conv2d(inputs=train_images_batch, kernel_size=9, stride=1, num_outputs=3, scope='conv1')\r\n        loss = tf.reduce_mean((train_images_batch - res) ** 2)\r\n        optimizer = tf.train.AdamOptimizer(0.001)\r\n        train_op = slim.learning.create_train_op(loss, optimizer)\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=tf.estimator.ModeKeys.TRAIN,\r\n            loss=loss, train_op=train_op)\r\n    \r\n    \r\n    def train():\r\n    \r\n        init()\r\n    \r\n        distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=args.num_gpus)\r\n    \r\n        config = tf.estimator.RunConfig(\r\n            model_dir=args.log_dir,\r\n            train_distribute=distribution,\r\n        )\r\n    \r\n        estimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\r\n        estimator.train(\r\n                input_fn=input_fn,\r\n                max_steps=args.train_steps,\r\n            )\r\n    \r\n    \r\n    def main():\r\n        train()\r\n    \r\n    \r\n    if __name__ == '__main__':\r\n        main()\r\n\r\n\r\nThank you!\r\nAdva\r\n\r\n\r\n"}