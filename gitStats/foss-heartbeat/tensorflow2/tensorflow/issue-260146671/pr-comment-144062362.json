{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/144062362", "pull_request_review_id": 68666433, "id": 144062362, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NDA2MjM2Mg==", "diff_hunk": "@@ -0,0 +1,210 @@\n+# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+\n+import time\n+\n+\n+from tensorflow.python.framework import ops\n+from tensorflow.python.platform import tf_logging as logging\n+from tensorflow.python.training import basic_session_run_hooks\n+from tensorflow.python.training import monitored_session\n+from tensorflow.python.training import saver\n+from tensorflow.python.training import session_run_hook\n+\n+\n+class CheckpointRestorerHook(session_run_hook.SessionRunHook):\n+  \"\"\"Restores checkpoints after tf.Session is created.\"\"\"\n+\n+  def __init__(self,\n+               checkpoint_dir=None,\n+               checkpoint_file=None,\n+               var_list=None,\n+               wait_for_checkpoint=False,\n+               max_wait_secs=7200,\n+               recovery_wait_secs=30,\n+               ):\n+    \"\"\"Initializes a `CheckpointRestorerHook`.\n+\n+    Args:\n+      checkpoint_dir: `str`, base directory for the checkpoint files.\n+      checkpoint_file: `str`, path name for the checkpoint file.\n+        only one of `checkpoint_file` and `checkpoint_dir` should be\n+        not None.\n+      var_list: `list`, optional, the list of variables to be restored.\n+        If None, all global variables defined would be restored.\n+      wait_for_checkpoint: Whether to wait for checkpoint to become available.\n+      max_wait_secs: Maximum time to wait for checkpoints to become available.\n+      recovery_wait_secs: Interval between checkpoint checks when waiting for\n+        checkpoint.\n+\n+    Use `CheckpointRestorerHook` with MonitoredSession to restore a\n+    training session from checkpoint, especially when only part of checkpoint\n+    variables are intended to be restored.\n+\n+    See `PartialRestoreSession` as a full example of usage.\n+\n+    \"\"\"\n+    logging.info(\"Create CheckpointRestorerHook.\")\n+    super(CheckpointRestorerHook, self).__init__()\n+    self._dir, self._file, self._var_list = checkpoint_dir, checkpoint_file, var_list\n+    self._wait_for_checkpoint, self._max_wait_secs, self._recovery_wait_secs = \\\n+        wait_for_checkpoint, max_wait_secs, recovery_wait_secs\n+    self._saver = saver.Saver(var_list=self._var_list)\n+\n+  def after_create_session(self, session, coord):\n+    super(CheckpointRestorerHook, self).after_create_session(session, coord)\n+\n+    if self._file:\n+      self._saver.restore(session, self._file)\n+      return\n+    wait_time = 0\n+    ckpt = saver.get_checkpoint_state(self._dir)\n+    while not ckpt or not ckpt.model_checkpoint_path:\n+      if self._wait_for_checkpoint and wait_time < self._max_wait_secs:\n+        logging.info(\"Waiting for checkpoint to be available.\")\n+        time.sleep(self._recovery_wait_secs)\n+        wait_time += self._recovery_wait_secs\n+        ckpt = saver.get_checkpoint_state(self._dir)\n+      else:\n+        return\n+\n+    # Loads the checkpoint.\n+    self._saver.restore(session, ckpt.model_checkpoint_path)\n+    self._saver.recover_last_checkpoints(ckpt.all_model_checkpoint_paths)\n+\n+\n+def PartialRestoreSession(master='',  # pylint: disable=invalid-name", "path": "tensorflow/contrib/training/python/training/partial_restore_session.py", "position": 94, "original_position": 94, "commit_id": "cf48e62f1cf0e26d850c3a5a27cbf75ad3f37d20", "original_commit_id": "cf48e62f1cf0e26d850c3a5a27cbf75ad3f37d20", "user": {"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}, "body": "PartialRestoreSession is a replication of MonitoredTrainingSession. I think we should not introduce a duplicated functionality until we verify usefulness of CheckpointRestorerHook.\r\n\r\nAFAIU, the part you want to reuse is the code block under 'if checkpoint_dir'. I still think we should only add the hook in this PR. You can give an example usage in the pydoc of the hook. The code is simpler then this function. \r\nOnly confusing part may be the summary hooks. You can create a utility function 'create_summary_hooks' to share code.\r\n", "created_at": "2017-10-11T16:20:56Z", "updated_at": "2017-10-11T16:21:05Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13284#discussion_r144062362", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13284", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/144062362"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13284#discussion_r144062362"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13284"}}, "body_html": "<p>PartialRestoreSession is a replication of MonitoredTrainingSession. I think we should not introduce a duplicated functionality until we verify usefulness of CheckpointRestorerHook.</p>\n<p>AFAIU, the part you want to reuse is the code block under 'if checkpoint_dir'. I still think we should only add the hook in this PR. You can give an example usage in the pydoc of the hook. The code is simpler then this function.<br>\nOnly confusing part may be the summary hooks. You can create a utility function 'create_summary_hooks' to share code.</p>", "body_text": "PartialRestoreSession is a replication of MonitoredTrainingSession. I think we should not introduce a duplicated functionality until we verify usefulness of CheckpointRestorerHook.\nAFAIU, the part you want to reuse is the code block under 'if checkpoint_dir'. I still think we should only add the hook in this PR. You can give an example usage in the pydoc of the hook. The code is simpler then this function.\nOnly confusing part may be the summary hooks. You can create a utility function 'create_summary_hooks' to share code."}