{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7445", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7445/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7445/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7445/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7445", "id": 207024306, "node_id": "MDU6SXNzdWUyMDcwMjQzMDY=", "number": 7445, "title": "memory overflow when processing Variable.eval()", "user": {"login": "lemmonation", "id": 9084510, "node_id": "MDQ6VXNlcjkwODQ1MTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9084510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lemmonation", "html_url": "https://github.com/lemmonation", "followers_url": "https://api.github.com/users/lemmonation/followers", "following_url": "https://api.github.com/users/lemmonation/following{/other_user}", "gists_url": "https://api.github.com/users/lemmonation/gists{/gist_id}", "starred_url": "https://api.github.com/users/lemmonation/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lemmonation/subscriptions", "organizations_url": "https://api.github.com/users/lemmonation/orgs", "repos_url": "https://api.github.com/users/lemmonation/repos", "events_url": "https://api.github.com/users/lemmonation/events{/privacy}", "received_events_url": "https://api.github.com/users/lemmonation/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-12T02:39:04Z", "updated_at": "2017-07-07T04:19:47Z", "closed_at": "2017-02-12T07:14:47Z", "author_association": "NONE", "body_html": "<p>I'm using Tensorflow to process a simple matrix factorization algorithm. Every step went correct but at the last step, where I want to <code>eval()</code> a Tensor to store it, the program didn't work and only occupied more and more memory. I tried to <code>eval()</code> the initial parameters before the algorithm, it correctly processed. Then I'm confused where the bug is.<br>\nCore code is as follows.</p>\n<pre><code>\nclass model(object):\n    def __init__(self, others):\n        self.D = tf.constant(D, dtype = tf.float32)\n        self.Q = tf.constant(Q, dtype = tf.float32)\n        self.W = tf.Variable((np.random.rand(self.rank, sample_num)), dtype = tf.float32, name = 'W')\n        self.C = tf.Variable((np.random.rand(context_num, self.rank)), dtype = tf.float32, name = 'C')\n\n    def _run(self, sess):\n        Q = self.Q\n        D = self.D\n        W = self.W\n        print W.eval()     #correct results\n        C = self.C\n        #the optimization step, you can jump this because I think it's not the point\n        for i in xrange(self.max_iter):\n            if (i + 1) % 2 == 1:\n                for j in xrange(self.inner_maxiter):\n                    ED = tf.transpose(Q) * (1.0 / (1.0 + tf.exp(- tf.matmul(C, W))))\n                    recons = D - ED\n                    W_grad = tf.matmul(tf.transpose(C), recons)\n                    W = W + self.stepsize * W_grad\n            else:\n                for j in xrange(self.inner_maxiter):\n                    ED = tf.transpose(Q) * (1.0 / (1.0 + tf.exp(- tf.matmul(C, W))))\n                    recons = D - ED\n                    C_grad = tf.matmul(recons, tf.transpose(W))\n                    C = C + self.stepsize * C_grad\n            print 'epoch: %d' % i\n        \n        print W.eval()  #program stopped and occupying memory \n        print C.eval()\n\ntrain_epoch = model(D, Q, others)\nwith tf.Session(config = config) as sess:\n    tf.initialize_all_variables().run()\n    train_epoch._run(sess)\n</code></pre>\n<p>It's fairly strange because eval() just work well before the optimization step, but crashed after it. Is this a bug in eval()?</p>", "body_text": "I'm using Tensorflow to process a simple matrix factorization algorithm. Every step went correct but at the last step, where I want to eval() a Tensor to store it, the program didn't work and only occupied more and more memory. I tried to eval() the initial parameters before the algorithm, it correctly processed. Then I'm confused where the bug is.\nCore code is as follows.\n\nclass model(object):\n    def __init__(self, others):\n        self.D = tf.constant(D, dtype = tf.float32)\n        self.Q = tf.constant(Q, dtype = tf.float32)\n        self.W = tf.Variable((np.random.rand(self.rank, sample_num)), dtype = tf.float32, name = 'W')\n        self.C = tf.Variable((np.random.rand(context_num, self.rank)), dtype = tf.float32, name = 'C')\n\n    def _run(self, sess):\n        Q = self.Q\n        D = self.D\n        W = self.W\n        print W.eval()     #correct results\n        C = self.C\n        #the optimization step, you can jump this because I think it's not the point\n        for i in xrange(self.max_iter):\n            if (i + 1) % 2 == 1:\n                for j in xrange(self.inner_maxiter):\n                    ED = tf.transpose(Q) * (1.0 / (1.0 + tf.exp(- tf.matmul(C, W))))\n                    recons = D - ED\n                    W_grad = tf.matmul(tf.transpose(C), recons)\n                    W = W + self.stepsize * W_grad\n            else:\n                for j in xrange(self.inner_maxiter):\n                    ED = tf.transpose(Q) * (1.0 / (1.0 + tf.exp(- tf.matmul(C, W))))\n                    recons = D - ED\n                    C_grad = tf.matmul(recons, tf.transpose(W))\n                    C = C + self.stepsize * C_grad\n            print 'epoch: %d' % i\n        \n        print W.eval()  #program stopped and occupying memory \n        print C.eval()\n\ntrain_epoch = model(D, Q, others)\nwith tf.Session(config = config) as sess:\n    tf.initialize_all_variables().run()\n    train_epoch._run(sess)\n\nIt's fairly strange because eval() just work well before the optimization step, but crashed after it. Is this a bug in eval()?", "body": "I'm using Tensorflow to process a simple matrix factorization algorithm. Every step went correct but at the last step, where I want to `eval()` a Tensor to store it, the program didn't work and only occupied more and more memory. I tried to `eval()` the initial parameters before the algorithm, it correctly processed. Then I'm confused where the bug is.\r\nCore code is as follows.\r\n```\r\n\r\nclass model(object):\r\n    def __init__(self, others):\r\n        self.D = tf.constant(D, dtype = tf.float32)\r\n        self.Q = tf.constant(Q, dtype = tf.float32)\r\n        self.W = tf.Variable((np.random.rand(self.rank, sample_num)), dtype = tf.float32, name = 'W')\r\n        self.C = tf.Variable((np.random.rand(context_num, self.rank)), dtype = tf.float32, name = 'C')\r\n\r\n    def _run(self, sess):\r\n        Q = self.Q\r\n        D = self.D\r\n        W = self.W\r\n        print W.eval()     #correct results\r\n        C = self.C\r\n        #the optimization step, you can jump this because I think it's not the point\r\n        for i in xrange(self.max_iter):\r\n            if (i + 1) % 2 == 1:\r\n                for j in xrange(self.inner_maxiter):\r\n                    ED = tf.transpose(Q) * (1.0 / (1.0 + tf.exp(- tf.matmul(C, W))))\r\n                    recons = D - ED\r\n                    W_grad = tf.matmul(tf.transpose(C), recons)\r\n                    W = W + self.stepsize * W_grad\r\n            else:\r\n                for j in xrange(self.inner_maxiter):\r\n                    ED = tf.transpose(Q) * (1.0 / (1.0 + tf.exp(- tf.matmul(C, W))))\r\n                    recons = D - ED\r\n                    C_grad = tf.matmul(recons, tf.transpose(W))\r\n                    C = C + self.stepsize * C_grad\r\n            print 'epoch: %d' % i\r\n        \r\n        print W.eval()  #program stopped and occupying memory \r\n        print C.eval()\r\n\r\ntrain_epoch = model(D, Q, others)\r\nwith tf.Session(config = config) as sess:\r\n    tf.initialize_all_variables().run()\r\n    train_epoch._run(sess)\r\n```\r\n\r\nIt's fairly strange because eval() just work well before the optimization step, but crashed after it. Is this a bug in eval()?"}