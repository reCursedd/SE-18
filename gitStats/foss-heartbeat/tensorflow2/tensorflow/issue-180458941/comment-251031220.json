{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/251031220", "html_url": "https://github.com/tensorflow/tensorflow/issues/4706#issuecomment-251031220", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4706", "id": 251031220, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MTAzMTIyMA==", "user": {"login": "concretevitamin", "id": 592670, "node_id": "MDQ6VXNlcjU5MjY3MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/592670?v=4", "gravatar_id": "", "url": "https://api.github.com/users/concretevitamin", "html_url": "https://github.com/concretevitamin", "followers_url": "https://api.github.com/users/concretevitamin/followers", "following_url": "https://api.github.com/users/concretevitamin/following{/other_user}", "gists_url": "https://api.github.com/users/concretevitamin/gists{/gist_id}", "starred_url": "https://api.github.com/users/concretevitamin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/concretevitamin/subscriptions", "organizations_url": "https://api.github.com/users/concretevitamin/orgs", "repos_url": "https://api.github.com/users/concretevitamin/repos", "events_url": "https://api.github.com/users/concretevitamin/events{/privacy}", "received_events_url": "https://api.github.com/users/concretevitamin/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-03T05:48:59Z", "updated_at": "2016-10-03T05:48:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6323467\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/chenghuige\">@chenghuige</a>: what do you mean by \"only running on one\"?  To me, this means setting <code>CUDA_VISIBLE_DEVICES</code>.  If you instead mean that you use <code>with tf.device(\"/gpu:0\")</code> exclusively in your code, then when initializing the TensorFlow runtime, it would have no way to <em>know</em> just one GPU is going to be used.</p>", "body_text": "@chenghuige: what do you mean by \"only running on one\"?  To me, this means setting CUDA_VISIBLE_DEVICES.  If you instead mean that you use with tf.device(\"/gpu:0\") exclusively in your code, then when initializing the TensorFlow runtime, it would have no way to know just one GPU is going to be used.", "body": "@chenghuige: what do you mean by \"only running on one\"?  To me, this means setting `CUDA_VISIBLE_DEVICES`.  If you instead mean that you use `with tf.device(\"/gpu:0\")` exclusively in your code, then when initializing the TensorFlow runtime, it would have no way to _know_ just one GPU is going to be used.\n"}