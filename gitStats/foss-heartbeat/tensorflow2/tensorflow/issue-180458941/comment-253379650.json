{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/253379650", "html_url": "https://github.com/tensorflow/tensorflow/issues/4706#issuecomment-253379650", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4706", "id": 253379650, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MzM3OTY1MA==", "user": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-13T00:42:36Z", "updated_at": "2016-10-13T00:42:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think the problem is that there's an Eigen scratch allocator in the GPUDevice constructor that allocates memory on the GPU.  Before r0.11, the call was directly calling cuMalloc instead of going through our allocator, and so although some memory was used on the GPU, it wasn't going through our allocator so the whole thing wasn't being taken.  But to properly track memory usage, we make all of our calls now go through the allocator, so GPUDevice construction now unfortunately allocates all the memory.</p>\n<p>Two solutions:</p>\n<ol>\n<li>\n<p>We lazily allocate the scratch allocator space instead of eagerly doing it in the constructor (not sure where / when we would do this though).</p>\n</li>\n<li>\n<p>You can set the 'allow_growth' option in ConfigProto.GPUOptions so that the initial allocation doesn't cause all of the GPU memory to be allocated.</p>\n</li>\n</ol>", "body_text": "I think the problem is that there's an Eigen scratch allocator in the GPUDevice constructor that allocates memory on the GPU.  Before r0.11, the call was directly calling cuMalloc instead of going through our allocator, and so although some memory was used on the GPU, it wasn't going through our allocator so the whole thing wasn't being taken.  But to properly track memory usage, we make all of our calls now go through the allocator, so GPUDevice construction now unfortunately allocates all the memory.\nTwo solutions:\n\n\nWe lazily allocate the scratch allocator space instead of eagerly doing it in the constructor (not sure where / when we would do this though).\n\n\nYou can set the 'allow_growth' option in ConfigProto.GPUOptions so that the initial allocation doesn't cause all of the GPU memory to be allocated.", "body": "I think the problem is that there's an Eigen scratch allocator in the GPUDevice constructor that allocates memory on the GPU.  Before r0.11, the call was directly calling cuMalloc instead of going through our allocator, and so although some memory was used on the GPU, it wasn't going through our allocator so the whole thing wasn't being taken.  But to properly track memory usage, we make all of our calls now go through the allocator, so GPUDevice construction now unfortunately allocates all the memory.\n\nTwo solutions: \n\n1) We lazily allocate the scratch allocator space instead of eagerly doing it in the constructor (not sure where / when we would do this though).\n\n2) You can set the 'allow_growth' option in ConfigProto.GPUOptions so that the initial allocation doesn't cause all of the GPU memory to be allocated.\n"}