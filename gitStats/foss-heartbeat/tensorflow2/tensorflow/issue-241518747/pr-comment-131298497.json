{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/131298497", "pull_request_review_id": 54265596, "id": 131298497, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzMTI5ODQ5Nw==", "diff_hunk": "@@ -0,0 +1,608 @@\n+#ifdef TENSORFLOW_USE_GDR\n+\n+#include \"tensorflow/contrib/gdr/gdr_memory_manager.h\"\n+\n+#include <atomic>\n+#include <cerrno>\n+#include <fstream>\n+#include <list>\n+#include <map>\n+\n+#include <fcntl.h>\n+#include <rdma/rdma_cma.h>\n+#include <rdma/rdma_verbs.h>\n+#include <sys/epoll.h>\n+\n+#include \"tensorflow/contrib/gdr/gdr.pb.h\"\n+#include \"tensorflow/core/common_runtime/bfc_allocator.h\"\n+#include \"tensorflow/core/common_runtime/device.h\"\n+#include \"tensorflow/core/common_runtime/dma_helper.h\"\n+#if GOOGLE_CUDA\n+#include \"tensorflow/core/common_runtime/gpu/gpu_util.h\"\n+#include \"tensorflow/core/common_runtime/gpu/process_state.h\"\n+#endif  // GOOGLE_CUDA\n+#include \"tensorflow/core/framework/allocator_registry.h\"\n+#include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/platform/macros.h\"\n+#include \"tensorflow/core/platform/mutex.h\"\n+\n+namespace tensorflow {\n+\n+namespace {\n+\n+bool IsGDRAvailable() {\n+  std::ifstream ifs(\"/proc/modules\");\n+  string line;\n+  while (std::getline(ifs, line)) {\n+    auto sep = line.find(' ');\n+    CHECK_NE(sep, std::string::npos);\n+    if (line.substr(0, sep) == \"nv_peer_mem\") {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+int TryToReadNumaNode(ibv_device* device) {\n+  static const int kUnknownNumaNode = -1;\n+\n+  auto filename = string(device->ibdev_path) + \"/device/numa_node\";\n+\n+  std::ifstream ifs(filename.c_str());\n+  string content;\n+  CHECK(std::getline(ifs, content));\n+\n+  int32 value;\n+  if (strings::safe_strto32(content, &value)) {\n+    if (value < 0) {\n+      LOG(INFO) << \"Successful NUMA node read from SysFS had negative value (\"\n+                << value << \"), but there must be at least one NUMA node\"\n+                            \", so returning NUMA node zero\";\n+      return 0;\n+    }\n+    LOG(INFO) << \"NUMA node for device: \" << device->name << \" is \" << value;\n+    return value;\n+  }\n+  return kUnknownNumaNode;\n+}\n+\n+void EndpointDeleter(rdma_cm_id* id) {\n+  if (id) {\n+    rdma_destroy_ep(id);\n+  }\n+}\n+\n+void MRDeleter(ibv_mr* mr) {\n+  if (mr) {\n+    rdma_dereg_mr(mr);\n+  }\n+}\n+\n+using RdmaEndpointPtr = std::unique_ptr<rdma_cm_id, decltype(&EndpointDeleter)>;\n+\n+using MemoryRegionPtr = std::unique_ptr<ibv_mr, decltype(&MRDeleter)>;\n+\n+class GdrMemoryManager : public RemoteMemoryManager {\n+ public:\n+  GdrMemoryManager(const string& host, const string& port);\n+\n+  virtual ~GdrMemoryManager();\n+\n+  virtual Status Init() override;\n+\n+  virtual void Run() override;\n+\n+  virtual void Stop() override;\n+\n+  virtual Status TransportOptionsFromTensor(\n+      ::google::protobuf::Any* mutable_transport_options, const Tensor& tensor,\n+      Device* device, DeviceContext* device_context, bool on_host) override;\n+\n+  virtual Status TensorFromTransportOptions(\n+      Tensor* tensor, const ::google::protobuf::Any& transport_options,\n+      Device* device, DeviceContext* device_context, bool on_host) override;\n+\n+ protected:\n+  Status CreateEndpoint(const string& host, const string& port,\n+                        RdmaEndpointPtr& endpoint);\n+\n+  static bool Comparator(const void* ptr, const MemoryRegionPtr& other) {\n+    return ptr < reinterpret_cast<char*>(other->addr) + other->length;\n+  }\n+\n+  ibv_mr* FindMemoryRegion(void* addr, size_t length);\n+\n+  void InsertMemoryRegion(void* addr, size_t length);\n+\n+  void EvictMemoryRegion(void* addr, size_t length);\n+\n+ private:\n+  const string host_;\n+  const string port_;\n+  RdmaEndpointPtr listening_;\n+  std::atomic<bool> stopped_;\n+  int epfd_;\n+\n+  // Server side endpoints\n+  // Accessed sequentially in Run() so not protected by lock\n+  std::list<RdmaEndpointPtr> server_clients_;\n+\n+  using TensorKey = uint32_t;\n+  std::atomic<TensorKey> next_key_;\n+\n+  // Server side on-the-fly tensor buffers\n+  mutex server_mu_;\n+  std::map<TensorKey, const TensorBuffer*> tensor_buffers_\n+      GUARDED_BY(server_mu_);\n+\n+  // Client side endpoints\n+  mutex client_mu_;\n+  std::map<std::pair<string, string>, RdmaEndpointPtr> clients_\n+      GUARDED_BY(cient_mu_);\n+\n+  // Managed memory regions\n+  mutex alloc_mu_;\n+  std::vector<MemoryRegionPtr> mrs_ GUARDED_BY(alloc_mu_);\n+\n+  TF_DISALLOW_COPY_AND_ASSIGN(GdrMemoryManager);\n+};\n+\n+class BasicCPUAllocator : public SubAllocator {\n+ public:\n+  ~BasicCPUAllocator() override {}\n+\n+  void* Alloc(size_t alignment, size_t num_bytes) override {\n+    return port::AlignedMalloc(num_bytes, alignment);\n+  }\n+  void Free(void* ptr, size_t) override { port::AlignedFree(ptr); }\n+};\n+\n+class BFCRdmaAllocator : public BFCAllocator {\n+ public:\n+  BFCRdmaAllocator()\n+      : BFCAllocator(new BasicCPUAllocator(), 1LL << 36, true, \"cpu_rdma_bfc\") {\n+  }\n+};\n+\n+REGISTER_MEM_ALLOCATOR(\"BFCRdmaAllocator\", 300, BFCRdmaAllocator);\n+\n+GdrMemoryManager::GdrMemoryManager(const string& host, const string& port)", "path": "tensorflow/contrib/gdr/gdr_memory_manager.cc", "position": null, "original_position": 169, "commit_id": "241c020c64410ca16683a7a7f42b223f422e5dae", "original_commit_id": "955764316dd9c796db874ae2034e336a48b1fb46", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "body": "Yes, this is designed to be consistent with the `server_def` [passed into gRPC server construction](https://github.com/red-bird/tensorflow/blob/955764316dd9c796db874ae2034e336a48b1fb46/tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc#L137) (each process listen to a particular TCP/IP address, which [propagates to here](https://github.com/red-bird/tensorflow/blob/955764316dd9c796db874ae2034e336a48b1fb46/tensorflow/contrib/gdr/gdr_server_lib.cc#L14)).\r\n\r\nAs a side note, I have not figured out a viable design to accommodate multiple IB interfaces yet. For the NICs I know of, there could actually be multiple ports on the same NIC (connected to different switches, as in our case),  so there are some potentials doing link level aggregation for load-balancing or fault-tolerance. And then of course there could be multiple NICs (as in DGX-1) to serve on different buses, which leaves interesting potentials doing request routing using device localities in the future.", "created_at": "2017-08-04T02:03:04Z", "updated_at": "2017-08-08T01:02:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11392#discussion_r131298497", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11392", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/131298497"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11392#discussion_r131298497"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11392"}}, "body_html": "<p>Yes, this is designed to be consistent with the <code>server_def</code> <a href=\"https://github.com/red-bird/tensorflow/blob/955764316dd9c796db874ae2034e336a48b1fb46/tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc#L137\">passed into gRPC server construction</a> (each process listen to a particular TCP/IP address, which <a href=\"https://github.com/red-bird/tensorflow/blob/955764316dd9c796db874ae2034e336a48b1fb46/tensorflow/contrib/gdr/gdr_server_lib.cc#L14\">propagates to here</a>).</p>\n<p>As a side note, I have not figured out a viable design to accommodate multiple IB interfaces yet. For the NICs I know of, there could actually be multiple ports on the same NIC (connected to different switches, as in our case),  so there are some potentials doing link level aggregation for load-balancing or fault-tolerance. And then of course there could be multiple NICs (as in DGX-1) to serve on different buses, which leaves interesting potentials doing request routing using device localities in the future.</p>", "body_text": "Yes, this is designed to be consistent with the server_def passed into gRPC server construction (each process listen to a particular TCP/IP address, which propagates to here).\nAs a side note, I have not figured out a viable design to accommodate multiple IB interfaces yet. For the NICs I know of, there could actually be multiple ports on the same NIC (connected to different switches, as in our case),  so there are some potentials doing link level aggregation for load-balancing or fault-tolerance. And then of course there could be multiple NICs (as in DGX-1) to serve on different buses, which leaves interesting potentials doing request routing using device localities in the future.", "in_reply_to_id": 131212452}