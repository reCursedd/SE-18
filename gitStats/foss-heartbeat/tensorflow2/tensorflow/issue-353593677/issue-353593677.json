{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21836", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21836/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21836/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21836/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21836", "id": 353593677, "node_id": "MDU6SXNzdWUzNTM1OTM2Nzc=", "number": 21836, "title": "tf.test.is_gpu_available(True) allocates all GPU(s) VRAM", "user": {"login": "BrianPugh", "id": 14318576, "node_id": "MDQ6VXNlcjE0MzE4NTc2", "avatar_url": "https://avatars3.githubusercontent.com/u/14318576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BrianPugh", "html_url": "https://github.com/BrianPugh", "followers_url": "https://api.github.com/users/BrianPugh/followers", "following_url": "https://api.github.com/users/BrianPugh/following{/other_user}", "gists_url": "https://api.github.com/users/BrianPugh/gists{/gist_id}", "starred_url": "https://api.github.com/users/BrianPugh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BrianPugh/subscriptions", "organizations_url": "https://api.github.com/users/BrianPugh/orgs", "repos_url": "https://api.github.com/users/BrianPugh/repos", "events_url": "https://api.github.com/users/BrianPugh/events{/privacy}", "received_events_url": "https://api.github.com/users/BrianPugh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-08-23T23:46:06Z", "updated_at": "2018-11-22T18:57:57Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:  1.10.0-devel-gpu-py3</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.0-devel-gpu-py3</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA: V9.0.176 cuDNN: V7.1.4</li>\n<li><strong>GPU model and memory</strong>: 2x 1080ti 11GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>import tensorflow as tf\n\ndata_format = 'channels_first' if tf.test.is_gpu_available(True) \\\n    else 'channels_last'\n# At this point, all memory is allocated across all GPUs\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsess = tf.Session(config=config)\n# All VRAM still allocated\n</code></pre>\n<h3>Describe the problem</h3>\n<p>Using tf.test.is_gpu_available(True) to check if a system GPU is available allocates all the VRAM available.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary):  1.10.0-devel-gpu-py3\nTensorFlow version (use command below): 1.10.0-devel-gpu-py3\nPython version: 3.5.2\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: CUDA: V9.0.176 cuDNN: V7.1.4\nGPU model and memory: 2x 1080ti 11GB\nExact command to reproduce:\n\nimport tensorflow as tf\n\ndata_format = 'channels_first' if tf.test.is_gpu_available(True) \\\n    else 'channels_last'\n# At this point, all memory is allocated across all GPUs\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsess = tf.Session(config=config)\n# All VRAM still allocated\n\nDescribe the problem\nUsing tf.test.is_gpu_available(True) to check if a system GPU is available allocates all the VRAM available.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**:  1.10.0-devel-gpu-py3\r\n- **TensorFlow version (use command below)**: 1.10.0-devel-gpu-py3\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA: V9.0.176 cuDNN: V7.1.4\r\n- **GPU model and memory**: 2x 1080ti 11GB\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndata_format = 'channels_first' if tf.test.is_gpu_available(True) \\\r\n    else 'channels_last'\r\n# At this point, all memory is allocated across all GPUs\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.Session(config=config)\r\n# All VRAM still allocated\r\n```\r\n\r\n### Describe the problem\r\nUsing tf.test.is_gpu_available(True) to check if a system GPU is available allocates all the VRAM available."}