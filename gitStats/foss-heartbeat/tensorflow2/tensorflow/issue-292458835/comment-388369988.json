{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/388369988", "html_url": "https://github.com/tensorflow/tensorflow/issues/16545#issuecomment-388369988", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16545", "id": 388369988, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODM2OTk4OA==", "user": {"login": "LucasMahieu", "id": 12006816, "node_id": "MDQ6VXNlcjEyMDA2ODE2", "avatar_url": "https://avatars3.githubusercontent.com/u/12006816?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LucasMahieu", "html_url": "https://github.com/LucasMahieu", "followers_url": "https://api.github.com/users/LucasMahieu/followers", "following_url": "https://api.github.com/users/LucasMahieu/following{/other_user}", "gists_url": "https://api.github.com/users/LucasMahieu/gists{/gist_id}", "starred_url": "https://api.github.com/users/LucasMahieu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LucasMahieu/subscriptions", "organizations_url": "https://api.github.com/users/LucasMahieu/orgs", "repos_url": "https://api.github.com/users/LucasMahieu/repos", "events_url": "https://api.github.com/users/LucasMahieu/events{/privacy}", "received_events_url": "https://api.github.com/users/LucasMahieu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-11T13:52:11Z", "updated_at": "2018-05-11T13:52:11Z", "author_association": "NONE", "body_html": "<p>The problem is still not solved...</p>\n<p>Given this example :</p>\n<pre><code>name: \"input\"\nop: \"Placeholder\"\nattr {\n  key: \"dtype\"\n  value {\n    type: DT_FLOAT\n  }\n}\nname: \"Pad\"\nop: \"Pad\"\ninput: \"input\"\ninput: \"Pad/paddings\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\n</code></pre>\n<p>The fold_constant() transformation change the name of the input tensor from \"input\" to \"input:0\".<br>\nBut the node named input is still named \"input\" and not \"input:0\".<br>\nlike this :</p>\n<pre><code>name: \"input\"\nop: \"Placeholder\"\nattr {\n  key: \"dtype\"\n  value {\n    type: DT_FLOAT\n  }\n}\nname: \"Pad\"\nop: \"Pad\"\ninput: \"input:0\"\ninput: \"Pad/paddings\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\n</code></pre>\n<p>So, after this transformation of the graph, the connection between the input node \"input\" and the next node is broken.</p>\n<p>(The input placeholder is not connected any more to the Pad node...)</p>", "body_text": "The problem is still not solved...\nGiven this example :\nname: \"input\"\nop: \"Placeholder\"\nattr {\n  key: \"dtype\"\n  value {\n    type: DT_FLOAT\n  }\n}\nname: \"Pad\"\nop: \"Pad\"\ninput: \"input\"\ninput: \"Pad/paddings\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\n\nThe fold_constant() transformation change the name of the input tensor from \"input\" to \"input:0\".\nBut the node named input is still named \"input\" and not \"input:0\".\nlike this :\nname: \"input\"\nop: \"Placeholder\"\nattr {\n  key: \"dtype\"\n  value {\n    type: DT_FLOAT\n  }\n}\nname: \"Pad\"\nop: \"Pad\"\ninput: \"input:0\"\ninput: \"Pad/paddings\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\n\nSo, after this transformation of the graph, the connection between the input node \"input\" and the next node is broken.\n(The input placeholder is not connected any more to the Pad node...)", "body": "The problem is still not solved...\r\n\r\nGiven this example : \r\n```\r\nname: \"input\"\r\nop: \"Placeholder\"\r\nattr {\r\n  key: \"dtype\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nname: \"Pad\"\r\nop: \"Pad\"\r\ninput: \"input\"\r\ninput: \"Pad/paddings\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\n```\r\n\r\nThe fold_constant() transformation change the name of the input tensor from \"input\" to \"input:0\".\r\nBut the node named input is still named \"input\" and not \"input:0\". \r\nlike this : \r\n```\r\nname: \"input\"\r\nop: \"Placeholder\"\r\nattr {\r\n  key: \"dtype\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nname: \"Pad\"\r\nop: \"Pad\"\r\ninput: \"input:0\"\r\ninput: \"Pad/paddings\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\n```\r\n\r\nSo, after this transformation of the graph, the connection between the input node \"input\" and the next node is broken.\r\n\r\n(The input placeholder is not connected any more to the Pad node...)"}