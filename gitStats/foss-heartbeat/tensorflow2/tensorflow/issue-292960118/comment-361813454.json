{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/361813454", "html_url": "https://github.com/tensorflow/tensorflow/issues/16606#issuecomment-361813454", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16606", "id": 361813454, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTgxMzQ1NA==", "user": {"login": "lrigazio", "id": 689295, "node_id": "MDQ6VXNlcjY4OTI5NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/689295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lrigazio", "html_url": "https://github.com/lrigazio", "followers_url": "https://api.github.com/users/lrigazio/followers", "following_url": "https://api.github.com/users/lrigazio/following{/other_user}", "gists_url": "https://api.github.com/users/lrigazio/gists{/gist_id}", "starred_url": "https://api.github.com/users/lrigazio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lrigazio/subscriptions", "organizations_url": "https://api.github.com/users/lrigazio/orgs", "repos_url": "https://api.github.com/users/lrigazio/repos", "events_url": "https://api.github.com/users/lrigazio/events{/privacy}", "received_events_url": "https://api.github.com/users/lrigazio/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-31T03:34:58Z", "updated_at": "2018-01-31T03:34:58Z", "author_association": "NONE", "body_html": "<p>here, I made it nice and self-contained -- just run this --</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">fix_sample_and_rebalance</span>(<span class=\"pl-smi\">which</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>works<span class=\"pl-pds\">'</span></span>):\n    class_num<span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">get_data_breaks</span>(<span class=\"pl-smi\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>):\n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">sample</span>(<span class=\"pl-smi\">data</span>, <span class=\"pl-smi\">label</span>): <span class=\"pl-c\"><span class=\"pl-c\">#</span> sample detection window inside chunk</span>\n            xx <span class=\"pl-k\">=</span> tf.cast(tf.random_uniform([<span class=\"pl-c1\">1</span>])<span class=\"pl-k\">*</span>class_num, tf.int32)[<span class=\"pl-c1\">0</span>]\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> with tf.control_dependencies([xx]): tf.Print(xx , [xx], 'xx&gt;&gt;')</span>\n            <span class=\"pl-k\">return</span> xx, xx\n\n        initial_dist<span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span>class_num <span class=\"pl-k\">for</span> cc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(class_num)]\n        classes <span class=\"pl-k\">=</span> np.random.choice(class_num,<span class=\"pl-c1\">20000</span>,<span class=\"pl-v\">p</span><span class=\"pl-k\">=</span>initial_dist)\n\n        data_ph <span class=\"pl-k\">=</span> tf.placeholder(classes.dtype, classes.shape)\n        labels_ph <span class=\"pl-k\">=</span> tf.placeholder(classes.dtype, classes.shape)\n        dataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\n\n        dataset <span class=\"pl-k\">=</span> dataset.map(sample, <span class=\"pl-v\">num_parallel_calls</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n        target_dist<span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span>class_num <span class=\"pl-k\">for</span> cc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(class_num)]\n        target_dist[<span class=\"pl-c1\">1</span>]<span class=\"pl-k\">+=</span>target_dist[<span class=\"pl-c1\">0</span>] ; target_dist[<span class=\"pl-c1\">0</span>]<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>target-dist&gt;&gt;<span class=\"pl-pds\">'</span></span>, target_dist)\n        initial_dist <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n        dataset <span class=\"pl-k\">=</span> dataset.apply(tf.contrib.data.rejection_resample(\n                    <span class=\"pl-v\">class_func</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">c</span>, <span class=\"pl-smi\">_</span>: c,\n                    <span class=\"pl-v\">target_dist</span><span class=\"pl-k\">=</span>target_dist,\n                    <span class=\"pl-v\">initial_dist</span><span class=\"pl-k\">=</span>initial_dist,\n                    <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">42</span>)).map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">a</span>,<span class=\"pl-smi\">b</span>: b)\n\n        dataset <span class=\"pl-k\">=</span> dataset.repeat(<span class=\"pl-c1\">None</span>)\n        iterator <span class=\"pl-k\">=</span> dataset.make_initializable_iterator()\n        iterator_initializer_func <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">sess</span>: sess.run(iterator.initializer,\n                        <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{data_ph: classes, labels_ph: classes})\n\n        <span class=\"pl-k\">return</span> iterator.get_next(), iterator_initializer_func\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">get_data_works</span>(<span class=\"pl-smi\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>):\n        initial_dist<span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span>class_num <span class=\"pl-k\">for</span> cc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(class_num)]\n        classes <span class=\"pl-k\">=</span> np.random.choice(class_num,<span class=\"pl-c1\">20000</span>,<span class=\"pl-v\">p</span><span class=\"pl-k\">=</span>initial_dist)\n\n        data_ph <span class=\"pl-k\">=</span> tf.placeholder(classes.dtype, classes.shape)\n        labels_ph <span class=\"pl-k\">=</span> tf.placeholder(classes.dtype, classes.shape)\n        dataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\n\n        target_dist<span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span>class_num <span class=\"pl-k\">for</span> cc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(class_num)]\n        target_dist[<span class=\"pl-c1\">1</span>]<span class=\"pl-k\">+=</span>target_dist[<span class=\"pl-c1\">0</span>] ; target_dist[<span class=\"pl-c1\">0</span>]<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>target-dist&gt;&gt;<span class=\"pl-pds\">'</span></span>, target_dist)\n        initial_dist <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n        dataset <span class=\"pl-k\">=</span> dataset.apply(tf.contrib.data.rejection_resample(\n                    <span class=\"pl-v\">class_func</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">c</span>, <span class=\"pl-smi\">_</span>: c,\n                    <span class=\"pl-v\">target_dist</span><span class=\"pl-k\">=</span>target_dist,\n                    <span class=\"pl-v\">initial_dist</span><span class=\"pl-k\">=</span>initial_dist,\n                    <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">42</span>)).map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">a</span>,<span class=\"pl-smi\">b</span>: b)\n\n        dataset <span class=\"pl-k\">=</span> dataset.repeat(<span class=\"pl-c1\">None</span>)\n        iterator <span class=\"pl-k\">=</span> dataset.make_initializable_iterator()\n        iterator_initializer_func <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">sess</span>: sess.run(iterator.initializer,\n                        <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{data_ph: classes, labels_ph: classes})\n\n        <span class=\"pl-k\">return</span> iterator.get_next(), iterator_initializer_func\n\n\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        <span class=\"pl-k\">if</span> which <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>works<span class=\"pl-pds\">'</span></span>:\n            get_next, iterator_initializer_func <span class=\"pl-k\">=</span> get_data_works()\n        <span class=\"pl-k\">else</span>:\n            get_next, iterator_initializer_func <span class=\"pl-k\">=</span> get_data_breaks()\n        iterator_initializer_func(sess)\n        returned <span class=\"pl-k\">=</span> []\n        <span class=\"pl-k\">for</span> kk <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">10000</span>):\n            <span class=\"pl-k\">try</span>:\n                sample<span class=\"pl-k\">=</span>sess.run(get_next)\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> print(sample[0].shape, sample[1].shape, sample[1])</span>\n                returned.append(sample[<span class=\"pl-c1\">0</span>])\n                <span class=\"pl-c1\">print</span>(np.bincount(np.array(returned)))\n            <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError:\n                <span class=\"pl-k\">break</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> output is nice and (un)balanced 0 on first class 2x on second and then all unif</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> [   0 2485 1284 1267 1271 1228 1250 1215]</span>\nfix_sample_and_rebalance()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> output shows po(x)==pi(x) -- rejection_resample didn't do nada~niente~nulla!</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> [1193 1247 1267 1341 1264 1260 1191 1237]</span>\nfix_sample_and_rebalance(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>breaks<span class=\"pl-pds\">'</span></span>)</pre></div>", "body_text": "here, I made it nice and self-contained -- just run this --\nimport numpy as np\nimport tensorflow as tf\n\ndef fix_sample_and_rebalance(which='works'):\n    class_num=8\n    def get_data_breaks(batch_size=1):\n        def sample(data, label): # sample detection window inside chunk\n            xx = tf.cast(tf.random_uniform([1])*class_num, tf.int32)[0]\n            # with tf.control_dependencies([xx]): tf.Print(xx , [xx], 'xx>>')\n            return xx, xx\n\n        initial_dist=[1.0/class_num for cc in range(class_num)]\n        classes = np.random.choice(class_num,20000,p=initial_dist)\n\n        data_ph = tf.placeholder(classes.dtype, classes.shape)\n        labels_ph = tf.placeholder(classes.dtype, classes.shape)\n        dataset = tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\n\n        dataset = dataset.map(sample, num_parallel_calls=1)\n\n        target_dist=[1.0/class_num for cc in range(class_num)]\n        target_dist[1]+=target_dist[0] ; target_dist[0]=0\n        print('target-dist>>', target_dist)\n        initial_dist = None\n\n        dataset = dataset.apply(tf.contrib.data.rejection_resample(\n                    class_func=lambda c, _: c,\n                    target_dist=target_dist,\n                    initial_dist=initial_dist,\n                    seed=42)).map(lambda a,b: b)\n\n        dataset = dataset.repeat(None)\n        iterator = dataset.make_initializable_iterator()\n        iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\n                        feed_dict={data_ph: classes, labels_ph: classes})\n\n        return iterator.get_next(), iterator_initializer_func\n\n    def get_data_works(batch_size=1):\n        initial_dist=[1.0/class_num for cc in range(class_num)]\n        classes = np.random.choice(class_num,20000,p=initial_dist)\n\n        data_ph = tf.placeholder(classes.dtype, classes.shape)\n        labels_ph = tf.placeholder(classes.dtype, classes.shape)\n        dataset = tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\n\n        target_dist=[1.0/class_num for cc in range(class_num)]\n        target_dist[1]+=target_dist[0] ; target_dist[0]=0\n        print('target-dist>>', target_dist)\n        initial_dist = None\n\n        dataset = dataset.apply(tf.contrib.data.rejection_resample(\n                    class_func=lambda c, _: c,\n                    target_dist=target_dist,\n                    initial_dist=initial_dist,\n                    seed=42)).map(lambda a,b: b)\n\n        dataset = dataset.repeat(None)\n        iterator = dataset.make_initializable_iterator()\n        iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\n                        feed_dict={data_ph: classes, labels_ph: classes})\n\n        return iterator.get_next(), iterator_initializer_func\n\n\n    with tf.Session() as sess:\n        if which == 'works':\n            get_next, iterator_initializer_func = get_data_works()\n        else:\n            get_next, iterator_initializer_func = get_data_breaks()\n        iterator_initializer_func(sess)\n        returned = []\n        for kk in range(0,10000):\n            try:\n                sample=sess.run(get_next)\n                # print(sample[0].shape, sample[1].shape, sample[1])\n                returned.append(sample[0])\n                print(np.bincount(np.array(returned)))\n            except tf.errors.OutOfRangeError:\n                break\n\n# output is nice and (un)balanced 0 on first class 2x on second and then all unif\n# [   0 2485 1284 1267 1271 1228 1250 1215]\nfix_sample_and_rebalance()\n\n# output shows po(x)==pi(x) -- rejection_resample didn't do nada~niente~nulla!\n# [1193 1247 1267 1341 1264 1260 1191 1237]\nfix_sample_and_rebalance('breaks')", "body": "here, I made it nice and self-contained -- just run this --\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef fix_sample_and_rebalance(which='works'):\r\n    class_num=8\r\n    def get_data_breaks(batch_size=1):\r\n        def sample(data, label): # sample detection window inside chunk\r\n            xx = tf.cast(tf.random_uniform([1])*class_num, tf.int32)[0]\r\n            # with tf.control_dependencies([xx]): tf.Print(xx , [xx], 'xx>>')\r\n            return xx, xx\r\n\r\n        initial_dist=[1.0/class_num for cc in range(class_num)]\r\n        classes = np.random.choice(class_num,20000,p=initial_dist)\r\n\r\n        data_ph = tf.placeholder(classes.dtype, classes.shape)\r\n        labels_ph = tf.placeholder(classes.dtype, classes.shape)\r\n        dataset = tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\r\n\r\n        dataset = dataset.map(sample, num_parallel_calls=1)\r\n\r\n        target_dist=[1.0/class_num for cc in range(class_num)]\r\n        target_dist[1]+=target_dist[0] ; target_dist[0]=0\r\n        print('target-dist>>', target_dist)\r\n        initial_dist = None\r\n\r\n        dataset = dataset.apply(tf.contrib.data.rejection_resample(\r\n                    class_func=lambda c, _: c,\r\n                    target_dist=target_dist,\r\n                    initial_dist=initial_dist,\r\n                    seed=42)).map(lambda a,b: b)\r\n\r\n        dataset = dataset.repeat(None)\r\n        iterator = dataset.make_initializable_iterator()\r\n        iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\r\n                        feed_dict={data_ph: classes, labels_ph: classes})\r\n\r\n        return iterator.get_next(), iterator_initializer_func\r\n\r\n    def get_data_works(batch_size=1):\r\n        initial_dist=[1.0/class_num for cc in range(class_num)]\r\n        classes = np.random.choice(class_num,20000,p=initial_dist)\r\n\r\n        data_ph = tf.placeholder(classes.dtype, classes.shape)\r\n        labels_ph = tf.placeholder(classes.dtype, classes.shape)\r\n        dataset = tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\r\n\r\n        target_dist=[1.0/class_num for cc in range(class_num)]\r\n        target_dist[1]+=target_dist[0] ; target_dist[0]=0\r\n        print('target-dist>>', target_dist)\r\n        initial_dist = None\r\n\r\n        dataset = dataset.apply(tf.contrib.data.rejection_resample(\r\n                    class_func=lambda c, _: c,\r\n                    target_dist=target_dist,\r\n                    initial_dist=initial_dist,\r\n                    seed=42)).map(lambda a,b: b)\r\n\r\n        dataset = dataset.repeat(None)\r\n        iterator = dataset.make_initializable_iterator()\r\n        iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\r\n                        feed_dict={data_ph: classes, labels_ph: classes})\r\n\r\n        return iterator.get_next(), iterator_initializer_func\r\n\r\n\r\n    with tf.Session() as sess:\r\n        if which == 'works':\r\n            get_next, iterator_initializer_func = get_data_works()\r\n        else:\r\n            get_next, iterator_initializer_func = get_data_breaks()\r\n        iterator_initializer_func(sess)\r\n        returned = []\r\n        for kk in range(0,10000):\r\n            try:\r\n                sample=sess.run(get_next)\r\n                # print(sample[0].shape, sample[1].shape, sample[1])\r\n                returned.append(sample[0])\r\n                print(np.bincount(np.array(returned)))\r\n            except tf.errors.OutOfRangeError:\r\n                break\r\n\r\n# output is nice and (un)balanced 0 on first class 2x on second and then all unif\r\n# [   0 2485 1284 1267 1271 1228 1250 1215]\r\nfix_sample_and_rebalance()\r\n\r\n# output shows po(x)==pi(x) -- rejection_resample didn't do nada~niente~nulla!\r\n# [1193 1247 1267 1341 1264 1260 1191 1237]\r\nfix_sample_and_rebalance('breaks')\r\n"}