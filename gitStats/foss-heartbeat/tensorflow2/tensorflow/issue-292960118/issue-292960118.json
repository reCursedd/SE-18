{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16606", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16606/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16606/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16606/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16606", "id": 292960118, "node_id": "MDU6SXNzdWUyOTI5NjAxMTg=", "number": 16606, "title": "tf.contrib.data.rejection_resample not balancing class/freq on random crops", "user": {"login": "lrigazio", "id": 689295, "node_id": "MDQ6VXNlcjY4OTI5NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/689295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lrigazio", "html_url": "https://github.com/lrigazio", "followers_url": "https://api.github.com/users/lrigazio/followers", "following_url": "https://api.github.com/users/lrigazio/following{/other_user}", "gists_url": "https://api.github.com/users/lrigazio/gists{/gist_id}", "starred_url": "https://api.github.com/users/lrigazio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lrigazio/subscriptions", "organizations_url": "https://api.github.com/users/lrigazio/orgs", "repos_url": "https://api.github.com/users/lrigazio/repos", "events_url": "https://api.github.com/users/lrigazio/events{/privacy}", "received_events_url": "https://api.github.com/users/lrigazio/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "joel-shor", "id": 6020988, "node_id": "MDQ6VXNlcjYwMjA5ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/6020988?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joel-shor", "html_url": "https://github.com/joel-shor", "followers_url": "https://api.github.com/users/joel-shor/followers", "following_url": "https://api.github.com/users/joel-shor/following{/other_user}", "gists_url": "https://api.github.com/users/joel-shor/gists{/gist_id}", "starred_url": "https://api.github.com/users/joel-shor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joel-shor/subscriptions", "organizations_url": "https://api.github.com/users/joel-shor/orgs", "repos_url": "https://api.github.com/users/joel-shor/repos", "events_url": "https://api.github.com/users/joel-shor/events{/privacy}", "received_events_url": "https://api.github.com/users/joel-shor/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "joel-shor", "id": 6020988, "node_id": "MDQ6VXNlcjYwMjA5ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/6020988?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joel-shor", "html_url": "https://github.com/joel-shor", "followers_url": "https://api.github.com/users/joel-shor/followers", "following_url": "https://api.github.com/users/joel-shor/following{/other_user}", "gists_url": "https://api.github.com/users/joel-shor/gists{/gist_id}", "starred_url": "https://api.github.com/users/joel-shor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joel-shor/subscriptions", "organizations_url": "https://api.github.com/users/joel-shor/orgs", "repos_url": "https://api.github.com/users/joel-shor/repos", "events_url": "https://api.github.com/users/joel-shor/events{/privacy}", "received_events_url": "https://api.github.com/users/joel-shor/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-01-30T22:22:56Z", "updated_at": "2018-03-20T22:14:26Z", "closed_at": "2018-03-20T22:14:26Z", "author_association": "NONE", "body_html": "<p>randomly sampling / cropping data seems to break rejection_resample ==&gt; meaning it won't do any re balancing of the class probability -- see these two simple feeders as example:</p>\n<p>The first randomly samples data with tf.random_uniform and breaks rejection_resample -- the second with static random data having  the same distribution is correctly resampled (output has p(class=0)=0)</p>\n<p>This creates issues when trying to real-time sample/crop/data-augment and at the same time rebalance classes with on the same pipeline</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">get_data_breaks</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">batch_size</span>, <span class=\"pl-smi\">iihook</span>, <span class=\"pl-smi\">this_set</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>train<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">sample</span>(<span class=\"pl-smi\">data</span>, <span class=\"pl-smi\">label</span>): <span class=\"pl-c\"><span class=\"pl-c\">#</span> sample detection window inside chunk</span>\n        xx <span class=\"pl-k\">=</span> tf.cast(tf.random_uniform([<span class=\"pl-c1\">1</span>])<span class=\"pl-k\">*</span><span class=\"pl-c1\">self</span>.class_num, tf.int32)[<span class=\"pl-c1\">0</span>]\n        <span class=\"pl-k\">with</span> tf.control_dependencies([xx]): tf.Print(xx , [xx], <span class=\"pl-s\"><span class=\"pl-pds\">'</span>xx&gt;&gt;<span class=\"pl-pds\">'</span></span>)\n        <span class=\"pl-k\">return</span> xx, xx\n\n    initial_dist<span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">self</span>.class_num <span class=\"pl-k\">for</span> cc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">self</span>.class_num)]\n    classes <span class=\"pl-k\">=</span> np.random.choice(<span class=\"pl-c1\">self</span>.class_num,<span class=\"pl-c1\">20000</span>,<span class=\"pl-v\">p</span><span class=\"pl-k\">=</span>initial_dist)\n\n    data_ph <span class=\"pl-k\">=</span> tf.placeholder(classes.dtype, classes.shape)\n    labels_ph <span class=\"pl-k\">=</span> tf.placeholder(classes.dtype, classes.shape)\n    dataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\n\n    dataset <span class=\"pl-k\">=</span> dataset.map(sample, <span class=\"pl-v\">num_parallel_calls</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n    target_dist<span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">self</span>.class_num <span class=\"pl-k\">for</span> cc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">self</span>.class_num)]\n    target_dist[<span class=\"pl-c1\">1</span>]<span class=\"pl-k\">+=</span>target_dist[<span class=\"pl-c1\">0</span>] ; target_dist[<span class=\"pl-c1\">0</span>]<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>target-dist&gt;&gt;<span class=\"pl-pds\">'</span></span>, target_dist)\n    initial_dist <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n    dataset <span class=\"pl-k\">=</span> dataset.apply(tf.contrib.data.rejection_resample(\n                <span class=\"pl-v\">class_func</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">c</span>, <span class=\"pl-smi\">_</span>: c,\n                <span class=\"pl-v\">target_dist</span><span class=\"pl-k\">=</span>target_dist,\n                <span class=\"pl-v\">initial_dist</span><span class=\"pl-k\">=</span>initial_dist,\n                <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">42</span>)).map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">a</span>,<span class=\"pl-smi\">b</span>: b)\n\n    dataset <span class=\"pl-k\">=</span> dataset.repeat(<span class=\"pl-c1\">None</span>)\n    iterator <span class=\"pl-k\">=</span> dataset.make_initializable_iterator()\n    iihook.iterator_initializer_func <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">sess</span>: sess.run(iterator.initializer,\n                    <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{data_ph: classes, labels_ph: classes})\n\n    <span class=\"pl-k\">return</span> iterator.get_next()\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">get_data_works</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">batch_size</span>, <span class=\"pl-smi\">iihook</span>, <span class=\"pl-smi\">this_set</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>train<span class=\"pl-pds\">'</span></span>):\n\n    initial_dist<span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">self</span>.class_num <span class=\"pl-k\">for</span> cc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">self</span>.class_num)]\n    classes <span class=\"pl-k\">=</span> np.random.choice(<span class=\"pl-c1\">self</span>.class_num,<span class=\"pl-c1\">20000</span>,<span class=\"pl-v\">p</span><span class=\"pl-k\">=</span>initial_dist)\n\n    data_ph <span class=\"pl-k\">=</span> tf.placeholder(classes.dtype, classes.shape)\n    labels_ph <span class=\"pl-k\">=</span> tf.placeholder(classes.dtype, classes.shape)\n    dataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\n\n    target_dist<span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">self</span>.class_num <span class=\"pl-k\">for</span> cc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">self</span>.class_num)]\n    target_dist[<span class=\"pl-c1\">1</span>]<span class=\"pl-k\">+=</span>target_dist[<span class=\"pl-c1\">0</span>] ; target_dist[<span class=\"pl-c1\">0</span>]<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>target-dist&gt;&gt;<span class=\"pl-pds\">'</span></span>, target_dist)\n    initial_dist <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n    dataset <span class=\"pl-k\">=</span> dataset.apply(tf.contrib.data.rejection_resample(\n                <span class=\"pl-v\">class_func</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">c</span>, <span class=\"pl-smi\">_</span>: c,\n                <span class=\"pl-v\">target_dist</span><span class=\"pl-k\">=</span>target_dist,\n                <span class=\"pl-v\">initial_dist</span><span class=\"pl-k\">=</span>initial_dist,\n                <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">42</span>)).map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">a</span>,<span class=\"pl-smi\">b</span>: b)\n\n    dataset <span class=\"pl-k\">=</span> dataset.repeat(<span class=\"pl-c1\">None</span>)\n    iterator <span class=\"pl-k\">=</span> dataset.make_initializable_iterator()\n    iihook.iterator_initializer_func <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">sess</span>: sess.run(iterator.initializer,\n                    <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{data_ph: classes, labels_ph: classes})\n\n    <span class=\"pl-k\">return</span> iterator.get_next()</pre></div>", "body_text": "randomly sampling / cropping data seems to break rejection_resample ==> meaning it won't do any re balancing of the class probability -- see these two simple feeders as example:\nThe first randomly samples data with tf.random_uniform and breaks rejection_resample -- the second with static random data having  the same distribution is correctly resampled (output has p(class=0)=0)\nThis creates issues when trying to real-time sample/crop/data-augment and at the same time rebalance classes with on the same pipeline\ndef get_data_breaks(self, batch_size, iihook, this_set='train'):\n    def sample(data, label): # sample detection window inside chunk\n        xx = tf.cast(tf.random_uniform([1])*self.class_num, tf.int32)[0]\n        with tf.control_dependencies([xx]): tf.Print(xx , [xx], 'xx>>')\n        return xx, xx\n\n    initial_dist=[1.0/self.class_num for cc in range(self.class_num)]\n    classes = np.random.choice(self.class_num,20000,p=initial_dist)\n\n    data_ph = tf.placeholder(classes.dtype, classes.shape)\n    labels_ph = tf.placeholder(classes.dtype, classes.shape)\n    dataset = tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\n\n    dataset = dataset.map(sample, num_parallel_calls=1)\n\n    target_dist=[1.0/self.class_num for cc in range(self.class_num)]\n    target_dist[1]+=target_dist[0] ; target_dist[0]=0\n    print('target-dist>>', target_dist)\n    initial_dist = None\n\n    dataset = dataset.apply(tf.contrib.data.rejection_resample(\n                class_func=lambda c, _: c,\n                target_dist=target_dist,\n                initial_dist=initial_dist,\n                seed=42)).map(lambda a,b: b)\n\n    dataset = dataset.repeat(None)\n    iterator = dataset.make_initializable_iterator()\n    iihook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\n                    feed_dict={data_ph: classes, labels_ph: classes})\n\n    return iterator.get_next()\n\n\ndef get_data_works(self, batch_size, iihook, this_set='train'):\n\n    initial_dist=[1.0/self.class_num for cc in range(self.class_num)]\n    classes = np.random.choice(self.class_num,20000,p=initial_dist)\n\n    data_ph = tf.placeholder(classes.dtype, classes.shape)\n    labels_ph = tf.placeholder(classes.dtype, classes.shape)\n    dataset = tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\n\n    target_dist=[1.0/self.class_num for cc in range(self.class_num)]\n    target_dist[1]+=target_dist[0] ; target_dist[0]=0\n    print('target-dist>>', target_dist)\n    initial_dist = None\n\n    dataset = dataset.apply(tf.contrib.data.rejection_resample(\n                class_func=lambda c, _: c,\n                target_dist=target_dist,\n                initial_dist=initial_dist,\n                seed=42)).map(lambda a,b: b)\n\n    dataset = dataset.repeat(None)\n    iterator = dataset.make_initializable_iterator()\n    iihook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\n                    feed_dict={data_ph: classes, labels_ph: classes})\n\n    return iterator.get_next()", "body": "randomly sampling / cropping data seems to break rejection_resample ==> meaning it won't do any re balancing of the class probability -- see these two simple feeders as example:\r\n\r\nThe first randomly samples data with tf.random_uniform and breaks rejection_resample -- the second with static random data having  the same distribution is correctly resampled (output has p(class=0)=0)\r\n\r\nThis creates issues when trying to real-time sample/crop/data-augment and at the same time rebalance classes with on the same pipeline\r\n\r\n```python\r\ndef get_data_breaks(self, batch_size, iihook, this_set='train'):\r\n    def sample(data, label): # sample detection window inside chunk\r\n        xx = tf.cast(tf.random_uniform([1])*self.class_num, tf.int32)[0]\r\n        with tf.control_dependencies([xx]): tf.Print(xx , [xx], 'xx>>')\r\n        return xx, xx\r\n\r\n    initial_dist=[1.0/self.class_num for cc in range(self.class_num)]\r\n    classes = np.random.choice(self.class_num,20000,p=initial_dist)\r\n\r\n    data_ph = tf.placeholder(classes.dtype, classes.shape)\r\n    labels_ph = tf.placeholder(classes.dtype, classes.shape)\r\n    dataset = tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\r\n\r\n    dataset = dataset.map(sample, num_parallel_calls=1)\r\n\r\n    target_dist=[1.0/self.class_num for cc in range(self.class_num)]\r\n    target_dist[1]+=target_dist[0] ; target_dist[0]=0\r\n    print('target-dist>>', target_dist)\r\n    initial_dist = None\r\n\r\n    dataset = dataset.apply(tf.contrib.data.rejection_resample(\r\n                class_func=lambda c, _: c,\r\n                target_dist=target_dist,\r\n                initial_dist=initial_dist,\r\n                seed=42)).map(lambda a,b: b)\r\n\r\n    dataset = dataset.repeat(None)\r\n    iterator = dataset.make_initializable_iterator()\r\n    iihook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\r\n                    feed_dict={data_ph: classes, labels_ph: classes})\r\n\r\n    return iterator.get_next()\r\n\r\n\r\ndef get_data_works(self, batch_size, iihook, this_set='train'):\r\n\r\n    initial_dist=[1.0/self.class_num for cc in range(self.class_num)]\r\n    classes = np.random.choice(self.class_num,20000,p=initial_dist)\r\n\r\n    data_ph = tf.placeholder(classes.dtype, classes.shape)\r\n    labels_ph = tf.placeholder(classes.dtype, classes.shape)\r\n    dataset = tf.data.Dataset.from_tensor_slices((data_ph, labels_ph))\r\n\r\n    target_dist=[1.0/self.class_num for cc in range(self.class_num)]\r\n    target_dist[1]+=target_dist[0] ; target_dist[0]=0\r\n    print('target-dist>>', target_dist)\r\n    initial_dist = None\r\n\r\n    dataset = dataset.apply(tf.contrib.data.rejection_resample(\r\n                class_func=lambda c, _: c,\r\n                target_dist=target_dist,\r\n                initial_dist=initial_dist,\r\n                seed=42)).map(lambda a,b: b)\r\n\r\n    dataset = dataset.repeat(None)\r\n    iterator = dataset.make_initializable_iterator()\r\n    iihook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\r\n                    feed_dict={data_ph: classes, labels_ph: classes})\r\n\r\n    return iterator.get_next()\r\n"}