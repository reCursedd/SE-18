{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/304195267", "html_url": "https://github.com/tensorflow/tensorflow/issues/10204#issuecomment-304195267", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10204", "id": 304195267, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNDE5NTI2Nw==", "user": {"login": "j-min", "id": 18069263, "node_id": "MDQ6VXNlcjE4MDY5MjYz", "avatar_url": "https://avatars3.githubusercontent.com/u/18069263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-min", "html_url": "https://github.com/j-min", "followers_url": "https://api.github.com/users/j-min/followers", "following_url": "https://api.github.com/users/j-min/following{/other_user}", "gists_url": "https://api.github.com/users/j-min/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-min/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-min/subscriptions", "organizations_url": "https://api.github.com/users/j-min/orgs", "repos_url": "https://api.github.com/users/j-min/repos", "events_url": "https://api.github.com/users/j-min/events{/privacy}", "received_events_url": "https://api.github.com/users/j-min/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-26T05:29:23Z", "updated_at": "2017-05-26T13:39:12Z", "author_association": "NONE", "body_html": "<p>I just found that</p>\n<ul>\n<li>\n<p>In CPU environment, the summaries are correctly stored when I add <code>summary_writer.flush()</code> after every <code>summary_writer.add_summary()</code>and run the code with python. (The errors were produced in jupyter notebook environment)<br>\nMaybe we can update documentation about using <code>Writer.flush()</code>?</p>\n</li>\n<li>\n<p>However, in multi GPU environment, even if I use <code>summary_writer.flush()</code>, the order of summaries are correct, but still not all the summaries are saved.</p>\n</li>\n</ul>\n<p>I was training image-captioning model.<br>\nDuring training, I used 4 replica graphs sharing variables and update variable synchronously with average gradient across all towers at each step.<br>\nEvery 100 step, I feed validation data sample text from separate validation graph sharing variables with training graphs above without loss function and optimizer like above.<br>\nAnd I added the validation result summary right after running training ops.</p>\n<p>Moreover, I found that summaries are overwritten by recent summaries. For example, the summaries added at step 1900 erased summaries added at step 1800.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/18069263/26496652/66efb8f8-4263-11e7-93e5-7773e055ca95.jpg\"><img src=\"https://cloud.githubusercontent.com/assets/18069263/26496652/66efb8f8-4263-11e7-93e5-7773e055ca95.jpg\" alt=\"screenshot_20170526-155055\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/18069263/26496654/686e8eac-4263-11e7-81fd-0bcde5bc69f9.jpg\"><img src=\"https://cloud.githubusercontent.com/assets/18069263/26496654/686e8eac-4263-11e7-81fd-0bcde5bc69f9.jpg\" alt=\"screenshot_20170526-155313\" style=\"max-width:100%;\"></a></p>\n<p>The brief codes look as below.</p>\n<pre><code>for step in range(total_steps):\n    ....\n    sess.run([training_op, lost...])\n\n    if step % 100:\n        generated_valid_ids = sess.run(validation_graph_inference_result, feed_dict={validation_input_placeholder: validation_data}\n        valid_sent = id2sent(genrated_valid_ids)\n        valid_summary = sess.run(valid_summary_op, feed_dict={valid_summary_placeholder: valid_sent}\n        summary_writer.add_summary(valid_summary, global_step=step)\n        summary_writer.flush()\n</code></pre>", "body_text": "I just found that\n\n\nIn CPU environment, the summaries are correctly stored when I add summary_writer.flush() after every summary_writer.add_summary()and run the code with python. (The errors were produced in jupyter notebook environment)\nMaybe we can update documentation about using Writer.flush()?\n\n\nHowever, in multi GPU environment, even if I use summary_writer.flush(), the order of summaries are correct, but still not all the summaries are saved.\n\n\nI was training image-captioning model.\nDuring training, I used 4 replica graphs sharing variables and update variable synchronously with average gradient across all towers at each step.\nEvery 100 step, I feed validation data sample text from separate validation graph sharing variables with training graphs above without loss function and optimizer like above.\nAnd I added the validation result summary right after running training ops.\nMoreover, I found that summaries are overwritten by recent summaries. For example, the summaries added at step 1900 erased summaries added at step 1800.\n\n\nThe brief codes look as below.\nfor step in range(total_steps):\n    ....\n    sess.run([training_op, lost...])\n\n    if step % 100:\n        generated_valid_ids = sess.run(validation_graph_inference_result, feed_dict={validation_input_placeholder: validation_data}\n        valid_sent = id2sent(genrated_valid_ids)\n        valid_summary = sess.run(valid_summary_op, feed_dict={valid_summary_placeholder: valid_sent}\n        summary_writer.add_summary(valid_summary, global_step=step)\n        summary_writer.flush()", "body": "I just found that\r\n- In CPU environment, the summaries are correctly stored when I add `summary_writer.flush()` after every `summary_writer.add_summary()`and run the code with python. (The errors were produced in jupyter notebook environment)\r\nMaybe we can update documentation about using `Writer.flush()`?\r\n\r\n- However, in multi GPU environment, even if I use `summary_writer.flush()`, the order of summaries are correct, but still not all the summaries are saved.\r\n\r\nI was training image-captioning model.\r\nDuring training, I used 4 replica graphs sharing variables and update variable synchronously with average gradient across all towers at each step. \r\nEvery 100 step, I feed validation data sample text from separate validation graph sharing variables with training graphs above without loss function and optimizer like above.\r\nAnd I added the validation result summary right after running training ops.\r\n\r\nMoreover, I found that summaries are overwritten by recent summaries. For example, the summaries added at step 1900 erased summaries added at step 1800.\r\n\r\n![screenshot_20170526-155055](https://cloud.githubusercontent.com/assets/18069263/26496652/66efb8f8-4263-11e7-93e5-7773e055ca95.jpg)\r\n![screenshot_20170526-155313](https://cloud.githubusercontent.com/assets/18069263/26496654/686e8eac-4263-11e7-81fd-0bcde5bc69f9.jpg)\r\n\r\n\r\nThe brief codes look as below.\r\n```\r\nfor step in range(total_steps):\r\n    ....\r\n    sess.run([training_op, lost...])\r\n\r\n    if step % 100:\r\n        generated_valid_ids = sess.run(validation_graph_inference_result, feed_dict={validation_input_placeholder: validation_data}\r\n        valid_sent = id2sent(genrated_valid_ids)\r\n        valid_summary = sess.run(valid_summary_op, feed_dict={valid_summary_placeholder: valid_sent}\r\n        summary_writer.add_summary(valid_summary, global_step=step)\r\n        summary_writer.flush()\r\n```"}