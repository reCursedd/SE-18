{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/318790632", "html_url": "https://github.com/tensorflow/tensorflow/issues/11157#issuecomment-318790632", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11157", "id": 318790632, "node_id": "MDEyOklzc3VlQ29tbWVudDMxODc5MDYzMg==", "user": {"login": "fabriciorsf", "id": 1422968, "node_id": "MDQ6VXNlcjE0MjI5Njg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1422968?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fabriciorsf", "html_url": "https://github.com/fabriciorsf", "followers_url": "https://api.github.com/users/fabriciorsf/followers", "following_url": "https://api.github.com/users/fabriciorsf/following{/other_user}", "gists_url": "https://api.github.com/users/fabriciorsf/gists{/gist_id}", "starred_url": "https://api.github.com/users/fabriciorsf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fabriciorsf/subscriptions", "organizations_url": "https://api.github.com/users/fabriciorsf/orgs", "repos_url": "https://api.github.com/users/fabriciorsf/repos", "events_url": "https://api.github.com/users/fabriciorsf/events{/privacy}", "received_events_url": "https://api.github.com/users/fabriciorsf/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-29T00:35:04Z", "updated_at": "2017-07-29T00:40:22Z", "author_association": "NONE", "body_html": "<p>I get this same error with <strong>Keras+TensorFlow</strong> on <code>fit_generator</code>.<br>\nAnd the same code with <strong>Keras+Theano works fine</strong>.</p>\n<p>Follow the command gets the error:</p>\n<pre><code>model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n                    validation_data=test_input_sequence, validation_steps=steps_test,\n                    max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n                    workers=self.train_inputs.workers, use_multiprocessing=True,\n                    callbacks = callbacks)\n</code></pre>\n<p>The error:</p>\n<pre><code>Epoch 1/1\nTraceback (most recent call last):\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\n    inputs = self.queue.get(block=True).get()\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\n    raise self._value\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\n    put(task)\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n    self._send_bytes(_ForkingPickler.dumps(obj))\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nTypeError: can't pickle _thread.lock objects\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"./myfolder/mycode.py\", line 473, in &lt;module&gt;\n    main()\n  File \"./myfolder/mycode.py\", line 459, in main\n    autonem.train_autonem(args.embedding_file, args.tune_embedding)\n  File \"./myfolder/mycode.py\", line 182, in train_autonem\n    callbacks = callbacks)\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\n    generator_output = next(output_generator)\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\n    raise StopIteration(e)\nStopIteration: can't pickle _thread.lock objects\n</code></pre>\n<p><strong>System information:</strong></p>\n<p><strong>Have I written custom code:</strong> Yes<br>\n<strong>OS Platform and Distribution:</strong> Linux GnomeUbuntu 16.04, but with new kernel<br>\n_<em>TensorFlow installed from:</em> pip<br>\n<strong>TensorFlow version:</strong> 1.2.1<br>\n<strong>Python version:</strong> 3.6.1 (Miniconda3 4.3.11-64bit)<br>\n<strong>Bazel version (if compiling from source):</strong> I don't know.<br>\n<strong>CUDA/cuDNN version:</strong> I don't use because my graphic card is AMD-Radeon<br>\n<strong>GPU model and memory:</strong> AMD Radeon R7 M260/M265<br>\n<strong>CPU model:</strong> Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4<br>\n<strong>RAM Memory:</strong> 16GiB (2x8Gib dual-channel)<br>\n<strong>Exact command to reproduce:</strong></p>\n<pre><code>history = CumulativeHistory()\ncallbacks = [history]\nfrom keras import backend as K\nif K.backend() == 'tensorflow':\n  board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\n                                    histogram_freq=1, write_graph=True, write_images=True)\n  callbacks.append(board)\nmetric_to_compare = 'val_euclidean_distance'\nprint(\"Begin of training model...\")\nfor i in range(MAX_NUM_EPOCHS):\n  model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n                      validation_data=test_input_sequence, validation_steps=steps_test,\n                      max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n                      workers=self.train_inputs.workers, use_multiprocessing=True,\n                      callbacks = callbacks)\n  try:\n    metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\n  except:\n    metrics_diff = -1\n  if metrics_diff &lt; 0:\n    self._save_models(i)\n    self.data_processor = None  # Empty memory\n    best_epoch = i\n    num_worse_epochs = 0\n  elif metrics_diff &gt; 0:\n    num_worse_epochs += 1\n    if num_worse_epochs &gt;= PATIENCE:\n      print(\"Ran out of patience. Stopping training.\")\n      break\nprint(\"End of training model.\")\n</code></pre>\n<p><strong>Collected information</strong>:</p>\n<pre><code>(myenv) myuser@mymachine:~$ ./tf_env_collect.sh \nCollecting system information...\n2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nWrote environment to tf_env.txt. You can review the contents of that file.\nand use it to populate the fields in the github issue template.\n\ncat tf_env.txt\n\n(myenv) myuser@mymachine:~$ cat tf_env.txt\n\n== cat /etc/issue ===============================================\nLinux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"14.04.5 LTS, Trusty Tahr\"\nVERSION_ID=\"14.04\"\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.3.0)\ntensorflow (1.2.1)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.2.1\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\n./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\n\n== cuda libs  ===================================================\n</code></pre>", "body_text": "I get this same error with Keras+TensorFlow on fit_generator.\nAnd the same code with Keras+Theano works fine.\nFollow the command gets the error:\nmodel.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n                    validation_data=test_input_sequence, validation_steps=steps_test,\n                    max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n                    workers=self.train_inputs.workers, use_multiprocessing=True,\n                    callbacks = callbacks)\n\nThe error:\nEpoch 1/1\nTraceback (most recent call last):\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\n    inputs = self.queue.get(block=True).get()\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\n    raise self._value\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\n    put(task)\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n    self._send_bytes(_ForkingPickler.dumps(obj))\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nTypeError: can't pickle _thread.lock objects\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"./myfolder/mycode.py\", line 473, in <module>\n    main()\n  File \"./myfolder/mycode.py\", line 459, in main\n    autonem.train_autonem(args.embedding_file, args.tune_embedding)\n  File \"./myfolder/mycode.py\", line 182, in train_autonem\n    callbacks = callbacks)\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\n    generator_output = next(output_generator)\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\n    raise StopIteration(e)\nStopIteration: can't pickle _thread.lock objects\n\nSystem information:\nHave I written custom code: Yes\nOS Platform and Distribution: Linux GnomeUbuntu 16.04, but with new kernel\n_TensorFlow installed from: pip\nTensorFlow version: 1.2.1\nPython version: 3.6.1 (Miniconda3 4.3.11-64bit)\nBazel version (if compiling from source): I don't know.\nCUDA/cuDNN version: I don't use because my graphic card is AMD-Radeon\nGPU model and memory: AMD Radeon R7 M260/M265\nCPU model: Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4\nRAM Memory: 16GiB (2x8Gib dual-channel)\nExact command to reproduce:\nhistory = CumulativeHistory()\ncallbacks = [history]\nfrom keras import backend as K\nif K.backend() == 'tensorflow':\n  board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\n                                    histogram_freq=1, write_graph=True, write_images=True)\n  callbacks.append(board)\nmetric_to_compare = 'val_euclidean_distance'\nprint(\"Begin of training model...\")\nfor i in range(MAX_NUM_EPOCHS):\n  model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n                      validation_data=test_input_sequence, validation_steps=steps_test,\n                      max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n                      workers=self.train_inputs.workers, use_multiprocessing=True,\n                      callbacks = callbacks)\n  try:\n    metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\n  except:\n    metrics_diff = -1\n  if metrics_diff < 0:\n    self._save_models(i)\n    self.data_processor = None  # Empty memory\n    best_epoch = i\n    num_worse_epochs = 0\n  elif metrics_diff > 0:\n    num_worse_epochs += 1\n    if num_worse_epochs >= PATIENCE:\n      print(\"Ran out of patience. Stopping training.\")\n      break\nprint(\"End of training model.\")\n\nCollected information:\n(myenv) myuser@mymachine:~$ ./tf_env_collect.sh \nCollecting system information...\n2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nWrote environment to tf_env.txt. You can review the contents of that file.\nand use it to populate the fields in the github issue template.\n\ncat tf_env.txt\n\n(myenv) myuser@mymachine:~$ cat tf_env.txt\n\n== cat /etc/issue ===============================================\nLinux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"14.04.5 LTS, Trusty Tahr\"\nVERSION_ID=\"14.04\"\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.3.0)\ntensorflow (1.2.1)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.2.1\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\n./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\n\n== cuda libs  ===================================================", "body": "I get this same error with __Keras+TensorFlow__ on `fit_generator`.\r\nAnd the same code with __Keras+Theano works fine__.\r\n\r\nFollow the command gets the error:\r\n```\r\nmodel.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\r\n                    validation_data=test_input_sequence, validation_steps=steps_test,\r\n                    max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\r\n                    workers=self.train_inputs.workers, use_multiprocessing=True,\r\n                    callbacks = callbacks)\r\n```\r\nThe error:\r\n```\r\nEpoch 1/1\r\nTraceback (most recent call last):\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\r\n    inputs = self.queue.get(block=True).get()\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\r\n    raise self._value\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\r\n    put(task)\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\r\n    self._send_bytes(_ForkingPickler.dumps(obj))\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\r\n    cls(buf, protocol).dump(obj)\r\nTypeError: can't pickle _thread.lock objects\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"./myfolder/mycode.py\", line 473, in <module>\r\n    main()\r\n  File \"./myfolder/mycode.py\", line 459, in main\r\n    autonem.train_autonem(args.embedding_file, args.tune_embedding)\r\n  File \"./myfolder/mycode.py\", line 182, in train_autonem\r\n    callbacks = callbacks)\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\r\n    generator_output = next(output_generator)\r\n  File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\r\n    raise StopIteration(e)\r\nStopIteration: can't pickle _thread.lock objects\r\n```\r\n\r\n__System information:__\r\n\r\n__Have I written custom code:__ Yes\r\n__OS Platform and Distribution:__ Linux GnomeUbuntu 16.04, but with new kernel\r\n__TensorFlow installed from:_ pip\r\n__TensorFlow version:__ 1.2.1\r\n__Python version:__ 3.6.1 (Miniconda3 4.3.11-64bit)\r\n__Bazel version (if compiling from source):__ I don't know.\r\n__CUDA/cuDNN version:__ I don't use because my graphic card is AMD-Radeon\r\n__GPU model and memory:__ AMD Radeon R7 M260/M265\r\n__CPU model:__ Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4\r\n__RAM Memory:__ 16GiB (2x8Gib dual-channel)\r\n__Exact command to reproduce:__\r\n```\r\nhistory = CumulativeHistory()\r\ncallbacks = [history]\r\nfrom keras import backend as K\r\nif K.backend() == 'tensorflow':\r\n  board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\r\n                                    histogram_freq=1, write_graph=True, write_images=True)\r\n  callbacks.append(board)\r\nmetric_to_compare = 'val_euclidean_distance'\r\nprint(\"Begin of training model...\")\r\nfor i in range(MAX_NUM_EPOCHS):\r\n  model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\r\n                      validation_data=test_input_sequence, validation_steps=steps_test,\r\n                      max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\r\n                      workers=self.train_inputs.workers, use_multiprocessing=True,\r\n                      callbacks = callbacks)\r\n  try:\r\n    metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\r\n  except:\r\n    metrics_diff = -1\r\n  if metrics_diff < 0:\r\n    self._save_models(i)\r\n    self.data_processor = None  # Empty memory\r\n    best_epoch = i\r\n    num_worse_epochs = 0\r\n  elif metrics_diff > 0:\r\n    num_worse_epochs += 1\r\n    if num_worse_epochs >= PATIENCE:\r\n      print(\"Ran out of patience. Stopping training.\")\r\n      break\r\nprint(\"End of training model.\")\r\n```\r\n\r\n__Collected information__:\r\n```\r\n(myenv) myuser@mymachine:~$ ./tf_env_collect.sh \r\nCollecting system information...\r\n2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nWrote environment to tf_env.txt. You can review the contents of that file.\r\nand use it to populate the fields in the github issue template.\r\n\r\ncat tf_env.txt\r\n\r\n(myenv) myuser@mymachine:~$ cat tf_env.txt\r\n\r\n== cat /etc/issue ===============================================\r\nLinux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"14.04.5 LTS, Trusty Tahr\"\r\nVERSION_ID=\"14.04\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\r\n\r\n== cuda libs  ===================================================\r\n```"}