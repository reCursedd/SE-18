{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/318856091", "html_url": "https://github.com/tensorflow/tensorflow/issues/11157#issuecomment-318856091", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11157", "id": 318856091, "node_id": "MDEyOklzc3VlQ29tbWVudDMxODg1NjA5MQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-29T20:09:12Z", "updated_at": "2017-07-29T20:09:12Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">Try using the tf 1.3 rc</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Jul 28, 2017 2:35 PM, \"Fabr\u00edcio Raphael Silva Pereira\" &lt; ***@***.***&gt; wrote:\n I get this same error with Keras+TensorFlow on fit_generator.\n And the same code with Keras+Theano works fine.\n\n Follow the command gets the error:\n\n model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n                     validation_data=test_input_sequence, validation_steps=steps_test,\n                     max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n                     workers=self.train_inputs.workers, use_multiprocessing=True,\n                     callbacks = callbacks)\n\n The error:\n\n Epoch 1/1\n Traceback (most recent call last):\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\n     inputs = self.queue.get(block=True).get()\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\n     raise self._value\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\n     put(task)\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n     self._send_bytes(_ForkingPickler.dumps(obj))\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n     cls(buf, protocol).dump(obj)\n TypeError: can't pickle _thread.lock objects\n\n During handling of the above exception, another exception occurred:\n\n Traceback (most recent call last):\n   File \"./myfolder/mycode.py\", line 473, in &lt;module&gt;\n     main()\n   File \"./myfolder/mycode.py\", line 459, in main\n     autonem.train_autonem(args.embedding_file, args.tune_embedding)\n   File \"./myfolder/mycode.py\", line 182, in train_autonem\n     callbacks = callbacks)\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n     return func(*args, **kwargs)\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\n     generator_output = next(output_generator)\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\n     raise StopIteration(e)\n StopIteration: can't pickle _thread.lock objects\n\n *System information:*\n\n *Have I written custom code:* Yes\n *OS Platform and Distribution:* Linux GnomeUbuntu 16.04, but with new\n kernel\n _*TensorFlow installed from:* pip\n *TensorFlow version:* 1.2.1\n Python version: 3.6.1 (Miniconda3 4.3.11-64bit)\n *Bazel version (if compiling from source):* I don't know.\n *CUDA/cuDNN version:* I don't use because my graphic card is AMD-Radeon\n *GPU model and memory:* AMD Radeon R7 M260/M265\n *CPU model:* Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4\n *RAM Memory:* 16GiB (2x8Gib dual-channel)\n Exact command to reproduce:\n\n history = CumulativeHistory()\n callbacks = [history]\n from keras import backend as K\n if K.backend() == 'tensorflow':\n   board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\n                                     histogram_freq=1, write_graph=True, write_images=True)\n   callbacks.append(board)\n metric_to_compare = 'val_euclidean_distance'\n print(\"Begin of training model...\")\n for i in range(MAX_NUM_EPOCHS):\n   model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n                       validation_data=test_input_sequence, validation_steps=steps_test,\n                       max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n                       workers=self.train_inputs.workers, use_multiprocessing=True,\n                       callbacks = callbacks)\n   try:\n     metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\n   except:\n     metrics_diff = -1\n   if metrics_diff &lt; 0:\n     self._save_models(i)\n     self.data_processor = None  # Empty memory\n     best_epoch = i\n     num_worse_epochs = 0\n   elif metrics_diff &gt; 0:\n     num_worse_epochs += 1\n     if num_worse_epochs &gt;= PATIENCE:\n       print(\"Ran out of patience. Stopping training.\")\n       break\n print(\"End of training model.\")\n\n *Collected information*:\n\n (myenv) ***@***.***:~$ ./tf_env_collect.sh\n Collecting system information...\n 2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n 2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n Wrote environment to tf_env.txt. You can review the contents of that file.\n and use it to populate the fields in the github issue template.\n\n cat tf_env.txt\n\n (myenv) ***@***.***:~$ cat tf_env.txt\n\n == cat /etc/issue ===============================================\n Linux mymachine 4.4.0-87-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116236573\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/110\" href=\"https://github.com/tensorflow/tensorflow/issues/110\">#110</a>~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n VERSION=\"14.04.5 LTS, Trusty Tahr\"\n VERSION_ID=\"14.04\"\n\n == are we in docker =============================================\n No\n\n == compiler =====================================================\n c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n Copyright (C) 2013 Free Software Foundation, Inc.\n This is free software; see the source for copying conditions.  There is NO\n warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n == uname -a =====================================================\n Linux mymachine 4.4.0-87-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116236573\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/110\" href=\"https://github.com/tensorflow/tensorflow/issues/110\">#110</a>~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n == check pips ===================================================\n numpy (1.13.1)\n protobuf (3.3.0)\n tensorflow (1.2.1)\n\n == check for virtualenv =========================================\n False\n\n == tensorflow import ============================================\n tf.VERSION = 1.2.1\n tf.GIT_VERSION = v1.2.0-5-g435cdfc\n tf.COMPILER_VERSION = v1.2.0-5-g435cdfc\n Sanity check: array([1], dtype=int32)\n\n == env ==========================================================\n LD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\n DYLD_LIBRARY_PATH is unset\n\n == nvidia-smi ===================================================\n ./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\n\n == cuda libs  ===================================================\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"239655317\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/11157\" href=\"https://github.com/tensorflow/tensorflow/issues/11157#issuecomment-318790632\">#11157 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim_x0X7z4fwR27nf-QB5eI0azF46Pks5sSn5qgaJpZM4OKDmJ\">https://github.com/notifications/unsubscribe-auth/ABtim_x0X7z4fwR27nf-QB5eI0azF46Pks5sSn5qgaJpZM4OKDmJ</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Try using the tf 1.3 rc\n\u2026\nOn Jul 28, 2017 2:35 PM, \"Fabr\u00edcio Raphael Silva Pereira\" < ***@***.***> wrote:\n I get this same error with Keras+TensorFlow on fit_generator.\n And the same code with Keras+Theano works fine.\n\n Follow the command gets the error:\n\n model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n                     validation_data=test_input_sequence, validation_steps=steps_test,\n                     max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n                     workers=self.train_inputs.workers, use_multiprocessing=True,\n                     callbacks = callbacks)\n\n The error:\n\n Epoch 1/1\n Traceback (most recent call last):\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\n     inputs = self.queue.get(block=True).get()\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\n     raise self._value\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\n     put(task)\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n     self._send_bytes(_ForkingPickler.dumps(obj))\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n     cls(buf, protocol).dump(obj)\n TypeError: can't pickle _thread.lock objects\n\n During handling of the above exception, another exception occurred:\n\n Traceback (most recent call last):\n   File \"./myfolder/mycode.py\", line 473, in <module>\n     main()\n   File \"./myfolder/mycode.py\", line 459, in main\n     autonem.train_autonem(args.embedding_file, args.tune_embedding)\n   File \"./myfolder/mycode.py\", line 182, in train_autonem\n     callbacks = callbacks)\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n     return func(*args, **kwargs)\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\n     generator_output = next(output_generator)\n   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\n     raise StopIteration(e)\n StopIteration: can't pickle _thread.lock objects\n\n *System information:*\n\n *Have I written custom code:* Yes\n *OS Platform and Distribution:* Linux GnomeUbuntu 16.04, but with new\n kernel\n _*TensorFlow installed from:* pip\n *TensorFlow version:* 1.2.1\n Python version: 3.6.1 (Miniconda3 4.3.11-64bit)\n *Bazel version (if compiling from source):* I don't know.\n *CUDA/cuDNN version:* I don't use because my graphic card is AMD-Radeon\n *GPU model and memory:* AMD Radeon R7 M260/M265\n *CPU model:* Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4\n *RAM Memory:* 16GiB (2x8Gib dual-channel)\n Exact command to reproduce:\n\n history = CumulativeHistory()\n callbacks = [history]\n from keras import backend as K\n if K.backend() == 'tensorflow':\n   board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\n                                     histogram_freq=1, write_graph=True, write_images=True)\n   callbacks.append(board)\n metric_to_compare = 'val_euclidean_distance'\n print(\"Begin of training model...\")\n for i in range(MAX_NUM_EPOCHS):\n   model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n                       validation_data=test_input_sequence, validation_steps=steps_test,\n                       max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n                       workers=self.train_inputs.workers, use_multiprocessing=True,\n                       callbacks = callbacks)\n   try:\n     metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\n   except:\n     metrics_diff = -1\n   if metrics_diff < 0:\n     self._save_models(i)\n     self.data_processor = None  # Empty memory\n     best_epoch = i\n     num_worse_epochs = 0\n   elif metrics_diff > 0:\n     num_worse_epochs += 1\n     if num_worse_epochs >= PATIENCE:\n       print(\"Ran out of patience. Stopping training.\")\n       break\n print(\"End of training model.\")\n\n *Collected information*:\n\n (myenv) ***@***.***:~$ ./tf_env_collect.sh\n Collecting system information...\n 2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n 2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n Wrote environment to tf_env.txt. You can review the contents of that file.\n and use it to populate the fields in the github issue template.\n\n cat tf_env.txt\n\n (myenv) ***@***.***:~$ cat tf_env.txt\n\n == cat /etc/issue ===============================================\n Linux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n VERSION=\"14.04.5 LTS, Trusty Tahr\"\n VERSION_ID=\"14.04\"\n\n == are we in docker =============================================\n No\n\n == compiler =====================================================\n c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n Copyright (C) 2013 Free Software Foundation, Inc.\n This is free software; see the source for copying conditions.  There is NO\n warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n == uname -a =====================================================\n Linux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n == check pips ===================================================\n numpy (1.13.1)\n protobuf (3.3.0)\n tensorflow (1.2.1)\n\n == check for virtualenv =========================================\n False\n\n == tensorflow import ============================================\n tf.VERSION = 1.2.1\n tf.GIT_VERSION = v1.2.0-5-g435cdfc\n tf.COMPILER_VERSION = v1.2.0-5-g435cdfc\n Sanity check: array([1], dtype=int32)\n\n == env ==========================================================\n LD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\n DYLD_LIBRARY_PATH is unset\n\n == nvidia-smi ===================================================\n ./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\n\n == cuda libs  ===================================================\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#11157 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim_x0X7z4fwR27nf-QB5eI0azF46Pks5sSn5qgaJpZM4OKDmJ>\n .", "body": "Try using the tf 1.3 rc\n\nOn Jul 28, 2017 2:35 PM, \"Fabr\u00edcio Raphael Silva Pereira\" <\nnotifications@github.com> wrote:\n\n> I get this same error with Keras+TensorFlow on fit_generator.\n> And the same code with Keras+Theano works fine.\n>\n> Follow the command gets the error:\n>\n> model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n>                     validation_data=test_input_sequence, validation_steps=steps_test,\n>                     max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n>                     workers=self.train_inputs.workers, use_multiprocessing=True,\n>                     callbacks = callbacks)\n>\n> The error:\n>\n> Epoch 1/1\n> Traceback (most recent call last):\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 497, in get\n>     inputs = self.queue.get(block=True).get()\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 608, in get\n>     raise self._value\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/pool.py\", line 385, in _handle_tasks\n>     put(task)\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n>     self._send_bytes(_ForkingPickler.dumps(obj))\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n>     cls(buf, protocol).dump(obj)\n> TypeError: can't pickle _thread.lock objects\n>\n> During handling of the above exception, another exception occurred:\n>\n> Traceback (most recent call last):\n>   File \"./myfolder/mycode.py\", line 473, in <module>\n>     main()\n>   File \"./myfolder/mycode.py\", line 459, in main\n>     autonem.train_autonem(args.embedding_file, args.tune_embedding)\n>   File \"./myfolder/mycode.py\", line 182, in train_autonem\n>     callbacks = callbacks)\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n>     return func(*args, **kwargs)\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/engine/training.py\", line 1809, in fit_generator\n>     generator_output = next(output_generator)\n>   File \"/opt/programs/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 502, in get\n>     raise StopIteration(e)\n> StopIteration: can't pickle _thread.lock objects\n>\n> *System information:*\n>\n> *Have I written custom code:* Yes\n> *OS Platform and Distribution:* Linux GnomeUbuntu 16.04, but with new\n> kernel\n> _*TensorFlow installed from:* pip\n> *TensorFlow version:* 1.2.1\n> Python version: 3.6.1 (Miniconda3 4.3.11-64bit)\n> *Bazel version (if compiling from source):* I don't know.\n> *CUDA/cuDNN version:* I don't use because my graphic card is AMD-Radeon\n> *GPU model and memory:* AMD Radeon R7 M260/M265\n> *CPU model:* Intel\u00ae Core\u2122 i7-4510U CPU @ 2.00GHz \u00d7 4\n> *RAM Memory:* 16GiB (2x8Gib dual-channel)\n> Exact command to reproduce:\n>\n> history = CumulativeHistory()\n> callbacks = [history]\n> from keras import backend as K\n> if K.backend() == 'tensorflow':\n>   board = keras.callbacks.TensorBoard(log_dir=f\"{self.prefix_folder_logs}{time()}\",\n>                                     histogram_freq=1, write_graph=True, write_images=True)\n>   callbacks.append(board)\n> metric_to_compare = 'val_euclidean_distance'\n> print(\"Begin of training model...\")\n> for i in range(MAX_NUM_EPOCHS):\n>   model.fit_generator(self.train_inputs, steps_per_epoch=self.train_inputs.steps_per_epoch(),\n>                       validation_data=test_input_sequence, validation_steps=steps_test,\n>                       max_queue_size=self.train_inputs.workers, epochs=i+1, initial_epoch=i,\n>                       workers=self.train_inputs.workers, use_multiprocessing=True,\n>                       callbacks = callbacks)\n>   try:\n>     metrics_diff = history.history[metric_to_compare][i] - min(history.history[metric_to_compare][:i])\n>   except:\n>     metrics_diff = -1\n>   if metrics_diff < 0:\n>     self._save_models(i)\n>     self.data_processor = None  # Empty memory\n>     best_epoch = i\n>     num_worse_epochs = 0\n>   elif metrics_diff > 0:\n>     num_worse_epochs += 1\n>     if num_worse_epochs >= PATIENCE:\n>       print(\"Ran out of patience. Stopping training.\")\n>       break\n> print(\"End of training model.\")\n>\n> *Collected information*:\n>\n> (myenv) myuser@mymachine:~$ ./tf_env_collect.sh\n> Collecting system information...\n> 2017-07-28 21:05:00.140602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n> 2017-07-28 21:05:00.140632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n> 2017-07-28 21:05:00.140645: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n> 2017-07-28 21:05:00.140650: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n> 2017-07-28 21:05:00.140656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n> Wrote environment to tf_env.txt. You can review the contents of that file.\n> and use it to populate the fields in the github issue template.\n>\n> cat tf_env.txt\n>\n> (myenv) myuser@mymachine:~$ cat tf_env.txt\n>\n> == cat /etc/issue ===============================================\n> Linux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n> VERSION=\"14.04.5 LTS, Trusty Tahr\"\n> VERSION_ID=\"14.04\"\n>\n> == are we in docker =============================================\n> No\n>\n> == compiler =====================================================\n> c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n> Copyright (C) 2013 Free Software Foundation, Inc.\n> This is free software; see the source for copying conditions.  There is NO\n> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n>\n>\n> == uname -a =====================================================\n> Linux mymachine 4.4.0-87-generic #110~14.04.1-Ubuntu SMP Tue Jul 18 14:51:32 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n>\n> == check pips ===================================================\n> numpy (1.13.1)\n> protobuf (3.3.0)\n> tensorflow (1.2.1)\n>\n> == check for virtualenv =========================================\n> False\n>\n> == tensorflow import ============================================\n> tf.VERSION = 1.2.1\n> tf.GIT_VERSION = v1.2.0-5-g435cdfc\n> tf.COMPILER_VERSION = v1.2.0-5-g435cdfc\n> Sanity check: array([1], dtype=int32)\n>\n> == env ==========================================================\n> LD_LIBRARY_PATH /opt/programs/miniconda3/envs/myenv/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin::/opt/programs/acml/gfortran64/lib\n> DYLD_LIBRARY_PATH is unset\n>\n> == nvidia-smi ===================================================\n> ./tf_env_collect.sh: linha 105: nvidia-smi: comando n\u00e3o encontrado\n>\n> == cuda libs  ===================================================\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11157#issuecomment-318790632>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim_x0X7z4fwR27nf-QB5eI0azF46Pks5sSn5qgaJpZM4OKDmJ>\n> .\n>\n"}