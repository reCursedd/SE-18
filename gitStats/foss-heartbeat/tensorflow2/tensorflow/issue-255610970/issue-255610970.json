{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12851", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12851/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12851/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12851/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12851", "id": 255610970, "node_id": "MDU6SXNzdWUyNTU2MTA5NzA=", "number": 12851, "title": "Dataset Unzip Operation", "user": {"login": "eaplatanios", "id": 1294940, "node_id": "MDQ6VXNlcjEyOTQ5NDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1294940?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eaplatanios", "html_url": "https://github.com/eaplatanios", "followers_url": "https://api.github.com/users/eaplatanios/followers", "following_url": "https://api.github.com/users/eaplatanios/following{/other_user}", "gists_url": "https://api.github.com/users/eaplatanios/gists{/gist_id}", "starred_url": "https://api.github.com/users/eaplatanios/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eaplatanios/subscriptions", "organizations_url": "https://api.github.com/users/eaplatanios/orgs", "repos_url": "https://api.github.com/users/eaplatanios/repos", "events_url": "https://api.github.com/users/eaplatanios/events{/privacy}", "received_events_url": "https://api.github.com/users/eaplatanios/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 19, "created_at": "2017-09-06T13:50:22Z", "updated_at": "2018-10-10T18:00:38Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> This is a comment I originally posted to the \"Redesigning input pipelines\" issue, but I think it went unnoticed given the amount of comments on that thread. Given that issue is now closed (for good reason :)), I decided to post it as a separate issue.</p>\n<p>I currently cannot see a way currently to \"unzip\" a dataset. Let's say we have a trainable model that has both a train/fit method and a infer/predict method. Let's call the type of the (potentially) nested structure of inputs to our model <code>I</code> and the type of training inputs, which are only needed when training (e.g., supervision labels), <code>TI</code>. In this case, we want the train method to accept datasets with elements of type <code>(I, TI)</code> (i.e., a tuple of <code>I</code> and <code>TI</code>) and the predict method to accept datasets with elements of type <code>I</code> or <code>(I, TI)</code> (in which case it would ignore the labels). We also want the model to only have one underlying graph, supporting all these types of input. The way I could see doing that was for the underlying model to construct two iterators (one with elements type <code>I</code> and one with type <code>TI</code>) and initialize them according to the provided datasets. However, if somebody provides a dataset with elements of type <code>(I, TI)</code> to the train method, there is no way to unzip this dataset and initialize both iterators. One has to use <code>Dataset.map</code> twice, which is not efficient (I think but please correct me if I'm wrong) and which may also not pull matching elements from the datasets (if each pull advances the current index in the original first dataset -- I'm not sure if that happens).</p>", "body_text": "@mrry This is a comment I originally posted to the \"Redesigning input pipelines\" issue, but I think it went unnoticed given the amount of comments on that thread. Given that issue is now closed (for good reason :)), I decided to post it as a separate issue.\nI currently cannot see a way currently to \"unzip\" a dataset. Let's say we have a trainable model that has both a train/fit method and a infer/predict method. Let's call the type of the (potentially) nested structure of inputs to our model I and the type of training inputs, which are only needed when training (e.g., supervision labels), TI. In this case, we want the train method to accept datasets with elements of type (I, TI) (i.e., a tuple of I and TI) and the predict method to accept datasets with elements of type I or (I, TI) (in which case it would ignore the labels). We also want the model to only have one underlying graph, supporting all these types of input. The way I could see doing that was for the underlying model to construct two iterators (one with elements type I and one with type TI) and initialize them according to the provided datasets. However, if somebody provides a dataset with elements of type (I, TI) to the train method, there is no way to unzip this dataset and initialize both iterators. One has to use Dataset.map twice, which is not efficient (I think but please correct me if I'm wrong) and which may also not pull matching elements from the datasets (if each pull advances the current index in the original first dataset -- I'm not sure if that happens).", "body": "@mrry This is a comment I originally posted to the \"Redesigning input pipelines\" issue, but I think it went unnoticed given the amount of comments on that thread. Given that issue is now closed (for good reason :)), I decided to post it as a separate issue.\r\n\r\nI currently cannot see a way currently to \"unzip\" a dataset. Let's say we have a trainable model that has both a train/fit method and a infer/predict method. Let's call the type of the (potentially) nested structure of inputs to our model `I` and the type of training inputs, which are only needed when training (e.g., supervision labels), `TI`. In this case, we want the train method to accept datasets with elements of type `(I, TI)` (i.e., a tuple of `I` and `TI`) and the predict method to accept datasets with elements of type `I` or `(I, TI)` (in which case it would ignore the labels). We also want the model to only have one underlying graph, supporting all these types of input. The way I could see doing that was for the underlying model to construct two iterators (one with elements type `I` and one with type `TI`) and initialize them according to the provided datasets. However, if somebody provides a dataset with elements of type `(I, TI)` to the train method, there is no way to unzip this dataset and initialize both iterators. One has to use `Dataset.map` twice, which is not efficient (I think but please correct me if I'm wrong) and which may also not pull matching elements from the datasets (if each pull advances the current index in the original first dataset -- I'm not sure if that happens)."}