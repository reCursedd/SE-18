{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/327498932", "html_url": "https://github.com/tensorflow/tensorflow/issues/12851#issuecomment-327498932", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12851", "id": 327498932, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNzQ5ODkzMg==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-06T14:21:31Z", "updated_at": "2017-09-06T14:21:31Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks for reposting this <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1294940\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/eaplatanios\">@eaplatanios</a>! I'd like to understand the use case more, so we can focus on the appropriate efficient solution. Just to check my understanding, are you proposing a transformation with the following type? (Please forgive the abuse of Haskell notation below :)....)</p>\n<div class=\"highlight highlight-source-haskell\"><pre><span class=\"pl-en\">unzip</span> <span class=\"pl-k\">::</span> <span class=\"pl-en\">Dataset</span> (<span class=\"pl-en\">I</span>, <span class=\"pl-en\">TI</span>) <span class=\"pl-k\">-&gt;</span> (<span class=\"pl-en\">Dataset</span> <span class=\"pl-en\">I</span>, <span class=\"pl-en\">Dataset</span> <span class=\"pl-en\">TI</span>)</pre></div>\n<p>If that's the case, you could do that by mapping twice over the the input, with the first map selecting the first component of the tuple, and the second map selecting the second component of the tuple. This would work\u2014<code>Dataset</code> objects are stateless, and the state is in the <code>Iterator</code>\u2014but you're right that it would be inefficient because (at least currently) the upstream work of producing the input (reading from files, parsing, etc.) would be duplicated.</p>\n<p>How could we avoid that duplication? Today, the easiest way to do that would be by adding a <code>Dataset.cache()</code> before the <code>unzip</code>, so that the elements are computed once and subsequently read from the cache (either in memory or on disk). However, this only works with finite <code>Dataset</code> objects, which is not as featureful as a true <code>unzip</code>! Plus there's not (necessarily) any need to cache the entire dataset, depending on how you are planning to consume the iterators.</p>\n<p>I'm a little unclear about why you'd want <em>two</em> iterators as input to the graph in your example. I'd presume that training and test data come from two different sources, so it wouldn't be a problem to create different iterators for those cases, and these could have the appropriate type <code>(I, TI)</code> or <code>(I)</code> as necessary. However, if you have a training graph and an input dataset of type <code>(I, TI)</code>, why would you prefer to unzip the datasets and make two iterators, rather than making one iterator and destructuring the elements it yields? The only reason I can think of\u2014but I haven't thought too hard about this\u2014is that you'd like to advance the iterators at different rates, but this creates a buffering issue: how many elements of type <code>TI</code> should be buffered while we're consuming the iterator of type <code>I</code> (or vice versa) to avoid recomputation?</p>\n<p>However, just because I can't think of an application doesn't mean that there isn't one! I'd be interested to learn more about your feature request....</p>", "body_text": "Thanks for reposting this @eaplatanios! I'd like to understand the use case more, so we can focus on the appropriate efficient solution. Just to check my understanding, are you proposing a transformation with the following type? (Please forgive the abuse of Haskell notation below :)....)\nunzip :: Dataset (I, TI) -> (Dataset I, Dataset TI)\nIf that's the case, you could do that by mapping twice over the the input, with the first map selecting the first component of the tuple, and the second map selecting the second component of the tuple. This would work\u2014Dataset objects are stateless, and the state is in the Iterator\u2014but you're right that it would be inefficient because (at least currently) the upstream work of producing the input (reading from files, parsing, etc.) would be duplicated.\nHow could we avoid that duplication? Today, the easiest way to do that would be by adding a Dataset.cache() before the unzip, so that the elements are computed once and subsequently read from the cache (either in memory or on disk). However, this only works with finite Dataset objects, which is not as featureful as a true unzip! Plus there's not (necessarily) any need to cache the entire dataset, depending on how you are planning to consume the iterators.\nI'm a little unclear about why you'd want two iterators as input to the graph in your example. I'd presume that training and test data come from two different sources, so it wouldn't be a problem to create different iterators for those cases, and these could have the appropriate type (I, TI) or (I) as necessary. However, if you have a training graph and an input dataset of type (I, TI), why would you prefer to unzip the datasets and make two iterators, rather than making one iterator and destructuring the elements it yields? The only reason I can think of\u2014but I haven't thought too hard about this\u2014is that you'd like to advance the iterators at different rates, but this creates a buffering issue: how many elements of type TI should be buffered while we're consuming the iterator of type I (or vice versa) to avoid recomputation?\nHowever, just because I can't think of an application doesn't mean that there isn't one! I'd be interested to learn more about your feature request....", "body": "Thanks for reposting this @eaplatanios! I'd like to understand the use case more, so we can focus on the appropriate efficient solution. Just to check my understanding, are you proposing a transformation with the following type? (Please forgive the abuse of Haskell notation below :)....)\r\n\r\n```haskell\r\nunzip :: Dataset (I, TI) -> (Dataset I, Dataset TI)\r\n```\r\n\r\nIf that's the case, you could do that by mapping twice over the the input, with the first map selecting the first component of the tuple, and the second map selecting the second component of the tuple. This would work\u2014`Dataset` objects are stateless, and the state is in the `Iterator`\u2014but you're right that it would be inefficient because (at least currently) the upstream work of producing the input (reading from files, parsing, etc.) would be duplicated.\r\n\r\nHow could we avoid that duplication? Today, the easiest way to do that would be by adding a `Dataset.cache()` before the `unzip`, so that the elements are computed once and subsequently read from the cache (either in memory or on disk). However, this only works with finite `Dataset` objects, which is not as featureful as a true `unzip`! Plus there's not (necessarily) any need to cache the entire dataset, depending on how you are planning to consume the iterators.\r\n\r\nI'm a little unclear about why you'd want *two* iterators as input to the graph in your example. I'd presume that training and test data come from two different sources, so it wouldn't be a problem to create different iterators for those cases, and these could have the appropriate type `(I, TI)` or `(I)` as necessary. However, if you have a training graph and an input dataset of type `(I, TI)`, why would you prefer to unzip the datasets and make two iterators, rather than making one iterator and destructuring the elements it yields? The only reason I can think of\u2014but I haven't thought too hard about this\u2014is that you'd like to advance the iterators at different rates, but this creates a buffering issue: how many elements of type `TI` should be buffered while we're consuming the iterator of type `I` (or vice versa) to avoid recomputation?\r\n\r\nHowever, just because I can't think of an application doesn't mean that there isn't one! I'd be interested to learn more about your feature request....\r\n\r\n"}