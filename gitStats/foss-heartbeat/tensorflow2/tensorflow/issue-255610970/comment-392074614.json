{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/392074614", "html_url": "https://github.com/tensorflow/tensorflow/issues/12851#issuecomment-392074614", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12851", "id": 392074614, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MjA3NDYxNA==", "user": {"login": "kho", "id": 460372, "node_id": "MDQ6VXNlcjQ2MDM3Mg==", "avatar_url": "https://avatars2.githubusercontent.com/u/460372?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kho", "html_url": "https://github.com/kho", "followers_url": "https://api.github.com/users/kho/followers", "following_url": "https://api.github.com/users/kho/following{/other_user}", "gists_url": "https://api.github.com/users/kho/gists{/gist_id}", "starred_url": "https://api.github.com/users/kho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kho/subscriptions", "organizations_url": "https://api.github.com/users/kho/orgs", "repos_url": "https://api.github.com/users/kho/repos", "events_url": "https://api.github.com/users/kho/events{/privacy}", "received_events_url": "https://api.github.com/users/kho/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-25T14:25:26Z", "updated_at": "2018-05-25T14:25:26Z", "author_association": "NONE", "body_html": "<p>cache() doesn't seem to prevent repeated work in my simple test below:</p>\n<pre><code>def one_to_two(x):\n  def work(x):\n    print('work', x)\n    return np.ones([2], dtype=np.int32) * x, np.ones([3], dtype=np.int32) * -x\n  \n  pos, neg = tf.py_func(work, [x], [np.int32, np.int32], stateful=False)\n  return pos, neg\n\nwith tf.Graph().as_default():\n  d0 = tf.data.Dataset.range(12).map(one_to_two).cache()\n  d1 = d0.map(lambda *x: x[0])\n  d2 = d0.map(lambda *x: x[1])\n\n  v1 = d1.make_one_shot_iterator().get_next()\n  v2 = d2.make_one_shot_iterator().get_next()\n\n  with tf.Session() as sess:\n    # \"work 0\" printed twice.\n    print(sess.run([v1, v2]))\n</code></pre>", "body_text": "cache() doesn't seem to prevent repeated work in my simple test below:\ndef one_to_two(x):\n  def work(x):\n    print('work', x)\n    return np.ones([2], dtype=np.int32) * x, np.ones([3], dtype=np.int32) * -x\n  \n  pos, neg = tf.py_func(work, [x], [np.int32, np.int32], stateful=False)\n  return pos, neg\n\nwith tf.Graph().as_default():\n  d0 = tf.data.Dataset.range(12).map(one_to_two).cache()\n  d1 = d0.map(lambda *x: x[0])\n  d2 = d0.map(lambda *x: x[1])\n\n  v1 = d1.make_one_shot_iterator().get_next()\n  v2 = d2.make_one_shot_iterator().get_next()\n\n  with tf.Session() as sess:\n    # \"work 0\" printed twice.\n    print(sess.run([v1, v2]))", "body": "cache() doesn't seem to prevent repeated work in my simple test below:\r\n\r\n```\r\ndef one_to_two(x):\r\n  def work(x):\r\n    print('work', x)\r\n    return np.ones([2], dtype=np.int32) * x, np.ones([3], dtype=np.int32) * -x\r\n  \r\n  pos, neg = tf.py_func(work, [x], [np.int32, np.int32], stateful=False)\r\n  return pos, neg\r\n\r\nwith tf.Graph().as_default():\r\n  d0 = tf.data.Dataset.range(12).map(one_to_two).cache()\r\n  d1 = d0.map(lambda *x: x[0])\r\n  d2 = d0.map(lambda *x: x[1])\r\n\r\n  v1 = d1.make_one_shot_iterator().get_next()\r\n  v2 = d2.make_one_shot_iterator().get_next()\r\n\r\n  with tf.Session() as sess:\r\n    # \"work 0\" printed twice.\r\n    print(sess.run([v1, v2]))\r\n```"}