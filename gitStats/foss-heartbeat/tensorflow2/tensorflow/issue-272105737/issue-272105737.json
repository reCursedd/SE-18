{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14352", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14352/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14352/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14352/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14352", "id": 272105737, "node_id": "MDU6SXNzdWUyNzIxMDU3Mzc=", "number": 14352, "title": "How can I export the model as serving format?", "user": {"login": "tcclks", "id": 13497701, "node_id": "MDQ6VXNlcjEzNDk3NzAx", "avatar_url": "https://avatars0.githubusercontent.com/u/13497701?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tcclks", "html_url": "https://github.com/tcclks", "followers_url": "https://api.github.com/users/tcclks/followers", "following_url": "https://api.github.com/users/tcclks/following{/other_user}", "gists_url": "https://api.github.com/users/tcclks/gists{/gist_id}", "starred_url": "https://api.github.com/users/tcclks/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tcclks/subscriptions", "organizations_url": "https://api.github.com/users/tcclks/orgs", "repos_url": "https://api.github.com/users/tcclks/repos", "events_url": "https://api.github.com/users/tcclks/events{/privacy}", "received_events_url": "https://api.github.com/users/tcclks/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-08T08:03:15Z", "updated_at": "2017-11-08T22:14:25Z", "closed_at": "2017-11-08T22:13:51Z", "author_association": "NONE", "body_html": "<h1>I want to get the serving model format for using server.</h1>\n<p>To export estimator m there are four steps:<br>\n1.Define estimator's features.</p>\n<p>2.Create a feature config.</p>\n<p>3.Build an export_input_fn suitable for use in serving.</p>\n<p>4.Export the model using export_savedmodel().</p>\n<p>I try to use \uff1a<br>\nexport_dir_base = \"./serving_save_model\"<br>\nfeature_spec = {<br>\n'times': tf.placeholder(tf.float32, name='times')<br>\n}<br>\nserving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)</p>\n<pre><code>estimator.export_savedmodel(export_dir_base, serving_input_fn)\n</code></pre>\n<p>But I encountered an error like this:</p>\n<p>Traceback (most recent call last):<br>\nFile \"E:/MyProject/Py/tensorFlow_time_series_predict/train_lstm_multivariate.py\", line 231, in <br>\nestimator.export_savedmodel(export_dir_base, serving_input_fn)<br>\nFile \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 504, in export_savedmodel<br>\nserving_input_receiver = serving_input_receiver_fn()<br>\nFile \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\export\\export.py\", line 142, in serving_input_receiver_fn<br>\nfeatures = parsing_ops.parse_example(serialized_tf_example, feature_spec)<br>\nFile \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\", line 577, in parse_example<br>\n[VarLenFeature, SparseFeature, FixedLenFeature, FixedLenSequenceFeature])<br>\nFile \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\", line 291, in _features_to_raw_params<br>\nraise ValueError(\"Invalid feature %s:%s.\" % (key, feature))<br>\nValueError: Invalid feature times:Tensor(\"times:0\", dtype=float32).</p>\n<p>How should I use it correctly?<br>\nThanks so much\uff01</p>", "body_text": "I want to get the serving model format for using server.\nTo export estimator m there are four steps:\n1.Define estimator's features.\n2.Create a feature config.\n3.Build an export_input_fn suitable for use in serving.\n4.Export the model using export_savedmodel().\nI try to use \uff1a\nexport_dir_base = \"./serving_save_model\"\nfeature_spec = {\n'times': tf.placeholder(tf.float32, name='times')\n}\nserving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\nestimator.export_savedmodel(export_dir_base, serving_input_fn)\n\nBut I encountered an error like this:\nTraceback (most recent call last):\nFile \"E:/MyProject/Py/tensorFlow_time_series_predict/train_lstm_multivariate.py\", line 231, in \nestimator.export_savedmodel(export_dir_base, serving_input_fn)\nFile \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 504, in export_savedmodel\nserving_input_receiver = serving_input_receiver_fn()\nFile \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\export\\export.py\", line 142, in serving_input_receiver_fn\nfeatures = parsing_ops.parse_example(serialized_tf_example, feature_spec)\nFile \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\", line 577, in parse_example\n[VarLenFeature, SparseFeature, FixedLenFeature, FixedLenSequenceFeature])\nFile \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\", line 291, in _features_to_raw_params\nraise ValueError(\"Invalid feature %s:%s.\" % (key, feature))\nValueError: Invalid feature times:Tensor(\"times:0\", dtype=float32).\nHow should I use it correctly?\nThanks so much\uff01", "body": "# I want to get the serving model format for using server.\r\nTo export estimator m there are four steps:\r\n1.Define estimator's features.\r\n\r\n2.Create a feature config.\r\n\r\n3.Build an export_input_fn suitable for use in serving.\r\n\r\n4.Export the model using export_savedmodel().\r\n\r\n\r\nI try to use \uff1a\r\n    export_dir_base = \"./serving_save_model\"\r\n    feature_spec = {\r\n                    'times': tf.placeholder(tf.float32, name='times')\r\n                    }\r\n    serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\r\n\r\n    estimator.export_savedmodel(export_dir_base, serving_input_fn)\r\n\r\nBut I encountered an error like this:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:/MyProject/Py/tensorFlow_time_series_predict/train_lstm_multivariate.py\", line 231, in <module>\r\n    estimator.export_savedmodel(export_dir_base, serving_input_fn)\r\n  File \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 504, in export_savedmodel\r\n    serving_input_receiver = serving_input_receiver_fn()\r\n  File \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\export\\export.py\", line 142, in serving_input_receiver_fn\r\n    features = parsing_ops.parse_example(serialized_tf_example, feature_spec)\r\n  File \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\", line 577, in parse_example\r\n    [VarLenFeature, SparseFeature, FixedLenFeature, FixedLenSequenceFeature])\r\n  File \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\", line 291, in _features_to_raw_params\r\n    raise ValueError(\"Invalid feature %s:%s.\" % (key, feature))\r\nValueError: Invalid feature times:Tensor(\"times:0\", dtype=float32).\r\n\r\n\r\nHow should I use it correctly?\r\nThanks so much\uff01\r\n"}