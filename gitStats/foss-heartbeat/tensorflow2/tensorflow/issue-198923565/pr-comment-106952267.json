{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/106952267", "pull_request_review_id": 27882337, "id": 106952267, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwNjk1MjI2Nw==", "diff_hunk": "@@ -199,32 +199,111 @@ __global__ void MaxPoolBackward(const int nthreads, const dtype* top_diff,\n   }\n }\n \n-#undef CUDA_1D_KERNEL_LOOP\n-}  // namespace\n+template <typename dtype>\n+__global__ void MaxPoolGradBackwardNoMaskNCHW(\n+    const int nthreads, const dtype* bottom_data, const dtype* output_data,\n+    const int pooled_height, const int pooled_width, const int channels,\n+    const int height, const int width, const int kernel_h, const int kernel_w,\n+    const int stride_h, const int stride_w, const int pad_t, const int pad_l,\n+    const dtype* top_diff, dtype* bottom_diff) {\n+  CUDA_1D_KERNEL_LOOP(index, nthreads) {\n+    // First find out the index to the maximum, since we have no mask.\n+    int pw = index % pooled_width;\n+    int ph = (index / pooled_width) % pooled_height;\n+    int c = (index / pooled_width / pooled_height) % channels;\n+    int n = index / pooled_width / pooled_height / channels;\n+    int hstart = ph * stride_h - pad_t;\n+    int wstart = pw * stride_w - pad_l;\n+    const int hend = min(hstart + kernel_h, height);\n+    const int wend = min(wstart + kernel_w, width);\n+    hstart = max(hstart, 0);\n+    wstart = max(wstart, 0);\n+    bool should_stop = false;\n+    int maxidx = -1;\n+    const dtype* bottom_data_n = bottom_data + n * channels * height * width;\n+    // Propagate only first value from top_diff corresponding to the maximum.\n+    for (int h = hstart; h < hend && !should_stop; ++h) {\n+      for (int w = wstart; w < wend && !should_stop; ++w) {\n+        int idx = c * height * width + h * width + w;\n+        if (output_data[index] == bottom_data_n[idx]) {\n+          maxidx = idx;\n+          should_stop = true;\n+        }\n+      }\n+    }\n+    // Set the bottom diff (atomic is not necessary). The index could still be\n+    // uninitialized, if all the bottom_data are NaN.\n+    if (maxidx != -1) {\n+      bottom_diff[index] = top_diff[n * channels * height * width + maxidx];\n+    }\n+  }\n+}\n \n-bool MaxPoolForwardWithOptionalArgmax(\n-    const float* bottom_data, const int batch, const int height,\n-    const int width, const int channels, const int pooled_height,\n-    const int pooled_width, const int kernel_h, const int kernel_w,\n+template <typename dtype>\n+__global__ void MaxPoolGradBackwardNoMaskNHWC(\n+    const int nthreads, const dtype* bottom_data, const dtype* output_data,\n+    const int pooled_height, const int pooled_width, const int channels,\n+    const int height, const int width, const int kernel_h, const int kernel_w,\n     const int stride_h, const int stride_w, const int pad_t, const int pad_l,\n-    float* top_data, int64* mask, const Eigen::GpuDevice& d) {\n-  const int kThreadsPerBlock = 1024;\n-  const int output_size = batch * channels * pooled_height * pooled_width;\n+    const dtype* top_diff, dtype* bottom_diff) {", "path": "tensorflow/core/kernels/maxpooling_op_gpu.cu.cc", "position": 73, "original_position": 59, "commit_id": "44449164baa4a004f69b5975a23c6335bc09797f", "original_commit_id": "3fdc5a2152162c0854194b3a84e4f2f89296e1a7", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "I realize that you didn't start this, but could you please add a comment clarifying what \"top\" and \"bottom\" refer to? (I agree that it is preferably to use those terms compared to further overloading \"input\" and \"output\".)\r\n\r\nSame everywhere.", "created_at": "2017-03-20T16:43:55Z", "updated_at": "2017-03-28T04:33:24Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/6664#discussion_r106952267", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6664", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/106952267"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/6664#discussion_r106952267"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6664"}}, "body_html": "<p>I realize that you didn't start this, but could you please add a comment clarifying what \"top\" and \"bottom\" refer to? (I agree that it is preferably to use those terms compared to further overloading \"input\" and \"output\".)</p>\n<p>Same everywhere.</p>", "body_text": "I realize that you didn't start this, but could you please add a comment clarifying what \"top\" and \"bottom\" refer to? (I agree that it is preferably to use those terms compared to further overloading \"input\" and \"output\".)\nSame everywhere."}