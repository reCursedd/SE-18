{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/369399577", "html_url": "https://github.com/tensorflow/tensorflow/issues/16291#issuecomment-369399577", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16291", "id": 369399577, "node_id": "MDEyOklzc3VlQ29tbWVudDM2OTM5OTU3Nw==", "user": {"login": "ChengshuLi", "id": 6732996, "node_id": "MDQ6VXNlcjY3MzI5OTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/6732996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChengshuLi", "html_url": "https://github.com/ChengshuLi", "followers_url": "https://api.github.com/users/ChengshuLi/followers", "following_url": "https://api.github.com/users/ChengshuLi/following{/other_user}", "gists_url": "https://api.github.com/users/ChengshuLi/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChengshuLi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChengshuLi/subscriptions", "organizations_url": "https://api.github.com/users/ChengshuLi/orgs", "repos_url": "https://api.github.com/users/ChengshuLi/repos", "events_url": "https://api.github.com/users/ChengshuLi/events{/privacy}", "received_events_url": "https://api.github.com/users/ChengshuLi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-28T22:05:35Z", "updated_at": "2018-03-01T03:55:55Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=28546240\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tensorflowbutler\">@tensorflowbutler</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5453737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tatatodd\">@tatatodd</a></p>\n<p>The issue still persists. I think this is a bug.</p>\n<p>I tried to debug a little bit and I found that when I called set_visible_device_list(\"1\"), it also set \"allocator_type\" to \"1\", which is an invalid value for allocator_type. That's why the error message is \"Invalid allocator type: 0\".</p>\n<p>In other words, allocator_type and visible_device_list seem to share the same memory location.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/3378865c5509dfb6d18e6f95f28757437f67d3da/tensorflow/core/protobuf/config.proto\">https://github.com/tensorflow/tensorflow/blob/3378865c5509dfb6d18e6f95f28757437f67d3da/tensorflow/core/protobuf/config.proto</a></p>\n<p>Please see the code snippet below as an example</p>\n<pre><code>auto options = tensorflow::SessionOptions();\nconst auto&amp; static_gpu_options = options.config.gpu_options();\nauto mutable_gpu_options = options.config.mutable_gpu_options();\n\nstd::cout &lt;&lt; static_gpu_options.visible_device_list() &lt;&lt; std::endl;     // print \"\"\nstd::cout &lt;&lt; static_gpu_options.allocator_type() &lt;&lt; std::endl;          // print \"\"\n\nmutable_gpu_options-&gt;set_visible_device_list(\"1\");\n\nstd::cout &lt;&lt; static_gpu_options.visible_device_list() &lt;&lt; std::endl;     // print \"1\"\nstd::cout &lt;&lt; static_gpu_options.allocator_type() &lt;&lt; std::endl;          // print \"1\"\n\nmutable_gpu_options-&gt;set_allocator_type(\"\");\n\nstd::cout &lt;&lt; static_gpu_options.visible_device_list() &lt;&lt; std::endl;     // print \"\"\nstd::cout &lt;&lt; static_gpu_options.allocator_type() &lt;&lt; std::endl;          // print \"\"\n</code></pre>", "body_text": "@tensorflowbutler @tatatodd\nThe issue still persists. I think this is a bug.\nI tried to debug a little bit and I found that when I called set_visible_device_list(\"1\"), it also set \"allocator_type\" to \"1\", which is an invalid value for allocator_type. That's why the error message is \"Invalid allocator type: 0\".\nIn other words, allocator_type and visible_device_list seem to share the same memory location.\nhttps://github.com/tensorflow/tensorflow/blob/3378865c5509dfb6d18e6f95f28757437f67d3da/tensorflow/core/protobuf/config.proto\nPlease see the code snippet below as an example\nauto options = tensorflow::SessionOptions();\nconst auto& static_gpu_options = options.config.gpu_options();\nauto mutable_gpu_options = options.config.mutable_gpu_options();\n\nstd::cout << static_gpu_options.visible_device_list() << std::endl;     // print \"\"\nstd::cout << static_gpu_options.allocator_type() << std::endl;          // print \"\"\n\nmutable_gpu_options->set_visible_device_list(\"1\");\n\nstd::cout << static_gpu_options.visible_device_list() << std::endl;     // print \"1\"\nstd::cout << static_gpu_options.allocator_type() << std::endl;          // print \"1\"\n\nmutable_gpu_options->set_allocator_type(\"\");\n\nstd::cout << static_gpu_options.visible_device_list() << std::endl;     // print \"\"\nstd::cout << static_gpu_options.allocator_type() << std::endl;          // print \"\"", "body": "@tensorflowbutler @tatatodd \r\n\r\nThe issue still persists. I think this is a bug.\r\n\r\nI tried to debug a little bit and I found that when I called set_visible_device_list(\"1\"), it also set \"allocator_type\" to \"1\", which is an invalid value for allocator_type. That's why the error message is \"Invalid allocator type: 0\". \r\n\r\nIn other words, allocator_type and visible_device_list seem to share the same memory location.\r\nhttps://github.com/tensorflow/tensorflow/blob/3378865c5509dfb6d18e6f95f28757437f67d3da/tensorflow/core/protobuf/config.proto\r\n\r\nPlease see the code snippet below as an example\r\n\r\n```\r\nauto options = tensorflow::SessionOptions();\r\nconst auto& static_gpu_options = options.config.gpu_options();\r\nauto mutable_gpu_options = options.config.mutable_gpu_options();\r\n\r\nstd::cout << static_gpu_options.visible_device_list() << std::endl;     // print \"\"\r\nstd::cout << static_gpu_options.allocator_type() << std::endl;          // print \"\"\r\n\r\nmutable_gpu_options->set_visible_device_list(\"1\");\r\n\r\nstd::cout << static_gpu_options.visible_device_list() << std::endl;     // print \"1\"\r\nstd::cout << static_gpu_options.allocator_type() << std::endl;          // print \"1\"\r\n\r\nmutable_gpu_options->set_allocator_type(\"\");\r\n\r\nstd::cout << static_gpu_options.visible_device_list() << std::endl;     // print \"\"\r\nstd::cout << static_gpu_options.allocator_type() << std::endl;          // print \"\"\r\n```"}