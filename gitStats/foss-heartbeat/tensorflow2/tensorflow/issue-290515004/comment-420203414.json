{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/420203414", "html_url": "https://github.com/tensorflow/tensorflow/issues/16291#issuecomment-420203414", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16291", "id": 420203414, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMDIwMzQxNA==", "user": {"login": "kerolos", "id": 3300016, "node_id": "MDQ6VXNlcjMzMDAwMTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/3300016?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kerolos", "html_url": "https://github.com/kerolos", "followers_url": "https://api.github.com/users/kerolos/followers", "following_url": "https://api.github.com/users/kerolos/following{/other_user}", "gists_url": "https://api.github.com/users/kerolos/gists{/gist_id}", "starred_url": "https://api.github.com/users/kerolos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kerolos/subscriptions", "organizations_url": "https://api.github.com/users/kerolos/orgs", "repos_url": "https://api.github.com/users/kerolos/repos", "events_url": "https://api.github.com/users/kerolos/events{/privacy}", "received_events_url": "https://api.github.com/users/kerolos/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-11T09:09:50Z", "updated_at": "2018-09-11T09:09:50Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6732996\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ChengshuLi\">@ChengshuLi</a><br>\nI would like to ask you if you solved this issue. because i figured it out the same as you,  the allocator_type and visible_device_list  point to the same memory.<br>\nif you could provide me with the solution to avoid that form happen.<br>\nI am using Tensorflow 1.71, thanks in advance.</p>", "body_text": "@ChengshuLi\nI would like to ask you if you solved this issue. because i figured it out the same as you,  the allocator_type and visible_device_list  point to the same memory.\nif you could provide me with the solution to avoid that form happen.\nI am using Tensorflow 1.71, thanks in advance.", "body": "@ChengshuLi  \r\nI would like to ask you if you solved this issue. because i figured it out the same as you,  the allocator_type and visible_device_list  point to the same memory. \r\nif you could provide me with the solution to avoid that form happen. \r\nI am using Tensorflow 1.71, thanks in advance.\r\n"}