{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16291", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16291/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16291/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16291/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16291", "id": 290515004, "node_id": "MDU6SXNzdWUyOTA1MTUwMDQ=", "number": 16291, "title": "[bug] Specify GPU device error when using session_options.config.mutable_gpu_options()->set_visible_device_list", "user": {"login": "mattdingmeng", "id": 26105061, "node_id": "MDQ6VXNlcjI2MTA1MDYx", "avatar_url": "https://avatars3.githubusercontent.com/u/26105061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mattdingmeng", "html_url": "https://github.com/mattdingmeng", "followers_url": "https://api.github.com/users/mattdingmeng/followers", "following_url": "https://api.github.com/users/mattdingmeng/following{/other_user}", "gists_url": "https://api.github.com/users/mattdingmeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/mattdingmeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mattdingmeng/subscriptions", "organizations_url": "https://api.github.com/users/mattdingmeng/orgs", "repos_url": "https://api.github.com/users/mattdingmeng/repos", "events_url": "https://api.github.com/users/mattdingmeng/events{/privacy}", "received_events_url": "https://api.github.com/users/mattdingmeng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 20, "created_at": "2018-01-22T15:53:27Z", "updated_at": "2018-09-15T16:35:37Z", "closed_at": "2018-05-26T18:37:16Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes.<br>\nsession_options.config.mutable_gpu_options()-&gt;set_visible_device_list(\"0\");<br>\nsession-&gt;reset(tensorflow::NewSession(session_options)); // Error in this line<br>\nStatus session_create_status = (*session)-&gt;Create(graph_def);</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\n1.4.0</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\n2.7.12</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\n0.9.0</p>\n</li>\n<li>\n<p><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\n5.4</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nCUDA 8.0  /  cuDNN 6.0.21</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:<br>\nQuadro P6000, 24G GPU memory</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:</p>\n</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I built the tensorflow C++ API from the source using Bazel 0.9.0. When I link the shared library libtensorflow_cc.so, my code works fine. (I do not need to link libtensorflow_framework.so, since I used '--config=monolithic' when I build tensorflow using bazel.)<br>\nHowever, I want to specify the GPU device in my code using this function to set gpu options:<br>\nsession_options.config.mutable_gpu_options()-&gt;set_visible_device_list(\"0\");<br>\nsession-&gt;reset(tensorflow::NewSession(session_options)); // <strong>Error in this line</strong></p>\n<h3>Source code / logs</h3>\n<p>Logs:<br>\n2018-01-22 09:39:57.262843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1202] Found device 0 with properties:<br>\nname: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645<br>\npciBusID: 0000:02:00.0<br>\ntotalMemory: 23.87GiB freeMemory: 22.46GiB<br>\n2018-01-22 09:39:57.262897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1296] Adding visible gpu device 0<br>\n2018-01-22 09:39:57.584754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21801 MB memory) -&gt; physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:02:00.0, compute capability: 6.1)<br>\n2018-01-22 09:39:57.584802: E tensorflow/core/common_runtime/gpu/process_state.cc:130] Invalid allocator type: 0<br>\nSegmentation fault (core dumped)</p>\n<p>Source Codes:<br>\n// Reads a model graph definition from disk, and creates a session object you<br>\n// can use to run it.<br>\nStatus LoadGraph(const string&amp; graph_file_name, std::unique_ptrtensorflow::Session* session)<br>\n{<br>\ntensorflow::GraphDef graph_def;<br>\nStatus load_graph_status = ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &amp;graph_def);<br>\nif (!load_graph_status.ok())<br>\n{<br>\nreturn tensorflow::errors::NotFound(\"Failed to load compute graph at '\",<br>\ngraph_file_name, \"'\");<br>\n}<br>\n//tensorflow::SessionOptions options;<br>\ntensorflow::SessionOptions session_options;<br>\nsession_options.config.mutable_gpu_options()-&gt;visible_device_list();<br>\nstd::cout&lt;&lt;\"list GPU done\"&lt;&lt;std::endl;<br>\nsession_options.config.mutable_gpu_options()-&gt;set_visible_device_list(\"0\");<br>\nstd::cout&lt;&lt;\"GPU assign is done\"&lt;&lt;std::endl;</p>\n<pre><code>session-&gt;reset(tensorflow::NewSession(session_options));\nstd::cout&lt;&lt;\"new session is created. \"&lt;&lt;std::endl;\nStatus session_create_status = (*session)-&gt;Create(graph_def);\nstd::cout&lt;&lt;\"Graph is loaded. \"&lt;&lt;std::endl;\nif (!session_create_status.ok()) \n{\n    return session_create_status;\n}\nreturn Status::OK();\n</code></pre>\n<p>}</p>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes.\nsession_options.config.mutable_gpu_options()->set_visible_device_list(\"0\");\nsession->reset(tensorflow::NewSession(session_options)); // Error in this line\nStatus session_create_status = (*session)->Create(graph_def);\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\n\n\nTensorFlow installed from (source or binary):\nsource\n\n\nTensorFlow version (use command below):\n1.4.0\n\n\nPython version:\n2.7.12\n\n\nBazel version (if compiling from source):\n0.9.0\n\n\nGCC/Compiler version (if compiling from source):\n5.4\n\n\nCUDA/cuDNN version:\nCUDA 8.0  /  cuDNN 6.0.21\n\n\nGPU model and memory:\nQuadro P6000, 24G GPU memory\n\n\nExact command to reproduce:\n\n\nDescribe the problem\nI built the tensorflow C++ API from the source using Bazel 0.9.0. When I link the shared library libtensorflow_cc.so, my code works fine. (I do not need to link libtensorflow_framework.so, since I used '--config=monolithic' when I build tensorflow using bazel.)\nHowever, I want to specify the GPU device in my code using this function to set gpu options:\nsession_options.config.mutable_gpu_options()->set_visible_device_list(\"0\");\nsession->reset(tensorflow::NewSession(session_options)); // Error in this line\nSource code / logs\nLogs:\n2018-01-22 09:39:57.262843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1202] Found device 0 with properties:\nname: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645\npciBusID: 0000:02:00.0\ntotalMemory: 23.87GiB freeMemory: 22.46GiB\n2018-01-22 09:39:57.262897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1296] Adding visible gpu device 0\n2018-01-22 09:39:57.584754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21801 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:02:00.0, compute capability: 6.1)\n2018-01-22 09:39:57.584802: E tensorflow/core/common_runtime/gpu/process_state.cc:130] Invalid allocator type: 0\nSegmentation fault (core dumped)\nSource Codes:\n// Reads a model graph definition from disk, and creates a session object you\n// can use to run it.\nStatus LoadGraph(const string& graph_file_name, std::unique_ptrtensorflow::Session* session)\n{\ntensorflow::GraphDef graph_def;\nStatus load_graph_status = ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);\nif (!load_graph_status.ok())\n{\nreturn tensorflow::errors::NotFound(\"Failed to load compute graph at '\",\ngraph_file_name, \"'\");\n}\n//tensorflow::SessionOptions options;\ntensorflow::SessionOptions session_options;\nsession_options.config.mutable_gpu_options()->visible_device_list();\nstd::cout<<\"list GPU done\"<<std::endl;\nsession_options.config.mutable_gpu_options()->set_visible_device_list(\"0\");\nstd::cout<<\"GPU assign is done\"<<std::endl;\nsession->reset(tensorflow::NewSession(session_options));\nstd::cout<<\"new session is created. \"<<std::endl;\nStatus session_create_status = (*session)->Create(graph_def);\nstd::cout<<\"Graph is loaded. \"<<std::endl;\nif (!session_create_status.ok()) \n{\n    return session_create_status;\n}\nreturn Status::OK();\n\n}", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes. \r\nsession_options.config.mutable_gpu_options()->set_visible_device_list(\"0\");\r\nsession->reset(tensorflow::NewSession(session_options)); // Error in this line\r\nStatus session_create_status = (*session)->Create(graph_def); \r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.4.0\r\n- **Python version**: \r\n2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n0.9.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\n5.4\r\n- **CUDA/cuDNN version**:\r\nCUDA 8.0  /  cuDNN 6.0.21\r\n- **GPU model and memory**:\r\nQuadro P6000, 24G GPU memory\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI built the tensorflow C++ API from the source using Bazel 0.9.0. When I link the shared library libtensorflow_cc.so, my code works fine. (I do not need to link libtensorflow_framework.so, since I used '--config=monolithic' when I build tensorflow using bazel.)\r\nHowever, I want to specify the GPU device in my code using this function to set gpu options:\r\nsession_options.config.mutable_gpu_options()->set_visible_device_list(\"0\");\r\nsession->reset(tensorflow::NewSession(session_options)); // **Error in this line**\r\n\r\n### Source code / logs\r\nLogs:\r\n2018-01-22 09:39:57.262843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1202] Found device 0 with properties: \r\nname: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 23.87GiB freeMemory: 22.46GiB\r\n2018-01-22 09:39:57.262897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1296] Adding visible gpu device 0\r\n2018-01-22 09:39:57.584754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21801 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2018-01-22 09:39:57.584802: E tensorflow/core/common_runtime/gpu/process_state.cc:130] Invalid allocator type: 0\r\nSegmentation fault (core dumped)\r\n\r\n\r\nSource Codes:\r\n// Reads a model graph definition from disk, and creates a session object you\r\n// can use to run it.\r\nStatus LoadGraph(const string& graph_file_name, std::unique_ptr<tensorflow::Session>* session) \r\n{\r\n    tensorflow::GraphDef graph_def;\r\n    Status load_graph_status = ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);\r\n    if (!load_graph_status.ok()) \r\n    {\r\n        return tensorflow::errors::NotFound(\"Failed to load compute graph at '\",\r\n                                        graph_file_name, \"'\");\r\n    }\r\n    //tensorflow::SessionOptions options;\r\n    tensorflow::SessionOptions session_options;\r\n    session_options.config.mutable_gpu_options()->visible_device_list();\r\n    std::cout<<\"list GPU done\"<<std::endl;\r\n    session_options.config.mutable_gpu_options()->set_visible_device_list(\"0\");\r\n    std::cout<<\"GPU assign is done\"<<std::endl;\r\n   \r\n    session->reset(tensorflow::NewSession(session_options));\r\n    std::cout<<\"new session is created. \"<<std::endl;\r\n    Status session_create_status = (*session)->Create(graph_def);\r\n    std::cout<<\"Graph is loaded. \"<<std::endl;\r\n    if (!session_create_status.ok()) \r\n    {\r\n        return session_create_status;\r\n    }\r\n    return Status::OK();\r\n}"}