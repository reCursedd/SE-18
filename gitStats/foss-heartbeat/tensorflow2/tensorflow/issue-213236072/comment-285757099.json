{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285757099", "html_url": "https://github.com/tensorflow/tensorflow/issues/8263#issuecomment-285757099", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8263", "id": 285757099, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTc1NzA5OQ==", "user": {"login": "CarbonComputed", "id": 1115442, "node_id": "MDQ6VXNlcjExMTU0NDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/1115442?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CarbonComputed", "html_url": "https://github.com/CarbonComputed", "followers_url": "https://api.github.com/users/CarbonComputed/followers", "following_url": "https://api.github.com/users/CarbonComputed/following{/other_user}", "gists_url": "https://api.github.com/users/CarbonComputed/gists{/gist_id}", "starred_url": "https://api.github.com/users/CarbonComputed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CarbonComputed/subscriptions", "organizations_url": "https://api.github.com/users/CarbonComputed/orgs", "repos_url": "https://api.github.com/users/CarbonComputed/repos", "events_url": "https://api.github.com/users/CarbonComputed/events{/privacy}", "received_events_url": "https://api.github.com/users/CarbonComputed/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-10T19:08:39Z", "updated_at": "2017-03-10T19:08:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Upon looking over this, I see whats being done here. They process in batches and store the running state for each batch. However, what led me to this confusion was the first example in the tutorial takes a batch of words as input, so it doesn't seem to make sense when compared to the Truncated Backprop example.  The initial example probably should be more clear on what a batch of words looks like in this example. Mainly I think many would appreciate just a bit more detail than the pseudo code provided.</p>", "body_text": "Upon looking over this, I see whats being done here. They process in batches and store the running state for each batch. However, what led me to this confusion was the first example in the tutorial takes a batch of words as input, so it doesn't seem to make sense when compared to the Truncated Backprop example.  The initial example probably should be more clear on what a batch of words looks like in this example. Mainly I think many would appreciate just a bit more detail than the pseudo code provided.", "body": "Upon looking over this, I see whats being done here. They process in batches and store the running state for each batch. However, what led me to this confusion was the first example in the tutorial takes a batch of words as input, so it doesn't seem to make sense when compared to the Truncated Backprop example.  The initial example probably should be more clear on what a batch of words looks like in this example. Mainly I think many would appreciate just a bit more detail than the pseudo code provided."}