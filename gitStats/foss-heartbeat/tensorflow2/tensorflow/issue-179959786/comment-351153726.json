{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/351153726", "html_url": "https://github.com/tensorflow/tensorflow/issues/4648#issuecomment-351153726", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4648", "id": 351153726, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MTE1MzcyNg==", "user": {"login": "amir-zeldes", "id": 2188635, "node_id": "MDQ6VXNlcjIxODg2MzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/2188635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amir-zeldes", "html_url": "https://github.com/amir-zeldes", "followers_url": "https://api.github.com/users/amir-zeldes/followers", "following_url": "https://api.github.com/users/amir-zeldes/following{/other_user}", "gists_url": "https://api.github.com/users/amir-zeldes/gists{/gist_id}", "starred_url": "https://api.github.com/users/amir-zeldes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amir-zeldes/subscriptions", "organizations_url": "https://api.github.com/users/amir-zeldes/orgs", "repos_url": "https://api.github.com/users/amir-zeldes/repos", "events_url": "https://api.github.com/users/amir-zeldes/events{/privacy}", "received_events_url": "https://api.github.com/users/amir-zeldes/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-12T18:57:08Z", "updated_at": "2017-12-12T18:57:08Z", "author_association": "NONE", "body_html": "<p>I'd like to second (or third?) that, it would be absolutely useful to have an out-of-the-box way to do multiple predictions asynchronously with the same graph in memory. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1296293\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/marcsto\">@marcsto</a> 's solution (fast_predict.py) is not working for me in TF 1.4.0.</p>\n<p>I also found this suggestion:</p>\n<p><a href=\"https://stackoverflow.com/questions/45111480/how-to-run-asynchronous-predictions-with-tensorflow-estimator-api\" rel=\"nofollow\">https://stackoverflow.com/questions/45111480/how-to-run-asynchronous-predictions-with-tensorflow-estimator-api</a></p>\n<p>Which is not working for me sadly (seems to have worked in TF 1.2.1)</p>", "body_text": "I'd like to second (or third?) that, it would be absolutely useful to have an out-of-the-box way to do multiple predictions asynchronously with the same graph in memory. @marcsto 's solution (fast_predict.py) is not working for me in TF 1.4.0.\nI also found this suggestion:\nhttps://stackoverflow.com/questions/45111480/how-to-run-asynchronous-predictions-with-tensorflow-estimator-api\nWhich is not working for me sadly (seems to have worked in TF 1.2.1)", "body": "I'd like to second (or third?) that, it would be absolutely useful to have an out-of-the-box way to do multiple predictions asynchronously with the same graph in memory. @marcsto 's solution (fast_predict.py) is not working for me in TF 1.4.0. \r\n\r\nI also found this suggestion: \r\n\r\nhttps://stackoverflow.com/questions/45111480/how-to-run-asynchronous-predictions-with-tensorflow-estimator-api\r\n\r\nWhich is not working for me sadly (seems to have worked in TF 1.2.1)"}