{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/362883053", "html_url": "https://github.com/tensorflow/tensorflow/issues/2381#issuecomment-362883053", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2381", "id": 362883053, "node_id": "MDEyOklzc3VlQ29tbWVudDM2Mjg4MzA1Mw==", "user": {"login": "Lynten", "id": 5766062, "node_id": "MDQ6VXNlcjU3NjYwNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5766062?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lynten", "html_url": "https://github.com/Lynten", "followers_url": "https://api.github.com/users/Lynten/followers", "following_url": "https://api.github.com/users/Lynten/following{/other_user}", "gists_url": "https://api.github.com/users/Lynten/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lynten/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lynten/subscriptions", "organizations_url": "https://api.github.com/users/Lynten/orgs", "repos_url": "https://api.github.com/users/Lynten/repos", "events_url": "https://api.github.com/users/Lynten/events{/privacy}", "received_events_url": "https://api.github.com/users/Lynten/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-04T05:53:01Z", "updated_at": "2018-02-04T05:53:01Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=70511\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/girving\">@girving</a> I'm somewhat confused.</p>\n<p>In <a href=\"https://github.com/tensorflow/tensorflow/blob/1752d9c8fac5f6cf85a41e77d92e2743adbfc446/tensorflow/python/ops/rnn.py#L1312\">static_rnn</a>, it does use Python loop to compute rnn outputs and final state.</p>\n<pre><code>    for time, input_ in enumerate(inputs):\n      if time &gt; 0:\n        varscope.reuse_variables()\n      # pylint: disable=cell-var-from-loop\n      call_cell = lambda: cell(input_, state)\n      # pylint: enable=cell-var-from-loop\n      if sequence_length is not None:\n        (output, state) = _rnn_step(\n            time=time,\n            sequence_length=sequence_length,\n            min_sequence_length=min_sequence_length,\n            max_sequence_length=max_sequence_length,\n            zero_output=zero_output,\n            state=state,\n            call_cell=call_cell,\n            state_size=cell.state_size)\n      else:\n        (output, state) = call_cell()\n\n      outputs.append(output)\n</code></pre>\n<p>You said \"a Python loop doesn't support automatic gradient computation\", then how does the static_rnn work?</p>", "body_text": "@girving I'm somewhat confused.\nIn static_rnn, it does use Python loop to compute rnn outputs and final state.\n    for time, input_ in enumerate(inputs):\n      if time > 0:\n        varscope.reuse_variables()\n      # pylint: disable=cell-var-from-loop\n      call_cell = lambda: cell(input_, state)\n      # pylint: enable=cell-var-from-loop\n      if sequence_length is not None:\n        (output, state) = _rnn_step(\n            time=time,\n            sequence_length=sequence_length,\n            min_sequence_length=min_sequence_length,\n            max_sequence_length=max_sequence_length,\n            zero_output=zero_output,\n            state=state,\n            call_cell=call_cell,\n            state_size=cell.state_size)\n      else:\n        (output, state) = call_cell()\n\n      outputs.append(output)\n\nYou said \"a Python loop doesn't support automatic gradient computation\", then how does the static_rnn work?", "body": "@girving I'm somewhat confused.\r\n\r\nIn [static_rnn](https://github.com/tensorflow/tensorflow/blob/1752d9c8fac5f6cf85a41e77d92e2743adbfc446/tensorflow/python/ops/rnn.py#L1312), it does use Python loop to compute rnn outputs and final state.\r\n```\r\n    for time, input_ in enumerate(inputs):\r\n      if time > 0:\r\n        varscope.reuse_variables()\r\n      # pylint: disable=cell-var-from-loop\r\n      call_cell = lambda: cell(input_, state)\r\n      # pylint: enable=cell-var-from-loop\r\n      if sequence_length is not None:\r\n        (output, state) = _rnn_step(\r\n            time=time,\r\n            sequence_length=sequence_length,\r\n            min_sequence_length=min_sequence_length,\r\n            max_sequence_length=max_sequence_length,\r\n            zero_output=zero_output,\r\n            state=state,\r\n            call_cell=call_cell,\r\n            state_size=cell.state_size)\r\n      else:\r\n        (output, state) = call_cell()\r\n\r\n      outputs.append(output)\r\n```\r\n\r\nYou said \"a Python loop doesn't support automatic gradient computation\", then how does the static_rnn work?\r\n"}