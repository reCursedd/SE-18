{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/223020162", "html_url": "https://github.com/tensorflow/tensorflow/issues/2381#issuecomment-223020162", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2381", "id": 223020162, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMzAyMDE2Mg==", "user": {"login": "wb14123", "id": 1906051, "node_id": "MDQ6VXNlcjE5MDYwNTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1906051?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wb14123", "html_url": "https://github.com/wb14123", "followers_url": "https://api.github.com/users/wb14123/followers", "following_url": "https://api.github.com/users/wb14123/following{/other_user}", "gists_url": "https://api.github.com/users/wb14123/gists{/gist_id}", "starred_url": "https://api.github.com/users/wb14123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wb14123/subscriptions", "organizations_url": "https://api.github.com/users/wb14123/orgs", "repos_url": "https://api.github.com/users/wb14123/repos", "events_url": "https://api.github.com/users/wb14123/events{/privacy}", "received_events_url": "https://api.github.com/users/wb14123/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-01T14:59:22Z", "updated_at": "2016-06-01T15:01:14Z", "author_association": "NONE", "body_html": "<p>In my understate, <code>dynamic_rnn</code> is not used to solve the problem of variable length, but used to run loops within a tensor. So is control flow ops.</p>\n<p>I think the good way to deal with variable length, is to divide one sample into multiple ones, and keep the RNN state between them. So the divided multiple samples are treated as one sample. On the other hand, if one sample is shorter, then padding it with zero or something like that. The implement of Keras gives a good example. This should be a better way than bucketing. Though in TensorFlow, it seems have a lot work to do.</p>", "body_text": "In my understate, dynamic_rnn is not used to solve the problem of variable length, but used to run loops within a tensor. So is control flow ops.\nI think the good way to deal with variable length, is to divide one sample into multiple ones, and keep the RNN state between them. So the divided multiple samples are treated as one sample. On the other hand, if one sample is shorter, then padding it with zero or something like that. The implement of Keras gives a good example. This should be a better way than bucketing. Though in TensorFlow, it seems have a lot work to do.", "body": "In my understate, `dynamic_rnn` is not used to solve the problem of variable length, but used to run loops within a tensor. So is control flow ops.\n\nI think the good way to deal with variable length, is to divide one sample into multiple ones, and keep the RNN state between them. So the divided multiple samples are treated as one sample. On the other hand, if one sample is shorter, then padding it with zero or something like that. The implement of Keras gives a good example. This should be a better way than bucketing. Though in TensorFlow, it seems have a lot work to do. \n"}