{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2381", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2381/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2381/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2381/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2381", "id": 154945094, "node_id": "MDU6SXNzdWUxNTQ5NDUwOTQ=", "number": 2381, "title": "understanding the current state of dynamic_rnn vs buckets vs scan for seq2seq", "user": {"login": "22csnyder", "id": 10726729, "node_id": "MDQ6VXNlcjEwNzI2NzI5", "avatar_url": "https://avatars3.githubusercontent.com/u/10726729?v=4", "gravatar_id": "", "url": "https://api.github.com/users/22csnyder", "html_url": "https://github.com/22csnyder", "followers_url": "https://api.github.com/users/22csnyder/followers", "following_url": "https://api.github.com/users/22csnyder/following{/other_user}", "gists_url": "https://api.github.com/users/22csnyder/gists{/gist_id}", "starred_url": "https://api.github.com/users/22csnyder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/22csnyder/subscriptions", "organizations_url": "https://api.github.com/users/22csnyder/orgs", "repos_url": "https://api.github.com/users/22csnyder/repos", "events_url": "https://api.github.com/users/22csnyder/events{/privacy}", "received_events_url": "https://api.github.com/users/22csnyder/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2016-05-16T01:29:13Z", "updated_at": "2018-02-04T05:53:01Z", "closed_at": "2016-06-07T16:32:13Z", "author_association": "NONE", "body_html": "<p>Bear with me as I am not an expert in the practical or theoretical details.</p>\n<p>Perhaps because tensorflow has developed so rapidly, I find it a little difficult to find the recommended procedure for RNNs with varying length, at least from my lay end-user perspective. It is unclear to me on May 15, 2016 what tool within tensorflow is best suited to this task.</p>\n<p>It seems that originally RNNs of varying sequence length were handled by \"bucketing\". This means building a \"separate\" model for each of several bucket lengths so that inputs could be padded to the same length without wasting too much gpu memory. There is not presently a \"simple\" example with bucketing, but to those unfamiliar, I would look to the <a href=\"https://github.com/tensorflow/tensorflow/blob/3c8780451007c27b69f10925d43d1f3501d94106/tensorflow/models/rnn/translate/seq2seq_model.py\">seq2seq</a> model for clarity. Also the <a href=\"https://github.com/tensorflow/tensorflow/blob/82ff4cd8b0d541ede107d34d8eecc769c91dda11/tensorflow/python/ops/seq2seq.py\">model_with_buckets function</a></p>\n<p>Sometime between March and May a number of (maybe?) different tools were added that could possibly be used to avoid this bucketing trick without wasting memory.</p>\n<ol>\n<li><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py\">rnn.py/dynamic_rnn</a></li>\n<li><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/functional_ops.py#L256\">functional_ops</a>, though within this code it's not clear without investigation if map_fn or tf.scan (!) would be better suited.</li>\n<li><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py\">control_flow_ops</a></li>\n</ol>\n<p>In spite of this, the seq2seq model still uses bucketing, and I struggle to find any examples using these newer methods.</p>\n<p>Creating detailed documentation is ultimately part of the endgoal, but <em>for now</em> I thought it would be useful to at least make a mention of what the recommended approach is.</p>\n<p>Thanks.</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/issues/208\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/208/hovercard\">relevant issue 208 </a><br>\n<a href=\"https://www.reddit.com/r/MachineLearning/comments/4dtbks/tensorflow_now_has_an_unofficial_scan_function/\" rel=\"nofollow\">relevant reddit with broken link to example</a></p>", "body_text": "Bear with me as I am not an expert in the practical or theoretical details.\nPerhaps because tensorflow has developed so rapidly, I find it a little difficult to find the recommended procedure for RNNs with varying length, at least from my lay end-user perspective. It is unclear to me on May 15, 2016 what tool within tensorflow is best suited to this task.\nIt seems that originally RNNs of varying sequence length were handled by \"bucketing\". This means building a \"separate\" model for each of several bucket lengths so that inputs could be padded to the same length without wasting too much gpu memory. There is not presently a \"simple\" example with bucketing, but to those unfamiliar, I would look to the seq2seq model for clarity. Also the model_with_buckets function\nSometime between March and May a number of (maybe?) different tools were added that could possibly be used to avoid this bucketing trick without wasting memory.\n\nrnn.py/dynamic_rnn\nfunctional_ops, though within this code it's not clear without investigation if map_fn or tf.scan (!) would be better suited.\ncontrol_flow_ops\n\nIn spite of this, the seq2seq model still uses bucketing, and I struggle to find any examples using these newer methods.\nCreating detailed documentation is ultimately part of the endgoal, but for now I thought it would be useful to at least make a mention of what the recommended approach is.\nThanks.\nrelevant issue 208 \nrelevant reddit with broken link to example", "body": "Bear with me as I am not an expert in the practical or theoretical details. \n\nPerhaps because tensorflow has developed so rapidly, I find it a little difficult to find the recommended procedure for RNNs with varying length, at least from my lay end-user perspective. It is unclear to me on May 15, 2016 what tool within tensorflow is best suited to this task.\n\nIt seems that originally RNNs of varying sequence length were handled by \"bucketing\". This means building a \"separate\" model for each of several bucket lengths so that inputs could be padded to the same length without wasting too much gpu memory. There is not presently a \"simple\" example with bucketing, but to those unfamiliar, I would look to the [seq2seq](https://github.com/tensorflow/tensorflow/blob/3c8780451007c27b69f10925d43d1f3501d94106/tensorflow/models/rnn/translate/seq2seq_model.py) model for clarity. Also the [model_with_buckets function](https://github.com/tensorflow/tensorflow/blob/82ff4cd8b0d541ede107d34d8eecc769c91dda11/tensorflow/python/ops/seq2seq.py)\n\nSometime between March and May a number of (maybe?) different tools were added that could possibly be used to avoid this bucketing trick without wasting memory.\n1. [rnn.py/dynamic_rnn](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py)\n2. [functional_ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/functional_ops.py#L256), though within this code it's not clear without investigation if map_fn or tf.scan (!) would be better suited.\n3. [control_flow_ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py)\n\nIn spite of this, the seq2seq model still uses bucketing, and I struggle to find any examples using these newer methods.\n\nCreating detailed documentation is ultimately part of the endgoal, but _for now_ I thought it would be useful to at least make a mention of what the recommended approach is.\n\nThanks.\n\n[relevant issue 208 ](https://github.com/tensorflow/tensorflow/issues/208)\n[relevant reddit with broken link to example](https://www.reddit.com/r/MachineLearning/comments/4dtbks/tensorflow_now_has_an_unofficial_scan_function/)\n"}