{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13804", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13804/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13804/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13804/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13804", "id": 266450733, "node_id": "MDU6SXNzdWUyNjY0NTA3MzM=", "number": 13804, "title": "Figure out CUDA and cuDNN versions", "user": {"login": "botev", "id": 1889878, "node_id": "MDQ6VXNlcjE4ODk4Nzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1889878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/botev", "html_url": "https://github.com/botev", "followers_url": "https://api.github.com/users/botev/followers", "following_url": "https://api.github.com/users/botev/following{/other_user}", "gists_url": "https://api.github.com/users/botev/gists{/gist_id}", "starred_url": "https://api.github.com/users/botev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/botev/subscriptions", "organizations_url": "https://api.github.com/users/botev/orgs", "repos_url": "https://api.github.com/users/botev/repos", "events_url": "https://api.github.com/users/botev/events{/privacy}", "received_events_url": "https://api.github.com/users/botev/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-10-18T11:00:20Z", "updated_at": "2017-10-18T19:21:07Z", "closed_at": "2017-10-18T19:21:07Z", "author_association": "NONE", "body_html": "<p>So I'm setting up an image for a group to be used in the cloud.<br>\nGiven that there certain cloud related things which we don't have premissions to we want to be able to verify that Tensorflow is using indeed what we intended. However, there does not seem to be any comprehensive way of understanding at the moment what exactly is it using. The output after creating a session is:</p>\n<pre><code>2017-10-18 10:49:51.880192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-10-18 10:49:51.880752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:00:1e.0\nTotal memory: 11.17GiB\nFree memory: 11.11GiB\n2017-10-18 10:49:51.880818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \n2017-10-18 10:49:51.880849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \n2017-10-18 10:49:51.880883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\n</code></pre>\n<p>Does this means the cuda fails since I don't see any \"succesffully loaded libcuda...\" or anthing like that. Does it even load cuDNN? Is there any way to directly check it (once is enough don't need to be printed every time.<br>\nI did not find any documentations and there was not too much here in the issues except people not beeing able to do it.</p>", "body_text": "So I'm setting up an image for a group to be used in the cloud.\nGiven that there certain cloud related things which we don't have premissions to we want to be able to verify that Tensorflow is using indeed what we intended. However, there does not seem to be any comprehensive way of understanding at the moment what exactly is it using. The output after creating a session is:\n2017-10-18 10:49:51.880192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-10-18 10:49:51.880752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:00:1e.0\nTotal memory: 11.17GiB\nFree memory: 11.11GiB\n2017-10-18 10:49:51.880818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \n2017-10-18 10:49:51.880849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \n2017-10-18 10:49:51.880883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\n\nDoes this means the cuda fails since I don't see any \"succesffully loaded libcuda...\" or anthing like that. Does it even load cuDNN? Is there any way to directly check it (once is enough don't need to be printed every time.\nI did not find any documentations and there was not too much here in the issues except people not beeing able to do it.", "body": "So I'm setting up an image for a group to be used in the cloud. \r\nGiven that there certain cloud related things which we don't have premissions to we want to be able to verify that Tensorflow is using indeed what we intended. However, there does not seem to be any comprehensive way of understanding at the moment what exactly is it using. The output after creating a session is:\r\n```\r\n2017-10-18 10:49:51.880192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-10-18 10:49:51.880752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \r\nname: Tesla K80\r\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\r\npciBusID 0000:00:1e.0\r\nTotal memory: 11.17GiB\r\nFree memory: 11.11GiB\r\n2017-10-18 10:49:51.880818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \r\n2017-10-18 10:49:51.880849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \r\n2017-10-18 10:49:51.880883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\r\n```\r\nDoes this means the cuda fails since I don't see any \"succesffully loaded libcuda...\" or anthing like that. Does it even load cuDNN? Is there any way to directly check it (once is enough don't need to be printed every time. \r\nI did not find any documentations and there was not too much here in the issues except people not beeing able to do it. "}