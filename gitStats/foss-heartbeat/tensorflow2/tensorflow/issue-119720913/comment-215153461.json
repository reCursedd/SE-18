{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/215153461", "html_url": "https://github.com/tensorflow/tensorflow/issues/386#issuecomment-215153461", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/386", "id": 215153461, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNTE1MzQ2MQ==", "user": {"login": "rryan", "id": 26527, "node_id": "MDQ6VXNlcjI2NTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/26527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rryan", "html_url": "https://github.com/rryan", "followers_url": "https://api.github.com/users/rryan/followers", "following_url": "https://api.github.com/users/rryan/following{/other_user}", "gists_url": "https://api.github.com/users/rryan/gists{/gist_id}", "starred_url": "https://api.github.com/users/rryan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rryan/subscriptions", "organizations_url": "https://api.github.com/users/rryan/orgs", "repos_url": "https://api.github.com/users/rryan/repos", "events_url": "https://api.github.com/users/rryan/events{/privacy}", "received_events_url": "https://api.github.com/users/rryan/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-27T17:13:50Z", "updated_at": "2016-04-28T16:58:43Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7644157\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alexhock\">@alexhock</a> -- I haven't tried your code myself but I believe you're hitting a common TensorFlow pitfall which is that you're also measuring the time TensorFlow spends constructing the graph and also the C++/Python conversion of the resulting tensor into a numpy array.</p>\n<div class=\"highlight highlight-source-python\"><pre>g <span class=\"pl-k\">=</span> tf.Graph()\nx <span class=\"pl-k\">=</span> np.ones((<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4000</span>, <span class=\"pl-c1\">4000</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\nx <span class=\"pl-k\">=</span> x <span class=\"pl-k\">*</span> <span class=\"pl-c1\">.1</span>\n<span class=\"pl-k\">with</span> g.as_default(), tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n  e <span class=\"pl-k\">=</span> tf.constant(x, tf.complex64)\n  fft <span class=\"pl-k\">=</span> tf.batch_fft2d(e)\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> This barrier executes the FFT op as a dependency but does </span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> not pay the cost of converting the result of the FFT into Python objects.</span>\n  <span class=\"pl-k\">with</span> tf.control_dependencies([fft]):\n    barrier <span class=\"pl-k\">=</span> tf.no_op(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>benchmark_barrier<span class=\"pl-pds\">'</span></span>)\n\n  <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    st <span class=\"pl-k\">=</span> time.time()\n    sess.run(barrier)\n    en <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu duration: <span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(en<span class=\"pl-k\">-</span>st))</pre></div>\n<p><em>EDIT</em>: Fix placement of tf.device.</p>\n<p>Can you give that a try?</p>\n<p>Also, note that to do a proper benchmark you're going to want to take multiple measurements in a loop and it's quite common to include a \"warmup\" phase of a dozen or so <code>session.run</code> calls that you ignore the results of.</p>", "body_text": "@alexhock -- I haven't tried your code myself but I believe you're hitting a common TensorFlow pitfall which is that you're also measuring the time TensorFlow spends constructing the graph and also the C++/Python conversion of the resulting tensor into a numpy array.\ng = tf.Graph()\nx = np.ones((1, 4000, 4000), dtype=np.float32)\nx = x * .1\nwith g.as_default(), tf.device('/gpu:0'):\n  e = tf.constant(x, tf.complex64)\n  fft = tf.batch_fft2d(e)\n\n  # This barrier executes the FFT op as a dependency but does \n  # not pay the cost of converting the result of the FFT into Python objects.\n  with tf.control_dependencies([fft]):\n    barrier = tf.no_op(name='benchmark_barrier')\n\n  with tf.Session() as sess:\n    st = time.time()\n    sess.run(barrier)\n    en = time.time()\n    print (\"gpu duration: {0}\".format(en-st))\nEDIT: Fix placement of tf.device.\nCan you give that a try?\nAlso, note that to do a proper benchmark you're going to want to take multiple measurements in a loop and it's quite common to include a \"warmup\" phase of a dozen or so session.run calls that you ignore the results of.", "body": "@alexhock -- I haven't tried your code myself but I believe you're hitting a common TensorFlow pitfall which is that you're also measuring the time TensorFlow spends constructing the graph and also the C++/Python conversion of the resulting tensor into a numpy array.\n\n``` python\ng = tf.Graph()\nx = np.ones((1, 4000, 4000), dtype=np.float32)\nx = x * .1\nwith g.as_default(), tf.device('/gpu:0'):\n  e = tf.constant(x, tf.complex64)\n  fft = tf.batch_fft2d(e)\n\n  # This barrier executes the FFT op as a dependency but does \n  # not pay the cost of converting the result of the FFT into Python objects.\n  with tf.control_dependencies([fft]):\n    barrier = tf.no_op(name='benchmark_barrier')\n\n  with tf.Session() as sess:\n    st = time.time()\n    sess.run(barrier)\n    en = time.time()\n    print (\"gpu duration: {0}\".format(en-st))\n```\n\n_EDIT_: Fix placement of tf.device.\n\nCan you give that a try?\n\nAlso, note that to do a proper benchmark you're going to want to take multiple measurements in a loop and it's quite common to include a \"warmup\" phase of a dozen or so `session.run` calls that you ignore the results of.\n"}