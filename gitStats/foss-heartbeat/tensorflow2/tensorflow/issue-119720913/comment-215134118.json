{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/215134118", "html_url": "https://github.com/tensorflow/tensorflow/issues/386#issuecomment-215134118", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/386", "id": 215134118, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNTEzNDExOA==", "user": {"login": "alexhock", "id": 7644157, "node_id": "MDQ6VXNlcjc2NDQxNTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7644157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexhock", "html_url": "https://github.com/alexhock", "followers_url": "https://api.github.com/users/alexhock/followers", "following_url": "https://api.github.com/users/alexhock/following{/other_user}", "gists_url": "https://api.github.com/users/alexhock/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexhock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexhock/subscriptions", "organizations_url": "https://api.github.com/users/alexhock/orgs", "repos_url": "https://api.github.com/users/alexhock/repos", "events_url": "https://api.github.com/users/alexhock/events{/privacy}", "received_events_url": "https://api.github.com/users/alexhock/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-27T16:11:00Z", "updated_at": "2016-04-27T16:11:00Z", "author_association": "NONE", "body_html": "<p>I'm not really sure what's happening here but I'm not getting the performance from the gpu implementation of batch_fft2d that I was expecting. Somehow Numpy is much faster.</p>\n<p>I'm using Tensorflow r0.8 and I've tried this with a gtx 980 on Fedora 23 and on a K40 on RedHat enterprise 7, CUDA 7.5 from NVIDIA. I'm using Anaconda 2.7.</p>\n<p>Here is the code and results:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> time\n\nx <span class=\"pl-k\">=</span> np.ones((<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4000</span>, <span class=\"pl-c1\">4000</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\nx <span class=\"pl-k\">=</span> x <span class=\"pl-k\">*</span> <span class=\"pl-c1\">.1</span>\ne <span class=\"pl-k\">=</span> tf.constant(x, tf.complex64)\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-k\">with</span> sess.graph.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>starting fft<span class=\"pl-pds\">\"</span></span>)\n        st <span class=\"pl-k\">=</span> time.time()\n        tf.batch_fft2d(e).eval()\n        en <span class=\"pl-k\">=</span> time.time()\n        <span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu duration: <span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(en<span class=\"pl-k\">-</span>st))\n\n\nnpst <span class=\"pl-k\">=</span> time.time()\nnp.fft.fft2(x[<span class=\"pl-c1\">0</span>])\nnpen <span class=\"pl-k\">=</span> time.time()\n\n<span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>npy duration: <span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(npen<span class=\"pl-k\">-</span>npst))</pre></div>\n<p>The results are:</p>\n<pre><code>gpu duration: 14.0613360405 seconds\nnumpy duration: 1.05315804482 seconds\n</code></pre>\n<p>Am I missing something?</p>", "body_text": "I'm not really sure what's happening here but I'm not getting the performance from the gpu implementation of batch_fft2d that I was expecting. Somehow Numpy is much faster.\nI'm using Tensorflow r0.8 and I've tried this with a gtx 980 on Fedora 23 and on a K40 on RedHat enterprise 7, CUDA 7.5 from NVIDIA. I'm using Anaconda 2.7.\nHere is the code and results:\nimport numpy as np\nimport tensorflow as tf\nimport time\n\nx = np.ones((1, 4000, 4000), dtype=np.float32)\nx = x * .1\ne = tf.constant(x, tf.complex64)\n\nwith tf.Session() as sess:\n    with sess.graph.device('/gpu:0'):\n        print(\"starting fft\")\n        st = time.time()\n        tf.batch_fft2d(e).eval()\n        en = time.time()\n        print (\"gpu duration: {0}\".format(en-st))\n\n\nnpst = time.time()\nnp.fft.fft2(x[0])\nnpen = time.time()\n\nprint (\"npy duration: {0}\".format(npen-npst))\nThe results are:\ngpu duration: 14.0613360405 seconds\nnumpy duration: 1.05315804482 seconds\n\nAm I missing something?", "body": "I'm not really sure what's happening here but I'm not getting the performance from the gpu implementation of batch_fft2d that I was expecting. Somehow Numpy is much faster.\n\nI'm using Tensorflow r0.8 and I've tried this with a gtx 980 on Fedora 23 and on a K40 on RedHat enterprise 7, CUDA 7.5 from NVIDIA. I'm using Anaconda 2.7.\n\nHere is the code and results:\n\n``` python\nimport numpy as np\nimport tensorflow as tf\nimport time\n\nx = np.ones((1, 4000, 4000), dtype=np.float32)\nx = x * .1\ne = tf.constant(x, tf.complex64)\n\nwith tf.Session() as sess:\n    with sess.graph.device('/gpu:0'):\n        print(\"starting fft\")\n        st = time.time()\n        tf.batch_fft2d(e).eval()\n        en = time.time()\n        print (\"gpu duration: {0}\".format(en-st))\n\n\nnpst = time.time()\nnp.fft.fft2(x[0])\nnpen = time.time()\n\nprint (\"npy duration: {0}\".format(npen-npst))\n```\n\nThe results are:\n\n```\ngpu duration: 14.0613360405 seconds\nnumpy duration: 1.05315804482 seconds\n```\n\nAm I missing something?\n"}