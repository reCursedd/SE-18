{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/161364420", "html_url": "https://github.com/tensorflow/tensorflow/issues/386#issuecomment-161364420", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/386", "id": 161364420, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MTM2NDQyMA==", "user": {"login": "NickShahML", "id": 14891677, "node_id": "MDQ6VXNlcjE0ODkxNjc3", "avatar_url": "https://avatars2.githubusercontent.com/u/14891677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NickShahML", "html_url": "https://github.com/NickShahML", "followers_url": "https://api.github.com/users/NickShahML/followers", "following_url": "https://api.github.com/users/NickShahML/following{/other_user}", "gists_url": "https://api.github.com/users/NickShahML/gists{/gist_id}", "starred_url": "https://api.github.com/users/NickShahML/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NickShahML/subscriptions", "organizations_url": "https://api.github.com/users/NickShahML/orgs", "repos_url": "https://api.github.com/users/NickShahML/repos", "events_url": "https://api.github.com/users/NickShahML/events{/privacy}", "received_events_url": "https://api.github.com/users/NickShahML/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-02T16:59:59Z", "updated_at": "2015-12-02T17:02:15Z", "author_association": "NONE", "body_html": "<p>Perfect! Thanks! <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=706666\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/adder\">@adder</a>, I primarily use GPUs and if you're going to use unitary RNN's for some serious language modeling, you gotta use GPU's (10x faster training time).</p>\n<p>I know they may converge more quickly (one of the benefits), but keep in mind that an epoch usually takes at least 24 hrs with normal LSTM's and GRU's for big datasets. So we simply can't afford to put them on CPUs.</p>", "body_text": "Perfect! Thanks! @adder, I primarily use GPUs and if you're going to use unitary RNN's for some serious language modeling, you gotta use GPU's (10x faster training time).\nI know they may converge more quickly (one of the benefits), but keep in mind that an epoch usually takes at least 24 hrs with normal LSTM's and GRU's for big datasets. So we simply can't afford to put them on CPUs.", "body": "Perfect! Thanks! @adder, I primarily use GPUs and if you're going to use unitary RNN's for some serious language modeling, you gotta use GPU's (10x faster training time). \n\nI know they may converge more quickly (one of the benefits), but keep in mind that an epoch usually takes at least 24 hrs with normal LSTM's and GRU's for big datasets. So we simply can't afford to put them on CPUs. \n"}