{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/359833855", "html_url": "https://github.com/tensorflow/tensorflow/pull/16253#issuecomment-359833855", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16253", "id": 359833855, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTgzMzg1NQ==", "user": {"login": "yangjunpro", "id": 407784, "node_id": "MDQ6VXNlcjQwNzc4NA==", "avatar_url": "https://avatars3.githubusercontent.com/u/407784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yangjunpro", "html_url": "https://github.com/yangjunpro", "followers_url": "https://api.github.com/users/yangjunpro/followers", "following_url": "https://api.github.com/users/yangjunpro/following{/other_user}", "gists_url": "https://api.github.com/users/yangjunpro/gists{/gist_id}", "starred_url": "https://api.github.com/users/yangjunpro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yangjunpro/subscriptions", "organizations_url": "https://api.github.com/users/yangjunpro/orgs", "repos_url": "https://api.github.com/users/yangjunpro/repos", "events_url": "https://api.github.com/users/yangjunpro/events{/privacy}", "received_events_url": "https://api.github.com/users/yangjunpro/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-23T15:51:08Z", "updated_at": "2018-01-23T15:52:52Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10539540\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/samikama\">@samikama</a><br>\nThanks for the nice work.<br>\nActually our team are working on the same task of integrating TensorRT with TensorFlow with the same design idea even with some similar function/variable name:). it looks that NVIDIA team run a little bit faster.</p>\n<p>May I know have you made any benchmark with current implementation? Since with this integration TensorRT actually could leverage existing TF ops for its functionality completeness which is actually a headache for traditional TensorRT execution solution.<br>\nBut there may be some potential performance overhead between the switch of TensorRT of TF(around several hundred us to 1ms observed in our scenarios), also if there are multiple switches between TensorRT and TF,  we need to be more careful about its overhead(considering TRT-&gt;TF-&gt;TRT execution plan).</p>\n<p>So any performance number sharing will be really helpful.</p>\n<p>If the work is solid enough, we would like to contribute more enhancement based on this PR and apply it into our production environment and I think this will be a win-win for community, NV and Alibaba.</p>", "body_text": "@samikama\nThanks for the nice work.\nActually our team are working on the same task of integrating TensorRT with TensorFlow with the same design idea even with some similar function/variable name:). it looks that NVIDIA team run a little bit faster.\nMay I know have you made any benchmark with current implementation? Since with this integration TensorRT actually could leverage existing TF ops for its functionality completeness which is actually a headache for traditional TensorRT execution solution.\nBut there may be some potential performance overhead between the switch of TensorRT of TF(around several hundred us to 1ms observed in our scenarios), also if there are multiple switches between TensorRT and TF,  we need to be more careful about its overhead(considering TRT->TF->TRT execution plan).\nSo any performance number sharing will be really helpful.\nIf the work is solid enough, we would like to contribute more enhancement based on this PR and apply it into our production environment and I think this will be a win-win for community, NV and Alibaba.", "body": "@samikama \r\nThanks for the nice work.  \r\nActually our team are working on the same task of integrating TensorRT with TensorFlow with the same design idea even with some similar function/variable name:). it looks that NVIDIA team run a little bit faster.\r\n\r\nMay I know have you made any benchmark with current implementation? Since with this integration TensorRT actually could leverage existing TF ops for its functionality completeness which is actually a headache for traditional TensorRT execution solution. \r\nBut there may be some potential performance overhead between the switch of TensorRT of TF(around several hundred us to 1ms observed in our scenarios), also if there are multiple switches between TensorRT and TF,  we need to be more careful about its overhead(considering TRT->TF->TRT execution plan).\r\n\r\nSo any performance number sharing will be really helpful.\r\n\r\nIf the work is solid enough, we would like to contribute more enhancement based on this PR and apply it into our production environment and I think this will be a win-win for community, NV and Alibaba."}