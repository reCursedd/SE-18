{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/166720736", "pull_request_review_id": 94829762, "id": 166720736, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjcyMDczNg==", "diff_hunk": "@@ -0,0 +1,1660 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/contrib/tensorrt/convert/convert_nodes.h\"\n+\n+#include <algorithm>\n+#include <list>\n+#include <map>\n+#include <memory>\n+#include <set>\n+#include <unordered_map>\n+#include <utility>\n+#include <vector>\n+\n+#include \"tensorflow/core/framework/attr_value.pb.h\"\n+#include \"tensorflow/core/framework/graph.pb.h\"\n+#include \"tensorflow/core/framework/node_def.pb.h\"\n+#include \"tensorflow/core/framework/node_def_builder.h\"\n+#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/framework/types.pb.h\"\n+#include \"tensorflow/core/graph/algorithm.h\"\n+#include \"tensorflow/core/graph/graph.h\"\n+#include \"tensorflow/core/graph/graph_constructor.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/lib/strings/strcat.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/platform/tensor_coding.h\"\n+#include \"tensorflow/core/platform/types.h\"\n+\n+#if GOOGLE_CUDA\n+#if GOOGLE_TENSORRT\n+#include \"tensorflow/contrib/tensorrt/log/trt_logger.h\"\n+#include \"tensorrt/include/NvInfer.h\"\n+\n+//  Check if the types are equal. Cast to int first so that failure log message\n+//  would work!\n+#define CHECK_EQ_TYPE(val1, val2) CHECK_EQ((int)val1, (int)val2)\n+\n+namespace tensorflow {\n+namespace tensorrt {\n+namespace convert {\n+\n+namespace {\n+\n+inline tensorflow::Status ConvertDType(tensorflow::DataType tf_dtype,\n+                                       nvinfer1::DataType* trt_dtype) {\n+  switch (tf_dtype) {\n+    case tensorflow::DataType::DT_FLOAT:\n+      *trt_dtype = nvinfer1::DataType::kFLOAT;\n+      break;\n+    case tensorflow::DataType::DT_INT8:\n+      *trt_dtype = nvinfer1::DataType::kINT8;\n+      break;\n+    case tensorflow::DataType::DT_HALF:\n+      *trt_dtype = nvinfer1::DataType::kHALF;\n+      break;\n+    default:\n+      return tensorflow::errors::InvalidArgument(\"Unsupported data type\");\n+  }\n+  return tensorflow::Status::OK();\n+}\n+\n+inline nvinfer1::Dims GetTensorShape(const tensorflow::Tensor& tensor) {\n+  nvinfer1::Dims dims;\n+  dims.nbDims = tensor.dims();\n+  for (int i = 0; i < dims.nbDims; i++) {\n+    dims.d[i] = tensor.dim_size(i);\n+  }\n+  return dims;\n+}\n+\n+inline int64_t GetShapeSize(nvinfer1::Dims shape) {\n+  // Returns total number of elements in shape\n+  int64_t count = 1;\n+  for (int d = 0; d < shape.nbDims; ++d) {\n+    count *= shape.d[d];\n+  }\n+  return count;\n+}\n+\n+static std::vector<std::pair<int, int>> CreateSamePadding(\n+    const nvinfer1::DimsHW& stride, const nvinfer1::DimsHW& kernel,\n+    const std::vector<int64_t>& input_dims) {\n+  std::vector<std::pair<int, int>> padding(input_dims.size());\n+  CHECK_EQ((size_t)stride.nbDims, input_dims.size());  // TODO(jie): N+C? NC+?\n+\n+  for (size_t i = 0; i < input_dims.size(); ++i) {\n+    // Formula to calculate the padding\n+    int p = ((input_dims[i] - 1) / stride.d[i]) * stride.d[i] + kernel.d[i] -\n+            input_dims[i];\n+    p = (p > 0) ? p : 0;\n+\n+    // Right precedence padding, like in TensorFlow\n+    int left = p / 2;\n+    int right = p - left;\n+\n+    VLOG(2) << \"PADDING_\" << i << \" pre: \" << left << \", post: \" << right\n+            << \"paras: \" << input_dims[i] << \", \" << stride.d[i] << \", \"\n+            << \"kernel: \" << kernel.d[i];\n+    padding[i] = {left, right};\n+  }\n+  return padding;\n+}\n+\n+class TRT_ShapedWeights {\n+ public:\n+  TRT_ShapedWeights(tensorflow::DataType type, const void* values,\n+                    nvinfer1::Dims shape,\n+                    const std::vector<char>* owned_values = nullptr)\n+      : shape_(shape),\n+        type_(type),\n+        values_(values),\n+        owned_values_(owned_values ? *owned_values : std::vector<char>({})),\n+        dummy_flag_(false) {\n+    // Note: this->shape.type[] is not used\n+  }\n+\n+  explicit TRT_ShapedWeights(tensorflow::DataType type)\n+      : shape_(),\n+        type_(type),\n+        values_(nullptr),\n+        owned_values_(),\n+        dummy_flag_(true) {}\n+\n+  TRT_ShapedWeights(const TRT_ShapedWeights& rhs)\n+      : shape_(rhs.shape_),\n+        type_(rhs.type_),\n+        values_(rhs.values_),\n+        owned_values_(rhs.owned_values_),\n+        dummy_flag_(rhs.dummy_flag_) {}\n+\n+  int64_t count() const {\n+    int64_t c = 1;\n+    for (int i = 0; i < shape_.nbDims; i++) c *= shape_.d[i];\n+    return c;\n+  }\n+\n+  nvinfer1::Weights GetWeightsForTRT() const {\n+    nvinfer1::DataType trt_type(nvinfer1::DataType::kFLOAT);\n+    TF_CHECK_OK(ConvertDType(type_, &trt_type));\n+    if (dummy_flag_) return nvinfer1::Weights{trt_type, nullptr, 0};\n+\n+    // Note: this->shape.type[] is not used\n+    return nvinfer1::Weights{trt_type, GetValues(), GetShapeSize(shape_)};\n+  }\n+\n+  const void* GetValues() const {\n+    if (values_) return values_;\n+    if (owned_values_.size()) return owned_values_.data();\n+    return nullptr;\n+  }\n+\n+  void SetValues(const void* values) {\n+    values_ = values;\n+    owned_values_.clear();\n+  }\n+\n+  size_t size_bytes() const {\n+    int type_size = tensorflow::DataTypeSize(this->type_);\n+    return this->count() * type_size;\n+  }\n+\n+  // Default converter\n+  operator nvinfer1::Weights() const { return GetWeightsForTRT(); }\n+\n+  nvinfer1::Dims shape_;\n+  tensorflow::DataType type_;\n+\n+ private:\n+  const void* values_;\n+  std::vector<char> owned_values_;\n+  bool dummy_flag_;\n+};\n+\n+class TRT_TensorOrWeights {\n+ public:\n+  explicit TRT_TensorOrWeights(nvinfer1::ITensor* tensor)\n+      : _tensor_(tensor), _weights_(DT_FLOAT), _variant_(TRT_NODE_TENSOR) {}\n+  explicit TRT_TensorOrWeights(const TRT_ShapedWeights& weights)\n+      : _tensor_(nullptr), _weights_(weights), _variant_(TRT_NODE_WEIGHTS) {}\n+  TRT_TensorOrWeights(const TRT_TensorOrWeights& rhs)\n+      : _tensor_(rhs._tensor_),\n+        _weights_(rhs._weights_),\n+        _variant_(rhs._variant_) {}\n+  ~TRT_TensorOrWeights() {}\n+\n+  bool is_tensor() const { return _variant_ == TRT_NODE_TENSOR; }\n+  bool is_weights() const { return _variant_ == TRT_NODE_WEIGHTS; }\n+\n+  nvinfer1::ITensor* tensor() {\n+    CHECK_EQ(is_tensor(), true);\n+    return _tensor_;\n+  }\n+  const nvinfer1::ITensor* tensor() const {\n+    CHECK_EQ(is_tensor(), true);\n+    return _tensor_;\n+  }\n+  TRT_ShapedWeights& weights() {\n+    CHECK_EQ(is_weights(), true);\n+    return _weights_;\n+  }\n+  const TRT_ShapedWeights& weights() const {\n+    CHECK_EQ(is_weights(), true);\n+    return _weights_;\n+  }\n+  nvinfer1::Dims shape() const {\n+    if (is_tensor()) {\n+      return tensor()->getDimensions();\n+    } else {\n+      return weights().shape_;\n+    }\n+  }\n+\n+ private:\n+  nvinfer1::ITensor* _tensor_;", "path": "tensorflow/contrib/tensorrt/convert/convert_nodes.cc", "position": null, "original_position": 229, "commit_id": "1e4b5b8c0cc1675b9ecac3569c91563a2a4f9984", "original_commit_id": "cfa374cefe132be886c26a374c51454177c68868", "user": {"login": "jjsjann123", "id": 3709243, "node_id": "MDQ6VXNlcjM3MDkyNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3709243?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jjsjann123", "html_url": "https://github.com/jjsjann123", "followers_url": "https://api.github.com/users/jjsjann123/followers", "following_url": "https://api.github.com/users/jjsjann123/following{/other_user}", "gists_url": "https://api.github.com/users/jjsjann123/gists{/gist_id}", "starred_url": "https://api.github.com/users/jjsjann123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jjsjann123/subscriptions", "organizations_url": "https://api.github.com/users/jjsjann123/orgs", "repos_url": "https://api.github.com/users/jjsjann123/repos", "events_url": "https://api.github.com/users/jjsjann123/events{/privacy}", "received_events_url": "https://api.github.com/users/jjsjann123/received_events", "type": "User", "site_admin": false}, "body": "Working on it.. :)", "created_at": "2018-02-07T19:01:21Z", "updated_at": "2018-02-12T23:36:57Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16253#discussion_r166720736", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16253", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/166720736"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16253#discussion_r166720736"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16253"}}, "body_html": "<p>Working on it.. :)</p>", "body_text": "Working on it.. :)", "in_reply_to_id": 166712270}