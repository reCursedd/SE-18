{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/326896963", "html_url": "https://github.com/tensorflow/tensorflow/issues/12701#issuecomment-326896963", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12701", "id": 326896963, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjg5Njk2Mw==", "user": {"login": "GPhilo", "id": 4441724, "node_id": "MDQ6VXNlcjQ0NDE3MjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/4441724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GPhilo", "html_url": "https://github.com/GPhilo", "followers_url": "https://api.github.com/users/GPhilo/followers", "following_url": "https://api.github.com/users/GPhilo/following{/other_user}", "gists_url": "https://api.github.com/users/GPhilo/gists{/gist_id}", "starred_url": "https://api.github.com/users/GPhilo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GPhilo/subscriptions", "organizations_url": "https://api.github.com/users/GPhilo/orgs", "repos_url": "https://api.github.com/users/GPhilo/repos", "events_url": "https://api.github.com/users/GPhilo/events{/privacy}", "received_events_url": "https://api.github.com/users/GPhilo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-04T08:18:26Z", "updated_at": "2017-09-04T08:18:26Z", "author_association": "NONE", "body_html": "<p>Well, I don't know all possible use-cases for this function, so I'll just describe mine.<br>\nI'm loading images from a set of folders, doing inference on every image, recording the prediction result and the filename.<br>\nMy pipeline looks like this:</p>\n<pre><code>  def preprocess_image(fn):\n    im_s = tf.read_file(fn)\n    im = tf.image.decode_jpeg(im_s, channels=3)\n    im = inception_preprocessing.preprocess_for_eval(im, width=299, height=299)\n    return (fn, im)\n\n  dataset = tf.contrib.data.Dataset.list_files('{}/*/*/*.jpg'.format(FLAGS.dataset_dir))\n  dataset = dataset.map(preprocess_image, num_threads=FLAGS.num_threads, output_buffer_size=3*FLAGS.batch_size)\n  dataset = dataset.ignore_errors()\n  iterator = dataset.make_one_shot_iterator()\n</code></pre>\n<p>My dataset contains a small number of corrupted images that raise errors when processed. As of now, the <code>ignore_errors()</code> function does what it promises, but I'd like to have a way to find out which files are the ones raising the error, log them and later remove them from the dataset.</p>\n<p>This is why I thought of the callback. The dataset ideally would give me as much information as possible about the specific sample that raised the error. At the very least, the exception details, but possibly also the data sample available up to the point in the pipeline where the error is raised.<br>\nIn my use-case, it's the <code>dataset.map()</code> call that internally raises errors when decoding images. It would be great to have, on error, a way to log/inspect/process the sample taken from the pipeline stage after the <code>list_files</code> call that, once processed in <code>map()</code>, raises the error.</p>", "body_text": "Well, I don't know all possible use-cases for this function, so I'll just describe mine.\nI'm loading images from a set of folders, doing inference on every image, recording the prediction result and the filename.\nMy pipeline looks like this:\n  def preprocess_image(fn):\n    im_s = tf.read_file(fn)\n    im = tf.image.decode_jpeg(im_s, channels=3)\n    im = inception_preprocessing.preprocess_for_eval(im, width=299, height=299)\n    return (fn, im)\n\n  dataset = tf.contrib.data.Dataset.list_files('{}/*/*/*.jpg'.format(FLAGS.dataset_dir))\n  dataset = dataset.map(preprocess_image, num_threads=FLAGS.num_threads, output_buffer_size=3*FLAGS.batch_size)\n  dataset = dataset.ignore_errors()\n  iterator = dataset.make_one_shot_iterator()\n\nMy dataset contains a small number of corrupted images that raise errors when processed. As of now, the ignore_errors() function does what it promises, but I'd like to have a way to find out which files are the ones raising the error, log them and later remove them from the dataset.\nThis is why I thought of the callback. The dataset ideally would give me as much information as possible about the specific sample that raised the error. At the very least, the exception details, but possibly also the data sample available up to the point in the pipeline where the error is raised.\nIn my use-case, it's the dataset.map() call that internally raises errors when decoding images. It would be great to have, on error, a way to log/inspect/process the sample taken from the pipeline stage after the list_files call that, once processed in map(), raises the error.", "body": "Well, I don't know all possible use-cases for this function, so I'll just describe mine.\r\nI'm loading images from a set of folders, doing inference on every image, recording the prediction result and the filename.\r\nMy pipeline looks like this:\r\n```\r\n  def preprocess_image(fn):\r\n    im_s = tf.read_file(fn)\r\n    im = tf.image.decode_jpeg(im_s, channels=3)\r\n    im = inception_preprocessing.preprocess_for_eval(im, width=299, height=299)\r\n    return (fn, im)\r\n\r\n  dataset = tf.contrib.data.Dataset.list_files('{}/*/*/*.jpg'.format(FLAGS.dataset_dir))\r\n  dataset = dataset.map(preprocess_image, num_threads=FLAGS.num_threads, output_buffer_size=3*FLAGS.batch_size)\r\n  dataset = dataset.ignore_errors()\r\n  iterator = dataset.make_one_shot_iterator()\r\n```\r\n\r\nMy dataset contains a small number of corrupted images that raise errors when processed. As of now, the `ignore_errors()` function does what it promises, but I'd like to have a way to find out which files are the ones raising the error, log them and later remove them from the dataset.\r\n\r\nThis is why I thought of the callback. The dataset ideally would give me as much information as possible about the specific sample that raised the error. At the very least, the exception details, but possibly also the data sample available up to the point in the pipeline where the error is raised.\r\nIn my use-case, it's the `dataset.map()` call that internally raises errors when decoding images. It would be great to have, on error, a way to log/inspect/process the sample taken from the pipeline stage after the `list_files` call that, once processed in `map()`, raises the error."}