{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12701", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12701/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12701/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12701/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12701", "id": 253927324, "node_id": "MDU6SXNzdWUyNTM5MjczMjQ=", "number": 12701, "title": "Feature Request: callback argument for tf.contrib.data.Dataset.ignore_errors() to enable error logging", "user": {"login": "GPhilo", "id": 4441724, "node_id": "MDQ6VXNlcjQ0NDE3MjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/4441724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GPhilo", "html_url": "https://github.com/GPhilo", "followers_url": "https://api.github.com/users/GPhilo/followers", "following_url": "https://api.github.com/users/GPhilo/following{/other_user}", "gists_url": "https://api.github.com/users/GPhilo/gists{/gist_id}", "starred_url": "https://api.github.com/users/GPhilo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GPhilo/subscriptions", "organizations_url": "https://api.github.com/users/GPhilo/orgs", "repos_url": "https://api.github.com/users/GPhilo/repos", "events_url": "https://api.github.com/users/GPhilo/events{/privacy}", "received_events_url": "https://api.github.com/users/GPhilo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-08-30T09:03:28Z", "updated_at": "2018-01-03T05:57:33Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3.0</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: -</li>\n<li><strong>CUDA/cuDNN version</strong>: 8/6</li>\n<li><strong>GPU model and memory</strong>: GTX 1080, 8GB</li>\n<li><strong>Exact command to reproduce</strong>: -</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The <a href=\"https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/contrib/data/Dataset#ignore_errors\" rel=\"nofollow\"><code>tf.contrib.data.Dataset.ignore_errors()</code></a> function is extremely useful when processing data that has not been fully cleaned beforehand (e.g., with streaming input), but I find the \"silently ignoring all errors\" a bit too strict.<br>\nIt would be very useful, for example, to know which files raise an error when processing the dataset, while keeping the exception-masking feature of the function.</p>\n<p>IMO, the most flexible way to obtain this would be to include an optional <code>callback</code> argument to the function that gets called passing as arguments the value in the dataset that raised an error.<br>\nThis way custom logging can be done for each erroneous data sample and dataset inspection becomes much simpler.</p>\n<p>Would this be very hard to implement?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.3.0\nPython version: 3.6\nBazel version (if compiling from source): -\nCUDA/cuDNN version: 8/6\nGPU model and memory: GTX 1080, 8GB\nExact command to reproduce: -\n\nDescribe the problem\nThe tf.contrib.data.Dataset.ignore_errors() function is extremely useful when processing data that has not been fully cleaned beforehand (e.g., with streaming input), but I find the \"silently ignoring all errors\" a bit too strict.\nIt would be very useful, for example, to know which files raise an error when processing the dataset, while keeping the exception-masking feature of the function.\nIMO, the most flexible way to obtain this would be to include an optional callback argument to the function that gets called passing as arguments the value in the dataset that raised an error.\nThis way custom logging can be done for each erroneous data sample and dataset inspection becomes much simpler.\nWould this be very hard to implement?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: 8/6\r\n- **GPU model and memory**: GTX 1080, 8GB\r\n- **Exact command to reproduce**: -\r\n\r\n### Describe the problem\r\nThe [`tf.contrib.data.Dataset.ignore_errors()`](https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/contrib/data/Dataset#ignore_errors) function is extremely useful when processing data that has not been fully cleaned beforehand (e.g., with streaming input), but I find the \"silently ignoring all errors\" a bit too strict.\r\nIt would be very useful, for example, to know which files raise an error when processing the dataset, while keeping the exception-masking feature of the function.\r\n\r\nIMO, the most flexible way to obtain this would be to include an optional `callback` argument to the function that gets called passing as arguments the value in the dataset that raised an error.\r\nThis way custom logging can be done for each erroneous data sample and dataset inspection becomes much simpler.\r\n\r\nWould this be very hard to implement?\r\n"}