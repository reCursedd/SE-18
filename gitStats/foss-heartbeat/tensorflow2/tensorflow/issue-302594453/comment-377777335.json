{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/377777335", "html_url": "https://github.com/tensorflow/tensorflow/issues/17468#issuecomment-377777335", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17468", "id": 377777335, "node_id": "MDEyOklzc3VlQ29tbWVudDM3Nzc3NzMzNQ==", "user": {"login": "calicratis19", "id": 1763767, "node_id": "MDQ6VXNlcjE3NjM3Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1763767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calicratis19", "html_url": "https://github.com/calicratis19", "followers_url": "https://api.github.com/users/calicratis19/followers", "following_url": "https://api.github.com/users/calicratis19/following{/other_user}", "gists_url": "https://api.github.com/users/calicratis19/gists{/gist_id}", "starred_url": "https://api.github.com/users/calicratis19/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calicratis19/subscriptions", "organizations_url": "https://api.github.com/users/calicratis19/orgs", "repos_url": "https://api.github.com/users/calicratis19/repos", "events_url": "https://api.github.com/users/calicratis19/events{/privacy}", "received_events_url": "https://api.github.com/users/calicratis19/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-01T10:28:26Z", "updated_at": "2018-04-01T10:31:49Z", "author_association": "NONE", "body_html": "<p>I'm facing the same issue with mobilenet v2 downloaded from <a href=\"http://download.tensorflow.org/models/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz\" rel=\"nofollow\">mobilenetv2_coco_voc_trainaug</a>.</p>\n<p>The command to generate tlite file</p>\n<pre><code>bazel-bin/tensorflow/contrib/lite/toco/toco \\\n&gt; --input_file=frozen_inference_graph.pb \\\n&gt; --input_format=TENSORFLOW_GRAPHDEF \\\n&gt; --output_format=TFLITE \\\n&gt; --output_file=frozen_inference_graph.lite \\\n&gt; --inference_type=FLOAT \\\n&gt; --input_type=FLOAT \\\n&gt; --input_arrays=ImageTensor \\\n&gt; --output_arrays=SemanticPredictions \\\n&gt; --input_shapes=1,513,342,3\n\n</code></pre>\n<p>The log of the error.</p>\n<pre><code>2018-04-01 15:57:00.360279: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\n2018-04-01 15:57:00.389245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1172] Converting unsupported operation: Equal\n2018-04-01 15:57:00.389504: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1172] Converting unsupported operation: LogicalAnd\n2018-04-01 15:57:00.406372: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 812 operators, 1241 arrays (0 quantized)\n2018-04-01 15:57:00.434485: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 802 operators, 1222 arrays (0 quantized)\n2018-04-01 15:57:00.465611: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 802 operators, 1222 arrays (0 quantized)\n2018-04-01 15:57:00.465869: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:737] Check failed: output_size_shape.dimensions_count() == 1 (2 vs. 1)\nAborted (core dumped)\n</code></pre>", "body_text": "I'm facing the same issue with mobilenet v2 downloaded from mobilenetv2_coco_voc_trainaug.\nThe command to generate tlite file\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\n> --input_file=frozen_inference_graph.pb \\\n> --input_format=TENSORFLOW_GRAPHDEF \\\n> --output_format=TFLITE \\\n> --output_file=frozen_inference_graph.lite \\\n> --inference_type=FLOAT \\\n> --input_type=FLOAT \\\n> --input_arrays=ImageTensor \\\n> --output_arrays=SemanticPredictions \\\n> --input_shapes=1,513,342,3\n\n\nThe log of the error.\n2018-04-01 15:57:00.360279: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\n2018-04-01 15:57:00.389245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1172] Converting unsupported operation: Equal\n2018-04-01 15:57:00.389504: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1172] Converting unsupported operation: LogicalAnd\n2018-04-01 15:57:00.406372: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 812 operators, 1241 arrays (0 quantized)\n2018-04-01 15:57:00.434485: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 802 operators, 1222 arrays (0 quantized)\n2018-04-01 15:57:00.465611: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 802 operators, 1222 arrays (0 quantized)\n2018-04-01 15:57:00.465869: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:737] Check failed: output_size_shape.dimensions_count() == 1 (2 vs. 1)\nAborted (core dumped)", "body": "I'm facing the same issue with mobilenet v2 downloaded from [mobilenetv2_coco_voc_trainaug](http://download.tensorflow.org/models/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz).\r\n\r\nThe command to generate tlite file\r\n\r\n```\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n> --input_file=frozen_inference_graph.pb \\\r\n> --input_format=TENSORFLOW_GRAPHDEF \\\r\n> --output_format=TFLITE \\\r\n> --output_file=frozen_inference_graph.lite \\\r\n> --inference_type=FLOAT \\\r\n> --input_type=FLOAT \\\r\n> --input_arrays=ImageTensor \\\r\n> --output_arrays=SemanticPredictions \\\r\n> --input_shapes=1,513,342,3\r\n\r\n```\r\nThe log of the error.\r\n```\r\n2018-04-01 15:57:00.360279: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\r\n2018-04-01 15:57:00.389245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1172] Converting unsupported operation: Equal\r\n2018-04-01 15:57:00.389504: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1172] Converting unsupported operation: LogicalAnd\r\n2018-04-01 15:57:00.406372: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 812 operators, 1241 arrays (0 quantized)\r\n2018-04-01 15:57:00.434485: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 802 operators, 1222 arrays (0 quantized)\r\n2018-04-01 15:57:00.465611: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 802 operators, 1222 arrays (0 quantized)\r\n2018-04-01 15:57:00.465869: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:737] Check failed: output_size_shape.dimensions_count() == 1 (2 vs. 1)\r\nAborted (core dumped)\r\n```\r\n"}