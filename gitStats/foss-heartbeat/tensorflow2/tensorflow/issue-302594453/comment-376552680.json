{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/376552680", "html_url": "https://github.com/tensorflow/tensorflow/issues/17468#issuecomment-376552680", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17468", "id": 376552680, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NjU1MjY4MA==", "user": {"login": "dodiknikola", "id": 5052480, "node_id": "MDQ6VXNlcjUwNTI0ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5052480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dodiknikola", "html_url": "https://github.com/dodiknikola", "followers_url": "https://api.github.com/users/dodiknikola/followers", "following_url": "https://api.github.com/users/dodiknikola/following{/other_user}", "gists_url": "https://api.github.com/users/dodiknikola/gists{/gist_id}", "starred_url": "https://api.github.com/users/dodiknikola/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dodiknikola/subscriptions", "organizations_url": "https://api.github.com/users/dodiknikola/orgs", "repos_url": "https://api.github.com/users/dodiknikola/repos", "events_url": "https://api.github.com/users/dodiknikola/events{/privacy}", "received_events_url": "https://api.github.com/users/dodiknikola/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-27T14:46:45Z", "updated_at": "2018-03-27T14:54:16Z", "author_association": "NONE", "body_html": "<p>Hi, I'm having the same issue. I'm using the frozen DeepLab v3+ model from <a href=\"https://github.com/tensorflow/models/tree/master/research/deeplab\">here</a> (<a href=\"https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md\">xception_coco_voc_trainaug</a>).</p>\n<p>I printed out the shapes of all <code>ResizeBilinear/size</code> tensors, as well as the shapes of the inputs to all of the <code>ResizeBilinear</code> tensors, and it seems that they are all 1D and have two elements:</p>\n<pre><code>In [59]: print([(n.name, n.outputs[0].get_shape(), tf.contrib.util.constant_value(n.outputs[0])) for n in tf.get_default_graph().get_operations() if 'Bilinear' in n.name and '/size' in n.name])\n\n[('import/ResizeBilinear_1/size', TensorShape([Dimension(2)]), array([65, 65], dtype=int32)), ('import/decoder/ResizeBilinear/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/decoder/ResizeBilinear_1/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_2/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32))]\n</code></pre>\n<pre><code>In [60]: print([(n.name, n.inputs[1].name, n.inputs[1].shape, tf.contrib.util.constant_value(n.inputs[1])) for n in tf.get_default_graph().get_operations() if 'Bilinear' in n.name and '/size' not in n.name])\n\n[('import/ResizeBilinear', 'import/ToInt32:0', TensorShape([Dimension(2)]), None), ('import/ResizeBilinear_1', 'import/ResizeBilinear_1/size:0', TensorShape([Dimension(2)]), array([65, 65], dtype=int32)), ('import/decoder/ResizeBilinear', 'import/decoder/ResizeBilinear/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/decoder/ResizeBilinear_1', 'import/decoder/ResizeBilinear_1/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_2', 'import/ResizeBilinear_2/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_3', 'import/strided_slice_7:0', TensorShape([Dimension(2)]), None)]\n</code></pre>\n<p>However, when I add the following code to <code>ProcessResizeBilinearOperator</code>,</p>\n<pre><code>  std::cout &lt;&lt; \"Output size shape for \" &lt;&lt; output_size_name &lt;&lt; \": \";\n  for(auto dim : output_size_shape.dims()) {\n    std::cout &lt;&lt; dim &lt;&lt; \", \";\n  }\n  std::cout &lt;&lt; std::endl;\n  // CHECK_EQ(output_size_shape.dimensions_count(), 1);\n</code></pre>\n<p>I get the output:</p>\n<pre><code>2018-03-27 16:44:23.330779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: Equal\n2018-03-27 16:44:23.330937: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: LogicalAnd\n2018-03-27 16:44:23.453760: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1895 operators, 3070 arrays (0 quantized)\n2018-03-27 16:44:23.504983: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1885 operators, 3051 arrays (0 quantized)\n2018-03-27 16:44:23.573858: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1885 operators, 3051 arrays (0 quantized)\nOutput size shape for ToInt32: 2, 1, \n2018-03-27 16:44:23.803197: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 460 operators, 1136 arrays (0 quantized)\nOutput size shape for ToInt32: 2, 1, \n2018-03-27 16:44:23.817572: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 460 operators, 1136 arrays (0 quantized)\n2018-03-27 16:44:23.827669: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 7105728 bytes, theoretical optimal value: 6316160 bytes.\n2018-03-27 16:44:23.830342: F tensorflow/contrib/lite/toco/tooling_util.cc:1818] Check failed: array.final_data_type == array.data_type Array \"ImageTensor\" has mis-matching actual and final data types (4,2).\n./convert.sh: line 10: 30075 Aborted                 (core dumped) bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=../deeplabv3/deeplabv3_pascal_train_aug/frozen_inference_graph.pb --input_format=TENSORF\nLOW_GRAPHDEF --output_format=TFLITE --output_file=../deeplabv3/deeplabv3_pascal_train_aug/deeplabv3.tflite --inference_type=FLOAT --input_type=FLOAT --input_arrays=ImageTensor --output_arrays=SemanticPredictions \n--input_shapes=1,513,513,3\n\n</code></pre>\n<p>Does this information help?</p>\n<p>EDIT: removing the <code>--input_type</code> and <code>--inference_type</code> flags from the call gets rid of the mis-match error (converting the model does not work though since it is TFLite is missing some operations).</p>", "body_text": "Hi, I'm having the same issue. I'm using the frozen DeepLab v3+ model from here (xception_coco_voc_trainaug).\nI printed out the shapes of all ResizeBilinear/size tensors, as well as the shapes of the inputs to all of the ResizeBilinear tensors, and it seems that they are all 1D and have two elements:\nIn [59]: print([(n.name, n.outputs[0].get_shape(), tf.contrib.util.constant_value(n.outputs[0])) for n in tf.get_default_graph().get_operations() if 'Bilinear' in n.name and '/size' in n.name])\n\n[('import/ResizeBilinear_1/size', TensorShape([Dimension(2)]), array([65, 65], dtype=int32)), ('import/decoder/ResizeBilinear/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/decoder/ResizeBilinear_1/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_2/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32))]\n\nIn [60]: print([(n.name, n.inputs[1].name, n.inputs[1].shape, tf.contrib.util.constant_value(n.inputs[1])) for n in tf.get_default_graph().get_operations() if 'Bilinear' in n.name and '/size' not in n.name])\n\n[('import/ResizeBilinear', 'import/ToInt32:0', TensorShape([Dimension(2)]), None), ('import/ResizeBilinear_1', 'import/ResizeBilinear_1/size:0', TensorShape([Dimension(2)]), array([65, 65], dtype=int32)), ('import/decoder/ResizeBilinear', 'import/decoder/ResizeBilinear/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/decoder/ResizeBilinear_1', 'import/decoder/ResizeBilinear_1/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_2', 'import/ResizeBilinear_2/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_3', 'import/strided_slice_7:0', TensorShape([Dimension(2)]), None)]\n\nHowever, when I add the following code to ProcessResizeBilinearOperator,\n  std::cout << \"Output size shape for \" << output_size_name << \": \";\n  for(auto dim : output_size_shape.dims()) {\n    std::cout << dim << \", \";\n  }\n  std::cout << std::endl;\n  // CHECK_EQ(output_size_shape.dimensions_count(), 1);\n\nI get the output:\n2018-03-27 16:44:23.330779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: Equal\n2018-03-27 16:44:23.330937: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: LogicalAnd\n2018-03-27 16:44:23.453760: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1895 operators, 3070 arrays (0 quantized)\n2018-03-27 16:44:23.504983: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1885 operators, 3051 arrays (0 quantized)\n2018-03-27 16:44:23.573858: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1885 operators, 3051 arrays (0 quantized)\nOutput size shape for ToInt32: 2, 1, \n2018-03-27 16:44:23.803197: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 460 operators, 1136 arrays (0 quantized)\nOutput size shape for ToInt32: 2, 1, \n2018-03-27 16:44:23.817572: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 460 operators, 1136 arrays (0 quantized)\n2018-03-27 16:44:23.827669: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 7105728 bytes, theoretical optimal value: 6316160 bytes.\n2018-03-27 16:44:23.830342: F tensorflow/contrib/lite/toco/tooling_util.cc:1818] Check failed: array.final_data_type == array.data_type Array \"ImageTensor\" has mis-matching actual and final data types (4,2).\n./convert.sh: line 10: 30075 Aborted                 (core dumped) bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=../deeplabv3/deeplabv3_pascal_train_aug/frozen_inference_graph.pb --input_format=TENSORF\nLOW_GRAPHDEF --output_format=TFLITE --output_file=../deeplabv3/deeplabv3_pascal_train_aug/deeplabv3.tflite --inference_type=FLOAT --input_type=FLOAT --input_arrays=ImageTensor --output_arrays=SemanticPredictions \n--input_shapes=1,513,513,3\n\n\nDoes this information help?\nEDIT: removing the --input_type and --inference_type flags from the call gets rid of the mis-match error (converting the model does not work though since it is TFLite is missing some operations).", "body": "Hi, I'm having the same issue. I'm using the frozen DeepLab v3+ model from [here](https://github.com/tensorflow/models/tree/master/research/deeplab) ([xception_coco_voc_trainaug](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md)).\r\n\r\nI printed out the shapes of all `ResizeBilinear/size` tensors, as well as the shapes of the inputs to all of the `ResizeBilinear` tensors, and it seems that they are all 1D and have two elements:\r\n\r\n```\r\nIn [59]: print([(n.name, n.outputs[0].get_shape(), tf.contrib.util.constant_value(n.outputs[0])) for n in tf.get_default_graph().get_operations() if 'Bilinear' in n.name and '/size' in n.name])\r\n\r\n[('import/ResizeBilinear_1/size', TensorShape([Dimension(2)]), array([65, 65], dtype=int32)), ('import/decoder/ResizeBilinear/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/decoder/ResizeBilinear_1/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_2/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32))]\r\n```\r\n\r\n```\r\nIn [60]: print([(n.name, n.inputs[1].name, n.inputs[1].shape, tf.contrib.util.constant_value(n.inputs[1])) for n in tf.get_default_graph().get_operations() if 'Bilinear' in n.name and '/size' not in n.name])\r\n\r\n[('import/ResizeBilinear', 'import/ToInt32:0', TensorShape([Dimension(2)]), None), ('import/ResizeBilinear_1', 'import/ResizeBilinear_1/size:0', TensorShape([Dimension(2)]), array([65, 65], dtype=int32)), ('import/decoder/ResizeBilinear', 'import/decoder/ResizeBilinear/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/decoder/ResizeBilinear_1', 'import/decoder/ResizeBilinear_1/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_2', 'import/ResizeBilinear_2/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_3', 'import/strided_slice_7:0', TensorShape([Dimension(2)]), None)]\r\n```\r\n\r\nHowever, when I add the following code to `ProcessResizeBilinearOperator`,\r\n\r\n```\r\n  std::cout << \"Output size shape for \" << output_size_name << \": \";\r\n  for(auto dim : output_size_shape.dims()) {\r\n    std::cout << dim << \", \";\r\n  }\r\n  std::cout << std::endl;\r\n  // CHECK_EQ(output_size_shape.dimensions_count(), 1);\r\n```\r\n\r\nI get the output:\r\n\r\n```\r\n2018-03-27 16:44:23.330779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: Equal\r\n2018-03-27 16:44:23.330937: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: LogicalAnd\r\n2018-03-27 16:44:23.453760: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1895 operators, 3070 arrays (0 quantized)\r\n2018-03-27 16:44:23.504983: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1885 operators, 3051 arrays (0 quantized)\r\n2018-03-27 16:44:23.573858: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1885 operators, 3051 arrays (0 quantized)\r\nOutput size shape for ToInt32: 2, 1, \r\n2018-03-27 16:44:23.803197: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 460 operators, 1136 arrays (0 quantized)\r\nOutput size shape for ToInt32: 2, 1, \r\n2018-03-27 16:44:23.817572: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 460 operators, 1136 arrays (0 quantized)\r\n2018-03-27 16:44:23.827669: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 7105728 bytes, theoretical optimal value: 6316160 bytes.\r\n2018-03-27 16:44:23.830342: F tensorflow/contrib/lite/toco/tooling_util.cc:1818] Check failed: array.final_data_type == array.data_type Array \"ImageTensor\" has mis-matching actual and final data types (4,2).\r\n./convert.sh: line 10: 30075 Aborted                 (core dumped) bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=../deeplabv3/deeplabv3_pascal_train_aug/frozen_inference_graph.pb --input_format=TENSORF\r\nLOW_GRAPHDEF --output_format=TFLITE --output_file=../deeplabv3/deeplabv3_pascal_train_aug/deeplabv3.tflite --inference_type=FLOAT --input_type=FLOAT --input_arrays=ImageTensor --output_arrays=SemanticPredictions \r\n--input_shapes=1,513,513,3\r\n\r\n```\r\n\r\nDoes this information help?\r\n\r\nEDIT: removing the `--input_type` and `--inference_type` flags from the call gets rid of the mis-match error (converting the model does not work though since it is TFLite is missing some operations)."}