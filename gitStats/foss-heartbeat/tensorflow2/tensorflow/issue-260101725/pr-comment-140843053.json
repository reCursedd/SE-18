{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/140843053", "pull_request_review_id": 64966160, "id": 140843053, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MDg0MzA1Mw==", "diff_hunk": "@@ -0,0 +1,344 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import re\n+\n+from tensorflow.contrib.framework.python.ops import variables\n+from tensorflow.contrib.layers.python.layers import optimizers\n+\n+from tensorflow.contrib.timeseries.python.timeseries import feature_keys\n+\n+from tensorflow.python.estimator import estimator_lib\n+from tensorflow.python.estimator.canned import head as head_lib\n+from tensorflow.python.estimator.export import export_lib\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import state_ops\n+from tensorflow.python.ops import variable_scope\n+from tensorflow.python.util import nest\n+\n+\n+def time_series_regression_head(\n+        model, state_manager, optimizer, input_statistics_generator=None):\n+  \"\"\"Creates a `_Head` for regression using the mean squared loss.\n+\n+  Args:\n+    weight_column: A string or a `_NumericColumn` created by\n+      `tf.feature_column.numeric_column` defining feature column representing\n+      weights. It is used to down weight or boost examples during training. It\n+      will be multiplied by the loss of the example.\n+    label_dimension: Number of regression labels per example. This is the size\n+      of the last dimension of the labels `Tensor` (typically, this has shape\n+      `[batch_size, label_dimension]`).\n+\n+  Returns:\n+    An instance of `_Head` for linear regression.\n+  \"\"\"\n+  return _TimeSeriesRegressionHead(\n+    model, state_manager, optimizer, input_statistics_generator)\n+\n+\n+class _TimeSeriesRegressionHead(head_lib._Head):  # pylint:disable=protected-access\n+  \"\"\"Returns a model function suitable for use with a tf.estimator.\n+\n+  Args:\n+    model: The object (inheriting from Model) to create a function for.\n+    state_manager: A state manager to wrap the model with (or\n+        PassthroughStateManager if no state needs to be managed).\n+    optimizer: An instance of `tf.train.Optimizer` to use for training.\n+    input_statistics_generator: An InputStatisticsFromMiniBatch object from\n+        math_utils.py, used for collecting statistics about input data during\n+        training.\n+  Returns:\n+    The model function, suitable for passing to a tf.estimator.Estimator.\n+  \"\"\"\n+  def __init__(self, model, state_manager, optimizer, input_statistics_generator=None):\n+    self.model = model\n+    self.state_manager = state_manager\n+    self.optimizer = optimizer\n+    self.input_statistics_generator = input_statistics_generator\n+\n+  def _train_ops(self, features):\n+    \"\"\"Add training ops to the graph.\"\"\"\n+    with variable_scope.variable_scope(\"model\"):\n+      model_outputs = self.state_manager.define_loss(self.model, features,\n+                                                     estimator_lib.ModeKeys.TRAIN)\n+    train_op = optimizers.optimize_loss(\n+      model_outputs.loss,\n+      global_step=variables.get_global_step(),\n+      optimizer=self.optimizer,\n+      # Learning rate is set in the Optimizer object\n+      learning_rate=None)\n+    return estimator_lib.EstimatorSpec(\n+      loss=model_outputs.loss,\n+      mode=estimator_lib.ModeKeys.TRAIN,\n+      train_op=train_op)\n+\n+  # TODO: check label dimension\n+  @property\n+  def logits_dimension(self):\n+    return None\n+\n+  def _evaluate_ops(self, features):\n+    \"\"\"Add ops for evaluation (aka filtering) to the graph.\"\"\"\n+    with variable_scope.variable_scope(\"model\"):\n+      model_outputs = self.state_manager.define_loss(self.model, features,\n+                                                     estimator_lib.ModeKeys.EVAL)\n+    metrics = {}\n+    # Just output in-sample predictions for the last chunk seen\n+    for prediction_key, prediction_value in model_outputs.predictions.items():\n+      metrics[prediction_key] = _identity_metric_single(prediction_key,\n+                                                        prediction_value)\n+    metrics[feature_keys.FilteringResults.TIMES] = _identity_metric_single(\n+      feature_keys.FilteringResults.TIMES, model_outputs.prediction_times)\n+    metrics[feature_keys.FilteringResults.STATE_TUPLE] = (\n+      _identity_metric_nested(feature_keys.FilteringResults.STATE_TUPLE,\n+                              model_outputs.end_state))\n+    return estimator_lib.EstimatorSpec(\n+      loss=model_outputs.loss,\n+      mode=estimator_lib.ModeKeys.EVAL,\n+      eval_metric_ops=metrics,\n+      predictions={})\n+\n+  def _predict_ops(self, features):\n+    \"\"\"Add ops for prediction to the graph.\"\"\"\n+    with variable_scope.variable_scope(\"model\"):\n+      prediction = self.model.predict(features=features)\n+    prediction[feature_keys.PredictionResults.TIMES] = features[\n+      feature_keys.PredictionFeatures.TIMES]\n+    return estimator_lib.EstimatorSpec(\n+      predictions=prediction, mode=estimator_lib.ModeKeys.PREDICT)\n+\n+  def _serving_ops(self, features):\n+    with variable_scope.variable_scope(\"model\"):\n+      prediction_outputs = self.model.predict(features=features)\n+    with variable_scope.variable_scope(\"model\", reuse=True):\n+      filtering_outputs = self.state_manager.define_loss(self.model, features,\n+                                                         estimator_lib.ModeKeys.EVAL)\n+    return estimator_lib.EstimatorSpec(\n+      mode=estimator_lib.ModeKeys.PREDICT,\n+      export_outputs={\n+        feature_keys.SavedModelLabels.PREDICT:\n+          export_lib.PredictOutput(prediction_outputs),\n+        feature_keys.SavedModelLabels.FILTER:\n+          export_lib.PredictOutput(\n+            _state_to_dictionary(filtering_outputs.end_state))\n+      },\n+      # Likely unused, but it is necessary to return `predictions` to satisfy\n+      # the Estimator's error checking.\n+      predictions={})\n+\n+  def _convert_feature_to_tensor(self, name, value):\n+    \"\"\"Casts features to the correct dtype based on their name.\"\"\"\n+    if name in [\n+      feature_keys.TrainEvalFeatures.TIMES,\n+      feature_keys.PredictionFeatures.TIMES\n+    ]:\n+      return math_ops.cast(value, dtypes.int64)\n+    if name == feature_keys.TrainEvalFeatures.VALUES:\n+      return math_ops.cast(value, self.model.dtype)\n+    if name == feature_keys.PredictionFeatures.STATE_TUPLE:\n+      return value  # Correct dtypes are model-dependent\n+    return ops.convert_to_tensor(value)\n+\n+  def _gather_state(self, features):\n+    \"\"\"Returns `features` with state packed, indicates if packing was done.\"\"\"\n+    prefixed_state_re = re.compile(r\"^\" + feature_keys.State.STATE_PREFIX +\n+                                   r\"_(\\d+)$\")\n+    numbered_state = []\n+    for key, tensor in features.items():\n+      search_result = prefixed_state_re.search(key)\n+      if search_result:\n+        numbered_state.append((int(search_result.group(1)), key, tensor))\n+    if not numbered_state:\n+      return features, False\n+    features = features.copy()\n+    for _, key, _ in numbered_state:\n+      del features[key]\n+    numbered_state.sort(key=lambda number, *_: number)\n+    features[feature_keys.State.STATE_TUPLE] = nest.pack_sequence_as(\n+      structure=self.model.get_start_state(),\n+      flat_sequence=[tensor for _, _, tensor in numbered_state])\n+    return features, True\n+\n+  def create_estimator_spec(\n+          self, features, mode, logits=None, labels=None, train_op_fn=None):", "path": "tensorflow/contrib/timeseries/python/timeseries/head.py", "position": null, "original_position": 169, "commit_id": "1d9feae3307c5e46454e2cdfacfeeb1d3adb8de4", "original_commit_id": "1393432dec2627e369a0a45f701e2b9612a49328", "user": {"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}, "body": "One-line docstring like \"Performs basic error checking and returns an EstimatorSpec.\"", "created_at": "2017-09-25T17:29:07Z", "updated_at": "2017-09-27T20:49:14Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13275#discussion_r140843053", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13275", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/140843053"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13275#discussion_r140843053"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13275"}}, "body_html": "<p>One-line docstring like \"Performs basic error checking and returns an EstimatorSpec.\"</p>", "body_text": "One-line docstring like \"Performs basic error checking and returns an EstimatorSpec.\""}