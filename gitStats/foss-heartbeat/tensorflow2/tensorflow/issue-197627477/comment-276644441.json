{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/276644441", "html_url": "https://github.com/tensorflow/tensorflow/issues/6509#issuecomment-276644441", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6509", "id": 276644441, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NjY0NDQ0MQ==", "user": {"login": "Pyrestone", "id": 20396757, "node_id": "MDQ6VXNlcjIwMzk2NzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/20396757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Pyrestone", "html_url": "https://github.com/Pyrestone", "followers_url": "https://api.github.com/users/Pyrestone/followers", "following_url": "https://api.github.com/users/Pyrestone/following{/other_user}", "gists_url": "https://api.github.com/users/Pyrestone/gists{/gist_id}", "starred_url": "https://api.github.com/users/Pyrestone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Pyrestone/subscriptions", "organizations_url": "https://api.github.com/users/Pyrestone/orgs", "repos_url": "https://api.github.com/users/Pyrestone/repos", "events_url": "https://api.github.com/users/Pyrestone/events{/privacy}", "received_events_url": "https://api.github.com/users/Pyrestone/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-01T12:21:52Z", "updated_at": "2017-02-01T12:21:52Z", "author_association": "NONE", "body_html": "<p>Hi guys, what's the status on this?<br>\nI've encountered the same bug on Windows/GPU with a GTX Titan Black.<br>\nWhen I replaced<br>\n<code>target_one_hot=tf.onehot(targets,vocab_size_targets,dtype=tf.float32)</code></p>\n<p>with the workaround by name-name<br>\nit worked just fine.</p>\n<p>here's the function wrapper i used for the workaround:</p>\n<pre><code>def one_hot_patch(x,depth):\n                #workaround by name-name\n                sparse_labels=tf.reshape(x,[-1,1])\n                derived_size=tf.shape(sparse_labels)[0]\n                indices=tf.reshape(tf.range(0,derived_size,1),[-1,1])\n                concated=tf.concat(1,[indices,sparse_labels])\n                outshape=tf.concat(0,[tf.reshape(derived_size,[1]),tf.reshape(depth,[1])])\n                return tf.sparse_to_dense(concated, outshape,1.0,0.0)\ntarget_one_hot=one_hot_patch(targets,vocab_size_targets)\n</code></pre>\n<p>my <code>targets</code> and <code>vocab_size_targets</code> are both tf.int32 Tensors.</p>\n<p>I'm currently on r0.12 (pip installation) with cuda 8.0 and CuDNN 5.1</p>", "body_text": "Hi guys, what's the status on this?\nI've encountered the same bug on Windows/GPU with a GTX Titan Black.\nWhen I replaced\ntarget_one_hot=tf.onehot(targets,vocab_size_targets,dtype=tf.float32)\nwith the workaround by name-name\nit worked just fine.\nhere's the function wrapper i used for the workaround:\ndef one_hot_patch(x,depth):\n                #workaround by name-name\n                sparse_labels=tf.reshape(x,[-1,1])\n                derived_size=tf.shape(sparse_labels)[0]\n                indices=tf.reshape(tf.range(0,derived_size,1),[-1,1])\n                concated=tf.concat(1,[indices,sparse_labels])\n                outshape=tf.concat(0,[tf.reshape(derived_size,[1]),tf.reshape(depth,[1])])\n                return tf.sparse_to_dense(concated, outshape,1.0,0.0)\ntarget_one_hot=one_hot_patch(targets,vocab_size_targets)\n\nmy targets and vocab_size_targets are both tf.int32 Tensors.\nI'm currently on r0.12 (pip installation) with cuda 8.0 and CuDNN 5.1", "body": "Hi guys, what's the status on this?\r\nI've encountered the same bug on Windows/GPU with a GTX Titan Black.\r\nWhen I replaced \r\n`target_one_hot=tf.onehot(targets,vocab_size_targets,dtype=tf.float32)`\r\n\r\nwith the workaround by name-name\r\nit worked just fine.\r\n\r\nhere's the function wrapper i used for the workaround:\r\n```\r\ndef one_hot_patch(x,depth):\r\n                #workaround by name-name\r\n                sparse_labels=tf.reshape(x,[-1,1])\r\n                derived_size=tf.shape(sparse_labels)[0]\r\n                indices=tf.reshape(tf.range(0,derived_size,1),[-1,1])\r\n                concated=tf.concat(1,[indices,sparse_labels])\r\n                outshape=tf.concat(0,[tf.reshape(derived_size,[1]),tf.reshape(depth,[1])])\r\n                return tf.sparse_to_dense(concated, outshape,1.0,0.0)\r\ntarget_one_hot=one_hot_patch(targets,vocab_size_targets)\r\n```\r\nmy `targets` and `vocab_size_targets` are both tf.int32 Tensors.\r\n\r\nI'm currently on r0.12 (pip installation) with cuda 8.0 and CuDNN 5.1"}