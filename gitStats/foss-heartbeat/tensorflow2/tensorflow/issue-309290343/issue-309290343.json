{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18044", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18044/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18044/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18044/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18044", "id": 309290343, "node_id": "MDU6SXNzdWUzMDkyOTAzNDM=", "number": 18044, "title": "FailedPreconditionError (see above for traceback): Failed to rename: <file_name> to: <file_name> : The process cannot access the file because it is being used by another process. ; Broken pipe", "user": {"login": "aforslow", "id": 17109848, "node_id": "MDQ6VXNlcjE3MTA5ODQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/17109848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aforslow", "html_url": "https://github.com/aforslow", "followers_url": "https://api.github.com/users/aforslow/followers", "following_url": "https://api.github.com/users/aforslow/following{/other_user}", "gists_url": "https://api.github.com/users/aforslow/gists{/gist_id}", "starred_url": "https://api.github.com/users/aforslow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aforslow/subscriptions", "organizations_url": "https://api.github.com/users/aforslow/orgs", "repos_url": "https://api.github.com/users/aforslow/repos", "events_url": "https://api.github.com/users/aforslow/events{/privacy}", "received_events_url": "https://api.github.com/users/aforslow/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-03-28T09:35:19Z", "updated_at": "2018-10-26T21:07:46Z", "closed_at": "2018-10-26T21:07:46Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 10 Pro 64-bit (10.0, Build 16299)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nBinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.6.0</li>\n<li><strong>Python version</strong>:<br>\nb'unknown' 1.6.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>I try to run a model using tf.train.MonitoredTrainingSession(), but get an error when the CheckPointSaverHook() tries to save the model. Having loked at the target saving directory, the saver seems to create a temporary directory from shards (something I assume is done because of the model being quite big) for later use. When the saver later on tries to use the sharded files in this directory, it seems to get blocked by another process accessing those files, resulting in a broken pipe error.</p>\n<p>I assume the problem has to do with the sharding mechanism, as this is the first time I've seen the saver having to save the checkpoints in shards. I am not sure though, so if you're sure something else is causing this error, you're probably right.</p>\n<h3>Source code / logs</h3>\n<p>Below is the error message I get when running my code.</p>\n<pre><code>Caused by op 'save/SaveV2', defined at:\n  File \"em_routing_train.py\", line 218, in &lt;module&gt;\n    tf.app.run()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\n    _sys.exit(main(argv))\n  File \"em_routing_train.py\", line 214, in main\n    train()\n  File \"em_routing_train.py\", line 135, in train\n    log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 384, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 795, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 981, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 986, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 675, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 437, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 212, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 871, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in __init__\n    self.build()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 787, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 411, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 385, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 326, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 241, in save_op\n    tensors)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1286, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Failed to rename: \n./tmp/em_routing_train3\\model.ckpt-1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-\n00001.index.tempstate15074727511180888636 to: ./tmp/em_routing_train3\\model.ckpt-\n1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-00001.index : The process cannot access \nthe file because it is being used by another process.\n; Broken pipe\n         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., \nDT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], \n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, \nsave/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Class_caps/capsule_cl_tr/beta_u/beta_u, \nClass_caps/capsule_cl_tr/beta_u/beta_u/Adam, Class_caps/capsule_cl_tr/beta_u/beta_u/Adam_1, \nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights, \nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights/Adam, \nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights/Adam_1, ReLu_Conv1/conv2d/bias, \nReLu_Conv1/conv2d/bias/Adam, ReLu_Conv1/conv2d/bias/Adam_1, ReLu_Conv1/conv2d/kernel, \nReLu_Conv1/conv2d/kernel/Adam, ReLu_Conv1/conv2d/kernel/Adam_1, beta1_power, beta2_power, \nbeta_a/beta_a, beta_a/beta_a/Adam, beta_a/beta_a/Adam_1, convCaps1/beta_u/beta_u, \nconvCaps1/beta_u/beta_u/Adam, convCaps1/beta_u/beta_u/Adam_1, convCaps1/weights/weights, \nconvCaps1/weights/weights/Adam, convCaps1/weights/weights/Adam_1, convCaps2/beta_u/beta_u, \nconvCaps2/beta_u/beta_u/Adam, convCaps2/beta_u/beta_u/Adam_1, convCaps2/weights/weights, \nconvCaps2/weights/weights/Adam, convCaps2/weights/weights/Adam_1, global_step, \nprimaryCaps/weights1, primaryCaps/weights1/Adam, primaryCaps/weights1/Adam_1, \nprimaryCaps/weights2, primaryCaps/weights2/Adam, primaryCaps/weights2/Adam_1)]]\n</code></pre>\n<p>The important part of this error message is, as I see it:</p>\n<pre><code>FailedPreconditionError (see above for traceback): Failed to rename: \n./tmp/em_routing_train3\\model.ckpt-1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-\n00001.index.tempstate15074727511180888636 to: ./tmp/em_routing_train3\\model.ckpt-\n1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-00001.index : The process cannot access \nthe file because it is being used by another process.\n; Broken pipe\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 10 Pro 64-bit (10.0, Build 16299)\nTensorFlow installed from (source or binary):\nBinary\nTensorFlow version (use command below):\n1.6.0\nPython version:\nb'unknown' 1.6.0\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nI try to run a model using tf.train.MonitoredTrainingSession(), but get an error when the CheckPointSaverHook() tries to save the model. Having loked at the target saving directory, the saver seems to create a temporary directory from shards (something I assume is done because of the model being quite big) for later use. When the saver later on tries to use the sharded files in this directory, it seems to get blocked by another process accessing those files, resulting in a broken pipe error.\nI assume the problem has to do with the sharding mechanism, as this is the first time I've seen the saver having to save the checkpoints in shards. I am not sure though, so if you're sure something else is causing this error, you're probably right.\nSource code / logs\nBelow is the error message I get when running my code.\nCaused by op 'save/SaveV2', defined at:\n  File \"em_routing_train.py\", line 218, in <module>\n    tf.app.run()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\n    _sys.exit(main(argv))\n  File \"em_routing_train.py\", line 214, in main\n    train()\n  File \"em_routing_train.py\", line 135, in train\n    log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 384, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 795, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 981, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 986, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 675, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 437, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 212, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 871, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in __init__\n    self.build()\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 787, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 411, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 385, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 326, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 241, in save_op\n    tensors)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1286, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Failed to rename: \n./tmp/em_routing_train3\\model.ckpt-1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-\n00001.index.tempstate15074727511180888636 to: ./tmp/em_routing_train3\\model.ckpt-\n1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-00001.index : The process cannot access \nthe file because it is being used by another process.\n; Broken pipe\n         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., \nDT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], \n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, \nsave/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Class_caps/capsule_cl_tr/beta_u/beta_u, \nClass_caps/capsule_cl_tr/beta_u/beta_u/Adam, Class_caps/capsule_cl_tr/beta_u/beta_u/Adam_1, \nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights, \nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights/Adam, \nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights/Adam_1, ReLu_Conv1/conv2d/bias, \nReLu_Conv1/conv2d/bias/Adam, ReLu_Conv1/conv2d/bias/Adam_1, ReLu_Conv1/conv2d/kernel, \nReLu_Conv1/conv2d/kernel/Adam, ReLu_Conv1/conv2d/kernel/Adam_1, beta1_power, beta2_power, \nbeta_a/beta_a, beta_a/beta_a/Adam, beta_a/beta_a/Adam_1, convCaps1/beta_u/beta_u, \nconvCaps1/beta_u/beta_u/Adam, convCaps1/beta_u/beta_u/Adam_1, convCaps1/weights/weights, \nconvCaps1/weights/weights/Adam, convCaps1/weights/weights/Adam_1, convCaps2/beta_u/beta_u, \nconvCaps2/beta_u/beta_u/Adam, convCaps2/beta_u/beta_u/Adam_1, convCaps2/weights/weights, \nconvCaps2/weights/weights/Adam, convCaps2/weights/weights/Adam_1, global_step, \nprimaryCaps/weights1, primaryCaps/weights1/Adam, primaryCaps/weights1/Adam_1, \nprimaryCaps/weights2, primaryCaps/weights2/Adam, primaryCaps/weights2/Adam_1)]]\n\nThe important part of this error message is, as I see it:\nFailedPreconditionError (see above for traceback): Failed to rename: \n./tmp/em_routing_train3\\model.ckpt-1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-\n00001.index.tempstate15074727511180888636 to: ./tmp/em_routing_train3\\model.ckpt-\n1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-00001.index : The process cannot access \nthe file because it is being used by another process.\n; Broken pipe", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 Pro 64-bit (10.0, Build 16299)\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.6.0\r\n- **Python version**: \r\nb'unknown' 1.6.0\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI try to run a model using tf.train.MonitoredTrainingSession(), but get an error when the CheckPointSaverHook() tries to save the model. Having loked at the target saving directory, the saver seems to create a temporary directory from shards (something I assume is done because of the model being quite big) for later use. When the saver later on tries to use the sharded files in this directory, it seems to get blocked by another process accessing those files, resulting in a broken pipe error.\r\n\r\nI assume the problem has to do with the sharding mechanism, as this is the first time I've seen the saver having to save the checkpoints in shards. I am not sure though, so if you're sure something else is causing this error, you're probably right.\r\n\r\n### Source code / logs\r\nBelow is the error message I get when running my code. \r\n\r\n```\r\nCaused by op 'save/SaveV2', defined at:\r\n  File \"em_routing_train.py\", line 218, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"em_routing_train.py\", line 214, in main\r\n    train()\r\n  File \"em_routing_train.py\", line 135, in train\r\n    log_device_placement=FLAGS.log_device_placement)) as mon_sess:\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 384, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 795, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 981, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 986, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 675, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 437, in create_session\r\n    self._scaffold.finalize()\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 212, in finalize\r\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 871, in _get_saver_or_default\r\n    saver = Saver(sharded=True, allow_empty=True)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in __init__\r\n    self.build()\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1302, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1339, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 787, in _build_internal\r\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 411, in _AddShardedSaveOps\r\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 385, in _AddShardedSaveOpsForV2\r\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 326, in _AddSaveOps\r\n    save = self.save_op(filename_tensor, saveables)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 241, in save_op\r\n    tensors)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1286, in save_v2\r\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nFailedPreconditionError (see above for traceback): Failed to rename: \r\n./tmp/em_routing_train3\\model.ckpt-1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-\r\n00001.index.tempstate15074727511180888636 to: ./tmp/em_routing_train3\\model.ckpt-\r\n1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-00001.index : The process cannot access \r\nthe file because it is being used by another process.\r\n; Broken pipe\r\n         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., \r\nDT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], \r\n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, \r\nsave/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Class_caps/capsule_cl_tr/beta_u/beta_u, \r\nClass_caps/capsule_cl_tr/beta_u/beta_u/Adam, Class_caps/capsule_cl_tr/beta_u/beta_u/Adam_1, \r\nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights, \r\nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights/Adam, \r\nClass_caps/capsule_cl_tr/weights/Class_caps/capsule_cl_tr/weights/Adam_1, ReLu_Conv1/conv2d/bias, \r\nReLu_Conv1/conv2d/bias/Adam, ReLu_Conv1/conv2d/bias/Adam_1, ReLu_Conv1/conv2d/kernel, \r\nReLu_Conv1/conv2d/kernel/Adam, ReLu_Conv1/conv2d/kernel/Adam_1, beta1_power, beta2_power, \r\nbeta_a/beta_a, beta_a/beta_a/Adam, beta_a/beta_a/Adam_1, convCaps1/beta_u/beta_u, \r\nconvCaps1/beta_u/beta_u/Adam, convCaps1/beta_u/beta_u/Adam_1, convCaps1/weights/weights, \r\nconvCaps1/weights/weights/Adam, convCaps1/weights/weights/Adam_1, convCaps2/beta_u/beta_u, \r\nconvCaps2/beta_u/beta_u/Adam, convCaps2/beta_u/beta_u/Adam_1, convCaps2/weights/weights, \r\nconvCaps2/weights/weights/Adam, convCaps2/weights/weights/Adam_1, global_step, \r\nprimaryCaps/weights1, primaryCaps/weights1/Adam, primaryCaps/weights1/Adam_1, \r\nprimaryCaps/weights2, primaryCaps/weights2/Adam, primaryCaps/weights2/Adam_1)]]\r\n```\r\n\r\nThe important part of this error message is, as I see it:\r\n\r\n```\r\nFailedPreconditionError (see above for traceback): Failed to rename: \r\n./tmp/em_routing_train3\\model.ckpt-1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-\r\n00001.index.tempstate15074727511180888636 to: ./tmp/em_routing_train3\\model.ckpt-\r\n1_temp_79c748505e6941cfa43f30080736273a/part-00000-of-00001.index : The process cannot access \r\nthe file because it is being used by another process.\r\n; Broken pipe\r\n```\r\n"}