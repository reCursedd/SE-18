{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/426111541", "html_url": "https://github.com/tensorflow/tensorflow/issues/21600#issuecomment-426111541", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21600", "id": 426111541, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNjExMTU0MQ==", "user": {"login": "alapha23", "id": 23239892, "node_id": "MDQ6VXNlcjIzMjM5ODky", "avatar_url": "https://avatars2.githubusercontent.com/u/23239892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alapha23", "html_url": "https://github.com/alapha23", "followers_url": "https://api.github.com/users/alapha23/followers", "following_url": "https://api.github.com/users/alapha23/following{/other_user}", "gists_url": "https://api.github.com/users/alapha23/gists{/gist_id}", "starred_url": "https://api.github.com/users/alapha23/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alapha23/subscriptions", "organizations_url": "https://api.github.com/users/alapha23/orgs", "repos_url": "https://api.github.com/users/alapha23/repos", "events_url": "https://api.github.com/users/alapha23/events{/privacy}", "received_events_url": "https://api.github.com/users/alapha23/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-02T00:56:49Z", "updated_at": "2018-10-02T00:56:49Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1990079\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/smit-hinsu\">@smit-hinsu</a><br>\nThank you for your reply.</p>\n<p>True. Total memory usage does not go above per_process_gpu_memory_fraction with UVM.</p>\n<p>In my experiments, it would be faster when <code>per_process_gpu_memory_fraction</code> is smaller.<br>\nSetting <code>per_process_gpu_memory_fraction</code> to a very high number would make training much much slower which is not applicable.</p>\n<p>That means I have to find the best <code>per_process_gpu_memory_fraction</code> with many times of trying and failing.</p>\n<p>Can you possibly make the total memory allocation(GPU+CPU) grow automatically when we need more memory?</p>\n<p>In addition, could you possibly suggest:</p>\n<ul>\n<li>Which memory(CPU or GPU memory) would be first used when we set <code>per_process_gpu_memory_fraction</code>  to a high number?\n<ul>\n<li>As I recognized, gpu memory would not be fully utilized when we set <code>per_process_gpu_memory_fraction</code>  to a high number</li>\n</ul>\n</li>\n<li>What is <code>allow_growth</code> doing?</li>\n</ul>\n<p>Thank you in advance!</p>", "body_text": "@smit-hinsu\nThank you for your reply.\nTrue. Total memory usage does not go above per_process_gpu_memory_fraction with UVM.\nIn my experiments, it would be faster when per_process_gpu_memory_fraction is smaller.\nSetting per_process_gpu_memory_fraction to a very high number would make training much much slower which is not applicable.\nThat means I have to find the best per_process_gpu_memory_fraction with many times of trying and failing.\nCan you possibly make the total memory allocation(GPU+CPU) grow automatically when we need more memory?\nIn addition, could you possibly suggest:\n\nWhich memory(CPU or GPU memory) would be first used when we set per_process_gpu_memory_fraction  to a high number?\n\nAs I recognized, gpu memory would not be fully utilized when we set per_process_gpu_memory_fraction  to a high number\n\n\nWhat is allow_growth doing?\n\nThank you in advance!", "body": "@smit-hinsu \r\nThank you for your reply. \r\n\r\nTrue. Total memory usage does not go above per_process_gpu_memory_fraction with UVM.\r\n\r\nIn my experiments, it would be faster when `per_process_gpu_memory_fraction` is smaller. \r\nSetting `per_process_gpu_memory_fraction` to a very high number would make training much much slower which is not applicable. \r\n\r\nThat means I have to find the best `per_process_gpu_memory_fraction` with many times of trying and failing. \r\n\r\nCan you possibly make the total memory allocation(GPU+CPU) grow automatically when we need more memory?\r\n\r\nIn addition, could you possibly suggest:\r\n- Which memory(CPU or GPU memory) would be first used when we set `per_process_gpu_memory_fraction`  to a high number?\r\n    - As I recognized, gpu memory would not be fully utilized when we set `per_process_gpu_memory_fraction`  to a high number\r\n- What is `allow_growth` doing?\r\n\r\nThank you in advance!"}