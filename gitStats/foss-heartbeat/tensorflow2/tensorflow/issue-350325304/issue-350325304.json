{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21600", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21600/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21600/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21600/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21600", "id": 350325304, "node_id": "MDU6SXNzdWUzNTAzMjUzMDQ=", "number": 21600, "title": "CUDA unified memory fail to increase on demand in r1.10 on PPC64le", "user": {"login": "alapha23", "id": 23239892, "node_id": "MDQ6VXNlcjIzMjM5ODky", "avatar_url": "https://avatars2.githubusercontent.com/u/23239892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alapha23", "html_url": "https://github.com/alapha23", "followers_url": "https://api.github.com/users/alapha23/followers", "following_url": "https://api.github.com/users/alapha23/following{/other_user}", "gists_url": "https://api.github.com/users/alapha23/gists{/gist_id}", "starred_url": "https://api.github.com/users/alapha23/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alapha23/subscriptions", "organizations_url": "https://api.github.com/users/alapha23/orgs", "repos_url": "https://api.github.com/users/alapha23/repos", "events_url": "https://api.github.com/users/alapha23/events{/privacy}", "received_events_url": "https://api.github.com/users/alapha23/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "smit-hinsu", "id": 1990079, "node_id": "MDQ6VXNlcjE5OTAwNzk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1990079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smit-hinsu", "html_url": "https://github.com/smit-hinsu", "followers_url": "https://api.github.com/users/smit-hinsu/followers", "following_url": "https://api.github.com/users/smit-hinsu/following{/other_user}", "gists_url": "https://api.github.com/users/smit-hinsu/gists{/gist_id}", "starred_url": "https://api.github.com/users/smit-hinsu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smit-hinsu/subscriptions", "organizations_url": "https://api.github.com/users/smit-hinsu/orgs", "repos_url": "https://api.github.com/users/smit-hinsu/repos", "events_url": "https://api.github.com/users/smit-hinsu/events{/privacy}", "received_events_url": "https://api.github.com/users/smit-hinsu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "smit-hinsu", "id": 1990079, "node_id": "MDQ6VXNlcjE5OTAwNzk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1990079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smit-hinsu", "html_url": "https://github.com/smit-hinsu", "followers_url": "https://api.github.com/users/smit-hinsu/followers", "following_url": "https://api.github.com/users/smit-hinsu/following{/other_user}", "gists_url": "https://api.github.com/users/smit-hinsu/gists{/gist_id}", "starred_url": "https://api.github.com/users/smit-hinsu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smit-hinsu/subscriptions", "organizations_url": "https://api.github.com/users/smit-hinsu/orgs", "repos_url": "https://api.github.com/users/smit-hinsu/repos", "events_url": "https://api.github.com/users/smit-hinsu/events{/privacy}", "received_events_url": "https://api.github.com/users/smit-hinsu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-08-14T08:16:24Z", "updated_at": "2018-10-02T02:07:04Z", "closed_at": "2018-10-02T02:07:04Z", "author_association": "NONE", "body_html": "<h3>Description</h3>\n<p>Based on the commit to <a href=\"https://github.com/tensorflow/tensorflow/commit/b1139814f91c5216eb5ff229ee7e1982e5f4e888?diff=split\">introduce an option to allocate CUDA unified memory</a>, theoretically we could expect a memory swap between CPU and GPU while running datasets with high memory demands.</p>\n<p>However, my tensorflow build still hits OOM.<br>\nI was training <a href=\"https://github.com/tensorflow/models/tree/master/official/resnet\">official resnet with cifar10 dataset</a>, with also a large batch ---- 48*128.</p>\n<p>I built another version without CUDA unified memory from commit <a href=\"https://github.com/tensorflow/tensorflow/commit/5aefa441276b5fdf2fec5e7cb282630c104f6f4a\">fixed ppc64le compile failure libpng</a>,<br>\nBoth tensorflow build hits OOM when I try to increase batch size from 47*128 to 48*128.<br>\nBased on this comparision, I was convinced that CUDA unified memory is not functioning in my build.</p>\n<p>However, I tried to set <code>per_process_gpu_memory_fraction</code> to 200 and pass the config to the <code>tf.Session</code>, it worked for much larger batches.<br>\nThen I realized that the UVM cannot grow on demand. Setting <code>allow_growth</code> to True won't help.</p>\n<p>In a word, can we make the CUDA unified memory allocation grow on demand?</p>\n<p>Could you possibly suggest a reason?<br>\nDid I miss out any configurations?</p>\n<h2>Thank you in advance!</h2>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:  no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:  Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:  source</li>\n<li><strong>TensorFlow version (use command below)</strong>:  r1.10</li>\n<li><strong>Python version</strong>:  3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:  0.15.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:  gcc (Ubuntu/IBM 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609</li>\n<li><strong>CUDA/cuDNN version</strong>:  9.2/7.1</li>\n<li><strong>GPU model and memory</strong>:   4 x Tesla P100, each has 16G memory; 1T RAM</li>\n</ul>", "body_text": "Description\nBased on the commit to introduce an option to allocate CUDA unified memory, theoretically we could expect a memory swap between CPU and GPU while running datasets with high memory demands.\nHowever, my tensorflow build still hits OOM.\nI was training official resnet with cifar10 dataset, with also a large batch ---- 48*128.\nI built another version without CUDA unified memory from commit fixed ppc64le compile failure libpng,\nBoth tensorflow build hits OOM when I try to increase batch size from 47*128 to 48*128.\nBased on this comparision, I was convinced that CUDA unified memory is not functioning in my build.\nHowever, I tried to set per_process_gpu_memory_fraction to 200 and pass the config to the tf.Session, it worked for much larger batches.\nThen I realized that the UVM cannot grow on demand. Setting allow_growth to True won't help.\nIn a word, can we make the CUDA unified memory allocation grow on demand?\nCould you possibly suggest a reason?\nDid I miss out any configurations?\nThank you in advance!\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):  no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary):  source\nTensorFlow version (use command below):  r1.10\nPython version:  3.5.2\nBazel version (if compiling from source):  0.15.0\nGCC/Compiler version (if compiling from source):  gcc (Ubuntu/IBM 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCUDA/cuDNN version:  9.2/7.1\nGPU model and memory:   4 x Tesla P100, each has 16G memory; 1T RAM", "body": "### Description\r\n\r\nBased on the commit to [introduce an option to allocate CUDA unified memory](https://github.com/tensorflow/tensorflow/commit/b1139814f91c5216eb5ff229ee7e1982e5f4e888?diff=split), theoretically we could expect a memory swap between CPU and GPU while running datasets with high memory demands. \r\n\r\nHowever, my tensorflow build still hits OOM. \r\nI was training [official resnet with cifar10 dataset](https://github.com/tensorflow/models/tree/master/official/resnet), with also a large batch ---- 48*128. \r\n\r\nI built another version without CUDA unified memory from commit [fixed ppc64le compile failure libpng](https://github.com/tensorflow/tensorflow/commit/5aefa441276b5fdf2fec5e7cb282630c104f6f4a), \r\nBoth tensorflow build hits OOM when I try to increase batch size from 47\\*128 to 48\\*128. \r\nBased on this comparision, I was convinced that CUDA unified memory is not functioning in my build. \r\n\r\nHowever, I tried to set `per_process_gpu_memory_fraction` to 200 and pass the config to the `tf.Session`, it worked for much larger batches. \r\nThen I realized that the UVM cannot grow on demand. Setting `allow_growth` to True won't help. \r\n\r\nIn a word, can we make the CUDA unified memory allocation grow on demand?\r\n\r\nCould you possibly suggest a reason?\r\nDid I miss out any configurations?\r\n\r\nThank you in advance!\r\n----------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:  source\r\n- **TensorFlow version (use command below)**:  r1.10\r\n- **Python version**:  3.5.2\r\n- **Bazel version (if compiling from source)**:  0.15.0\r\n- **GCC/Compiler version (if compiling from source)**:  gcc (Ubuntu/IBM 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**:  9.2/7.1\r\n- **GPU model and memory**:   4 x Tesla P100, each has 16G memory; 1T RAM"}