{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/426114028", "html_url": "https://github.com/tensorflow/tensorflow/issues/21600#issuecomment-426114028", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21600", "id": 426114028, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNjExNDAyOA==", "user": {"login": "smit-hinsu", "id": 1990079, "node_id": "MDQ6VXNlcjE5OTAwNzk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1990079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smit-hinsu", "html_url": "https://github.com/smit-hinsu", "followers_url": "https://api.github.com/users/smit-hinsu/followers", "following_url": "https://api.github.com/users/smit-hinsu/following{/other_user}", "gists_url": "https://api.github.com/users/smit-hinsu/gists{/gist_id}", "starred_url": "https://api.github.com/users/smit-hinsu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smit-hinsu/subscriptions", "organizations_url": "https://api.github.com/users/smit-hinsu/orgs", "repos_url": "https://api.github.com/users/smit-hinsu/repos", "events_url": "https://api.github.com/users/smit-hinsu/events{/privacy}", "received_events_url": "https://api.github.com/users/smit-hinsu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-02T01:12:38Z", "updated_at": "2018-10-02T01:12:38Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Did you try setting per_process_gpu_memory_fraction to a high number along with enabling allow_growth option?</p>\n<p>It should make the total memory allocation(GPU+CPU) to grow automatically when more memory is required as you requested. See allow_growth documentation at <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L36\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L36</a>.</p>\n<p>Memory is first allocated on CPU and migrated to GPU on demand. It is expected that training will become slower with unified memory as size of the working memory increases. It would generate many faults and stall the training process until memory is moved to GPU.</p>\n<p>See cuda unified memory documentation for more details:<br>\n<a href=\"https://devblogs.nvidia.com/maximizing-unified-memory-performance-cuda/\" rel=\"nofollow\">https://devblogs.nvidia.com/maximizing-unified-memory-performance-cuda/</a><br>\n<a href=\"http://on-demand.gputechconf.com/gtc/2017/presentation/s7285-nikolay-sakharnykh-unified-memory-on-pascal-and-volta.pdf\" rel=\"nofollow\">http://on-demand.gputechconf.com/gtc/2017/presentation/s7285-nikolay-sakharnykh-unified-memory-on-pascal-and-volta.pdf</a></p>\n<p>Hope this helps!</p>", "body_text": "Did you try setting per_process_gpu_memory_fraction to a high number along with enabling allow_growth option?\nIt should make the total memory allocation(GPU+CPU) to grow automatically when more memory is required as you requested. See allow_growth documentation at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L36.\nMemory is first allocated on CPU and migrated to GPU on demand. It is expected that training will become slower with unified memory as size of the working memory increases. It would generate many faults and stall the training process until memory is moved to GPU.\nSee cuda unified memory documentation for more details:\nhttps://devblogs.nvidia.com/maximizing-unified-memory-performance-cuda/\nhttp://on-demand.gputechconf.com/gtc/2017/presentation/s7285-nikolay-sakharnykh-unified-memory-on-pascal-and-volta.pdf\nHope this helps!", "body": "Did you try setting per_process_gpu_memory_fraction to a high number along with enabling allow_growth option?\r\n\r\nIt should make the total memory allocation(GPU+CPU) to grow automatically when more memory is required as you requested. See allow_growth documentation at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L36.\r\n\r\nMemory is first allocated on CPU and migrated to GPU on demand. It is expected that training will become slower with unified memory as size of the working memory increases. It would generate many faults and stall the training process until memory is moved to GPU.\r\n\r\nSee cuda unified memory documentation for more details:\r\nhttps://devblogs.nvidia.com/maximizing-unified-memory-performance-cuda/\r\nhttp://on-demand.gputechconf.com/gtc/2017/presentation/s7285-nikolay-sakharnykh-unified-memory-on-pascal-and-volta.pdf\r\n\r\nHope this helps!"}