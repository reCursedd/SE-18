{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/283615407", "html_url": "https://github.com/tensorflow/tensorflow/issues/7988#issuecomment-283615407", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7988", "id": 283615407, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MzYxNTQwNw==", "user": {"login": "Leishuyu-bupt", "id": 17901200, "node_id": "MDQ6VXNlcjE3OTAxMjAw", "avatar_url": "https://avatars1.githubusercontent.com/u/17901200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Leishuyu-bupt", "html_url": "https://github.com/Leishuyu-bupt", "followers_url": "https://api.github.com/users/Leishuyu-bupt/followers", "following_url": "https://api.github.com/users/Leishuyu-bupt/following{/other_user}", "gists_url": "https://api.github.com/users/Leishuyu-bupt/gists{/gist_id}", "starred_url": "https://api.github.com/users/Leishuyu-bupt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Leishuyu-bupt/subscriptions", "organizations_url": "https://api.github.com/users/Leishuyu-bupt/orgs", "repos_url": "https://api.github.com/users/Leishuyu-bupt/repos", "events_url": "https://api.github.com/users/Leishuyu-bupt/events{/privacy}", "received_events_url": "https://api.github.com/users/Leishuyu-bupt/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-02T10:25:40Z", "updated_at": "2017-03-02T10:25:40Z", "author_association": "NONE", "body_html": "<p>you can try to define tf.train.AdamOptimizer(0.01).minimize(cost) out of  tf.variable_scope() like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph<span class=\"pl-pds\">'</span></span>):\n    W<span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>W<span class=\"pl-pds\">'</span></span>,[<span class=\"pl-c1\">16</span>,<span class=\"pl-c1\">16</span>],<span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.truncated_normal_initializer(<span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.01</span>))\n    <span class=\"pl-c1\">...</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>your graph</span>\noptimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer.AdadeltaOptimizer(<span class=\"pl-c1\">0.01</span>).minimize(cost)</pre></div>", "body_text": "you can try to define tf.train.AdamOptimizer(0.01).minimize(cost) out of  tf.variable_scope() like this:\nwith tf.variable_scope('graph'):\n    W= tf.get_variable('W',[16,16],initializer=tf.truncated_normal_initializer(stddev=0.01))\n    ...#your graph\noptimizer = tf.train.AdamOptimizer.AdadeltaOptimizer(0.01).minimize(cost)", "body": "you can try to define tf.train.AdamOptimizer(0.01).minimize(cost) out of  tf.variable_scope() like this:\r\n```python\r\nwith tf.variable_scope('graph'):\r\n    W= tf.get_variable('W',[16,16],initializer=tf.truncated_normal_initializer(stddev=0.01))\r\n    ...#your graph\r\noptimizer = tf.train.AdamOptimizer.AdadeltaOptimizer(0.01).minimize(cost)\r\n```\r\n    "}