{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/418199267", "html_url": "https://github.com/tensorflow/tensorflow/issues/21920#issuecomment-418199267", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21920", "id": 418199267, "node_id": "MDEyOklzc3VlQ29tbWVudDQxODE5OTI2Nw==", "user": {"login": "georgesterpu", "id": 6018251, "node_id": "MDQ6VXNlcjYwMTgyNTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/6018251?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgesterpu", "html_url": "https://github.com/georgesterpu", "followers_url": "https://api.github.com/users/georgesterpu/followers", "following_url": "https://api.github.com/users/georgesterpu/following{/other_user}", "gists_url": "https://api.github.com/users/georgesterpu/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgesterpu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgesterpu/subscriptions", "organizations_url": "https://api.github.com/users/georgesterpu/orgs", "repos_url": "https://api.github.com/users/georgesterpu/repos", "events_url": "https://api.github.com/users/georgesterpu/events{/privacy}", "received_events_url": "https://api.github.com/users/georgesterpu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-03T22:16:06Z", "updated_at": "2018-09-03T22:17:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13504420\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/weiwancheng\">@weiwancheng</a>,</p>\n<p>From your post it is unclear whether you are using a well tested framework or your own. Could you please give us more details ?</p>\n<p>I have to assume that you are looking at the outputs (<code>predicted_ids</code>) of the <code>seq2seq.dynamic_decode</code> method, instantiated with the beam search decoder you mentioned, and that you translated the numerical ids back into symbols from your vocabulary. <code>dynamic_decode</code> will also return you the final sequence lengths. Looking at my own results, they are typically the lengths up to the first occurrence of the <code>eos</code> token (but I can also see that the decoder sometimes predict a few more extra characters when <code>eos</code> is fed back as input)). In your case, the lengths should be [9, 4, 4, 4, 4], and you can ignore the rest.</p>\n<p>Unfortunately I did not study the implementation of this function to help you further. I assume it depends a lot on the task that you are trying to solve, and also on the checkpoint you are loading (is it a well trained model ?). At least in my case, all the beams appear to be unique (just sampling a few of them, nothing rigorous). I have also seen that the inputs and the outputs of the decoder have to be properly formatted in order to obtain sound results (e.g. where you place the GO and EOS in the sequence, ensuring that the provided sequence length also includes these symbols). If it helps you, I will open-source our seq2seq ASR projects this week to see an example, yet the <code>nmt</code> tutorial might be an even better resource.</p>", "body_text": "Hello @weiwancheng,\nFrom your post it is unclear whether you are using a well tested framework or your own. Could you please give us more details ?\nI have to assume that you are looking at the outputs (predicted_ids) of the seq2seq.dynamic_decode method, instantiated with the beam search decoder you mentioned, and that you translated the numerical ids back into symbols from your vocabulary. dynamic_decode will also return you the final sequence lengths. Looking at my own results, they are typically the lengths up to the first occurrence of the eos token (but I can also see that the decoder sometimes predict a few more extra characters when eos is fed back as input)). In your case, the lengths should be [9, 4, 4, 4, 4], and you can ignore the rest.\nUnfortunately I did not study the implementation of this function to help you further. I assume it depends a lot on the task that you are trying to solve, and also on the checkpoint you are loading (is it a well trained model ?). At least in my case, all the beams appear to be unique (just sampling a few of them, nothing rigorous). I have also seen that the inputs and the outputs of the decoder have to be properly formatted in order to obtain sound results (e.g. where you place the GO and EOS in the sequence, ensuring that the provided sequence length also includes these symbols). If it helps you, I will open-source our seq2seq ASR projects this week to see an example, yet the nmt tutorial might be an even better resource.", "body": "Hello @weiwancheng,\r\n\r\nFrom your post it is unclear whether you are using a well tested framework or your own. Could you please give us more details ?\r\n\r\nI have to assume that you are looking at the outputs (`predicted_ids`) of the `seq2seq.dynamic_decode` method, instantiated with the beam search decoder you mentioned, and that you translated the numerical ids back into symbols from your vocabulary. `dynamic_decode` will also return you the final sequence lengths. Looking at my own results, they are typically the lengths up to the first occurrence of the `eos` token (but I can also see that the decoder sometimes predict a few more extra characters when `eos` is fed back as input)). In your case, the lengths should be [9, 4, 4, 4, 4], and you can ignore the rest.\r\n\r\nUnfortunately I did not study the implementation of this function to help you further. I assume it depends a lot on the task that you are trying to solve, and also on the checkpoint you are loading (is it a well trained model ?). At least in my case, all the beams appear to be unique (just sampling a few of them, nothing rigorous). I have also seen that the inputs and the outputs of the decoder have to be properly formatted in order to obtain sound results (e.g. where you place the GO and EOS in the sequence, ensuring that the provided sequence length also includes these symbols). If it helps you, I will open-source our seq2seq ASR projects this week to see an example, yet the `nmt` tutorial might be an even better resource.\r\n\r\n\r\n"}