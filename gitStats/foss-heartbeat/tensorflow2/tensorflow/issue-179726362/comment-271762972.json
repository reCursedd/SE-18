{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/271762972", "html_url": "https://github.com/tensorflow/tensorflow/issues/4620#issuecomment-271762972", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4620", "id": 271762972, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MTc2Mjk3Mg==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-11T02:45:35Z", "updated_at": "2017-01-11T02:46:37Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7966776\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pswpswpsw\">@pswpswpsw</a> The user specifies where to locate weights and training data and TensorFlow adds transfers as necessary. If you place your training data and weights on GPU, and all ops have GPU implementation, then all the data will stay on GPU. You can use timeline profiling to see where ops are executed and when CPU/GPU transfers are taking place -- <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"146958443\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1824\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1824/hovercard?comment_id=225754659&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-225754659\">#1824 (comment)</a></p>", "body_text": "@pswpswpsw The user specifies where to locate weights and training data and TensorFlow adds transfers as necessary. If you place your training data and weights on GPU, and all ops have GPU implementation, then all the data will stay on GPU. You can use timeline profiling to see where ops are executed and when CPU/GPU transfers are taking place -- #1824 (comment)", "body": "@pswpswpsw The user specifies where to locate weights and training data and TensorFlow adds transfers as necessary. If you place your training data and weights on GPU, and all ops have GPU implementation, then all the data will stay on GPU. You can use timeline profiling to see where ops are executed and when CPU/GPU transfers are taking place -- https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-225754659"}