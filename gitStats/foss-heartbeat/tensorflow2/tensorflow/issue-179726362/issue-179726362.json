{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4620", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4620/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4620/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4620/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4620", "id": 179726362, "node_id": "MDU6SXNzdWUxNzk3MjYzNjI=", "number": 4620, "title": "new feature in cuda8.0 release", "user": {"login": "fayeshine", "id": 11470826, "node_id": "MDQ6VXNlcjExNDcwODI2", "avatar_url": "https://avatars0.githubusercontent.com/u/11470826?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fayeshine", "html_url": "https://github.com/fayeshine", "followers_url": "https://api.github.com/users/fayeshine/followers", "following_url": "https://api.github.com/users/fayeshine/following{/other_user}", "gists_url": "https://api.github.com/users/fayeshine/gists{/gist_id}", "starred_url": "https://api.github.com/users/fayeshine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fayeshine/subscriptions", "organizations_url": "https://api.github.com/users/fayeshine/orgs", "repos_url": "https://api.github.com/users/fayeshine/repos", "events_url": "https://api.github.com/users/fayeshine/events{/privacy}", "received_events_url": "https://api.github.com/users/fayeshine/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-09-28T09:43:39Z", "updated_at": "2017-01-27T19:24:46Z", "closed_at": "2017-01-27T19:24:46Z", "author_association": "CONTRIBUTOR", "body_html": "<pre><code>New in CUDA 8\nPascal Architecture Support\nEnhance performance out-of-the-box on Pascal GPUs\nSimplify programming using Unified Memory including support for large datasets, concurrent data access and atomics\nOptimize Unified Memory performance using new data migration APIs\nIncrease throughput at ultra-fast speeds using NVLINK, new high-speed interconnect\nDeveloper Tools\nIdentify latent system-level bottlenecks using critical path analysis\nImprove productivity up to 2x with NVCC\nTune OpenACC applications and overall host code using new profiling extensions\nLibraries\nAccelerate graph analytics algorithms with nvGRAPH\nSpeed-up Deep Learning applications using native support for FP16 and INT8, support for batch operation in cuBLAS\n</code></pre>\n<p>Do we have anything to improve in these places<br>\n1.Simplify programming using Unified Memory including support for large datasets, concurrent data access and atomics<br>\n2.Optimize Unified Memory performance using new data migration APIs<br>\n3.Increase throughput at ultra-fast speeds using NVLINK, new high-speed interconnect<br>\n4.Speed-up Deep Learning applications using native support for FP16 and INT8, support for batch operation in cuBLAS</p>", "body_text": "New in CUDA 8\nPascal Architecture Support\nEnhance performance out-of-the-box on Pascal GPUs\nSimplify programming using Unified Memory including support for large datasets, concurrent data access and atomics\nOptimize Unified Memory performance using new data migration APIs\nIncrease throughput at ultra-fast speeds using NVLINK, new high-speed interconnect\nDeveloper Tools\nIdentify latent system-level bottlenecks using critical path analysis\nImprove productivity up to 2x with NVCC\nTune OpenACC applications and overall host code using new profiling extensions\nLibraries\nAccelerate graph analytics algorithms with nvGRAPH\nSpeed-up Deep Learning applications using native support for FP16 and INT8, support for batch operation in cuBLAS\n\nDo we have anything to improve in these places\n1.Simplify programming using Unified Memory including support for large datasets, concurrent data access and atomics\n2.Optimize Unified Memory performance using new data migration APIs\n3.Increase throughput at ultra-fast speeds using NVLINK, new high-speed interconnect\n4.Speed-up Deep Learning applications using native support for FP16 and INT8, support for batch operation in cuBLAS", "body": "```\nNew in CUDA 8\nPascal Architecture Support\nEnhance performance out-of-the-box on Pascal GPUs\nSimplify programming using Unified Memory including support for large datasets, concurrent data access and atomics\nOptimize Unified Memory performance using new data migration APIs\nIncrease throughput at ultra-fast speeds using NVLINK, new high-speed interconnect\nDeveloper Tools\nIdentify latent system-level bottlenecks using critical path analysis\nImprove productivity up to 2x with NVCC\nTune OpenACC applications and overall host code using new profiling extensions\nLibraries\nAccelerate graph analytics algorithms with nvGRAPH\nSpeed-up Deep Learning applications using native support for FP16 and INT8, support for batch operation in cuBLAS\n```\n\nDo we have anything to improve in these places\n1.Simplify programming using Unified Memory including support for large datasets, concurrent data access and atomics\n2.Optimize Unified Memory performance using new data migration APIs\n3.Increase throughput at ultra-fast speeds using NVLINK, new high-speed interconnect\n4.Speed-up Deep Learning applications using native support for FP16 and INT8, support for batch operation in cuBLAS\n"}