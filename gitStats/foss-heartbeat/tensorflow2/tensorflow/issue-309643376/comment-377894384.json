{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/377894384", "html_url": "https://github.com/tensorflow/tensorflow/issues/18080#issuecomment-377894384", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18080", "id": 377894384, "node_id": "MDEyOklzc3VlQ29tbWVudDM3Nzg5NDM4NA==", "user": {"login": "balavenkatesh3322", "id": 24771457, "node_id": "MDQ6VXNlcjI0NzcxNDU3", "avatar_url": "https://avatars3.githubusercontent.com/u/24771457?v=4", "gravatar_id": "", "url": "https://api.github.com/users/balavenkatesh3322", "html_url": "https://github.com/balavenkatesh3322", "followers_url": "https://api.github.com/users/balavenkatesh3322/followers", "following_url": "https://api.github.com/users/balavenkatesh3322/following{/other_user}", "gists_url": "https://api.github.com/users/balavenkatesh3322/gists{/gist_id}", "starred_url": "https://api.github.com/users/balavenkatesh3322/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/balavenkatesh3322/subscriptions", "organizations_url": "https://api.github.com/users/balavenkatesh3322/orgs", "repos_url": "https://api.github.com/users/balavenkatesh3322/repos", "events_url": "https://api.github.com/users/balavenkatesh3322/events{/privacy}", "received_events_url": "https://api.github.com/users/balavenkatesh3322/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-02T09:32:45Z", "updated_at": "2018-04-02T09:32:45Z", "author_association": "NONE", "body_html": "<p>Below is my code.please look into that and give some clarification about two model loading</p>\n<pre><code>`# What model to download.\nMODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\nMODEL_FILE = MODEL_NAME + '.tar.gz'\nDOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n\n# Path to frozen detection graph. This is the actual model that is used for the object detection.\n#PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\nPATH_TO_CKPT = 'screwdriver_graph/frozen_inference_graph.pb'\n\n\n# List of the strings that is used to add correct label for each box.\n#PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\nPATH_TO_LABELS = os.path.join('data', 'screwdriver_label.pbtxt')\n\nNUM_CLASSES = 1\n#NUM_CLASSES = 90\n\n\n# ## Download Model\n\n#if not os.path.exists(MODEL_NAME + '/frozen_inference_graph.pb'):\nif not os.path.exists('screwdriver_graph/frozen_inference_graph.pb'):\n\tprint ('Downloading the model')\n\topener = urllib.request.URLopener()\n\topener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n\ttar_file = tarfile.open(MODEL_FILE)\n\tfor file in tar_file.getmembers():\n\t  file_name = os.path.basename(file.name)\n\t  if 'frozen_inference_graph.pb' in file_name:\n\t    tar_file.extract(file, os.getcwd())\n\tprint ('Download complete')\nelse:\n\tprint ('Model already exists')\n\n# ## Load a (frozen) Tensorflow model into memory.\n\ndetection_graph = tf.Graph()\nwith detection_graph.as_default():\n  od_graph_def = tf.GraphDef()\n  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n    serialized_graph = fid.read()\n    od_graph_def.ParseFromString(serialized_graph)\n    tf.import_graph_def(od_graph_def, name='')\n\n\n# ## Loading label map\n# Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\n\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)\n\n#intializing the web camera device\n\nimport cv2\ncap = cv2.VideoCapture(1)\n\n\n\n# Running the tensorflow session\nwith detection_graph.as_default():\n  with tf.Session(graph=detection_graph) as sess:\n   ret = True\n   while (ret):\n      ret,image_np = cap.read()\n      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n      image_np_expanded = np.expand_dims(image_np, axis=0)\n      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n      # Each box represents a part of the image where a particular object was detected.\n      boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n      # Each score represent how level of confidence for each of the objects.\n      # Score is shown on the result image, together with the class label.\n      scores = detection_graph.get_tensor_by_name('detection_scores:0')\n      classes = detection_graph.get_tensor_by_name('detection_classes:0')\n      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n      # Actual detection.\n      (boxes, scores, classes, num_detections) = sess.run(\n          [boxes, scores, classes, num_detections],\n          feed_dict={image_tensor: image_np_expanded})\n      # Visualization of the results of a detection.\n      vis_util.visualize_boxes_and_labels_on_image_array(\n          image_np,\n          np.squeeze(boxes),\n          np.squeeze(classes).astype(np.int32),\n          np.squeeze(scores),\n          category_index,\n          use_normalized_coordinates=True,\n          line_thickness=8)\n#      plt.figure(figsize=IMAGE_SIZE)\n#      plt.imshow(image_np)\n      #cv2.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,2)\n      cv2.imshow('Detected Tools',cv2.resize(image_np,(1000,850)))\n      #cv2.imshow('Tools Name',cv2.resize(cv2.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,2),(100,150)))\n      if cv2.waitKey(25) &amp; 0xFF == ord('q'):\n          cv2.destroyAllWindows()\n          cap.release()\n          break\n\n\n`\n</code></pre>\n<p>Thanks for helping</p>", "body_text": "Below is my code.please look into that and give some clarification about two model loading\n`# What model to download.\nMODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\nMODEL_FILE = MODEL_NAME + '.tar.gz'\nDOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n\n# Path to frozen detection graph. This is the actual model that is used for the object detection.\n#PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\nPATH_TO_CKPT = 'screwdriver_graph/frozen_inference_graph.pb'\n\n\n# List of the strings that is used to add correct label for each box.\n#PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\nPATH_TO_LABELS = os.path.join('data', 'screwdriver_label.pbtxt')\n\nNUM_CLASSES = 1\n#NUM_CLASSES = 90\n\n\n# ## Download Model\n\n#if not os.path.exists(MODEL_NAME + '/frozen_inference_graph.pb'):\nif not os.path.exists('screwdriver_graph/frozen_inference_graph.pb'):\n\tprint ('Downloading the model')\n\topener = urllib.request.URLopener()\n\topener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n\ttar_file = tarfile.open(MODEL_FILE)\n\tfor file in tar_file.getmembers():\n\t  file_name = os.path.basename(file.name)\n\t  if 'frozen_inference_graph.pb' in file_name:\n\t    tar_file.extract(file, os.getcwd())\n\tprint ('Download complete')\nelse:\n\tprint ('Model already exists')\n\n# ## Load a (frozen) Tensorflow model into memory.\n\ndetection_graph = tf.Graph()\nwith detection_graph.as_default():\n  od_graph_def = tf.GraphDef()\n  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n    serialized_graph = fid.read()\n    od_graph_def.ParseFromString(serialized_graph)\n    tf.import_graph_def(od_graph_def, name='')\n\n\n# ## Loading label map\n# Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\n\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)\n\n#intializing the web camera device\n\nimport cv2\ncap = cv2.VideoCapture(1)\n\n\n\n# Running the tensorflow session\nwith detection_graph.as_default():\n  with tf.Session(graph=detection_graph) as sess:\n   ret = True\n   while (ret):\n      ret,image_np = cap.read()\n      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n      image_np_expanded = np.expand_dims(image_np, axis=0)\n      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n      # Each box represents a part of the image where a particular object was detected.\n      boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n      # Each score represent how level of confidence for each of the objects.\n      # Score is shown on the result image, together with the class label.\n      scores = detection_graph.get_tensor_by_name('detection_scores:0')\n      classes = detection_graph.get_tensor_by_name('detection_classes:0')\n      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n      # Actual detection.\n      (boxes, scores, classes, num_detections) = sess.run(\n          [boxes, scores, classes, num_detections],\n          feed_dict={image_tensor: image_np_expanded})\n      # Visualization of the results of a detection.\n      vis_util.visualize_boxes_and_labels_on_image_array(\n          image_np,\n          np.squeeze(boxes),\n          np.squeeze(classes).astype(np.int32),\n          np.squeeze(scores),\n          category_index,\n          use_normalized_coordinates=True,\n          line_thickness=8)\n#      plt.figure(figsize=IMAGE_SIZE)\n#      plt.imshow(image_np)\n      #cv2.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,2)\n      cv2.imshow('Detected Tools',cv2.resize(image_np,(1000,850)))\n      #cv2.imshow('Tools Name',cv2.resize(cv2.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,2),(100,150)))\n      if cv2.waitKey(25) & 0xFF == ord('q'):\n          cv2.destroyAllWindows()\n          cap.release()\n          break\n\n\n`\n\nThanks for helping", "body": "Below is my code.please look into that and give some clarification about two model loading\r\n\r\n```\r\n`# What model to download.\r\nMODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\r\nMODEL_FILE = MODEL_NAME + '.tar.gz'\r\nDOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\r\n\r\n# Path to frozen detection graph. This is the actual model that is used for the object detection.\r\n#PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\r\nPATH_TO_CKPT = 'screwdriver_graph/frozen_inference_graph.pb'\r\n\r\n\r\n# List of the strings that is used to add correct label for each box.\r\n#PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\r\nPATH_TO_LABELS = os.path.join('data', 'screwdriver_label.pbtxt')\r\n\r\nNUM_CLASSES = 1\r\n#NUM_CLASSES = 90\r\n\r\n\r\n# ## Download Model\r\n\r\n#if not os.path.exists(MODEL_NAME + '/frozen_inference_graph.pb'):\r\nif not os.path.exists('screwdriver_graph/frozen_inference_graph.pb'):\r\n\tprint ('Downloading the model')\r\n\topener = urllib.request.URLopener()\r\n\topener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\r\n\ttar_file = tarfile.open(MODEL_FILE)\r\n\tfor file in tar_file.getmembers():\r\n\t  file_name = os.path.basename(file.name)\r\n\t  if 'frozen_inference_graph.pb' in file_name:\r\n\t    tar_file.extract(file, os.getcwd())\r\n\tprint ('Download complete')\r\nelse:\r\n\tprint ('Model already exists')\r\n\r\n# ## Load a (frozen) Tensorflow model into memory.\r\n\r\ndetection_graph = tf.Graph()\r\nwith detection_graph.as_default():\r\n  od_graph_def = tf.GraphDef()\r\n  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\r\n    serialized_graph = fid.read()\r\n    od_graph_def.ParseFromString(serialized_graph)\r\n    tf.import_graph_def(od_graph_def, name='')\r\n\r\n\r\n# ## Loading label map\r\n# Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\r\n\r\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\r\ncategory_index = label_map_util.create_category_index(categories)\r\n\r\n#intializing the web camera device\r\n\r\nimport cv2\r\ncap = cv2.VideoCapture(1)\r\n\r\n\r\n\r\n# Running the tensorflow session\r\nwith detection_graph.as_default():\r\n  with tf.Session(graph=detection_graph) as sess:\r\n   ret = True\r\n   while (ret):\r\n      ret,image_np = cap.read()\r\n      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\r\n      image_np_expanded = np.expand_dims(image_np, axis=0)\r\n      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\r\n      # Each box represents a part of the image where a particular object was detected.\r\n      boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\r\n      # Each score represent how level of confidence for each of the objects.\r\n      # Score is shown on the result image, together with the class label.\r\n      scores = detection_graph.get_tensor_by_name('detection_scores:0')\r\n      classes = detection_graph.get_tensor_by_name('detection_classes:0')\r\n      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\r\n      # Actual detection.\r\n      (boxes, scores, classes, num_detections) = sess.run(\r\n          [boxes, scores, classes, num_detections],\r\n          feed_dict={image_tensor: image_np_expanded})\r\n      # Visualization of the results of a detection.\r\n      vis_util.visualize_boxes_and_labels_on_image_array(\r\n          image_np,\r\n          np.squeeze(boxes),\r\n          np.squeeze(classes).astype(np.int32),\r\n          np.squeeze(scores),\r\n          category_index,\r\n          use_normalized_coordinates=True,\r\n          line_thickness=8)\r\n#      plt.figure(figsize=IMAGE_SIZE)\r\n#      plt.imshow(image_np)\r\n      #cv2.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,2)\r\n      cv2.imshow('Detected Tools',cv2.resize(image_np,(1000,850)))\r\n      #cv2.imshow('Tools Name',cv2.resize(cv2.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,2),(100,150)))\r\n      if cv2.waitKey(25) & 0xFF == ord('q'):\r\n          cv2.destroyAllWindows()\r\n          cap.release()\r\n          break\r\n\r\n\r\n`\r\n```\r\n\r\nThanks for helping "}