{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/230931282", "html_url": "https://github.com/tensorflow/tensorflow/issues/3148#issuecomment-230931282", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3148", "id": 230931282, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMDkzMTI4Mg==", "user": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-06T22:50:55Z", "updated_at": "2016-07-06T22:50:55Z", "author_association": "MEMBER", "body_html": "<p>This type of question is best asked on StackOverflow. I don't believe this is a bug. Your arange() version has a mean of 50ish. That means the learning rate provided to gradient descent will be too high for stable convergence. You can fix this by<br>\nx_data = np.arange(100).astype(np.float32) / 100<br>\nor if you don't want to change your data you'll need to reduce learning rate to .0001 and take 40000ish iterations.</p>", "body_text": "This type of question is best asked on StackOverflow. I don't believe this is a bug. Your arange() version has a mean of 50ish. That means the learning rate provided to gradient descent will be too high for stable convergence. You can fix this by\nx_data = np.arange(100).astype(np.float32) / 100\nor if you don't want to change your data you'll need to reduce learning rate to .0001 and take 40000ish iterations.", "body": "This type of question is best asked on StackOverflow. I don't believe this is a bug. Your arange() version has a mean of 50ish. That means the learning rate provided to gradient descent will be too high for stable convergence. You can fix this by \nx_data = np.arange(100).astype(np.float32) / 100\nor if you don't want to change your data you'll need to reduce learning rate to .0001 and take 40000ish iterations.\n"}