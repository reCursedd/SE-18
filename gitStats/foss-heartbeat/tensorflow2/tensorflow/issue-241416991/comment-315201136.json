{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/315201136", "html_url": "https://github.com/tensorflow/tensorflow/issues/11365#issuecomment-315201136", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11365", "id": 315201136, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTIwMTEzNg==", "user": {"login": "jagthebeetle", "id": 6564473, "node_id": "MDQ6VXNlcjY1NjQ0NzM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6564473?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jagthebeetle", "html_url": "https://github.com/jagthebeetle", "followers_url": "https://api.github.com/users/jagthebeetle/followers", "following_url": "https://api.github.com/users/jagthebeetle/following{/other_user}", "gists_url": "https://api.github.com/users/jagthebeetle/gists{/gist_id}", "starred_url": "https://api.github.com/users/jagthebeetle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jagthebeetle/subscriptions", "organizations_url": "https://api.github.com/users/jagthebeetle/orgs", "repos_url": "https://api.github.com/users/jagthebeetle/repos", "events_url": "https://api.github.com/users/jagthebeetle/events{/privacy}", "received_events_url": "https://api.github.com/users/jagthebeetle/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-13T21:01:12Z", "updated_at": "2017-07-13T21:01:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p>My training results have not shown the difference to be that big either, but the edge cases worried me.</p>\n<p>The difference at the first step (step1) of decoding is between:</p>\n<pre><code>state1 = cell((context1=attn(state0)), state0) # RNNSearch\ncontext1 = attn((state1 = cell(context0, state0))) # AttentionWrapper\n</code></pre>\n<p>(assuming, as in GRU cells, that states and outputs are the same)</p>\n<p>On further inspection, the two turn out to be the same if I provide the initial state for AttentionWrapper as:</p>\n<pre><code>AttentionWrapperState(\n    attention=attn(_cell.zero_state()) # score with bahdanau and calculate context from alignments\n    cell_state=_cell.zero_state())\n</code></pre>\n<p>Leaving the note for posterity. Thanks for the clarification!</p>", "body_text": "My training results have not shown the difference to be that big either, but the edge cases worried me.\nThe difference at the first step (step1) of decoding is between:\nstate1 = cell((context1=attn(state0)), state0) # RNNSearch\ncontext1 = attn((state1 = cell(context0, state0))) # AttentionWrapper\n\n(assuming, as in GRU cells, that states and outputs are the same)\nOn further inspection, the two turn out to be the same if I provide the initial state for AttentionWrapper as:\nAttentionWrapperState(\n    attention=attn(_cell.zero_state()) # score with bahdanau and calculate context from alignments\n    cell_state=_cell.zero_state())\n\nLeaving the note for posterity. Thanks for the clarification!", "body": "My training results have not shown the difference to be that big either, but the edge cases worried me.\r\n\r\nThe difference at the first step (step1) of decoding is between:\r\n```\r\nstate1 = cell((context1=attn(state0)), state0) # RNNSearch\r\ncontext1 = attn((state1 = cell(context0, state0))) # AttentionWrapper\r\n```\r\n(assuming, as in GRU cells, that states and outputs are the same)\r\n\r\nOn further inspection, the two turn out to be the same if I provide the initial state for AttentionWrapper as:\r\n```\r\nAttentionWrapperState(\r\n    attention=attn(_cell.zero_state()) # score with bahdanau and calculate context from alignments\r\n    cell_state=_cell.zero_state())\r\n```\r\nLeaving the note for posterity. Thanks for the clarification!"}