{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/348438151", "html_url": "https://github.com/tensorflow/tensorflow/issues/14993#issuecomment-348438151", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14993", "id": 348438151, "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODQzODE1MQ==", "user": {"login": "zh794390558", "id": 3038472, "node_id": "MDQ6VXNlcjMwMzg0NzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3038472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zh794390558", "html_url": "https://github.com/zh794390558", "followers_url": "https://api.github.com/users/zh794390558/followers", "following_url": "https://api.github.com/users/zh794390558/following{/other_user}", "gists_url": "https://api.github.com/users/zh794390558/gists{/gist_id}", "starred_url": "https://api.github.com/users/zh794390558/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zh794390558/subscriptions", "organizations_url": "https://api.github.com/users/zh794390558/orgs", "repos_url": "https://api.github.com/users/zh794390558/repos", "events_url": "https://api.github.com/users/zh794390558/events{/privacy}", "received_events_url": "https://api.github.com/users/zh794390558/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-01T08:52:38Z", "updated_at": "2017-12-01T08:55:15Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16824702\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/caisq\">@caisq</a> my OS  is centos, and the code is too large which is attention-based seq-2-seq model.   The <a href=\"https://github.com/tensorflow/nmt\">https://github.com/tensorflow/nmt</a>  repo is same to my.</p>\n<p>snippet usage code is blew all other snippet request.</p>\n<pre><code>if hp.debug:\n     hooks.append(tf_debug.LocalCLIDebugHook(dump_root='/lustre/atlas/zhanghui/debug'))\n \n with tf.train.MonitoredTrainingSession(\n         hooks=hooks,\n         scaffold=scaffold,\n         checkpoint_dir=checkpoint_dir,\n         save_checkpoint_secs=600,\n         save_summaries_steps=50,\n         config=config) as sess:\n\n</code></pre>", "body_text": "@caisq my OS  is centos, and the code is too large which is attention-based seq-2-seq model.   The https://github.com/tensorflow/nmt  repo is same to my.\nsnippet usage code is blew all other snippet request.\nif hp.debug:\n     hooks.append(tf_debug.LocalCLIDebugHook(dump_root='/lustre/atlas/zhanghui/debug'))\n \n with tf.train.MonitoredTrainingSession(\n         hooks=hooks,\n         scaffold=scaffold,\n         checkpoint_dir=checkpoint_dir,\n         save_checkpoint_secs=600,\n         save_summaries_steps=50,\n         config=config) as sess:", "body": "@caisq my OS  is centos, and the code is too large which is attention-based seq-2-seq model.   The https://github.com/tensorflow/nmt  repo is same to my. \r\n\r\n\r\nsnippet usage code is blew all other snippet request.\r\n```\r\nif hp.debug:\r\n     hooks.append(tf_debug.LocalCLIDebugHook(dump_root='/lustre/atlas/zhanghui/debug'))\r\n \r\n with tf.train.MonitoredTrainingSession(\r\n         hooks=hooks,\r\n         scaffold=scaffold,\r\n         checkpoint_dir=checkpoint_dir,\r\n         save_checkpoint_secs=600,\r\n         save_summaries_steps=50,\r\n         config=config) as sess:\r\n\r\n```"}