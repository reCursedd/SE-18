{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15914", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15914/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15914/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15914/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15914", "id": 286497173, "node_id": "MDU6SXNzdWUyODY0OTcxNzM=", "number": 15914, "title": "How to know my loss function does not have numerical problems?", "user": {"login": "JoaoLages", "id": 17574157, "node_id": "MDQ6VXNlcjE3NTc0MTU3", "avatar_url": "https://avatars0.githubusercontent.com/u/17574157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JoaoLages", "html_url": "https://github.com/JoaoLages", "followers_url": "https://api.github.com/users/JoaoLages/followers", "following_url": "https://api.github.com/users/JoaoLages/following{/other_user}", "gists_url": "https://api.github.com/users/JoaoLages/gists{/gist_id}", "starred_url": "https://api.github.com/users/JoaoLages/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JoaoLages/subscriptions", "organizations_url": "https://api.github.com/users/JoaoLages/orgs", "repos_url": "https://api.github.com/users/JoaoLages/repos", "events_url": "https://api.github.com/users/JoaoLages/events{/privacy}", "received_events_url": "https://api.github.com/users/JoaoLages/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-06T16:36:28Z", "updated_at": "2018-01-07T01:05:33Z", "closed_at": "2018-01-07T01:05:33Z", "author_association": "NONE", "body_html": "<p>I wrote the following loss function that I post below. How do I know that I don't have any kind of numerical issues with it? (because something tells me that I do)</p>\n<pre><code>def gather_cols(params, indices, name=None):\n    \"\"\"Gather columns of a 2D tensor.\n\n    Args:\n        params: A 2D tensor.\n        indices: A 1D tensor. Must be one of the following types: ``int32``, ``int64``.\n        name: A name for the operation (optional).\n\n    Returns:\n        A 2D Tensor. Has the same type as ``params``.\n    \"\"\"\n    with tf.op_scope([params, indices], name, \"gather_cols\") as scope:\n        # Check input\n        params = tf.convert_to_tensor(params, name=\"params\")\n        indices = tf.convert_to_tensor(indices, name=\"indices\")\n        try:\n            params.get_shape().assert_has_rank(2)\n        except ValueError:\n            raise ValueError('\\'params\\' must be 2D.')\n        try:\n            indices.get_shape().assert_has_rank(1)\n        except ValueError:\n            raise ValueError('\\'params\\' must be 1D.')\n\n        # Define op\n        p_shape = tf.shape(params)\n        p_flat = tf.reshape(params, [-1])\n        i_flat = tf.reshape(tf.reshape(tf.range(0, p_shape[0]) * p_shape[1],\n                                       [-1, 1]) + indices, [-1])\n        return tf.reshape(tf.gather(p_flat, i_flat),\n                          [p_shape[0], -1])\n\n\ndef custom_binary_crossentropy(y_true, y_pred):\n    # Assumes y_pred are probabilities and that y_true has actually 2 labels inside\n    # Calculate: gain(y1, y2) * log(p) + gain(y2, y1) * log(1 - p)\n    # gain(x1, x2) = (2 ^ x1 - 1) / ((2 ^ x1 - 1) + (2 ^ x2 - 1))\n\n    # Gather y1 and y2 first\n    y1 = gather_cols(y_true, [0])\n    y2 = gather_cols(y_true, [1])\n\n    # Get 2^y - 1\n    y1_g = tf.subtract(tf.pow(tf.fill(tf.shape(y1), 2.0), y1), tf.fill(tf.shape(y1), 1.0))\n    y2_g = tf.subtract(tf.pow(tf.fill(tf.shape(y2), 2.0), y1), tf.fill(tf.shape(y2), 1.0))\n\n    # Get gains\n    gain1 = tf.div(y1_g, tf.add(y1_g, y2_g))\n    gain2 = tf.div(y2_g, tf.add(y1_g, y2_g))\n\n    # Get logs\n    log1 = tf.log(y_pred)\n    log2 = tf.log(tf.subtract(tf.fill(tf.shape(y_pred), 1.0), y_pred))\n\n    return -K.mean(tf.add(tf.multiply(gain1, log1), tf.multiply(gain2, log2)))\n</code></pre>", "body_text": "I wrote the following loss function that I post below. How do I know that I don't have any kind of numerical issues with it? (because something tells me that I do)\ndef gather_cols(params, indices, name=None):\n    \"\"\"Gather columns of a 2D tensor.\n\n    Args:\n        params: A 2D tensor.\n        indices: A 1D tensor. Must be one of the following types: ``int32``, ``int64``.\n        name: A name for the operation (optional).\n\n    Returns:\n        A 2D Tensor. Has the same type as ``params``.\n    \"\"\"\n    with tf.op_scope([params, indices], name, \"gather_cols\") as scope:\n        # Check input\n        params = tf.convert_to_tensor(params, name=\"params\")\n        indices = tf.convert_to_tensor(indices, name=\"indices\")\n        try:\n            params.get_shape().assert_has_rank(2)\n        except ValueError:\n            raise ValueError('\\'params\\' must be 2D.')\n        try:\n            indices.get_shape().assert_has_rank(1)\n        except ValueError:\n            raise ValueError('\\'params\\' must be 1D.')\n\n        # Define op\n        p_shape = tf.shape(params)\n        p_flat = tf.reshape(params, [-1])\n        i_flat = tf.reshape(tf.reshape(tf.range(0, p_shape[0]) * p_shape[1],\n                                       [-1, 1]) + indices, [-1])\n        return tf.reshape(tf.gather(p_flat, i_flat),\n                          [p_shape[0], -1])\n\n\ndef custom_binary_crossentropy(y_true, y_pred):\n    # Assumes y_pred are probabilities and that y_true has actually 2 labels inside\n    # Calculate: gain(y1, y2) * log(p) + gain(y2, y1) * log(1 - p)\n    # gain(x1, x2) = (2 ^ x1 - 1) / ((2 ^ x1 - 1) + (2 ^ x2 - 1))\n\n    # Gather y1 and y2 first\n    y1 = gather_cols(y_true, [0])\n    y2 = gather_cols(y_true, [1])\n\n    # Get 2^y - 1\n    y1_g = tf.subtract(tf.pow(tf.fill(tf.shape(y1), 2.0), y1), tf.fill(tf.shape(y1), 1.0))\n    y2_g = tf.subtract(tf.pow(tf.fill(tf.shape(y2), 2.0), y1), tf.fill(tf.shape(y2), 1.0))\n\n    # Get gains\n    gain1 = tf.div(y1_g, tf.add(y1_g, y2_g))\n    gain2 = tf.div(y2_g, tf.add(y1_g, y2_g))\n\n    # Get logs\n    log1 = tf.log(y_pred)\n    log2 = tf.log(tf.subtract(tf.fill(tf.shape(y_pred), 1.0), y_pred))\n\n    return -K.mean(tf.add(tf.multiply(gain1, log1), tf.multiply(gain2, log2)))", "body": "I wrote the following loss function that I post below. How do I know that I don't have any kind of numerical issues with it? (because something tells me that I do)\r\n\r\n```\r\ndef gather_cols(params, indices, name=None):\r\n    \"\"\"Gather columns of a 2D tensor.\r\n\r\n    Args:\r\n        params: A 2D tensor.\r\n        indices: A 1D tensor. Must be one of the following types: ``int32``, ``int64``.\r\n        name: A name for the operation (optional).\r\n\r\n    Returns:\r\n        A 2D Tensor. Has the same type as ``params``.\r\n    \"\"\"\r\n    with tf.op_scope([params, indices], name, \"gather_cols\") as scope:\r\n        # Check input\r\n        params = tf.convert_to_tensor(params, name=\"params\")\r\n        indices = tf.convert_to_tensor(indices, name=\"indices\")\r\n        try:\r\n            params.get_shape().assert_has_rank(2)\r\n        except ValueError:\r\n            raise ValueError('\\'params\\' must be 2D.')\r\n        try:\r\n            indices.get_shape().assert_has_rank(1)\r\n        except ValueError:\r\n            raise ValueError('\\'params\\' must be 1D.')\r\n\r\n        # Define op\r\n        p_shape = tf.shape(params)\r\n        p_flat = tf.reshape(params, [-1])\r\n        i_flat = tf.reshape(tf.reshape(tf.range(0, p_shape[0]) * p_shape[1],\r\n                                       [-1, 1]) + indices, [-1])\r\n        return tf.reshape(tf.gather(p_flat, i_flat),\r\n                          [p_shape[0], -1])\r\n\r\n\r\ndef custom_binary_crossentropy(y_true, y_pred):\r\n    # Assumes y_pred are probabilities and that y_true has actually 2 labels inside\r\n    # Calculate: gain(y1, y2) * log(p) + gain(y2, y1) * log(1 - p)\r\n    # gain(x1, x2) = (2 ^ x1 - 1) / ((2 ^ x1 - 1) + (2 ^ x2 - 1))\r\n\r\n    # Gather y1 and y2 first\r\n    y1 = gather_cols(y_true, [0])\r\n    y2 = gather_cols(y_true, [1])\r\n\r\n    # Get 2^y - 1\r\n    y1_g = tf.subtract(tf.pow(tf.fill(tf.shape(y1), 2.0), y1), tf.fill(tf.shape(y1), 1.0))\r\n    y2_g = tf.subtract(tf.pow(tf.fill(tf.shape(y2), 2.0), y1), tf.fill(tf.shape(y2), 1.0))\r\n\r\n    # Get gains\r\n    gain1 = tf.div(y1_g, tf.add(y1_g, y2_g))\r\n    gain2 = tf.div(y2_g, tf.add(y1_g, y2_g))\r\n\r\n    # Get logs\r\n    log1 = tf.log(y_pred)\r\n    log2 = tf.log(tf.subtract(tf.fill(tf.shape(y_pred), 1.0), y_pred))\r\n\r\n    return -K.mean(tf.add(tf.multiply(gain1, log1), tf.multiply(gain2, log2)))\r\n```"}