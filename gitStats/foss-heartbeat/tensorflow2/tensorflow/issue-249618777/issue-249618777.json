{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12215", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12215/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12215/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12215/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12215", "id": 249618777, "node_id": "MDU6SXNzdWUyNDk2MTg3Nzc=", "number": 12215, "title": "CTC loss with dynamic length", "user": {"login": "githubharald", "id": 15148095, "node_id": "MDQ6VXNlcjE1MTQ4MDk1", "avatar_url": "https://avatars2.githubusercontent.com/u/15148095?v=4", "gravatar_id": "", "url": "https://api.github.com/users/githubharald", "html_url": "https://github.com/githubharald", "followers_url": "https://api.github.com/users/githubharald/followers", "following_url": "https://api.github.com/users/githubharald/following{/other_user}", "gists_url": "https://api.github.com/users/githubharald/gists{/gist_id}", "starred_url": "https://api.github.com/users/githubharald/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/githubharald/subscriptions", "organizations_url": "https://api.github.com/users/githubharald/orgs", "repos_url": "https://api.github.com/users/githubharald/repos", "events_url": "https://api.github.com/users/githubharald/events{/privacy}", "received_events_url": "https://api.github.com/users/githubharald/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2017-08-11T12:19:12Z", "updated_at": "2018-05-17T22:26:43Z", "closed_at": "2018-05-17T22:26:43Z", "author_association": "NONE", "body_html": "<p>This is a very specific questions, I'm afraid nobody on stackoverflow will ever answer this. I will copy the text from there, the original question can be found there:<br>\n<a href=\"https://stackoverflow.com/questions/45568266/tensorflow-ctc-loss-ctc-merge-repeated-parameter\" rel=\"nofollow\">https://stackoverflow.com/questions/45568266/tensorflow-ctc-loss-ctc-merge-repeated-parameter</a></p>\n<p>And I'm not 100% sure if this behaviour is wanted or a bug (I think its the former one but I'm really not sure).</p>\n<p>I'm using Tensorflow 1.0 and its CTC loss [1]. When training, I sometimes get the \"No valid path found.\" warning (which harms learning). It is not due to a high learning rate as sometimes reported by other Tensorflow users.</p>\n<p>After analyzing it a bit, I found the pattern that causes this warning:</p>\n<ul>\n<li>feeding an input sequence into the ctc_loss with length seqLen</li>\n<li>feeding a label with labelLen characters</li>\n<li>label has numRepeatedChars repeated chars in it, where I count \"ab\" as 0, \"aa\" as 1, \"aaa\" as 2 and so on</li>\n<li>warning occurs, when: seqLen - labelLen &lt; numRepeatedChars</li>\n</ul>\n<p>Three examples:</p>\n<ul>\n<li>Ex.1: label=\"abb\", len(label)=3, len(inputSequence)=3 =&gt; (3-3=0)&lt;1 is true --&gt; warning</li>\n<li>Ex.2: label=\"abb\", len(label)=3, len(inputSequence)=4 =&gt; (4-3=1)&lt;1 is false --&gt; no warning</li>\n<li>Ex.3: label=\"bbb\", len(label)=3, len(inputSequence)=4 =&gt; (4-3=1)&lt;2 is true --&gt; warning</li>\n</ul>\n<p>When I now set the ctc_loss parameter ctc_merge_repeated=False, then the warning disappears.</p>\n<p>Three questions:</p>\n<ul>\n<li>Q1: why is there a warning when repeated chars occur? I thought, as long as the input sequence is not shorter than the target labelling, there is no problem. And when repeated chars are merged in the label, then it gets even shorter, therefore the condition that the input sequence is not shorter still holds.</li>\n<li>Q2: why does the ctc_loss in its default settings produce this warning? Repeated chars are common in the domains CTCs are used such as handwritten text recognition (HTR)</li>\n<li>Q3: what settings should I use when doing HTR? Of course labels can have repeated chars. Therefore ctc_merge_repeated=False would make sense. Any suggestions?</li>\n</ul>\n<p>Python program to reproduce warning:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef createGraph():\n    tinputs=tf.placeholder(tf.float32, [100, 1, 65]) # max 100 time steps, 1 batch element, 64+1 classes\n    tlabels=tf.SparseTensor(tf.placeholder(tf.int64, shape=[None,2]) , tf.placeholder(tf.int32,[None]), tf.placeholder(tf.int64,[2])) # labels\n    tseqLen=tf.placeholder(tf.int32, [None]) # list of sequence length in batch\n    tloss=tf.reduce_mean(tf.nn.ctc_loss(labels=tlabels, inputs=tinputs, sequence_length=tseqLen, ctc_merge_repeated=True)) # ctc loss\n    return (tinputs, tlabels, tseqLen, tloss)\n\ndef getNextBatch(nc): # next batch with given number of chars in label\n    indices=[[0,i] for i in range(nc)]\n    values=[i%65 for i in range(nc)]\n    values[0]=0\n    values[1]=0 # TODO: (un)comment this to trigger warning\n    shape=[1, nc]\n    labels=tf.SparseTensorValue(indices, values, shape)\n    seqLen=[nc]\n    inputs=np.random.rand(100, 1, 65)\n    return (labels, inputs, seqLen) \n\n\n(tinputs, tlabels, tseqLen, tloss)=createGraph()\n\nsess=tf.Session()\nsess.run(tf.global_variables_initializer())\n\nnc=3 # number of chars in label\nprint('next batch with 1 element has label len='+str(nc))\n(labels, inputs, seqLen)=getNextBatch(nc)\nres=sess.run([tloss], { tlabels: labels, tinputs:inputs, tseqLen:seqLen } )\n</code></pre>\n<p>This is the C++ Tensorflow code [2] where the warning comes from:</p>\n<pre><code>// It is possible that no valid path is found if the activations for the\n// targets are zero.\nif (log_p_z_x == kLogZero) {\n    LOG(WARNING) &lt;&lt; \"No valid path found.\";\n    dy_b = y;\n    return;\n}\n</code></pre>\n<p>[1] <a href=\"https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/ctc_loss\" rel=\"nofollow\">https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/ctc_loss</a><br>\n[2] <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_loss_calculator.cc\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_loss_calculator.cc</a></p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: costum</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.0.0-rc2-15-g47bba63-dirty, 1.0.0</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: -</li>\n<li><strong>CUDA/cuDNN version</strong>: [problem also on CPU]</li>\n<li><strong>GPU model and memory</strong>: [problem also on CPU]</li>\n<li><strong>Exact command to reproduce</strong>: see code above</li>\n</ul>", "body_text": "This is a very specific questions, I'm afraid nobody on stackoverflow will ever answer this. I will copy the text from there, the original question can be found there:\nhttps://stackoverflow.com/questions/45568266/tensorflow-ctc-loss-ctc-merge-repeated-parameter\nAnd I'm not 100% sure if this behaviour is wanted or a bug (I think its the former one but I'm really not sure).\nI'm using Tensorflow 1.0 and its CTC loss [1]. When training, I sometimes get the \"No valid path found.\" warning (which harms learning). It is not due to a high learning rate as sometimes reported by other Tensorflow users.\nAfter analyzing it a bit, I found the pattern that causes this warning:\n\nfeeding an input sequence into the ctc_loss with length seqLen\nfeeding a label with labelLen characters\nlabel has numRepeatedChars repeated chars in it, where I count \"ab\" as 0, \"aa\" as 1, \"aaa\" as 2 and so on\nwarning occurs, when: seqLen - labelLen < numRepeatedChars\n\nThree examples:\n\nEx.1: label=\"abb\", len(label)=3, len(inputSequence)=3 => (3-3=0)<1 is true --> warning\nEx.2: label=\"abb\", len(label)=3, len(inputSequence)=4 => (4-3=1)<1 is false --> no warning\nEx.3: label=\"bbb\", len(label)=3, len(inputSequence)=4 => (4-3=1)<2 is true --> warning\n\nWhen I now set the ctc_loss parameter ctc_merge_repeated=False, then the warning disappears.\nThree questions:\n\nQ1: why is there a warning when repeated chars occur? I thought, as long as the input sequence is not shorter than the target labelling, there is no problem. And when repeated chars are merged in the label, then it gets even shorter, therefore the condition that the input sequence is not shorter still holds.\nQ2: why does the ctc_loss in its default settings produce this warning? Repeated chars are common in the domains CTCs are used such as handwritten text recognition (HTR)\nQ3: what settings should I use when doing HTR? Of course labels can have repeated chars. Therefore ctc_merge_repeated=False would make sense. Any suggestions?\n\nPython program to reproduce warning:\nimport tensorflow as tf\nimport numpy as np\n\ndef createGraph():\n    tinputs=tf.placeholder(tf.float32, [100, 1, 65]) # max 100 time steps, 1 batch element, 64+1 classes\n    tlabels=tf.SparseTensor(tf.placeholder(tf.int64, shape=[None,2]) , tf.placeholder(tf.int32,[None]), tf.placeholder(tf.int64,[2])) # labels\n    tseqLen=tf.placeholder(tf.int32, [None]) # list of sequence length in batch\n    tloss=tf.reduce_mean(tf.nn.ctc_loss(labels=tlabels, inputs=tinputs, sequence_length=tseqLen, ctc_merge_repeated=True)) # ctc loss\n    return (tinputs, tlabels, tseqLen, tloss)\n\ndef getNextBatch(nc): # next batch with given number of chars in label\n    indices=[[0,i] for i in range(nc)]\n    values=[i%65 for i in range(nc)]\n    values[0]=0\n    values[1]=0 # TODO: (un)comment this to trigger warning\n    shape=[1, nc]\n    labels=tf.SparseTensorValue(indices, values, shape)\n    seqLen=[nc]\n    inputs=np.random.rand(100, 1, 65)\n    return (labels, inputs, seqLen) \n\n\n(tinputs, tlabels, tseqLen, tloss)=createGraph()\n\nsess=tf.Session()\nsess.run(tf.global_variables_initializer())\n\nnc=3 # number of chars in label\nprint('next batch with 1 element has label len='+str(nc))\n(labels, inputs, seqLen)=getNextBatch(nc)\nres=sess.run([tloss], { tlabels: labels, tinputs:inputs, tseqLen:seqLen } )\n\nThis is the C++ Tensorflow code [2] where the warning comes from:\n// It is possible that no valid path is found if the activations for the\n// targets are zero.\nif (log_p_z_x == kLogZero) {\n    LOG(WARNING) << \"No valid path found.\";\n    dy_b = y;\n    return;\n}\n\n[1] https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/ctc_loss\n[2] https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_loss_calculator.cc\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): costum\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.0.0-rc2-15-g47bba63-dirty, 1.0.0\nPython version: 3.5.2\nBazel version (if compiling from source): -\nCUDA/cuDNN version: [problem also on CPU]\nGPU model and memory: [problem also on CPU]\nExact command to reproduce: see code above", "body": "This is a very specific questions, I'm afraid nobody on stackoverflow will ever answer this. I will copy the text from there, the original question can be found there: \r\nhttps://stackoverflow.com/questions/45568266/tensorflow-ctc-loss-ctc-merge-repeated-parameter\r\n\r\nAnd I'm not 100% sure if this behaviour is wanted or a bug (I think its the former one but I'm really not sure).\r\n\r\n\r\nI'm using Tensorflow 1.0 and its CTC loss [1]. When training, I sometimes get the \"No valid path found.\" warning (which harms learning). It is not due to a high learning rate as sometimes reported by other Tensorflow users.\r\n\r\nAfter analyzing it a bit, I found the pattern that causes this warning:\r\n - feeding an input sequence into the ctc_loss with length seqLen\r\n - feeding a label with labelLen characters\r\n - label has numRepeatedChars repeated chars in it, where I count \"ab\" as 0, \"aa\" as 1, \"aaa\" as 2 and so on \r\n - warning occurs, when: seqLen - labelLen < numRepeatedChars\r\n\r\n\r\nThree examples:\r\n\r\n - Ex.1: label=\"abb\", len(label)=3, len(inputSequence)=3 => (3-3=0)<1 is true --> warning\r\n - Ex.2: label=\"abb\", len(label)=3, len(inputSequence)=4 => (4-3=1)<1 is false --> no warning\r\n - Ex.3: label=\"bbb\", len(label)=3, len(inputSequence)=4 => (4-3=1)<2 is true --> warning\r\n\r\nWhen I now set the ctc_loss parameter ctc_merge_repeated=False, then the warning disappears.\r\n\r\nThree questions:\r\n\r\n - Q1: why is there a warning when repeated chars occur? I thought, as long as the input sequence is not shorter than the target labelling, there is no problem. And when repeated chars are merged in the label, then it gets even shorter, therefore the condition that the input sequence is not shorter still holds.\r\n - Q2: why does the ctc_loss in its default settings produce this warning? Repeated chars are common in the domains CTCs are used such as handwritten text recognition (HTR)\r\n - Q3: what settings should I use when doing HTR? Of course labels can have repeated chars. Therefore ctc_merge_repeated=False would make sense. Any suggestions?\r\n\r\nPython program to reproduce warning:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef createGraph():\r\n    tinputs=tf.placeholder(tf.float32, [100, 1, 65]) # max 100 time steps, 1 batch element, 64+1 classes\r\n    tlabels=tf.SparseTensor(tf.placeholder(tf.int64, shape=[None,2]) , tf.placeholder(tf.int32,[None]), tf.placeholder(tf.int64,[2])) # labels\r\n    tseqLen=tf.placeholder(tf.int32, [None]) # list of sequence length in batch\r\n    tloss=tf.reduce_mean(tf.nn.ctc_loss(labels=tlabels, inputs=tinputs, sequence_length=tseqLen, ctc_merge_repeated=True)) # ctc loss\r\n    return (tinputs, tlabels, tseqLen, tloss)\r\n\r\ndef getNextBatch(nc): # next batch with given number of chars in label\r\n    indices=[[0,i] for i in range(nc)]\r\n    values=[i%65 for i in range(nc)]\r\n    values[0]=0\r\n    values[1]=0 # TODO: (un)comment this to trigger warning\r\n    shape=[1, nc]\r\n    labels=tf.SparseTensorValue(indices, values, shape)\r\n    seqLen=[nc]\r\n    inputs=np.random.rand(100, 1, 65)\r\n    return (labels, inputs, seqLen) \r\n\r\n\r\n(tinputs, tlabels, tseqLen, tloss)=createGraph()\r\n\r\nsess=tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\nnc=3 # number of chars in label\r\nprint('next batch with 1 element has label len='+str(nc))\r\n(labels, inputs, seqLen)=getNextBatch(nc)\r\nres=sess.run([tloss], { tlabels: labels, tinputs:inputs, tseqLen:seqLen } )\r\n```\r\n\r\nThis is the C++ Tensorflow code [2] where the warning comes from:\r\n```\r\n// It is possible that no valid path is found if the activations for the\r\n// targets are zero.\r\nif (log_p_z_x == kLogZero) {\r\n    LOG(WARNING) << \"No valid path found.\";\r\n    dy_b = y;\r\n    return;\r\n}\r\n```\r\n\r\n[1] https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/ctc_loss\r\n[2] https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_loss_calculator.cc\r\n\r\n\r\n-----\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: costum\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.0.0-rc2-15-g47bba63-dirty, 1.0.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: [problem also on CPU]\r\n- **GPU model and memory**: [problem also on CPU]\r\n- **Exact command to reproduce**: see code above\r\n"}