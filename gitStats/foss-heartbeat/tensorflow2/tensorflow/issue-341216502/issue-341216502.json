{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20796", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20796/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20796/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20796/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20796", "id": 341216502, "node_id": "MDU6SXNzdWUzNDEyMTY1MDI=", "number": 20796, "title": "TypeError: 'EagerTensor' object cannot be interpreted as an integer", "user": {"login": "jock4319", "id": 5265959, "node_id": "MDQ6VXNlcjUyNjU5NTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5265959?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jock4319", "html_url": "https://github.com/jock4319", "followers_url": "https://api.github.com/users/jock4319/followers", "following_url": "https://api.github.com/users/jock4319/following{/other_user}", "gists_url": "https://api.github.com/users/jock4319/gists{/gist_id}", "starred_url": "https://api.github.com/users/jock4319/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jock4319/subscriptions", "organizations_url": "https://api.github.com/users/jock4319/orgs", "repos_url": "https://api.github.com/users/jock4319/repos", "events_url": "https://api.github.com/users/jock4319/events{/privacy}", "received_events_url": "https://api.github.com/users/jock4319/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-07-14T07:22:20Z", "updated_at": "2018-09-17T06:25:05Z", "closed_at": "2018-09-17T06:25:05Z", "author_association": "NONE", "body_html": "<p>Running automatic_differentiation.ipynb on Colab, and there's a error.</p>\n<pre><code>def f(x, y):\n  output = 1\n  for i in range(y):\n    output = tf.multiply(output, x)\n  return output\n\ndef g(x, y):\n  # Return the gradient of `f` with respect to it's first parameter\n  return tfe.gradients_function(f)(x, y)[0]\n\nassert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x\nassert g(3.0, 2).numpy() == 6.0   # And its gradient will be 2 * x\nassert f(4.0, 3).numpy() == 64.0  # f(x, 3) is essentially x * x * x\nassert g(4.0, 3).numpy() == 48.0  # And its gradient will be 3 * x * x\n</code></pre>\n<hr>\n<p>TypeError                                 Traceback (most recent call last)<br>\n in ()<br>\n10<br>\n11 assert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x<br>\n---&gt; 12 assert g(3.0, 2).numpy() == 6.0   # And its gradient will be 2 * x<br>\n13 assert f(4.0, 3).numpy() == 64.0  # f(x, 3) is essentially x * x * x<br>\n14 assert g(4.0, 3).numpy() == 48.0  # And its gradient will be 3 * x * x</p>\n<p> in g(x, y)<br>\n7 def g(x, y):<br>\n8   # Return the gradient of <code>f</code> with respect to it's first parameter<br>\n----&gt; 9   return tfe.gradients_function(f)(x, y)[0]<br>\n10<br>\n11 assert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)<br>\n367     \"\"\"Computes the gradient of the decorated function.\"\"\"<br>\n368<br>\n--&gt; 369     _, grad = val_and_grad_function(f, params=params)(*args, **kwds)<br>\n370     return grad<br>\n371</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)<br>\n466       raise ValueError(\"Functions to be differentiated cannot \"<br>\n467                        \"receive keyword arguments.\")<br>\n--&gt; 468     val, vjp = make_vjp(f, params)(*args, **kwds)<br>\n469     return val, vjp(dy=dy)<br>\n470</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)<br>\n522         sources.append(args[i])<br>\n523         tape.watch(args[i])<br>\n--&gt; 524       result = f(*args)<br>\n525       if result is None:<br>\n526         raise ValueError(\"Cannot differentiate a function that returns None; \"</p>\n<p> in f(x, y)<br>\n1 def f(x, y):<br>\n2   output = 1<br>\n----&gt; 3   for i in range(y):<br>\n4     output = tf.multiply(output, x)<br>\n5   return output</p>\n<p>TypeError: 'EagerTensor' object cannot be interpreted as an integer</p>", "body_text": "Running automatic_differentiation.ipynb on Colab, and there's a error.\ndef f(x, y):\n  output = 1\n  for i in range(y):\n    output = tf.multiply(output, x)\n  return output\n\ndef g(x, y):\n  # Return the gradient of `f` with respect to it's first parameter\n  return tfe.gradients_function(f)(x, y)[0]\n\nassert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x\nassert g(3.0, 2).numpy() == 6.0   # And its gradient will be 2 * x\nassert f(4.0, 3).numpy() == 64.0  # f(x, 3) is essentially x * x * x\nassert g(4.0, 3).numpy() == 48.0  # And its gradient will be 3 * x * x\n\n\nTypeError                                 Traceback (most recent call last)\n in ()\n10\n11 assert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x\n---> 12 assert g(3.0, 2).numpy() == 6.0   # And its gradient will be 2 * x\n13 assert f(4.0, 3).numpy() == 64.0  # f(x, 3) is essentially x * x * x\n14 assert g(4.0, 3).numpy() == 48.0  # And its gradient will be 3 * x * x\n in g(x, y)\n7 def g(x, y):\n8   # Return the gradient of f with respect to it's first parameter\n----> 9   return tfe.gradients_function(f)(x, y)[0]\n10\n11 assert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\n367     \"\"\"Computes the gradient of the decorated function.\"\"\"\n368\n--> 369     _, grad = val_and_grad_function(f, params=params)(*args, **kwds)\n370     return grad\n371\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\n466       raise ValueError(\"Functions to be differentiated cannot \"\n467                        \"receive keyword arguments.\")\n--> 468     val, vjp = make_vjp(f, params)(*args, **kwds)\n469     return val, vjp(dy=dy)\n470\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\n522         sources.append(args[i])\n523         tape.watch(args[i])\n--> 524       result = f(*args)\n525       if result is None:\n526         raise ValueError(\"Cannot differentiate a function that returns None; \"\n in f(x, y)\n1 def f(x, y):\n2   output = 1\n----> 3   for i in range(y):\n4     output = tf.multiply(output, x)\n5   return output\nTypeError: 'EagerTensor' object cannot be interpreted as an integer", "body": "Running automatic_differentiation.ipynb on Colab, and there's a error.\r\n\r\n```\r\ndef f(x, y):\r\n  output = 1\r\n  for i in range(y):\r\n    output = tf.multiply(output, x)\r\n  return output\r\n\r\ndef g(x, y):\r\n  # Return the gradient of `f` with respect to it's first parameter\r\n  return tfe.gradients_function(f)(x, y)[0]\r\n\r\nassert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x\r\nassert g(3.0, 2).numpy() == 6.0   # And its gradient will be 2 * x\r\nassert f(4.0, 3).numpy() == 64.0  # f(x, 3) is essentially x * x * x\r\nassert g(4.0, 3).numpy() == 48.0  # And its gradient will be 3 * x * x\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-21-2c4ab5c7a8b8> in <module>()\r\n     10 \r\n     11 assert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x\r\n---> 12 assert g(3.0, 2).numpy() == 6.0   # And its gradient will be 2 * x\r\n     13 assert f(4.0, 3).numpy() == 64.0  # f(x, 3) is essentially x * x * x\r\n     14 assert g(4.0, 3).numpy() == 48.0  # And its gradient will be 3 * x * x\r\n\r\n<ipython-input-21-2c4ab5c7a8b8> in g(x, y)\r\n      7 def g(x, y):\r\n      8   # Return the gradient of `f` with respect to it's first parameter\r\n----> 9   return tfe.gradients_function(f)(x, y)[0]\r\n     10 \r\n     11 assert f(3.0, 2).numpy() == 9.0   # f(x, 2) is essentially x * x\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\r\n    367     \"\"\"Computes the gradient of the decorated function.\"\"\"\r\n    368 \r\n--> 369     _, grad = val_and_grad_function(f, params=params)(*args, **kwds)\r\n    370     return grad\r\n    371 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\r\n    466       raise ValueError(\"Functions to be differentiated cannot \"\r\n    467                        \"receive keyword arguments.\")\r\n--> 468     val, vjp = make_vjp(f, params)(*args, **kwds)\r\n    469     return val, vjp(dy=dy)\r\n    470 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\r\n    522         sources.append(args[i])\r\n    523         tape.watch(args[i])\r\n--> 524       result = f(*args)\r\n    525       if result is None:\r\n    526         raise ValueError(\"Cannot differentiate a function that returns None; \"\r\n\r\n<ipython-input-21-2c4ab5c7a8b8> in f(x, y)\r\n      1 def f(x, y):\r\n      2   output = 1\r\n----> 3   for i in range(y):\r\n      4     output = tf.multiply(output, x)\r\n      5   return output\r\n\r\nTypeError: 'EagerTensor' object cannot be interpreted as an integer"}