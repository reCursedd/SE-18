{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/209006049", "html_url": "https://github.com/tensorflow/tensorflow/issues/1875#issuecomment-209006049", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1875", "id": 209006049, "node_id": "MDEyOklzc3VlQ29tbWVudDIwOTAwNjA0OQ==", "user": {"login": "alexggmatthews", "id": 6596998, "node_id": "MDQ6VXNlcjY1OTY5OTg=", "avatar_url": "https://avatars2.githubusercontent.com/u/6596998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexggmatthews", "html_url": "https://github.com/alexggmatthews", "followers_url": "https://api.github.com/users/alexggmatthews/followers", "following_url": "https://api.github.com/users/alexggmatthews/following{/other_user}", "gists_url": "https://api.github.com/users/alexggmatthews/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexggmatthews/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexggmatthews/subscriptions", "organizations_url": "https://api.github.com/users/alexggmatthews/orgs", "repos_url": "https://api.github.com/users/alexggmatthews/repos", "events_url": "https://api.github.com/users/alexggmatthews/events{/privacy}", "received_events_url": "https://api.github.com/users/alexggmatthews/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-12T16:56:39Z", "updated_at": "2016-04-12T16:56:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi Geoffrey,<br>\nThanks for your quick response. I looked here for inspiration on the code:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/linalg_grad.py#L79\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/linalg_grad.py#L79</a></p>\n<p>You need to account for the fact that the matrix will change from being upper triangular to lower triangular and vice versa when you take the adjoint but that's fine.</p>\n<p>I then played with adding the MatrixTriangularSolve op here:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/linalg_grad_test.py#L133\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/linalg_grad_test.py#L133</a></p>\n<p>and using np.tril to give it lower triangular random inputs.  I'm not sure I did this in a very tidy way. But in any case I was getting big differences between the finite differences and the backprop. Perhaps as you suggest random lower triangular matrices are very ill conditioned.</p>\n<p>I could submit as a PR with help needed if you like? I thought if you guys where doing this anyway that it might be more efficient not to tread on your toes.</p>", "body_text": "Hi Geoffrey,\nThanks for your quick response. I looked here for inspiration on the code:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/linalg_grad.py#L79\nYou need to account for the fact that the matrix will change from being upper triangular to lower triangular and vice versa when you take the adjoint but that's fine.\nI then played with adding the MatrixTriangularSolve op here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/linalg_grad_test.py#L133\nand using np.tril to give it lower triangular random inputs.  I'm not sure I did this in a very tidy way. But in any case I was getting big differences between the finite differences and the backprop. Perhaps as you suggest random lower triangular matrices are very ill conditioned.\nI could submit as a PR with help needed if you like? I thought if you guys where doing this anyway that it might be more efficient not to tread on your toes.", "body": "Hi Geoffrey,\nThanks for your quick response. I looked here for inspiration on the code:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/linalg_grad.py#L79\n\nYou need to account for the fact that the matrix will change from being upper triangular to lower triangular and vice versa when you take the adjoint but that's fine. \n\nI then played with adding the MatrixTriangularSolve op here:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/linalg_grad_test.py#L133\n\nand using np.tril to give it lower triangular random inputs.  I'm not sure I did this in a very tidy way. But in any case I was getting big differences between the finite differences and the backprop. Perhaps as you suggest random lower triangular matrices are very ill conditioned. \n\nI could submit as a PR with help needed if you like? I thought if you guys where doing this anyway that it might be more efficient not to tread on your toes.\n"}