{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10146", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10146/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10146/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10146/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10146", "id": 230852468, "node_id": "MDU6SXNzdWUyMzA4NTI0Njg=", "number": 10146, "title": "CUDA_ERROR_INVALID_DEVICE", "user": {"login": "kemaswill", "id": 1715587, "node_id": "MDQ6VXNlcjE3MTU1ODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1715587?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kemaswill", "html_url": "https://github.com/kemaswill", "followers_url": "https://api.github.com/users/kemaswill/followers", "following_url": "https://api.github.com/users/kemaswill/following{/other_user}", "gists_url": "https://api.github.com/users/kemaswill/gists{/gist_id}", "starred_url": "https://api.github.com/users/kemaswill/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kemaswill/subscriptions", "organizations_url": "https://api.github.com/users/kemaswill/orgs", "repos_url": "https://api.github.com/users/kemaswill/repos", "events_url": "https://api.github.com/users/kemaswill/events{/privacy}", "received_events_url": "https://api.github.com/users/kemaswill/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-23T21:28:41Z", "updated_at": "2017-09-08T04:56:03Z", "closed_at": "2017-09-08T04:56:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Got the following error when trying to run tensorflow on GPU:</p>\n<blockquote>\n<p>E tensorflow/core/common_runtime/direct_session.cc:137] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE<br>\nTraceback (most recent call last):<br>\nFile \"main.py\", line 200, in <br>\nmodel = PNN2(**pnn2_params)<br>\nFile \"/homes/jwpan/Github/DL_MultiField_Categorical_Data/python/models.py\", line 767, in <strong>init</strong><br>\nself.sess = tf.Session(config=config)<br>\nFile \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1176, in <strong>init</strong><br>\nsuper(Session, self).<strong>init</strong>(target, graph, config=config)<br>\nFile \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 552, in <strong>init</strong><br>\nself._session = tf_session.TF_NewDeprecatedSession(opts, status)<br>\nFile \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/contextlib.py\", line 24, in <strong>exit</strong><br>\nself.gen.next()<br>\nFile \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status<br>\npywrap_tensorflow.TF_GetCode(status))<br>\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.</p>\n</blockquote>\n<p>Have tried to set CUDA_VISIBLE_DEVICES but still does not work.<br>\nHere is the output of nvidia-smi, just wonder why all GPUs are \"Off\"?</p>\n<blockquote>\n<p>Tue May 23 21:28:08 2017<br>\n+------------------------------------------------------+<br>\n| NVIDIA-SMI 352.39     Driver Version: 352.39         |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Tesla K80           On   | 0000:06:00.0     Off |                    0 |<br>\n| N/A   37C    P0    62W / 149W |  10983MiB / 11519MiB |      0%   E. Process |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  Tesla K80           On   | 0000:07:00.0     Off |                    0 |<br>\n| N/A   57C    P0    73W / 149W |  10983MiB / 11519MiB |      0%   E. Process |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   2  Tesla K80           On   | 0000:0A:00.0     Off |                    0 |<br>\n| N/A   38C    P0    60W / 149W |  10983MiB / 11519MiB |      0%   E. Process |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   3  Tesla K80           On   | 0000:0B:00.0     Off |                    0 |<br>\n| N/A   54C    P0    73W / 149W |  10983MiB / 11519MiB |      0%   E. Process |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   4  Tesla K80           On   | 0000:0E:00.0     Off |                    0 |<br>\n| N/A   37C    P0    61W / 149W |  10983MiB / 11519MiB |      0%   E. Process |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   5  Tesla K80           On   | 0000:0F:00.0     Off |                    0 |<br>\n| N/A   59C    P0    75W / 149W |  10983MiB / 11519MiB |      0%   E. Process |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   6  Tesla K80           On   | 0000:12:00.0     Off |                    0 |<br>\n| N/A   39C    P0    61W / 149W |  10983MiB / 11519MiB |      0%   E. Process |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   7  Tesla K80           On   | 0000:13:00.0     Off |                    0 |<br>\n| N/A   62C    P0    74W / 149W |  10983MiB / 11519MiB |      0%   E. Process |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID  Type  Process name                               Usage      |<br>\n|=============================================================================|<br>\n|    0     24673    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |<br>\n|    1     16902    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |<br>\n|    2     27468    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |<br>\n|    3     11704    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |<br>\n|    4     13475    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |<br>\n|    5     16115    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |<br>\n|    6      2095    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |<br>\n|    7     23351    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n</blockquote>", "body_text": "Got the following error when trying to run tensorflow on GPU:\n\nE tensorflow/core/common_runtime/direct_session.cc:137] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE\nTraceback (most recent call last):\nFile \"main.py\", line 200, in \nmodel = PNN2(**pnn2_params)\nFile \"/homes/jwpan/Github/DL_MultiField_Categorical_Data/python/models.py\", line 767, in init\nself.sess = tf.Session(config=config)\nFile \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1176, in init\nsuper(Session, self).init(target, graph, config=config)\nFile \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 552, in init\nself._session = tf_session.TF_NewDeprecatedSession(opts, status)\nFile \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/contextlib.py\", line 24, in exit\nself.gen.next()\nFile \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\npywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.\n\nHave tried to set CUDA_VISIBLE_DEVICES but still does not work.\nHere is the output of nvidia-smi, just wonder why all GPUs are \"Off\"?\n\nTue May 23 21:28:08 2017\n+------------------------------------------------------+\n| NVIDIA-SMI 352.39     Driver Version: 352.39         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           On   | 0000:06:00.0     Off |                    0 |\n| N/A   37C    P0    62W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           On   | 0000:07:00.0     Off |                    0 |\n| N/A   57C    P0    73W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla K80           On   | 0000:0A:00.0     Off |                    0 |\n| N/A   38C    P0    60W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla K80           On   | 0000:0B:00.0     Off |                    0 |\n| N/A   54C    P0    73W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   4  Tesla K80           On   | 0000:0E:00.0     Off |                    0 |\n| N/A   37C    P0    61W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   5  Tesla K80           On   | 0000:0F:00.0     Off |                    0 |\n| N/A   59C    P0    75W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   6  Tesla K80           On   | 0000:12:00.0     Off |                    0 |\n| N/A   39C    P0    61W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   7  Tesla K80           On   | 0000:13:00.0     Off |                    0 |\n| N/A   62C    P0    74W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     24673    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\n|    1     16902    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\n|    2     27468    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\n|    3     11704    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\n|    4     13475    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\n|    5     16115    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\n|    6      2095    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\n|    7     23351    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\n+-----------------------------------------------------------------------------+", "body": "Got the following error when trying to run tensorflow on GPU:\r\n\r\n> E tensorflow/core/common_runtime/direct_session.cc:137] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE\r\n> Traceback (most recent call last):\r\n>   File \"main.py\", line 200, in <module>\r\n>     model = PNN2(**pnn2_params)\r\n>   File \"/homes/jwpan/Github/DL_MultiField_Categorical_Data/python/models.py\", line 767, in __init__\r\n>     self.sess = tf.Session(config=config)\r\n>   File \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1176, in __init__\r\n>     super(Session, self).__init__(target, graph, config=config)\r\n>   File \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 552, in __init__\r\n>     self._session = tf_session.TF_NewDeprecatedSession(opts, status)\r\n>   File \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n>     self.gen.next()\r\n>   File \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n>     pywrap_tensorflow.TF_GetCode(status))\r\n> tensorflow.python.framework.errors_impl.InternalError: Failed to create session.\r\n\r\nHave tried to set CUDA_VISIBLE_DEVICES but still does not work.\r\nHere is the output of nvidia-smi, just wonder why all GPUs are \"Off\"?\r\n\r\n> Tue May 23 21:28:08 2017\r\n> +------------------------------------------------------+\r\n> | NVIDIA-SMI 352.39     Driver Version: 352.39         |\r\n> |-------------------------------+----------------------+----------------------+\r\n> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n> |===============================+======================+======================|\r\n> |   0  Tesla K80           On   | 0000:06:00.0     Off |                    0 |\r\n> | N/A   37C    P0    62W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   1  Tesla K80           On   | 0000:07:00.0     Off |                    0 |\r\n> | N/A   57C    P0    73W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   2  Tesla K80           On   | 0000:0A:00.0     Off |                    0 |\r\n> | N/A   38C    P0    60W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   3  Tesla K80           On   | 0000:0B:00.0     Off |                    0 |\r\n> | N/A   54C    P0    73W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   4  Tesla K80           On   | 0000:0E:00.0     Off |                    0 |\r\n> | N/A   37C    P0    61W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   5  Tesla K80           On   | 0000:0F:00.0     Off |                    0 |\r\n> | N/A   59C    P0    75W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   6  Tesla K80           On   | 0000:12:00.0     Off |                    0 |\r\n> | N/A   39C    P0    61W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   7  Tesla K80           On   | 0000:13:00.0     Off |                    0 |\r\n> | N/A   62C    P0    74W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> \r\n> +-----------------------------------------------------------------------------+\r\n> | Processes:                                                       GPU Memory |\r\n> |  GPU       PID  Type  Process name                               Usage      |\r\n> |=============================================================================|\r\n> |    0     24673    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    1     16902    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    2     27468    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    3     11704    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    4     13475    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    5     16115    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    6      2095    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    7     23351    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> +-----------------------------------------------------------------------------+"}