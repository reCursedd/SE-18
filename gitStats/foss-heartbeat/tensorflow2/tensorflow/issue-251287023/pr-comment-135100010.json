{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/135100010", "pull_request_review_id": 58474674, "id": 135100010, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNTEwMDAxMA==", "diff_hunk": "@@ -364,6 +364,72 @@ TEST_F(GradientsTest, MultipleNodeOutputGrads) {\n       test::AsTensor<int>({60, 61, 62, 63, 66, 66, 66, 67}, {4, 2}));\n }\n \n+TEST_F(GradientsTest, UnreachableEdgeGradOneOutput) {\n+  auto x = Variable(scope_test_, {2, 3}, DT_DOUBLE);\n+  auto x_const = Const(scope_test_, {{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}});\n+  auto x_assign = Assign(scope_test_, x, x_const);\n+\n+  auto y = Variable(scope_test_, {3, 1}, DT_DOUBLE);\n+  auto y_const = Const(scope_test_, {{1.0}, {2.0}, {3.0}});\n+  auto y_assign = Assign(scope_test_, y, y_const);\n+\n+  auto m1 = MatMul(scope_test_, x, y);\n+\n+  auto z = Variable(scope_test_, {1, 3}, DT_DOUBLE);\n+  auto z_const = Const(scope_test_, {{9.0, 10.0, 11.0}});\n+  auto z_assign = Assign(scope_test_, z, z_const);\n+\n+  auto m2 = MatMul(scope_test_, y, z);\n+\n+  auto dm1 = Const(scope_test_, {{0.5}, {0.5}});\n+\n+  std::vector<Output> grad_outputs;\n+  TF_ASSERT_OK(\n+      AddSymbolicGradients(scope_test_, {m1}, {y}, {dm1}, &grad_outputs));\n+\n+  std::vector<Tensor> outputs;\n+  test::GetTensors(scope_test_, {x_assign, y_assign, z_assign},\n+                   {grad_outputs[0]}, &outputs);\n+\n+  test::ExpectTensorNear<double>(\n+      outputs[0], test::AsTensor<double>({2.5, 3.5, 4.5}, {3, 1}), 1e-5);\n+}\n+\n+TEST_F(GradientsTest, UnreachableEdgeGradTwoOutputs) {\n+  auto x = Variable(scope_test_, {2, 3}, DT_DOUBLE);\n+  auto x_const = Const(scope_test_, {{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}});\n+  auto x_assign = Assign(scope_test_, x, x_const);\n+\n+  auto y = Variable(scope_test_, {3, 1}, DT_DOUBLE);\n+  auto y_const = Const(scope_test_, {{1.0}, {2.0}, {3.0}});\n+  auto y_assign = Assign(scope_test_, y, y_const);\n+\n+  auto m1 = MatMul(scope_test_, x, y);\n+\n+  auto z = Variable(scope_test_, {1, 3}, DT_DOUBLE);\n+  auto z_const = Const(scope_test_, {{9.0, 10.0, 11.0}});\n+  auto z_assign = Assign(scope_test_, z, z_const);\n+\n+  auto m2 = MatMul(scope_test_, y, z);\n+\n+  auto dm1 = Const(scope_test_, {{0.5}, {0.5}});\n+  auto dm2 =\n+      Const(scope_test_, {{0.5, 0.5, 0.5}, {0.6, 0.7, 0.8}, {0.6, 0.7, 0.9}});\n+\n+  std::vector<Output> grad_outputs;\n+  TF_ASSERT_OK(AddSymbolicGradients(scope_test_, {m1, m2}, {y}, {dm1, dm2},\n+                                    &grad_outputs));\n+\n+  std::vector<Tensor> outputs;\n+  test::GetTensors(scope_test_, {x_assign, y_assign, z_assign},\n+                   {grad_outputs[0]}, &outputs);\n+\n+  // the gradients from m1 and m2 will be summed to compute the gradient\n+  // w.r.t y", "path": "tensorflow/cc/framework/gradients_test.cc", "position": 65, "original_position": 65, "commit_id": "47e093dd36ff74c9ab8a3b2728d4c0c5331f1bef", "original_commit_id": "3e8ecdd8c90c4e9f3ca63cc259e94f5940b62dcd", "user": {"login": "theflofly", "id": 3902382, "node_id": "MDQ6VXNlcjM5MDIzODI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3902382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/theflofly", "html_url": "https://github.com/theflofly", "followers_url": "https://api.github.com/users/theflofly/followers", "following_url": "https://api.github.com/users/theflofly/following{/other_user}", "gists_url": "https://api.github.com/users/theflofly/gists{/gist_id}", "starred_url": "https://api.github.com/users/theflofly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/theflofly/subscriptions", "organizations_url": "https://api.github.com/users/theflofly/orgs", "repos_url": "https://api.github.com/users/theflofly/repos", "events_url": "https://api.github.com/users/theflofly/events{/privacy}", "received_events_url": "https://api.github.com/users/theflofly/received_events", "type": "User", "site_admin": false}, "body": "Above the output given to AddSymbolicGradients is m1 so the gradient is backpropagated from m1 but not from m2, so there is no sum. Here the output given to AddSymbolicGradients is {m1, m2} so the gradients from m1 and m2 are summed. That's why the comment is only here. I guess it should be like that?\r\nElse I agree with all others comments and will update soon.", "created_at": "2017-08-24T18:51:00Z", "updated_at": "2017-08-29T21:01:29Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/12397#discussion_r135100010", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12397", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/135100010"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/12397#discussion_r135100010"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12397"}}, "body_html": "<p>Above the output given to AddSymbolicGradients is m1 so the gradient is backpropagated from m1 but not from m2, so there is no sum. Here the output given to AddSymbolicGradients is {m1, m2} so the gradients from m1 and m2 are summed. That's why the comment is only here. I guess it should be like that?<br>\nElse I agree with all others comments and will update soon.</p>", "body_text": "Above the output given to AddSymbolicGradients is m1 so the gradient is backpropagated from m1 but not from m2, so there is no sum. Here the output given to AddSymbolicGradients is {m1, m2} so the gradients from m1 and m2 are summed. That's why the comment is only here. I guess it should be like that?\nElse I agree with all others comments and will update soon.", "in_reply_to_id": 135060000}