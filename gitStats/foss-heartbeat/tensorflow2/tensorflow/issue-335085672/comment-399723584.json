{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/399723584", "html_url": "https://github.com/tensorflow/tensorflow/issues/20241#issuecomment-399723584", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20241", "id": 399723584, "node_id": "MDEyOklzc3VlQ29tbWVudDM5OTcyMzU4NA==", "user": {"login": "Shanlans", "id": 29950321, "node_id": "MDQ6VXNlcjI5OTUwMzIx", "avatar_url": "https://avatars1.githubusercontent.com/u/29950321?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Shanlans", "html_url": "https://github.com/Shanlans", "followers_url": "https://api.github.com/users/Shanlans/followers", "following_url": "https://api.github.com/users/Shanlans/following{/other_user}", "gists_url": "https://api.github.com/users/Shanlans/gists{/gist_id}", "starred_url": "https://api.github.com/users/Shanlans/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Shanlans/subscriptions", "organizations_url": "https://api.github.com/users/Shanlans/orgs", "repos_url": "https://api.github.com/users/Shanlans/repos", "events_url": "https://api.github.com/users/Shanlans/events{/privacy}", "received_events_url": "https://api.github.com/users/Shanlans/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-24T02:12:14Z", "updated_at": "2018-06-24T15:12:41Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=28546240\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tensorflowbutler\">@tensorflowbutler</a><br>\nOs: Windows 10<br>\nHave I written custom code - No<br>\nTensorFlow version -1.4.0<br>\nCUDA/cuDNN version - 8.0<br>\nGPU model and memory - 1x NVIDIA GTX1050 / 4 GB</p>\n<p>We followed an unofficial tutorial to build tensorflow c++ API for WINDOWS10 using. We design 2 threads, each thread has 2 instances of session which load the different model to process the different task. We found when we run 2 models in one thread and 1 model in another thread at the same time, everything is ok, but both 2 threads load 2 models simultaneously, the project would break down. We tried to set 'set_per_process_gpu_memory_fraction(0.3)' to restrict each process memory usage, but still the same issue, and memory usage seems not change. So, I wonder to know whether Tensorflow 1.4 does not support the multiple processes on single device well like this. Or we need to do the specific operation to make this happen.</p>\n<p>By the way, 4 models are 2 deeplab V3 Xeption65 + 2 mobilenet V1_1.0_224</p>\n<p>Thanks a lot.</p>", "body_text": "@tensorflowbutler\nOs: Windows 10\nHave I written custom code - No\nTensorFlow version -1.4.0\nCUDA/cuDNN version - 8.0\nGPU model and memory - 1x NVIDIA GTX1050 / 4 GB\nWe followed an unofficial tutorial to build tensorflow c++ API for WINDOWS10 using. We design 2 threads, each thread has 2 instances of session which load the different model to process the different task. We found when we run 2 models in one thread and 1 model in another thread at the same time, everything is ok, but both 2 threads load 2 models simultaneously, the project would break down. We tried to set 'set_per_process_gpu_memory_fraction(0.3)' to restrict each process memory usage, but still the same issue, and memory usage seems not change. So, I wonder to know whether Tensorflow 1.4 does not support the multiple processes on single device well like this. Or we need to do the specific operation to make this happen.\nBy the way, 4 models are 2 deeplab V3 Xeption65 + 2 mobilenet V1_1.0_224\nThanks a lot.", "body": "@tensorflowbutler \r\nOs: Windows 10 \r\nHave I written custom code - No\r\nTensorFlow version -1.4.0\r\nCUDA/cuDNN version - 8.0\r\nGPU model and memory - 1x NVIDIA GTX1050 / 4 GB \r\n\r\nWe followed an unofficial tutorial to build tensorflow c++ API for WINDOWS10 using. We design 2 threads, each thread has 2 instances of session which load the different model to process the different task. We found when we run 2 models in one thread and 1 model in another thread at the same time, everything is ok, but both 2 threads load 2 models simultaneously, the project would break down. We tried to set 'set_per_process_gpu_memory_fraction(0.3)' to restrict each process memory usage, but still the same issue, and memory usage seems not change. So, I wonder to know whether Tensorflow 1.4 does not support the multiple processes on single device well like this. Or we need to do the specific operation to make this happen. \r\n\r\nBy the way, 4 models are 2 deeplab V3 Xeption65 + 2 mobilenet V1_1.0_224\r\n\r\nThanks a lot. "}