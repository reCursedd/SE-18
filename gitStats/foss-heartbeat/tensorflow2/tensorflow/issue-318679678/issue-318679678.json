{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18952", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18952/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18952/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18952/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18952", "id": 318679678, "node_id": "MDU6SXNzdWUzMTg2Nzk2Nzg=", "number": 18952, "title": "Feature request: Option to create dataset from a subset of the columns in the CSV file using tf.contrib.data.make_csv_dataset()", "user": {"login": "sibyjackgrove", "id": 25213730, "node_id": "MDQ6VXNlcjI1MjEzNzMw", "avatar_url": "https://avatars0.githubusercontent.com/u/25213730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sibyjackgrove", "html_url": "https://github.com/sibyjackgrove", "followers_url": "https://api.github.com/users/sibyjackgrove/followers", "following_url": "https://api.github.com/users/sibyjackgrove/following{/other_user}", "gists_url": "https://api.github.com/users/sibyjackgrove/gists{/gist_id}", "starred_url": "https://api.github.com/users/sibyjackgrove/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sibyjackgrove/subscriptions", "organizations_url": "https://api.github.com/users/sibyjackgrove/orgs", "repos_url": "https://api.github.com/users/sibyjackgrove/repos", "events_url": "https://api.github.com/users/sibyjackgrove/events{/privacy}", "received_events_url": "https://api.github.com/users/sibyjackgrove/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "angersson", "id": 32465472, "node_id": "MDQ6VXNlcjMyNDY1NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/32465472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angersson", "html_url": "https://github.com/angersson", "followers_url": "https://api.github.com/users/angersson/followers", "following_url": "https://api.github.com/users/angersson/following{/other_user}", "gists_url": "https://api.github.com/users/angersson/gists{/gist_id}", "starred_url": "https://api.github.com/users/angersson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angersson/subscriptions", "organizations_url": "https://api.github.com/users/angersson/orgs", "repos_url": "https://api.github.com/users/angersson/repos", "events_url": "https://api.github.com/users/angersson/events{/privacy}", "received_events_url": "https://api.github.com/users/angersson/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "angersson", "id": 32465472, "node_id": "MDQ6VXNlcjMyNDY1NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/32465472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angersson", "html_url": "https://github.com/angersson", "followers_url": "https://api.github.com/users/angersson/followers", "following_url": "https://api.github.com/users/angersson/following{/other_user}", "gists_url": "https://api.github.com/users/angersson/gists{/gist_id}", "starred_url": "https://api.github.com/users/angersson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angersson/subscriptions", "organizations_url": "https://api.github.com/users/angersson/orgs", "repos_url": "https://api.github.com/users/angersson/repos", "events_url": "https://api.github.com/users/angersson/events{/privacy}", "received_events_url": "https://api.github.com/users/angersson/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-04-29T00:38:12Z", "updated_at": "2018-05-01T18:23:31Z", "closed_at": "2018-05-01T18:23:31Z", "author_association": "CONTRIBUTOR", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Custom</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.8</li>\n<li><strong>Python version</strong>:  3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>:NA</li>\n<li><strong>Exact command to reproduce</strong>:<br>\ntf.contrib.data.make_csv_dataset()</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The <code>tf.contrib.data.make_csv_dataset()</code> is a very useful feature which allows us to convert CSV files directly into at dataset without having to use Pandas library (like shown <a href=\"https://stackoverflow.com/questions/49116343/dataset-api-flat-map-method-producing-error-for-same-code-which-works-with-ma/49140725#49140725\" rel=\"nofollow\">here</a>). However it is missing an important feature which Pandas had, that is to read a subset of the columns in the CSV file.<br>\nFor example the following code:</p>\n<pre><code>dataset=tf.contrib.data.make_csv_dataset(file_pattern='./data/power_data/MISO_power_data1.csv',batch_size=24,shuffle=False)\ndataset = dataset.batch(4)\nX_iter = dataset.make_one_shot_iterator()\nX_batch = X_iter.get_next()\nX_batch\n</code></pre>\n<p>results in following dataset:</p>\n<pre><code>{'Actual_Load_MWh': &lt;tf.Tensor 'IteratorGetNext_9:0' shape=(?, ?) dtype=float32&gt;,\n 'Hour_Ending': &lt;tf.Tensor 'IteratorGetNext_9:1' shape=(?, ?) dtype=int32&gt;,\n 'Market_Day': &lt;tf.Tensor 'IteratorGetNext_9:2' shape=(?, ?) dtype=int32&gt;,\n 'Wind_MWh': &lt;tf.Tensor 'IteratorGetNext_9:3' shape=(?, ?) dtype=float32&gt;}\n</code></pre>\n<p>However I don't want feature columns for 'Hour_Ending'  and  'Market_Day' in my dataset (since they are not relevant training data) . This could be done in Pandas using code below:</p>\n<pre><code>df_input=pd.read_csv('./data/power_data/MISO_power_data1.csv',\n                         usecols=['Wind_MWh', 'Actual_Load_MWh'], nrows=24)\n</code></pre>\n<p>I know the easy solution would be to create a CSV file having only the feature columns I want. But it would be a great utility feature to add before <code>make_csv_dataset()</code> migrates out of contrib into core TF. I can submit a PR for this if required.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): 1.8\nPython version:  3.6\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source): NA\nCUDA/cuDNN version: NA\nGPU model and memory:NA\nExact command to reproduce:\ntf.contrib.data.make_csv_dataset()\n\nDescribe the problem\nThe tf.contrib.data.make_csv_dataset() is a very useful feature which allows us to convert CSV files directly into at dataset without having to use Pandas library (like shown here). However it is missing an important feature which Pandas had, that is to read a subset of the columns in the CSV file.\nFor example the following code:\ndataset=tf.contrib.data.make_csv_dataset(file_pattern='./data/power_data/MISO_power_data1.csv',batch_size=24,shuffle=False)\ndataset = dataset.batch(4)\nX_iter = dataset.make_one_shot_iterator()\nX_batch = X_iter.get_next()\nX_batch\n\nresults in following dataset:\n{'Actual_Load_MWh': <tf.Tensor 'IteratorGetNext_9:0' shape=(?, ?) dtype=float32>,\n 'Hour_Ending': <tf.Tensor 'IteratorGetNext_9:1' shape=(?, ?) dtype=int32>,\n 'Market_Day': <tf.Tensor 'IteratorGetNext_9:2' shape=(?, ?) dtype=int32>,\n 'Wind_MWh': <tf.Tensor 'IteratorGetNext_9:3' shape=(?, ?) dtype=float32>}\n\nHowever I don't want feature columns for 'Hour_Ending'  and  'Market_Day' in my dataset (since they are not relevant training data) . This could be done in Pandas using code below:\ndf_input=pd.read_csv('./data/power_data/MISO_power_data1.csv',\n                         usecols=['Wind_MWh', 'Actual_Load_MWh'], nrows=24)\n\nI know the easy solution would be to create a CSV file having only the feature columns I want. But it would be a great utility feature to add before make_csv_dataset() migrates out of contrib into core TF. I can submit a PR for this if required.", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**:NA\r\n- **Exact command to reproduce**:\r\ntf.contrib.data.make_csv_dataset()\r\n\r\n### Describe the problem\r\n\r\nThe `tf.contrib.data.make_csv_dataset()` is a very useful feature which allows us to convert CSV files directly into at dataset without having to use Pandas library (like shown [here](https://stackoverflow.com/questions/49116343/dataset-api-flat-map-method-producing-error-for-same-code-which-works-with-ma/49140725#49140725)). However it is missing an important feature which Pandas had, that is to read a subset of the columns in the CSV file.\r\nFor example the following code:\r\n```\r\ndataset=tf.contrib.data.make_csv_dataset(file_pattern='./data/power_data/MISO_power_data1.csv',batch_size=24,shuffle=False)\r\ndataset = dataset.batch(4)\r\nX_iter = dataset.make_one_shot_iterator()\r\nX_batch = X_iter.get_next()\r\nX_batch\r\n```\r\nresults in following dataset:\r\n```\r\n{'Actual_Load_MWh': <tf.Tensor 'IteratorGetNext_9:0' shape=(?, ?) dtype=float32>,\r\n 'Hour_Ending': <tf.Tensor 'IteratorGetNext_9:1' shape=(?, ?) dtype=int32>,\r\n 'Market_Day': <tf.Tensor 'IteratorGetNext_9:2' shape=(?, ?) dtype=int32>,\r\n 'Wind_MWh': <tf.Tensor 'IteratorGetNext_9:3' shape=(?, ?) dtype=float32>}\r\n```\r\nHowever I don't want feature columns for 'Hour_Ending'  and  'Market_Day' in my dataset (since they are not relevant training data) . This could be done in Pandas using code below:\r\n```\r\ndf_input=pd.read_csv('./data/power_data/MISO_power_data1.csv',\r\n                         usecols=['Wind_MWh', 'Actual_Load_MWh'], nrows=24)\r\n```\r\nI know the easy solution would be to create a CSV file having only the feature columns I want. But it would be a great utility feature to add before `make_csv_dataset()` migrates out of contrib into core TF. I can submit a PR for this if required."}