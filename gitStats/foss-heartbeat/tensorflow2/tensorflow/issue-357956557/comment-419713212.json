{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/419713212", "html_url": "https://github.com/tensorflow/tensorflow/issues/22140#issuecomment-419713212", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22140", "id": 419713212, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTcxMzIxMg==", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-09T12:41:26Z", "updated_at": "2018-09-09T14:59:45Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3731025\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/allenlavoie\">@allenlavoie</a> I think it would be nice to track and record any trainable layer variables, no matter what data structure they are in.<br>\nI'm also interested in the mechanism of saving vars.</p>\n<ol>\n<li>Seems if use another layer like B in Layer A(B is a member of A), then we do not save any vars of B.</li>\n<li>Then in order to save vars of B I have to make A a Model instead of a Layer, but for Model seems<br>\nwe can not use add_weight, then I have to wrap members using add_weight using Layer.. A bit complex.</li>\n</ol>", "body_text": "@allenlavoie I think it would be nice to track and record any trainable layer variables, no matter what data structure they are in.\nI'm also interested in the mechanism of saving vars.\n\nSeems if use another layer like B in Layer A(B is a member of A), then we do not save any vars of B.\nThen in order to save vars of B I have to make A a Model instead of a Layer, but for Model seems\nwe can not use add_weight, then I have to wrap members using add_weight using Layer.. A bit complex.", "body": "@allenlavoie I think it would be nice to track and record any trainable layer variables, no matter what data structure they are in.\r\nI'm also interested in the mechanism of saving vars.\r\n1. Seems if use another layer like B in Layer A(B is a member of A), then we do not save any vars of B.\r\n2. Then in order to save vars of B I have to make A a Model instead of a Layer, but for Model seems \r\n    we can not use add_weight, then I have to wrap members using add_weight using Layer.. A bit complex. \r\n"}