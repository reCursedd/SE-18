{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2414", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2414/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2414/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2414/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2414", "id": 155440309, "node_id": "MDU6SXNzdWUxNTU0NDAzMDk=", "number": 2414, "title": "how to run lstm on multi gpus?", "user": {"login": "qingzew", "id": 3603171, "node_id": "MDQ6VXNlcjM2MDMxNzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3603171?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qingzew", "html_url": "https://github.com/qingzew", "followers_url": "https://api.github.com/users/qingzew/followers", "following_url": "https://api.github.com/users/qingzew/following{/other_user}", "gists_url": "https://api.github.com/users/qingzew/gists{/gist_id}", "starred_url": "https://api.github.com/users/qingzew/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qingzew/subscriptions", "organizations_url": "https://api.github.com/users/qingzew/orgs", "repos_url": "https://api.github.com/users/qingzew/repos", "events_url": "https://api.github.com/users/qingzew/events{/privacy}", "received_events_url": "https://api.github.com/users/qingzew/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-05-18T08:08:29Z", "updated_at": "2016-05-18T14:39:49Z", "closed_at": "2016-05-18T14:39:49Z", "author_association": "NONE", "body_html": "<p>I run a example of lstm on multi gpus using codes in <code>models/image/cifar10</code>, but it turns out that Attempting to use uninitialized value lstm/LSTMCell/W_0. I have read the issues 1390, so I have a question if the implementation of lstmcell is ok. when I want to store variables on cpu, and run ops on gpu, the implementation of lstmcell do initialization of <code>w</code> in blackbox, then variables and ops must be in the same place, cpu or gpu, it's not a good idea, right?</p>", "body_text": "I run a example of lstm on multi gpus using codes in models/image/cifar10, but it turns out that Attempting to use uninitialized value lstm/LSTMCell/W_0. I have read the issues 1390, so I have a question if the implementation of lstmcell is ok. when I want to store variables on cpu, and run ops on gpu, the implementation of lstmcell do initialization of w in blackbox, then variables and ops must be in the same place, cpu or gpu, it's not a good idea, right?", "body": "I run a example of lstm on multi gpus using codes in `models/image/cifar10`, but it turns out that Attempting to use uninitialized value lstm/LSTMCell/W_0. I have read the issues 1390, so I have a question if the implementation of lstmcell is ok. when I want to store variables on cpu, and run ops on gpu, the implementation of lstmcell do initialization of `w` in blackbox, then variables and ops must be in the same place, cpu or gpu, it's not a good idea, right?\n"}