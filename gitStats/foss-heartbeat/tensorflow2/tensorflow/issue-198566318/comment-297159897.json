{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/297159897", "html_url": "https://github.com/tensorflow/tensorflow/issues/6620#issuecomment-297159897", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6620", "id": 297159897, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NzE1OTg5Nw==", "user": {"login": "alquraishi", "id": 5205204, "node_id": "MDQ6VXNlcjUyMDUyMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/5205204?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alquraishi", "html_url": "https://github.com/alquraishi", "followers_url": "https://api.github.com/users/alquraishi/followers", "following_url": "https://api.github.com/users/alquraishi/following{/other_user}", "gists_url": "https://api.github.com/users/alquraishi/gists{/gist_id}", "starred_url": "https://api.github.com/users/alquraishi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alquraishi/subscriptions", "organizations_url": "https://api.github.com/users/alquraishi/orgs", "repos_url": "https://api.github.com/users/alquraishi/repos", "events_url": "https://api.github.com/users/alquraishi/events{/privacy}", "received_events_url": "https://api.github.com/users/alquraishi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-25T20:47:01Z", "updated_at": "2017-04-25T20:47:01Z", "author_association": "NONE", "body_html": "<p>I just tried it with the latest nightly build and the problem is still there.</p>\n<p>Note that what's needed is not really the shape, but the <em>size</em> of the parameter buffer, since what's being passed to CudnnLSTM is just a flat 1D vector anyway. And the size should not vary from HW iteration to another (otherwise there cannot be a 'canonical' version and the whole premise of <code>RNNParamsSaveable</code> would be moot). Given that, it seems like a very simple solution would be to just calculate the size and return that for <code>model.params_size()</code>. For an LSTM it's literally just:</p>\n<pre><code>params_size = ((input_size * layer_size * 4) + (layer_size * layer_size * 4) + (layer_size * 2 * 4)) * dir_count\n</code></pre>\n<p>for one layer. Multiple layers would need to modify the input_size for layers &gt; 1 to be the size of the previous layer.</p>", "body_text": "I just tried it with the latest nightly build and the problem is still there.\nNote that what's needed is not really the shape, but the size of the parameter buffer, since what's being passed to CudnnLSTM is just a flat 1D vector anyway. And the size should not vary from HW iteration to another (otherwise there cannot be a 'canonical' version and the whole premise of RNNParamsSaveable would be moot). Given that, it seems like a very simple solution would be to just calculate the size and return that for model.params_size(). For an LSTM it's literally just:\nparams_size = ((input_size * layer_size * 4) + (layer_size * layer_size * 4) + (layer_size * 2 * 4)) * dir_count\n\nfor one layer. Multiple layers would need to modify the input_size for layers > 1 to be the size of the previous layer.", "body": "I just tried it with the latest nightly build and the problem is still there.\r\n\r\nNote that what's needed is not really the shape, but the _size_ of the parameter buffer, since what's being passed to CudnnLSTM is just a flat 1D vector anyway. And the size should not vary from HW iteration to another (otherwise there cannot be a 'canonical' version and the whole premise of `RNNParamsSaveable` would be moot). Given that, it seems like a very simple solution would be to just calculate the size and return that for `model.params_size()`. For an LSTM it's literally just:\r\n\r\n```\r\nparams_size = ((input_size * layer_size * 4) + (layer_size * layer_size * 4) + (layer_size * 2 * 4)) * dir_count\r\n```\r\n\r\nfor one layer. Multiple layers would need to modify the input_size for layers > 1 to be the size of the previous layer."}