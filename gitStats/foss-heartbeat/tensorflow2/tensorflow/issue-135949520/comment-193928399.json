{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/193928399", "html_url": "https://github.com/tensorflow/tensorflow/issues/1268#issuecomment-193928399", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1268", "id": 193928399, "node_id": "MDEyOklzc3VlQ29tbWVudDE5MzkyODM5OQ==", "user": {"login": "Palang2014", "id": 13631873, "node_id": "MDQ6VXNlcjEzNjMxODcz", "avatar_url": "https://avatars1.githubusercontent.com/u/13631873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Palang2014", "html_url": "https://github.com/Palang2014", "followers_url": "https://api.github.com/users/Palang2014/followers", "following_url": "https://api.github.com/users/Palang2014/following{/other_user}", "gists_url": "https://api.github.com/users/Palang2014/gists{/gist_id}", "starred_url": "https://api.github.com/users/Palang2014/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Palang2014/subscriptions", "organizations_url": "https://api.github.com/users/Palang2014/orgs", "repos_url": "https://api.github.com/users/Palang2014/repos", "events_url": "https://api.github.com/users/Palang2014/events{/privacy}", "received_events_url": "https://api.github.com/users/Palang2014/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-08T19:20:50Z", "updated_at": "2016-03-08T19:20:50Z", "author_association": "NONE", "body_html": "<p>Thanks for reply. Let me ask them separately,</p>\n<p>(1) Is it possible to use embedding layer with GPU? I think it is not because when I change <code>with tf.device(\"/cpu:0\")</code> to <code>with tf.device(\"/gpu:0\")</code> I get the following error which is caused by embedding look up. Is this because it is faster on CPU or it also supports GPU with a different syntax?</p>\n<pre><code>tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'model/embedding_lookup': Could not satisfy explicit device specification '/device:GPU:0'\n     [[Node: model/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/device:GPU:0\"](model/embedding/read, model/Placeholder)]]\nCaused by op u'model/embedding_lookup'\n</code></pre>\n<p>(2) For the rest of the code it uses just one GPU even if I made two GPUs visible for it with:</p>\n<pre><code>os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n</code></pre>\n<p>How I can set the language model example to use more than one GPU?</p>\n<p>Thanks!<br>\nHamid</p>", "body_text": "Thanks for reply. Let me ask them separately,\n(1) Is it possible to use embedding layer with GPU? I think it is not because when I change with tf.device(\"/cpu:0\") to with tf.device(\"/gpu:0\") I get the following error which is caused by embedding look up. Is this because it is faster on CPU or it also supports GPU with a different syntax?\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'model/embedding_lookup': Could not satisfy explicit device specification '/device:GPU:0'\n     [[Node: model/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/device:GPU:0\"](model/embedding/read, model/Placeholder)]]\nCaused by op u'model/embedding_lookup'\n\n(2) For the rest of the code it uses just one GPU even if I made two GPUs visible for it with:\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n\nHow I can set the language model example to use more than one GPU?\nThanks!\nHamid", "body": "Thanks for reply. Let me ask them separately, \n\n(1) Is it possible to use embedding layer with GPU? I think it is not because when I change `with tf.device(\"/cpu:0\")` to `with tf.device(\"/gpu:0\")` I get the following error which is caused by embedding look up. Is this because it is faster on CPU or it also supports GPU with a different syntax?\n\n```\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'model/embedding_lookup': Could not satisfy explicit device specification '/device:GPU:0'\n     [[Node: model/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/device:GPU:0\"](model/embedding/read, model/Placeholder)]]\nCaused by op u'model/embedding_lookup'\n```\n\n(2) For the rest of the code it uses just one GPU even if I made two GPUs visible for it with:\n\n```\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n```\n\nHow I can set the language model example to use more than one GPU?\n\nThanks!\nHamid\n"}