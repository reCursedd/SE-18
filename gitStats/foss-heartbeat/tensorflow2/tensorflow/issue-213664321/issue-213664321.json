{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8337", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8337/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8337/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8337/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8337", "id": 213664321, "node_id": "MDU6SXNzdWUyMTM2NjQzMjE=", "number": 8337, "title": "tfdbg error: Causality violated in timing relations of debug dumps", "user": {"login": "zxvix", "id": 2542360, "node_id": "MDQ6VXNlcjI1NDIzNjA=", "avatar_url": "https://avatars3.githubusercontent.com/u/2542360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zxvix", "html_url": "https://github.com/zxvix", "followers_url": "https://api.github.com/users/zxvix/followers", "following_url": "https://api.github.com/users/zxvix/following{/other_user}", "gists_url": "https://api.github.com/users/zxvix/gists{/gist_id}", "starred_url": "https://api.github.com/users/zxvix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zxvix/subscriptions", "organizations_url": "https://api.github.com/users/zxvix/orgs", "repos_url": "https://api.github.com/users/zxvix/repos", "events_url": "https://api.github.com/users/zxvix/events{/privacy}", "received_events_url": "https://api.github.com/users/zxvix/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-03-13T03:22:54Z", "updated_at": "2017-07-26T20:16:40Z", "closed_at": "2017-03-31T07:09:24Z", "author_association": "NONE", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>Nothing found</p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nUbuntu 14.04<br>\nInstalled version of CUDA and cuDNN:<br>\nCUDA 8.0, cuDNN 5.1<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<pre><code>-rw-r--r-- 1 root root   558720  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16  9\u6708 15 07:05 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root       19  9\u6708 15 07:05 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44\n-rw-r--r-- 1 root root   415432  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn_static.a\n</code></pre>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)<br>\n<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/12a98726e769e988f6368a029ec2f5b0ac3ccbd4/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/12a98726e769e988f6368a029ec2f5b0ac3ccbd4\"><tt>12a9872</tt></a></li>\n<li>The output of <code>bazel version</code></li>\n</ol>\n<pre><code>Build label: 0.4.4\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\nBuild timestamp: 1485975261\nBuild timestamp as int: 1485975261\n</code></pre>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>I have a model that basically consists of several bidirectional rnns, the longest of which has hundreds of timesteps.</p>\n<h3>What other attempted solutions have you tried?</h3>\n<h3>Logs or other output that would be helpful</h3>\n<p>When I try to launch the first Session.run() call in tfdbg using command r, I got the following error:</p>\n<pre><code>2017-03-13 10:54:06.173974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:\nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:81:00.0\nTotal memory: 7.92GiB\nFree memory: 7.81GiB\n2017-03-13 10:54:06.174082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0\n2017-03-13 10:54:06.174106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y\n2017-03-13 10:54:06.174138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:81:00.0)\nCreated model with fresh parameters.\nTraceback (most recent call last):\n  File \"train.py\", line 143, in &lt;module&gt;\n    trainer.train()\n  File \"train.py\", line 76, in train\n    step_loss, summary = self.m.train_step(self.sess, batch_docs, batch_queries, batch_answers, batch_target)\n  File \"/home/zhangx/nn_tool_x33/MR_base/model.py\", line 186, in train_step\n    feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/framework.py\", line 470, in run\n    run_end_resp = self.on_run_end(run_end_req)\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py\", line 267, in on_run_end\n    self._dump_root, partition_graphs=partition_graphs)\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 502, in __init__\n    self._load_partition_graphs(partition_graphs, validate)\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 760, in _load_partition_graphs\n    self._validate_dump_with_graphs()\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 927, in _validate_dump_with_graphs\n    (node, datum.timestamp, repr(pending_inputs[node])))\nValueError: Causality violated in timing relations of debug dumps: optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2 (1489373660302841): these input(s) are not satisfied: [('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1', 0), ('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration', 0)]\n</code></pre>\n<p>Is this a model related error or possibly a tfdbg bug?</p>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nNothing found\nEnvironment info\nOperating System:\nUbuntu 14.04\nInstalled version of CUDA and cuDNN:\nCUDA 8.0, cuDNN 5.1\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n-rw-r--r-- 1 root root   558720  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16  9\u6708 15 07:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19  9\u6708 15 07:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rw-r--r-- 1 root root   415432  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD)\n12a9872\nThe output of bazel version\n\nBuild label: 0.4.4\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\nBuild timestamp: 1485975261\nBuild timestamp as int: 1485975261\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nI have a model that basically consists of several bidirectional rnns, the longest of which has hundreds of timesteps.\nWhat other attempted solutions have you tried?\nLogs or other output that would be helpful\nWhen I try to launch the first Session.run() call in tfdbg using command r, I got the following error:\n2017-03-13 10:54:06.173974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:\nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:81:00.0\nTotal memory: 7.92GiB\nFree memory: 7.81GiB\n2017-03-13 10:54:06.174082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0\n2017-03-13 10:54:06.174106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y\n2017-03-13 10:54:06.174138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:81:00.0)\nCreated model with fresh parameters.\nTraceback (most recent call last):\n  File \"train.py\", line 143, in <module>\n    trainer.train()\n  File \"train.py\", line 76, in train\n    step_loss, summary = self.m.train_step(self.sess, batch_docs, batch_queries, batch_answers, batch_target)\n  File \"/home/zhangx/nn_tool_x33/MR_base/model.py\", line 186, in train_step\n    feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/framework.py\", line 470, in run\n    run_end_resp = self.on_run_end(run_end_req)\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py\", line 267, in on_run_end\n    self._dump_root, partition_graphs=partition_graphs)\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 502, in __init__\n    self._load_partition_graphs(partition_graphs, validate)\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 760, in _load_partition_graphs\n    self._validate_dump_with_graphs()\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 927, in _validate_dump_with_graphs\n    (node, datum.timestamp, repr(pending_inputs[node])))\nValueError: Causality violated in timing relations of debug dumps: optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2 (1489373660302841): these input(s) are not satisfied: [('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1', 0), ('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration', 0)]\n\nIs this a model related error or possibly a tfdbg bug?", "body": "\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nNothing found\r\n### Environment info\r\nOperating System:\r\nUbuntu 14.04\r\nInstalled version of CUDA and cuDNN: \r\nCUDA 8.0, cuDNN 5.1\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\n-rw-r--r-- 1 root root   558720  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16  9\u6708 15 07:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19  9\u6708 15 07:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   415432  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudart_static.a\r\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so\r\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5\r\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n12a98726e769e988f6368a029ec2f5b0ac3ccbd4\r\n2. The output of `bazel version`\r\n```\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nI have a model that basically consists of several bidirectional rnns, the longest of which has hundreds of timesteps.\r\n### What other attempted solutions have you tried?\r\n\r\n### Logs or other output that would be helpful\r\nWhen I try to launch the first Session.run() call in tfdbg using command r, I got the following error:\r\n```\r\n2017-03-13 10:54:06.173974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:\r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\npciBusID 0000:81:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.81GiB\r\n2017-03-13 10:54:06.174082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0\r\n2017-03-13 10:54:06.174106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y\r\n2017-03-13 10:54:06.174138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:81:00.0)\r\nCreated model with fresh parameters.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 143, in <module>\r\n    trainer.train()\r\n  File \"train.py\", line 76, in train\r\n    step_loss, summary = self.m.train_step(self.sess, batch_docs, batch_queries, batch_answers, batch_target)\r\n  File \"/home/zhangx/nn_tool_x33/MR_base/model.py\", line 186, in train_step\r\n    feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/framework.py\", line 470, in run\r\n    run_end_resp = self.on_run_end(run_end_req)\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py\", line 267, in on_run_end\r\n    self._dump_root, partition_graphs=partition_graphs)\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 502, in __init__\r\n    self._load_partition_graphs(partition_graphs, validate)\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 760, in _load_partition_graphs\r\n    self._validate_dump_with_graphs()\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 927, in _validate_dump_with_graphs\r\n    (node, datum.timestamp, repr(pending_inputs[node])))\r\nValueError: Causality violated in timing relations of debug dumps: optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2 (1489373660302841): these input(s) are not satisfied: [('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1', 0), ('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration', 0)]\r\n```\r\nIs this a model related error or possibly a tfdbg bug?"}