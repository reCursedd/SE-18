{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/191816862", "html_url": "https://github.com/tensorflow/tensorflow/issues/504#issuecomment-191816862", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/504", "id": 191816862, "node_id": "MDEyOklzc3VlQ29tbWVudDE5MTgxNjg2Mg==", "user": {"login": "syed-ahmed", "id": 8906225, "node_id": "MDQ6VXNlcjg5MDYyMjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8906225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syed-ahmed", "html_url": "https://github.com/syed-ahmed", "followers_url": "https://api.github.com/users/syed-ahmed/followers", "following_url": "https://api.github.com/users/syed-ahmed/following{/other_user}", "gists_url": "https://api.github.com/users/syed-ahmed/gists{/gist_id}", "starred_url": "https://api.github.com/users/syed-ahmed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syed-ahmed/subscriptions", "organizations_url": "https://api.github.com/users/syed-ahmed/orgs", "repos_url": "https://api.github.com/users/syed-ahmed/repos", "events_url": "https://api.github.com/users/syed-ahmed/events{/privacy}", "received_events_url": "https://api.github.com/users/syed-ahmed/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-03T15:34:56Z", "updated_at": "2016-03-03T15:40:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=971353\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/savage7\">@savage7</a> yes, the model is correctly recognizing images. You are right that there is a difference in implementation between the label_image and android demo. I have seen that the android demo doesn't use the division op using the standard dev that is done in the label_image. I guess that is because of the way the input tensor is being filled up (mapping RGB values) in the android demo (I don't have a clear idea on the \"why\" of this but continued working with the assumption that the input tensor was being populated correctly).</p>\n<p>I tried doing the division you mentioned some days ago but it turned out that wasn't the problem. The BUILD file of the kernels was missing the \"batch_norm_op\" and the \"check_numerics_op\".</p>", "body_text": "@savage7 yes, the model is correctly recognizing images. You are right that there is a difference in implementation between the label_image and android demo. I have seen that the android demo doesn't use the division op using the standard dev that is done in the label_image. I guess that is because of the way the input tensor is being filled up (mapping RGB values) in the android demo (I don't have a clear idea on the \"why\" of this but continued working with the assumption that the input tensor was being populated correctly).\nI tried doing the division you mentioned some days ago but it turned out that wasn't the problem. The BUILD file of the kernels was missing the \"batch_norm_op\" and the \"check_numerics_op\".", "body": "@savage7 yes, the model is correctly recognizing images. You are right that there is a difference in implementation between the label_image and android demo. I have seen that the android demo doesn't use the division op using the standard dev that is done in the label_image. I guess that is because of the way the input tensor is being filled up (mapping RGB values) in the android demo (I don't have a clear idea on the \"why\" of this but continued working with the assumption that the input tensor was being populated correctly). \n\nI tried doing the division you mentioned some days ago but it turned out that wasn't the problem. The BUILD file of the kernels was missing the \"batch_norm_op\" and the \"check_numerics_op\". \n"}