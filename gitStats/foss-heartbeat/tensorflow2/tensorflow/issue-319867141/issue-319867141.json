{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19053", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19053/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19053/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19053/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/19053", "id": 319867141, "node_id": "MDExOlB1bGxSZXF1ZXN0MTg1Njc1NTIy", "number": 19053, "title": "Fix bug of declaring regularization loss multiple times when reusing PartitionedVariables in tf layers", "user": {"login": "wangsiyu", "id": 5387343, "node_id": "MDQ6VXNlcjUzODczNDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5387343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wangsiyu", "html_url": "https://github.com/wangsiyu", "followers_url": "https://api.github.com/users/wangsiyu/followers", "following_url": "https://api.github.com/users/wangsiyu/following{/other_user}", "gists_url": "https://api.github.com/users/wangsiyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/wangsiyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wangsiyu/subscriptions", "organizations_url": "https://api.github.com/users/wangsiyu/orgs", "repos_url": "https://api.github.com/users/wangsiyu/repos", "events_url": "https://api.github.com/users/wangsiyu/events{/privacy}", "received_events_url": "https://api.github.com/users/wangsiyu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 419840263, "node_id": "MDU6TGFiZWw0MTk4NDAyNjM=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20testing%20(then%20merge)", "name": "awaiting testing (then merge)", "color": "c2e0c6", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-05-03T10:34:39Z", "updated_at": "2018-05-09T07:33:21Z", "closed_at": "2018-05-08T19:38:57Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19053", "html_url": "https://github.com/tensorflow/tensorflow/pull/19053", "diff_url": "https://github.com/tensorflow/tensorflow/pull/19053.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/19053.patch"}, "body_html": "<p>When reusing a variable in current variable scope, we should always reuse its regularization loss computation. But it will declare regularization loss multiple times when reusing PartitionedVariables in tf.layers.  For example:</p>\n<pre><code>import tensorflow as tf\npartitioner = tf.fixed_size_partitioner(3)\nl2_regularizer = tf.contrib.layers.l2_regularizer(0.001)\nfor i in xrange(2):\n  with tf.variable_scope(tf.get_variable_scope(), partitioner=partitioner, reuse=False if i == 0 else True):\n    inputs_tensor = tf.constant(1.0, shape=[100, 100])\n    logits = tf.layers.dense(inputs_tensor, 256, use_bias=False, name=\"fc\", kernel_regularizer=l2_regularizer)\nprint (tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n</code></pre>\n<p>This short program should get result 3 because the PartitionedVariable has 3 shards. However, it got 6.  To debug the source code, we found that there is no judgement on PartitionedVariables when declaring the regularization loss in /tensorflow/python/layers/base.py</p>", "body_text": "When reusing a variable in current variable scope, we should always reuse its regularization loss computation. But it will declare regularization loss multiple times when reusing PartitionedVariables in tf.layers.  For example:\nimport tensorflow as tf\npartitioner = tf.fixed_size_partitioner(3)\nl2_regularizer = tf.contrib.layers.l2_regularizer(0.001)\nfor i in xrange(2):\n  with tf.variable_scope(tf.get_variable_scope(), partitioner=partitioner, reuse=False if i == 0 else True):\n    inputs_tensor = tf.constant(1.0, shape=[100, 100])\n    logits = tf.layers.dense(inputs_tensor, 256, use_bias=False, name=\"fc\", kernel_regularizer=l2_regularizer)\nprint (tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n\nThis short program should get result 3 because the PartitionedVariable has 3 shards. However, it got 6.  To debug the source code, we found that there is no judgement on PartitionedVariables when declaring the regularization loss in /tensorflow/python/layers/base.py", "body": "When reusing a variable in current variable scope, we should always reuse its regularization loss computation. But it will declare regularization loss multiple times when reusing PartitionedVariables in tf.layers.  For example:\r\n```\r\nimport tensorflow as tf\r\npartitioner = tf.fixed_size_partitioner(3)\r\nl2_regularizer = tf.contrib.layers.l2_regularizer(0.001)\r\nfor i in xrange(2):\r\n  with tf.variable_scope(tf.get_variable_scope(), partitioner=partitioner, reuse=False if i == 0 else True):\r\n    inputs_tensor = tf.constant(1.0, shape=[100, 100])\r\n    logits = tf.layers.dense(inputs_tensor, 256, use_bias=False, name=\"fc\", kernel_regularizer=l2_regularizer)\r\nprint (tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\r\n```\r\nThis short program should get result 3 because the PartitionedVariable has 3 shards. However, it got 6.  To debug the source code, we found that there is no judgement on PartitionedVariables when declaring the regularization loss in /tensorflow/python/layers/base.py"}