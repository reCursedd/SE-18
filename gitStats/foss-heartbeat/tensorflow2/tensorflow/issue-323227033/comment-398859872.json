{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/398859872", "html_url": "https://github.com/tensorflow/tensorflow/issues/19292#issuecomment-398859872", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19292", "id": 398859872, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODg1OTg3Mg==", "user": {"login": "pavithrasv", "id": 13326758, "node_id": "MDQ6VXNlcjEzMzI2NzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13326758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithrasv", "html_url": "https://github.com/pavithrasv", "followers_url": "https://api.github.com/users/pavithrasv/followers", "following_url": "https://api.github.com/users/pavithrasv/following{/other_user}", "gists_url": "https://api.github.com/users/pavithrasv/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithrasv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithrasv/subscriptions", "organizations_url": "https://api.github.com/users/pavithrasv/orgs", "repos_url": "https://api.github.com/users/pavithrasv/repos", "events_url": "https://api.github.com/users/pavithrasv/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithrasv/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-20T18:58:36Z", "updated_at": "2018-06-20T18:58:36Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2902390\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kirk86\">@kirk86</a> tf.layers can be used the same way as tf.keras layers and they will maintain the keras metadata.  For example, you can do:</p>\n<pre><code>      inputs = keras.Input(shape=(10,))\n      x = tf_core_layers.Dense(32, activation=nn.relu)(inputs)\n      outputs = tf_core_layers.Dense(2, activation=nn.softmax)(x)\n      model = keras.Model(inputs, outputs)\n</code></pre>\n<p>You are seeing an issue because of the way TimeDistributed layer has been initialized. TimeDistributed should be initialized with a <code>Layer</code> and not a tensor. It applies the wrapped layer to every timestep in the input sequences.</p>\n<pre><code>inputs = Input(shape=(5, 4)) # 5 =&gt; 5 timesteps\noutput = TimeDistributed(Dense(2))(inputs) # output of this layer will be (5, 2)\n</code></pre>\n<p>Please try after changing your code as follows:</p>\n<pre><code>tf.keras.layers.TimeDistributed(tf.layers.Conv2D(64, 3, padding='valid', activation=tf.nn.relu))(x) \n</code></pre>\n<p>We will improve the error message for this layer so that it is easier to identify the issue.</p>", "body_text": "@kirk86 tf.layers can be used the same way as tf.keras layers and they will maintain the keras metadata.  For example, you can do:\n      inputs = keras.Input(shape=(10,))\n      x = tf_core_layers.Dense(32, activation=nn.relu)(inputs)\n      outputs = tf_core_layers.Dense(2, activation=nn.softmax)(x)\n      model = keras.Model(inputs, outputs)\n\nYou are seeing an issue because of the way TimeDistributed layer has been initialized. TimeDistributed should be initialized with a Layer and not a tensor. It applies the wrapped layer to every timestep in the input sequences.\ninputs = Input(shape=(5, 4)) # 5 => 5 timesteps\noutput = TimeDistributed(Dense(2))(inputs) # output of this layer will be (5, 2)\n\nPlease try after changing your code as follows:\ntf.keras.layers.TimeDistributed(tf.layers.Conv2D(64, 3, padding='valid', activation=tf.nn.relu))(x) \n\nWe will improve the error message for this layer so that it is easier to identify the issue.", "body": "@kirk86 tf.layers can be used the same way as tf.keras layers and they will maintain the keras metadata.  For example, you can do:\r\n\r\n```\r\n      inputs = keras.Input(shape=(10,))\r\n      x = tf_core_layers.Dense(32, activation=nn.relu)(inputs)\r\n      outputs = tf_core_layers.Dense(2, activation=nn.softmax)(x)\r\n      model = keras.Model(inputs, outputs)\r\n```\r\nYou are seeing an issue because of the way TimeDistributed layer has been initialized. TimeDistributed should be initialized with a `Layer` and not a tensor. It applies the wrapped layer to every timestep in the input sequences. \r\n\r\n```\r\ninputs = Input(shape=(5, 4)) # 5 => 5 timesteps\r\noutput = TimeDistributed(Dense(2))(inputs) # output of this layer will be (5, 2)\r\n```\r\nPlease try after changing your code as follows:\r\n```\r\ntf.keras.layers.TimeDistributed(tf.layers.Conv2D(64, 3, padding='valid', activation=tf.nn.relu))(x) \r\n```\r\nWe will improve the error message for this layer so that it is easier to identify the issue.\r\n"}