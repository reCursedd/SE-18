{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3057", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3057/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3057/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3057/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3057", "id": 162432526, "node_id": "MDU6SXNzdWUxNjI0MzI1MjY=", "number": 3057, "title": "Use gpu_memory_fraction in while using distributed tensorflow", "user": {"login": "carpedm20", "id": 3346407, "node_id": "MDQ6VXNlcjMzNDY0MDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3346407?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carpedm20", "html_url": "https://github.com/carpedm20", "followers_url": "https://api.github.com/users/carpedm20/followers", "following_url": "https://api.github.com/users/carpedm20/following{/other_user}", "gists_url": "https://api.github.com/users/carpedm20/gists{/gist_id}", "starred_url": "https://api.github.com/users/carpedm20/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carpedm20/subscriptions", "organizations_url": "https://api.github.com/users/carpedm20/orgs", "repos_url": "https://api.github.com/users/carpedm20/repos", "events_url": "https://api.github.com/users/carpedm20/events{/privacy}", "received_events_url": "https://api.github.com/users/carpedm20/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2016-06-27T11:41:17Z", "updated_at": "2017-06-30T04:06:57Z", "closed_at": "2016-06-28T20:02:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p>While I'm implementing models in A3C, I tried to allocate a fraction of gpu to a process and processes that use multiple fractions of gpus update a parameters of a parameter server (in a single machine). For example, I want to create 12 workers with 3 gpus to update a master model.</p>\n<p>I referenced <a href=\"https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html\" rel=\"nofollow\">https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html</a> and used <code>tf.GPUOptions(per_process_gpu_memory_fraction=0.1)</code> but it doesn't work when we pass it to <code>sv.managed_session</code> (just take all of the memory of the first visible gpu).</p>\n<p>Also, I can't find how to give <code>GPUOptions</code> to parameter server that does not have session creation (I always pass <code>GPUoptions</code> to <code>tf.Session</code> which similar to <code>sv.managed_session</code>). <strong>How can I allocate a specific fraction of a gpu to each tasks including parameter server and workers?</strong></p>\n<p>Code can be found <a href=\"https://github.com/devsisters/DQN-tensorflow/blob/distributed/main.py#L78\">https://github.com/devsisters/DQN-tensorflow/blob/distributed/main.py#L78</a>.</p>", "body_text": "While I'm implementing models in A3C, I tried to allocate a fraction of gpu to a process and processes that use multiple fractions of gpus update a parameters of a parameter server (in a single machine). For example, I want to create 12 workers with 3 gpus to update a master model.\nI referenced https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html and used tf.GPUOptions(per_process_gpu_memory_fraction=0.1) but it doesn't work when we pass it to sv.managed_session (just take all of the memory of the first visible gpu).\nAlso, I can't find how to give GPUOptions to parameter server that does not have session creation (I always pass GPUoptions to tf.Session which similar to sv.managed_session). How can I allocate a specific fraction of a gpu to each tasks including parameter server and workers?\nCode can be found https://github.com/devsisters/DQN-tensorflow/blob/distributed/main.py#L78.", "body": "While I'm implementing models in A3C, I tried to allocate a fraction of gpu to a process and processes that use multiple fractions of gpus update a parameters of a parameter server (in a single machine). For example, I want to create 12 workers with 3 gpus to update a master model.\n\nI referenced https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html and used `tf.GPUOptions(per_process_gpu_memory_fraction=0.1)` but it doesn't work when we pass it to `sv.managed_session` (just take all of the memory of the first visible gpu).\n\nAlso, I can't find how to give `GPUOptions` to parameter server that does not have session creation (I always pass `GPUoptions` to `tf.Session` which similar to `sv.managed_session`). **How can I allocate a specific fraction of a gpu to each tasks including parameter server and workers?**\n\nCode can be found https://github.com/devsisters/DQN-tensorflow/blob/distributed/main.py#L78.\n"}