{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288364567", "html_url": "https://github.com/tensorflow/tensorflow/issues/7952#issuecomment-288364567", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7952", "id": 288364567, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODM2NDU2Nw==", "user": {"login": "dadib", "id": 3441636, "node_id": "MDQ6VXNlcjM0NDE2MzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/3441636?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dadib", "html_url": "https://github.com/dadib", "followers_url": "https://api.github.com/users/dadib/followers", "following_url": "https://api.github.com/users/dadib/following{/other_user}", "gists_url": "https://api.github.com/users/dadib/gists{/gist_id}", "starred_url": "https://api.github.com/users/dadib/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dadib/subscriptions", "organizations_url": "https://api.github.com/users/dadib/orgs", "repos_url": "https://api.github.com/users/dadib/repos", "events_url": "https://api.github.com/users/dadib/events{/privacy}", "received_events_url": "https://api.github.com/users/dadib/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-22T10:59:38Z", "updated_at": "2017-03-22T10:59:38Z", "author_association": "NONE", "body_html": "<p>I am running into the same issue and have reduced it to a minimal failing example.</p>\n<div class=\"highlight highlight-source-shell\"><pre>dbSpotify:<span class=\"pl-k\">~</span> dadi$ sw_vers\nProductName:\tMac OS X\nProductVersion:\t10.12\nBuildVersion:\t16A323</pre></div>\n<p>The problem seems to be in dynamic_rnn. When we unroll the network manually rather than use dynamic_rnn it works fine.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">define_graph</span>():\n    features <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">3</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>)\n    cell <span class=\"pl-k\">=</span> tf.contrib.rnn.BasicLSTMCell(<span class=\"pl-c1\">20</span>)\n    output, _ <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(cell, features, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    tf.identity(output, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Tensorflow version: <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> tf.<span class=\"pl-c1\">__version__</span>)\n    define_graph()\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run([tf.global_variables_initializer()])\n        in_graph_def <span class=\"pl-k\">=</span> tf.get_default_graph().as_graph_def()\n        out_graph_def <span class=\"pl-k\">=</span> tf.graph_util.convert_variables_to_constants(\n            sess, in_graph_def, [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>])\n\n    <span class=\"pl-k\">with</span> tf.gfile.GFile(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>frozen_model.pb<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>wb<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n        f.write(out_graph_def.SerializeToString())\n</pre></div>\n<div class=\"highlight highlight-source-shell\"><pre>dbSpotify:models dadi$ python example.py\nTensorflow version: 1.0.1\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn<span class=\"pl-s\"><span class=\"pl-pds\">'</span>t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.</span>\n<span class=\"pl-s\">W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn<span class=\"pl-pds\">'</span></span>t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn<span class=\"pl-s\"><span class=\"pl-pds\">'</span>t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.</span>\n<span class=\"pl-s\">W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn<span class=\"pl-pds\">'</span></span>t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn<span class=\"pl-s\"><span class=\"pl-pds\">'</span>t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.</span>\n<span class=\"pl-s\">Converted 2 variables to const ops.</span></pre></div>\n<p>Dowloaded jar / CPU-only native libs as per <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java\">instructions</a><br>\nLoading the model in java:</p>\n<div class=\"highlight highlight-source-java\"><pre><span class=\"pl-k\">package</span> <span class=\"pl-smi\">com.spotify</span>;\n\n<span class=\"pl-k\">import</span> <span class=\"pl-smi\">java.io.File</span>;\n<span class=\"pl-k\">import</span> <span class=\"pl-smi\">java.io.IOException</span>;\n<span class=\"pl-k\">import</span> <span class=\"pl-smi\">java.nio.file.Files</span>;\n<span class=\"pl-k\">import</span> <span class=\"pl-smi\">org.junit.Test</span>;\n<span class=\"pl-k\">import</span> <span class=\"pl-smi\">org.tensorflow.Graph</span>;\n\n<span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en\">TfModelLoadTest</span> {\n\n  <span class=\"pl-k\">@Test</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> <span class=\"pl-en\">testImportTfModel</span>() <span class=\"pl-k\">throws</span> <span class=\"pl-smi\">IOException</span> {\n    <span class=\"pl-k\">final</span> <span class=\"pl-smi\">File</span> modelFile <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">File</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>./frozen_model.pb<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"pl-k\">byte</span>[] graphDef <span class=\"pl-k\">=</span> <span class=\"pl-smi\">Files</span><span class=\"pl-k\">.</span>readAllBytes(modelFile<span class=\"pl-k\">.</span>toPath());\n    <span class=\"pl-smi\">Graph</span> graph <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">Graph</span>();\n    graph<span class=\"pl-k\">.</span>importGraphDef(graphDef);\n  }\n\n}\n</pre></div>\n<p>Leads to this <a href=\"https://gist.github.com/dadib/6270b70797997b0b0d9163cf4b8877ce\">error report</a></p>", "body_text": "I am running into the same issue and have reduced it to a minimal failing example.\ndbSpotify:~ dadi$ sw_vers\nProductName:\tMac OS X\nProductVersion:\t10.12\nBuildVersion:\t16A323\nThe problem seems to be in dynamic_rnn. When we unroll the network manually rather than use dynamic_rnn it works fine.\nimport tensorflow as tf\n\n\ndef define_graph():\n    features = tf.placeholder(tf.float32, [1, None, 3], name='input')\n    cell = tf.contrib.rnn.BasicLSTMCell(20)\n    output, _ = tf.nn.dynamic_rnn(cell, features, dtype=tf.float32)\n    tf.identity(output, name='output')\n\nif __name__ == '__main__':\n    print(\"Tensorflow version: \" + tf.__version__)\n    define_graph()\n    with tf.Session() as sess:\n        sess.run([tf.global_variables_initializer()])\n        in_graph_def = tf.get_default_graph().as_graph_def()\n        out_graph_def = tf.graph_util.convert_variables_to_constants(\n            sess, in_graph_def, ['output'])\n\n    with tf.gfile.GFile('frozen_model.pb', 'wb') as f:\n        f.write(out_graph_def.SerializeToString())\n\ndbSpotify:models dadi$ python example.py\nTensorflow version: 1.0.1\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nConverted 2 variables to const ops.\nDowloaded jar / CPU-only native libs as per instructions\nLoading the model in java:\npackage com.spotify;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport org.junit.Test;\nimport org.tensorflow.Graph;\n\npublic class TfModelLoadTest {\n\n  @Test\n  public void testImportTfModel() throws IOException {\n    final File modelFile = new File(\"./frozen_model.pb\");\n    byte[] graphDef = Files.readAllBytes(modelFile.toPath());\n    Graph graph = new Graph();\n    graph.importGraphDef(graphDef);\n  }\n\n}\n\nLeads to this error report", "body": "I am running into the same issue and have reduced it to a minimal failing example.\r\n```shell\r\ndbSpotify:~ dadi$ sw_vers\r\nProductName:\tMac OS X\r\nProductVersion:\t10.12\r\nBuildVersion:\t16A323\r\n```\r\n\r\nThe problem seems to be in dynamic_rnn. When we unroll the network manually rather than use dynamic_rnn it works fine.\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ndef define_graph():\r\n    features = tf.placeholder(tf.float32, [1, None, 3], name='input')\r\n    cell = tf.contrib.rnn.BasicLSTMCell(20)\r\n    output, _ = tf.nn.dynamic_rnn(cell, features, dtype=tf.float32)\r\n    tf.identity(output, name='output')\r\n\r\nif __name__ == '__main__':\r\n    print(\"Tensorflow version: \" + tf.__version__)\r\n    define_graph()\r\n    with tf.Session() as sess:\r\n        sess.run([tf.global_variables_initializer()])\r\n        in_graph_def = tf.get_default_graph().as_graph_def()\r\n        out_graph_def = tf.graph_util.convert_variables_to_constants(\r\n            sess, in_graph_def, ['output'])\r\n\r\n    with tf.gfile.GFile('frozen_model.pb', 'wb') as f:\r\n        f.write(out_graph_def.SerializeToString())\r\n\r\n```\r\n\r\n```shell\r\ndbSpotify:models dadi$ python example.py\r\nTensorflow version: 1.0.1\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nConverted 2 variables to const ops.\r\n```\r\nDowloaded jar / CPU-only native libs as per [instructions](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java)\r\nLoading the model in java:\r\n```java\r\npackage com.spotify;\r\n\r\nimport java.io.File;\r\nimport java.io.IOException;\r\nimport java.nio.file.Files;\r\nimport org.junit.Test;\r\nimport org.tensorflow.Graph;\r\n\r\npublic class TfModelLoadTest {\r\n\r\n  @Test\r\n  public void testImportTfModel() throws IOException {\r\n    final File modelFile = new File(\"./frozen_model.pb\");\r\n    byte[] graphDef = Files.readAllBytes(modelFile.toPath());\r\n    Graph graph = new Graph();\r\n    graph.importGraphDef(graphDef);\r\n  }\r\n\r\n}\r\n\r\n```\r\n\r\nLeads to this [error report](https://gist.github.com/dadib/6270b70797997b0b0d9163cf4b8877ce)\r\n\r\n\r\n\r\n\r\n\r\n\r\n"}