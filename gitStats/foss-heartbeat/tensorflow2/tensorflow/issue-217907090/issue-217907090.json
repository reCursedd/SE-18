{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8805", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8805/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8805/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8805/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8805", "id": 217907090, "node_id": "MDU6SXNzdWUyMTc5MDcwOTA=", "number": 8805, "title": "valgrind helloworld.py throws 7805 errors", "user": {"login": "lobachevzky", "id": 10344742, "node_id": "MDQ6VXNlcjEwMzQ0NzQy", "avatar_url": "https://avatars2.githubusercontent.com/u/10344742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lobachevzky", "html_url": "https://github.com/lobachevzky", "followers_url": "https://api.github.com/users/lobachevzky/followers", "following_url": "https://api.github.com/users/lobachevzky/following{/other_user}", "gists_url": "https://api.github.com/users/lobachevzky/gists{/gist_id}", "starred_url": "https://api.github.com/users/lobachevzky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lobachevzky/subscriptions", "organizations_url": "https://api.github.com/users/lobachevzky/orgs", "repos_url": "https://api.github.com/users/lobachevzky/repos", "events_url": "https://api.github.com/users/lobachevzky/events{/privacy}", "received_events_url": "https://api.github.com/users/lobachevzky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-03-29T15:04:05Z", "updated_at": "2017-06-17T00:37:23Z", "closed_at": "2017-06-16T21:05:02Z", "author_association": "NONE", "body_html": "<p>NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.</p>\n<p>For general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>Several issues report memory leaks, but only for specific uses of Tensorflow:<br>\n<a href=\"https://raw.githubusercontent.com/aymericdamien/TensorFlow-Examples/master/examples/1_Introduction/helloworld.py\" rel=\"nofollow\">https://raw.githubusercontent.com/aymericdamien/TensorFlow-Examples/master/examples/1_Introduction/helloworld.py</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"125054784\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/700\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/700/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/700\">#700</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"174493965\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4151\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4151/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4151\">#4151</a><br>\n<a href=\"http://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session\" rel=\"nofollow\">http://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session</a></p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nLinux, Ubuntu 14.04</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<pre><code>\u276f ls -l /usr/local/cuda-8.0/lib64/libcud*\n-rw-r--r-- 1 root root   556000 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Jan 26 18:51 /usr/local/cuda-8.0/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Jan 26 18:51 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.61\n-rw-r--r-- 1 root root   415432 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n-rw-r--r-- 1 root root   775162 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so -&gt; libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 79337624 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n</code></pre>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>\n<p>A link to the pip package you installed:<br>\n<code>pip install tensorflow</code></p>\n</li>\n<li>\n<p>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</p>\n</li>\n</ol>\n<pre><code>(env) \u276f python -c \"import tensorflow; print(tensorflow.__version__)\"\n1.0.1\n</code></pre>\n<p>If installed from source, provide<br>\n<strong>I'm listing both because I encountered the problem using both source and pip package.</strong></p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)</li>\n</ol>\n<pre><code>~/tensorflow r1.0*\n\u276f git rev-parse HEAD\ne895d5ca395c2362df4f5c8f08b68501b41f8a98\n\n</code></pre>\n<ol start=\"2\">\n<li>The output of <code>bazel version</code></li>\n</ol>\n<pre><code>\u276f bazel version\n............\nBuild label: 0.4.4\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\nBuild timestamp: 1485975261\nBuild timestamp as int: 1485975261\n</code></pre>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<pre><code>valgrind python helloworld.py\n</code></pre>\n<p>Here, <code>helloworld.py</code> refers to <a href=\"https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/1_Introduction/helloworld.py\">https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/1_Introduction/helloworld.py</a>.</p>\n<p>While there are certain cases in which memory violations are not a problem, I am trying to track down a segfault from using Tensorflow with Ros and Gazebo. It's very difficult to know whether one of the memory issues already present in Tensorflow is  responsible.</p>\n<p>Final summary is as follows:</p>\n<pre><code>==18112== HEAP SUMMARY:\n==18112==     in use at exit: 8,356,021 bytes in 99,634 blocks\n==18112==   total heap usage: 775,798 allocs, 676,164 frees, 352,616,777 bytes allocated\n==18112== \n==18112== LEAK SUMMARY:\n==18112==    definitely lost: 154,618 bytes in 82 blocks\n==18112==    indirectly lost: 0 bytes in 0 blocks\n==18112==      possibly lost: 1,745,007 bytes in 32,420 blocks\n==18112==    still reachable: 6,456,396 bytes in 67,132 blocks\n==18112==         suppressed: 0 bytes in 0 blocks\n==18112== Rerun with --leak-check=full to see details of leaked memory\n==18112== \n==18112== For counts of detected and suppressed errors, rerun with: -v\n==18112== Use --track-origins=yes to see where uninitialised values come from\n==18112== ERROR SUMMARY: 7713 errors from 159 contexts (suppressed: 0 from 0)\n</code></pre>\n<h3>What other attempted solutions have you tried?</h3>\n<p>None.</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).<br>\nThis <a href=\"https://gist.github.com/lobachevzky/0a7319f9cb5df23e32c1cc173210e768\">gist</a> contains the full output of <code>valgrind python helloworld.py</code>.</p>", "body_text": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nSeveral issues report memory leaks, but only for specific uses of Tensorflow:\nhttps://raw.githubusercontent.com/aymericdamien/TensorFlow-Examples/master/examples/1_Introduction/helloworld.py\n#700\n#4151\nhttp://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session\nEnvironment info\nOperating System:\nLinux, Ubuntu 14.04\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n\u276f ls -l /usr/local/cuda-8.0/lib64/libcud*\n-rw-r--r-- 1 root root   556000 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Jan 26 18:51 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Jan 26 18:51 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\n-rw-r--r-- 1 root root   415432 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n-rw-r--r-- 1 root root   775162 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 79337624 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n\n\nA link to the pip package you installed:\npip install tensorflow\n\n\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\n\n(env) \u276f python -c \"import tensorflow; print(tensorflow.__version__)\"\n1.0.1\n\nIf installed from source, provide\nI'm listing both because I encountered the problem using both source and pip package.\n\nThe commit hash (git rev-parse HEAD)\n\n~/tensorflow r1.0*\n\u276f git rev-parse HEAD\ne895d5ca395c2362df4f5c8f08b68501b41f8a98\n\n\n\nThe output of bazel version\n\n\u276f bazel version\n............\nBuild label: 0.4.4\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\nBuild timestamp: 1485975261\nBuild timestamp as int: 1485975261\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nvalgrind python helloworld.py\n\nHere, helloworld.py refers to https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/1_Introduction/helloworld.py.\nWhile there are certain cases in which memory violations are not a problem, I am trying to track down a segfault from using Tensorflow with Ros and Gazebo. It's very difficult to know whether one of the memory issues already present in Tensorflow is  responsible.\nFinal summary is as follows:\n==18112== HEAP SUMMARY:\n==18112==     in use at exit: 8,356,021 bytes in 99,634 blocks\n==18112==   total heap usage: 775,798 allocs, 676,164 frees, 352,616,777 bytes allocated\n==18112== \n==18112== LEAK SUMMARY:\n==18112==    definitely lost: 154,618 bytes in 82 blocks\n==18112==    indirectly lost: 0 bytes in 0 blocks\n==18112==      possibly lost: 1,745,007 bytes in 32,420 blocks\n==18112==    still reachable: 6,456,396 bytes in 67,132 blocks\n==18112==         suppressed: 0 bytes in 0 blocks\n==18112== Rerun with --leak-check=full to see details of leaked memory\n==18112== \n==18112== For counts of detected and suppressed errors, rerun with: -v\n==18112== Use --track-origins=yes to see where uninitialised values come from\n==18112== ERROR SUMMARY: 7713 errors from 159 contexts (suppressed: 0 from 0)\n\nWhat other attempted solutions have you tried?\nNone.\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\nThis gist contains the full output of valgrind python helloworld.py.", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nSeveral issues report memory leaks, but only for specific uses of Tensorflow:\r\nhttps://raw.githubusercontent.com/aymericdamien/TensorFlow-Examples/master/examples/1_Introduction/helloworld.py\r\nhttps://github.com/tensorflow/tensorflow/issues/700\r\nhttps://github.com/tensorflow/tensorflow/issues/4151\r\nhttp://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session\r\n\r\n### Environment info\r\nOperating System:\r\nLinux, Ubuntu 14.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n```\r\n\u276f ls -l /usr/local/cuda-8.0/lib64/libcud*\r\n-rw-r--r-- 1 root root   556000 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Jan 26 18:51 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Jan 26 18:51 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n-rw-r--r-- 1 root root   415432 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n-rw-r--r-- 1 root root   775162 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 79337624 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n`pip install tensorflow`\r\n\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\n(env) \u276f python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n1.0.1\r\n```\r\n\r\nIf installed from source, provide \r\n**I'm listing both because I encountered the problem using both source and pip package.**\r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n```\r\n~/tensorflow r1.0*\r\n\u276f git rev-parse HEAD\r\ne895d5ca395c2362df4f5c8f08b68501b41f8a98\r\n\r\n```\r\n\r\n2. The output of `bazel version`\r\n```\r\n\u276f bazel version\r\n............\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```\r\nvalgrind python helloworld.py\r\n```\r\nHere, `helloworld.py` refers to https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/1_Introduction/helloworld.py.\r\n\r\nWhile there are certain cases in which memory violations are not a problem, I am trying to track down a segfault from using Tensorflow with Ros and Gazebo. It's very difficult to know whether one of the memory issues already present in Tensorflow is  responsible.\r\n\r\nFinal summary is as follows:\r\n```\r\n==18112== HEAP SUMMARY:\r\n==18112==     in use at exit: 8,356,021 bytes in 99,634 blocks\r\n==18112==   total heap usage: 775,798 allocs, 676,164 frees, 352,616,777 bytes allocated\r\n==18112== \r\n==18112== LEAK SUMMARY:\r\n==18112==    definitely lost: 154,618 bytes in 82 blocks\r\n==18112==    indirectly lost: 0 bytes in 0 blocks\r\n==18112==      possibly lost: 1,745,007 bytes in 32,420 blocks\r\n==18112==    still reachable: 6,456,396 bytes in 67,132 blocks\r\n==18112==         suppressed: 0 bytes in 0 blocks\r\n==18112== Rerun with --leak-check=full to see details of leaked memory\r\n==18112== \r\n==18112== For counts of detected and suppressed errors, rerun with: -v\r\n==18112== Use --track-origins=yes to see where uninitialised values come from\r\n==18112== ERROR SUMMARY: 7713 errors from 159 contexts (suppressed: 0 from 0)\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\nNone.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\nThis [gist](https://gist.github.com/lobachevzky/0a7319f9cb5df23e32c1cc173210e768) contains the full output of `valgrind python helloworld.py`.\r\n"}