{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12987", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12987/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12987/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12987/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/12987", "id": 256903481, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQwNDc4Nzc3", "number": 12987, "title": "fix ExponentialMovingAverage documentation regarding control_dependencies", "user": {"login": "kjslag", "id": 233837, "node_id": "MDQ6VXNlcjIzMzgzNw==", "avatar_url": "https://avatars1.githubusercontent.com/u/233837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kjslag", "html_url": "https://github.com/kjslag", "followers_url": "https://api.github.com/users/kjslag/followers", "following_url": "https://api.github.com/users/kjslag/following{/other_user}", "gists_url": "https://api.github.com/users/kjslag/gists{/gist_id}", "starred_url": "https://api.github.com/users/kjslag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kjslag/subscriptions", "organizations_url": "https://api.github.com/users/kjslag/orgs", "repos_url": "https://api.github.com/users/kjslag/repos", "events_url": "https://api.github.com/users/kjslag/events{/privacy}", "received_events_url": "https://api.github.com/users/kjslag/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-12T03:06:44Z", "updated_at": "2017-09-12T17:30:18Z", "closed_at": "2017-09-12T17:24:19Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12987", "html_url": "https://github.com/tensorflow/tensorflow/pull/12987", "diff_url": "https://github.com/tensorflow/tensorflow/pull/12987.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/12987.patch"}, "body_html": "<p>This PR fixes the documentation for ExponentialMovingAverage so that <code>ema.apply([var0, var1])</code> is evaluated within <code>tf.control_dependencies([opt_op])</code>.</p>\n<p>The documentation for <a href=\"https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\" rel=\"nofollow\"><code>ExponentialMovingAverage</code></a> contains the following code:</p>\n<div class=\"highlight highlight-source-python\"><pre>var0 <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">...</span>)\nvar1 <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">...</span>)\nopt_op <span class=\"pl-k\">=</span> opt.minimize(my_loss, [var0, var1])\nema <span class=\"pl-k\">=</span> tf.train.ExponentialMovingAverage(<span class=\"pl-v\">decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.9999</span>)\n\nmaintain_averages_op <span class=\"pl-k\">=</span> ema.apply([var0, var1])\n<span class=\"pl-k\">with</span> tf.control_dependencies([opt_op]):\n    training_op <span class=\"pl-k\">=</span> tf.group(maintain_averages_op)</pre></div>\n<p>However, according to my understanding, the last three lines are actually equivalent to</p>\n<div class=\"highlight highlight-source-python\"><pre>maintain_averages_op <span class=\"pl-k\">=</span> ema.apply([var0, var1])\ntraining_op <span class=\"pl-k\">=</span> tf.group(opt_op, maintain_averages_op)</pre></div>\n<p>for which the evaluation order of <code>opt_op</code> and <code>maintain_averages_op</code> is undefined.<br>\nI think the last three lines should be replaced with</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> tf.control_dependencies([opt_op]):\n    training_op <span class=\"pl-k\">=</span> ema.apply([var0, var1])</pre></div>\n<p>so that <code>opt_op</code> is evaluated before <code>ema.apply([var0, var1])</code>, which is what the current documentation is suggestive of. This PR makes this correction.</p>\n<p>This issue was previously brought up in P.S. in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"151421563\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2131\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2131/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2131\">#2131</a>, but was ignored because it was posed as a question more appropriate for StackOverflow.</p>\n<p>It is easy to test that this makes a difference. Below we calculate the moving average of a variable that gets incremented by 1 for each step. We do this 5 times using 5 different sessions. When <code>follow_doc = True</code>, we follow the current documentation's example and each of the 5 sessions returns a different moving average (on my computer). However, the moving averages should all be the same, which is achieved using <code>follow_doc = False</code>, which instead follows the (correct) documentation written in this PR.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\nfollow_doc <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\navgs <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">5</span>):\n    var <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">0</span>., <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    ema <span class=\"pl-k\">=</span> tf.train.ExponentialMovingAverage(<span class=\"pl-v\">decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.75</span>)\n    opt_op <span class=\"pl-k\">=</span> var.assign_add(<span class=\"pl-c1\">1</span>)\n    <span class=\"pl-k\">if</span> follow_doc:\n        maintain_averages_op <span class=\"pl-k\">=</span> ema.apply([var])\n        <span class=\"pl-k\">with</span> tf.control_dependencies([opt_op]):\n            training_op <span class=\"pl-k\">=</span> tf.group(maintain_averages_op)\n    <span class=\"pl-k\">else</span>:\n        <span class=\"pl-k\">with</span> tf.control_dependencies([opt_op]):\n            training_op <span class=\"pl-k\">=</span> ema.apply([var])\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(tf.global_variables_initializer())\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n            sess.run(training_op)\n        avgs.append(sess.run(ema.average(var)))\n<span class=\"pl-c1\">print</span>(avgs)</pre></div>", "body_text": "This PR fixes the documentation for ExponentialMovingAverage so that ema.apply([var0, var1]) is evaluated within tf.control_dependencies([opt_op]).\nThe documentation for ExponentialMovingAverage contains the following code:\nvar0 = tf.Variable(...)\nvar1 = tf.Variable(...)\nopt_op = opt.minimize(my_loss, [var0, var1])\nema = tf.train.ExponentialMovingAverage(decay=0.9999)\n\nmaintain_averages_op = ema.apply([var0, var1])\nwith tf.control_dependencies([opt_op]):\n    training_op = tf.group(maintain_averages_op)\nHowever, according to my understanding, the last three lines are actually equivalent to\nmaintain_averages_op = ema.apply([var0, var1])\ntraining_op = tf.group(opt_op, maintain_averages_op)\nfor which the evaluation order of opt_op and maintain_averages_op is undefined.\nI think the last three lines should be replaced with\nwith tf.control_dependencies([opt_op]):\n    training_op = ema.apply([var0, var1])\nso that opt_op is evaluated before ema.apply([var0, var1]), which is what the current documentation is suggestive of. This PR makes this correction.\nThis issue was previously brought up in P.S. in #2131, but was ignored because it was posed as a question more appropriate for StackOverflow.\nIt is easy to test that this makes a difference. Below we calculate the moving average of a variable that gets incremented by 1 for each step. We do this 5 times using 5 different sessions. When follow_doc = True, we follow the current documentation's example and each of the 5 sessions returns a different moving average (on my computer). However, the moving averages should all be the same, which is achieved using follow_doc = False, which instead follows the (correct) documentation written in this PR.\nimport tensorflow as tf\nfollow_doc = True\navgs = []\nfor i in range(5):\n    var = tf.Variable(0., dtype=tf.float32)\n    ema = tf.train.ExponentialMovingAverage(decay=0.75)\n    opt_op = var.assign_add(1)\n    if follow_doc:\n        maintain_averages_op = ema.apply([var])\n        with tf.control_dependencies([opt_op]):\n            training_op = tf.group(maintain_averages_op)\n    else:\n        with tf.control_dependencies([opt_op]):\n            training_op = ema.apply([var])\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        for i in range(10):\n            sess.run(training_op)\n        avgs.append(sess.run(ema.average(var)))\nprint(avgs)", "body": "This PR fixes the documentation for ExponentialMovingAverage so that `ema.apply([var0, var1])` is evaluated within `tf.control_dependencies([opt_op])`.\r\n\r\nThe documentation for [`ExponentialMovingAverage`](https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage) contains the following code:\r\n```python\r\nvar0 = tf.Variable(...)\r\nvar1 = tf.Variable(...)\r\nopt_op = opt.minimize(my_loss, [var0, var1])\r\nema = tf.train.ExponentialMovingAverage(decay=0.9999)\r\n\r\nmaintain_averages_op = ema.apply([var0, var1])\r\nwith tf.control_dependencies([opt_op]):\r\n    training_op = tf.group(maintain_averages_op)\r\n```\r\nHowever, according to my understanding, the last three lines are actually equivalent to\r\n```python\r\nmaintain_averages_op = ema.apply([var0, var1])\r\ntraining_op = tf.group(opt_op, maintain_averages_op)\r\n```\r\nfor which the evaluation order of `opt_op` and `maintain_averages_op` is undefined.\r\nI think the last three lines should be replaced with\r\n```python\r\nwith tf.control_dependencies([opt_op]):\r\n    training_op = ema.apply([var0, var1])\r\n```\r\nso that `opt_op` is evaluated before `ema.apply([var0, var1])`, which is what the current documentation is suggestive of. This PR makes this correction.\r\n\r\nThis issue was previously brought up in P.S. in #2131, but was ignored because it was posed as a question more appropriate for StackOverflow.\r\n\r\nIt is easy to test that this makes a difference. Below we calculate the moving average of a variable that gets incremented by 1 for each step. We do this 5 times using 5 different sessions. When `follow_doc = True`, we follow the current documentation's example and each of the 5 sessions returns a different moving average (on my computer). However, the moving averages should all be the same, which is achieved using `follow_doc = False`, which instead follows the (correct) documentation written in this PR.\r\n```python\r\nimport tensorflow as tf\r\nfollow_doc = True\r\navgs = []\r\nfor i in range(5):\r\n    var = tf.Variable(0., dtype=tf.float32)\r\n    ema = tf.train.ExponentialMovingAverage(decay=0.75)\r\n    opt_op = var.assign_add(1)\r\n    if follow_doc:\r\n        maintain_averages_op = ema.apply([var])\r\n        with tf.control_dependencies([opt_op]):\r\n            training_op = tf.group(maintain_averages_op)\r\n    else:\r\n        with tf.control_dependencies([opt_op]):\r\n            training_op = ema.apply([var])\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        for i in range(10):\r\n            sess.run(training_op)\r\n        avgs.append(sess.run(ema.average(var)))\r\nprint(avgs)\r\n```"}