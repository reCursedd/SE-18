{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23455", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23455/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23455/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23455/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23455", "id": 376845843, "node_id": "MDU6SXNzdWUzNzY4NDU4NDM=", "number": 23455, "title": "Excessive MKL memory consumption with variable sized tensors", "user": {"login": "mavrov", "id": 31657104, "node_id": "MDQ6VXNlcjMxNjU3MTA0", "avatar_url": "https://avatars1.githubusercontent.com/u/31657104?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mavrov", "html_url": "https://github.com/mavrov", "followers_url": "https://api.github.com/users/mavrov/followers", "following_url": "https://api.github.com/users/mavrov/following{/other_user}", "gists_url": "https://api.github.com/users/mavrov/gists{/gist_id}", "starred_url": "https://api.github.com/users/mavrov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mavrov/subscriptions", "organizations_url": "https://api.github.com/users/mavrov/orgs", "repos_url": "https://api.github.com/users/mavrov/repos", "events_url": "https://api.github.com/users/mavrov/events{/privacy}", "received_events_url": "https://api.github.com/users/mavrov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1104829434, "node_id": "MDU6TGFiZWwxMTA0ODI5NDM0", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:mkl", "name": "comp:mkl", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "TensorFlow-MKL", "id": 44416303, "node_id": "MDQ6VXNlcjQ0NDE2MzAz", "avatar_url": "https://avatars2.githubusercontent.com/u/44416303?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TensorFlow-MKL", "html_url": "https://github.com/TensorFlow-MKL", "followers_url": "https://api.github.com/users/TensorFlow-MKL/followers", "following_url": "https://api.github.com/users/TensorFlow-MKL/following{/other_user}", "gists_url": "https://api.github.com/users/TensorFlow-MKL/gists{/gist_id}", "starred_url": "https://api.github.com/users/TensorFlow-MKL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TensorFlow-MKL/subscriptions", "organizations_url": "https://api.github.com/users/TensorFlow-MKL/orgs", "repos_url": "https://api.github.com/users/TensorFlow-MKL/repos", "events_url": "https://api.github.com/users/TensorFlow-MKL/events{/privacy}", "received_events_url": "https://api.github.com/users/TensorFlow-MKL/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "TensorFlow-MKL", "id": 44416303, "node_id": "MDQ6VXNlcjQ0NDE2MzAz", "avatar_url": "https://avatars2.githubusercontent.com/u/44416303?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TensorFlow-MKL", "html_url": "https://github.com/TensorFlow-MKL", "followers_url": "https://api.github.com/users/TensorFlow-MKL/followers", "following_url": "https://api.github.com/users/TensorFlow-MKL/following{/other_user}", "gists_url": "https://api.github.com/users/TensorFlow-MKL/gists{/gist_id}", "starred_url": "https://api.github.com/users/TensorFlow-MKL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TensorFlow-MKL/subscriptions", "organizations_url": "https://api.github.com/users/TensorFlow-MKL/orgs", "repos_url": "https://api.github.com/users/TensorFlow-MKL/repos", "events_url": "https://api.github.com/users/TensorFlow-MKL/events{/privacy}", "received_events_url": "https://api.github.com/users/TensorFlow-MKL/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-11-02T15:00:58Z", "updated_at": "2018-11-15T07:01:26Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A</li>\n<li>TensorFlow installed from (source or binary): Both source and binary</li>\n<li>TensorFlow version (use command below): 1.11.0</li>\n<li>Python version: 3.5.2</li>\n<li>Bazel version (if compiling from source): 0.15.0</li>\n<li>GCC/Compiler version (if compiling from source): gcc 5.4.0</li>\n<li>CUDA/cuDNN version: N/A</li>\n<li>GPU model and memory: N/A</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nDuring inference of variable sized examples with Tensorflow MKL system memory consumption gradually increases.<br>\nIf a server application is running long enough to go through a lot of examples of same rank but different shapes it would eventually run out of system memory.<br>\nAfter further investigation setting the <a href=\"https://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/core/util/mkl_util.h#L2041\">TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE</a> to either 0 or 1 does not help.<br>\nMost MKL primitive factories ignore TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE and even some that know about it may choose to ignore it based on other heuristics like <a href=\"https://github.com/tensorflow/tensorflow/commit/86d9ce130c5691cdba16024f7cc7987082acd294#diff-192dfeafbdd684934bdb0dfa8983674a\">batches smaller than 32</a> for example (I am not sure this is intended behavior).<br>\nThese <a href=\"https://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/core/kernels/mkl_conv_ops.cc#L902\">\"do_not_cache\" heuristics</a> on the other hand don't seem to follow the described logic in the comments above replacing \"or\" for \"and\".</p>\n<p><strong>Describe the expected behavior</strong><br>\nThere should be a way to disable MKL primitive memory reuse globally with an environment variable be it TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE or better yet something else.<br>\nPrimitive memory reuse does not play nice with unknown tensor sizes as most of the time there are no cache hits and allocated memory is simply piled up in the cache.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nI've attached a small example.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2542973/min-leak-example.txt\">min-leak-example.txt</a></p>\n<p><strong>Other info / logs</strong><br>\nI've attached Valgrind results of the example running on TF version 1.11.0 with and without MKL.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2542977/min-leak-example-mkl.txt\">min-leak-example-mkl.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2542978/min-leak-example-no-mkl.txt\">min-leak-example-no-mkl.txt</a></p>\n<p>I've been working on a solution I can propose.<br>\nShould you find it reasonable I've extended the solution to full refactoring of the MKL primitive factories.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): Both source and binary\nTensorFlow version (use command below): 1.11.0\nPython version: 3.5.2\nBazel version (if compiling from source): 0.15.0\nGCC/Compiler version (if compiling from source): gcc 5.4.0\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\n\nDescribe the current behavior\nDuring inference of variable sized examples with Tensorflow MKL system memory consumption gradually increases.\nIf a server application is running long enough to go through a lot of examples of same rank but different shapes it would eventually run out of system memory.\nAfter further investigation setting the TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE to either 0 or 1 does not help.\nMost MKL primitive factories ignore TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE and even some that know about it may choose to ignore it based on other heuristics like batches smaller than 32 for example (I am not sure this is intended behavior).\nThese \"do_not_cache\" heuristics on the other hand don't seem to follow the described logic in the comments above replacing \"or\" for \"and\".\nDescribe the expected behavior\nThere should be a way to disable MKL primitive memory reuse globally with an environment variable be it TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE or better yet something else.\nPrimitive memory reuse does not play nice with unknown tensor sizes as most of the time there are no cache hits and allocated memory is simply piled up in the cache.\nCode to reproduce the issue\nI've attached a small example.\nmin-leak-example.txt\nOther info / logs\nI've attached Valgrind results of the example running on TF version 1.11.0 with and without MKL.\nmin-leak-example-mkl.txt\nmin-leak-example-no-mkl.txt\nI've been working on a solution I can propose.\nShould you find it reasonable I've extended the solution to full refactoring of the MKL primitive factories.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Both source and binary\r\n- TensorFlow version (use command below): 1.11.0\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source): 0.15.0\r\n- GCC/Compiler version (if compiling from source): gcc 5.4.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nDuring inference of variable sized examples with Tensorflow MKL system memory consumption gradually increases.\r\nIf a server application is running long enough to go through a lot of examples of same rank but different shapes it would eventually run out of system memory.\r\nAfter further investigation setting the [TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE](https://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/core/util/mkl_util.h#L2041) to either 0 or 1 does not help.\r\nMost MKL primitive factories ignore TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE and even some that know about it may choose to ignore it based on other heuristics like [batches smaller than 32](https://github.com/tensorflow/tensorflow/commit/86d9ce130c5691cdba16024f7cc7987082acd294#diff-192dfeafbdd684934bdb0dfa8983674a) for example (I am not sure this is intended behavior).\r\nThese [\"do_not_cache\" heuristics](https://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/core/kernels/mkl_conv_ops.cc#L902\r\n) on the other hand don't seem to follow the described logic in the comments above replacing \"or\" for \"and\".\r\n\r\n**Describe the expected behavior**\r\nThere should be a way to disable MKL primitive memory reuse globally with an environment variable be it TF_MKL_OPTIMIZE_PRIMITVE_MEMUSE or better yet something else.\r\nPrimitive memory reuse does not play nice with unknown tensor sizes as most of the time there are no cache hits and allocated memory is simply piled up in the cache.\r\n\r\n**Code to reproduce the issue**\r\nI've attached a small example.\r\n[min-leak-example.txt](https://github.com/tensorflow/tensorflow/files/2542973/min-leak-example.txt)\r\n\r\n**Other info / logs**\r\nI've attached Valgrind results of the example running on TF version 1.11.0 with and without MKL.\r\n[min-leak-example-mkl.txt](https://github.com/tensorflow/tensorflow/files/2542977/min-leak-example-mkl.txt)\r\n[min-leak-example-no-mkl.txt](https://github.com/tensorflow/tensorflow/files/2542978/min-leak-example-no-mkl.txt)\r\n\r\nI've been working on a solution I can propose.\r\nShould you find it reasonable I've extended the solution to full refactoring of the MKL primitive factories."}