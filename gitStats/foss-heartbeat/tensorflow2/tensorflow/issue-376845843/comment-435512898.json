{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/435512898", "html_url": "https://github.com/tensorflow/tensorflow/issues/23455#issuecomment-435512898", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23455", "id": 435512898, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTUxMjg5OA==", "user": {"login": "gzmkl", "id": 29215195, "node_id": "MDQ6VXNlcjI5MjE1MTk1", "avatar_url": "https://avatars0.githubusercontent.com/u/29215195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gzmkl", "html_url": "https://github.com/gzmkl", "followers_url": "https://api.github.com/users/gzmkl/followers", "following_url": "https://api.github.com/users/gzmkl/following{/other_user}", "gists_url": "https://api.github.com/users/gzmkl/gists{/gist_id}", "starred_url": "https://api.github.com/users/gzmkl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gzmkl/subscriptions", "organizations_url": "https://api.github.com/users/gzmkl/orgs", "repos_url": "https://api.github.com/users/gzmkl/repos", "events_url": "https://api.github.com/users/gzmkl/events{/privacy}", "received_events_url": "https://api.github.com/users/gzmkl/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-02T21:21:25Z", "updated_at": "2018-11-02T21:21:25Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Just for trouble-shooting purpose, please experiment by hard-coding<br>\ndo_not_cache = true;     (comment out existing logic).</p>\n<p>My initial feeling is that more and more MKL primitive caching due to new op input dimensions (thus new keys), so that the memory usage is going higher and higher (that is, the feeling of leakage).</p>\n<p>Of cause, this is just a guess. To confirm it, do the hard-coding experiment on all do_not_cache<br>\noccurrences (in files of mkl*.cc in folder tensorflow/core/kernels).</p>\n<p>Thanks!</p>", "body_text": "Just for trouble-shooting purpose, please experiment by hard-coding\ndo_not_cache = true;     (comment out existing logic).\nMy initial feeling is that more and more MKL primitive caching due to new op input dimensions (thus new keys), so that the memory usage is going higher and higher (that is, the feeling of leakage).\nOf cause, this is just a guess. To confirm it, do the hard-coding experiment on all do_not_cache\noccurrences (in files of mkl*.cc in folder tensorflow/core/kernels).\nThanks!", "body": "Just for trouble-shooting purpose, please experiment by hard-coding \r\n do_not_cache = true;     (comment out existing logic). \r\n\r\nMy initial feeling is that more and more MKL primitive caching due to new op input dimensions (thus new keys), so that the memory usage is going higher and higher (that is, the feeling of leakage). \r\n\r\nOf cause, this is just a guess. To confirm it, do the hard-coding experiment on all do_not_cache \r\noccurrences (in files of mkl*.cc in folder tensorflow/core/kernels). \r\n\r\nThanks!"}