{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/438653555", "html_url": "https://github.com/tensorflow/tensorflow/issues/23455#issuecomment-438653555", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23455", "id": 438653555, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODY1MzU1NQ==", "user": {"login": "vignesh-irtt", "id": 18422526, "node_id": "MDQ6VXNlcjE4NDIyNTI2", "avatar_url": "https://avatars3.githubusercontent.com/u/18422526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vignesh-irtt", "html_url": "https://github.com/vignesh-irtt", "followers_url": "https://api.github.com/users/vignesh-irtt/followers", "following_url": "https://api.github.com/users/vignesh-irtt/following{/other_user}", "gists_url": "https://api.github.com/users/vignesh-irtt/gists{/gist_id}", "starred_url": "https://api.github.com/users/vignesh-irtt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vignesh-irtt/subscriptions", "organizations_url": "https://api.github.com/users/vignesh-irtt/orgs", "repos_url": "https://api.github.com/users/vignesh-irtt/repos", "events_url": "https://api.github.com/users/vignesh-irtt/events{/privacy}", "received_events_url": "https://api.github.com/users/vignesh-irtt/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-14T13:00:01Z", "updated_at": "2018-11-14T13:00:01Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>The problem is that there are a lot of primitive reuse cases and not all factories even have an option to turn caching off. In TF 1.9 turning the cache off for the convolution should be enough but in later versions the caching is becoming widely adopted in other operations as well and very few can be turned off. My proposed solution introduces a new environment variable with a default value that preserves current behaviour for backwards compatibility. It changes all factories so that they take this new variable into consideration when deciding to cache.</p>\n</blockquote>\n<p>We tried ur branch r1.9 still we have the memory leak but it is reduced to <strong>1/4th</strong> previously we had and <a href=\"https://github.com/hyperscience/tensorflow/tree/ivan/mkl-variable-input-size-fix-refactor\">https://github.com/hyperscience/tensorflow/tree/ivan/mkl-variable-input-size-fix-refactor</a> branch leaks more memory as normal tensorflow-mkl</p>", "body_text": "The problem is that there are a lot of primitive reuse cases and not all factories even have an option to turn caching off. In TF 1.9 turning the cache off for the convolution should be enough but in later versions the caching is becoming widely adopted in other operations as well and very few can be turned off. My proposed solution introduces a new environment variable with a default value that preserves current behaviour for backwards compatibility. It changes all factories so that they take this new variable into consideration when deciding to cache.\n\nWe tried ur branch r1.9 still we have the memory leak but it is reduced to 1/4th previously we had and https://github.com/hyperscience/tensorflow/tree/ivan/mkl-variable-input-size-fix-refactor branch leaks more memory as normal tensorflow-mkl", "body": "> The problem is that there are a lot of primitive reuse cases and not all factories even have an option to turn caching off. In TF 1.9 turning the cache off for the convolution should be enough but in later versions the caching is becoming widely adopted in other operations as well and very few can be turned off. My proposed solution introduces a new environment variable with a default value that preserves current behaviour for backwards compatibility. It changes all factories so that they take this new variable into consideration when deciding to cache.\r\n\r\nWe tried ur branch r1.9 still we have the memory leak but it is reduced to **1/4th** previously we had and https://github.com/hyperscience/tensorflow/tree/ivan/mkl-variable-input-size-fix-refactor branch leaks more memory as normal tensorflow-mkl  "}