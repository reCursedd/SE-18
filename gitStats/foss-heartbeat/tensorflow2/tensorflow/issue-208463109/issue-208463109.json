{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7625", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7625/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7625/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7625/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7625", "id": 208463109, "node_id": "MDU6SXNzdWUyMDg0NjMxMDk=", "number": 7625, "title": "tf.train.import_meta_graph should be parallelized", "user": {"login": "kirk86", "id": 2902390, "node_id": "MDQ6VXNlcjI5MDIzOTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2902390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kirk86", "html_url": "https://github.com/kirk86", "followers_url": "https://api.github.com/users/kirk86/followers", "following_url": "https://api.github.com/users/kirk86/following{/other_user}", "gists_url": "https://api.github.com/users/kirk86/gists{/gist_id}", "starred_url": "https://api.github.com/users/kirk86/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kirk86/subscriptions", "organizations_url": "https://api.github.com/users/kirk86/orgs", "repos_url": "https://api.github.com/users/kirk86/repos", "events_url": "https://api.github.com/users/kirk86/events{/privacy}", "received_events_url": "https://api.github.com/users/kirk86/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-02-17T14:48:02Z", "updated_at": "2017-03-03T23:41:42Z", "closed_at": "2017-03-03T23:41:42Z", "author_association": "NONE", "body_html": "<p>Hey guys, I've been wondering whether it's possible the <code>tf.train.import_meta_graph</code> to be parallelized across multiple cores. When I load a complex model it takes too long and I only see one of my 24 cores being utilized to 100%.</p>\n<h3>Environment info</h3>\n<p>Operating System: CentOS</p>\n<p>Installed version of CUDA and cuDNN:<br>\nNot applicable</p>\n<p>Minimal example:</p>\n<pre><code>sess = tf.Session()\nnew_saver = tf.train.import_meta_graph('my-model.meta')\nnew_saver.restore(sess, tf.train.latest_checkpoint('./'))\nall_vars = tf.get_collection('vars')\nfor v in all_vars:\n    v_ = sess.run(v)\n    print(v_)\n</code></pre>\n<p>Any plans on changing that in the near future?</p>", "body_text": "Hey guys, I've been wondering whether it's possible the tf.train.import_meta_graph to be parallelized across multiple cores. When I load a complex model it takes too long and I only see one of my 24 cores being utilized to 100%.\nEnvironment info\nOperating System: CentOS\nInstalled version of CUDA and cuDNN:\nNot applicable\nMinimal example:\nsess = tf.Session()\nnew_saver = tf.train.import_meta_graph('my-model.meta')\nnew_saver.restore(sess, tf.train.latest_checkpoint('./'))\nall_vars = tf.get_collection('vars')\nfor v in all_vars:\n    v_ = sess.run(v)\n    print(v_)\n\nAny plans on changing that in the near future?", "body": "Hey guys, I've been wondering whether it's possible the `tf.train.import_meta_graph` to be parallelized across multiple cores. When I load a complex model it takes too long and I only see one of my 24 cores being utilized to 100%.\r\n\r\n### Environment info\r\nOperating System: CentOS\r\n\r\nInstalled version of CUDA and cuDNN: \r\nNot applicable\r\n\r\nMinimal example:\r\n```\r\nsess = tf.Session()\r\nnew_saver = tf.train.import_meta_graph('my-model.meta')\r\nnew_saver.restore(sess, tf.train.latest_checkpoint('./'))\r\nall_vars = tf.get_collection('vars')\r\nfor v in all_vars:\r\n    v_ = sess.run(v)\r\n    print(v_)\r\n```\r\n\r\nAny plans on changing that in the near future?"}