{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5285", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5285/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5285/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5285/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5285", "id": 186144503, "node_id": "MDU6SXNzdWUxODYxNDQ1MDM=", "number": 5285, "title": "(0.11) parse_single_example doesn't play well with read_file", "user": {"login": "elibixby", "id": 6596957, "node_id": "MDQ6VXNlcjY1OTY5NTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6596957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elibixby", "html_url": "https://github.com/elibixby", "followers_url": "https://api.github.com/users/elibixby/followers", "following_url": "https://api.github.com/users/elibixby/following{/other_user}", "gists_url": "https://api.github.com/users/elibixby/gists{/gist_id}", "starred_url": "https://api.github.com/users/elibixby/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elibixby/subscriptions", "organizations_url": "https://api.github.com/users/elibixby/orgs", "repos_url": "https://api.github.com/users/elibixby/repos", "events_url": "https://api.github.com/users/elibixby/events{/privacy}", "received_events_url": "https://api.github.com/users/elibixby/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2016-10-30T15:58:08Z", "updated_at": "2018-01-22T02:14:03Z", "closed_at": "2018-01-22T02:14:03Z", "author_association": "NONE", "body_html": "<p>minimal reproduction:</p>\n<pre><code>import tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\nindex = ['a', 'b', 'c']\n\nwith tf.python_io.TFRecordWriter('test.pb2') as writer:\n    writer.write(tf.train.Example(features=tf.train.Features(\n        feature={'index': tf.train.Feature(bytes_list=tf.train.BytesList(\n            value=index))})).SerializeToString())\n\nindex_example = tf.read_file('test.pb2')\nindex = tf.parse_single_example(\n    index_example,\n    {'index': tf.FixedLenFeature([3], tf.string)}\n)['index']\n\nwith tf.Session() as sess:\n    tf.logging.debug(index_example.eval())\n    tf.logging.debug(index.eval())\n</code></pre>\n<p>You'll notice that read_file works just fine, and outputs bytes as expected, but then the process will completely lock up, and does not respond to SIGINT, responding only to SIGKILL or SIGTERM. Not sure what's going on here, although I suspect that read_file is reading some leading/trailing bytes that TFRecordReader strips off.</p>\n<p>Still it seems like TFRecords should be a valid I/O format without requiring a filename queue, (e.g. for reading in initial vocabulary files), and I thought that <code>read_file</code> + <code>parse_single_example</code> would be the expected way to do this. Instead I guess I need to use <code>make_tensor_proto</code> or something? Not sure why this is a separate serialization strategy... and completely missing from the docs.</p>\n<p>At the very least, <code>parse_single_example</code> should fail and not livelock when it gets these strings.</p>\n<p>EDIT: For people wondering what the correct pattern is it appears to be something like:</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib.util import make_tensor_proto\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\nindex = ['a', 'b', 'c']\n\nwith open('test.pb2', 'wb') as writer:\n    writer.write(make_tensor_proto(index, dtype=tf.string, shape=[3]).SerializeToString())\n\nindex_example = tf.read_file('test.pb2')\nindex = tf.parse_tensor(index_example, tf.string)\n\nwith tf.Session() as sess:\n    tf.logging.debug(index_example.eval())\n    tf.logging.debug(index.eval())\n</code></pre>", "body_text": "minimal reproduction:\nimport tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\nindex = ['a', 'b', 'c']\n\nwith tf.python_io.TFRecordWriter('test.pb2') as writer:\n    writer.write(tf.train.Example(features=tf.train.Features(\n        feature={'index': tf.train.Feature(bytes_list=tf.train.BytesList(\n            value=index))})).SerializeToString())\n\nindex_example = tf.read_file('test.pb2')\nindex = tf.parse_single_example(\n    index_example,\n    {'index': tf.FixedLenFeature([3], tf.string)}\n)['index']\n\nwith tf.Session() as sess:\n    tf.logging.debug(index_example.eval())\n    tf.logging.debug(index.eval())\n\nYou'll notice that read_file works just fine, and outputs bytes as expected, but then the process will completely lock up, and does not respond to SIGINT, responding only to SIGKILL or SIGTERM. Not sure what's going on here, although I suspect that read_file is reading some leading/trailing bytes that TFRecordReader strips off.\nStill it seems like TFRecords should be a valid I/O format without requiring a filename queue, (e.g. for reading in initial vocabulary files), and I thought that read_file + parse_single_example would be the expected way to do this. Instead I guess I need to use make_tensor_proto or something? Not sure why this is a separate serialization strategy... and completely missing from the docs.\nAt the very least, parse_single_example should fail and not livelock when it gets these strings.\nEDIT: For people wondering what the correct pattern is it appears to be something like:\nimport tensorflow as tf\nfrom tensorflow.contrib.util import make_tensor_proto\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\nindex = ['a', 'b', 'c']\n\nwith open('test.pb2', 'wb') as writer:\n    writer.write(make_tensor_proto(index, dtype=tf.string, shape=[3]).SerializeToString())\n\nindex_example = tf.read_file('test.pb2')\nindex = tf.parse_tensor(index_example, tf.string)\n\nwith tf.Session() as sess:\n    tf.logging.debug(index_example.eval())\n    tf.logging.debug(index.eval())", "body": "minimal reproduction:\n\n```\nimport tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\nindex = ['a', 'b', 'c']\n\nwith tf.python_io.TFRecordWriter('test.pb2') as writer:\n    writer.write(tf.train.Example(features=tf.train.Features(\n        feature={'index': tf.train.Feature(bytes_list=tf.train.BytesList(\n            value=index))})).SerializeToString())\n\nindex_example = tf.read_file('test.pb2')\nindex = tf.parse_single_example(\n    index_example,\n    {'index': tf.FixedLenFeature([3], tf.string)}\n)['index']\n\nwith tf.Session() as sess:\n    tf.logging.debug(index_example.eval())\n    tf.logging.debug(index.eval())\n```\n\nYou'll notice that read_file works just fine, and outputs bytes as expected, but then the process will completely lock up, and does not respond to SIGINT, responding only to SIGKILL or SIGTERM. Not sure what's going on here, although I suspect that read_file is reading some leading/trailing bytes that TFRecordReader strips off. \n\nStill it seems like TFRecords should be a valid I/O format without requiring a filename queue, (e.g. for reading in initial vocabulary files), and I thought that `read_file` + `parse_single_example` would be the expected way to do this. Instead I guess I need to use `make_tensor_proto` or something? Not sure why this is a separate serialization strategy... and completely missing from the docs.\n\nAt the very least, `parse_single_example` should fail and not livelock when it gets these strings. \n\nEDIT: For people wondering what the correct pattern is it appears to be something like:\n\n```\nimport tensorflow as tf\nfrom tensorflow.contrib.util import make_tensor_proto\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\nindex = ['a', 'b', 'c']\n\nwith open('test.pb2', 'wb') as writer:\n    writer.write(make_tensor_proto(index, dtype=tf.string, shape=[3]).SerializeToString())\n\nindex_example = tf.read_file('test.pb2')\nindex = tf.parse_tensor(index_example, tf.string)\n\nwith tf.Session() as sess:\n    tf.logging.debug(index_example.eval())\n    tf.logging.debug(index.eval())\n```\n"}