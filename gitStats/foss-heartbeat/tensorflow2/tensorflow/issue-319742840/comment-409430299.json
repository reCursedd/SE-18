{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/409430299", "html_url": "https://github.com/tensorflow/tensorflow/issues/19041#issuecomment-409430299", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19041", "id": 409430299, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTQzMDI5OQ==", "user": {"login": "Arjuna197", "id": 34486624, "node_id": "MDQ6VXNlcjM0NDg2NjI0", "avatar_url": "https://avatars2.githubusercontent.com/u/34486624?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Arjuna197", "html_url": "https://github.com/Arjuna197", "followers_url": "https://api.github.com/users/Arjuna197/followers", "following_url": "https://api.github.com/users/Arjuna197/following{/other_user}", "gists_url": "https://api.github.com/users/Arjuna197/gists{/gist_id}", "starred_url": "https://api.github.com/users/Arjuna197/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Arjuna197/subscriptions", "organizations_url": "https://api.github.com/users/Arjuna197/orgs", "repos_url": "https://api.github.com/users/Arjuna197/repos", "events_url": "https://api.github.com/users/Arjuna197/events{/privacy}", "received_events_url": "https://api.github.com/users/Arjuna197/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-01T02:38:13Z", "updated_at": "2018-08-01T02:38:13Z", "author_association": "NONE", "body_html": "<p>If you view your graph in tensorboard, you can pretty easily discern the name of the tensors you'll need at inference time.<br>\nThen, something like:</p>\n<pre><code>saver.restore(sess, tf.train.latest_checkpoint(model_dir))\ngd = sess.graph_def\ninp, prediction = tf.import_graph_def(\n  gd, return_elements = ['input_node:0', 'output_node/BiasAdd:0'])\nresult = sess.run(prediction, feed_dict={inp: my_prediction_inputs})\n</code></pre>\n<p>you can specify more than one input and output also. However, if your restored graph has batch_norm or dropout you may run into issues with this method. There is also probably a more elegant solution, but I just gave up and stopped using estimators in favor of having direct access to the session and layers and both training and inference time.</p>", "body_text": "If you view your graph in tensorboard, you can pretty easily discern the name of the tensors you'll need at inference time.\nThen, something like:\nsaver.restore(sess, tf.train.latest_checkpoint(model_dir))\ngd = sess.graph_def\ninp, prediction = tf.import_graph_def(\n  gd, return_elements = ['input_node:0', 'output_node/BiasAdd:0'])\nresult = sess.run(prediction, feed_dict={inp: my_prediction_inputs})\n\nyou can specify more than one input and output also. However, if your restored graph has batch_norm or dropout you may run into issues with this method. There is also probably a more elegant solution, but I just gave up and stopped using estimators in favor of having direct access to the session and layers and both training and inference time.", "body": "If you view your graph in tensorboard, you can pretty easily discern the name of the tensors you'll need at inference time.\r\nThen, something like: \r\n\r\n```\r\nsaver.restore(sess, tf.train.latest_checkpoint(model_dir))\r\ngd = sess.graph_def\r\ninp, prediction = tf.import_graph_def(\r\n  gd, return_elements = ['input_node:0', 'output_node/BiasAdd:0'])\r\nresult = sess.run(prediction, feed_dict={inp: my_prediction_inputs})\r\n```\r\n\r\nyou can specify more than one input and output also. However, if your restored graph has batch_norm or dropout you may run into issues with this method. There is also probably a more elegant solution, but I just gave up and stopped using estimators in favor of having direct access to the session and layers and both training and inference time. "}