{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/360572801", "html_url": "https://github.com/tensorflow/tensorflow/issues/16396#issuecomment-360572801", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16396", "id": 360572801, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDU3MjgwMQ==", "user": {"login": "aisuni", "id": 35795681, "node_id": "MDQ6VXNlcjM1Nzk1Njgx", "avatar_url": "https://avatars3.githubusercontent.com/u/35795681?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aisuni", "html_url": "https://github.com/aisuni", "followers_url": "https://api.github.com/users/aisuni/followers", "following_url": "https://api.github.com/users/aisuni/following{/other_user}", "gists_url": "https://api.github.com/users/aisuni/gists{/gist_id}", "starred_url": "https://api.github.com/users/aisuni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aisuni/subscriptions", "organizations_url": "https://api.github.com/users/aisuni/orgs", "repos_url": "https://api.github.com/users/aisuni/repos", "events_url": "https://api.github.com/users/aisuni/events{/privacy}", "received_events_url": "https://api.github.com/users/aisuni/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-25T19:25:26Z", "updated_at": "2018-01-25T20:02:23Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=28546240\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tensorflowbutler\">@tensorflowbutler</a>, thank you for quick response in this regard.  Here is <code>snip</code> of code I have tried, and this is very much reproducible.</p>\n<p>Have I written custom code: <code>N/A</code></p>\n<p>Exact command to reproduce:</p>\n<pre><code>    FILE_NAMES = ['train-example.tfrecords']\n    def input_fn(split='train', **kwargs):\n\n        # Dataset args\n        repeat = kwargs.get('repeat', True)\n        shuffle = kwargs.get('shuffle', True)\n\n        # List TFrecords\n        # split args will have 'train' or 'validate'\n        dataset = tf.data.TFRecordDataset(FILE_NAMES)\n        # Process dataset for training only.\n        if split.strip().lower() == 'train':\n            if repeat:\n                dataset = dataset.repeat()\n            if shuffle:\n                dataset = dataset.shuffle(buffer_size=len(FILE_NAMES))\n\n        # Add parallelism in input process.\n        dataset = _parse_example_proto(dataset, 224, 224, 3, tf.float32, num_parallel_calls=4):\n\n        # tf.image.resize_image_with_crop_or_pad()  and random crop\n        dataset = _dataset_preprocess_fn(dataset, 224, 224, num_parallel_calls=4)\n\n        # Process dataset for training only.\n        if split.strip().lower() == 'train':\n            if shuffle:\n                dataset = dataset.shuffle(buffer_size=5000)\n        # Combines consecutive elements of this dataset into batches\n        dataset = dataset.batch(bsz)\n        # Batch iterator\n        iterator = dataset.make_one_shot_iterator()\n        input_batch, labels_batch = iterator.get_next()\n        labels_batch = tf.one_hot(labels_batch, 1000)\n        return input_batch, labels_batch\ndef _parse_example_proto(dataset, height, width, depth, dtype, num_parallel_calls=1):\n    def _input_parser(record):\n        keys_to_features = {\n            \"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n            \"image/format\": tf.FixedLenFeature((), tf.string, default_value=\"jpeg\"),\n            \"image/class/label\": tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\n        }\n        parsed = tf.parse_single_example(record, keys_to_features)\n        image = tf.image.decode_jpeg(parsed[\"image/encoded\"], channels=depth)\n        image = tf.image.convert_image_dtype(image, dtype=dtype)\n        label = tf.cast(parsed[\"image/class/label\"], tf.int32)\n        return image, label\n    return dataset.map(_input_parser, num_parallel_calls=num_parallel_calls)\n\ndef _dataset_preprocess_fn(dataset, height, width, num_parallel_calls=1):\n    def _preprocess_fn(image, label):\n        image = tf.image.resize_image_with_crop_or_pad(image, height + 8, width + 8 )\n        image = tf.random_crop(image, [height, width, 3])\n        image = tf.image.random_flip_left_right(image)\n        image = (ISTD * image) + MEAN  #dataset level MEAN\n        return image, label\n    return dataset.map(_preprocess_fn, num_parallel_calls=num_parallel_calls)\n</code></pre>", "body_text": "@tensorflowbutler, thank you for quick response in this regard.  Here is snip of code I have tried, and this is very much reproducible.\nHave I written custom code: N/A\nExact command to reproduce:\n    FILE_NAMES = ['train-example.tfrecords']\n    def input_fn(split='train', **kwargs):\n\n        # Dataset args\n        repeat = kwargs.get('repeat', True)\n        shuffle = kwargs.get('shuffle', True)\n\n        # List TFrecords\n        # split args will have 'train' or 'validate'\n        dataset = tf.data.TFRecordDataset(FILE_NAMES)\n        # Process dataset for training only.\n        if split.strip().lower() == 'train':\n            if repeat:\n                dataset = dataset.repeat()\n            if shuffle:\n                dataset = dataset.shuffle(buffer_size=len(FILE_NAMES))\n\n        # Add parallelism in input process.\n        dataset = _parse_example_proto(dataset, 224, 224, 3, tf.float32, num_parallel_calls=4):\n\n        # tf.image.resize_image_with_crop_or_pad()  and random crop\n        dataset = _dataset_preprocess_fn(dataset, 224, 224, num_parallel_calls=4)\n\n        # Process dataset for training only.\n        if split.strip().lower() == 'train':\n            if shuffle:\n                dataset = dataset.shuffle(buffer_size=5000)\n        # Combines consecutive elements of this dataset into batches\n        dataset = dataset.batch(bsz)\n        # Batch iterator\n        iterator = dataset.make_one_shot_iterator()\n        input_batch, labels_batch = iterator.get_next()\n        labels_batch = tf.one_hot(labels_batch, 1000)\n        return input_batch, labels_batch\ndef _parse_example_proto(dataset, height, width, depth, dtype, num_parallel_calls=1):\n    def _input_parser(record):\n        keys_to_features = {\n            \"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n            \"image/format\": tf.FixedLenFeature((), tf.string, default_value=\"jpeg\"),\n            \"image/class/label\": tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\n        }\n        parsed = tf.parse_single_example(record, keys_to_features)\n        image = tf.image.decode_jpeg(parsed[\"image/encoded\"], channels=depth)\n        image = tf.image.convert_image_dtype(image, dtype=dtype)\n        label = tf.cast(parsed[\"image/class/label\"], tf.int32)\n        return image, label\n    return dataset.map(_input_parser, num_parallel_calls=num_parallel_calls)\n\ndef _dataset_preprocess_fn(dataset, height, width, num_parallel_calls=1):\n    def _preprocess_fn(image, label):\n        image = tf.image.resize_image_with_crop_or_pad(image, height + 8, width + 8 )\n        image = tf.random_crop(image, [height, width, 3])\n        image = tf.image.random_flip_left_right(image)\n        image = (ISTD * image) + MEAN  #dataset level MEAN\n        return image, label\n    return dataset.map(_preprocess_fn, num_parallel_calls=num_parallel_calls)", "body": "@tensorflowbutler, thank you for quick response in this regard.  Here is `snip` of code I have tried, and this is very much reproducible. \r\n\r\nHave I written custom code: `N/A`\r\n\r\nExact command to reproduce:\r\n```\r\n    FILE_NAMES = ['train-example.tfrecords']\r\n    def input_fn(split='train', **kwargs):\r\n\r\n        # Dataset args\r\n        repeat = kwargs.get('repeat', True)\r\n        shuffle = kwargs.get('shuffle', True)\r\n\r\n        # List TFrecords\r\n        # split args will have 'train' or 'validate'\r\n        dataset = tf.data.TFRecordDataset(FILE_NAMES)\r\n        # Process dataset for training only.\r\n        if split.strip().lower() == 'train':\r\n            if repeat:\r\n                dataset = dataset.repeat()\r\n            if shuffle:\r\n                dataset = dataset.shuffle(buffer_size=len(FILE_NAMES))\r\n\r\n        # Add parallelism in input process.\r\n        dataset = _parse_example_proto(dataset, 224, 224, 3, tf.float32, num_parallel_calls=4):\r\n\r\n        # tf.image.resize_image_with_crop_or_pad()  and random crop\r\n        dataset = _dataset_preprocess_fn(dataset, 224, 224, num_parallel_calls=4)\r\n\r\n        # Process dataset for training only.\r\n        if split.strip().lower() == 'train':\r\n            if shuffle:\r\n                dataset = dataset.shuffle(buffer_size=5000)\r\n        # Combines consecutive elements of this dataset into batches\r\n        dataset = dataset.batch(bsz)\r\n        # Batch iterator\r\n        iterator = dataset.make_one_shot_iterator()\r\n        input_batch, labels_batch = iterator.get_next()\r\n        labels_batch = tf.one_hot(labels_batch, 1000)\r\n        return input_batch, labels_batch\r\ndef _parse_example_proto(dataset, height, width, depth, dtype, num_parallel_calls=1):\r\n    def _input_parser(record):\r\n        keys_to_features = {\r\n            \"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\r\n            \"image/format\": tf.FixedLenFeature((), tf.string, default_value=\"jpeg\"),\r\n            \"image/class/label\": tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\r\n        }\r\n        parsed = tf.parse_single_example(record, keys_to_features)\r\n        image = tf.image.decode_jpeg(parsed[\"image/encoded\"], channels=depth)\r\n        image = tf.image.convert_image_dtype(image, dtype=dtype)\r\n        label = tf.cast(parsed[\"image/class/label\"], tf.int32)\r\n        return image, label\r\n    return dataset.map(_input_parser, num_parallel_calls=num_parallel_calls)\r\n\r\ndef _dataset_preprocess_fn(dataset, height, width, num_parallel_calls=1):\r\n    def _preprocess_fn(image, label):\r\n        image = tf.image.resize_image_with_crop_or_pad(image, height + 8, width + 8 )\r\n        image = tf.random_crop(image, [height, width, 3])\r\n        image = tf.image.random_flip_left_right(image)\r\n        image = (ISTD * image) + MEAN  #dataset level MEAN\r\n        return image, label\r\n    return dataset.map(_preprocess_fn, num_parallel_calls=num_parallel_calls)\r\n```"}