{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16396", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16396/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16396/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16396/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16396", "id": 291477701, "node_id": "MDU6SXNzdWUyOTE0Nzc3MDE=", "number": 16396, "title": "tf.image.resize_image_with_crop_or_pad() is taking too much time to process an image or batch of images", "user": {"login": "aisuni", "id": 35795681, "node_id": "MDQ6VXNlcjM1Nzk1Njgx", "avatar_url": "https://avatars3.githubusercontent.com/u/35795681?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aisuni", "html_url": "https://github.com/aisuni", "followers_url": "https://api.github.com/users/aisuni/followers", "following_url": "https://api.github.com/users/aisuni/following{/other_user}", "gists_url": "https://api.github.com/users/aisuni/gists{/gist_id}", "starred_url": "https://api.github.com/users/aisuni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aisuni/subscriptions", "organizations_url": "https://api.github.com/users/aisuni/orgs", "repos_url": "https://api.github.com/users/aisuni/repos", "events_url": "https://api.github.com/users/aisuni/events{/privacy}", "received_events_url": "https://api.github.com/users/aisuni/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-01-25T07:43:27Z", "updated_at": "2018-10-30T17:09:27Z", "closed_at": "2018-10-30T17:09:26Z", "author_association": "NONE", "body_html": "<p>ISSUE:<br>\nI am stuck in fine tuning imagenet data rendering speed for the reason being tf.image.resize_image_with_crop_or_pad() is taking too much time to process an image or batch of images.<br>\n<code>Testing was done by preprocessing ONE image (no batching) and an observed latency was `~160msec`. </code></p>\n<p>NOTE: I did not observe memory pressure or any possible compute bottleneck during this time.<br>\nDescription:<br>\nI have a tool to load ImageNet dataset which reads the dataset from processed TFRecords and returns an iterator object to iterate over the datasets with a shuffle and repeat.<br>\nI have been observing slow rendering of data due to some overtime by certain steps in image (batch of images) pre-preprocessing. This is really impacting in data rendering speed and hence the slow training of models(Reference here is AlexNet).</p>\n<p>Here is the <code>snip</code> of time taken for each operation,<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/35795681/35406079-d4ec3584-01bc-11e8-9ba6-50e4dabba29e.png\"><img width=\"1425\" alt=\"imagenet_loader_perf_profile\" src=\"https://user-images.githubusercontent.com/35795681/35406079-d4ec3584-01bc-11e8-9ba6-50e4dabba29e.png\" style=\"max-width:100%;\"></a></p>\n<p>Here is a <code>snip</code>  of data preprocess methods,</p>\n<pre><code>def _parse_example_proto(dataset, height, width, depth, dtype, num_parallel_calls):\n    def _input_parser(record):\n        keys_to_features = {\n            \"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n            \"image/format\": tf.FixedLenFeature((), tf.string, default_value=\"jpeg\"),\n            \"image/class/label\": tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\n        }\n        parsed = tf.parse_single_example(record, keys_to_features)\n        image = tf.image.decode_jpeg(parsed[\"image/encoded\"], channels=depth)\n        image = tf.image.convert_image_dtype(image, dtype=dtype)\n        label = tf.cast(parsed[\"image/class/label\"], tf.int32)\n        return image, label\n    return dataset.map(_input_parser, num_parallel_calls=num_parallel_calls)\n\ndef _dataset_preprocess_fn(dataset, height, width, num_parallel_calls):\n    def _preprocess_fn(image, label):\n        image = tf.image.resize_image_with_crop_or_pad(image, height + 8, width + 8 )\n        image = tf.random_crop(image, [height, width, 3])\n        image = tf.image.random_flip_left_right(image)\n        image = (ISTD * image) + MEAN  #dataset level MEAN\n        return image, label\n    return dataset.map(_preprocess_fn, num_parallel_calls=num_parallel_calls)\n</code></pre>\n<h3>System information</h3>\n<ul>\n<li>**OS Platform and Distribution *:  Linux Centos 7.2</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: 1.4.0 rc1 ( commit hash <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/badd35648851c0b84fdbd997b1f6e9aa20122216/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/badd35648851c0b84fdbd997b1f6e9aa20122216\"><tt>badd356</tt></a>)</li>\n<li><strong>TensorFlow version (use command below)</strong>:  b'v1.3.0-rc1-4546-gef196f3' 1.4.0-rc1</li>\n<li><strong>Python version</strong>:  3.4.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: Build label: 0.8.1</li>\n<li><strong>CUDA/CUDAnn version</strong>: CUDA 9 and  CUDAnn 7.0</li>\n<li><strong>GPU model and memory</strong>: Volta 100, 16GiB</li>\n</ul>\n<p>I am using Amazon Instance and here are the details,</p>\n<pre><code>GPUs - Tesla V100\nGPU Memory (GB): 16\nvCPUs : 8\nMemory (GB):61\nNetwork Bandwidth: Upto 10Gbps\nEBS Bandwidth: 1.5 Gbps\n</code></pre>", "body_text": "ISSUE:\nI am stuck in fine tuning imagenet data rendering speed for the reason being tf.image.resize_image_with_crop_or_pad() is taking too much time to process an image or batch of images.\nTesting was done by preprocessing ONE image (no batching) and an observed latency was `~160msec`. \nNOTE: I did not observe memory pressure or any possible compute bottleneck during this time.\nDescription:\nI have a tool to load ImageNet dataset which reads the dataset from processed TFRecords and returns an iterator object to iterate over the datasets with a shuffle and repeat.\nI have been observing slow rendering of data due to some overtime by certain steps in image (batch of images) pre-preprocessing. This is really impacting in data rendering speed and hence the slow training of models(Reference here is AlexNet).\nHere is the snip of time taken for each operation,\n\nHere is a snip  of data preprocess methods,\ndef _parse_example_proto(dataset, height, width, depth, dtype, num_parallel_calls):\n    def _input_parser(record):\n        keys_to_features = {\n            \"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n            \"image/format\": tf.FixedLenFeature((), tf.string, default_value=\"jpeg\"),\n            \"image/class/label\": tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\n        }\n        parsed = tf.parse_single_example(record, keys_to_features)\n        image = tf.image.decode_jpeg(parsed[\"image/encoded\"], channels=depth)\n        image = tf.image.convert_image_dtype(image, dtype=dtype)\n        label = tf.cast(parsed[\"image/class/label\"], tf.int32)\n        return image, label\n    return dataset.map(_input_parser, num_parallel_calls=num_parallel_calls)\n\ndef _dataset_preprocess_fn(dataset, height, width, num_parallel_calls):\n    def _preprocess_fn(image, label):\n        image = tf.image.resize_image_with_crop_or_pad(image, height + 8, width + 8 )\n        image = tf.random_crop(image, [height, width, 3])\n        image = tf.image.random_flip_left_right(image)\n        image = (ISTD * image) + MEAN  #dataset level MEAN\n        return image, label\n    return dataset.map(_preprocess_fn, num_parallel_calls=num_parallel_calls)\n\nSystem information\n\n**OS Platform and Distribution *:  Linux Centos 7.2\nTensorFlow installed from (source or binary): 1.4.0 rc1 ( commit hash badd356)\nTensorFlow version (use command below):  b'v1.3.0-rc1-4546-gef196f3' 1.4.0-rc1\nPython version:  3.4.5\nBazel version (if compiling from source): Build label: 0.8.1\nCUDA/CUDAnn version: CUDA 9 and  CUDAnn 7.0\nGPU model and memory: Volta 100, 16GiB\n\nI am using Amazon Instance and here are the details,\nGPUs - Tesla V100\nGPU Memory (GB): 16\nvCPUs : 8\nMemory (GB):61\nNetwork Bandwidth: Upto 10Gbps\nEBS Bandwidth: 1.5 Gbps", "body": "ISSUE: \r\nI am stuck in fine tuning imagenet data rendering speed for the reason being tf.image.resize_image_with_crop_or_pad() is taking too much time to process an image or batch of images. \r\n```Testing was done by preprocessing ONE image (no batching) and an observed latency was `~160msec`. ```\r\n\r\nNOTE: I did not observe memory pressure or any possible compute bottleneck during this time. \r\nDescription:\r\nI have a tool to load ImageNet dataset which reads the dataset from processed TFRecords and returns an iterator object to iterate over the datasets with a shuffle and repeat.\r\nI have been observing slow rendering of data due to some overtime by certain steps in image (batch of images) pre-preprocessing. This is really impacting in data rendering speed and hence the slow training of models(Reference here is AlexNet). \r\n\r\nHere is the `snip` of time taken for each operation,\r\n<img width=\"1425\" alt=\"imagenet_loader_perf_profile\" src=\"https://user-images.githubusercontent.com/35795681/35406079-d4ec3584-01bc-11e8-9ba6-50e4dabba29e.png\">\r\n\r\nHere is a `snip`  of data preprocess methods,\r\n```\r\ndef _parse_example_proto(dataset, height, width, depth, dtype, num_parallel_calls):\r\n    def _input_parser(record):\r\n        keys_to_features = {\r\n            \"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\r\n            \"image/format\": tf.FixedLenFeature((), tf.string, default_value=\"jpeg\"),\r\n            \"image/class/label\": tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\r\n        }\r\n        parsed = tf.parse_single_example(record, keys_to_features)\r\n        image = tf.image.decode_jpeg(parsed[\"image/encoded\"], channels=depth)\r\n        image = tf.image.convert_image_dtype(image, dtype=dtype)\r\n        label = tf.cast(parsed[\"image/class/label\"], tf.int32)\r\n        return image, label\r\n    return dataset.map(_input_parser, num_parallel_calls=num_parallel_calls)\r\n\r\ndef _dataset_preprocess_fn(dataset, height, width, num_parallel_calls):\r\n    def _preprocess_fn(image, label):\r\n        image = tf.image.resize_image_with_crop_or_pad(image, height + 8, width + 8 )\r\n        image = tf.random_crop(image, [height, width, 3])\r\n        image = tf.image.random_flip_left_right(image)\r\n        image = (ISTD * image) + MEAN  #dataset level MEAN\r\n        return image, label\r\n    return dataset.map(_preprocess_fn, num_parallel_calls=num_parallel_calls)\r\n```\r\n### System information\r\n- **OS Platform and Distribution *:  Linux Centos 7.2\r\n- **TensorFlow installed from (source or binary)**: 1.4.0 rc1 ( commit hash badd356)\r\n- **TensorFlow version (use command below)**:  b'v1.3.0-rc1-4546-gef196f3' 1.4.0-rc1\r\n- **Python version**:  3.4.5\r\n- **Bazel version (if compiling from source)**: Build label: 0.8.1\r\n- **CUDA/CUDAnn version**: CUDA 9 and  CUDAnn 7.0\r\n- **GPU model and memory**: Volta 100, 16GiB\r\n\r\n\r\nI am using Amazon Instance and here are the details,\r\n```\r\nGPUs - Tesla V100\r\nGPU Memory (GB): 16\r\nvCPUs : 8\r\nMemory (GB):61\r\nNetwork Bandwidth: Upto 10Gbps\r\nEBS Bandwidth: 1.5 Gbps\r\n```\r\n"}