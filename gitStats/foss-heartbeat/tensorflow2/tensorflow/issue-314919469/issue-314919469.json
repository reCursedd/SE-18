{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18586", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18586/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18586/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18586/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18586", "id": 314919469, "node_id": "MDU6SXNzdWUzMTQ5MTk0Njk=", "number": 18586, "title": "tf.train.batch does not work with tf.uint32 and tf.uint64 data types", "user": {"login": "jml6757", "id": 4644759, "node_id": "MDQ6VXNlcjQ2NDQ3NTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/4644759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jml6757", "html_url": "https://github.com/jml6757", "followers_url": "https://api.github.com/users/jml6757/followers", "following_url": "https://api.github.com/users/jml6757/following{/other_user}", "gists_url": "https://api.github.com/users/jml6757/gists{/gist_id}", "starred_url": "https://api.github.com/users/jml6757/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jml6757/subscriptions", "organizations_url": "https://api.github.com/users/jml6757/orgs", "repos_url": "https://api.github.com/users/jml6757/repos", "events_url": "https://api.github.com/users/jml6757/events{/privacy}", "received_events_url": "https://api.github.com/users/jml6757/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-04-17T06:15:55Z", "updated_at": "2018-04-28T19:04:45Z", "closed_at": "2018-04-28T19:04:45Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7.0</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>import tensorflow as tf\n\nvalues = tf.constant([0, 1, 2, 3, 4], dtype=tf.uint64)\nbatch = tf.train.batch(\n    [values],\n    batch_size=2,\n    num_threads=1,\n    enqueue_many=True,\n)\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    print(sess.run(batch))\n\n    coord.request_stop()\n    coord.join(threads)\n</code></pre>\n<h3>Describe the problem</h3>\n<p><code>tf.train.batch</code> does not work on tensors with types <code>uint32</code> or <code>uint64</code>. It works with all other primitive types. The source of this issue can be traced back to <code>CopyElementToSlice</code> which calls <code>TF_CALL_ALL_TYPES</code></p>\n<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8/tensorflow/core/kernels/batch_util.cc#L94\">tensorflow/tensorflow/core/kernels/batch_util.cc</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 94\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8\">3128b43</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L94\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"94\"></td>\n          <td id=\"LC94\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> Status <span class=\"pl-en\">CopyElementToSlice</span>(Tensor element, Tensor* parent, int64 index) { </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>This <code>TF_CALL_ALL_TYPES</code> macro eventually calls into <code>TF_CALL_INTEGRAL_TYPES</code></p>\n<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8/tensorflow/core/framework/register_types.h#L154\">tensorflow/tensorflow/core/framework/register_types.h</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 154\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8\">3128b43</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L154\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"154\"></td>\n          <td id=\"LC154\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> #<span class=\"pl-k\">define</span> <span class=\"pl-en\">TF_CALL_INTEGRAL_TYPES</span>(<span class=\"pl-v\">m</span>)                                      \\ </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>This macro includes <code>int8</code>, <code>uint8</code>, <code>int16</code>, <code>uint16</code>, <code>int32</code>, and <code>int64</code> but <strong>does not</strong> include <code>uint32</code> or <code>uint64</code></p>\n<p>The change to support these types appears to be simple, but since <code>TF_CALL_ALL_TYPES</code> is a high-level macro, I did not know if these data types were purposefully excluded.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): 1.7.0\nPython version: 3.6\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce:\n\nimport tensorflow as tf\n\nvalues = tf.constant([0, 1, 2, 3, 4], dtype=tf.uint64)\nbatch = tf.train.batch(\n    [values],\n    batch_size=2,\n    num_threads=1,\n    enqueue_many=True,\n)\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    print(sess.run(batch))\n\n    coord.request_stop()\n    coord.join(threads)\n\nDescribe the problem\ntf.train.batch does not work on tensors with types uint32 or uint64. It works with all other primitive types. The source of this issue can be traced back to CopyElementToSlice which calls TF_CALL_ALL_TYPES\n\n  \n    \n      tensorflow/tensorflow/core/kernels/batch_util.cc\n    \n    \n         Line 94\n      in\n      3128b43\n    \n    \n    \n    \n\n        \n          \n           Status CopyElementToSlice(Tensor element, Tensor* parent, int64 index) { \n        \n    \n  \n\n\nThis TF_CALL_ALL_TYPES macro eventually calls into TF_CALL_INTEGRAL_TYPES\n\n  \n    \n      tensorflow/tensorflow/core/framework/register_types.h\n    \n    \n         Line 154\n      in\n      3128b43\n    \n    \n    \n    \n\n        \n          \n           #define TF_CALL_INTEGRAL_TYPES(m)                                      \\ \n        \n    \n  \n\n\nThis macro includes int8, uint8, int16, uint16, int32, and int64 but does not include uint32 or uint64\nThe change to support these types appears to be simple, but since TF_CALL_ALL_TYPES is a high-level macro, I did not know if these data types were purposefully excluded.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nvalues = tf.constant([0, 1, 2, 3, 4], dtype=tf.uint64)\r\nbatch = tf.train.batch(\r\n    [values],\r\n    batch_size=2,\r\n    num_threads=1,\r\n    enqueue_many=True,\r\n)\r\n\r\nwith tf.Session() as sess:\r\n    coord = tf.train.Coordinator()\r\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n    print(sess.run(batch))\r\n\r\n    coord.request_stop()\r\n    coord.join(threads)\r\n```\r\n\r\n### Describe the problem\r\n`tf.train.batch` does not work on tensors with types `uint32` or `uint64`. It works with all other primitive types. The source of this issue can be traced back to `CopyElementToSlice` which calls `TF_CALL_ALL_TYPES`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8/tensorflow/core/kernels/batch_util.cc#L94\r\n\r\nThis `TF_CALL_ALL_TYPES` macro eventually calls into `TF_CALL_INTEGRAL_TYPES` \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8/tensorflow/core/framework/register_types.h#L154\r\n\r\nThis macro includes `int8`, `uint8`, `int16`, `uint16`, `int32`, and `int64` but **does not** include `uint32` or `uint64`\r\n\r\nThe change to support these types appears to be simple, but since `TF_CALL_ALL_TYPES` is a high-level macro, I did not know if these data types were purposefully excluded.\r\n"}