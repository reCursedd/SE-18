{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/312226444", "html_url": "https://github.com/tensorflow/tensorflow/issues/11147#issuecomment-312226444", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11147", "id": 312226444, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjIyNjQ0NA==", "user": {"login": "jubjamie", "id": 25011496, "node_id": "MDQ6VXNlcjI1MDExNDk2", "avatar_url": "https://avatars3.githubusercontent.com/u/25011496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jubjamie", "html_url": "https://github.com/jubjamie", "followers_url": "https://api.github.com/users/jubjamie/followers", "following_url": "https://api.github.com/users/jubjamie/following{/other_user}", "gists_url": "https://api.github.com/users/jubjamie/gists{/gist_id}", "starred_url": "https://api.github.com/users/jubjamie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jubjamie/subscriptions", "organizations_url": "https://api.github.com/users/jubjamie/orgs", "repos_url": "https://api.github.com/users/jubjamie/repos", "events_url": "https://api.github.com/users/jubjamie/events{/privacy}", "received_events_url": "https://api.github.com/users/jubjamie/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-30T09:52:54Z", "updated_at": "2017-06-30T09:52:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p><em>Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow.</em></p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=65011\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vade\">@vade</a> has posted a good answer for Caffe. Shoutout to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=833911\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xdumaine\">@xdumaine</a> for filling the issue tracker with unfunny comments instead of actually helping.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25650372\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/puckpuck85\">@puckpuck85</a> You have a couple of ways of attacking this. Your current method of classifying between different image classes has potential but will need much more training data. As you've said, the difference between many of these images can be rather subtle in some instances and more obvious in others. NSFW content can take so many forms that just 160 images won't cover the breadth of the different types of images you are likely to come across. Looking at the repo <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=65011\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vade\">@vade</a> posted it appears that they used a large dataset but it is private. This was labelled manually of course.</p>\n<p>If you want to quickly bolster your dataset you can always scrape images from google images and train on that with inception. I've had surprising success with this! You can then implement a function on your website that if there is a certain uncertainty, it goes to manual review and if it is blocked it gives the user a chance to appeal or whatever.</p>\n<p>Your alternative option (which may be slightly overkill for this situation) is to implement an object detector with annotated objects. Then you can filter out images with have detections. This is a lot of work however as i'm 99% sure that dataset does not already exist.</p>\n<p>For the meantime I would suggest increasing your dataset. Perhaps you have a repository of \"banned\" images from your website that you could use to train?</p>\n<p>I suggest you move this to Stack Overflow as, whilst your question is extremely valid and the basics of image training, it is neither a bug or feature request and i'm not sure how the devs will feel about this on their issue tracker! I'm sure it will make them chuckle.</p>\n<p>If you decide to move this issue to Stack Overflow, please post the link here so that myself (or others that stumble upon this issue) can find the S/O thread.</p>", "body_text": "Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow.\n@vade has posted a good answer for Caffe. Shoutout to @xdumaine for filling the issue tracker with unfunny comments instead of actually helping.\n@puckpuck85 You have a couple of ways of attacking this. Your current method of classifying between different image classes has potential but will need much more training data. As you've said, the difference between many of these images can be rather subtle in some instances and more obvious in others. NSFW content can take so many forms that just 160 images won't cover the breadth of the different types of images you are likely to come across. Looking at the repo @vade posted it appears that they used a large dataset but it is private. This was labelled manually of course.\nIf you want to quickly bolster your dataset you can always scrape images from google images and train on that with inception. I've had surprising success with this! You can then implement a function on your website that if there is a certain uncertainty, it goes to manual review and if it is blocked it gives the user a chance to appeal or whatever.\nYour alternative option (which may be slightly overkill for this situation) is to implement an object detector with annotated objects. Then you can filter out images with have detections. This is a lot of work however as i'm 99% sure that dataset does not already exist.\nFor the meantime I would suggest increasing your dataset. Perhaps you have a repository of \"banned\" images from your website that you could use to train?\nI suggest you move this to Stack Overflow as, whilst your question is extremely valid and the basics of image training, it is neither a bug or feature request and i'm not sure how the devs will feel about this on their issue tracker! I'm sure it will make them chuckle.\nIf you decide to move this issue to Stack Overflow, please post the link here so that myself (or others that stumble upon this issue) can find the S/O thread.", "body": "_Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow._\r\n\r\n@vade has posted a good answer for Caffe. Shoutout to @xdumaine for filling the issue tracker with unfunny comments instead of actually helping.\r\n\r\n@puckpuck85 You have a couple of ways of attacking this. Your current method of classifying between different image classes has potential but will need much more training data. As you've said, the difference between many of these images can be rather subtle in some instances and more obvious in others. NSFW content can take so many forms that just 160 images won't cover the breadth of the different types of images you are likely to come across. Looking at the repo @vade posted it appears that they used a large dataset but it is private. This was labelled manually of course.\r\n\r\nIf you want to quickly bolster your dataset you can always scrape images from google images and train on that with inception. I've had surprising success with this! You can then implement a function on your website that if there is a certain uncertainty, it goes to manual review and if it is blocked it gives the user a chance to appeal or whatever. \r\n\r\nYour alternative option (which may be slightly overkill for this situation) is to implement an object detector with annotated objects. Then you can filter out images with have detections. This is a lot of work however as i'm 99% sure that dataset does not already exist.\r\n\r\nFor the meantime I would suggest increasing your dataset. Perhaps you have a repository of \"banned\" images from your website that you could use to train? \r\n\r\nI suggest you move this to Stack Overflow as, whilst your question is extremely valid and the basics of image training, it is neither a bug or feature request and i'm not sure how the devs will feel about this on their issue tracker! I'm sure it will make them chuckle.\r\n\r\nIf you decide to move this issue to Stack Overflow, please post the link here so that myself (or others that stumble upon this issue) can find the S/O thread."}