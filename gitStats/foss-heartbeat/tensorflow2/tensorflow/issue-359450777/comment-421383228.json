{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/421383228", "html_url": "https://github.com/tensorflow/tensorflow/issues/22238#issuecomment-421383228", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22238", "id": 421383228, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTM4MzIyOA==", "user": {"login": "Raj-08", "id": 15856029, "node_id": "MDQ6VXNlcjE1ODU2MDI5", "avatar_url": "https://avatars3.githubusercontent.com/u/15856029?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Raj-08", "html_url": "https://github.com/Raj-08", "followers_url": "https://api.github.com/users/Raj-08/followers", "following_url": "https://api.github.com/users/Raj-08/following{/other_user}", "gists_url": "https://api.github.com/users/Raj-08/gists{/gist_id}", "starred_url": "https://api.github.com/users/Raj-08/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Raj-08/subscriptions", "organizations_url": "https://api.github.com/users/Raj-08/orgs", "repos_url": "https://api.github.com/users/Raj-08/repos", "events_url": "https://api.github.com/users/Raj-08/events{/privacy}", "received_events_url": "https://api.github.com/users/Raj-08/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-14T14:50:51Z", "updated_at": "2018-09-14T14:50:51Z", "author_association": "NONE", "body_html": "<p>I am using default commands given by tensorflow:</p>\n<p><code>bazel build tensorflow/python/tools:optimize_for_inference bazel-bin/tensorflow/python/tools/optimize_for_inference \\ --input=/tf_files/retrained_graph.pb \\ --output=/tf_files/optimized_graph.pb \\ --input_names=Mul \\ --output_names=final_result</code></p>\n<p><code>bazel build tensorflow/tools/quantization:quantize_graph bazel-bin/tensorflow/tools/quantization/quantize_graph \\ --input=/tf_files/optimized_graph.pb \\ --output=/tf_files/rounded_graph.pb \\ --output_node_names=final_result \\ --mode=weights_rounded</code></p>\n<p><code>bazel build tensorflow/tools/graph_transforms:transform_graph bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\ --in_graph=tensorflow_inception_graph.pb \\ --out_graph=optimized_inception_graph.pb \\ --inputs='Mul:0' \\ --outputs='softmax:0' \\ --transforms=' strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics) fold_old_batch_norms '</code></p>\n<p>For freezing i am using my custom script --<br>\nWith tf.graph.default() as graph:<br>\n`input_graph_def = graph.as_graph_def()<br>\noutput_node_names =_OUTPUT_NAME<br>\noutput_graph_name =  '/home/ubuntu/raj/freeze_inference_graph_mobilenet.pb'</p>\n<pre><code>with tf.Session() as sess:\n    saver = tf.train.import_meta_graph('/home/ubuntu/raj/research/train_mat_dp_1/model.ckpt-0.meta',clear_devices=True)\n    saver.restore(sess, '/home/ubuntu/raj/research/train_mat_dp_1/model.ckpt-0')\n    print (\"Exporting graph...\")\n    output_graph_def = graph_util.convert_variables_to_constants(\n        sess,\n        input_graph_def,\n       [_OUTPUT_NAME])\n\n    with tf.gfile.GFile(output_graph_name, \"wb\") as f:\n        f.write(output_graph_def.SerializeToString())`\n</code></pre>", "body_text": "I am using default commands given by tensorflow:\nbazel build tensorflow/python/tools:optimize_for_inference bazel-bin/tensorflow/python/tools/optimize_for_inference \\ --input=/tf_files/retrained_graph.pb \\ --output=/tf_files/optimized_graph.pb \\ --input_names=Mul \\ --output_names=final_result\nbazel build tensorflow/tools/quantization:quantize_graph bazel-bin/tensorflow/tools/quantization/quantize_graph \\ --input=/tf_files/optimized_graph.pb \\ --output=/tf_files/rounded_graph.pb \\ --output_node_names=final_result \\ --mode=weights_rounded\nbazel build tensorflow/tools/graph_transforms:transform_graph bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\ --in_graph=tensorflow_inception_graph.pb \\ --out_graph=optimized_inception_graph.pb \\ --inputs='Mul:0' \\ --outputs='softmax:0' \\ --transforms=' strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics) fold_old_batch_norms '\nFor freezing i am using my custom script --\nWith tf.graph.default() as graph:\n`input_graph_def = graph.as_graph_def()\noutput_node_names =_OUTPUT_NAME\noutput_graph_name =  '/home/ubuntu/raj/freeze_inference_graph_mobilenet.pb'\nwith tf.Session() as sess:\n    saver = tf.train.import_meta_graph('/home/ubuntu/raj/research/train_mat_dp_1/model.ckpt-0.meta',clear_devices=True)\n    saver.restore(sess, '/home/ubuntu/raj/research/train_mat_dp_1/model.ckpt-0')\n    print (\"Exporting graph...\")\n    output_graph_def = graph_util.convert_variables_to_constants(\n        sess,\n        input_graph_def,\n       [_OUTPUT_NAME])\n\n    with tf.gfile.GFile(output_graph_name, \"wb\") as f:\n        f.write(output_graph_def.SerializeToString())`", "body": "I am using default commands given by tensorflow:\r\n\r\n`bazel build tensorflow/python/tools:optimize_for_inference\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference \\\r\n--input=/tf_files/retrained_graph.pb \\\r\n--output=/tf_files/optimized_graph.pb \\\r\n--input_names=Mul \\\r\n--output_names=final_result`\r\n\r\n\r\n`bazel build tensorflow/tools/quantization:quantize_graph\r\nbazel-bin/tensorflow/tools/quantization/quantize_graph \\\r\n--input=/tf_files/optimized_graph.pb \\\r\n--output=/tf_files/rounded_graph.pb \\\r\n--output_node_names=final_result \\\r\n--mode=weights_rounded`\r\n\r\n`bazel build tensorflow/tools/graph_transforms:transform_graph\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=tensorflow_inception_graph.pb \\\r\n--out_graph=optimized_inception_graph.pb \\\r\n--inputs='Mul:0' \\\r\n--outputs='softmax:0' \\\r\n--transforms='\r\nstrip_unused_nodes(type=float, shape=\"1,299,299,3\")\r\nremove_nodes(op=Identity, op=CheckNumerics)\r\nfold_old_batch_norms\r\n'`\r\n\r\nFor freezing i am using my custom script --\r\nWith tf.graph.default() as graph:\r\n`input_graph_def = graph.as_graph_def()\r\n    output_node_names =_OUTPUT_NAME\r\n    output_graph_name =  '/home/ubuntu/raj/freeze_inference_graph_mobilenet.pb'\r\n\r\n    with tf.Session() as sess:\r\n        saver = tf.train.import_meta_graph('/home/ubuntu/raj/research/train_mat_dp_1/model.ckpt-0.meta',clear_devices=True)\r\n        saver.restore(sess, '/home/ubuntu/raj/research/train_mat_dp_1/model.ckpt-0')\r\n        print (\"Exporting graph...\")\r\n        output_graph_def = graph_util.convert_variables_to_constants(\r\n            sess,\r\n            input_graph_def,\r\n           [_OUTPUT_NAME])\r\n\r\n        with tf.gfile.GFile(output_graph_name, \"wb\") as f:\r\n            f.write(output_graph_def.SerializeToString())`"}