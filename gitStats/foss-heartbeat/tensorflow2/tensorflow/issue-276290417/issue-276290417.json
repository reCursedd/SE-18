{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14825", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14825/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14825/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14825/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14825", "id": 276290417, "node_id": "MDU6SXNzdWUyNzYyOTA0MTc=", "number": 14825, "title": "how to extract parameters of sim.batch_norm", "user": {"login": "patienceFromZhou", "id": 31264567, "node_id": "MDQ6VXNlcjMxMjY0NTY3", "avatar_url": "https://avatars3.githubusercontent.com/u/31264567?v=4", "gravatar_id": "", "url": "https://api.github.com/users/patienceFromZhou", "html_url": "https://github.com/patienceFromZhou", "followers_url": "https://api.github.com/users/patienceFromZhou/followers", "following_url": "https://api.github.com/users/patienceFromZhou/following{/other_user}", "gists_url": "https://api.github.com/users/patienceFromZhou/gists{/gist_id}", "starred_url": "https://api.github.com/users/patienceFromZhou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/patienceFromZhou/subscriptions", "organizations_url": "https://api.github.com/users/patienceFromZhou/orgs", "repos_url": "https://api.github.com/users/patienceFromZhou/repos", "events_url": "https://api.github.com/users/patienceFromZhou/events{/privacy}", "received_events_url": "https://api.github.com/users/patienceFromZhou/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-23T08:06:02Z", "updated_at": "2017-11-27T18:48:58Z", "closed_at": "2017-11-27T18:48:58Z", "author_association": "NONE", "body_html": "<p>using slim.batch_norm for normalize and here are the batch_norm_params:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/31264567/33162735-1b13082c-d066-11e7-918c-62bec95e328c.png\"><img src=\"https://user-images.githubusercontent.com/31264567/33162735-1b13082c-d066-11e7-918c-62bec95e328c.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>in this way, i think all the trainable variables (beta, gamma, moving_mean, moving_variance) was stored. and when i print elements in tf.trainable_variables, here is the result.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/31264567/33162835-8c4c091c-d066-11e7-96c9-da7f9b85865e.png\"><img src=\"https://user-images.githubusercontent.com/31264567/33162835-8c4c091c-d066-11e7-96c9-da7f9b85865e.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>missing gamma,<br>\ni extracted the output tensor of the first layer, and manually calculate correspond feature map through these parameters.  its not the same, but can be transformed into the same through linear transformation.<br>\nso, i'm sure there's something wrong with batch_norm params. where can i find the correct ones.</p>", "body_text": "using slim.batch_norm for normalize and here are the batch_norm_params:\n\nin this way, i think all the trainable variables (beta, gamma, moving_mean, moving_variance) was stored. and when i print elements in tf.trainable_variables, here is the result.\n\nmissing gamma,\ni extracted the output tensor of the first layer, and manually calculate correspond feature map through these parameters.  its not the same, but can be transformed into the same through linear transformation.\nso, i'm sure there's something wrong with batch_norm params. where can i find the correct ones.", "body": "using slim.batch_norm for normalize and here are the batch_norm_params:\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/31264567/33162735-1b13082c-d066-11e7-918c-62bec95e328c.png)\r\n\r\n\r\nin this way, i think all the trainable variables (beta, gamma, moving_mean, moving_variance) was stored. and when i print elements in tf.trainable_variables, here is the result. \r\n\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/31264567/33162835-8c4c091c-d066-11e7-96c9-da7f9b85865e.png)\r\n\r\n\r\nmissing gamma, \r\ni extracted the output tensor of the first layer, and manually calculate correspond feature map through these parameters.  its not the same, but can be transformed into the same through linear transformation.\r\nso, i'm sure there's something wrong with batch_norm params. where can i find the correct ones. "}