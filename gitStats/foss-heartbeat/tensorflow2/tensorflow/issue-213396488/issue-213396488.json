{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8277", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8277/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8277/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8277/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8277", "id": 213396488, "node_id": "MDU6SXNzdWUyMTMzOTY0ODg=", "number": 8277, "title": "Different Code Path Taken in conv2d for Constant vs Variable Filter", "user": {"login": "cancan101", "id": 51059, "node_id": "MDQ6VXNlcjUxMDU5", "avatar_url": "https://avatars1.githubusercontent.com/u/51059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cancan101", "html_url": "https://github.com/cancan101", "followers_url": "https://api.github.com/users/cancan101/followers", "following_url": "https://api.github.com/users/cancan101/following{/other_user}", "gists_url": "https://api.github.com/users/cancan101/gists{/gist_id}", "starred_url": "https://api.github.com/users/cancan101/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cancan101/subscriptions", "organizations_url": "https://api.github.com/users/cancan101/orgs", "repos_url": "https://api.github.com/users/cancan101/repos", "events_url": "https://api.github.com/users/cancan101/events{/privacy}", "received_events_url": "https://api.github.com/users/cancan101/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "yzhwang", "id": 1002405, "node_id": "MDQ6VXNlcjEwMDI0MDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1002405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yzhwang", "html_url": "https://github.com/yzhwang", "followers_url": "https://api.github.com/users/yzhwang/followers", "following_url": "https://api.github.com/users/yzhwang/following{/other_user}", "gists_url": "https://api.github.com/users/yzhwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yzhwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yzhwang/subscriptions", "organizations_url": "https://api.github.com/users/yzhwang/orgs", "repos_url": "https://api.github.com/users/yzhwang/repos", "events_url": "https://api.github.com/users/yzhwang/events{/privacy}", "received_events_url": "https://api.github.com/users/yzhwang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "yzhwang", "id": 1002405, "node_id": "MDQ6VXNlcjEwMDI0MDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1002405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yzhwang", "html_url": "https://github.com/yzhwang", "followers_url": "https://api.github.com/users/yzhwang/followers", "following_url": "https://api.github.com/users/yzhwang/following{/other_user}", "gists_url": "https://api.github.com/users/yzhwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yzhwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yzhwang/subscriptions", "organizations_url": "https://api.github.com/users/yzhwang/orgs", "repos_url": "https://api.github.com/users/yzhwang/repos", "events_url": "https://api.github.com/users/yzhwang/events{/privacy}", "received_events_url": "https://api.github.com/users/yzhwang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-03-10T17:02:19Z", "updated_at": "2017-12-22T18:10:44Z", "closed_at": "2017-12-22T18:10:43Z", "author_association": "CONTRIBUTOR", "body_html": "<p>It appears that a different code path is taken in <code>conv2d</code> for Constant vs Variable filters.</p>\n<p>On a box with GPU, this works:</p>\n<div class=\"highlight highlight-source-python\"><pre>images <span class=\"pl-k\">=</span> tf.constant(np.arange(<span class=\"pl-c1\">2</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">15</span>. <span class=\"pl-k\">*</span> <span class=\"pl-c1\">15</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">2</span>).reshape((<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">15</span>,<span class=\"pl-c1\">15</span>)).astype(np.float32))\nfilters <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-v\">initial_value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span> <span class=\"pl-k\">*</span> np.ones((<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">1</span>), np.float32))\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(tf.global_variables_initializer())\n    output <span class=\"pl-k\">=</span> nn_ops.conv2d(\n      images,\n      filters,\n      <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>),\n      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>NCHW<span class=\"pl-pds\">'</span></span>,\n  ).eval()</pre></div>\n<p>however this fails with <code>Check failed: data_format == FORMAT_NHWC Generic conv implementation only supports NHWC tensor format for now.</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre>images <span class=\"pl-k\">=</span> tf.constant(np.arange(<span class=\"pl-c1\">2</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">15</span>. <span class=\"pl-k\">*</span> <span class=\"pl-c1\">15</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">2</span>).reshape((<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">15</span>,<span class=\"pl-c1\">15</span>)).astype(np.float32))\nfilters <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">*</span> np.ones((<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">1</span>), np.float32))\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    output <span class=\"pl-k\">=</span> nn_ops.conv2d(\n      images,\n      filters,\n      <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>),\n      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>NCHW<span class=\"pl-pds\">'</span></span>,\n  ).eval()</pre></div>\n<p>Both of these work (the data_format is supported):</p>\n<div class=\"highlight highlight-source-python\"><pre>images <span class=\"pl-k\">=</span> tf.constant(np.arange(<span class=\"pl-c1\">2</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">15</span>. <span class=\"pl-k\">*</span> <span class=\"pl-c1\">15</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">2</span>).reshape((<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">15</span>,<span class=\"pl-c1\">15</span>,<span class=\"pl-c1\">2</span>)).astype(np.float32))\nfilters <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-v\">initial_value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span> <span class=\"pl-k\">*</span> np.ones((<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">1</span>), np.float32))\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(tf.global_variables_initializer())\n    output <span class=\"pl-k\">=</span> nn_ops.conv2d(\n      images,\n      filters,\n      <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>),\n      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>,\n  ).eval()</pre></div>\n<p>and</p>\n<div class=\"highlight highlight-source-python\"><pre>images <span class=\"pl-k\">=</span> tf.constant(np.arange(<span class=\"pl-c1\">2</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">15</span>. <span class=\"pl-k\">*</span> <span class=\"pl-c1\">15</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">2</span>).reshape((<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">15</span>,<span class=\"pl-c1\">15</span>,<span class=\"pl-c1\">2</span>)).astype(np.float32))\nfilters <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">*</span> np.ones((<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">1</span>), np.float32))\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    output <span class=\"pl-k\">=</span> nn_ops.conv2d(\n      images,\n      filters,\n      <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>),\n      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>,\n  ).eval()</pre></div>\n<p>I don't see a reason for the Constant filter to take what I am guessing is a less efficient code path (not using GPU op) than the Variable Filter.</p>\n<p>To make things even weirder, it seems like even though the GPU is not being used for the Constant, there is still cuda <code>memcpy</code>. Run on 20 calls:</p>\n<pre><code>Time(%)      Time     Calls       Avg       Min       Max  Name\n 52.45%  90.108us        20  4.5050us  4.0950us  6.0800us  [CUDA memcpy HtoD]\n 42.91%  73.726us        20  3.6860us  3.5520us  4.5120us  [CUDA memcpy DtoH]\n  4.64%  7.9680us         1  7.9680us  7.9680us  7.9680us  [CUDA memset]\n</code></pre>", "body_text": "It appears that a different code path is taken in conv2d for Constant vs Variable filters.\nOn a box with GPU, this works:\nimages = tf.constant(np.arange(2*15. * 15*2).reshape((2,2,15,15)).astype(np.float32))\nfilters = tf.Variable(initial_value=1 * np.ones((1,1,2,1), np.float32))\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    output = nn_ops.conv2d(\n      images,\n      filters,\n      strides=(1,1,1,1),\n      padding='VALID',\n      data_format='NCHW',\n  ).eval()\nhowever this fails with Check failed: data_format == FORMAT_NHWC Generic conv implementation only supports NHWC tensor format for now.:\nimages = tf.constant(np.arange(2*15. * 15*2).reshape((2,2,15,15)).astype(np.float32))\nfilters = tf.constant(1 * np.ones((1,1,2,1), np.float32))\nwith tf.Session() as sess:\n    output = nn_ops.conv2d(\n      images,\n      filters,\n      strides=(1,1,1,1),\n      padding='VALID',\n      data_format='NCHW',\n  ).eval()\nBoth of these work (the data_format is supported):\nimages = tf.constant(np.arange(2*15. * 15*2).reshape((2,15,15,2)).astype(np.float32))\nfilters = tf.Variable(initial_value=1 * np.ones((1,1,2,1), np.float32))\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    output = nn_ops.conv2d(\n      images,\n      filters,\n      strides=(1,1,1,1),\n      padding='VALID',\n  ).eval()\nand\nimages = tf.constant(np.arange(2*15. * 15*2).reshape((2,15,15,2)).astype(np.float32))\nfilters = tf.constant(1 * np.ones((1,1,2,1), np.float32))\nwith tf.Session() as sess:\n    output = nn_ops.conv2d(\n      images,\n      filters,\n      strides=(1,1,1,1),\n      padding='VALID',\n  ).eval()\nI don't see a reason for the Constant filter to take what I am guessing is a less efficient code path (not using GPU op) than the Variable Filter.\nTo make things even weirder, it seems like even though the GPU is not being used for the Constant, there is still cuda memcpy. Run on 20 calls:\nTime(%)      Time     Calls       Avg       Min       Max  Name\n 52.45%  90.108us        20  4.5050us  4.0950us  6.0800us  [CUDA memcpy HtoD]\n 42.91%  73.726us        20  3.6860us  3.5520us  4.5120us  [CUDA memcpy DtoH]\n  4.64%  7.9680us         1  7.9680us  7.9680us  7.9680us  [CUDA memset]", "body": "It appears that a different code path is taken in `conv2d` for Constant vs Variable filters.\r\n\r\nOn a box with GPU, this works:\r\n```python\r\nimages = tf.constant(np.arange(2*15. * 15*2).reshape((2,2,15,15)).astype(np.float32))\r\nfilters = tf.Variable(initial_value=1 * np.ones((1,1,2,1), np.float32))\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    output = nn_ops.conv2d(\r\n      images,\r\n      filters,\r\n      strides=(1,1,1,1),\r\n      padding='VALID',\r\n      data_format='NCHW',\r\n  ).eval()\r\n```\r\nhowever this fails with `Check failed: data_format == FORMAT_NHWC Generic conv implementation only supports NHWC tensor format for now.`:\r\n```python\r\nimages = tf.constant(np.arange(2*15. * 15*2).reshape((2,2,15,15)).astype(np.float32))\r\nfilters = tf.constant(1 * np.ones((1,1,2,1), np.float32))\r\nwith tf.Session() as sess:\r\n    output = nn_ops.conv2d(\r\n      images,\r\n      filters,\r\n      strides=(1,1,1,1),\r\n      padding='VALID',\r\n      data_format='NCHW',\r\n  ).eval()\r\n```\r\n\r\nBoth of these work (the data_format is supported):\r\n```python\r\nimages = tf.constant(np.arange(2*15. * 15*2).reshape((2,15,15,2)).astype(np.float32))\r\nfilters = tf.Variable(initial_value=1 * np.ones((1,1,2,1), np.float32))\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    output = nn_ops.conv2d(\r\n      images,\r\n      filters,\r\n      strides=(1,1,1,1),\r\n      padding='VALID',\r\n  ).eval()\r\n```\r\nand\r\n```python\r\nimages = tf.constant(np.arange(2*15. * 15*2).reshape((2,15,15,2)).astype(np.float32))\r\nfilters = tf.constant(1 * np.ones((1,1,2,1), np.float32))\r\nwith tf.Session() as sess:\r\n    output = nn_ops.conv2d(\r\n      images,\r\n      filters,\r\n      strides=(1,1,1,1),\r\n      padding='VALID',\r\n  ).eval()\r\n```\r\nI don't see a reason for the Constant filter to take what I am guessing is a less efficient code path (not using GPU op) than the Variable Filter.\r\n\r\nTo make things even weirder, it seems like even though the GPU is not being used for the Constant, there is still cuda `memcpy`. Run on 20 calls:\r\n```\r\nTime(%)      Time     Calls       Avg       Min       Max  Name\r\n 52.45%  90.108us        20  4.5050us  4.0950us  6.0800us  [CUDA memcpy HtoD]\r\n 42.91%  73.726us        20  3.6860us  3.5520us  4.5120us  [CUDA memcpy DtoH]\r\n  4.64%  7.9680us         1  7.9680us  7.9680us  7.9680us  [CUDA memset]\r\n```"}