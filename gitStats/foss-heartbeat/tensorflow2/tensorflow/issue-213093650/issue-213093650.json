{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8242", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8242/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8242/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8242/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8242", "id": 213093650, "node_id": "MDU6SXNzdWUyMTMwOTM2NTA=", "number": 8242, "title": "Operations used for inference are dropped by optimize_for_inference", "user": {"login": "tristandeleu", "id": 2018752, "node_id": "MDQ6VXNlcjIwMTg3NTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/2018752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tristandeleu", "html_url": "https://github.com/tristandeleu", "followers_url": "https://api.github.com/users/tristandeleu/followers", "following_url": "https://api.github.com/users/tristandeleu/following{/other_user}", "gists_url": "https://api.github.com/users/tristandeleu/gists{/gist_id}", "starred_url": "https://api.github.com/users/tristandeleu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tristandeleu/subscriptions", "organizations_url": "https://api.github.com/users/tristandeleu/orgs", "repos_url": "https://api.github.com/users/tristandeleu/repos", "events_url": "https://api.github.com/users/tristandeleu/events{/privacy}", "received_events_url": "https://api.github.com/users/tristandeleu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-03-09T16:36:48Z", "updated_at": "2018-02-06T09:16:55Z", "closed_at": "2017-07-12T23:14:17Z", "author_association": "NONE", "body_html": "<p>Inspired by the <a href=\"https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/\" rel=\"nofollow\">TensorFlow for Poets</a>, I have been exporting models optimized for inference with the <code>freeze_graph</code> and <code>optimize_for_inference</code>. I have run into an issue where some of the nodes required for inference get dropped by <code>optimize_for_inference</code>. The most critical one being the output node being dropped, even though it was explicitly given to <code>freeze_graph</code> and <code>optimize_for_inference</code> (through the <code>output_node_name</code>/<code>output_names</code>).</p>\n<p>I think that might be related to the output node being a <code>tf.identity</code> (to give an explicit name to the result of a <code>tf.layers</code> for example).</p>\n<h3>Minimal working example</h3>\n<p>Here is a piece of code to create a very simple model, running on TensorFlow v.1.0.1.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nl_input <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">2</span>), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>)\nl_dense <span class=\"pl-k\">=</span> tf.layers.dense(l_input, <span class=\"pl-v\">units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>)\nl_output <span class=\"pl-k\">=</span> tf.identity(l_dense, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(tf.global_variables_initializer())\n    saver <span class=\"pl-k\">=</span> tf.train.Saver(tf.global_variables())\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Save GraphDef</span>\n    tf.train.write_graph(sess.graph_def, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>.<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph.pb<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Save Checkpoint</span>\n    saver.save(sess, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>model.ckpt<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">write_meta_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)</pre></div>\n<p>I am exporting the model using the <code>freeze_graph</code> and <code>optimize_for_inference</code> tools, inspired by the <a href=\"https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/\" rel=\"nofollow\">TensorFlow for Poets post</a>.</p>\n<pre><code>bazel-bin/tensorflow/python/tools/freeze_graph --input_graph graph.pb --input_checkpoint model.ckpt --output_graph graph_frozen.pb --output_node_name=output\n</code></pre>\n<pre><code>bazel-bin/tensorflow/python/tools/optimize_for_inference --input graph_frozen.pb --output graph_optimized.pb --input_names=input --output_names=output\n</code></pre>\n<p>I am using Python to load both of these models (<code>graph_frozen.pb</code> and <code>graph_optimized.pb</code>). The model defined by <code>graph_frozen.pb</code> works as expected, but the model defined by <code>graph_optimized.pb</code> is missing some operations (<code>import/dense/BiasAdd</code> and <code>import/output</code>).</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Data</span>\nx <span class=\"pl-k\">=</span> np.random.rand(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">2</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Frozen Graph</span>\n<span class=\"pl-k\">with</span> tf.gfile.GFile(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph_frozen.pb<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n    graph_def_frozen <span class=\"pl-k\">=</span> tf.GraphDef()\n    graph_def_frozen.ParseFromString(f.read())\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default() <span class=\"pl-k\">as</span> graph:\n    l_output, <span class=\"pl-k\">=</span> tf.import_graph_def(graph_def_frozen,\n        <span class=\"pl-v\">return_elements</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>output:0<span class=\"pl-pds\">'</span></span>], \n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>import<span class=\"pl-pds\">'</span></span>\n    )\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Operations in Frozen Graph:<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c1\">print</span>([op.name <span class=\"pl-k\">for</span> op <span class=\"pl-k\">in</span> graph.get_operations()])\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> &gt;&gt;&gt; [u'import/input', u'import/dense/kernel',</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>      u'import/dense/kernel/read', u'import/dense/bias',</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>      u'import/dense/bias/read', u'import/dense/MatMul',</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>      u'import/dense/BiasAdd', u'import/output']</span>\n\n    l_input <span class=\"pl-k\">=</span> graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>import/input:0<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph) <span class=\"pl-k\">as</span> sess:\n        sess.run(l_output, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{l_input: x})\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Optimized Graph</span>\n<span class=\"pl-k\">with</span> tf.gfile.GFile(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph_optimized.pb<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n    graph_def_optimized <span class=\"pl-k\">=</span> tf.GraphDef()\n    graph_def_optimized.ParseFromString(f.read())\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default() <span class=\"pl-k\">as</span> graph:\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Using `return_elements=['output:0']` raises a ValueError</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> ValueError: Requested return_element 'output:0' not found in graph_def.</span>\n    tf.import_graph_def(graph_def_optimized, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>import<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Operations in Optimized Graph:<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c1\">print</span>([op.name <span class=\"pl-k\">for</span> op <span class=\"pl-k\">in</span> graph.get_operations()])\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> &gt;&gt;&gt; [u'import/input', u'import/dense/kernel',</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>      u'import/dense/bias', u'import/dense/MatMul']</span>\n\n    l_input <span class=\"pl-k\">=</span> graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>import/input:0<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Raises a KeyError</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> KeyError: \"The name 'import/output:0' refers to a Tensor which does</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> not exist. The operation, 'import/output', does not exist in the graph.\"</span>\n    l_output <span class=\"pl-k\">=</span> graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>import/output:0<span class=\"pl-pds\">'</span></span>)\n    \n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph) <span class=\"pl-k\">as</span> sess:\n        sess.run(l_output, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{l_input: x})</pre></div>\n<h3>Environment info</h3>\n<ul>\n<li>Operating System: OSX 10.11.1</li>\n<li>TensorFlow installed through pip (<code>tensorflow-1.0.1-cp27-cp27m-macosx_10_11_x86_64.whl</code>)</li>\n<li>TensorFlow v.1.0.1</li>\n<li>To export the models, I built <code>freeze_graph</code> and <code>optimize_for_inference</code> with bazel (version 0.4.3-homebrew) in <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/100552f943c78cbf90aad521f9981df9b5e3c738/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/100552f943c78cbf90aad521f9981df9b5e3c738\"><tt>100552f</tt></a></li>\n</ul>", "body_text": "Inspired by the TensorFlow for Poets, I have been exporting models optimized for inference with the freeze_graph and optimize_for_inference. I have run into an issue where some of the nodes required for inference get dropped by optimize_for_inference. The most critical one being the output node being dropped, even though it was explicitly given to freeze_graph and optimize_for_inference (through the output_node_name/output_names).\nI think that might be related to the output node being a tf.identity (to give an explicit name to the result of a tf.layers for example).\nMinimal working example\nHere is a piece of code to create a very simple model, running on TensorFlow v.1.0.1.\nimport tensorflow as tf\n\nl_input = tf.placeholder(tf.float32, shape=(None, 2), name='input')\nl_dense = tf.layers.dense(l_input, units=1, activation=None)\nl_output = tf.identity(l_dense, name='output')\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    saver = tf.train.Saver(tf.global_variables())\n    \n    # Save GraphDef\n    tf.train.write_graph(sess.graph_def, '.', 'graph.pb')\n    # Save Checkpoint\n    saver.save(sess, 'model.ckpt', write_meta_graph=False)\nI am exporting the model using the freeze_graph and optimize_for_inference tools, inspired by the TensorFlow for Poets post.\nbazel-bin/tensorflow/python/tools/freeze_graph --input_graph graph.pb --input_checkpoint model.ckpt --output_graph graph_frozen.pb --output_node_name=output\n\nbazel-bin/tensorflow/python/tools/optimize_for_inference --input graph_frozen.pb --output graph_optimized.pb --input_names=input --output_names=output\n\nI am using Python to load both of these models (graph_frozen.pb and graph_optimized.pb). The model defined by graph_frozen.pb works as expected, but the model defined by graph_optimized.pb is missing some operations (import/dense/BiasAdd and import/output).\nimport tensorflow as tf\nimport numpy as np\n\n# Data\nx = np.random.rand(3, 2)\n\n# Frozen Graph\nwith tf.gfile.GFile('graph_frozen.pb', 'rb') as f:\n    graph_def_frozen = tf.GraphDef()\n    graph_def_frozen.ParseFromString(f.read())\n\nwith tf.Graph().as_default() as graph:\n    l_output, = tf.import_graph_def(graph_def_frozen,\n        return_elements=['output:0'], \n        name='import'\n    )\n    print('Operations in Frozen Graph:')\n    print([op.name for op in graph.get_operations()])\n    # >>> [u'import/input', u'import/dense/kernel',\n    #      u'import/dense/kernel/read', u'import/dense/bias',\n    #      u'import/dense/bias/read', u'import/dense/MatMul',\n    #      u'import/dense/BiasAdd', u'import/output']\n\n    l_input = graph.get_tensor_by_name('import/input:0')\n\n    with tf.Session(graph=graph) as sess:\n        sess.run(l_output, feed_dict={l_input: x})\n\n# Optimized Graph\nwith tf.gfile.GFile('graph_optimized.pb', 'rb') as f:\n    graph_def_optimized = tf.GraphDef()\n    graph_def_optimized.ParseFromString(f.read())\n\nwith tf.Graph().as_default() as graph:\n    # Using `return_elements=['output:0']` raises a ValueError\n    # ValueError: Requested return_element 'output:0' not found in graph_def.\n    tf.import_graph_def(graph_def_optimized, name='import')\n    print('Operations in Optimized Graph:')\n    print([op.name for op in graph.get_operations()])\n    # >>> [u'import/input', u'import/dense/kernel',\n    #      u'import/dense/bias', u'import/dense/MatMul']\n\n    l_input = graph.get_tensor_by_name('import/input:0')\n\n    # Raises a KeyError\n    # KeyError: \"The name 'import/output:0' refers to a Tensor which does\n    # not exist. The operation, 'import/output', does not exist in the graph.\"\n    l_output = graph.get_tensor_by_name('import/output:0')\n    \n    with tf.Session(graph=graph) as sess:\n        sess.run(l_output, feed_dict={l_input: x})\nEnvironment info\n\nOperating System: OSX 10.11.1\nTensorFlow installed through pip (tensorflow-1.0.1-cp27-cp27m-macosx_10_11_x86_64.whl)\nTensorFlow v.1.0.1\nTo export the models, I built freeze_graph and optimize_for_inference with bazel (version 0.4.3-homebrew) in 100552f", "body": "Inspired by the [TensorFlow for Poets](https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/), I have been exporting models optimized for inference with the `freeze_graph` and `optimize_for_inference`. I have run into an issue where some of the nodes required for inference get dropped by `optimize_for_inference`. The most critical one being the output node being dropped, even though it was explicitly given to `freeze_graph` and `optimize_for_inference` (through the `output_node_name`/`output_names`).\r\n\r\nI think that might be related to the output node being a `tf.identity` (to give an explicit name to the result of a `tf.layers` for example).\r\n\r\n### Minimal working example\r\nHere is a piece of code to create a very simple model, running on TensorFlow v.1.0.1.\r\n```python\r\nimport tensorflow as tf\r\n\r\nl_input = tf.placeholder(tf.float32, shape=(None, 2), name='input')\r\nl_dense = tf.layers.dense(l_input, units=1, activation=None)\r\nl_output = tf.identity(l_dense, name='output')\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    saver = tf.train.Saver(tf.global_variables())\r\n    \r\n    # Save GraphDef\r\n    tf.train.write_graph(sess.graph_def, '.', 'graph.pb')\r\n    # Save Checkpoint\r\n    saver.save(sess, 'model.ckpt', write_meta_graph=False)\r\n```\r\nI am exporting the model using the `freeze_graph` and `optimize_for_inference` tools, inspired by the [TensorFlow for Poets post](https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/).\r\n```\r\nbazel-bin/tensorflow/python/tools/freeze_graph --input_graph graph.pb --input_checkpoint model.ckpt --output_graph graph_frozen.pb --output_node_name=output\r\n```\r\n```\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference --input graph_frozen.pb --output graph_optimized.pb --input_names=input --output_names=output\r\n```\r\nI am using Python to load both of these models (`graph_frozen.pb` and `graph_optimized.pb`). The model defined by `graph_frozen.pb` works as expected, but the model defined by `graph_optimized.pb` is missing some operations (`import/dense/BiasAdd` and `import/output`).\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# Data\r\nx = np.random.rand(3, 2)\r\n\r\n# Frozen Graph\r\nwith tf.gfile.GFile('graph_frozen.pb', 'rb') as f:\r\n    graph_def_frozen = tf.GraphDef()\r\n    graph_def_frozen.ParseFromString(f.read())\r\n\r\nwith tf.Graph().as_default() as graph:\r\n    l_output, = tf.import_graph_def(graph_def_frozen,\r\n        return_elements=['output:0'], \r\n        name='import'\r\n    )\r\n    print('Operations in Frozen Graph:')\r\n    print([op.name for op in graph.get_operations()])\r\n    # >>> [u'import/input', u'import/dense/kernel',\r\n    #      u'import/dense/kernel/read', u'import/dense/bias',\r\n    #      u'import/dense/bias/read', u'import/dense/MatMul',\r\n    #      u'import/dense/BiasAdd', u'import/output']\r\n\r\n    l_input = graph.get_tensor_by_name('import/input:0')\r\n\r\n    with tf.Session(graph=graph) as sess:\r\n        sess.run(l_output, feed_dict={l_input: x})\r\n\r\n# Optimized Graph\r\nwith tf.gfile.GFile('graph_optimized.pb', 'rb') as f:\r\n    graph_def_optimized = tf.GraphDef()\r\n    graph_def_optimized.ParseFromString(f.read())\r\n\r\nwith tf.Graph().as_default() as graph:\r\n    # Using `return_elements=['output:0']` raises a ValueError\r\n    # ValueError: Requested return_element 'output:0' not found in graph_def.\r\n    tf.import_graph_def(graph_def_optimized, name='import')\r\n    print('Operations in Optimized Graph:')\r\n    print([op.name for op in graph.get_operations()])\r\n    # >>> [u'import/input', u'import/dense/kernel',\r\n    #      u'import/dense/bias', u'import/dense/MatMul']\r\n\r\n    l_input = graph.get_tensor_by_name('import/input:0')\r\n\r\n    # Raises a KeyError\r\n    # KeyError: \"The name 'import/output:0' refers to a Tensor which does\r\n    # not exist. The operation, 'import/output', does not exist in the graph.\"\r\n    l_output = graph.get_tensor_by_name('import/output:0')\r\n    \r\n    with tf.Session(graph=graph) as sess:\r\n        sess.run(l_output, feed_dict={l_input: x})\r\n```\r\n\r\n### Environment info\r\n - Operating System: OSX 10.11.1\r\n - TensorFlow installed through pip (`tensorflow-1.0.1-cp27-cp27m-macosx_10_11_x86_64.whl`)\r\n - TensorFlow v.1.0.1\r\n - To export the models, I built `freeze_graph` and `optimize_for_inference` with bazel (version 0.4.3-homebrew) in 100552f943c78cbf90aad521f9981df9b5e3c738\r\n"}