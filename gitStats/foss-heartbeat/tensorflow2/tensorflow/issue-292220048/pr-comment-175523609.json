{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/175523609", "pull_request_review_id": 105066762, "id": 175523609, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NTUyMzYwOQ==", "diff_hunk": "@@ -25,92 +25,200 @@\n #include \"tensorflow/core/framework/shape_inference.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/util/work_sharder.h\"\n \n namespace {\n \n-template <class IndexVecT, class IndexT>\n-IndexT compute_input_index(\n-    IndexVecT* target_dimensions, const IndexT& output_index,\n-    const IndexVecT& original_dimensions, const int& adjustable_dimension,\n-    const std::vector<tensorflow::int64>& dimension_ceiling,\n-    const std::vector<tensorflow::int64>& cumulative_dimensions, IndexT* result,\n-    std::vector<IndexT>* output_indices, const int& rank) {\n-  *result = 0;\n-  output_indices->clear();\n+// Computes input tensor index for given output index during forward\n+// propagation through periodic_resample operation.\n+class InputIndexer {\n+ public:\n+  InputIndexer(const std::vector<tensorflow::int64>& output_dimensions,\n+               const tensorflow::TensorShape& input_shape,\n+               int adjustable_dimension)\n+      : output_dimensions_(output_dimensions),\n+        adjustable_dimension_(adjustable_dimension),\n+        rank_(input_shape.dims()),\n+        linear_output_index_(0),\n+        linear_input_index_(0),\n+        adjustable_dimension_carriage_sum_(0) {\n+    auto input_dimensions = TensorShapeToVector(input_shape);\n+    // factors by which input_dimensions increases/decreases w.r.t.\n+    // output_dimensions\n+    dimension_ceiling_ =\n+        ComputeDimensionCeiling(output_dimensions, input_dimensions);\n+    cumulative_dimensions_ = ComputeCumulativeDimensions();\n+\n+    output_indices_.resize(output_dimensions_.size());\n+    input_indices_.resize(output_dimensions_.size());\n+\n+    // Compute index_factors\n+    index_factors_.resize(rank_);\n+    tensorflow::int64 last_index_factor = 1;\n+    for (auto r = rank_ - 1; r >= 0; --r) {\n+      index_factors_[r] = last_index_factor;\n+      last_index_factor *= input_dimensions[r];\n+    }\n+  }\n+\n+  tensorflow::int64 linear_input_index() const { return linear_input_index_; }\n+\n+  void MoveToOutputIndex(tensorflow::int64 output_index);\n+  void IncrementOutputIndex();\n+\n+ private:\n+  void RecomputeInputAdjustableDimensionIndex() {\n+    tensorflow::int64 index = adjustable_dimension_carriage_sum_;\n+    index *= output_dimensions_[adjustable_dimension_];\n+    index += output_indices_[adjustable_dimension_];\n+    input_indices_[adjustable_dimension_] = index;\n+  }\n+\n+  std::vector<tensorflow::int64> TensorShapeToVector(\n+      const tensorflow::TensorShape& tensor_shape);\n+\n+  std::vector<tensorflow::int64> ComputeDimensionCeiling(\n+      const std::vector<tensorflow::int64>& output_dimensions,\n+      const std::vector<tensorflow::int64>& input_dimensions);\n+\n+  std::vector<tensorflow::int64> ComputeCumulativeDimensions();\n+\n+  const std::vector<tensorflow::int64> output_dimensions_;\n+  std::vector<tensorflow::int64> dimension_ceiling_;\n+  std::vector<tensorflow::int64> index_factors_;\n+  std::vector<tensorflow::int64> cumulative_dimensions_;\n+  std::vector<tensorflow::int64> output_indices_;\n+  std::vector<tensorflow::int64> input_indices_;\n+\n+  const int adjustable_dimension_;\n+  const int rank_;\n+  tensorflow::int64 linear_output_index_;\n+  tensorflow::int64 linear_input_index_;\n+  tensorflow::int64 adjustable_dimension_carriage_sum_;\n+};\n+\n+void InputIndexer::MoveToOutputIndex(tensorflow::int64 output_index) {\n+  linear_output_index_ = output_index;\n+  linear_input_index_ = 0;\n \n   // un-rasterize the output index\n   auto last_reduced_i = output_index;\n-  for (auto r = rank - 1; r >= 0; --r) {\n-    (*output_indices)[r] = last_reduced_i % (*target_dimensions)[r];\n+  for (auto r = rank_ - 1; r >= 0; --r) {\n+    output_indices_[r] = last_reduced_i % output_dimensions_[r];\n     last_reduced_i =\n-        (last_reduced_i - (*output_indices)[r]) / (*target_dimensions)[r];\n+        (last_reduced_i - output_indices_[r]) / output_dimensions_[r];\n   }\n \n+  tensorflow::int64 carriage_sum = 0;\n+  for (int qi = 0; qi < rank_; ++qi) {\n+    if (qi == adjustable_dimension_) continue;\n+    carriage_sum += cumulative_dimensions_[qi] *\n+                    (output_indices_[qi] % dimension_ceiling_[qi]);\n+  }\n+  adjustable_dimension_carriage_sum_ = carriage_sum;\n+\n   // rasterize the input index\n-  IndexT last_index_factor = 1;\n-  for (auto r = rank - 1; r >= 0; --r) {\n-    IndexT index = 0;\n-    if (r != adjustable_dimension)\n-      index = (*output_indices)[r] / dimension_ceiling[r];\n-    else {\n-      for (int qi = 0; qi < rank; ++qi) {\n-        if (qi == adjustable_dimension) continue;\n-        index += cumulative_dimensions[qi] *\n-                 ((*output_indices)[qi] % dimension_ceiling[qi]);\n-      }\n-      index *= (*target_dimensions)[adjustable_dimension];\n-      index += (*output_indices)[r];\n+  for (auto r = rank_ - 1; r >= 0; --r) {\n+    if (r != adjustable_dimension_)\n+      input_indices_[r] = output_indices_[r] / dimension_ceiling_[r];\n+    else\n+      RecomputeInputAdjustableDimensionIndex();\n+  }\n+  for (auto r = rank_ - 1; r >= 0; --r) {\n+    linear_input_index_ += index_factors_[r] * input_indices_[r];\n+  }\n+}\n+\n+void InputIndexer::IncrementOutputIndex() {\n+  linear_output_index_++;\n+  for (auto r = rank_ - 1; r >= 0; --r) {\n+    auto old_carriage_sum_increment =\n+        cumulative_dimensions_[r] *\n+        (output_indices_[r] % dimension_ceiling_[r]);\n+    output_indices_[r] = (output_indices_[r] + 1) % output_dimensions_[r];\n+    if (r != adjustable_dimension_) {\n+      auto new_input_index = output_indices_[r] / dimension_ceiling_[r];\n+      linear_input_index_ +=\n+          (new_input_index - input_indices_[r]) * index_factors_[r];\n+\n+      input_indices_[r] = new_input_index;\n+\n+      auto new_carriage_sum_increment =\n+          cumulative_dimensions_[r] *\n+          (output_indices_[r] % dimension_ceiling_[r]);\n+\n+      adjustable_dimension_carriage_sum_ = adjustable_dimension_carriage_sum_ -\n+                                           old_carriage_sum_increment +\n+                                           new_carriage_sum_increment;\n+    }\n+\n+    if (output_indices_[r] != 0) {\n+      // No more carries to higher indices.\n+      break;\n     }\n-    *result += last_index_factor * index;\n-    last_index_factor *= original_dimensions[r];\n   }\n+  auto old_adjustable_dimension_input_index =\n+      input_indices_[adjustable_dimension_];\n+  RecomputeInputAdjustableDimensionIndex();\n+  linear_input_index_ += (input_indices_[adjustable_dimension_] -\n+                           old_adjustable_dimension_input_index) *\n+                          index_factors_[adjustable_dimension_];\n+}\n \n-  return *result;\n+std::vector<tensorflow::int64> InputIndexer::TensorShapeToVector(\n+    const tensorflow::TensorShape& tensor_shape) {\n+  std::vector<tensorflow::int64> result(tensor_shape.dims());\n+  int count = 0;\n+  for (const auto dim_info : tensor_shape) {\n+    result[count] = dim_info.size;\n+    ++count;\n+  }\n+  return result;\n }\n \n-template <class InputDataT,\n-          class IndexVecT>  // both types are needed here b/c IndexVecT and\n-                            // InputDataT are not related\n-                            void\n-                            fill_periodic_tensor(\n-                                tensorflow::OpKernelContext* context,\n-                                const IndexVecT& desired_shape,\n-                                const tensorflow::Tensor& input_tensor) {\n-  // input is a strided array (last index is fastest, C-ordered)\n-  auto input = input_tensor.flat<InputDataT>();\n-  const int rank = input_tensor.dims();\n-  // original and target dimensions\n-  std::vector<tensorflow::int64> original_dimensions(rank),\n-      target_dimensions(rank);\n-  tensorflow::int64 total_size(input_tensor.NumElements()), new_sliced_size(1);\n-  // factors by which original_dimensions increases/decreases w.r.t.\n-  // target_dimensions\n-  std::vector<tensorflow::int64> dimension_ceiling(rank),\n-      cumulative_dimensions(rank);\n-  // index of adjustable dimension\n-  int adjustable_dimension;\n-  tensorflow::TensorShape output_shape;\n+std::vector<tensorflow::int64> InputIndexer::ComputeDimensionCeiling(\n+    const std::vector<tensorflow::int64>& output_dimensions,\n+    const std::vector<tensorflow::int64>& input_dimensions) {\n+  std::vector<tensorflow::int64> dimension_ceiling(input_dimensions.size());\n+  for (size_t i = 0; i < input_dimensions.size(); ++i) {\n+    dimension_ceiling[i] = tensorflow::int64(\n+        std::ceil(float(output_dimensions[i]) / float(input_dimensions[i])));", "path": "tensorflow/contrib/periodic_resample/kernels/periodic_resample_op.h", "position": null, "original_position": 211, "commit_id": "5916a8ea00719e389ed9c667ddc83c73ca6cd4aa", "original_commit_id": "1677dea2161195bee199a5c310ad0e6b6e02aa98", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "There is no need to use floating point arithmetic to compute ceil(a/b) for integers, use the formula (a + b - 1) / b. It is defined as a macro in numerous places. You can also use the templated Eigen function Eigen::div_up(a, b).", "created_at": "2018-03-19T17:38:48Z", "updated_at": "2018-05-09T11:46:55Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16520#discussion_r175523609", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16520", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/175523609"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16520#discussion_r175523609"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16520"}}, "body_html": "<p>There is no need to use floating point arithmetic to compute ceil(a/b) for integers, use the formula (a + b - 1) / b. It is defined as a macro in numerous places. You can also use the templated Eigen function Eigen::div_up(a, b).</p>", "body_text": "There is no need to use floating point arithmetic to compute ceil(a/b) for integers, use the formula (a + b - 1) / b. It is defined as a macro in numerous places. You can also use the templated Eigen function Eigen::div_up(a, b)."}