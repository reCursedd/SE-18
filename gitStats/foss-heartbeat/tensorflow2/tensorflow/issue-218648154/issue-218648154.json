{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8887", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8887/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8887/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8887/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8887", "id": 218648154, "node_id": "MDU6SXNzdWUyMTg2NDgxNTQ=", "number": 8887, "title": "Embedding visualizations for hi-res images training (feature request)", "user": {"login": "argavish", "id": 26752557, "node_id": "MDQ6VXNlcjI2NzUyNTU3", "avatar_url": "https://avatars3.githubusercontent.com/u/26752557?v=4", "gravatar_id": "", "url": "https://api.github.com/users/argavish", "html_url": "https://github.com/argavish", "followers_url": "https://api.github.com/users/argavish/followers", "following_url": "https://api.github.com/users/argavish/following{/other_user}", "gists_url": "https://api.github.com/users/argavish/gists{/gist_id}", "starred_url": "https://api.github.com/users/argavish/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/argavish/subscriptions", "organizations_url": "https://api.github.com/users/argavish/orgs", "repos_url": "https://api.github.com/users/argavish/repos", "events_url": "https://api.github.com/users/argavish/events{/privacy}", "received_events_url": "https://api.github.com/users/argavish/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284285184, "node_id": "MDU6TGFiZWwyODQyODUxODQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:tensorboard", "name": "comp:tensorboard", "color": "0052cc", "default": false}, {"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-04-01T00:10:34Z", "updated_at": "2017-06-16T22:03:01Z", "closed_at": "2017-06-16T22:03:01Z", "author_association": "NONE", "body_html": "<p>Hi Tensorflow people, thank you all.<br>\nI wonder if I could train my image classification model on my normal sized images (1080px X 1920px) but still use Tensorboard's cool embedding visualizations. I prefer to keep the images with the highest resolution possible since it proved to be important for the classification.</p>\n<p>In the tutorial (<a href=\"https://www.tensorflow.org/get_started/embedding_viz\" rel=\"nofollow\">https://www.tensorflow.org/get_started/embedding_viz</a>) the developers specify tensorflow currently supports sprites up to 8192px X 8192px, meaning you can either use a lot of low-res images (fine for MNIST 28X28 and CIFAR-10 32X32) or a few high-res images (a too small training set size). So, I was wondering if there could be a way around it.</p>\n<p><strong>What if, we could use full-res photos for training, but downsize them for the thumbnails needed to make up the sprite?</strong><br>\nThat way we could still get a sense of which picture is which in the visualization, but let the model train on higher quality data.</p>\n<ol>\n<li>Can I do it myself, by creating a low-res (down-sized) copy of my entire database beforehand, and use it to create the sprite etc., will the embedding event still correlate to the same source image (and the right label in the metadata)?</li>\n<li>Instead, should I put inside the training code itself, a small procedure for resizing of the full-res image after each bottleneck calculation, and then store that thumbnail in a separate folder - making sure the embedding log in the metadata actually corresponds to the right thumbnail?</li>\n</ol>\n<hr>\n<p>Environment info:</p>\n<p>Ubuntu 16.04.02 (64 bit)<br>\ntensorflow 0.12.1 CPU only (64 bit). I have a NVIDIA GTX 1050ti waiting to be used if crucial for this task.</p>\n<p>I'm am a kind of a coding noob so forgive my inaccuracies and ignorance. I'm relatively new (6 months) to tensorflow and CNNs in general. I've been transfer-training inception V3 on classification of large (1080px X 1920px) images, divided to 10 labels (folders).<br>\nThe reason I'm asking and not just diving deep into it is that I'll have to spend a lot of time to resize my images and create the perfect sprite image and metadata file, but won't have the confidence that the trained data corresponds to the sprite image. So I want to see if it's even possible to begin with - <strong>to get full certainty of visualized thumbnail corresponding to actual full-res image used for training.</strong></p>\n<p>Thank you for this great platform!! Tensorboard is a very powerful tool and I'm very excited to unlock the embedding visualizations' potential. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=38796628\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dandelionmane\">@dandelionmane</a></p>", "body_text": "Hi Tensorflow people, thank you all.\nI wonder if I could train my image classification model on my normal sized images (1080px X 1920px) but still use Tensorboard's cool embedding visualizations. I prefer to keep the images with the highest resolution possible since it proved to be important for the classification.\nIn the tutorial (https://www.tensorflow.org/get_started/embedding_viz) the developers specify tensorflow currently supports sprites up to 8192px X 8192px, meaning you can either use a lot of low-res images (fine for MNIST 28X28 and CIFAR-10 32X32) or a few high-res images (a too small training set size). So, I was wondering if there could be a way around it.\nWhat if, we could use full-res photos for training, but downsize them for the thumbnails needed to make up the sprite?\nThat way we could still get a sense of which picture is which in the visualization, but let the model train on higher quality data.\n\nCan I do it myself, by creating a low-res (down-sized) copy of my entire database beforehand, and use it to create the sprite etc., will the embedding event still correlate to the same source image (and the right label in the metadata)?\nInstead, should I put inside the training code itself, a small procedure for resizing of the full-res image after each bottleneck calculation, and then store that thumbnail in a separate folder - making sure the embedding log in the metadata actually corresponds to the right thumbnail?\n\n\nEnvironment info:\nUbuntu 16.04.02 (64 bit)\ntensorflow 0.12.1 CPU only (64 bit). I have a NVIDIA GTX 1050ti waiting to be used if crucial for this task.\nI'm am a kind of a coding noob so forgive my inaccuracies and ignorance. I'm relatively new (6 months) to tensorflow and CNNs in general. I've been transfer-training inception V3 on classification of large (1080px X 1920px) images, divided to 10 labels (folders).\nThe reason I'm asking and not just diving deep into it is that I'll have to spend a lot of time to resize my images and create the perfect sprite image and metadata file, but won't have the confidence that the trained data corresponds to the sprite image. So I want to see if it's even possible to begin with - to get full certainty of visualized thumbnail corresponding to actual full-res image used for training.\nThank you for this great platform!! Tensorboard is a very powerful tool and I'm very excited to unlock the embedding visualizations' potential. @dandelionmane", "body": "Hi Tensorflow people, thank you all.\r\nI wonder if I could train my image classification model on my normal sized images (1080px X 1920px) but still use Tensorboard's cool embedding visualizations. I prefer to keep the images with the highest resolution possible since it proved to be important for the classification.\r\n\r\nIn the tutorial (https://www.tensorflow.org/get_started/embedding_viz) the developers specify tensorflow currently supports sprites up to 8192px X 8192px, meaning you can either use a lot of low-res images (fine for MNIST 28X28 and CIFAR-10 32X32) or a few high-res images (a too small training set size). So, I was wondering if there could be a way around it.\r\n\r\n**What if, we could use full-res photos for training, but downsize them for the thumbnails needed to make up the sprite?**\r\nThat way we could still get a sense of which picture is which in the visualization, but let the model train on higher quality data.\r\n\r\n1. Can I do it myself, by creating a low-res (down-sized) copy of my entire database beforehand, and use it to create the sprite etc., will the embedding event still correlate to the same source image (and the right label in the metadata)?\r\n2. Instead, should I put inside the training code itself, a small procedure for resizing of the full-res image after each bottleneck calculation, and then store that thumbnail in a separate folder - making sure the embedding log in the metadata actually corresponds to the right thumbnail?\r\n\r\n***************************************\r\nEnvironment info:\r\n\r\nUbuntu 16.04.02 (64 bit)\r\ntensorflow 0.12.1 CPU only (64 bit). I have a NVIDIA GTX 1050ti waiting to be used if crucial for this task.\r\n\r\nI'm am a kind of a coding noob so forgive my inaccuracies and ignorance. I'm relatively new (6 months) to tensorflow and CNNs in general. I've been transfer-training inception V3 on classification of large (1080px X 1920px) images, divided to 10 labels (folders). \r\nThe reason I'm asking and not just diving deep into it is that I'll have to spend a lot of time to resize my images and create the perfect sprite image and metadata file, but won't have the confidence that the trained data corresponds to the sprite image. So I want to see if it's even possible to begin with - **to get full certainty of visualized thumbnail corresponding to actual full-res image used for training.**\r\n\r\nThank you for this great platform!! Tensorboard is a very powerful tool and I'm very excited to unlock the embedding visualizations' potential. @dandelionmane\r\n"}