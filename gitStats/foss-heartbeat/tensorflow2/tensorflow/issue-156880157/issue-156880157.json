{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2510", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2510/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2510/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2510/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2510", "id": 156880157, "node_id": "MDU6SXNzdWUxNTY4ODAxNTc=", "number": 2510, "title": "Tensorboard feature request - Text summary", "user": {"login": "cgorman", "id": 1765047, "node_id": "MDQ6VXNlcjE3NjUwNDc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1765047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgorman", "html_url": "https://github.com/cgorman", "followers_url": "https://api.github.com/users/cgorman/followers", "following_url": "https://api.github.com/users/cgorman/following{/other_user}", "gists_url": "https://api.github.com/users/cgorman/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgorman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgorman/subscriptions", "organizations_url": "https://api.github.com/users/cgorman/orgs", "repos_url": "https://api.github.com/users/cgorman/repos", "events_url": "https://api.github.com/users/cgorman/events{/privacy}", "received_events_url": "https://api.github.com/users/cgorman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284285184, "node_id": "MDU6TGFiZWwyODQyODUxODQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:tensorboard", "name": "comp:tensorboard", "color": "0052cc", "default": false}, {"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-05-26T00:38:21Z", "updated_at": "2017-06-16T19:38:15Z", "closed_at": "2017-06-16T19:38:15Z", "author_association": "NONE", "body_html": "<p>Would it be reasonable to add a basic text summary feature to Tensorboard? Personally I've run my network a few dozen times with really minor changes between them for testing and it would be really useful if there was a field where I could put some arbitrary text where I just wrote the key differences in my runs.</p>\n<p>For example, on the Events page (or somewhere else) there would be a dropdown, similar to the summaries on the Events and Histograms page, with text I added (either hardcoded or as a script argument) that says what I did differently this run. Maybe I would print out the argument values for each run as well, that would be pretty useful, but basically something where I can say \"What did I do with this run again? Why was it different than the one before? Oh yeah I changed the batch size\" or \"Oh yeah I used my other dataset instead.\"</p>\n<p>Obviously if it's arbitrary text you could maybe use it to write up a description of the network or whatever you want.</p>", "body_text": "Would it be reasonable to add a basic text summary feature to Tensorboard? Personally I've run my network a few dozen times with really minor changes between them for testing and it would be really useful if there was a field where I could put some arbitrary text where I just wrote the key differences in my runs.\nFor example, on the Events page (or somewhere else) there would be a dropdown, similar to the summaries on the Events and Histograms page, with text I added (either hardcoded or as a script argument) that says what I did differently this run. Maybe I would print out the argument values for each run as well, that would be pretty useful, but basically something where I can say \"What did I do with this run again? Why was it different than the one before? Oh yeah I changed the batch size\" or \"Oh yeah I used my other dataset instead.\"\nObviously if it's arbitrary text you could maybe use it to write up a description of the network or whatever you want.", "body": "Would it be reasonable to add a basic text summary feature to Tensorboard? Personally I've run my network a few dozen times with really minor changes between them for testing and it would be really useful if there was a field where I could put some arbitrary text where I just wrote the key differences in my runs.\n\nFor example, on the Events page (or somewhere else) there would be a dropdown, similar to the summaries on the Events and Histograms page, with text I added (either hardcoded or as a script argument) that says what I did differently this run. Maybe I would print out the argument values for each run as well, that would be pretty useful, but basically something where I can say \"What did I do with this run again? Why was it different than the one before? Oh yeah I changed the batch size\" or \"Oh yeah I used my other dataset instead.\"\n\nObviously if it's arbitrary text you could maybe use it to write up a description of the network or whatever you want. \n"}