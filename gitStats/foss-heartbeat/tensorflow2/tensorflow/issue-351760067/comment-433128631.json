{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/433128631", "html_url": "https://github.com/tensorflow/tensorflow/issues/21693#issuecomment-433128631", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21693", "id": 433128631, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzEyODYzMQ==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-25T16:59:45Z", "updated_at": "2018-10-25T16:59:45Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">Currently you'll have better performance on GPUs if you convert shapes to\nint32 tensors. We're finally close to getting rid of this problem, though.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Wed, Oct 24, 2018 at 9:56 PM Anthony Platanios ***@***.***&gt; wrote:\n Hey <a class=\"user-mention\" href=\"https://github.com/alextp\">@alextp</a> &lt;<a href=\"https://github.com/alextp\">https://github.com/alextp</a>&gt;! I recently made a big update to\n TF Scala (PR &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"365966753\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/eaplatanios/tensorflow_scala/issues/131\" href=\"https://github.com/eaplatanios/tensorflow_scala/pull/131\">eaplatanios/tensorflow_scala#131</a>&gt;)\n that makes all of the graph construction API statically-typed (finally\n :))). This raised the following question that relates to this issue:\n whenever a shape is used when a tensor is expected, I implicitly convert\n the shape to a tensor (similarly to what the Python API does). However, I\n was converting to Tensor[Long] previously, because I had assumed shapes\n are represented as int64 tensors. If I keep doing that though I run into\n issues like the one described above.\n\n So, what should be the convention for implicit conversion of shapes to\n tensors? Should they be converted to int32 tensors or int64 tensors?\n\n I believe it would be good to make a decision about this and stick with\n it, given the awkward handling of int32 tensors when it comes to GPUs.\n Also, what is currently happening in the Python API? Is it int32 or int64\n that is used for these implicit conversions?\n\n Thanks! :)\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"351760067\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/21693\" href=\"https://github.com/tensorflow/tensorflow/issues/21693#issuecomment-432914008\">#21693 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAATxdPaOuz458ahSgZ2h59P7Xms_Sukks5uoUR8gaJpZM4WCSla\">https://github.com/notifications/unsubscribe-auth/AAATxdPaOuz458ahSgZ2h59P7Xms_Sukks5uoUR8gaJpZM4WCSla</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \n - Alex</div>\n</div>", "body_text": "Currently you'll have better performance on GPUs if you convert shapes to\nint32 tensors. We're finally close to getting rid of this problem, though.\n\u2026\nOn Wed, Oct 24, 2018 at 9:56 PM Anthony Platanios ***@***.***> wrote:\n Hey @alextp <https://github.com/alextp>! I recently made a big update to\n TF Scala (PR <eaplatanios/tensorflow_scala#131>)\n that makes all of the graph construction API statically-typed (finally\n :))). This raised the following question that relates to this issue:\n whenever a shape is used when a tensor is expected, I implicitly convert\n the shape to a tensor (similarly to what the Python API does). However, I\n was converting to Tensor[Long] previously, because I had assumed shapes\n are represented as int64 tensors. If I keep doing that though I run into\n issues like the one described above.\n\n So, what should be the convention for implicit conversion of shapes to\n tensors? Should they be converted to int32 tensors or int64 tensors?\n\n I believe it would be good to make a decision about this and stick with\n it, given the awkward handling of int32 tensors when it comes to GPUs.\n Also, what is currently happening in the Python API? Is it int32 or int64\n that is used for these implicit conversions?\n\n Thanks! :)\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#21693 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AAATxdPaOuz458ahSgZ2h59P7Xms_Sukks5uoUR8gaJpZM4WCSla>\n .\n\n\n-- \n - Alex", "body": "Currently you'll have better performance on GPUs if you convert shapes to\nint32 tensors. We're finally close to getting rid of this problem, though.\n\nOn Wed, Oct 24, 2018 at 9:56 PM Anthony Platanios <notifications@github.com>\nwrote:\n\n> Hey @alextp <https://github.com/alextp>! I recently made a big update to\n> TF Scala (PR <https://github.com/eaplatanios/tensorflow_scala/pull/131>)\n> that makes all of the graph construction API statically-typed (finally\n> :))). This raised the following question that relates to this issue:\n> whenever a shape is used when a tensor is expected, I implicitly convert\n> the shape to a tensor (similarly to what the Python API does). However, I\n> was converting to Tensor[Long] previously, because I had assumed shapes\n> are represented as int64 tensors. If I keep doing that though I run into\n> issues like the one described above.\n>\n> So, what should be the convention for implicit conversion of shapes to\n> tensors? Should they be converted to int32 tensors or int64 tensors?\n>\n> I believe it would be good to make a decision about this and stick with\n> it, given the awkward handling of int32 tensors when it comes to GPUs.\n> Also, what is currently happening in the Python API? Is it int32 or int64\n> that is used for these implicit conversions?\n>\n> Thanks! :)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21693#issuecomment-432914008>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxdPaOuz458ahSgZ2h59P7Xms_Sukks5uoUR8gaJpZM4WCSla>\n> .\n>\n\n\n-- \n - Alex\n"}