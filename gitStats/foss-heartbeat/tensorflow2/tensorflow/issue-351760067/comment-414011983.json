{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/414011983", "html_url": "https://github.com/tensorflow/tensorflow/issues/21693#issuecomment-414011983", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21693", "id": 414011983, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNDAxMTk4Mw==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-17T23:29:46Z", "updated_at": "2018-08-17T23:29:46Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">You can allow int64 shapes for GPUs but int64 tensors aren't automatically\nplaced on host memory so you need to be careful or your model will silently\nrun shape computations on the GPU and then block the host to synchronize\nthe stream before executing the random op. I'd accept a PR allowing int64\nthere, though you should be very careful when using it.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Fri, Aug 17, 2018 at 4:03 PM Anthony Platanios ***@***.***&gt; wrote:\n But the op allows for int64 tensors to be passed in for the shape. I\u2019m not\n talking about the host memory annotations but rather just the type\n constraint on the shape. The CPU kernel registrations for RandomUniform\n allow int64 shapes so why not allow them for the GPU kernels too?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"351760067\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/21693\" href=\"https://github.com/tensorflow/tensorflow/issues/21693#issuecomment-414008189\">#21693 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAATxen6ekb_9UZp0xYIuMbI1wvns4ITks5uR0vMgaJpZM4WCSla\">https://github.com/notifications/unsubscribe-auth/AAATxen6ekb_9UZp0xYIuMbI1wvns4ITks5uR0vMgaJpZM4WCSla</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \n - Alex</div>\n</div>", "body_text": "You can allow int64 shapes for GPUs but int64 tensors aren't automatically\nplaced on host memory so you need to be careful or your model will silently\nrun shape computations on the GPU and then block the host to synchronize\nthe stream before executing the random op. I'd accept a PR allowing int64\nthere, though you should be very careful when using it.\n\u2026\nOn Fri, Aug 17, 2018 at 4:03 PM Anthony Platanios ***@***.***> wrote:\n But the op allows for int64 tensors to be passed in for the shape. I\u2019m not\n talking about the host memory annotations but rather just the type\n constraint on the shape. The CPU kernel registrations for RandomUniform\n allow int64 shapes so why not allow them for the GPU kernels too?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#21693 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AAATxen6ekb_9UZp0xYIuMbI1wvns4ITks5uR0vMgaJpZM4WCSla>\n .\n\n\n-- \n - Alex", "body": "You can allow int64 shapes for GPUs but int64 tensors aren't automatically\nplaced on host memory so you need to be careful or your model will silently\nrun shape computations on the GPU and then block the host to synchronize\nthe stream before executing the random op. I'd accept a PR allowing int64\nthere, though you should be very careful when using it.\n\nOn Fri, Aug 17, 2018 at 4:03 PM Anthony Platanios <notifications@github.com>\nwrote:\n\n> But the op allows for int64 tensors to be passed in for the shape. I\u2019m not\n> talking about the host memory annotations but rather just the type\n> constraint on the shape. The CPU kernel registrations for RandomUniform\n> allow int64 shapes so why not allow them for the GPU kernels too?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21693#issuecomment-414008189>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxen6ekb_9UZp0xYIuMbI1wvns4ITks5uR0vMgaJpZM4WCSla>\n> .\n>\n\n\n-- \n - Alex\n"}