{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/292089961", "html_url": "https://github.com/tensorflow/tensorflow/issues/6713#issuecomment-292089961", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6713", "id": 292089961, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjA4OTk2MQ==", "user": {"login": "randomrandom", "id": 1579822, "node_id": "MDQ6VXNlcjE1Nzk4MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1579822?v=4", "gravatar_id": "", "url": "https://api.github.com/users/randomrandom", "html_url": "https://github.com/randomrandom", "followers_url": "https://api.github.com/users/randomrandom/followers", "following_url": "https://api.github.com/users/randomrandom/following{/other_user}", "gists_url": "https://api.github.com/users/randomrandom/gists{/gist_id}", "starred_url": "https://api.github.com/users/randomrandom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/randomrandom/subscriptions", "organizations_url": "https://api.github.com/users/randomrandom/orgs", "repos_url": "https://api.github.com/users/randomrandom/repos", "events_url": "https://api.github.com/users/randomrandom/events{/privacy}", "received_events_url": "https://api.github.com/users/randomrandom/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-06T07:18:31Z", "updated_at": "2017-04-06T07:18:31Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> what about if we want to create queue with different buckets? I'm following the example here: <a href=\"url\">http://programtalk.com/vs2/python/13142/deep_recommend_system/java_predict_client/src/main/proto/tensorflow/contrib/training/python/training/bucket_ops_test.py/</a></p>\n<p>It all looks good, except that my data is a sparse array, e.g.<br>\nsources = [[1], [2, 0, 3], [3,2]]<br>\ntargets = [[2. 3 4], [1,2], [2,3,4,5]]</p>\n<p>First I tried using <code>convert_to_tensor</code> but I assume this would not work well with sparse arrays so I started exploring using the SparseTensor, however looks like transforming the data into a SparseTensor won't help much since it cannot be fead to the RandomShuffleQueue. Would the <code>tf.train.shuffle_batch</code> be a good substitute? What's the best approach to add <code>slice_input_producer</code> in that case? I noticed that it doesn't work with SparseTensor<br>\n`        # load train corpus<br>\nsources, targets, lengths, validation_sources, validation_targets, validation_lengths = self._load_corpus()</p>\n<pre><code>     print(\"Finished corpus loading\")\n\n     # to a constant tensor\n     source = tf.convert_to_tensor(sources)\n     target = tf.convert_to_tensor(targets)\n     length = tf.convert_to_tensor(lengths)\n\n     input_queue = tf.RandomShuffleQueue(batch_size*64, # capacity\n                                         batch_size*32, # min_after_dequeue\n                                         tf.int32, name=name)\n     input_queue = input_queue.enqueue((length, source, targets))\n\n     lengths_t, sources_t, targets_t = input_queue.dequeue()\n\n\n     source_batch, target_batch = self.shuffle_bucket_batch(\n          length_t, [sources_t, targets_t],\n          batch_size=batch_size,\n          bucket_boundaries=self.BUCKET_BOUNDARIES,\n          # this will bad the source_batch and target_batch independently\n          dynamic_pad=True,\n          capacity=batch_size*64,\n          num_threads=32,\n          allow_smaller_final_batch=False, name=name\n      )\n</code></pre>\n<p>`</p>", "body_text": "@ebrevdo what about if we want to create queue with different buckets? I'm following the example here: http://programtalk.com/vs2/python/13142/deep_recommend_system/java_predict_client/src/main/proto/tensorflow/contrib/training/python/training/bucket_ops_test.py/\nIt all looks good, except that my data is a sparse array, e.g.\nsources = [[1], [2, 0, 3], [3,2]]\ntargets = [[2. 3 4], [1,2], [2,3,4,5]]\nFirst I tried using convert_to_tensor but I assume this would not work well with sparse arrays so I started exploring using the SparseTensor, however looks like transforming the data into a SparseTensor won't help much since it cannot be fead to the RandomShuffleQueue. Would the tf.train.shuffle_batch be a good substitute? What's the best approach to add slice_input_producer in that case? I noticed that it doesn't work with SparseTensor\n`        # load train corpus\nsources, targets, lengths, validation_sources, validation_targets, validation_lengths = self._load_corpus()\n     print(\"Finished corpus loading\")\n\n     # to a constant tensor\n     source = tf.convert_to_tensor(sources)\n     target = tf.convert_to_tensor(targets)\n     length = tf.convert_to_tensor(lengths)\n\n     input_queue = tf.RandomShuffleQueue(batch_size*64, # capacity\n                                         batch_size*32, # min_after_dequeue\n                                         tf.int32, name=name)\n     input_queue = input_queue.enqueue((length, source, targets))\n\n     lengths_t, sources_t, targets_t = input_queue.dequeue()\n\n\n     source_batch, target_batch = self.shuffle_bucket_batch(\n          length_t, [sources_t, targets_t],\n          batch_size=batch_size,\n          bucket_boundaries=self.BUCKET_BOUNDARIES,\n          # this will bad the source_batch and target_batch independently\n          dynamic_pad=True,\n          capacity=batch_size*64,\n          num_threads=32,\n          allow_smaller_final_batch=False, name=name\n      )\n\n`", "body": "@ebrevdo what about if we want to create queue with different buckets? I'm following the example here: [http://programtalk.com/vs2/python/13142/deep_recommend_system/java_predict_client/src/main/proto/tensorflow/contrib/training/python/training/bucket_ops_test.py/](url)\r\n\r\nIt all looks good, except that my data is a sparse array, e.g.\r\nsources = [[1], [2, 0, 3], [3,2]]\r\ntargets = [[2. 3 4], [1,2], [2,3,4,5]]\r\n\r\nFirst I tried using `convert_to_tensor` but I assume this would not work well with sparse arrays so I started exploring using the SparseTensor, however looks like transforming the data into a SparseTensor won't help much since it cannot be fead to the RandomShuffleQueue. Would the `tf.train.shuffle_batch` be a good substitute? What's the best approach to add `slice_input_producer` in that case? I noticed that it doesn't work with SparseTensor\r\n`        # load train corpus\r\n         sources, targets, lengths, validation_sources, validation_targets, validation_lengths = self._load_corpus()\r\n \r\n         print(\"Finished corpus loading\")\r\n \r\n         # to a constant tensor\r\n         source = tf.convert_to_tensor(sources)\r\n         target = tf.convert_to_tensor(targets)\r\n         length = tf.convert_to_tensor(lengths)\r\n \r\n         input_queue = tf.RandomShuffleQueue(batch_size*64, # capacity\r\n                                             batch_size*32, # min_after_dequeue\r\n                                             tf.int32, name=name)\r\n         input_queue = input_queue.enqueue((length, source, targets))\r\n \r\n         lengths_t, sources_t, targets_t = input_queue.dequeue()\r\n \r\n \r\n         source_batch, target_batch = self.shuffle_bucket_batch(\r\n              length_t, [sources_t, targets_t],\r\n              batch_size=batch_size,\r\n              bucket_boundaries=self.BUCKET_BOUNDARIES,\r\n              # this will bad the source_batch and target_batch independently\r\n              dynamic_pad=True,\r\n              capacity=batch_size*64,\r\n              num_threads=32,\r\n              allow_smaller_final_batch=False, name=name\r\n          )\r\n`"}