{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/258967993", "html_url": "https://github.com/tensorflow/tensorflow/issues/5464#issuecomment-258967993", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5464", "id": 258967993, "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODk2Nzk5Mw==", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-07T21:27:22Z", "updated_at": "2016-11-07T21:27:22Z", "author_association": "NONE", "body_html": "<p>By using first convolutional layer as input (conv1/Conv2D) I get an interesting error:</p>\n<blockquote>\n<p>E tensorflow/examples/label_image/main.cc:306] Running model failed: Invalid argument: Must provide as many biases as the last dimension of the input tensor: [64] vs. [1,32,32,3]<br>\n[[Node: conv1/BiasAdd = BiasAdd[T=DT_FLOAT, data_format=\"NHWC\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_conv1/Conv2D_0, conv1/biases/read)]]</p>\n</blockquote>\n<p>It is a bit strange to me, I've checked label_image example and it uses convention for image ops [batch_size, img_width, img_height, channels] and Cifar10 example also uses the same. Now, if Cifar10 is training and running properly, why do we get this error here? It doesn't make sense to me.</p>\n<p>Here is code from label_image example that reads image as a tensor:</p>\n<pre><code>// Given an image file name, read in the data, try to decode it as an image,\n// resize it to the requested size, and then scale the values as desired.\nStatus ReadTensorFromImageFile(string file_name, const int input_height,\n                               const int input_width, const float input_mean,\n                               const float input_std,\n                               std::vector&lt;Tensor&gt;* out_tensors) {\n  auto root = tensorflow::Scope::NewRootScope();\n  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)\n\n  string input_name = \"file_reader\";\n  string output_name = \"normalized\";\n  auto file_reader = ReadFile(root.WithOpName(input_name), file_name);\n  // Now try to figure out what kind of file it is and decode it.\n  const int wanted_channels = 3;\n  Output image_reader;\n  if (tensorflow::StringPiece(file_name).ends_with(\".png\")) {\n    image_reader = DecodePng(root.WithOpName(\"png_reader\"), file_reader,\n                             DecodePng::Channels(wanted_channels));\n  } else if (tensorflow::StringPiece(file_name).ends_with(\".gif\")) {\n    image_reader = DecodeGif(root.WithOpName(\"gif_reader\"), file_reader);\n  } else {\n    // Assume if it's neither a PNG nor a GIF then it must be a JPEG.\n    image_reader = DecodeJpeg(root.WithOpName(\"jpeg_reader\"), file_reader,\n                              DecodeJpeg::Channels(wanted_channels));\n  }\n  // Now cast the image data to float so we can do normal math on it.\n  auto float_caster =\n      Cast(root.WithOpName(\"float_caster\"), image_reader, tensorflow::DT_FLOAT);\n  // The convention for image ops in TensorFlow is that all images are expected\n  // to be in batches, so that they're four-dimensional arrays with indices of\n  // [batch, height, width, channel]. Because we only have a single image, we\n  // have to add a batch dimension of 1 to the start with ExpandDims().\n  auto dims_expander = ExpandDims(root, float_caster, 0);\n  // Bilinearly resize the image to fit the required dimensions.\n  auto resized = ResizeBilinear(\n      root, dims_expander,\n      Const(root.WithOpName(\"size\"), {input_height, input_width}));\n  // Subtract the mean and divide by the scale.\n  Div(root.WithOpName(output_name), Sub(root, resized, {input_mean}),\n      {input_std});\n\n  // This runs the GraphDef network definition that we've just constructed, and\n  // returns the results in the output tensor.\n  tensorflow::GraphDef graph;\n  TF_RETURN_IF_ERROR(root.ToGraphDef(&amp;graph));\n\n  std::unique_ptr&lt;tensorflow::Session&gt; session(\n      tensorflow::NewSession(tensorflow::SessionOptions()));\n  TF_RETURN_IF_ERROR(session-&gt;Create(graph));\n  TF_RETURN_IF_ERROR(session-&gt;Run({}, {output_name}, {}, out_tensors));\n  return Status::OK();\n}\n</code></pre>", "body_text": "By using first convolutional layer as input (conv1/Conv2D) I get an interesting error:\n\nE tensorflow/examples/label_image/main.cc:306] Running model failed: Invalid argument: Must provide as many biases as the last dimension of the input tensor: [64] vs. [1,32,32,3]\n[[Node: conv1/BiasAdd = BiasAdd[T=DT_FLOAT, data_format=\"NHWC\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_conv1/Conv2D_0, conv1/biases/read)]]\n\nIt is a bit strange to me, I've checked label_image example and it uses convention for image ops [batch_size, img_width, img_height, channels] and Cifar10 example also uses the same. Now, if Cifar10 is training and running properly, why do we get this error here? It doesn't make sense to me.\nHere is code from label_image example that reads image as a tensor:\n// Given an image file name, read in the data, try to decode it as an image,\n// resize it to the requested size, and then scale the values as desired.\nStatus ReadTensorFromImageFile(string file_name, const int input_height,\n                               const int input_width, const float input_mean,\n                               const float input_std,\n                               std::vector<Tensor>* out_tensors) {\n  auto root = tensorflow::Scope::NewRootScope();\n  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)\n\n  string input_name = \"file_reader\";\n  string output_name = \"normalized\";\n  auto file_reader = ReadFile(root.WithOpName(input_name), file_name);\n  // Now try to figure out what kind of file it is and decode it.\n  const int wanted_channels = 3;\n  Output image_reader;\n  if (tensorflow::StringPiece(file_name).ends_with(\".png\")) {\n    image_reader = DecodePng(root.WithOpName(\"png_reader\"), file_reader,\n                             DecodePng::Channels(wanted_channels));\n  } else if (tensorflow::StringPiece(file_name).ends_with(\".gif\")) {\n    image_reader = DecodeGif(root.WithOpName(\"gif_reader\"), file_reader);\n  } else {\n    // Assume if it's neither a PNG nor a GIF then it must be a JPEG.\n    image_reader = DecodeJpeg(root.WithOpName(\"jpeg_reader\"), file_reader,\n                              DecodeJpeg::Channels(wanted_channels));\n  }\n  // Now cast the image data to float so we can do normal math on it.\n  auto float_caster =\n      Cast(root.WithOpName(\"float_caster\"), image_reader, tensorflow::DT_FLOAT);\n  // The convention for image ops in TensorFlow is that all images are expected\n  // to be in batches, so that they're four-dimensional arrays with indices of\n  // [batch, height, width, channel]. Because we only have a single image, we\n  // have to add a batch dimension of 1 to the start with ExpandDims().\n  auto dims_expander = ExpandDims(root, float_caster, 0);\n  // Bilinearly resize the image to fit the required dimensions.\n  auto resized = ResizeBilinear(\n      root, dims_expander,\n      Const(root.WithOpName(\"size\"), {input_height, input_width}));\n  // Subtract the mean and divide by the scale.\n  Div(root.WithOpName(output_name), Sub(root, resized, {input_mean}),\n      {input_std});\n\n  // This runs the GraphDef network definition that we've just constructed, and\n  // returns the results in the output tensor.\n  tensorflow::GraphDef graph;\n  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));\n\n  std::unique_ptr<tensorflow::Session> session(\n      tensorflow::NewSession(tensorflow::SessionOptions()));\n  TF_RETURN_IF_ERROR(session->Create(graph));\n  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));\n  return Status::OK();\n}", "body": "By using first convolutional layer as input (conv1/Conv2D) I get an interesting error:\n\n> E tensorflow/examples/label_image/main.cc:306] Running model failed: Invalid argument: Must provide as many biases as the last dimension of the input tensor: [64] vs. [1,32,32,3]\n>          [[Node: conv1/BiasAdd = BiasAdd[T=DT_FLOAT, data_format=\"NHWC\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_conv1/Conv2D_0, conv1/biases/read)]]\n\nIt is a bit strange to me, I've checked label_image example and it uses convention for image ops [batch_size, img_width, img_height, channels] and Cifar10 example also uses the same. Now, if Cifar10 is training and running properly, why do we get this error here? It doesn't make sense to me. \n\nHere is code from label_image example that reads image as a tensor:\n\n```\n// Given an image file name, read in the data, try to decode it as an image,\n// resize it to the requested size, and then scale the values as desired.\nStatus ReadTensorFromImageFile(string file_name, const int input_height,\n                               const int input_width, const float input_mean,\n                               const float input_std,\n                               std::vector<Tensor>* out_tensors) {\n  auto root = tensorflow::Scope::NewRootScope();\n  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)\n\n  string input_name = \"file_reader\";\n  string output_name = \"normalized\";\n  auto file_reader = ReadFile(root.WithOpName(input_name), file_name);\n  // Now try to figure out what kind of file it is and decode it.\n  const int wanted_channels = 3;\n  Output image_reader;\n  if (tensorflow::StringPiece(file_name).ends_with(\".png\")) {\n    image_reader = DecodePng(root.WithOpName(\"png_reader\"), file_reader,\n                             DecodePng::Channels(wanted_channels));\n  } else if (tensorflow::StringPiece(file_name).ends_with(\".gif\")) {\n    image_reader = DecodeGif(root.WithOpName(\"gif_reader\"), file_reader);\n  } else {\n    // Assume if it's neither a PNG nor a GIF then it must be a JPEG.\n    image_reader = DecodeJpeg(root.WithOpName(\"jpeg_reader\"), file_reader,\n                              DecodeJpeg::Channels(wanted_channels));\n  }\n  // Now cast the image data to float so we can do normal math on it.\n  auto float_caster =\n      Cast(root.WithOpName(\"float_caster\"), image_reader, tensorflow::DT_FLOAT);\n  // The convention for image ops in TensorFlow is that all images are expected\n  // to be in batches, so that they're four-dimensional arrays with indices of\n  // [batch, height, width, channel]. Because we only have a single image, we\n  // have to add a batch dimension of 1 to the start with ExpandDims().\n  auto dims_expander = ExpandDims(root, float_caster, 0);\n  // Bilinearly resize the image to fit the required dimensions.\n  auto resized = ResizeBilinear(\n      root, dims_expander,\n      Const(root.WithOpName(\"size\"), {input_height, input_width}));\n  // Subtract the mean and divide by the scale.\n  Div(root.WithOpName(output_name), Sub(root, resized, {input_mean}),\n      {input_std});\n\n  // This runs the GraphDef network definition that we've just constructed, and\n  // returns the results in the output tensor.\n  tensorflow::GraphDef graph;\n  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));\n\n  std::unique_ptr<tensorflow::Session> session(\n      tensorflow::NewSession(tensorflow::SessionOptions()));\n  TF_RETURN_IF_ERROR(session->Create(graph));\n  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));\n  return Status::OK();\n}\n```\n"}