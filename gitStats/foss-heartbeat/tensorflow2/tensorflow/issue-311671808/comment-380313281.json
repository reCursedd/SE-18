{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/380313281", "html_url": "https://github.com/tensorflow/tensorflow/issues/18266#issuecomment-380313281", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18266", "id": 380313281, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MDMxMzI4MQ==", "user": {"login": "xiejw", "id": 1184671, "node_id": "MDQ6VXNlcjExODQ2NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1184671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiejw", "html_url": "https://github.com/xiejw", "followers_url": "https://api.github.com/users/xiejw/followers", "following_url": "https://api.github.com/users/xiejw/following{/other_user}", "gists_url": "https://api.github.com/users/xiejw/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiejw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiejw/subscriptions", "organizations_url": "https://api.github.com/users/xiejw/orgs", "repos_url": "https://api.github.com/users/xiejw/repos", "events_url": "https://api.github.com/users/xiejw/events{/privacy}", "received_events_url": "https://api.github.com/users/xiejw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-11T03:14:07Z", "updated_at": "2018-04-11T03:14:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If I understand the problem correctly, user defines the dataset with cache(filename). For this input_fn, as the input_fn is invoked multiple times, train_and_evalaute will error out. Is this the issue?</p>\n<p>Unfortunately, train_and_evaluate does not specify the contract how many times train input_fn and eval input_fn will be invoked today. It will limit the implementation space we have.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> can user change the code into following way?</p>\n<pre><code>ds = tf.data.Dataset.range(100000)\nds = ds.map(\n    lambda x: tf.py_func(func=gen, inp=[x], Tout=[tf.float32, tf.float32]))\nds = ds.map(batch_reshape)\nds = ds.cache(\"/tmp/mycache_train\")\nds = ds.repeat(3)\n\ndef my_input_fn_train():\n    value = ds.make_one_shot_iterator().get_next()\n   return {\"input_rgb\": value[0]}, {\"softmax\": value[1]}\n</code></pre>", "body_text": "If I understand the problem correctly, user defines the dataset with cache(filename). For this input_fn, as the input_fn is invoked multiple times, train_and_evalaute will error out. Is this the issue?\nUnfortunately, train_and_evaluate does not specify the contract how many times train input_fn and eval input_fn will be invoked today. It will limit the implementation space we have.\n@mrry can user change the code into following way?\nds = tf.data.Dataset.range(100000)\nds = ds.map(\n    lambda x: tf.py_func(func=gen, inp=[x], Tout=[tf.float32, tf.float32]))\nds = ds.map(batch_reshape)\nds = ds.cache(\"/tmp/mycache_train\")\nds = ds.repeat(3)\n\ndef my_input_fn_train():\n    value = ds.make_one_shot_iterator().get_next()\n   return {\"input_rgb\": value[0]}, {\"softmax\": value[1]}", "body": "If I understand the problem correctly, user defines the dataset with cache(filename). For this input_fn, as the input_fn is invoked multiple times, train_and_evalaute will error out. Is this the issue? \r\n\r\nUnfortunately, train_and_evaluate does not specify the contract how many times train input_fn and eval input_fn will be invoked today. It will limit the implementation space we have. \r\n\r\n@mrry can user change the code into following way? \r\n\r\n    ds = tf.data.Dataset.range(100000)\r\n    ds = ds.map(\r\n        lambda x: tf.py_func(func=gen, inp=[x], Tout=[tf.float32, tf.float32]))\r\n    ds = ds.map(batch_reshape)\r\n    ds = ds.cache(\"/tmp/mycache_train\")\r\n    ds = ds.repeat(3)\r\n\r\n    def my_input_fn_train():\r\n        value = ds.make_one_shot_iterator().get_next()\r\n       return {\"input_rgb\": value[0]}, {\"softmax\": value[1]}"}