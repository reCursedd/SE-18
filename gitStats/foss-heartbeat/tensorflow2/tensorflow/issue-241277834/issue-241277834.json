{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11352", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11352/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11352/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11352/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11352", "id": 241277834, "node_id": "MDU6SXNzdWUyNDEyNzc4MzQ=", "number": 11352, "title": " Ran out of memory when running ROLO on tensorflow", "user": {"login": "MansourTrabelsi", "id": 27732169, "node_id": "MDQ6VXNlcjI3NzMyMTY5", "avatar_url": "https://avatars1.githubusercontent.com/u/27732169?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MansourTrabelsi", "html_url": "https://github.com/MansourTrabelsi", "followers_url": "https://api.github.com/users/MansourTrabelsi/followers", "following_url": "https://api.github.com/users/MansourTrabelsi/following{/other_user}", "gists_url": "https://api.github.com/users/MansourTrabelsi/gists{/gist_id}", "starred_url": "https://api.github.com/users/MansourTrabelsi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MansourTrabelsi/subscriptions", "organizations_url": "https://api.github.com/users/MansourTrabelsi/orgs", "repos_url": "https://api.github.com/users/MansourTrabelsi/repos", "events_url": "https://api.github.com/users/MansourTrabelsi/events{/privacy}", "received_events_url": "https://api.github.com/users/MansourTrabelsi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-07-07T14:17:07Z", "updated_at": "2017-10-07T01:01:38Z", "closed_at": "2017-10-07T01:01:23Z", "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>Environment : ubuntu 14.04, Nvidia 740M 2Gb, 8Gb RAM, Cuda 7.5, TF 0.8.0</p>\n<p>`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally<br>\nROLO init<br>\nUtils init<br>\nself.cfgPath=<br>\nDefault: running ROLO test.<br>\nBuilding ROLO graph...<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: GeForce GT 740M<br>\nmajor: 3 minor: 5 memoryClockRate (GHz) 1.0325<br>\npciBusID 0000:0a:00.0<br>\nTotal memory: 1.96GiB<br>\nFree memory: 1.81GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)<br>\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 1.00G (1073741824 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY<br>\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 921.60M (966367744 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY<br>\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 829.44M (869731072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY<br>\nLoading complete!</p>\n<p>('TESTING ROLO on video sequence: ', 'Human2')<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (256): \tTotal Chunks: 1, Chunks in use: 0 256B allocated for chunks. 24B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (512): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0 96.2KiB allocated for chunks. 96.1KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0 442.5KiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:652] Bin for 513.50MiB was 256.00MiB, Chunk State:<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0000 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0100 of size 65792<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0200 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0300 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0400 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0500 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0600 of size 98560<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8700 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8800 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8900 of size 65792<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8a00 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8b00 of size 98560<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610c00 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610d00 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610e00 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610f00 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501611100 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629300 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629400 of size 65792<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501639500 of size 98560<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611000 of size 256<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611200 of size 98560<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501651600 of size 453120<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501dc0000 of size 1073741824<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x541dc0000 of size 704482304<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:685]      Summary of in-use Chunks by size:<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 14 Chunks of size 256 totalling 3.5KiB<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 65792 totalling 192.8KiB<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 98560 totalling 288.8KiB<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 704482304 totalling 671.85MiB<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1073741824 totalling 1.00GiB<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:692] Sum Total of in-use chunks: 1.66GiB<br>\nI tensorflow/core/common_runtime/bfc_allocator.cc:694] Stats:<br>\nLimit:                  1739522048<br>\nInUse:                  1778720768<br>\nMaxInUse:               1778819584<br>\nNumAllocs:                      37<br>\nMaxAllocSize:           1073741824</p>\n<p>W tensorflow/core/common_runtime/bfc_allocator.cc:270] <em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>xxxxxxxxxxxxxxxxxxxxxxxxxxxxx</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em>xxxxxxxxx<br>\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 513.50MiB.  See logs for memory state.<br>\nW tensorflow/core/framework/op_kernel.cc:900] Resource exhausted: OOM when allocating tensor with shape[8204,16408]<br>\nTraceback (most recent call last):<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 276, in <br>\nmain(' ')<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 272, in main<br>\nROLO_TF(argvs)<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 93, in <strong>init</strong><br>\nself.ROLO(argvs)<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 267, in ROLO<br>\nself.testing(x_path, y_path)<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 157, in testing<br>\nsess.run(init)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run<br>\nfeed_dict_string, options, run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run<br>\ntarget_list, options, run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call<br>\ne.code)<br>\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[8204,16408]<br>\n[[Node: RNN/LSTMCell/W_0/Initializer/random_uniform/mul = Mul[T=DT_FLOAT, _class=[\"loc:@RNN/LSTMCell/W_0\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/LSTMCell/W_0/Initializer/random_uniform/RandomUniform, RNN/LSTMCell/W_0/Initializer/random_uniform/sub)]]<br>\nCaused by op u'RNN/LSTMCell/W_0/Initializer/random_uniform/mul', defined at:<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 276, in <br>\nmain(' ')<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 272, in main<br>\nROLO_TF(argvs)<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 93, in <strong>init</strong><br>\nself.ROLO(argvs)<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 236, in ROLO<br>\nself.build_networks()<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 125, in build_networks<br>\nself.lstm_module = self.LSTM_single('lstm_test', self.x, self.istate, self.weights, self.biases)<br>\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 108, in LSTM_single<br>\noutputs, state = tf.nn.rnn(cell, [<em>X[step]], state)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 143, in rnn<br>\n(output, state) = call_cell()<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 136, in <br>\ncall_cell = lambda: cell(input</em>, state)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 352, in <strong>call</strong><br>\ndtype, self._num_unit_shards)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 216, in _get_concat_variable<br>\nsharded_variable = _get_sharded_variable(name, shape, dtype, num_shards)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 246, in _get_sharded_variable<br>\ndtype=dtype))<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 339, in get_variable<br>\ncollections=collections)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 262, in get_variable<br>\ncollections=collections, caching_device=caching_device)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 158, in get_variable<br>\ndtype=variable_dtype)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in <strong>init</strong><br>\ndtype=dtype)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 275, in _init_from_args<br>\nself._initial_value = ops.convert_to_tensor(initial_value(),<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 149, in <br>\ninit_val = lambda: initializer(shape.as_list(), dtype=dtype)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py\", line 200, in _initializer<br>\ndtype, seed=seed)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/random_ops.py\", line 183, in random_uniform<br>\nreturn math_ops.add(rnd * (maxval - minval), minval, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 518, in binary_op_wrapper<br>\nreturn func(x, y, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1039, in mul<br>\nreturn _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in <strong>init</strong><br>\nself._traceback = _extract_stack()`</p>", "body_text": "Hello,\nEnvironment : ubuntu 14.04, Nvidia 740M 2Gb, 8Gb RAM, Cuda 7.5, TF 0.8.0\n`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nROLO init\nUtils init\nself.cfgPath=\nDefault: running ROLO test.\nBuilding ROLO graph...\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GT 740M\nmajor: 3 minor: 5 memoryClockRate (GHz) 1.0325\npciBusID 0000:0a:00.0\nTotal memory: 1.96GiB\nFree memory: 1.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 1.00G (1073741824 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 921.60M (966367744 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 829.44M (869731072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nLoading complete!\n('TESTING ROLO on video sequence: ', 'Human2')\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (256): \tTotal Chunks: 1, Chunks in use: 0 256B allocated for chunks. 24B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (512): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0 96.2KiB allocated for chunks. 96.1KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0 442.5KiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:652] Bin for 513.50MiB was 256.00MiB, Chunk State:\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0000 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0100 of size 65792\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0200 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0300 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0400 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0500 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0600 of size 98560\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8700 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8800 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8900 of size 65792\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8a00 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8b00 of size 98560\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610c00 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610d00 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610e00 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610f00 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501611100 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629300 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629400 of size 65792\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501639500 of size 98560\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611000 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611200 of size 98560\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501651600 of size 453120\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501dc0000 of size 1073741824\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x541dc0000 of size 704482304\nI tensorflow/core/common_runtime/bfc_allocator.cc:685]      Summary of in-use Chunks by size:\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 14 Chunks of size 256 totalling 3.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 65792 totalling 192.8KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 98560 totalling 288.8KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 704482304 totalling 671.85MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1073741824 totalling 1.00GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:692] Sum Total of in-use chunks: 1.66GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:694] Stats:\nLimit:                  1739522048\nInUse:                  1778720768\nMaxInUse:               1778819584\nNumAllocs:                      37\nMaxAllocSize:           1073741824\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 513.50MiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:900] Resource exhausted: OOM when allocating tensor with shape[8204,16408]\nTraceback (most recent call last):\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 276, in \nmain(' ')\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 272, in main\nROLO_TF(argvs)\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 93, in init\nself.ROLO(argvs)\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 267, in ROLO\nself.testing(x_path, y_path)\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 157, in testing\nsess.run(init)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\nrun_metadata_ptr)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run\nfeed_dict_string, options, run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run\ntarget_list, options, run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call\ne.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[8204,16408]\n[[Node: RNN/LSTMCell/W_0/Initializer/random_uniform/mul = Mul[T=DT_FLOAT, _class=[\"loc:@RNN/LSTMCell/W_0\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/LSTMCell/W_0/Initializer/random_uniform/RandomUniform, RNN/LSTMCell/W_0/Initializer/random_uniform/sub)]]\nCaused by op u'RNN/LSTMCell/W_0/Initializer/random_uniform/mul', defined at:\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 276, in \nmain(' ')\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 272, in main\nROLO_TF(argvs)\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 93, in init\nself.ROLO(argvs)\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 236, in ROLO\nself.build_networks()\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 125, in build_networks\nself.lstm_module = self.LSTM_single('lstm_test', self.x, self.istate, self.weights, self.biases)\nFile \"./experiments/testing/ROLO_network_test_all.py\", line 108, in LSTM_single\noutputs, state = tf.nn.rnn(cell, [X[step]], state)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 143, in rnn\n(output, state) = call_cell()\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 136, in \ncall_cell = lambda: cell(input, state)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 352, in call\ndtype, self._num_unit_shards)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 216, in _get_concat_variable\nsharded_variable = _get_sharded_variable(name, shape, dtype, num_shards)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 246, in _get_sharded_variable\ndtype=dtype))\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 339, in get_variable\ncollections=collections)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 262, in get_variable\ncollections=collections, caching_device=caching_device)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 158, in get_variable\ndtype=variable_dtype)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in init\ndtype=dtype)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 275, in _init_from_args\nself._initial_value = ops.convert_to_tensor(initial_value(),\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 149, in \ninit_val = lambda: initializer(shape.as_list(), dtype=dtype)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py\", line 200, in _initializer\ndtype, seed=seed)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/random_ops.py\", line 183, in random_uniform\nreturn math_ops.add(rnd * (maxval - minval), minval, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 518, in binary_op_wrapper\nreturn func(x, y, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1039, in mul\nreturn _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in init\nself._traceback = _extract_stack()`", "body": "Hello,\r\n\r\nEnvironment : ubuntu 14.04, Nvidia 740M 2Gb, 8Gb RAM, Cuda 7.5, TF 0.8.0\r\n\r\n`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\r\nROLO init\r\nUtils init\r\nself.cfgPath=\r\nDefault: running ROLO test.\r\nBuilding ROLO graph...\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \r\nname: GeForce GT 740M\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 1.0325\r\npciBusID 0000:0a:00.0\r\nTotal memory: 1.96GiB\r\nFree memory: 1.81GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 1.00G (1073741824 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 921.60M (966367744 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 829.44M (869731072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nLoading complete!\r\n\r\n('TESTING ROLO on video sequence: ', 'Human2')\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (256): \tTotal Chunks: 1, Chunks in use: 0 256B allocated for chunks. 24B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (512): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0 96.2KiB allocated for chunks. 96.1KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0 442.5KiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:652] Bin for 513.50MiB was 256.00MiB, Chunk State: \r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0000 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0100 of size 65792\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0200 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0300 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0400 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0500 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0600 of size 98560\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8700 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8800 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8900 of size 65792\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8a00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8b00 of size 98560\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610c00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610d00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610e00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610f00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501611100 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629300 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629400 of size 65792\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501639500 of size 98560\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611000 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611200 of size 98560\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501651600 of size 453120\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501dc0000 of size 1073741824\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x541dc0000 of size 704482304\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:685]      Summary of in-use Chunks by size: \r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 14 Chunks of size 256 totalling 3.5KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 65792 totalling 192.8KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 98560 totalling 288.8KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 704482304 totalling 671.85MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1073741824 totalling 1.00GiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:692] Sum Total of in-use chunks: 1.66GiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:694] Stats: \r\nLimit:                  1739522048\r\nInUse:                  1778720768\r\nMaxInUse:               1778819584\r\nNumAllocs:                      37\r\nMaxAllocSize:           1073741824\r\n\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] *******************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxx*******************************xxxxxxxxx\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 513.50MiB.  See logs for memory state.\r\nW tensorflow/core/framework/op_kernel.cc:900] Resource exhausted: OOM when allocating tensor with shape[8204,16408]\r\nTraceback (most recent call last):\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 276, in <module>\r\n    main(' ')\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 272, in main\r\n    ROLO_TF(argvs)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 93, in __init__\r\n    self.ROLO(argvs)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 267, in ROLO\r\n    self.testing(x_path, y_path)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 157, in testing\r\n    sess.run(init)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call\r\n    e.code)\r\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[8204,16408]\r\n\t [[Node: RNN/LSTMCell/W_0/Initializer/random_uniform/mul = Mul[T=DT_FLOAT, _class=[\"loc:@RNN/LSTMCell/W_0\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/LSTMCell/W_0/Initializer/random_uniform/RandomUniform, RNN/LSTMCell/W_0/Initializer/random_uniform/sub)]]\r\nCaused by op u'RNN/LSTMCell/W_0/Initializer/random_uniform/mul', defined at:\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 276, in <module>\r\n    main(' ')\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 272, in main\r\n    ROLO_TF(argvs)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 93, in __init__\r\n    self.ROLO(argvs)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 236, in ROLO\r\n    self.build_networks()\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 125, in build_networks\r\n    self.lstm_module = self.LSTM_single('lstm_test', self.x, self.istate, self.weights, self.biases)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 108, in LSTM_single\r\n    outputs, state = tf.nn.rnn(cell, [_X[step]], state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 143, in rnn\r\n    (output, state) = call_cell()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 136, in <lambda>\r\n    call_cell = lambda: cell(input_, state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 352, in __call__\r\n    dtype, self._num_unit_shards)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 216, in _get_concat_variable\r\n    sharded_variable = _get_sharded_variable(name, shape, dtype, num_shards)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 246, in _get_sharded_variable\r\n    dtype=dtype))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 339, in get_variable\r\n    collections=collections)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 262, in get_variable\r\n    collections=collections, caching_device=caching_device)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 158, in get_variable\r\n    dtype=variable_dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in __init__\r\n    dtype=dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 275, in _init_from_args\r\n    self._initial_value = ops.convert_to_tensor(initial_value(),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 149, in <lambda>\r\n    init_val = lambda: initializer(shape.as_list(), dtype=dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py\", line 200, in _initializer\r\n    dtype, seed=seed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/random_ops.py\", line 183, in random_uniform\r\n    return math_ops.add(rnd * (maxval - minval), minval, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 518, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1039, in mul\r\n    return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\r\n    self._traceback = _extract_stack()`"}