{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/424206056", "html_url": "https://github.com/tensorflow/tensorflow/issues/22396#issuecomment-424206056", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22396", "id": 424206056, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDIwNjA1Ng==", "user": {"login": "haotianteng", "id": 11155295, "node_id": "MDQ6VXNlcjExMTU1Mjk1", "avatar_url": "https://avatars3.githubusercontent.com/u/11155295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haotianteng", "html_url": "https://github.com/haotianteng", "followers_url": "https://api.github.com/users/haotianteng/followers", "following_url": "https://api.github.com/users/haotianteng/following{/other_user}", "gists_url": "https://api.github.com/users/haotianteng/gists{/gist_id}", "starred_url": "https://api.github.com/users/haotianteng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haotianteng/subscriptions", "organizations_url": "https://api.github.com/users/haotianteng/orgs", "repos_url": "https://api.github.com/users/haotianteng/repos", "events_url": "https://api.github.com/users/haotianteng/events{/privacy}", "received_events_url": "https://api.github.com/users/haotianteng/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-25T04:48:16Z", "updated_at": "2018-09-25T04:50:17Z", "author_association": "NONE", "body_html": "<p>And here is a reproducing example I try to build by deleting unrelevant code from my own project:<br>\nExport script:</p>\n<pre><code>import os\nimport tensorflow as tf\nfrom tensorflow.python.saved_model import signature_constants as sig_constants\nfrom chiron.chiron_model import inference,read_config\nfrom chiron.chiron_eval import path_prob\n\nmodel_path = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL\"\nOUTPUT = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL/export\"\ndef output_list(x,seq_length):\n    training = tf.constant(False,dtype = tf.bool,name = 'Training')\n    config_path = os.path.join(model_path,'model.json')\n    model_configure = read_config(config_path)\n    logits, ratio = inference(x, \n                              seq_length, \n                              training=training,\n                              full_sequence_len = 4,\n                              configure = model_configure)\n    ratio = tf.constant(ratio,dtype = tf.float32,shape = [])\n    seq_length_r = tf.cast(tf.round(tf.cast(seq_length,dtype = tf.float32)/ratio),tf.int32)\n    prob_logits = path_prob(logits)\n    predict,log_prob = tf.nn.ctc_beam_search_decoder(tf.transpose(logits, perm=[1, 0, 2]), \n                                            seq_length_r, \n                                            merge_repeated=True,\n                                            beam_width = 30)\n    return predict[0],logits,prob_logits,log_prob\n\ndef build_and_run_exports():\n    \"\"\"Given the latest checkpoint file export the saved model.\n    \"\"\"\n\n    prediction_graph = tf.Graph()\n    \n    with prediction_graph.as_default():\n        x = tf.placeholder(tf.float32, shape=[None, 4])\n        seq_len = tf.placeholder(tf.int32, shape = [None])\n        #Inference\n        predict,logits,prob_logits,log_prob = output_list(x,seq_len)\n        values, indices = tf.nn.top_k(logits,k=1)\n        saver = tf.train.Saver()\n\n        with tf.Session(graph=prediction_graph) as sess:\n            ckpt = tf.train.get_checkpoint_state(model_path)\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess,ckpt.model_checkpoint_path)\n            output_path = os.path.join(\n                    tf.compat.as_bytes(OUTPUT),\n                    tf.compat.as_bytes(str(1)))\n            exporter = tf.saved_model.builder.SavedModelBuilder(output_path)\n            x_tensor_info = tf.saved_model.utils.build_tensor_info(x)\n            seq_len_tensor_info = tf.saved_model.utils.build_tensor_info(seq_len)\n            sparse_output_tensor_info = tf.saved_model.utils.build_tensor_info(\n                    predict)\n            \n            prediction_signature = (tf.saved_model.signature_def_utils.build_signature_def(\n                inputs = {'x':x_tensor_info,\n                          'seq_len':seq_len_tensor_info},\n                outputs = {'output':sparse_output_tensor_info},\n                method_name=sig_constants.PREDICT_METHOD_NAME))\n            \n            exporter.add_meta_graph_and_variables(\n                sess,\n                tags=[tf.saved_model.tag_constants.SERVING],\n                signature_def_map={\n                        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature\n                },\n                main_op=tf.tables_initializer(),\n                strip_default_attrs=True)\n            exporter.save()\n\n\nif __name__ == '__main__':\n    build_and_run_exports()\n</code></pre>\n<p>Predict Script:</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib import predictor\nfrom tensorflow.contrib.saved_model.python.saved_model import reader\nfrom tensorflow.contrib.saved_model.python.saved_model import signature_def_utils\nfrom tensorflow.python.tools import saved_model_utils\nimport numpy as np\n\nexp_dir = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL/export/1\"\nmetagraph_def = saved_model_utils.get_meta_graph_def(exp_dir,'serve')\nsignature_def = signature_def_utils.get_signature_def_by_key(\n        metagraph_def,\n         tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY)\noutput_names = {k: v.name for k, v in signature_def.outputs.items()}\nprint(output_names)\npredict_fn = predictor.from_saved_model(exp_dir)\nbatch_x = np.asarray([[[1,1,1,1]]])\nseq_len = np.asarray([[4]])\npredictions = predict_fn({'x':batch_x,'seq_len':seq_len})\n</code></pre>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/2413795/TEST_MODEL.tar.gz\">TEST_MODEL.tar.gz</a></p>", "body_text": "And here is a reproducing example I try to build by deleting unrelevant code from my own project:\nExport script:\nimport os\nimport tensorflow as tf\nfrom tensorflow.python.saved_model import signature_constants as sig_constants\nfrom chiron.chiron_model import inference,read_config\nfrom chiron.chiron_eval import path_prob\n\nmodel_path = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL\"\nOUTPUT = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL/export\"\ndef output_list(x,seq_length):\n    training = tf.constant(False,dtype = tf.bool,name = 'Training')\n    config_path = os.path.join(model_path,'model.json')\n    model_configure = read_config(config_path)\n    logits, ratio = inference(x, \n                              seq_length, \n                              training=training,\n                              full_sequence_len = 4,\n                              configure = model_configure)\n    ratio = tf.constant(ratio,dtype = tf.float32,shape = [])\n    seq_length_r = tf.cast(tf.round(tf.cast(seq_length,dtype = tf.float32)/ratio),tf.int32)\n    prob_logits = path_prob(logits)\n    predict,log_prob = tf.nn.ctc_beam_search_decoder(tf.transpose(logits, perm=[1, 0, 2]), \n                                            seq_length_r, \n                                            merge_repeated=True,\n                                            beam_width = 30)\n    return predict[0],logits,prob_logits,log_prob\n\ndef build_and_run_exports():\n    \"\"\"Given the latest checkpoint file export the saved model.\n    \"\"\"\n\n    prediction_graph = tf.Graph()\n    \n    with prediction_graph.as_default():\n        x = tf.placeholder(tf.float32, shape=[None, 4])\n        seq_len = tf.placeholder(tf.int32, shape = [None])\n        #Inference\n        predict,logits,prob_logits,log_prob = output_list(x,seq_len)\n        values, indices = tf.nn.top_k(logits,k=1)\n        saver = tf.train.Saver()\n\n        with tf.Session(graph=prediction_graph) as sess:\n            ckpt = tf.train.get_checkpoint_state(model_path)\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess,ckpt.model_checkpoint_path)\n            output_path = os.path.join(\n                    tf.compat.as_bytes(OUTPUT),\n                    tf.compat.as_bytes(str(1)))\n            exporter = tf.saved_model.builder.SavedModelBuilder(output_path)\n            x_tensor_info = tf.saved_model.utils.build_tensor_info(x)\n            seq_len_tensor_info = tf.saved_model.utils.build_tensor_info(seq_len)\n            sparse_output_tensor_info = tf.saved_model.utils.build_tensor_info(\n                    predict)\n            \n            prediction_signature = (tf.saved_model.signature_def_utils.build_signature_def(\n                inputs = {'x':x_tensor_info,\n                          'seq_len':seq_len_tensor_info},\n                outputs = {'output':sparse_output_tensor_info},\n                method_name=sig_constants.PREDICT_METHOD_NAME))\n            \n            exporter.add_meta_graph_and_variables(\n                sess,\n                tags=[tf.saved_model.tag_constants.SERVING],\n                signature_def_map={\n                        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature\n                },\n                main_op=tf.tables_initializer(),\n                strip_default_attrs=True)\n            exporter.save()\n\n\nif __name__ == '__main__':\n    build_and_run_exports()\n\nPredict Script:\nimport tensorflow as tf\nfrom tensorflow.contrib import predictor\nfrom tensorflow.contrib.saved_model.python.saved_model import reader\nfrom tensorflow.contrib.saved_model.python.saved_model import signature_def_utils\nfrom tensorflow.python.tools import saved_model_utils\nimport numpy as np\n\nexp_dir = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL/export/1\"\nmetagraph_def = saved_model_utils.get_meta_graph_def(exp_dir,'serve')\nsignature_def = signature_def_utils.get_signature_def_by_key(\n        metagraph_def,\n         tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY)\noutput_names = {k: v.name for k, v in signature_def.outputs.items()}\nprint(output_names)\npredict_fn = predictor.from_saved_model(exp_dir)\nbatch_x = np.asarray([[[1,1,1,1]]])\nseq_len = np.asarray([[4]])\npredictions = predict_fn({'x':batch_x,'seq_len':seq_len})\n\nTEST_MODEL.tar.gz", "body": "And here is a reproducing example I try to build by deleting unrelevant code from my own project:\r\nExport script:\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.saved_model import signature_constants as sig_constants\r\nfrom chiron.chiron_model import inference,read_config\r\nfrom chiron.chiron_eval import path_prob\r\n\r\nmodel_path = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL\"\r\nOUTPUT = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL/export\"\r\ndef output_list(x,seq_length):\r\n    training = tf.constant(False,dtype = tf.bool,name = 'Training')\r\n    config_path = os.path.join(model_path,'model.json')\r\n    model_configure = read_config(config_path)\r\n    logits, ratio = inference(x, \r\n                              seq_length, \r\n                              training=training,\r\n                              full_sequence_len = 4,\r\n                              configure = model_configure)\r\n    ratio = tf.constant(ratio,dtype = tf.float32,shape = [])\r\n    seq_length_r = tf.cast(tf.round(tf.cast(seq_length,dtype = tf.float32)/ratio),tf.int32)\r\n    prob_logits = path_prob(logits)\r\n    predict,log_prob = tf.nn.ctc_beam_search_decoder(tf.transpose(logits, perm=[1, 0, 2]), \r\n                                            seq_length_r, \r\n                                            merge_repeated=True,\r\n                                            beam_width = 30)\r\n    return predict[0],logits,prob_logits,log_prob\r\n\r\ndef build_and_run_exports():\r\n    \"\"\"Given the latest checkpoint file export the saved model.\r\n    \"\"\"\r\n\r\n    prediction_graph = tf.Graph()\r\n    \r\n    with prediction_graph.as_default():\r\n        x = tf.placeholder(tf.float32, shape=[None, 4])\r\n        seq_len = tf.placeholder(tf.int32, shape = [None])\r\n        #Inference\r\n        predict,logits,prob_logits,log_prob = output_list(x,seq_len)\r\n        values, indices = tf.nn.top_k(logits,k=1)\r\n        saver = tf.train.Saver()\r\n\r\n        with tf.Session(graph=prediction_graph) as sess:\r\n            ckpt = tf.train.get_checkpoint_state(model_path)\r\n            if ckpt and ckpt.model_checkpoint_path:\r\n                saver.restore(sess,ckpt.model_checkpoint_path)\r\n            output_path = os.path.join(\r\n                    tf.compat.as_bytes(OUTPUT),\r\n                    tf.compat.as_bytes(str(1)))\r\n            exporter = tf.saved_model.builder.SavedModelBuilder(output_path)\r\n            x_tensor_info = tf.saved_model.utils.build_tensor_info(x)\r\n            seq_len_tensor_info = tf.saved_model.utils.build_tensor_info(seq_len)\r\n            sparse_output_tensor_info = tf.saved_model.utils.build_tensor_info(\r\n                    predict)\r\n            \r\n            prediction_signature = (tf.saved_model.signature_def_utils.build_signature_def(\r\n                inputs = {'x':x_tensor_info,\r\n                          'seq_len':seq_len_tensor_info},\r\n                outputs = {'output':sparse_output_tensor_info},\r\n                method_name=sig_constants.PREDICT_METHOD_NAME))\r\n            \r\n            exporter.add_meta_graph_and_variables(\r\n                sess,\r\n                tags=[tf.saved_model.tag_constants.SERVING],\r\n                signature_def_map={\r\n                        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature\r\n                },\r\n                main_op=tf.tables_initializer(),\r\n                strip_default_attrs=True)\r\n            exporter.save()\r\n\r\n\r\nif __name__ == '__main__':\r\n    build_and_run_exports()\r\n```\r\nPredict Script:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import predictor\r\nfrom tensorflow.contrib.saved_model.python.saved_model import reader\r\nfrom tensorflow.contrib.saved_model.python.saved_model import signature_def_utils\r\nfrom tensorflow.python.tools import saved_model_utils\r\nimport numpy as np\r\n\r\nexp_dir = \"/home/heavens/Documents/ErrorReport_tf_SparseTensor_Name/TEST_MODEL/export/1\"\r\nmetagraph_def = saved_model_utils.get_meta_graph_def(exp_dir,'serve')\r\nsignature_def = signature_def_utils.get_signature_def_by_key(\r\n        metagraph_def,\r\n         tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY)\r\noutput_names = {k: v.name for k, v in signature_def.outputs.items()}\r\nprint(output_names)\r\npredict_fn = predictor.from_saved_model(exp_dir)\r\nbatch_x = np.asarray([[[1,1,1,1]]])\r\nseq_len = np.asarray([[4]])\r\npredictions = predict_fn({'x':batch_x,'seq_len':seq_len})\r\n```\r\n[TEST_MODEL.tar.gz](https://github.com/tensorflow/tensorflow/files/2413795/TEST_MODEL.tar.gz)\r\n"}