{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/419983554", "html_url": "https://github.com/tensorflow/tensorflow/issues/22133#issuecomment-419983554", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22133", "id": 419983554, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTk4MzU1NA==", "user": {"login": "baobao7766", "id": 10491686, "node_id": "MDQ6VXNlcjEwNDkxNjg2", "avatar_url": "https://avatars3.githubusercontent.com/u/10491686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/baobao7766", "html_url": "https://github.com/baobao7766", "followers_url": "https://api.github.com/users/baobao7766/followers", "following_url": "https://api.github.com/users/baobao7766/following{/other_user}", "gists_url": "https://api.github.com/users/baobao7766/gists{/gist_id}", "starred_url": "https://api.github.com/users/baobao7766/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/baobao7766/subscriptions", "organizations_url": "https://api.github.com/users/baobao7766/orgs", "repos_url": "https://api.github.com/users/baobao7766/repos", "events_url": "https://api.github.com/users/baobao7766/events{/privacy}", "received_events_url": "https://api.github.com/users/baobao7766/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-10T16:54:11Z", "updated_at": "2018-09-10T16:55:35Z", "author_association": "NONE", "body_html": "<p>Thank you for your reply, so if i re-train the model with higher version, this will be solved ? <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4805513\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/guillaumekln\">@guillaumekln</a><br>\nThe code is what i do and my solution in project. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> (I'm sorry for my terrible code ^_^)</p>\n<pre><code>\tbeam_decoder = BeamSearchDecoder(\n\t    cell=dec_cell,\n\t    embedding=emb_dec,\n\t    start_tokens=tf.ones_like(qes_seq_len) * go_id, \n\t    end_token=eos_id,\n\t    initial_state=init_state,\n\t    beam_width=beam_width,\n\t    output_layer=output_layer,\n\t    diversity_promoting=diversity_promoting,\n\t    length_penalty_weight=0.6)\n\tbeam_output_idx, beam_output_state, beam_lengths = tf.contrib.seq2seq.dynamic_decode(\n\t    decoder=beam_decoder,\n\t    maximum_iterations=max_decode_len)\n\n\twith tf.variable_scope(\"beamSearch\"):\n\t    beam_out = index2symbol.lookup(\n\t        tf.cast(beam_output_idx.predicted_ids, tf.int64),\n\t        name='beam_out')\n\t    beam_scores = beam_output_idx.beam_search_decoder_output[0]\n\t    beam_log_probs = beam_output_state[1]\n\n\t    beam_out_trans = tf.transpose(beam_out, perm=[0, 2, 1])\n\t    beam_scores_trans = tf.transpose(beam_scores, perm=[0, 2, 1])\n\t......\n\tout_infers  = tf.saved_model.utils.build_tensor_info(\n\t                tensor=graph.get_tensor_by_name(\"beamCandidate/chosenAnswers/Merge:0\"))\n\tout_score = tf.saved_model.utils.build_tensor_info(\n\t                tensor=graph.get_tensor_by_name(\"beamCandidate/chosenAnswers/Merge_1:0\"))\n\tprediction_signature = tf.saved_model.signature_def_utils.build_signature_def(\n\t    inputs={\n\t        'question': question_placeholder,\n\t        'answer': answer_placeholder,\n\t        'question_len': qes_len_placeholder,\n\t        'answer_len': ans_len_placeholder,\n\t        'answer_threshold': answer_threshold,\n\t    },\n\t    outputs={\n\t        'output': out_infers,\n\t        'score': out_score,\n\t    },\n\t    method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n</code></pre>\n<p>This is my solution, and it's not super slow at all, but it will be nice if <code>_beam_search_ops</code> worked in higher version, i will take this step later.</p>\n<pre><code>\tdef gather_tree_tf(step_ids, parent_ids, sequence_lengths):\n\t    with tf.variable_scope(name_or_scope=\"GatherTree\", reuse=None):\n\t        idx_shape = tf.shape(step_ids)      # 4, 2, 3\n\t        idx_dtype = step_ids.dtype\n\n\t        max_time    = idx_shape[0]  # 4\n\t        batch_size  = idx_shape[1]  # 2\n\t        beam_width  = idx_shape[2]  # 3\n\n\t        init_res = tf.zeros(idx_shape, dtype=idx_dtype)\n\t        init_cnt = tf.constant(0)\n\n\t        a = tf.reshape(tf.tile(tf.expand_dims(tf.range(beam_width), axis=1), [1, batch_size]), [-1, ])\n\t        b = tf.tile(tf.range(batch_size), [beam_width])\n\t        idx_arr = tf.concat(\n\t            [\n\t                tf.expand_dims(a, axis=1),  # beam_width\n\t                tf.expand_dims(b, axis=1),  # batch_size\n\t            ], axis=-1)\n\t        max_cnt = tf.shape(idx_arr)[0]  # 8\n\n\t        def condition(cnt, res_arr):\n\t            return tf.less(cnt, max_cnt)\n\n\t        def body(cnt, res_arr):\n\t            beam_id = idx_arr[cnt][0]   # 0\n\t            batch   = idx_arr[cnt][1]   # 0\n\n\t            max_len = sequence_lengths[batch][beam_id]  # 4\n\t            parent = parent_ids[max_len - 1][batch][beam_id]    # 2\n\t            temp_idx = tf.concat([tf.expand_dims(batch, axis=0), tf.expand_dims(beam_id, axis=0)], axis=-1)\n\t            temp_a = tf.expand_dims(tf.range(start=max_len-1, limit=max_time), axis=1)\n\t            temp_b = tf.tile(tf.expand_dims(temp_idx, axis=0), [max_time-max_len+1, 1])\n\t            mask_idx = tf.concat([temp_a, temp_b], axis=1)\n\t            mask = indice2mask3D(idxs=mask_idx, shape=idx_shape)\n\t            new_res_arr = tf.where(mask, step_ids, res_arr)\n\n\t            def condition2(cnt2, parent2, res_arr2):\n\t                return tf.greater(cnt2, 0)\n\n\t            def body2(cnt2, parent2, res_arr2):\n\t                level = cnt2 - 1\n\t                new_res_arr2 = tf.reshape(\n\t                    tf.tile(tf.expand_dims(step_ids[level][batch][parent2], axis=0), [tf.reduce_prod(idx_shape)]),\n\t                    idx_shape)\n\t                temp_idx2 = tf.expand_dims(tf.concat(\n\t                    [\n\t                        tf.expand_dims(level, axis=0),  # time = 2\n\t                        tf.expand_dims(batch, axis=0),  # batch = 0\n\t                        tf.expand_dims(beam_id, axis=0),  # parent_beam = 2, beam_id = 0\n\t                    ], axis=0), axis=0)\n\t                mask2 = indice2mask3D(idxs=temp_idx2, shape=idx_shape)\n\t                new_res_arr2 = tf.where(mask2, new_res_arr2, res_arr2)\n\t                new_parent = parent_ids[level][batch][parent2]\n\t                return tf.subtract(cnt2, 1), new_parent, new_res_arr2\n\n\t            out_cnt2, out_new_parent2, out_res_arr2 = tf.while_loop(\n\t                cond=condition2,\n\t                body=body2,\n\t                loop_vars=[max_len-1, parent, new_res_arr],\n\t                name=\"SubLoop2\")\n\t            new_cnt = tf.add(cnt, 1, name=\"newCount\")\n\t            return new_cnt, out_res_arr2\n\n\t        final_cnt, final_res_arr = tf.while_loop(\n\t            cond=condition,\n\t            body=body,\n\t            loop_vars=[init_cnt, init_res],\n\t            name=\"MainLoop\")\n\t        return final_res_arr\n\n\tdef indice2mask3D(idxs, shape):\n\t    with tf.variable_scope(\"Mask3D\"):\n\t        t = tf.range(tf.reduce_prod(shape))\n\t        max_cnt = tf.shape(idxs)[0]\n\t        init_mask = tf.zeros(shape=shape, dtype=tf.bool)\n\t        def cond(cnt, mask):\n\t            return tf.less(cnt, max_cnt)\n\t        def body(cnt, mask):\n\t            idx = idxs[cnt]\n\t            pos = idx[0] * shape[1] * shape[2] + idx[1] * shape[2] + idx[2]\n\t            cur_mask = tf.reshape(tf.equal(t, pos), shape)\n\t            return tf.add(cnt, 1), tf.logical_or(mask, cur_mask)\n\t        final_cnt, final_mask = tf.while_loop(\n\t            cond=cond, body=body, loop_vars=[0, init_mask],\n\t            name=\"ResultLoop\")\n\t        return final_mask\n</code></pre>", "body_text": "Thank you for your reply, so if i re-train the model with higher version, this will be solved ? @guillaumekln\nThe code is what i do and my solution in project. @ebrevdo (I'm sorry for my terrible code ^_^)\n\tbeam_decoder = BeamSearchDecoder(\n\t    cell=dec_cell,\n\t    embedding=emb_dec,\n\t    start_tokens=tf.ones_like(qes_seq_len) * go_id, \n\t    end_token=eos_id,\n\t    initial_state=init_state,\n\t    beam_width=beam_width,\n\t    output_layer=output_layer,\n\t    diversity_promoting=diversity_promoting,\n\t    length_penalty_weight=0.6)\n\tbeam_output_idx, beam_output_state, beam_lengths = tf.contrib.seq2seq.dynamic_decode(\n\t    decoder=beam_decoder,\n\t    maximum_iterations=max_decode_len)\n\n\twith tf.variable_scope(\"beamSearch\"):\n\t    beam_out = index2symbol.lookup(\n\t        tf.cast(beam_output_idx.predicted_ids, tf.int64),\n\t        name='beam_out')\n\t    beam_scores = beam_output_idx.beam_search_decoder_output[0]\n\t    beam_log_probs = beam_output_state[1]\n\n\t    beam_out_trans = tf.transpose(beam_out, perm=[0, 2, 1])\n\t    beam_scores_trans = tf.transpose(beam_scores, perm=[0, 2, 1])\n\t......\n\tout_infers  = tf.saved_model.utils.build_tensor_info(\n\t                tensor=graph.get_tensor_by_name(\"beamCandidate/chosenAnswers/Merge:0\"))\n\tout_score = tf.saved_model.utils.build_tensor_info(\n\t                tensor=graph.get_tensor_by_name(\"beamCandidate/chosenAnswers/Merge_1:0\"))\n\tprediction_signature = tf.saved_model.signature_def_utils.build_signature_def(\n\t    inputs={\n\t        'question': question_placeholder,\n\t        'answer': answer_placeholder,\n\t        'question_len': qes_len_placeholder,\n\t        'answer_len': ans_len_placeholder,\n\t        'answer_threshold': answer_threshold,\n\t    },\n\t    outputs={\n\t        'output': out_infers,\n\t        'score': out_score,\n\t    },\n\t    method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n\nThis is my solution, and it's not super slow at all, but it will be nice if _beam_search_ops worked in higher version, i will take this step later.\n\tdef gather_tree_tf(step_ids, parent_ids, sequence_lengths):\n\t    with tf.variable_scope(name_or_scope=\"GatherTree\", reuse=None):\n\t        idx_shape = tf.shape(step_ids)      # 4, 2, 3\n\t        idx_dtype = step_ids.dtype\n\n\t        max_time    = idx_shape[0]  # 4\n\t        batch_size  = idx_shape[1]  # 2\n\t        beam_width  = idx_shape[2]  # 3\n\n\t        init_res = tf.zeros(idx_shape, dtype=idx_dtype)\n\t        init_cnt = tf.constant(0)\n\n\t        a = tf.reshape(tf.tile(tf.expand_dims(tf.range(beam_width), axis=1), [1, batch_size]), [-1, ])\n\t        b = tf.tile(tf.range(batch_size), [beam_width])\n\t        idx_arr = tf.concat(\n\t            [\n\t                tf.expand_dims(a, axis=1),  # beam_width\n\t                tf.expand_dims(b, axis=1),  # batch_size\n\t            ], axis=-1)\n\t        max_cnt = tf.shape(idx_arr)[0]  # 8\n\n\t        def condition(cnt, res_arr):\n\t            return tf.less(cnt, max_cnt)\n\n\t        def body(cnt, res_arr):\n\t            beam_id = idx_arr[cnt][0]   # 0\n\t            batch   = idx_arr[cnt][1]   # 0\n\n\t            max_len = sequence_lengths[batch][beam_id]  # 4\n\t            parent = parent_ids[max_len - 1][batch][beam_id]    # 2\n\t            temp_idx = tf.concat([tf.expand_dims(batch, axis=0), tf.expand_dims(beam_id, axis=0)], axis=-1)\n\t            temp_a = tf.expand_dims(tf.range(start=max_len-1, limit=max_time), axis=1)\n\t            temp_b = tf.tile(tf.expand_dims(temp_idx, axis=0), [max_time-max_len+1, 1])\n\t            mask_idx = tf.concat([temp_a, temp_b], axis=1)\n\t            mask = indice2mask3D(idxs=mask_idx, shape=idx_shape)\n\t            new_res_arr = tf.where(mask, step_ids, res_arr)\n\n\t            def condition2(cnt2, parent2, res_arr2):\n\t                return tf.greater(cnt2, 0)\n\n\t            def body2(cnt2, parent2, res_arr2):\n\t                level = cnt2 - 1\n\t                new_res_arr2 = tf.reshape(\n\t                    tf.tile(tf.expand_dims(step_ids[level][batch][parent2], axis=0), [tf.reduce_prod(idx_shape)]),\n\t                    idx_shape)\n\t                temp_idx2 = tf.expand_dims(tf.concat(\n\t                    [\n\t                        tf.expand_dims(level, axis=0),  # time = 2\n\t                        tf.expand_dims(batch, axis=0),  # batch = 0\n\t                        tf.expand_dims(beam_id, axis=0),  # parent_beam = 2, beam_id = 0\n\t                    ], axis=0), axis=0)\n\t                mask2 = indice2mask3D(idxs=temp_idx2, shape=idx_shape)\n\t                new_res_arr2 = tf.where(mask2, new_res_arr2, res_arr2)\n\t                new_parent = parent_ids[level][batch][parent2]\n\t                return tf.subtract(cnt2, 1), new_parent, new_res_arr2\n\n\t            out_cnt2, out_new_parent2, out_res_arr2 = tf.while_loop(\n\t                cond=condition2,\n\t                body=body2,\n\t                loop_vars=[max_len-1, parent, new_res_arr],\n\t                name=\"SubLoop2\")\n\t            new_cnt = tf.add(cnt, 1, name=\"newCount\")\n\t            return new_cnt, out_res_arr2\n\n\t        final_cnt, final_res_arr = tf.while_loop(\n\t            cond=condition,\n\t            body=body,\n\t            loop_vars=[init_cnt, init_res],\n\t            name=\"MainLoop\")\n\t        return final_res_arr\n\n\tdef indice2mask3D(idxs, shape):\n\t    with tf.variable_scope(\"Mask3D\"):\n\t        t = tf.range(tf.reduce_prod(shape))\n\t        max_cnt = tf.shape(idxs)[0]\n\t        init_mask = tf.zeros(shape=shape, dtype=tf.bool)\n\t        def cond(cnt, mask):\n\t            return tf.less(cnt, max_cnt)\n\t        def body(cnt, mask):\n\t            idx = idxs[cnt]\n\t            pos = idx[0] * shape[1] * shape[2] + idx[1] * shape[2] + idx[2]\n\t            cur_mask = tf.reshape(tf.equal(t, pos), shape)\n\t            return tf.add(cnt, 1), tf.logical_or(mask, cur_mask)\n\t        final_cnt, final_mask = tf.while_loop(\n\t            cond=cond, body=body, loop_vars=[0, init_mask],\n\t            name=\"ResultLoop\")\n\t        return final_mask", "body": "Thank you for your reply, so if i re-train the model with higher version, this will be solved ? @guillaumekln \r\nThe code is what i do and my solution in project. @ebrevdo (I'm sorry for my terrible code ^_^)\r\n```\r\n\tbeam_decoder = BeamSearchDecoder(\r\n\t    cell=dec_cell,\r\n\t    embedding=emb_dec,\r\n\t    start_tokens=tf.ones_like(qes_seq_len) * go_id, \r\n\t    end_token=eos_id,\r\n\t    initial_state=init_state,\r\n\t    beam_width=beam_width,\r\n\t    output_layer=output_layer,\r\n\t    diversity_promoting=diversity_promoting,\r\n\t    length_penalty_weight=0.6)\r\n\tbeam_output_idx, beam_output_state, beam_lengths = tf.contrib.seq2seq.dynamic_decode(\r\n\t    decoder=beam_decoder,\r\n\t    maximum_iterations=max_decode_len)\r\n\r\n\twith tf.variable_scope(\"beamSearch\"):\r\n\t    beam_out = index2symbol.lookup(\r\n\t        tf.cast(beam_output_idx.predicted_ids, tf.int64),\r\n\t        name='beam_out')\r\n\t    beam_scores = beam_output_idx.beam_search_decoder_output[0]\r\n\t    beam_log_probs = beam_output_state[1]\r\n\r\n\t    beam_out_trans = tf.transpose(beam_out, perm=[0, 2, 1])\r\n\t    beam_scores_trans = tf.transpose(beam_scores, perm=[0, 2, 1])\r\n\t......\r\n\tout_infers  = tf.saved_model.utils.build_tensor_info(\r\n\t                tensor=graph.get_tensor_by_name(\"beamCandidate/chosenAnswers/Merge:0\"))\r\n\tout_score = tf.saved_model.utils.build_tensor_info(\r\n\t                tensor=graph.get_tensor_by_name(\"beamCandidate/chosenAnswers/Merge_1:0\"))\r\n\tprediction_signature = tf.saved_model.signature_def_utils.build_signature_def(\r\n\t    inputs={\r\n\t        'question': question_placeholder,\r\n\t        'answer': answer_placeholder,\r\n\t        'question_len': qes_len_placeholder,\r\n\t        'answer_len': ans_len_placeholder,\r\n\t        'answer_threshold': answer_threshold,\r\n\t    },\r\n\t    outputs={\r\n\t        'output': out_infers,\r\n\t        'score': out_score,\r\n\t    },\r\n\t    method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\r\n```\r\nThis is my solution, and it's not super slow at all, but it will be nice if `_beam_search_ops` worked in higher version, i will take this step later.\r\n```\r\n\tdef gather_tree_tf(step_ids, parent_ids, sequence_lengths):\r\n\t    with tf.variable_scope(name_or_scope=\"GatherTree\", reuse=None):\r\n\t        idx_shape = tf.shape(step_ids)      # 4, 2, 3\r\n\t        idx_dtype = step_ids.dtype\r\n\r\n\t        max_time    = idx_shape[0]  # 4\r\n\t        batch_size  = idx_shape[1]  # 2\r\n\t        beam_width  = idx_shape[2]  # 3\r\n\r\n\t        init_res = tf.zeros(idx_shape, dtype=idx_dtype)\r\n\t        init_cnt = tf.constant(0)\r\n\r\n\t        a = tf.reshape(tf.tile(tf.expand_dims(tf.range(beam_width), axis=1), [1, batch_size]), [-1, ])\r\n\t        b = tf.tile(tf.range(batch_size), [beam_width])\r\n\t        idx_arr = tf.concat(\r\n\t            [\r\n\t                tf.expand_dims(a, axis=1),  # beam_width\r\n\t                tf.expand_dims(b, axis=1),  # batch_size\r\n\t            ], axis=-1)\r\n\t        max_cnt = tf.shape(idx_arr)[0]  # 8\r\n\r\n\t        def condition(cnt, res_arr):\r\n\t            return tf.less(cnt, max_cnt)\r\n\r\n\t        def body(cnt, res_arr):\r\n\t            beam_id = idx_arr[cnt][0]   # 0\r\n\t            batch   = idx_arr[cnt][1]   # 0\r\n\r\n\t            max_len = sequence_lengths[batch][beam_id]  # 4\r\n\t            parent = parent_ids[max_len - 1][batch][beam_id]    # 2\r\n\t            temp_idx = tf.concat([tf.expand_dims(batch, axis=0), tf.expand_dims(beam_id, axis=0)], axis=-1)\r\n\t            temp_a = tf.expand_dims(tf.range(start=max_len-1, limit=max_time), axis=1)\r\n\t            temp_b = tf.tile(tf.expand_dims(temp_idx, axis=0), [max_time-max_len+1, 1])\r\n\t            mask_idx = tf.concat([temp_a, temp_b], axis=1)\r\n\t            mask = indice2mask3D(idxs=mask_idx, shape=idx_shape)\r\n\t            new_res_arr = tf.where(mask, step_ids, res_arr)\r\n\r\n\t            def condition2(cnt2, parent2, res_arr2):\r\n\t                return tf.greater(cnt2, 0)\r\n\r\n\t            def body2(cnt2, parent2, res_arr2):\r\n\t                level = cnt2 - 1\r\n\t                new_res_arr2 = tf.reshape(\r\n\t                    tf.tile(tf.expand_dims(step_ids[level][batch][parent2], axis=0), [tf.reduce_prod(idx_shape)]),\r\n\t                    idx_shape)\r\n\t                temp_idx2 = tf.expand_dims(tf.concat(\r\n\t                    [\r\n\t                        tf.expand_dims(level, axis=0),  # time = 2\r\n\t                        tf.expand_dims(batch, axis=0),  # batch = 0\r\n\t                        tf.expand_dims(beam_id, axis=0),  # parent_beam = 2, beam_id = 0\r\n\t                    ], axis=0), axis=0)\r\n\t                mask2 = indice2mask3D(idxs=temp_idx2, shape=idx_shape)\r\n\t                new_res_arr2 = tf.where(mask2, new_res_arr2, res_arr2)\r\n\t                new_parent = parent_ids[level][batch][parent2]\r\n\t                return tf.subtract(cnt2, 1), new_parent, new_res_arr2\r\n\r\n\t            out_cnt2, out_new_parent2, out_res_arr2 = tf.while_loop(\r\n\t                cond=condition2,\r\n\t                body=body2,\r\n\t                loop_vars=[max_len-1, parent, new_res_arr],\r\n\t                name=\"SubLoop2\")\r\n\t            new_cnt = tf.add(cnt, 1, name=\"newCount\")\r\n\t            return new_cnt, out_res_arr2\r\n\r\n\t        final_cnt, final_res_arr = tf.while_loop(\r\n\t            cond=condition,\r\n\t            body=body,\r\n\t            loop_vars=[init_cnt, init_res],\r\n\t            name=\"MainLoop\")\r\n\t        return final_res_arr\r\n\r\n\tdef indice2mask3D(idxs, shape):\r\n\t    with tf.variable_scope(\"Mask3D\"):\r\n\t        t = tf.range(tf.reduce_prod(shape))\r\n\t        max_cnt = tf.shape(idxs)[0]\r\n\t        init_mask = tf.zeros(shape=shape, dtype=tf.bool)\r\n\t        def cond(cnt, mask):\r\n\t            return tf.less(cnt, max_cnt)\r\n\t        def body(cnt, mask):\r\n\t            idx = idxs[cnt]\r\n\t            pos = idx[0] * shape[1] * shape[2] + idx[1] * shape[2] + idx[2]\r\n\t            cur_mask = tf.reshape(tf.equal(t, pos), shape)\r\n\t            return tf.add(cnt, 1), tf.logical_or(mask, cur_mask)\r\n\t        final_cnt, final_mask = tf.while_loop(\r\n\t            cond=cond, body=body, loop_vars=[0, init_mask],\r\n\t            name=\"ResultLoop\")\r\n\t        return final_mask\r\n```"}