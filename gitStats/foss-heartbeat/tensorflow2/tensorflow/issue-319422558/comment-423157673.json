{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/423157673", "html_url": "https://github.com/tensorflow/tensorflow/issues/19016#issuecomment-423157673", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19016", "id": 423157673, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMzE1NzY3Mw==", "user": {"login": "edumotya", "id": 13154422, "node_id": "MDQ6VXNlcjEzMTU0NDIy", "avatar_url": "https://avatars1.githubusercontent.com/u/13154422?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edumotya", "html_url": "https://github.com/edumotya", "followers_url": "https://api.github.com/users/edumotya/followers", "following_url": "https://api.github.com/users/edumotya/following{/other_user}", "gists_url": "https://api.github.com/users/edumotya/gists{/gist_id}", "starred_url": "https://api.github.com/users/edumotya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edumotya/subscriptions", "organizations_url": "https://api.github.com/users/edumotya/orgs", "repos_url": "https://api.github.com/users/edumotya/repos", "events_url": "https://api.github.com/users/edumotya/events{/privacy}", "received_events_url": "https://api.github.com/users/edumotya/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-20T12:02:49Z", "updated_at": "2018-09-21T09:04:08Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5249258\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/praveeny1986\">@praveeny1986</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16227629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/seanliu96\">@seanliu96</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12630218\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cocoakeith\">@cocoakeith</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16227629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/seanliu96\">@seanliu96</a>, we have met the exact same problem. It persists from tensorflow 1.6 to 1.11.0rc1. We can train on GPU through the <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5249258\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/praveeny1986\">@praveeny1986</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5117188\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/protoget\">@protoget</a> workaround <a href=\"https://gist.github.com/protoget/9b45881f23c96e201a90581c8f4b692d\">https://gist.github.com/protoget/9b45881f23c96e201a90581c8f4b692d</a>. However, the inference code for CPU does not work for us:</p>\n<p><code> No OpKernel was registered to support Op 'LSTMBlockCell' with these attrs.  Registered devices: [CPU], Registered kernels: &lt;no registered kernels&gt; [[Node: OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell = LSTMBlockCell[T=DT_FLOAT, cell_clip=-1, forget_bias=0, use_peephole=false](OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Identity_3, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Identity_4, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell/Enter, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell/Enter_1)]]</code></p>\n<hr>\n<p>UPDATED:</p>\n<p>It was actually another situation, a known issue. Solved by importing the contrib.rnn modules:</p>\n<p><code>from tensorflow.contrib.rnn import * </code></p>", "body_text": "Hi @drpngx @praveeny1986 @seanliu96 @cocoakeith @seanliu96, we have met the exact same problem. It persists from tensorflow 1.6 to 1.11.0rc1. We can train on GPU through the @praveeny1986 @protoget workaround https://gist.github.com/protoget/9b45881f23c96e201a90581c8f4b692d. However, the inference code for CPU does not work for us:\n No OpKernel was registered to support Op 'LSTMBlockCell' with these attrs.  Registered devices: [CPU], Registered kernels: <no registered kernels> [[Node: OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell = LSTMBlockCell[T=DT_FLOAT, cell_clip=-1, forget_bias=0, use_peephole=false](OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Identity_3, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Identity_4, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell/Enter, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell/Enter_1)]]\n\nUPDATED:\nIt was actually another situation, a known issue. Solved by importing the contrib.rnn modules:\nfrom tensorflow.contrib.rnn import *", "body": "Hi @drpngx @praveeny1986 @seanliu96 @cocoakeith @seanliu96, we have met the exact same problem. It persists from tensorflow 1.6 to 1.11.0rc1. We can train on GPU through the @praveeny1986 @protoget workaround [https://gist.github.com/protoget/9b45881f23c96e201a90581c8f4b692d](https://gist.github.com/protoget/9b45881f23c96e201a90581c8f4b692d). However, the inference code for CPU does not work for us:\r\n\r\n` No OpKernel was registered to support Op 'LSTMBlockCell' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\t [[Node: OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell = LSTMBlockCell[T=DT_FLOAT, cell_clip=-1, forget_bias=0, use_peephole=false](OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Identity_3, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Identity_4, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell/Enter, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/zeros, OCR/Rnn/bdrnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/cudnn_compatible_lstm_cell/LSTMBlockCell/Enter_1)]]`\r\n\r\n------\r\nUPDATED:\r\n\r\nIt was actually another situation, a known issue. Solved by importing the contrib.rnn modules:\r\n\r\n`from tensorflow.contrib.rnn import *\r\n`"}