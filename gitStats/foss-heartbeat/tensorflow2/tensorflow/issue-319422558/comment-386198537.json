{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/386198537", "html_url": "https://github.com/tensorflow/tensorflow/issues/19016#issuecomment-386198537", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19016", "id": 386198537, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjE5ODUzNw==", "user": {"login": "praveeny1986", "id": 5249258, "node_id": "MDQ6VXNlcjUyNDkyNTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/5249258?v=4", "gravatar_id": "", "url": "https://api.github.com/users/praveeny1986", "html_url": "https://github.com/praveeny1986", "followers_url": "https://api.github.com/users/praveeny1986/followers", "following_url": "https://api.github.com/users/praveeny1986/following{/other_user}", "gists_url": "https://api.github.com/users/praveeny1986/gists{/gist_id}", "starred_url": "https://api.github.com/users/praveeny1986/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/praveeny1986/subscriptions", "organizations_url": "https://api.github.com/users/praveeny1986/orgs", "repos_url": "https://api.github.com/users/praveeny1986/repos", "events_url": "https://api.github.com/users/praveeny1986/events{/privacy}", "received_events_url": "https://api.github.com/users/praveeny1986/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-03T06:02:26Z", "updated_at": "2018-05-03T06:31:27Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5117188\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/protoget\">@protoget</a> , <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16018\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/asimshankar\">@asimshankar</a> ,<br>\nWe trained the model using CudnnLSTM and then for inferencing on CPU we tried the CudnnCompatibleLSTMCell (didnt find CudnnCompatibleLSTM as you mentioned in the API but instead found CudnnCompatibleLSTMCell and hence used it) as mentioned in example.</p>\n<p><strong>Training code on GPU:</strong></p>\n<pre><code>lstm = tf.contrib.cudnn_rnn.CudnnLSTM(num_layers=1,\n                                         num_units=n_cell_dim,\n                                         direction='bidirectional',\n                                         seed=FLAGS.random_seed,\n                                         dtype=tf.float32)\nlstm.build(inputs.get_shape())\noutputs, output_states = lstm(inputs, training=is_training)\n</code></pre>\n<p><strong>Inferencing code on CPU:</strong></p>\n<pre><code>   single_cell = lambda: tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(n_cell_dim, \n   reuse=tf.get_variable_scope().reuse)\n\n   lstm_fw_cell = [single_cell() for _ in range(1)]\n   lstm_bw_cell = [single_cell() for _ in range(1)]\n   (outputs, output_state_fw,\n    output_state_bw) = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(lstm_fw_cell,\n                                                            lstm_bw_cell,\n                                                            inputs,\n                                                            dtype=tf.float32,\n                                                            time_major=True,\n                                                            sequence_length=seq_length)\n\n</code></pre>\n<p><strong>But we are getting the following error:</strong></p>\n<pre><code>Key stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/cudnn_compatible_lstm_cell/bias not found in checkpoint\n[[Node: save_1/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\n</code></pre>\n<p>How can we make it work?</p>", "body_text": "@protoget , @asimshankar ,\nWe trained the model using CudnnLSTM and then for inferencing on CPU we tried the CudnnCompatibleLSTMCell (didnt find CudnnCompatibleLSTM as you mentioned in the API but instead found CudnnCompatibleLSTMCell and hence used it) as mentioned in example.\nTraining code on GPU:\nlstm = tf.contrib.cudnn_rnn.CudnnLSTM(num_layers=1,\n                                         num_units=n_cell_dim,\n                                         direction='bidirectional',\n                                         seed=FLAGS.random_seed,\n                                         dtype=tf.float32)\nlstm.build(inputs.get_shape())\noutputs, output_states = lstm(inputs, training=is_training)\n\nInferencing code on CPU:\n   single_cell = lambda: tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(n_cell_dim, \n   reuse=tf.get_variable_scope().reuse)\n\n   lstm_fw_cell = [single_cell() for _ in range(1)]\n   lstm_bw_cell = [single_cell() for _ in range(1)]\n   (outputs, output_state_fw,\n    output_state_bw) = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(lstm_fw_cell,\n                                                            lstm_bw_cell,\n                                                            inputs,\n                                                            dtype=tf.float32,\n                                                            time_major=True,\n                                                            sequence_length=seq_length)\n\n\nBut we are getting the following error:\nKey stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/cudnn_compatible_lstm_cell/bias not found in checkpoint\n[[Node: save_1/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\n\nHow can we make it work?", "body": "@protoget , @asimshankar ,\r\nWe trained the model using CudnnLSTM and then for inferencing on CPU we tried the CudnnCompatibleLSTMCell (didnt find CudnnCompatibleLSTM as you mentioned in the API but instead found CudnnCompatibleLSTMCell and hence used it) as mentioned in example.\r\n\r\n**Training code on GPU:**\r\n```\r\nlstm = tf.contrib.cudnn_rnn.CudnnLSTM(num_layers=1,\r\n                                         num_units=n_cell_dim,\r\n                                         direction='bidirectional',\r\n                                         seed=FLAGS.random_seed,\r\n                                         dtype=tf.float32)\r\nlstm.build(inputs.get_shape())\r\noutputs, output_states = lstm(inputs, training=is_training)\r\n```\r\n**Inferencing code on CPU:**\r\n```\r\n   single_cell = lambda: tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(n_cell_dim, \r\n   reuse=tf.get_variable_scope().reuse)\r\n\r\n   lstm_fw_cell = [single_cell() for _ in range(1)]\r\n   lstm_bw_cell = [single_cell() for _ in range(1)]\r\n   (outputs, output_state_fw,\r\n    output_state_bw) = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(lstm_fw_cell,\r\n                                                            lstm_bw_cell,\r\n                                                            inputs,\r\n                                                            dtype=tf.float32,\r\n                                                            time_major=True,\r\n                                                            sequence_length=seq_length)\r\n\r\n```\r\n**But we are getting the following error:**\r\n```\r\nKey stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/cudnn_compatible_lstm_cell/bias not found in checkpoint\r\n[[Node: save_1/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\r\n```\r\nHow can we make it work?"}