{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21953", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21953/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21953/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21953/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21953", "id": 355221675, "node_id": "MDU6SXNzdWUzNTUyMjE2NzU=", "number": 21953, "title": "Feature request: partial_run_reset()", "user": {"login": "slerman12", "id": 9126603, "node_id": "MDQ6VXNlcjkxMjY2MDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/9126603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/slerman12", "html_url": "https://github.com/slerman12", "followers_url": "https://api.github.com/users/slerman12/followers", "following_url": "https://api.github.com/users/slerman12/following{/other_user}", "gists_url": "https://api.github.com/users/slerman12/gists{/gist_id}", "starred_url": "https://api.github.com/users/slerman12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/slerman12/subscriptions", "organizations_url": "https://api.github.com/users/slerman12/orgs", "repos_url": "https://api.github.com/users/slerman12/repos", "events_url": "https://api.github.com/users/slerman12/events{/privacy}", "received_events_url": "https://api.github.com/users/slerman12/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-08-29T15:43:46Z", "updated_at": "2018-09-01T00:38:39Z", "closed_at": "2018-09-01T00:38:39Z", "author_association": "NONE", "body_html": "<p>Experimental partial_run feature leaks memory. The problem is demonstrated below (with explanatory comments). A simple solution might look like <code>session.partial_run_reset()</code> at the end of the while loop.</p>\n<p>Thanks if this can be added!</p>\n<pre><code>import tensorflow as tf\n\n# Define graph\nsome_placeholder_value = tf.placeholder(tf.float32, shape=[])\nlong_list_of_ones = tf.ones(10000)\nsome_operation = long_list_of_ones + 1\na_second_operation = some_operation + some_placeholder_value\n\n# Initialize\ninitialize = tf.global_variables_initializer()\nsession = tf.Session()\nsession.run(initialize)\n\n# Using partial run in a loop causes a memory leak if not all fetches are fetched. \n# For increased dynamism please allow resetting the partial run graph so that one \n# does not have to know for sure which fetches will be used ahead of time.\n\nwhile True:\n    # Watch as application memory steadily increases... \n    handle = session.partial_run_setup([some_operation, a_second_operation], \n                                       [some_placeholder_value])\n    run = session.partial_run(handle, some_operation)\n</code></pre>\n<p>Memory usage grows really fast! Since a great advantage of this feature is that it affords greater dynamism and modularity, the option to reset at the end of each iteration would help since it would allow one to use this feature without knowing the full list of fetches a priori.</p>\n<p>Alternatively, allowing the same graph components to be re-fetched would also do the trick (by putting handle outside the while loop) and would afford even more dynamism and modularity... but is probably harder to implement.</p>", "body_text": "Experimental partial_run feature leaks memory. The problem is demonstrated below (with explanatory comments). A simple solution might look like session.partial_run_reset() at the end of the while loop.\nThanks if this can be added!\nimport tensorflow as tf\n\n# Define graph\nsome_placeholder_value = tf.placeholder(tf.float32, shape=[])\nlong_list_of_ones = tf.ones(10000)\nsome_operation = long_list_of_ones + 1\na_second_operation = some_operation + some_placeholder_value\n\n# Initialize\ninitialize = tf.global_variables_initializer()\nsession = tf.Session()\nsession.run(initialize)\n\n# Using partial run in a loop causes a memory leak if not all fetches are fetched. \n# For increased dynamism please allow resetting the partial run graph so that one \n# does not have to know for sure which fetches will be used ahead of time.\n\nwhile True:\n    # Watch as application memory steadily increases... \n    handle = session.partial_run_setup([some_operation, a_second_operation], \n                                       [some_placeholder_value])\n    run = session.partial_run(handle, some_operation)\n\nMemory usage grows really fast! Since a great advantage of this feature is that it affords greater dynamism and modularity, the option to reset at the end of each iteration would help since it would allow one to use this feature without knowing the full list of fetches a priori.\nAlternatively, allowing the same graph components to be re-fetched would also do the trick (by putting handle outside the while loop) and would afford even more dynamism and modularity... but is probably harder to implement.", "body": "Experimental partial_run feature leaks memory. The problem is demonstrated below (with explanatory comments). A simple solution might look like `session.partial_run_reset()` at the end of the while loop. \r\n\r\nThanks if this can be added!\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n# Define graph\r\nsome_placeholder_value = tf.placeholder(tf.float32, shape=[])\r\nlong_list_of_ones = tf.ones(10000)\r\nsome_operation = long_list_of_ones + 1\r\na_second_operation = some_operation + some_placeholder_value\r\n\r\n# Initialize\r\ninitialize = tf.global_variables_initializer()\r\nsession = tf.Session()\r\nsession.run(initialize)\r\n\r\n# Using partial run in a loop causes a memory leak if not all fetches are fetched. \r\n# For increased dynamism please allow resetting the partial run graph so that one \r\n# does not have to know for sure which fetches will be used ahead of time.\r\n\r\nwhile True:\r\n    # Watch as application memory steadily increases... \r\n    handle = session.partial_run_setup([some_operation, a_second_operation], \r\n                                       [some_placeholder_value])\r\n    run = session.partial_run(handle, some_operation)\r\n```\r\n\r\nMemory usage grows really fast! Since a great advantage of this feature is that it affords greater dynamism and modularity, the option to reset at the end of each iteration would help since it would allow one to use this feature without knowing the full list of fetches a priori.\r\n\r\nAlternatively, allowing the same graph components to be re-fetched would also do the trick (by putting handle outside the while loop) and would afford even more dynamism and modularity... but is probably harder to implement."}