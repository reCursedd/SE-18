{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17368", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17368/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17368/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17368/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17368", "id": 301566954, "node_id": "MDU6SXNzdWUzMDE1NjY5NTQ=", "number": 17368, "title": "The best way to pass the LSTM state between batches", "user": {"login": "FrancescoSaverioZuppichini", "id": 15908060, "node_id": "MDQ6VXNlcjE1OTA4MDYw", "avatar_url": "https://avatars3.githubusercontent.com/u/15908060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FrancescoSaverioZuppichini", "html_url": "https://github.com/FrancescoSaverioZuppichini", "followers_url": "https://api.github.com/users/FrancescoSaverioZuppichini/followers", "following_url": "https://api.github.com/users/FrancescoSaverioZuppichini/following{/other_user}", "gists_url": "https://api.github.com/users/FrancescoSaverioZuppichini/gists{/gist_id}", "starred_url": "https://api.github.com/users/FrancescoSaverioZuppichini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FrancescoSaverioZuppichini/subscriptions", "organizations_url": "https://api.github.com/users/FrancescoSaverioZuppichini/orgs", "repos_url": "https://api.github.com/users/FrancescoSaverioZuppichini/repos", "events_url": "https://api.github.com/users/FrancescoSaverioZuppichini/events{/privacy}", "received_events_url": "https://api.github.com/users/FrancescoSaverioZuppichini/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-01T21:32:16Z", "updated_at": "2018-03-03T00:59:51Z", "closed_at": "2018-03-03T00:59:51Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<h3>System information</h3>\n<p>The problem is independent of the system information.</p>\n<p>I am using Tensorflow 1.5</p>\n<h3>Describe the problem</h3>\n<p>I think I will be insane. I am trying to find the best way to pass the LSTM state between batches. I have searched everything but I could not find a solution for the current implementation. Imagine I have something like:</p>\n<pre><code>cells = [rnn.LSTMCell(size) for size in [256,256]\ncells = rnn.MultiRNNCell(cells, state_is_tuple=True)\ninit_state = cells.zero_state(tf.shape(x_hot)[0], dtype=tf.float32)\nnet, new_state = tf.nn.dynamic_rnn(cells, x_hot, initial_state=init_state ,dtype=tf.float32)\n</code></pre>\n<p>Now I would like to pass the <code>new_state</code> in each batch efficiently, so without storing it back to memory and then re-feed to tf using <code>feed_dict</code>. To be more precise, all the solutions I found use <code>sess.run</code> to evaluate <code>new_state</code> and  <code>feed-dict</code> to pass it into <code>init_state</code>. Is there any way to do so without having the bottleneck of using <code>feed-dict</code>?</p>\n<p>I think I should use <code>tf.assign</code> in some way but the doc is incomplete and I could not find any workaround.</p>\n<p>I am writing this problem here since It is unsolved everywhere else and I think this should be in the doc since it is a common case scenario.</p>\n<p>I want to thank everybody that will ask in advance.</p>\n<p>Cheers,</p>\n<p>Francesco Saverio</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\nSystem information\nThe problem is independent of the system information.\nI am using Tensorflow 1.5\nDescribe the problem\nI think I will be insane. I am trying to find the best way to pass the LSTM state between batches. I have searched everything but I could not find a solution for the current implementation. Imagine I have something like:\ncells = [rnn.LSTMCell(size) for size in [256,256]\ncells = rnn.MultiRNNCell(cells, state_is_tuple=True)\ninit_state = cells.zero_state(tf.shape(x_hot)[0], dtype=tf.float32)\nnet, new_state = tf.nn.dynamic_rnn(cells, x_hot, initial_state=init_state ,dtype=tf.float32)\n\nNow I would like to pass the new_state in each batch efficiently, so without storing it back to memory and then re-feed to tf using feed_dict. To be more precise, all the solutions I found use sess.run to evaluate new_state and  feed-dict to pass it into init_state. Is there any way to do so without having the bottleneck of using feed-dict?\nI think I should use tf.assign in some way but the doc is incomplete and I could not find any workaround.\nI am writing this problem here since It is unsolved everywhere else and I think this should be in the doc since it is a common case scenario.\nI want to thank everybody that will ask in advance.\nCheers,\nFrancesco Saverio", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n### System information\r\nThe problem is independent of the system information.\r\n\r\nI am using Tensorflow 1.5\r\n\r\n### Describe the problem\r\nI think I will be insane. I am trying to find the best way to pass the LSTM state between batches. I have searched everything but I could not find a solution for the current implementation. Imagine I have something like:\r\n\r\n```\r\ncells = [rnn.LSTMCell(size) for size in [256,256]\r\ncells = rnn.MultiRNNCell(cells, state_is_tuple=True)\r\ninit_state = cells.zero_state(tf.shape(x_hot)[0], dtype=tf.float32)\r\nnet, new_state = tf.nn.dynamic_rnn(cells, x_hot, initial_state=init_state ,dtype=tf.float32)\r\n```\r\n\r\nNow I would like to pass the `new_state` in each batch efficiently, so without storing it back to memory and then re-feed to tf using `feed_dict`. To be more precise, all the solutions I found use `sess.run` to evaluate `new_state` and  `feed-dict` to pass it into `init_state`. Is there any way to do so without having the bottleneck of using `feed-dict`?\r\n\r\nI think I should use `tf.assign` in some way but the doc is incomplete and I could not find any workaround.\r\n\r\nI am writing this problem here since It is unsolved everywhere else and I think this should be in the doc since it is a common case scenario. \r\n\r\nI want to thank everybody that will ask in advance.\r\n\r\nCheers,\r\n\r\nFrancesco Saverio\r\n"}