{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16465", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16465/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16465/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16465/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16465", "id": 291987395, "node_id": "MDU6SXNzdWUyOTE5ODczOTU=", "number": 16465, "title": "bug with frame_step in tf.contrib.signal overlap_and_add inverse_stft", "user": {"login": "memo", "id": 144230, "node_id": "MDQ6VXNlcjE0NDIzMA==", "avatar_url": "https://avatars0.githubusercontent.com/u/144230?v=4", "gravatar_id": "", "url": "https://api.github.com/users/memo", "html_url": "https://github.com/memo", "followers_url": "https://api.github.com/users/memo/followers", "following_url": "https://api.github.com/users/memo/following{/other_user}", "gists_url": "https://api.github.com/users/memo/gists{/gist_id}", "starred_url": "https://api.github.com/users/memo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/memo/subscriptions", "organizations_url": "https://api.github.com/users/memo/orgs", "repos_url": "https://api.github.com/users/memo/repos", "events_url": "https://api.github.com/users/memo/events{/privacy}", "received_events_url": "https://api.github.com/users/memo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "rryan", "id": 26527, "node_id": "MDQ6VXNlcjI2NTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/26527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rryan", "html_url": "https://github.com/rryan", "followers_url": "https://api.github.com/users/rryan/followers", "following_url": "https://api.github.com/users/rryan/following{/other_user}", "gists_url": "https://api.github.com/users/rryan/gists{/gist_id}", "starred_url": "https://api.github.com/users/rryan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rryan/subscriptions", "organizations_url": "https://api.github.com/users/rryan/orgs", "repos_url": "https://api.github.com/users/rryan/repos", "events_url": "https://api.github.com/users/rryan/events{/privacy}", "received_events_url": "https://api.github.com/users/rryan/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rryan", "id": 26527, "node_id": "MDQ6VXNlcjI2NTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/26527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rryan", "html_url": "https://github.com/rryan", "followers_url": "https://api.github.com/users/rryan/followers", "following_url": "https://api.github.com/users/rryan/following{/other_user}", "gists_url": "https://api.github.com/users/rryan/gists{/gist_id}", "starred_url": "https://api.github.com/users/rryan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rryan/subscriptions", "organizations_url": "https://api.github.com/users/rryan/orgs", "repos_url": "https://api.github.com/users/rryan/repos", "events_url": "https://api.github.com/users/rryan/events{/privacy}", "received_events_url": "https://api.github.com/users/rryan/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-01-26T18:16:59Z", "updated_at": "2018-11-14T19:14:46Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li>Based on example</li>\n<li>Linux Ubuntu 16.04</li>\n<li>installed from binary</li>\n<li>v1.4.0-19-ga52c8d9, 1.4.1; also 1.5.0</li>\n<li>Python 2.7.14 |Anaconda custom (64-bit)| (default, Oct 16 2017, 17:29:19). IPython 5.4.1</li>\n<li>Cuda release 8.0, V8.0.61, cuDNN 6; also Cuda release 9.0, V9.0.176, cuDNN 7.0.5</li>\n<li>Geforce GTX 970M, also GTX 1070, Driver Version: 384.111</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>A.) When I create frames from a signal with <code>frame_length=1024</code> and  <code>frame_step=256</code> (i.e. 25% hop size, 75% overlap) using a hann window (also tried hamming), and then I reconstruct with <code>overlap_and_add</code>, I'd expect the signal to be reconstructed correctly (because of COLA etc). But instead it comes out exactly double the amplitude. I need to divide the resulting signal by two for it to be correct.</p>\n<p>B.) If I use STFT to create a series of overlapping spectrograms, and then reconstruct with inverse STFT, again with <code>frame_length=1024</code> and <code>frame_step=256</code>, the signal is again reconstructed at double amplitude.</p>\n<p>I realise why these might be the case (unity gain at 50% overlap for hann, so 75% overlap will double the signal). But is it not normal for the reconstruction function to take this into account? E.g. librosa istft does return signal with correct amplitude while tensorflow returns double.</p>\n<p>C.)<br>\nAt any other frame_step there is severe amplitude modulation going on. See images below. This doesn't seem right at all.</p>\n<p><strong>UPDATE</strong>: If I explicitly set <code>window_fn=tf.contrib.signal.inverse_stft_window_fn(frame_step)</code> in <code>inverse_stft</code> the output is correct. So it seems the <code>frame_step</code> parameter in <code>inverse_stft</code> is not being passed into the window function (which is also what the results hint at).</p>\n<h3>Source code / logs</h3>\n<p>original data:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579363-64e51ef6-05de-11e8-8dc2-f4220265c2f8.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579363-64e51ef6-05de-11e8-8dc2-f4220265c2f8.png\" alt=\"22050 orig\" style=\"max-width:100%;\"></a></p>\n<p>tensorflow output from frames + overlap_and_add:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579392-7907d798-05de-11e8-8971-64597d3e06d3.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579392-7907d798-05de-11e8-8971-64597d3e06d3.png\" alt=\"tensorflow 22050 frame l1024 s256\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579393-792fb060-05de-11e8-93af-efc2bd30d058.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579393-792fb060-05de-11e8-93af-efc2bd30d058.png\" alt=\"tensorflow 22050 frame l1024 s512\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579394-794b9898-05de-11e8-82e7-ecbb41feed9a.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579394-794b9898-05de-11e8-82e7-ecbb41feed9a.png\" alt=\"tensorflow 22050 frame l1024 s768\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579397-7a3116fc-05de-11e8-815d-d4df17e86dc5.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579397-7a3116fc-05de-11e8-815d-d4df17e86dc5.png\" alt=\"tensorflow 22050 frame l1024 s1024\" style=\"max-width:100%;\"></a></p>\n<p>tensorflow output from stft+istft:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579401-7ed0727a-05de-11e8-9cf2-e8dd06df9e05.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579401-7ed0727a-05de-11e8-9cf2-e8dd06df9e05.png\" alt=\"tensorflow 22050 stft l1024 s256\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579402-7ee9d29c-05de-11e8-93e0-a6d676c7d5ae.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579402-7ee9d29c-05de-11e8-93e0-a6d676c7d5ae.png\" alt=\"tensorflow 22050 stft l1024 s512\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579403-7f01f818-05de-11e8-8779-e50b824b8aec.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579403-7f01f818-05de-11e8-8779-e50b824b8aec.png\" alt=\"tensorflow 22050 stft l1024 s768\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579404-7f272a34-05de-11e8-9b55-a41942db7eb1.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579404-7f272a34-05de-11e8-9b55-a41942db7eb1.png\" alt=\"tensorflow 22050 stft l1024 s1024\" style=\"max-width:100%;\"></a></p>\n<p>librosa output from stft+istft:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579408-834faee2-05de-11e8-8f44-e6ef0e797fb4.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579408-834faee2-05de-11e8-8f44-e6ef0e797fb4.png\" alt=\"librosa 22050 stft l1024 s256\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579409-8385fa6a-05de-11e8-8d36-b96c35ba862a.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579409-8385fa6a-05de-11e8-8d36-b96c35ba862a.png\" alt=\"librosa 22050 stft l1024 s512\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579410-83a5767e-05de-11e8-89bd-6d01c9a7cb8c.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579410-83a5767e-05de-11e8-89bd-6d01c9a7cb8c.png\" alt=\"librosa 22050 stft l1024 s768\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/144230/35579411-83c791c8-05de-11e8-8b6c-7ef5508a66e5.png\"><img src=\"https://user-images.githubusercontent.com/144230/35579411-83c791c8-05de-11e8-8b6c-7ef5508a66e5.png\" alt=\"librosa 22050 stft l1024 s1024\" style=\"max-width:100%;\"></a></p>\n<p>tensorflow code:</p>\n<pre><code>from __future__ import print_function\nfrom __future__ import division\n\nimport numpy as np\nimport scipy.io.wavfile\nimport math\nimport random\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nout_prefix = 'tensorflow'\n\n\ndef plot(data, title, do_save=True):\n    plt.figure(figsize=(20,5))\n    plt.plot(data[:3*frame_length])\n    plt.ylim([-1, 1])\n    plt.title(title)\n    plt.grid()\n    if do_save: plt.savefig(title + '.png')\n    plt.show()\n\n\ndef reconstruct_from_frames(x, frame_length, frame_step):\n    name = 'frame'\n    frames_T = tf.contrib.signal.frame(x, frame_length=frame_length, frame_step=frame_step)\n    windowed_frames_T = frames_T * tf.contrib.signal.hann_window(frame_length, periodic=True)\n    output_T = tf.contrib.signal.overlap_and_add(windowed_frames_T, frame_step=frame_step)\n    return name, output_T\n\n\ndef reconstruct_from_stft(x, frame_length, frame_step):\n    name = 'stft'\n    spectrograms_T = tf.contrib.signal.stft(x, frame_length, frame_step)\n    output_T = tf.contrib.signal.inverse_stft(spectrograms_T, frame_length, frame_step)\n    return name, output_T\n\n\ndef test(fn, input_data):\n    print('-'*80)\n    tf.reset_default_graph()\n    input_T = tf.placeholder(tf.float32, [None]) \n    name, output_T = fn(input_T, frame_length, frame_step)\n\n    title = \"{}.{}.{}.l{}.s{}\".format(out_prefix, sample_rate, name, frame_length, frame_step)\n    print(title)\n\n    with tf.Session():\n        output_data =  output_T.eval({input_T:input_data})\n\n#    output_data /= frame_length/frame_step/2 # tensorflow needs this to normalise amp\n    plot(output_data, title)\n    scipy.io.wavfile.write(title+'.wav', sample_rate, output_data)\n\n\ndef generate_data(duration_secs, sample_rate, num_sin, min_freq=10, max_freq=500, rnd_seed=0, max_val=0):\n    '''generate signal from multiple random sin waves'''\n    if rnd_seed&gt;0: random.seed(rnd_seed)\n    data = np.zeros([duration_secs*sample_rate], np.float32)\n    for i in range(num_sin):\n        w = np.float32(np.sin(np.linspace(0, math.pi*2*random.randrange(min_freq, max_freq), num=duration_secs*sample_rate)))\n        data += random.random() * w\n    if max_val&gt;0:\n        data *= max_val / np.max(np.abs(data))\n    return data\n    \n\nframe_length = 1024\nsample_rate = 22050\n\ninput_data = generate_data(duration_secs=1, sample_rate=sample_rate, num_sin=1, rnd_seed=2, max_val=0.5)\n\ntitle = \"{}.orig\".format(sample_rate)\nplot(input_data, title)\nscipy.io.wavfile.write(title+'.wav', sample_rate, input_data)\n\nfor frame_step in [256, 512, 768, 1024]:\n    test(reconstruct_from_frames, input_data)\n    test(reconstruct_from_stft, input_data)\n\nprint('done.')\n</code></pre>\n<p>librosa code:</p>\n<pre><code>from __future__ import print_function\nfrom __future__ import division\n\nimport numpy as np\nimport scipy.io.wavfile\nimport math\nimport random\nimport matplotlib.pyplot as plt\n\nimport librosa.core as lc\nout_prefix = 'librosa'\n\n\ndef plot(data, title, do_save=True):\n    plt.figure(figsize=(20,5))\n    plt.plot(data[:3*frame_length])\n    plt.ylim([-1, 1])\n    plt.title(title)\n    plt.grid()\n    if do_save: plt.savefig(title + '.png')\n    plt.show()\n\n\ndef reconstruct_from_stft(x, frame_length, frame_step):\n    name = 'stft'\n    stft = lc.stft(x, n_fft=frame_length, hop_length=frame_step)\n    istft = lc.istft(stft, frame_step)\n    return name, istft\n\n\ndef test(fn, input_data):\n    print('-'*80)\n    name, output_data = fn(input_data, frame_length, frame_step)\n\n    title = \"{}.{}.{}.l{}.s{}\".format(out_prefix, sample_rate, name, frame_length, frame_step)\n    print(title)\n\n#    output_data /= frame_length/frame_step/2 # tensorflow needs this to normalise amp\n    plot(output_data, title)\n    scipy.io.wavfile.write(title+'.wav', sample_rate, output_data)\n\n\ndef generate_data(duration_secs, sample_rate, num_sin, min_freq=10, max_freq=500, rnd_seed=0, max_val=0):\n    '''generate signal from multiple random sin waves'''\n    if rnd_seed&gt;0: random.seed(rnd_seed)\n    data = np.zeros([duration_secs*sample_rate], np.float32)\n    for i in range(num_sin):\n        w = np.float32(np.sin(np.linspace(0, math.pi*2*random.randrange(min_freq, max_freq), num=duration_secs*sample_rate)))\n        data += random.random() * w\n    if max_val&gt;0:\n        data *= max_val / np.max(np.abs(data))\n    return data\n    \n\nframe_length = 1024\nsample_rate = 22050\n\ninput_data = generate_data(duration_secs=1, sample_rate=sample_rate, num_sin=1, rnd_seed=2, max_val=0.5)\n\ntitle = \"{}.orig\".format(sample_rate)\nplot(input_data, title)\nscipy.io.wavfile.write(title+'.wav', sample_rate, input_data)\n\nfor frame_step in [256, 512, 768, 1024]:\n    test(reconstruct_from_stft, input_data)\n\nprint('done.')\n</code></pre>", "body_text": "System information\n\nBased on example\nLinux Ubuntu 16.04\ninstalled from binary\nv1.4.0-19-ga52c8d9, 1.4.1; also 1.5.0\nPython 2.7.14 |Anaconda custom (64-bit)| (default, Oct 16 2017, 17:29:19). IPython 5.4.1\nCuda release 8.0, V8.0.61, cuDNN 6; also Cuda release 9.0, V9.0.176, cuDNN 7.0.5\nGeforce GTX 970M, also GTX 1070, Driver Version: 384.111\n\nDescribe the problem\nA.) When I create frames from a signal with frame_length=1024 and  frame_step=256 (i.e. 25% hop size, 75% overlap) using a hann window (also tried hamming), and then I reconstruct with overlap_and_add, I'd expect the signal to be reconstructed correctly (because of COLA etc). But instead it comes out exactly double the amplitude. I need to divide the resulting signal by two for it to be correct.\nB.) If I use STFT to create a series of overlapping spectrograms, and then reconstruct with inverse STFT, again with frame_length=1024 and frame_step=256, the signal is again reconstructed at double amplitude.\nI realise why these might be the case (unity gain at 50% overlap for hann, so 75% overlap will double the signal). But is it not normal for the reconstruction function to take this into account? E.g. librosa istft does return signal with correct amplitude while tensorflow returns double.\nC.)\nAt any other frame_step there is severe amplitude modulation going on. See images below. This doesn't seem right at all.\nUPDATE: If I explicitly set window_fn=tf.contrib.signal.inverse_stft_window_fn(frame_step) in inverse_stft the output is correct. So it seems the frame_step parameter in inverse_stft is not being passed into the window function (which is also what the results hint at).\nSource code / logs\noriginal data:\n\ntensorflow output from frames + overlap_and_add:\n\n\n\n\ntensorflow output from stft+istft:\n\n\n\n\nlibrosa output from stft+istft:\n\n\n\n\ntensorflow code:\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport numpy as np\nimport scipy.io.wavfile\nimport math\nimport random\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nout_prefix = 'tensorflow'\n\n\ndef plot(data, title, do_save=True):\n    plt.figure(figsize=(20,5))\n    plt.plot(data[:3*frame_length])\n    plt.ylim([-1, 1])\n    plt.title(title)\n    plt.grid()\n    if do_save: plt.savefig(title + '.png')\n    plt.show()\n\n\ndef reconstruct_from_frames(x, frame_length, frame_step):\n    name = 'frame'\n    frames_T = tf.contrib.signal.frame(x, frame_length=frame_length, frame_step=frame_step)\n    windowed_frames_T = frames_T * tf.contrib.signal.hann_window(frame_length, periodic=True)\n    output_T = tf.contrib.signal.overlap_and_add(windowed_frames_T, frame_step=frame_step)\n    return name, output_T\n\n\ndef reconstruct_from_stft(x, frame_length, frame_step):\n    name = 'stft'\n    spectrograms_T = tf.contrib.signal.stft(x, frame_length, frame_step)\n    output_T = tf.contrib.signal.inverse_stft(spectrograms_T, frame_length, frame_step)\n    return name, output_T\n\n\ndef test(fn, input_data):\n    print('-'*80)\n    tf.reset_default_graph()\n    input_T = tf.placeholder(tf.float32, [None]) \n    name, output_T = fn(input_T, frame_length, frame_step)\n\n    title = \"{}.{}.{}.l{}.s{}\".format(out_prefix, sample_rate, name, frame_length, frame_step)\n    print(title)\n\n    with tf.Session():\n        output_data =  output_T.eval({input_T:input_data})\n\n#    output_data /= frame_length/frame_step/2 # tensorflow needs this to normalise amp\n    plot(output_data, title)\n    scipy.io.wavfile.write(title+'.wav', sample_rate, output_data)\n\n\ndef generate_data(duration_secs, sample_rate, num_sin, min_freq=10, max_freq=500, rnd_seed=0, max_val=0):\n    '''generate signal from multiple random sin waves'''\n    if rnd_seed>0: random.seed(rnd_seed)\n    data = np.zeros([duration_secs*sample_rate], np.float32)\n    for i in range(num_sin):\n        w = np.float32(np.sin(np.linspace(0, math.pi*2*random.randrange(min_freq, max_freq), num=duration_secs*sample_rate)))\n        data += random.random() * w\n    if max_val>0:\n        data *= max_val / np.max(np.abs(data))\n    return data\n    \n\nframe_length = 1024\nsample_rate = 22050\n\ninput_data = generate_data(duration_secs=1, sample_rate=sample_rate, num_sin=1, rnd_seed=2, max_val=0.5)\n\ntitle = \"{}.orig\".format(sample_rate)\nplot(input_data, title)\nscipy.io.wavfile.write(title+'.wav', sample_rate, input_data)\n\nfor frame_step in [256, 512, 768, 1024]:\n    test(reconstruct_from_frames, input_data)\n    test(reconstruct_from_stft, input_data)\n\nprint('done.')\n\nlibrosa code:\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport numpy as np\nimport scipy.io.wavfile\nimport math\nimport random\nimport matplotlib.pyplot as plt\n\nimport librosa.core as lc\nout_prefix = 'librosa'\n\n\ndef plot(data, title, do_save=True):\n    plt.figure(figsize=(20,5))\n    plt.plot(data[:3*frame_length])\n    plt.ylim([-1, 1])\n    plt.title(title)\n    plt.grid()\n    if do_save: plt.savefig(title + '.png')\n    plt.show()\n\n\ndef reconstruct_from_stft(x, frame_length, frame_step):\n    name = 'stft'\n    stft = lc.stft(x, n_fft=frame_length, hop_length=frame_step)\n    istft = lc.istft(stft, frame_step)\n    return name, istft\n\n\ndef test(fn, input_data):\n    print('-'*80)\n    name, output_data = fn(input_data, frame_length, frame_step)\n\n    title = \"{}.{}.{}.l{}.s{}\".format(out_prefix, sample_rate, name, frame_length, frame_step)\n    print(title)\n\n#    output_data /= frame_length/frame_step/2 # tensorflow needs this to normalise amp\n    plot(output_data, title)\n    scipy.io.wavfile.write(title+'.wav', sample_rate, output_data)\n\n\ndef generate_data(duration_secs, sample_rate, num_sin, min_freq=10, max_freq=500, rnd_seed=0, max_val=0):\n    '''generate signal from multiple random sin waves'''\n    if rnd_seed>0: random.seed(rnd_seed)\n    data = np.zeros([duration_secs*sample_rate], np.float32)\n    for i in range(num_sin):\n        w = np.float32(np.sin(np.linspace(0, math.pi*2*random.randrange(min_freq, max_freq), num=duration_secs*sample_rate)))\n        data += random.random() * w\n    if max_val>0:\n        data *= max_val / np.max(np.abs(data))\n    return data\n    \n\nframe_length = 1024\nsample_rate = 22050\n\ninput_data = generate_data(duration_secs=1, sample_rate=sample_rate, num_sin=1, rnd_seed=2, max_val=0.5)\n\ntitle = \"{}.orig\".format(sample_rate)\nplot(input_data, title)\nscipy.io.wavfile.write(title+'.wav', sample_rate, input_data)\n\nfor frame_step in [256, 512, 768, 1024]:\n    test(reconstruct_from_stft, input_data)\n\nprint('done.')", "body": "### System information\r\n- Based on example \r\n- Linux Ubuntu 16.04\r\n- installed from binary\r\n- v1.4.0-19-ga52c8d9, 1.4.1; also 1.5.0\r\n- Python 2.7.14 |Anaconda custom (64-bit)| (default, Oct 16 2017, 17:29:19). IPython 5.4.1\r\n- Cuda release 8.0, V8.0.61, cuDNN 6; also Cuda release 9.0, V9.0.176, cuDNN 7.0.5\r\n- Geforce GTX 970M, also GTX 1070, Driver Version: 384.111\r\n\r\n### Describe the problem\r\n\r\nA.) When I create frames from a signal with `frame_length=1024` and  `frame_step=256` (i.e. 25% hop size, 75% overlap) using a hann window (also tried hamming), and then I reconstruct with `overlap_and_add`, I'd expect the signal to be reconstructed correctly (because of COLA etc). But instead it comes out exactly double the amplitude. I need to divide the resulting signal by two for it to be correct. \r\n\r\nB.) If I use STFT to create a series of overlapping spectrograms, and then reconstruct with inverse STFT, again with `frame_length=1024` and `frame_step=256`, the signal is again reconstructed at double amplitude. \r\n\r\nI realise why these might be the case (unity gain at 50% overlap for hann, so 75% overlap will double the signal). But is it not normal for the reconstruction function to take this into account? E.g. librosa istft does return signal with correct amplitude while tensorflow returns double.\r\n\r\nC.) \r\nAt any other frame_step there is severe amplitude modulation going on. See images below. This doesn't seem right at all. \r\n\r\n**UPDATE**: If I explicitly set `window_fn=tf.contrib.signal.inverse_stft_window_fn(frame_step)` in `inverse_stft` the output is correct. So it seems the `frame_step` parameter in `inverse_stft` is not being passed into the window function (which is also what the results hint at).\r\n\r\n### Source code / logs\r\n\r\noriginal data:\r\n![22050 orig](https://user-images.githubusercontent.com/144230/35579363-64e51ef6-05de-11e8-8dc2-f4220265c2f8.png)\r\n\r\ntensorflow output from frames + overlap_and_add:\r\n![tensorflow 22050 frame l1024 s256](https://user-images.githubusercontent.com/144230/35579392-7907d798-05de-11e8-8971-64597d3e06d3.png)\r\n![tensorflow 22050 frame l1024 s512](https://user-images.githubusercontent.com/144230/35579393-792fb060-05de-11e8-93af-efc2bd30d058.png)\r\n![tensorflow 22050 frame l1024 s768](https://user-images.githubusercontent.com/144230/35579394-794b9898-05de-11e8-82e7-ecbb41feed9a.png)\r\n![tensorflow 22050 frame l1024 s1024](https://user-images.githubusercontent.com/144230/35579397-7a3116fc-05de-11e8-815d-d4df17e86dc5.png)\r\n\r\ntensorflow output from stft+istft:\r\n![tensorflow 22050 stft l1024 s256](https://user-images.githubusercontent.com/144230/35579401-7ed0727a-05de-11e8-9cf2-e8dd06df9e05.png)\r\n![tensorflow 22050 stft l1024 s512](https://user-images.githubusercontent.com/144230/35579402-7ee9d29c-05de-11e8-93e0-a6d676c7d5ae.png)\r\n![tensorflow 22050 stft l1024 s768](https://user-images.githubusercontent.com/144230/35579403-7f01f818-05de-11e8-8779-e50b824b8aec.png)\r\n![tensorflow 22050 stft l1024 s1024](https://user-images.githubusercontent.com/144230/35579404-7f272a34-05de-11e8-9b55-a41942db7eb1.png)\r\n\r\nlibrosa output from stft+istft:\r\n![librosa 22050 stft l1024 s256](https://user-images.githubusercontent.com/144230/35579408-834faee2-05de-11e8-8f44-e6ef0e797fb4.png)\r\n![librosa 22050 stft l1024 s512](https://user-images.githubusercontent.com/144230/35579409-8385fa6a-05de-11e8-8d36-b96c35ba862a.png)\r\n![librosa 22050 stft l1024 s768](https://user-images.githubusercontent.com/144230/35579410-83a5767e-05de-11e8-89bd-6d01c9a7cb8c.png)\r\n![librosa 22050 stft l1024 s1024](https://user-images.githubusercontent.com/144230/35579411-83c791c8-05de-11e8-8b6c-7ef5508a66e5.png)\r\n\r\ntensorflow code:\r\n\r\n    from __future__ import print_function\r\n    from __future__ import division\r\n    \r\n    import numpy as np\r\n    import scipy.io.wavfile\r\n    import math\r\n    import random\r\n    import matplotlib.pyplot as plt\r\n    \r\n    import tensorflow as tf\r\n    out_prefix = 'tensorflow'\r\n    \r\n    \r\n    def plot(data, title, do_save=True):\r\n        plt.figure(figsize=(20,5))\r\n        plt.plot(data[:3*frame_length])\r\n        plt.ylim([-1, 1])\r\n        plt.title(title)\r\n        plt.grid()\r\n        if do_save: plt.savefig(title + '.png')\r\n        plt.show()\r\n    \r\n    \r\n    def reconstruct_from_frames(x, frame_length, frame_step):\r\n        name = 'frame'\r\n        frames_T = tf.contrib.signal.frame(x, frame_length=frame_length, frame_step=frame_step)\r\n        windowed_frames_T = frames_T * tf.contrib.signal.hann_window(frame_length, periodic=True)\r\n        output_T = tf.contrib.signal.overlap_and_add(windowed_frames_T, frame_step=frame_step)\r\n        return name, output_T\r\n    \r\n    \r\n    def reconstruct_from_stft(x, frame_length, frame_step):\r\n        name = 'stft'\r\n        spectrograms_T = tf.contrib.signal.stft(x, frame_length, frame_step)\r\n        output_T = tf.contrib.signal.inverse_stft(spectrograms_T, frame_length, frame_step)\r\n        return name, output_T\r\n    \r\n    \r\n    def test(fn, input_data):\r\n        print('-'*80)\r\n        tf.reset_default_graph()\r\n        input_T = tf.placeholder(tf.float32, [None]) \r\n        name, output_T = fn(input_T, frame_length, frame_step)\r\n    \r\n        title = \"{}.{}.{}.l{}.s{}\".format(out_prefix, sample_rate, name, frame_length, frame_step)\r\n        print(title)\r\n    \r\n        with tf.Session():\r\n            output_data =  output_T.eval({input_T:input_data})\r\n    \r\n    #    output_data /= frame_length/frame_step/2 # tensorflow needs this to normalise amp\r\n        plot(output_data, title)\r\n        scipy.io.wavfile.write(title+'.wav', sample_rate, output_data)\r\n    \r\n    \r\n    def generate_data(duration_secs, sample_rate, num_sin, min_freq=10, max_freq=500, rnd_seed=0, max_val=0):\r\n        '''generate signal from multiple random sin waves'''\r\n        if rnd_seed>0: random.seed(rnd_seed)\r\n        data = np.zeros([duration_secs*sample_rate], np.float32)\r\n        for i in range(num_sin):\r\n            w = np.float32(np.sin(np.linspace(0, math.pi*2*random.randrange(min_freq, max_freq), num=duration_secs*sample_rate)))\r\n            data += random.random() * w\r\n        if max_val>0:\r\n            data *= max_val / np.max(np.abs(data))\r\n        return data\r\n        \r\n    \r\n    frame_length = 1024\r\n    sample_rate = 22050\r\n    \r\n    input_data = generate_data(duration_secs=1, sample_rate=sample_rate, num_sin=1, rnd_seed=2, max_val=0.5)\r\n    \r\n    title = \"{}.orig\".format(sample_rate)\r\n    plot(input_data, title)\r\n    scipy.io.wavfile.write(title+'.wav', sample_rate, input_data)\r\n    \r\n    for frame_step in [256, 512, 768, 1024]:\r\n        test(reconstruct_from_frames, input_data)\r\n        test(reconstruct_from_stft, input_data)\r\n    \r\n    print('done.')\r\n\r\nlibrosa code:\r\n\r\n    from __future__ import print_function\r\n    from __future__ import division\r\n    \r\n    import numpy as np\r\n    import scipy.io.wavfile\r\n    import math\r\n    import random\r\n    import matplotlib.pyplot as plt\r\n    \r\n    import librosa.core as lc\r\n    out_prefix = 'librosa'\r\n    \r\n    \r\n    def plot(data, title, do_save=True):\r\n        plt.figure(figsize=(20,5))\r\n        plt.plot(data[:3*frame_length])\r\n        plt.ylim([-1, 1])\r\n        plt.title(title)\r\n        plt.grid()\r\n        if do_save: plt.savefig(title + '.png')\r\n        plt.show()\r\n    \r\n    \r\n    def reconstruct_from_stft(x, frame_length, frame_step):\r\n        name = 'stft'\r\n        stft = lc.stft(x, n_fft=frame_length, hop_length=frame_step)\r\n        istft = lc.istft(stft, frame_step)\r\n        return name, istft\r\n    \r\n    \r\n    def test(fn, input_data):\r\n        print('-'*80)\r\n        name, output_data = fn(input_data, frame_length, frame_step)\r\n    \r\n        title = \"{}.{}.{}.l{}.s{}\".format(out_prefix, sample_rate, name, frame_length, frame_step)\r\n        print(title)\r\n    \r\n    #    output_data /= frame_length/frame_step/2 # tensorflow needs this to normalise amp\r\n        plot(output_data, title)\r\n        scipy.io.wavfile.write(title+'.wav', sample_rate, output_data)\r\n    \r\n    \r\n    def generate_data(duration_secs, sample_rate, num_sin, min_freq=10, max_freq=500, rnd_seed=0, max_val=0):\r\n        '''generate signal from multiple random sin waves'''\r\n        if rnd_seed>0: random.seed(rnd_seed)\r\n        data = np.zeros([duration_secs*sample_rate], np.float32)\r\n        for i in range(num_sin):\r\n            w = np.float32(np.sin(np.linspace(0, math.pi*2*random.randrange(min_freq, max_freq), num=duration_secs*sample_rate)))\r\n            data += random.random() * w\r\n        if max_val>0:\r\n            data *= max_val / np.max(np.abs(data))\r\n        return data\r\n        \r\n    \r\n    frame_length = 1024\r\n    sample_rate = 22050\r\n    \r\n    input_data = generate_data(duration_secs=1, sample_rate=sample_rate, num_sin=1, rnd_seed=2, max_val=0.5)\r\n    \r\n    title = \"{}.orig\".format(sample_rate)\r\n    plot(input_data, title)\r\n    scipy.io.wavfile.write(title+'.wav', sample_rate, input_data)\r\n    \r\n    for frame_step in [256, 512, 768, 1024]:\r\n        test(reconstruct_from_stft, input_data)\r\n    \r\n    print('done.')\r\n"}