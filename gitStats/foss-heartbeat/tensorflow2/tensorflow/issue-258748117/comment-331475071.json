{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/331475071", "html_url": "https://github.com/tensorflow/tensorflow/issues/13148#issuecomment-331475071", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13148", "id": 331475071, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMTQ3NTA3MQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-22T15:12:03Z", "updated_at": "2017-09-22T15:12:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>What interface and semantics would you expect for a feature like this? To guide the discussion, I doubt it would make sense to make <em>all</em> datasets mutable, because this would inhibit optimization and lead us down a path similar to the queues. However, it could make sense to have some kind of mutable data <em>source</em>, and allow using datasets to transform and iterators to iterate over these.</p>\n<p>For example, today you can write code that creates a dataset from a queue, using this (slightly unintuitive) construction:</p>\n<div class=\"highlight highlight-source-python\"><pre>q <span class=\"pl-k\">=</span> tf.FIFOQueue(<span class=\"pl-c1\">...</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Create an infinite dummy dataset</span>\ndummy <span class=\"pl-k\">=</span> Dataset.from_tensors(<span class=\"pl-c1\">0</span>).repeat(<span class=\"pl-c1\">None</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a dataset by dequeuing successive elements from `q`.</span>\ndataset <span class=\"pl-k\">=</span> dummy.map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">_</span>: q.dequeue())</pre></div>\n<p>You could also achieve something similar using the (new in 1.4) <code>Dataset.from_generator()</code> and a Python <code>queue</code> object.</p>\n<p>If you used this functionality, would it satisfy your use case, or are there other things you'd like to see?</p>", "body_text": "What interface and semantics would you expect for a feature like this? To guide the discussion, I doubt it would make sense to make all datasets mutable, because this would inhibit optimization and lead us down a path similar to the queues. However, it could make sense to have some kind of mutable data source, and allow using datasets to transform and iterators to iterate over these.\nFor example, today you can write code that creates a dataset from a queue, using this (slightly unintuitive) construction:\nq = tf.FIFOQueue(...)\n\n# Create an infinite dummy dataset\ndummy = Dataset.from_tensors(0).repeat(None)\n\n# Create a dataset by dequeuing successive elements from `q`.\ndataset = dummy.map(lambda _: q.dequeue())\nYou could also achieve something similar using the (new in 1.4) Dataset.from_generator() and a Python queue object.\nIf you used this functionality, would it satisfy your use case, or are there other things you'd like to see?", "body": "What interface and semantics would you expect for a feature like this? To guide the discussion, I doubt it would make sense to make *all* datasets mutable, because this would inhibit optimization and lead us down a path similar to the queues. However, it could make sense to have some kind of mutable data *source*, and allow using datasets to transform and iterators to iterate over these. \r\n\r\nFor example, today you can write code that creates a dataset from a queue, using this (slightly unintuitive) construction:\r\n\r\n```python\r\nq = tf.FIFOQueue(...)\r\n\r\n# Create an infinite dummy dataset\r\ndummy = Dataset.from_tensors(0).repeat(None)\r\n\r\n# Create a dataset by dequeuing successive elements from `q`.\r\ndataset = dummy.map(lambda _: q.dequeue())\r\n```\r\n\r\nYou could also achieve something similar using the (new in 1.4) `Dataset.from_generator()` and a Python `queue` object.\r\n\r\nIf you used this functionality, would it satisfy your use case, or are there other things you'd like to see? "}