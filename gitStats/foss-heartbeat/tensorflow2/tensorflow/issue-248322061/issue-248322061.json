{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12070", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12070/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12070/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12070/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12070", "id": 248322061, "node_id": "MDU6SXNzdWUyNDgzMjIwNjE=", "number": 12070, "title": "[XLA] Should we disable `REGISTER_XLA_BACKEND(GPU)` if there is no GPU installed on the machine? ", "user": {"login": "ScorpioCPH", "id": 5319646, "node_id": "MDQ6VXNlcjUzMTk2NDY=", "avatar_url": "https://avatars2.githubusercontent.com/u/5319646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ScorpioCPH", "html_url": "https://github.com/ScorpioCPH", "followers_url": "https://api.github.com/users/ScorpioCPH/followers", "following_url": "https://api.github.com/users/ScorpioCPH/following{/other_user}", "gists_url": "https://api.github.com/users/ScorpioCPH/gists{/gist_id}", "starred_url": "https://api.github.com/users/ScorpioCPH/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ScorpioCPH/subscriptions", "organizations_url": "https://api.github.com/users/ScorpioCPH/orgs", "repos_url": "https://api.github.com/users/ScorpioCPH/repos", "events_url": "https://api.github.com/users/ScorpioCPH/events{/privacy}", "received_events_url": "https://api.github.com/users/ScorpioCPH/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-08-07T06:51:51Z", "updated_at": "2017-08-10T14:26:58Z", "closed_at": "2017-08-10T02:52:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I install TensorFlow from source with <code>XLA</code> and <code>TF_CPP_MIN_VLOG_LEVEL</code> enabled (without <code>GPU</code>), after trying <code>XLA</code> example, I got these logs:</p>\n<div class=\"highlight highlight-source-shell\"><pre>...\nXLA op registration: device: XLA_CPU_JIT op: AssignAddVariableOp\nXLA op registration: device: XLA_GPU_JIT op: AssignAddVariableOp\nXLA op registration: device: XLA_CPU_JIT op: _UnsafeReadVariable\nXLA op registration: device: XLA_GPU_JIT op: _UnsafeReadVariable\nXLA op registration: device: XLA_CPU_JIT op: Unpack\nXLA op registration: device: XLA_GPU_JIT op: Unpack\n...</pre></div>\n<p>But there is no <code>GPU</code> installed on my machine, so I don't enable <code>CUDA</code> option, but it still do</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"pl-en\">REGISTER_XLA_BACKEND</span>(DEVICE_GPU_XLA_JIT, <span class=\"pl-c1\">kGpuAllTypes</span>, GpuOpFilter);</pre></div>\n<p>Should we disable <code>REGISTER_XLA_BACKEND(GPU)</code> if there is no <code>GPU</code> installed on the machine?</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5453737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tatatodd\">@tatatodd</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=348932\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hawkinsp\">@hawkinsp</a> WDYT?</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nNo.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nSource</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nv1.2.1</li>\n<li><strong>Python version</strong>:<br>\n2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.4.5</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nN/A</li>\n<li><strong>GPU model and memory</strong>:<br>\nN/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>", "body_text": "I install TensorFlow from source with XLA and TF_CPP_MIN_VLOG_LEVEL enabled (without GPU), after trying XLA example, I got these logs:\n...\nXLA op registration: device: XLA_CPU_JIT op: AssignAddVariableOp\nXLA op registration: device: XLA_GPU_JIT op: AssignAddVariableOp\nXLA op registration: device: XLA_CPU_JIT op: _UnsafeReadVariable\nXLA op registration: device: XLA_GPU_JIT op: _UnsafeReadVariable\nXLA op registration: device: XLA_CPU_JIT op: Unpack\nXLA op registration: device: XLA_GPU_JIT op: Unpack\n...\nBut there is no GPU installed on my machine, so I don't enable CUDA option, but it still do\nREGISTER_XLA_BACKEND(DEVICE_GPU_XLA_JIT, kGpuAllTypes, GpuOpFilter);\nShould we disable REGISTER_XLA_BACKEND(GPU) if there is no GPU installed on the machine?\n@tatatodd @hawkinsp WDYT?\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nNo.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\nTensorFlow installed from (source or binary):\nSource\nTensorFlow version (use command below):\nv1.2.1\nPython version:\n2.7\nBazel version (if compiling from source):\n0.4.5\nCUDA/cuDNN version:\nN/A\nGPU model and memory:\nN/A\nExact command to reproduce:", "body": "I install TensorFlow from source with `XLA` and `TF_CPP_MIN_VLOG_LEVEL` enabled (without `GPU`), after trying `XLA` example, I got these logs:\r\n\r\n```shell\r\n...\r\nXLA op registration: device: XLA_CPU_JIT op: AssignAddVariableOp\r\nXLA op registration: device: XLA_GPU_JIT op: AssignAddVariableOp\r\nXLA op registration: device: XLA_CPU_JIT op: _UnsafeReadVariable\r\nXLA op registration: device: XLA_GPU_JIT op: _UnsafeReadVariable\r\nXLA op registration: device: XLA_CPU_JIT op: Unpack\r\nXLA op registration: device: XLA_GPU_JIT op: Unpack\r\n...\r\n```\r\n\r\nBut there is no `GPU` installed on my machine, so I don't enable `CUDA` option, but it still do\r\n\r\n```cpp\r\nREGISTER_XLA_BACKEND(DEVICE_GPU_XLA_JIT, kGpuAllTypes, GpuOpFilter);\r\n```\r\n\r\nShould we disable `REGISTER_XLA_BACKEND(GPU)` if there is no `GPU` installed on the machine?\r\n\r\n@tatatodd @hawkinsp WDYT?\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n  No.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n  Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\n  Source\r\n- **TensorFlow version (use command below)**:\r\n  v1.2.1\r\n- **Python version**: \r\n  2.7\r\n- **Bazel version (if compiling from source)**:\r\n  0.4.5\r\n- **CUDA/cuDNN version**:\r\n  N/A\r\n- **GPU model and memory**:\r\n  N/A\r\n- **Exact command to reproduce**:"}