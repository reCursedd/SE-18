{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/352068367", "html_url": "https://github.com/tensorflow/tensorflow/issues/15320#issuecomment-352068367", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15320", "id": 352068367, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MjA2ODM2Nw==", "user": {"login": "BogdanRuzh", "id": 20704139, "node_id": "MDQ6VXNlcjIwNzA0MTM5", "avatar_url": "https://avatars3.githubusercontent.com/u/20704139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BogdanRuzh", "html_url": "https://github.com/BogdanRuzh", "followers_url": "https://api.github.com/users/BogdanRuzh/followers", "following_url": "https://api.github.com/users/BogdanRuzh/following{/other_user}", "gists_url": "https://api.github.com/users/BogdanRuzh/gists{/gist_id}", "starred_url": "https://api.github.com/users/BogdanRuzh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BogdanRuzh/subscriptions", "organizations_url": "https://api.github.com/users/BogdanRuzh/orgs", "repos_url": "https://api.github.com/users/BogdanRuzh/repos", "events_url": "https://api.github.com/users/BogdanRuzh/events{/privacy}", "received_events_url": "https://api.github.com/users/BogdanRuzh/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-15T17:46:51Z", "updated_at": "2017-12-15T17:46:51Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25373098\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vivek-rane\">@vivek-rane</a><br>\nSorry for late response. I did a bunch of tests and have good results with improving performance for MKL tf in comparison with pip tf - it's 3x faster for my segmentation model and 2x faster for inception v3.<br>\nAlso, I'm curious about how it tf parallelize inception blocks. Check timelines below. So inception blocks can be processed much faster than straightforward cnn?</p>\n<p>Segmentation model, very straightforward, no parallelization showed:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/20704139/34053133-38ee8456-e1ce-11e7-835d-d23f616e3ce2.png\"><img src=\"https://user-images.githubusercontent.com/20704139/34053133-38ee8456-e1ce-11e7-835d-d23f616e3ce2.png\" alt=\"image\" style=\"max-width:100%;\"></a><br>\nBest run with :</p>\n<blockquote>\n<p>OMP_NUM_THREADS=8<br>\nKMP_BLOCKTIME=0<br>\nKMP_AFFINITY=granularity=fine,verbose,compact,1,0<br>\nKMP_SETTINGS=1<br>\nintra_op_parallelism_threads=8<br>\ninter_op_parallelism_threads=3</p>\n</blockquote>\n<p>In comparison, Inception V3 have good parallelization because of Inception blocks:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/20704139/34053606-1cab1eb0-e1d0-11e7-95e1-c8bdaa203f35.png\"><img src=\"https://user-images.githubusercontent.com/20704139/34053606-1cab1eb0-e1d0-11e7-95e1-c8bdaa203f35.png\" alt=\"image\" style=\"max-width:100%;\"></a><br>\nBest run with :</p>\n<blockquote>\n<p>OMP_NUM_THREADS=12<br>\nKMP_BLOCKTIME=0<br>\nKMP_AFFINITY=granularity=fine,verbose,compact,1,0<br>\nKMP_SETTINGS=1<br>\nintra_op_parallelism_threads=12<br>\ninter_op_parallelism_threads=3</p>\n</blockquote>\n<p><strong>Tested on i7-6850K (6 cores, 3.60GHz)</strong></p>", "body_text": "@vivek-rane\nSorry for late response. I did a bunch of tests and have good results with improving performance for MKL tf in comparison with pip tf - it's 3x faster for my segmentation model and 2x faster for inception v3.\nAlso, I'm curious about how it tf parallelize inception blocks. Check timelines below. So inception blocks can be processed much faster than straightforward cnn?\nSegmentation model, very straightforward, no parallelization showed:\n\nBest run with :\n\nOMP_NUM_THREADS=8\nKMP_BLOCKTIME=0\nKMP_AFFINITY=granularity=fine,verbose,compact,1,0\nKMP_SETTINGS=1\nintra_op_parallelism_threads=8\ninter_op_parallelism_threads=3\n\nIn comparison, Inception V3 have good parallelization because of Inception blocks:\n\nBest run with :\n\nOMP_NUM_THREADS=12\nKMP_BLOCKTIME=0\nKMP_AFFINITY=granularity=fine,verbose,compact,1,0\nKMP_SETTINGS=1\nintra_op_parallelism_threads=12\ninter_op_parallelism_threads=3\n\nTested on i7-6850K (6 cores, 3.60GHz)", "body": "@vivek-rane \r\nSorry for late response. I did a bunch of tests and have good results with improving performance for MKL tf in comparison with pip tf - it's 3x faster for my segmentation model and 2x faster for inception v3. \r\nAlso, I'm curious about how it tf parallelize inception blocks. Check timelines below. So inception blocks can be processed much faster than straightforward cnn?\r\n\r\nSegmentation model, very straightforward, no parallelization showed:\r\n![image](https://user-images.githubusercontent.com/20704139/34053133-38ee8456-e1ce-11e7-835d-d23f616e3ce2.png)\r\nBest run with : \r\n> OMP_NUM_THREADS=8 \r\n> KMP_BLOCKTIME=0 \r\n> KMP_AFFINITY=granularity=fine,verbose,compact,1,0 \r\n> KMP_SETTINGS=1\r\n> intra_op_parallelism_threads=8\r\n> inter_op_parallelism_threads=3\r\n\r\nIn comparison, Inception V3 have good parallelization because of Inception blocks:\r\n![image](https://user-images.githubusercontent.com/20704139/34053606-1cab1eb0-e1d0-11e7-95e1-c8bdaa203f35.png)\r\nBest run with : \r\n> OMP_NUM_THREADS=12\r\n> KMP_BLOCKTIME=0 \r\n> KMP_AFFINITY=granularity=fine,verbose,compact,1,0 \r\n> KMP_SETTINGS=1\r\n> intra_op_parallelism_threads=12\r\n> inter_op_parallelism_threads=3\r\n\r\n**Tested on i7-6850K (6 cores, 3.60GHz)**"}