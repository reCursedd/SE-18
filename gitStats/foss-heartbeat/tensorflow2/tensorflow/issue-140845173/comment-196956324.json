{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/196956324", "html_url": "https://github.com/tensorflow/tensorflow/issues/1502#issuecomment-196956324", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1502", "id": 196956324, "node_id": "MDEyOklzc3VlQ29tbWVudDE5Njk1NjMyNA==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-15T18:14:28Z", "updated_at": "2016-03-15T18:21:27Z", "author_association": "MEMBER", "body_html": "<p>If you're seeing a significant regression from the non-fused kernel, I'd be interested in hearing about it. Note that there were two changes:</p>\n<ul>\n<li>removing the fused kernel, which did not affect performance on any benchmark I could run. In particular, this one:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/0249729a26b2cd3bdbbc5880f8d634a56860b0fd/tensorflow/python/ops/batch_norm_benchmark.py\">https://github.com/tensorflow/tensorflow/blob/0249729a26b2cd3bdbbc5880f8d634a56860b0fd/tensorflow/python/ops/batch_norm_benchmark.py</a></li>\n<li>replacing the two-pass moment accumulation algorithm with a one-pass algorithm. This was a tad slower on GPU, and faster on CPU.</li>\n</ul>\n<p>On balance, those two changes gave us a lot more flexibility:</p>\n<ul>\n<li>the one-pass moment accumulation removes a long-lived doubling of the memory footprint of the activations.</li>\n<li>it makes it possible to compute moments over long sequences more efficiently.</li>\n<li>the removal of the fused kernel generalized the computation to many more data shapes and layouts, and will enable for example batch-major and depth-major for convolutions.</li>\n</ul>\n<p>We could recreate a fused op that implements the more flexible shapes if it significantly improved performance. It's also possible that a fused kernel for the one-pass moment computation wold be much more efficient. We need to know which is causing regressions first if there are any.</p>", "body_text": "If you're seeing a significant regression from the non-fused kernel, I'd be interested in hearing about it. Note that there were two changes:\n\nremoving the fused kernel, which did not affect performance on any benchmark I could run. In particular, this one:\nhttps://github.com/tensorflow/tensorflow/blob/0249729a26b2cd3bdbbc5880f8d634a56860b0fd/tensorflow/python/ops/batch_norm_benchmark.py\nreplacing the two-pass moment accumulation algorithm with a one-pass algorithm. This was a tad slower on GPU, and faster on CPU.\n\nOn balance, those two changes gave us a lot more flexibility:\n\nthe one-pass moment accumulation removes a long-lived doubling of the memory footprint of the activations.\nit makes it possible to compute moments over long sequences more efficiently.\nthe removal of the fused kernel generalized the computation to many more data shapes and layouts, and will enable for example batch-major and depth-major for convolutions.\n\nWe could recreate a fused op that implements the more flexible shapes if it significantly improved performance. It's also possible that a fused kernel for the one-pass moment computation wold be much more efficient. We need to know which is causing regressions first if there are any.", "body": "If you're seeing a significant regression from the non-fused kernel, I'd be interested in hearing about it. Note that there were two changes:\n- removing the fused kernel, which did not affect performance on any benchmark I could run. In particular, this one:\n  https://github.com/tensorflow/tensorflow/blob/0249729a26b2cd3bdbbc5880f8d634a56860b0fd/tensorflow/python/ops/batch_norm_benchmark.py\n- replacing the two-pass moment accumulation algorithm with a one-pass algorithm. This was a tad slower on GPU, and faster on CPU.\n\nOn balance, those two changes gave us a lot more flexibility:\n- the one-pass moment accumulation removes a long-lived doubling of the memory footprint of the activations.\n- it makes it possible to compute moments over long sequences more efficiently.\n- the removal of the fused kernel generalized the computation to many more data shapes and layouts, and will enable for example batch-major and depth-major for convolutions.\n\nWe could recreate a fused op that implements the more flexible shapes if it significantly improved performance. It's also possible that a fused kernel for the one-pass moment computation wold be much more efficient. We need to know which is causing regressions first if there are any.\n"}