{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22407", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22407/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22407/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22407/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22407", "id": 362109093, "node_id": "MDU6SXNzdWUzNjIxMDkwOTM=", "number": 22407, "title": "Distributed training hangs up when I use CollectiveAllReduceStrategy (Python 2)", "user": {"login": "dmitrievanthony", "id": 1028969, "node_id": "MDQ6VXNlcjEwMjg5Njk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1028969?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dmitrievanthony", "html_url": "https://github.com/dmitrievanthony", "followers_url": "https://api.github.com/users/dmitrievanthony/followers", "following_url": "https://api.github.com/users/dmitrievanthony/following{/other_user}", "gists_url": "https://api.github.com/users/dmitrievanthony/gists{/gist_id}", "starred_url": "https://api.github.com/users/dmitrievanthony/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dmitrievanthony/subscriptions", "organizations_url": "https://api.github.com/users/dmitrievanthony/orgs", "repos_url": "https://api.github.com/users/dmitrievanthony/repos", "events_url": "https://api.github.com/users/dmitrievanthony/events{/privacy}", "received_events_url": "https://api.github.com/users/dmitrievanthony/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "yuefengz", "id": 1647833, "node_id": "MDQ6VXNlcjE2NDc4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1647833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuefengz", "html_url": "https://github.com/yuefengz", "followers_url": "https://api.github.com/users/yuefengz/followers", "following_url": "https://api.github.com/users/yuefengz/following{/other_user}", "gists_url": "https://api.github.com/users/yuefengz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuefengz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuefengz/subscriptions", "organizations_url": "https://api.github.com/users/yuefengz/orgs", "repos_url": "https://api.github.com/users/yuefengz/repos", "events_url": "https://api.github.com/users/yuefengz/events{/privacy}", "received_events_url": "https://api.github.com/users/yuefengz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "yuefengz", "id": 1647833, "node_id": "MDQ6VXNlcjE2NDc4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1647833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuefengz", "html_url": "https://github.com/yuefengz", "followers_url": "https://api.github.com/users/yuefengz/followers", "following_url": "https://api.github.com/users/yuefengz/following{/other_user}", "gists_url": "https://api.github.com/users/yuefengz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuefengz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuefengz/subscriptions", "organizations_url": "https://api.github.com/users/yuefengz/orgs", "repos_url": "https://api.github.com/users/yuefengz/repos", "events_url": "https://api.github.com/users/yuefengz/events{/privacy}", "received_events_url": "https://api.github.com/users/yuefengz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-09-20T09:55:36Z", "updated_at": "2018-09-23T17:07:28Z", "closed_at": "2018-09-23T16:10:44Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nI slightly updated keras_model_to_estimator_client.py example so that it doesn't require Kubernetes. Updated version is <a href=\"https://github.com/dmitrievanthony/ecosystem/blob/ignite-3/distribution_strategy/keras_model_to_estimator_client.py\">here</a>.</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nUbuntu 17.04</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\nBinary</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\n1.12.0-dev20180919</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\n2.7.13</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\nStart <a href=\"https://github.com/dmitrievanthony/ecosystem/blob/ignite-3/ignite/worker1.py\">worker1.py</a>.<br>\nStart <a href=\"https://github.com/dmitrievanthony/ecosystem/blob/ignite-3/ignite/worker2.py\">worker2.py</a>.<br>\nStart <a href=\"https://github.com/dmitrievanthony/ecosystem/blob/ignite-3/distribution_strategy/keras_model_to_estimator_client.py\">keras_model_to_estimator_client.py</a>.</p>\n</li>\n</ul>\n<p>As result I would expect distributed training started in standalone mode with the following cluster config: <code>{\"worker\": [\"localhost:1111\", \"localhost:1112\"], \"chief\": [\"localhost:1113\"]}</code>. After initialization I would expect to see the same output as in local (non-distributed) mode.</p>\n<h3>Describe the problem</h3>\n<p>Hi,</p>\n<p>It looks like the process hangs up on initialization step. See logs of processes below.</p>\n<h3>Source code / logs</h3>\n<p>Logs of <code>worker1.py</code>.</p>\n<pre><code>2018-09-20 12:23:37.784529: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-20 12:23:37.785450: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job chief -&gt; {0 -&gt; localhost:1113}\n2018-09-20 12:23:37.785469: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:1111, 1 -&gt; localhost:1112}\n2018-09-20 12:23:37.786408: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:381] Started server with target: grpc://localhost:1111\n2018-09-20 12:23:37.786477: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1111)\n2018-09-20 12:23:37.786586: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1111)\n2018-09-20 12:24:02.453219: I tensorflow/core/distributed_runtime/master_session.cc:1161] Start master session 10324091b7c40099 with config: device_filters: \"/job:worker/task:0\" device_filters: \"/job:worker/task:0\" allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE scoped_allocator_optimization: ON scoped_allocator_opts { enable_op: \"CollectiveReduce\" enable_op: \"CollectiveReduce\" } } } isolate_session_state: true experimental { collective_group_leader: \"/job:chief/replica:0/task:0\" }\n2018-09-20 12:24:02.471993: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:355] Starting optimization for grappler item: tf_graph\n</code></pre>\n<p>Logs of <code>worker2.py</code>.</p>\n<pre><code>2018-09-20 12:23:43.680413: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-20 12:23:43.681625: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job chief -&gt; {0 -&gt; localhost:1113}\n2018-09-20 12:23:43.681664: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:1111, 1 -&gt; localhost:1112}\n2018-09-20 12:23:43.682404: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:381] Started server with target: grpc://localhost:1112\n2018-09-20 12:23:43.682480: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1112)\n2018-09-20 12:23:43.682577: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1112)\n2018-09-20 12:24:02.426685: I tensorflow/core/distributed_runtime/master_session.cc:1161] Start master session 438db1d6d8b24351 with config: device_filters: \"/job:worker/task:1\" device_filters: \"/job:worker/task:1\" allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE scoped_allocator_optimization: ON scoped_allocator_opts { enable_op: \"CollectiveReduce\" enable_op: \"CollectiveReduce\" } } } isolate_session_state: true experimental { collective_group_leader: \"/job:chief/replica:0/task:0\" }\n2018-09-20 12:24:02.441035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:355] Starting optimization for grappler item: tf_graph\n</code></pre>\n<p>Logs of <code>keras_model_to_estimator_client.py</code>.</p>\n<pre><code>Using /tmp/asdasdasd to store checkpoints.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 16)                176       \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 193\nTrainable params: 193\nNon-trainable params: 0\n_________________________________________________________________\nINFO:tensorflow:CollectiveAllReduceStrategy with local_devices = ['/device:CPU:0']\n2018-09-20 12:30:36.241065: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:RunConfig initialized for Distribute Coordinator with STANDALONE_CLIENT mode\nINFO:tensorflow:Using the Keras model provided.\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f971668a110&gt;, '_model_dir': '/tmp/asdasdasd', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': DistributeConfig(train_distribute=&lt;tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f97166f2ed0&gt;, eval_distribute=&lt;tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f971668a190&gt;, remote_cluster=&lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f971668a110&gt;), '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': &lt;tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f971668a190&gt;, '_train_distribute': &lt;tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f97166f2ed0&gt;, '_master': '', '_distribute_coordinator_mode': 'standalone_client'}\nINFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\nINFO:tensorflow:Running Distribute Coordinator with mode = 'standalone_client', cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = None, task_id = None, environment = None, rpc_layer = 'grpc'\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ['/job:chief/task:0']\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'worker', task_id = 0, num_workers = 3, local_devices = ['/job:worker/task:0']\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'worker', task_id = 1, num_workers = 3, local_devices = ['/job:worker/task:1']\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:0\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\n}\n\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:1\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\n}\n\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:chief/task:0\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\n}\n\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Graph was finalized.\n</code></pre>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nI slightly updated keras_model_to_estimator_client.py example so that it doesn't require Kubernetes. Updated version is here.\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nUbuntu 17.04\n\n\nTensorFlow installed from (source or binary):\nBinary\n\n\nTensorFlow version (use command below):\n1.12.0-dev20180919\n\n\nPython version:\n2.7.13\n\n\nExact command to reproduce:\nStart worker1.py.\nStart worker2.py.\nStart keras_model_to_estimator_client.py.\n\n\nAs result I would expect distributed training started in standalone mode with the following cluster config: {\"worker\": [\"localhost:1111\", \"localhost:1112\"], \"chief\": [\"localhost:1113\"]}. After initialization I would expect to see the same output as in local (non-distributed) mode.\nDescribe the problem\nHi,\nIt looks like the process hangs up on initialization step. See logs of processes below.\nSource code / logs\nLogs of worker1.py.\n2018-09-20 12:23:37.784529: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-20 12:23:37.785450: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job chief -> {0 -> localhost:1113}\n2018-09-20 12:23:37.785469: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job worker -> {0 -> localhost:1111, 1 -> localhost:1112}\n2018-09-20 12:23:37.786408: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:381] Started server with target: grpc://localhost:1111\n2018-09-20 12:23:37.786477: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1111)\n2018-09-20 12:23:37.786586: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1111)\n2018-09-20 12:24:02.453219: I tensorflow/core/distributed_runtime/master_session.cc:1161] Start master session 10324091b7c40099 with config: device_filters: \"/job:worker/task:0\" device_filters: \"/job:worker/task:0\" allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE scoped_allocator_optimization: ON scoped_allocator_opts { enable_op: \"CollectiveReduce\" enable_op: \"CollectiveReduce\" } } } isolate_session_state: true experimental { collective_group_leader: \"/job:chief/replica:0/task:0\" }\n2018-09-20 12:24:02.471993: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:355] Starting optimization for grappler item: tf_graph\n\nLogs of worker2.py.\n2018-09-20 12:23:43.680413: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-20 12:23:43.681625: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job chief -> {0 -> localhost:1113}\n2018-09-20 12:23:43.681664: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job worker -> {0 -> localhost:1111, 1 -> localhost:1112}\n2018-09-20 12:23:43.682404: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:381] Started server with target: grpc://localhost:1112\n2018-09-20 12:23:43.682480: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1112)\n2018-09-20 12:23:43.682577: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1112)\n2018-09-20 12:24:02.426685: I tensorflow/core/distributed_runtime/master_session.cc:1161] Start master session 438db1d6d8b24351 with config: device_filters: \"/job:worker/task:1\" device_filters: \"/job:worker/task:1\" allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE scoped_allocator_optimization: ON scoped_allocator_opts { enable_op: \"CollectiveReduce\" enable_op: \"CollectiveReduce\" } } } isolate_session_state: true experimental { collective_group_leader: \"/job:chief/replica:0/task:0\" }\n2018-09-20 12:24:02.441035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:355] Starting optimization for grappler item: tf_graph\n\nLogs of keras_model_to_estimator_client.py.\nUsing /tmp/asdasdasd to store checkpoints.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 16)                176       \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 193\nTrainable params: 193\nNon-trainable params: 0\n_________________________________________________________________\nINFO:tensorflow:CollectiveAllReduceStrategy with local_devices = ['/device:CPU:0']\n2018-09-20 12:30:36.241065: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:RunConfig initialized for Distribute Coordinator with STANDALONE_CLIENT mode\nINFO:tensorflow:Using the Keras model provided.\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f971668a110>, '_model_dir': '/tmp/asdasdasd', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f97166f2ed0>, eval_distribute=<tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f971668a190>, remote_cluster=<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f971668a110>), '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f971668a190>, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f97166f2ed0>, '_master': '', '_distribute_coordinator_mode': 'standalone_client'}\nINFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\nINFO:tensorflow:Running Distribute Coordinator with mode = 'standalone_client', cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = None, task_id = None, environment = None, rpc_layer = 'grpc'\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ['/job:chief/task:0']\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'worker', task_id = 0, num_workers = 3, local_devices = ['/job:worker/task:0']\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'worker', task_id = 1, num_workers = 3, local_devices = ['/job:worker/task:1']\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:0\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\n}\n\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:1\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\n}\n\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:chief/task:0\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\n}\n\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Graph was finalized.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nI slightly updated keras_model_to_estimator_client.py example so that it doesn't require Kubernetes. Updated version is [here](https://github.com/dmitrievanthony/ecosystem/blob/ignite-3/distribution_strategy/keras_model_to_estimator_client.py).\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 17.04\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.12.0-dev20180919\r\n\r\n- **Python version**:\r\n2.7.13\r\n\r\n- **Exact command to reproduce**:\r\nStart [worker1.py](https://github.com/dmitrievanthony/ecosystem/blob/ignite-3/ignite/worker1.py).\r\nStart [worker2.py](https://github.com/dmitrievanthony/ecosystem/blob/ignite-3/ignite/worker2.py).\r\nStart [keras_model_to_estimator_client.py](https://github.com/dmitrievanthony/ecosystem/blob/ignite-3/distribution_strategy/keras_model_to_estimator_client.py).\r\n\r\nAs result I would expect distributed training started in standalone mode with the following cluster config: `{\"worker\": [\"localhost:1111\", \"localhost:1112\"], \"chief\": [\"localhost:1113\"]}`. After initialization I would expect to see the same output as in local (non-distributed) mode.\r\n\r\n### Describe the problem\r\n\r\nHi, \r\n\r\nIt looks like the process hangs up on initialization step. See logs of processes below.\r\n\r\n### Source code / logs\r\n\r\nLogs of `worker1.py`.\r\n```\r\n2018-09-20 12:23:37.784529: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-20 12:23:37.785450: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job chief -> {0 -> localhost:1113}\r\n2018-09-20 12:23:37.785469: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job worker -> {0 -> localhost:1111, 1 -> localhost:1112}\r\n2018-09-20 12:23:37.786408: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:381] Started server with target: grpc://localhost:1111\r\n2018-09-20 12:23:37.786477: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1111)\r\n2018-09-20 12:23:37.786586: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1111)\r\n2018-09-20 12:24:02.453219: I tensorflow/core/distributed_runtime/master_session.cc:1161] Start master session 10324091b7c40099 with config: device_filters: \"/job:worker/task:0\" device_filters: \"/job:worker/task:0\" allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE scoped_allocator_optimization: ON scoped_allocator_opts { enable_op: \"CollectiveReduce\" enable_op: \"CollectiveReduce\" } } } isolate_session_state: true experimental { collective_group_leader: \"/job:chief/replica:0/task:0\" }\r\n2018-09-20 12:24:02.471993: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:355] Starting optimization for grappler item: tf_graph\r\n```\r\n\r\nLogs of `worker2.py`.\r\n```\r\n2018-09-20 12:23:43.680413: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-20 12:23:43.681625: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job chief -> {0 -> localhost:1113}\r\n2018-09-20 12:23:43.681664: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:222] Initialize GrpcChannelCache for job worker -> {0 -> localhost:1111, 1 -> localhost:1112}\r\n2018-09-20 12:23:43.682404: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:381] Started server with target: grpc://localhost:1112\r\n2018-09-20 12:23:43.682480: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1112)\r\n2018-09-20 12:23:43.682577: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:385] Server already started (target: grpc://localhost:1112)\r\n2018-09-20 12:24:02.426685: I tensorflow/core/distributed_runtime/master_session.cc:1161] Start master session 438db1d6d8b24351 with config: device_filters: \"/job:worker/task:1\" device_filters: \"/job:worker/task:1\" allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE scoped_allocator_optimization: ON scoped_allocator_opts { enable_op: \"CollectiveReduce\" enable_op: \"CollectiveReduce\" } } } isolate_session_state: true experimental { collective_group_leader: \"/job:chief/replica:0/task:0\" }\r\n2018-09-20 12:24:02.441035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:355] Starting optimization for grappler item: tf_graph\r\n```\r\n\r\nLogs of `keras_model_to_estimator_client.py`.\r\n```\r\nUsing /tmp/asdasdasd to store checkpoints.\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense (Dense)                (None, 16)                176       \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 1)                 17        \r\n=================================================================\r\nTotal params: 193\r\nTrainable params: 193\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nINFO:tensorflow:CollectiveAllReduceStrategy with local_devices = ['/device:CPU:0']\r\n2018-09-20 12:30:36.241065: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\r\nINFO:tensorflow:RunConfig initialized for Distribute Coordinator with STANDALONE_CLIENT mode\r\nINFO:tensorflow:Using the Keras model provided.\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f971668a110>, '_model_dir': '/tmp/asdasdasd', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f97166f2ed0>, eval_distribute=<tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f971668a190>, remote_cluster=<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f971668a110>), '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f971668a190>, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f97166f2ed0>, '_master': '', '_distribute_coordinator_mode': 'standalone_client'}\r\nINFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\r\nINFO:tensorflow:Running Distribute Coordinator with mode = 'standalone_client', cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = None, task_id = None, environment = None, rpc_layer = 'grpc'\r\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ['/job:chief/task:0']\r\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'worker', task_id = 0, num_workers = 3, local_devices = ['/job:worker/task:0']\r\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['localhost:1113'], 'worker': ['localhost:1111', 'localhost:1112']}, task_type = 'worker', task_id = 1, num_workers = 3, local_devices = ['/job:worker/task:1']\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\r\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\r\nINFO:tensorflow:Collective All-reduce invoked with batches size = 4, num_workers = 3\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\r\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:0\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n    scoped_allocator_optimization: ON\r\n    scoped_allocator_opts {\r\n      enable_op: \"CollectiveReduce\"\r\n    }\r\n  }\r\n}\r\nisolate_session_state: true\r\nexperimental {\r\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\r\n}\r\n\r\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\r\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u'/tmp/asdasdasd/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:tensorflow:Warm-starting from: (u'/tmp/asdasdasd/keras/keras_model.ckpt',)\r\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:1\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n    scoped_allocator_optimization: ON\r\n    scoped_allocator_opts {\r\n      enable_op: \"CollectiveReduce\"\r\n    }\r\n  }\r\n}\r\nisolate_session_state: true\r\nexperimental {\r\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\r\n}\r\n\r\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:chief/task:0\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n    scoped_allocator_optimization: ON\r\n    scoped_allocator_opts {\r\n      enable_op: \"CollectiveReduce\"\r\n    }\r\n  }\r\n}\r\nisolate_session_state: true\r\nexperimental {\r\n  collective_group_leader: \"/job:chief/replica:0/task:0\"\r\n}\r\n\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Graph was finalized.\r\n```"}