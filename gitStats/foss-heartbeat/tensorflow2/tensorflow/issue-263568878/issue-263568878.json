{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13536", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13536/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13536/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13536/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13536", "id": 263568878, "node_id": "MDU6SXNzdWUyNjM1Njg4Nzg=", "number": 13536, "title": "BeamSearchDecoder incorrectly truncates results when used with dynamic_decode", "user": {"login": "bdaskalov", "id": 2833552, "node_id": "MDQ6VXNlcjI4MzM1NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2833552?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bdaskalov", "html_url": "https://github.com/bdaskalov", "followers_url": "https://api.github.com/users/bdaskalov/followers", "following_url": "https://api.github.com/users/bdaskalov/following{/other_user}", "gists_url": "https://api.github.com/users/bdaskalov/gists{/gist_id}", "starred_url": "https://api.github.com/users/bdaskalov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bdaskalov/subscriptions", "organizations_url": "https://api.github.com/users/bdaskalov/orgs", "repos_url": "https://api.github.com/users/bdaskalov/repos", "events_url": "https://api.github.com/users/bdaskalov/events{/privacy}", "received_events_url": "https://api.github.com/users/bdaskalov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-10-06T20:53:52Z", "updated_at": "2018-04-30T17:16:08Z", "closed_at": "2017-10-18T05:45:06Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information (irrelevant for this bug)</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04/Any</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.3.0-rc2-20-g0787eee 1.3.0</li>\n<li><strong>Python version</strong>: Python 3.5.2 :: Continuum Analytics, Inc.</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: irrelevant</li>\n<li><strong>GPU model and memory</strong>: irrelevant</li>\n<li><strong>Exact command to reproduce</strong>: irrelevant</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>tf.contrib.seq2seq.BeamSearchDecoder incorrectly truncates some of the results because the same index was previously used for a beam member that ended at a earlier step.</p>\n<p>The root of the problem is that the while_loop body in dynamic_decode assumes that sequences are independent and will finish only once. In the same time BeamSearchDecoder creates a tree-like structure where a beam index can be reused in a later step for a state that originates from a different parent index.  This causes the decoding loop to sometimes record the wrong sequence length for a beam member. Then this wrong sequence length is passed to BeamSearchDecoder.finalize which returns a truncated sequence.</p>\n<h3>Source code / logs</h3>\n<p>I use the following code to workaround the problem. This causes the right sequence to be returned but still the length returned by dynamic_decode is wrong.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">FixedBeamSearchDecoder</span>(<span class=\"pl-e\">seq2seq</span>.<span class=\"pl-e\">BeamSearchDecoder</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">finalize</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">outputs</span>, <span class=\"pl-smi\">final_state</span>, <span class=\"pl-smi\">sequence_lengths</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> BeamSearchDecoder does not follow the correct semantics of the the finished flag</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> which results in taking wrong length here and getting wrong decoded string.</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> We substitute the sequence length recorded by dynamic_decoder (which is wrong because</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> of the wrong finished flag returned by BeamSearchDecoder.step) with the length</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> recorded in BeamSearchState which is correct.</span>\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">super</span>().finalize(outputs, final_state, final_state.lengths)</pre></div>", "body_text": "System information (irrelevant for this bug)\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04/Any\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0\nPython version: Python 3.5.2 :: Continuum Analytics, Inc.\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: irrelevant\nGPU model and memory: irrelevant\nExact command to reproduce: irrelevant\n\nDescribe the problem\ntf.contrib.seq2seq.BeamSearchDecoder incorrectly truncates some of the results because the same index was previously used for a beam member that ended at a earlier step.\nThe root of the problem is that the while_loop body in dynamic_decode assumes that sequences are independent and will finish only once. In the same time BeamSearchDecoder creates a tree-like structure where a beam index can be reused in a later step for a state that originates from a different parent index.  This causes the decoding loop to sometimes record the wrong sequence length for a beam member. Then this wrong sequence length is passed to BeamSearchDecoder.finalize which returns a truncated sequence.\nSource code / logs\nI use the following code to workaround the problem. This causes the right sequence to be returned but still the length returned by dynamic_decode is wrong.\nclass FixedBeamSearchDecoder(seq2seq.BeamSearchDecoder):\n    def finalize(self, outputs, final_state, sequence_lengths):\n        # BeamSearchDecoder does not follow the correct semantics of the the finished flag\n        # which results in taking wrong length here and getting wrong decoded string.\n        # We substitute the sequence length recorded by dynamic_decoder (which is wrong because\n        # of the wrong finished flag returned by BeamSearchDecoder.step) with the length\n        # recorded in BeamSearchState which is correct.\n        return super().finalize(outputs, final_state, final_state.lengths)", "body": "### System information (irrelevant for this bug)\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04/Any\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: Python 3.5.2 :: Continuum Analytics, Inc.\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: irrelevant\r\n- **GPU model and memory**: irrelevant\r\n- **Exact command to reproduce**: irrelevant\r\n\r\n### Describe the problem\r\ntf.contrib.seq2seq.BeamSearchDecoder incorrectly truncates some of the results because the same index was previously used for a beam member that ended at a earlier step.\r\n\r\nThe root of the problem is that the while_loop body in dynamic_decode assumes that sequences are independent and will finish only once. In the same time BeamSearchDecoder creates a tree-like structure where a beam index can be reused in a later step for a state that originates from a different parent index.  This causes the decoding loop to sometimes record the wrong sequence length for a beam member. Then this wrong sequence length is passed to BeamSearchDecoder.finalize which returns a truncated sequence.\r\n\r\n\r\n### Source code / logs\r\nI use the following code to workaround the problem. This causes the right sequence to be returned but still the length returned by dynamic_decode is wrong.\r\n```python\r\nclass FixedBeamSearchDecoder(seq2seq.BeamSearchDecoder):\r\n    def finalize(self, outputs, final_state, sequence_lengths):\r\n        # BeamSearchDecoder does not follow the correct semantics of the the finished flag\r\n        # which results in taking wrong length here and getting wrong decoded string.\r\n        # We substitute the sequence length recorded by dynamic_decoder (which is wrong because\r\n        # of the wrong finished flag returned by BeamSearchDecoder.step) with the length\r\n        # recorded in BeamSearchState which is correct.\r\n        return super().finalize(outputs, final_state, final_state.lengths)\r\n``` \r\n"}