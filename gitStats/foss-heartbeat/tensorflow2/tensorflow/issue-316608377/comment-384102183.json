{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/384102183", "html_url": "https://github.com/tensorflow/tensorflow/issues/18781#issuecomment-384102183", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18781", "id": 384102183, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NDEwMjE4Mw==", "user": {"login": "facaiy", "id": 1112263, "node_id": "MDQ6VXNlcjExMTIyNjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1112263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/facaiy", "html_url": "https://github.com/facaiy", "followers_url": "https://api.github.com/users/facaiy/followers", "following_url": "https://api.github.com/users/facaiy/following{/other_user}", "gists_url": "https://api.github.com/users/facaiy/gists{/gist_id}", "starred_url": "https://api.github.com/users/facaiy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/facaiy/subscriptions", "organizations_url": "https://api.github.com/users/facaiy/orgs", "repos_url": "https://api.github.com/users/facaiy/repos", "events_url": "https://api.github.com/users/facaiy/events{/privacy}", "received_events_url": "https://api.github.com/users/facaiy/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-24T22:39:20Z", "updated_at": "2018-04-24T23:09:34Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9438971\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/sleighsoft\">@sleighsoft</a> Thank you for feedback. Actually <code>auxiliary_name_scope</code> is introduced in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"272425781\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/14390\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/14390/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/14390\">#14390</a> to resolve the name scope conflict of <code>tf.layers</code> when reentering variable scope, I modify your codes to make it work:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n  <span class=\"pl-c1\">NSO</span> <span class=\"pl-k\">=</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>ns_outer<span class=\"pl-pds\">'</span></span>).<span class=\"pl-c1\">__enter__</span>()\n\n  <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>vs_outer<span class=\"pl-pds\">'</span></span>,\n                         <span class=\"pl-v\">auxiliary_name_scope</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                         <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>tf.<span class=\"pl-c1\">AUTO_REUSE</span>) <span class=\"pl-k\">as</span> <span class=\"pl-c1\">VSO</span>:\n    <span class=\"pl-k\">pass</span>\n\n  <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-c1\">NSO</span>):\n    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>ns_inner_1<span class=\"pl-pds\">'</span></span>):\n      <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-c1\">VSO</span>, <span class=\"pl-v\">auxiliary_name_scope</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n        <span class=\"pl-c1\">print</span>((tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>var<span class=\"pl-pds\">'</span></span>, [<span class=\"pl-c1\">1</span>]), tf.constant(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>const<span class=\"pl-pds\">'</span></span>)))\n\n  <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-c1\">NSO</span>):\n    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>ns_inner_2<span class=\"pl-pds\">'</span></span>):\n      <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-c1\">VSO</span>, <span class=\"pl-v\">auxiliary_name_scope</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n        <span class=\"pl-c1\">print</span>((tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>var<span class=\"pl-pds\">'</span></span>, [<span class=\"pl-c1\">1</span>]), tf.constant(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>const<span class=\"pl-pds\">'</span></span>)))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> (&lt;tf.Variable 'vs_outer/var:0' shape=(1,) dtype=float32_ref&gt;, &lt;tf.Tensor 'ns_outer/ns_inner_1/const:0' shape=() dtype=float32&gt;)</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> (&lt;tf.Variable 'vs_outer/var:0' shape=(1,) dtype=float32_ref&gt;, &lt;tf.Tensor 'ns_outer/ns_inner_2/const:0' shape=() dtype=float32&gt;)</span>\n</pre></div>\n<p>Perhaps we'd better to document that it is only designed for reentering case, or give an example about how to use it correctly? cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=684901\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lukaszkaiser\">@lukaszkaiser</a></p>", "body_text": "@sleighsoft Thank you for feedback. Actually auxiliary_name_scope is introduced in #14390 to resolve the name scope conflict of tf.layers when reentering variable scope, I modify your codes to make it work:\nimport tensorflow as tf\n\nwith tf.Graph().as_default():\n  NSO = tf.name_scope('ns_outer').__enter__()\n\n  with tf.variable_scope('vs_outer',\n                         auxiliary_name_scope=False,\n                         reuse=tf.AUTO_REUSE) as VSO:\n    pass\n\n  with tf.name_scope(NSO):\n    with tf.name_scope('ns_inner_1'):\n      with tf.variable_scope(VSO, auxiliary_name_scope=False):\n        print((tf.get_variable('var', [1]), tf.constant(1.0, name='const')))\n\n  with tf.name_scope(NSO):\n    with tf.name_scope('ns_inner_2'):\n      with tf.variable_scope(VSO, auxiliary_name_scope=False):\n        print((tf.get_variable('var', [1]), tf.constant(1.0, name='const')))\n\n# (<tf.Variable 'vs_outer/var:0' shape=(1,) dtype=float32_ref>, <tf.Tensor 'ns_outer/ns_inner_1/const:0' shape=() dtype=float32>)\n# (<tf.Variable 'vs_outer/var:0' shape=(1,) dtype=float32_ref>, <tf.Tensor 'ns_outer/ns_inner_2/const:0' shape=() dtype=float32>)\n\nPerhaps we'd better to document that it is only designed for reentering case, or give an example about how to use it correctly? cc @lukaszkaiser", "body": "@sleighsoft Thank you for feedback. Actually `auxiliary_name_scope` is introduced in #14390 to resolve the name scope conflict of `tf.layers` when reentering variable scope, I modify your codes to make it work:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nwith tf.Graph().as_default():\r\n  NSO = tf.name_scope('ns_outer').__enter__()\r\n\r\n  with tf.variable_scope('vs_outer',\r\n                         auxiliary_name_scope=False,\r\n                         reuse=tf.AUTO_REUSE) as VSO:\r\n    pass\r\n\r\n  with tf.name_scope(NSO):\r\n    with tf.name_scope('ns_inner_1'):\r\n      with tf.variable_scope(VSO, auxiliary_name_scope=False):\r\n        print((tf.get_variable('var', [1]), tf.constant(1.0, name='const')))\r\n\r\n  with tf.name_scope(NSO):\r\n    with tf.name_scope('ns_inner_2'):\r\n      with tf.variable_scope(VSO, auxiliary_name_scope=False):\r\n        print((tf.get_variable('var', [1]), tf.constant(1.0, name='const')))\r\n\r\n# (<tf.Variable 'vs_outer/var:0' shape=(1,) dtype=float32_ref>, <tf.Tensor 'ns_outer/ns_inner_1/const:0' shape=() dtype=float32>)\r\n# (<tf.Variable 'vs_outer/var:0' shape=(1,) dtype=float32_ref>, <tf.Tensor 'ns_outer/ns_inner_2/const:0' shape=() dtype=float32>)\r\n\r\n```\r\n\r\nPerhaps we'd better to document that it is only designed for reentering case, or give an example about how to use it correctly? cc @lukaszkaiser "}