{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11495", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11495/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11495/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11495/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11495", "id": 242918032, "node_id": "MDU6SXNzdWUyNDI5MTgwMzI=", "number": 11495, "title": "MultiGPU multi-session ", "user": {"login": "surajkamal", "id": 6723464, "node_id": "MDQ6VXNlcjY3MjM0NjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/6723464?v=4", "gravatar_id": "", "url": "https://api.github.com/users/surajkamal", "html_url": "https://github.com/surajkamal", "followers_url": "https://api.github.com/users/surajkamal/followers", "following_url": "https://api.github.com/users/surajkamal/following{/other_user}", "gists_url": "https://api.github.com/users/surajkamal/gists{/gist_id}", "starred_url": "https://api.github.com/users/surajkamal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/surajkamal/subscriptions", "organizations_url": "https://api.github.com/users/surajkamal/orgs", "repos_url": "https://api.github.com/users/surajkamal/repos", "events_url": "https://api.github.com/users/surajkamal/events{/privacy}", "received_events_url": "https://api.github.com/users/surajkamal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-07-14T07:22:07Z", "updated_at": "2017-07-17T15:41:41Z", "closed_at": "2017-07-17T15:41:41Z", "author_association": "NONE", "body_html": "<p>It would be nice if there is an official way to do limit devices initialised by tensorflow other than the os level environment variable settings specifically as in<a href=\"https://stackoverflow.com/a/34776814\" rel=\"nofollow\"> this</a> answer posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> in stackoverflow. As of my understanding the setup mentioned in <a href=\"https://stackoverflow.com/a/34200194\" rel=\"nofollow\">another</a> answer by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> will not prevent tensorflow from grabbing all the GPU resources available on a same workstation at initialization as it is in by <code>tf.train.Server()</code>.  It would be essentially helpful for those sharing a machine among multiple users, so that they could independently initiate tensorflow graphs in different GPU units. Although this could be achieved via <code>nvidia-docker </code>or other resource orchestration tools, a native API would be a great addition to tensorflow.  Please ignore this if there is already an official way or my understanding is wrong.</p>", "body_text": "It would be nice if there is an official way to do limit devices initialised by tensorflow other than the os level environment variable settings specifically as in this answer posted by @mrry in stackoverflow. As of my understanding the setup mentioned in another answer by @mrry will not prevent tensorflow from grabbing all the GPU resources available on a same workstation at initialization as it is in by tf.train.Server().  It would be essentially helpful for those sharing a machine among multiple users, so that they could independently initiate tensorflow graphs in different GPU units. Although this could be achieved via nvidia-docker or other resource orchestration tools, a native API would be a great addition to tensorflow.  Please ignore this if there is already an official way or my understanding is wrong.", "body": "It would be nice if there is an official way to do limit devices initialised by tensorflow other than the os level environment variable settings specifically as in[ this](https://stackoverflow.com/a/34776814) answer posted by @mrry in stackoverflow. As of my understanding the setup mentioned in [another](https://stackoverflow.com/a/34200194) answer by @mrry will not prevent tensorflow from grabbing all the GPU resources available on a same workstation at initialization as it is in by `tf.train.Server()`.  It would be essentially helpful for those sharing a machine among multiple users, so that they could independently initiate tensorflow graphs in different GPU units. Although this could be achieved via `nvidia-docker `or other resource orchestration tools, a native API would be a great addition to tensorflow.  Please ignore this if there is already an official way or my understanding is wrong.  "}