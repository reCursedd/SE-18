{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/315324375", "html_url": "https://github.com/tensorflow/tensorflow/issues/11495#issuecomment-315324375", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11495", "id": 315324375, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTMyNDM3NQ==", "user": {"login": "surajkamal", "id": 6723464, "node_id": "MDQ6VXNlcjY3MjM0NjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/6723464?v=4", "gravatar_id": "", "url": "https://api.github.com/users/surajkamal", "html_url": "https://github.com/surajkamal", "followers_url": "https://api.github.com/users/surajkamal/followers", "following_url": "https://api.github.com/users/surajkamal/following{/other_user}", "gists_url": "https://api.github.com/users/surajkamal/gists{/gist_id}", "starred_url": "https://api.github.com/users/surajkamal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/surajkamal/subscriptions", "organizations_url": "https://api.github.com/users/surajkamal/orgs", "repos_url": "https://api.github.com/users/surajkamal/repos", "events_url": "https://api.github.com/users/surajkamal/events{/privacy}", "received_events_url": "https://api.github.com/users/surajkamal/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-14T10:12:28Z", "updated_at": "2017-07-14T10:12:28Z", "author_association": "NONE", "body_html": "<p>I think it may not, because tensorflow grabs all the available GPU RAM (a good share of it) while a call to <code>tf.train.Server()</code> is made from one process, so other process that could possibly co-exist with it may not get enough RAM which would essentially fail.  The option of  manual device placement or allocating finite amount of GPU RAM might sounds to be a solution, but the previous condition do not allows that, if I understood it correctly. I have tried <code>config.gpu_options.visible_device_list</code> also but it didn't help. In the stackoverflow answer <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> points out as calling separate process with a prefix from the shell, and similarly <a href=\"https://stackoverflow.com/a/37901914\" rel=\"nofollow\">here</a> in the python code itself. Both of it works but it would be great if there is a native way to do this in tensorflow API to make thing straight forward. This would be particularly preferable when a node with many GPU is shared among multiple users, so that each of them could independently run their task on the same node. It may not be a problem with <code>ingraphreplication</code> because as you mentioned all GPUs are utilised by a single process with manual device placement. Is there anything fundamentally prevents from doing this, such as os level GPU arbitration or something?. Though <code>apache mesos</code> or similar systems provides much higher level ways to do this, it would be nice if this could be done with the native tensorflow code.</p>", "body_text": "I think it may not, because tensorflow grabs all the available GPU RAM (a good share of it) while a call to tf.train.Server() is made from one process, so other process that could possibly co-exist with it may not get enough RAM which would essentially fail.  The option of  manual device placement or allocating finite amount of GPU RAM might sounds to be a solution, but the previous condition do not allows that, if I understood it correctly. I have tried config.gpu_options.visible_device_list also but it didn't help. In the stackoverflow answer @mrry points out as calling separate process with a prefix from the shell, and similarly here in the python code itself. Both of it works but it would be great if there is a native way to do this in tensorflow API to make thing straight forward. This would be particularly preferable when a node with many GPU is shared among multiple users, so that each of them could independently run their task on the same node. It may not be a problem with ingraphreplication because as you mentioned all GPUs are utilised by a single process with manual device placement. Is there anything fundamentally prevents from doing this, such as os level GPU arbitration or something?. Though apache mesos or similar systems provides much higher level ways to do this, it would be nice if this could be done with the native tensorflow code.", "body": "I think it may not, because tensorflow grabs all the available GPU RAM (a good share of it) while a call to `tf.train.Server()` is made from one process, so other process that could possibly co-exist with it may not get enough RAM which would essentially fail.  The option of  manual device placement or allocating finite amount of GPU RAM might sounds to be a solution, but the previous condition do not allows that, if I understood it correctly. I have tried `config.gpu_options.visible_device_list` also but it didn't help. In the stackoverflow answer @mrry points out as calling separate process with a prefix from the shell, and similarly [here](https://stackoverflow.com/a/37901914) in the python code itself. Both of it works but it would be great if there is a native way to do this in tensorflow API to make thing straight forward. This would be particularly preferable when a node with many GPU is shared among multiple users, so that each of them could independently run their task on the same node. It may not be a problem with `ingraphreplication` because as you mentioned all GPUs are utilised by a single process with manual device placement. Is there anything fundamentally prevents from doing this, such as os level GPU arbitration or something?. Though `apache mesos` or similar systems provides much higher level ways to do this, it would be nice if this could be done with the native tensorflow code. "}