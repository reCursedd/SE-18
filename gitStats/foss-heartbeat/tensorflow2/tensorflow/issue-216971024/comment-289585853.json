{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/289585853", "html_url": "https://github.com/tensorflow/tensorflow/issues/8712#issuecomment-289585853", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8712", "id": 289585853, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTU4NTg1Mw==", "user": {"login": "andrewharp", "id": 3376817, "node_id": "MDQ6VXNlcjMzNzY4MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3376817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewharp", "html_url": "https://github.com/andrewharp", "followers_url": "https://api.github.com/users/andrewharp/followers", "following_url": "https://api.github.com/users/andrewharp/following{/other_user}", "gists_url": "https://api.github.com/users/andrewharp/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewharp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewharp/subscriptions", "organizations_url": "https://api.github.com/users/andrewharp/orgs", "repos_url": "https://api.github.com/users/andrewharp/repos", "events_url": "https://api.github.com/users/andrewharp/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewharp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-27T21:05:12Z", "updated_at": "2017-03-27T21:06:12Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16437156\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Androbin\">@Androbin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16018\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/asimshankar\">@asimshankar</a> I just gave this a shot on my own and got the same results. I think something about the method tracing in Android Manager is interfering with the operation of the inference thread, as I noticed the iterating speed slows down by more than an order of magnitude.</p>\n<p>If I directly log the relevant sections while running Inception v1 (5h) on my Pixel with org.tensorflow.demo.env.SplitTimer, I get this:</p>\n<pre><code>03-27 16:56:47.036  6848  6961 I tensorflow: classifier: preprocessBitmap: cpu=1ms wall=2ms\n03-27 16:56:47.053  6848  6961 I tensorflow: classifier: feed: cpu=14ms wall=17ms\n03-27 16:56:47.389  6848  6961 I tensorflow: classifier: run: cpu=63ms wall=336ms\n03-27 16:56:47.390  6848  6961 I tensorflow: classifier: fetch: cpu=0ms wall=0ms\n</code></pre>\n<p>feed might be something to take a look at optimizing if possible, but in reality it's only taking about 5% of the total walltime spent processing each frame.</p>", "body_text": "@Androbin @asimshankar I just gave this a shot on my own and got the same results. I think something about the method tracing in Android Manager is interfering with the operation of the inference thread, as I noticed the iterating speed slows down by more than an order of magnitude.\nIf I directly log the relevant sections while running Inception v1 (5h) on my Pixel with org.tensorflow.demo.env.SplitTimer, I get this:\n03-27 16:56:47.036  6848  6961 I tensorflow: classifier: preprocessBitmap: cpu=1ms wall=2ms\n03-27 16:56:47.053  6848  6961 I tensorflow: classifier: feed: cpu=14ms wall=17ms\n03-27 16:56:47.389  6848  6961 I tensorflow: classifier: run: cpu=63ms wall=336ms\n03-27 16:56:47.390  6848  6961 I tensorflow: classifier: fetch: cpu=0ms wall=0ms\n\nfeed might be something to take a look at optimizing if possible, but in reality it's only taking about 5% of the total walltime spent processing each frame.", "body": "@Androbin @asimshankar I just gave this a shot on my own and got the same results. I think something about the method tracing in Android Manager is interfering with the operation of the inference thread, as I noticed the iterating speed slows down by more than an order of magnitude.\r\n\r\nIf I directly log the relevant sections while running Inception v1 (5h) on my Pixel with org.tensorflow.demo.env.SplitTimer, I get this:\r\n```\r\n03-27 16:56:47.036  6848  6961 I tensorflow: classifier: preprocessBitmap: cpu=1ms wall=2ms\r\n03-27 16:56:47.053  6848  6961 I tensorflow: classifier: feed: cpu=14ms wall=17ms\r\n03-27 16:56:47.389  6848  6961 I tensorflow: classifier: run: cpu=63ms wall=336ms\r\n03-27 16:56:47.390  6848  6961 I tensorflow: classifier: fetch: cpu=0ms wall=0ms\r\n```\r\n\r\nfeed might be something to take a look at optimizing if possible, but in reality it's only taking about 5% of the total walltime spent processing each frame."}