{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19961", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19961/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19961/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19961/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19961", "id": 331801958, "node_id": "MDU6SXNzdWUzMzE4MDE5NTg=", "number": 19961, "title": "compute_output_shape() Not Working For Custom Layer", "user": {"login": "Chasearmer", "id": 23300817, "node_id": "MDQ6VXNlcjIzMzAwODE3", "avatar_url": "https://avatars3.githubusercontent.com/u/23300817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Chasearmer", "html_url": "https://github.com/Chasearmer", "followers_url": "https://api.github.com/users/Chasearmer/followers", "following_url": "https://api.github.com/users/Chasearmer/following{/other_user}", "gists_url": "https://api.github.com/users/Chasearmer/gists{/gist_id}", "starred_url": "https://api.github.com/users/Chasearmer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Chasearmer/subscriptions", "organizations_url": "https://api.github.com/users/Chasearmer/orgs", "repos_url": "https://api.github.com/users/Chasearmer/repos", "events_url": "https://api.github.com/users/Chasearmer/events{/privacy}", "received_events_url": "https://api.github.com/users/Chasearmer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "angersson", "id": 32465472, "node_id": "MDQ6VXNlcjMyNDY1NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/32465472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angersson", "html_url": "https://github.com/angersson", "followers_url": "https://api.github.com/users/angersson/followers", "following_url": "https://api.github.com/users/angersson/following{/other_user}", "gists_url": "https://api.github.com/users/angersson/gists{/gist_id}", "starred_url": "https://api.github.com/users/angersson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angersson/subscriptions", "organizations_url": "https://api.github.com/users/angersson/orgs", "repos_url": "https://api.github.com/users/angersson/repos", "events_url": "https://api.github.com/users/angersson/events{/privacy}", "received_events_url": "https://api.github.com/users/angersson/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "angersson", "id": 32465472, "node_id": "MDQ6VXNlcjMyNDY1NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/32465472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angersson", "html_url": "https://github.com/angersson", "followers_url": "https://api.github.com/users/angersson/followers", "following_url": "https://api.github.com/users/angersson/following{/other_user}", "gists_url": "https://api.github.com/users/angersson/gists{/gist_id}", "starred_url": "https://api.github.com/users/angersson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angersson/subscriptions", "organizations_url": "https://api.github.com/users/angersson/orgs", "repos_url": "https://api.github.com/users/angersson/repos", "events_url": "https://api.github.com/users/angersson/events{/privacy}", "received_events_url": "https://api.github.com/users/angersson/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-06-13T00:43:02Z", "updated_at": "2018-11-23T13:07:34Z", "closed_at": "2018-06-21T19:41:46Z", "author_association": "NONE", "body_html": "<p>I have created a custom layer (called GraphGather) in Keras, yet the output tensor prints as :</p>\n<blockquote>\n<p>Tensor(\"graph_gather/Tanh:0\", shape=(?, ?), dtype=float32)</p>\n</blockquote>\n<p>For some reason the shape is being returned as (?,?), which is causing the next dense layer to raise the following error:</p>\n<blockquote>\n<p>ValueError: The last dimension of the inputs to <code>Dense</code> should be defined. Found <code>None</code>.</p>\n</blockquote>\n<p>The GraphGather layer code is as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">GraphGather</span>(<span class=\"pl-e\">tf</span>.<span class=\"pl-e\">keras</span>.<span class=\"pl-e\">layers</span>.<span class=\"pl-e\">Layer</span>):\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">batch_size</span>, <span class=\"pl-smi\">num_mols_in_batch</span>, <span class=\"pl-smi\">activation_fn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-k\">**</span><span class=\"pl-smi\">kwargs</span>):\n    <span class=\"pl-c1\">self</span>.batch_size <span class=\"pl-k\">=</span> batch_size\n    <span class=\"pl-c1\">self</span>.num_mols_in_batch <span class=\"pl-k\">=</span> num_mols_in_batch\n    <span class=\"pl-c1\">self</span>.activation_fn <span class=\"pl-k\">=</span> activation_fn\n    <span class=\"pl-c1\">super</span>(GraphGather, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>(<span class=\"pl-k\">**</span>kwargs)\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">build</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input_shape</span>):\n    <span class=\"pl-c1\">super</span>(GraphGather, <span class=\"pl-c1\">self</span>).build(input_shape)\n\n <span class=\"pl-k\">def</span> <span class=\"pl-en\">call</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>, <span class=\"pl-k\">**</span><span class=\"pl-smi\">kwargs</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> some operations (most of def call omitted)</span>\n    out_tensor <span class=\"pl-k\">=</span> result_of_operations() <span class=\"pl-c\"><span class=\"pl-c\">#</span> this line is pseudo code</span>\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.activation_fn <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n      out_tensor <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.activation_fn(out_tensor)\n    out_tensor <span class=\"pl-k\">=</span> out_tensor\n    <span class=\"pl-k\">return</span> out_tensor\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">compute_output_shape</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input_shape</span>):\n    <span class=\"pl-k\">return</span> (<span class=\"pl-c1\">self</span>.num_mols_in_batch, <span class=\"pl-c1\">2</span> <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">0</span>][<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>])</pre></div>\n<p>I have also tried hardcoding compute_output_shape to be:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">compute_output_shape</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input_shape</span>):\n    <span class=\"pl-k\">return</span> (<span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">150</span>)</pre></div>\n<p>Yet the output tensor when printed is still</p>\n<blockquote>\n<p>Tensor(\"graph_gather/Tanh:0\", shape=(?, ?), dtype=float32)</p>\n</blockquote>\n<p>which causes the ValueError written above.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li>Have written custom code</li>\n<li>*<em>OS Platform and Distribution</em>:  Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5.0</li>\n<li><strong>Python version</strong>: 3.5.5</li>\n</ul>", "body_text": "I have created a custom layer (called GraphGather) in Keras, yet the output tensor prints as :\n\nTensor(\"graph_gather/Tanh:0\", shape=(?, ?), dtype=float32)\n\nFor some reason the shape is being returned as (?,?), which is causing the next dense layer to raise the following error:\n\nValueError: The last dimension of the inputs to Dense should be defined. Found None.\n\nThe GraphGather layer code is as follows:\nclass GraphGather(tf.keras.layers.Layer):\n\n  def __init__(self, batch_size, num_mols_in_batch, activation_fn=None, **kwargs):\n    self.batch_size = batch_size\n    self.num_mols_in_batch = num_mols_in_batch\n    self.activation_fn = activation_fn\n    super(GraphGather, self).__init__(**kwargs)\n\n  def build(self, input_shape):\n    super(GraphGather, self).build(input_shape)\n\n def call(self, x, **kwargs):\n    # some operations (most of def call omitted)\n    out_tensor = result_of_operations() # this line is pseudo code\n    if self.activation_fn is not None:\n      out_tensor = self.activation_fn(out_tensor)\n    out_tensor = out_tensor\n    return out_tensor\n\n  def compute_output_shape(self, input_shape):\n    return (self.num_mols_in_batch, 2 * input_shape[0][-1])\nI have also tried hardcoding compute_output_shape to be:\ndef compute_output_shape(self, input_shape):\n    return (64, 150)\nYet the output tensor when printed is still\n\nTensor(\"graph_gather/Tanh:0\", shape=(?, ?), dtype=float32)\n\nwhich causes the ValueError written above.\n\nSystem information\n\nHave written custom code\n*OS Platform and Distribution:  Linux Ubuntu 16.04\nTensorFlow version (use command below): 1.5.0\nPython version: 3.5.5", "body": "I have created a custom layer (called GraphGather) in Keras, yet the output tensor prints as :\r\n>Tensor(\"graph_gather/Tanh:0\", shape=(?, ?), dtype=float32)\r\n\r\nFor some reason the shape is being returned as (?,?), which is causing the next dense layer to raise the following error:\r\n>ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\r\n\r\nThe GraphGather layer code is as follows:\r\n```python\r\nclass GraphGather(tf.keras.layers.Layer):\r\n\r\n  def __init__(self, batch_size, num_mols_in_batch, activation_fn=None, **kwargs):\r\n    self.batch_size = batch_size\r\n    self.num_mols_in_batch = num_mols_in_batch\r\n    self.activation_fn = activation_fn\r\n    super(GraphGather, self).__init__(**kwargs)\r\n\r\n  def build(self, input_shape):\r\n    super(GraphGather, self).build(input_shape)\r\n\r\n def call(self, x, **kwargs):\r\n    # some operations (most of def call omitted)\r\n    out_tensor = result_of_operations() # this line is pseudo code\r\n    if self.activation_fn is not None:\r\n      out_tensor = self.activation_fn(out_tensor)\r\n    out_tensor = out_tensor\r\n    return out_tensor\r\n\r\n  def compute_output_shape(self, input_shape):\r\n    return (self.num_mols_in_batch, 2 * input_shape[0][-1])\r\n```\r\nI have also tried hardcoding compute_output_shape to be:\r\n```python\r\ndef compute_output_shape(self, input_shape):\r\n    return (64, 150)\r\n```\r\nYet the output tensor when printed is still \r\n>Tensor(\"graph_gather/Tanh:0\", shape=(?, ?), dtype=float32)\r\n\r\nwhich causes the ValueError written above. \r\n\r\n------------------------\r\n\r\n### System information\r\n- Have written custom code\r\n- **OS Platform and Distribution*:  Linux Ubuntu 16.04\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 3.5.5\r\n"}