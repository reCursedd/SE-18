{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/404051489", "html_url": "https://github.com/tensorflow/tensorflow/issues/13664#issuecomment-404051489", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13664", "id": 404051489, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDA1MTQ4OQ==", "user": {"login": "brave-hannah", "id": 26771750, "node_id": "MDQ6VXNlcjI2NzcxNzUw", "avatar_url": "https://avatars3.githubusercontent.com/u/26771750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brave-hannah", "html_url": "https://github.com/brave-hannah", "followers_url": "https://api.github.com/users/brave-hannah/followers", "following_url": "https://api.github.com/users/brave-hannah/following{/other_user}", "gists_url": "https://api.github.com/users/brave-hannah/gists{/gist_id}", "starred_url": "https://api.github.com/users/brave-hannah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brave-hannah/subscriptions", "organizations_url": "https://api.github.com/users/brave-hannah/orgs", "repos_url": "https://api.github.com/users/brave-hannah/repos", "events_url": "https://api.github.com/users/brave-hannah/events{/privacy}", "received_events_url": "https://api.github.com/users/brave-hannah/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-11T05:42:14Z", "updated_at": "2018-07-11T06:19:52Z", "author_association": "NONE", "body_html": "<p>I meet this issue also with tf-1.8 and P100 when I do distributed train via benchmark, even while I have set num_gpus to 2 but it seems using cpu both nodes without control, which makes me confused at all... <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16850179\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Leslie-Fang\">@Leslie-Fang</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=24963061\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mahmoud-abuzaina\">@mahmoud-abuzaina</a><br>\nThis is the command I execute</p>\n<blockquote>\n<p>CUDA_VISIBLE_DEVICES='' python3.4 tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=2 --batch_size=128 --model=resnet50 --variable_update=distributed_replicated --job_name=ps --ps_hosts=10.10.1.71:50071,10.10.1.20:50020 --worker_hosts=10.10.1.71:40071,10.10.1.20:40020 --task_index=0 --server_protocol='grpc+verbs' --all_reduce_spec='nccl/xring'<br>\nCUDA_VISIBLE_DEVICES='' python3.4 tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=2 --batch_size=128 --model=resnet50 --variable_update=distributed_replicated --job_name=worker --ps_hosts=10.10.1.71:50071,10.10.1.20:50020 --worker_hosts=10.10.1.71:40071,10.10.1.20:40020 --task_index=0 --server_protocol='grpc+verbs' --all_reduce_spec='nccl/xring'</p>\n</blockquote>\n<p>This is a part of output</p>\n<blockquote>\n<p>I0711 13:18:38.419439 140188219279168 tf_logging.py:116] Running local_init_op.<br>\nI0711 13:18:41.063343 140188219279168 tf_logging.py:116] Done running local_init_op.<br>\nRunning warm up<br>\n2018-07-11 13:18:45.151136: E tensorflow/core/common_runtime/executor.cc:660] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU<br>\n[[Node: v0/tower_0/cg/mpool0/MaxPool = MaxPool<a href=\"v0/tower_0/cg/conv0/Relu\">T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"</a>]]<br>\nI0711 13:18:45.186572 140188219279168 tf_logging.py:116] Error reported to Coordinator: &lt;class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'&gt;, Default MaxPoolingOp only supports NHWC on device type CPU<br>\n[[Node: v0/tower_0/cg/mpool0/MaxPool = MaxPool<a href=\"v0/tower_0/cg/conv0/Relu\">T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"</a>]]</p>\n</blockquote>", "body_text": "I meet this issue also with tf-1.8 and P100 when I do distributed train via benchmark, even while I have set num_gpus to 2 but it seems using cpu both nodes without control, which makes me confused at all... @Leslie-Fang @mahmoud-abuzaina\nThis is the command I execute\n\nCUDA_VISIBLE_DEVICES='' python3.4 tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=2 --batch_size=128 --model=resnet50 --variable_update=distributed_replicated --job_name=ps --ps_hosts=10.10.1.71:50071,10.10.1.20:50020 --worker_hosts=10.10.1.71:40071,10.10.1.20:40020 --task_index=0 --server_protocol='grpc+verbs' --all_reduce_spec='nccl/xring'\nCUDA_VISIBLE_DEVICES='' python3.4 tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=2 --batch_size=128 --model=resnet50 --variable_update=distributed_replicated --job_name=worker --ps_hosts=10.10.1.71:50071,10.10.1.20:50020 --worker_hosts=10.10.1.71:40071,10.10.1.20:40020 --task_index=0 --server_protocol='grpc+verbs' --all_reduce_spec='nccl/xring'\n\nThis is a part of output\n\nI0711 13:18:38.419439 140188219279168 tf_logging.py:116] Running local_init_op.\nI0711 13:18:41.063343 140188219279168 tf_logging.py:116] Done running local_init_op.\nRunning warm up\n2018-07-11 13:18:45.151136: E tensorflow/core/common_runtime/executor.cc:660] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU\n[[Node: v0/tower_0/cg/mpool0/MaxPool = MaxPoolT=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"]]\nI0711 13:18:45.186572 140188219279168 tf_logging.py:116] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Default MaxPoolingOp only supports NHWC on device type CPU\n[[Node: v0/tower_0/cg/mpool0/MaxPool = MaxPoolT=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"]]", "body": "I meet this issue also with tf-1.8 and P100 when I do distributed train via benchmark, even while I have set num_gpus to 2 but it seems using cpu both nodes without control, which makes me confused at all... @Leslie-Fang @mahmoud-abuzaina \r\nThis is the command I execute\r\n\r\n> CUDA_VISIBLE_DEVICES='' python3.4 tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=2 --batch_size=128 --model=resnet50 --variable_update=distributed_replicated --job_name=ps --ps_hosts=10.10.1.71:50071,10.10.1.20:50020 --worker_hosts=10.10.1.71:40071,10.10.1.20:40020 --task_index=0 --server_protocol='grpc+verbs' --all_reduce_spec='nccl/xring'\r\n>CUDA_VISIBLE_DEVICES='' python3.4 tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=2 --batch_size=128 --model=resnet50 --variable_update=distributed_replicated --job_name=worker --ps_hosts=10.10.1.71:50071,10.10.1.20:50020 --worker_hosts=10.10.1.71:40071,10.10.1.20:40020 --task_index=0 --server_protocol='grpc+verbs' --all_reduce_spec='nccl/xring'\r\n\r\nThis is a part of output\r\n> I0711 13:18:38.419439 140188219279168 tf_logging.py:116] Running local_init_op.\r\nI0711 13:18:41.063343 140188219279168 tf_logging.py:116] Done running local_init_op.\r\nRunning warm up\r\n2018-07-11 13:18:45.151136: E tensorflow/core/common_runtime/executor.cc:660] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU\r\n         [[Node: v0/tower_0/cg/mpool0/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"](v0/tower_0/cg/conv0/Relu)]]\r\nI0711 13:18:45.186572 140188219279168 tf_logging.py:116] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Default MaxPoolingOp only supports NHWC on device type CPU\r\n         [[Node: v0/tower_0/cg/mpool0/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"](v0/tower_0/cg/conv0/Relu)]]\r\n"}