{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/329856964", "html_url": "https://github.com/tensorflow/tensorflow/issues/2134#issuecomment-329856964", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2134", "id": 329856964, "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTg1Njk2NA==", "user": {"login": "vribic", "id": 13556929, "node_id": "MDQ6VXNlcjEzNTU2OTI5", "avatar_url": "https://avatars3.githubusercontent.com/u/13556929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vribic", "html_url": "https://github.com/vribic", "followers_url": "https://api.github.com/users/vribic/followers", "following_url": "https://api.github.com/users/vribic/following{/other_user}", "gists_url": "https://api.github.com/users/vribic/gists{/gist_id}", "starred_url": "https://api.github.com/users/vribic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vribic/subscriptions", "organizations_url": "https://api.github.com/users/vribic/orgs", "repos_url": "https://api.github.com/users/vribic/repos", "events_url": "https://api.github.com/users/vribic/events{/privacy}", "received_events_url": "https://api.github.com/users/vribic/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-15T18:06:51Z", "updated_at": "2017-09-15T18:06:51Z", "author_association": "NONE", "body_html": "<p>It is possible to use extract_glimpse with zero padding by playing around with resize_image_with_crop_or_pad first.</p>\n<p>If the img_batch variable is a tensor of shape [batch_size,img_width,img_height,channels] you could do first something like this:</p>\n<div class=\"highlight highlight-source-python\"><pre> <span class=\"pl-c\"><span class=\"pl-c\">#</span> unstack images in batch</span>\nimg_batch_unstacked <span class=\"pl-k\">=</span> tf.unstack(img_batch , <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>)\n\n <span class=\"pl-c\"><span class=\"pl-c\">#</span> stack images on channels</span>\nconcat_on_channel_batch <span class=\"pl-k\">=</span> tf.concat(img_batch_unstacked, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>)\n\n <span class=\"pl-c\"><span class=\"pl-c\">#</span> pad the image with max glimpse width/height</span>\nresized_img_batch <span class=\"pl-k\">=</span> tf.image.resize_image_with_crop_or_pad(\n    <span class=\"pl-v\">image</span><span class=\"pl-k\">=</span> concat_on_channel_batch,\n    <span class=\"pl-v\">target_width</span><span class=\"pl-k\">=</span> conf.get_padded_img_width(), \n    <span class=\"pl-v\">target_height</span><span class=\"pl-k\">=</span> conf.get_padded_img_height() \n)\n\n <span class=\"pl-c\"><span class=\"pl-c\">#</span> undo the opeartions to get the original batch</span>\n <span class=\"pl-c\"><span class=\"pl-c\">#</span> first split images on channels </span>\nsplited_on_channel_batch <span class=\"pl-k\">=</span> tf.split( \n    resized_img_batch, \n    <span class=\"pl-v\">num_or_size_splits</span><span class=\"pl-k\">=</span>conf.batch_size, \n    <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>\n)\n\n <span class=\"pl-c\"><span class=\"pl-c\">#</span> combine the images back to the original shape</span>\nimg_batch_padded <span class=\"pl-k\">=</span> tf.stack(\n    splited_on_channel_batch,\n    <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n)</pre></div>\n<p>Now you need to modify the offsets variable so that it goes from -x to x where x is a new boundary depending on the original image dimensions and the padding dimensions. You can calculate it like:</p>\n<div class=\"highlight highlight-source-python\"><pre>offset <span class=\"pl-k\">=</span> offset <span class=\"pl-k\">*</span> original_image_dimension <span class=\"pl-k\">/</span> padded_image_dimension</pre></div>\n<p>Finally for the extract_glimpse use :</p>\n<div class=\"highlight highlight-source-python\"><pre>glimpses <span class=\"pl-k\">=</span> tf.image.extract_glimpse(\n    <span class=\"pl-v\">input</span><span class=\"pl-k\">=</span>img_batch_padded,\n    <span class=\"pl-v\">size</span> <span class=\"pl-k\">=</span> glimpse_dim,\n    <span class=\"pl-v\">offsets</span><span class=\"pl-k\">=</span>offset,\n    <span class=\"pl-v\">centered</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    <span class=\"pl-v\">normalized</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\n)</pre></div>\n<p>I'm not sure if this is the best solution but it keeps all calculations in Tensorflow what was my goal. Hope this helps until the fix for zero padding get implemented.</p>", "body_text": "It is possible to use extract_glimpse with zero padding by playing around with resize_image_with_crop_or_pad first.\nIf the img_batch variable is a tensor of shape [batch_size,img_width,img_height,channels] you could do first something like this:\n # unstack images in batch\nimg_batch_unstacked = tf.unstack(img_batch , axis= 0)\n\n # stack images on channels\nconcat_on_channel_batch = tf.concat(img_batch_unstacked, axis= 2)\n\n # pad the image with max glimpse width/height\nresized_img_batch = tf.image.resize_image_with_crop_or_pad(\n    image= concat_on_channel_batch,\n    target_width= conf.get_padded_img_width(), \n    target_height= conf.get_padded_img_height() \n)\n\n # undo the opeartions to get the original batch\n # first split images on channels \nsplited_on_channel_batch = tf.split( \n    resized_img_batch, \n    num_or_size_splits=conf.batch_size, \n    axis=2\n)\n\n # combine the images back to the original shape\nimg_batch_padded = tf.stack(\n    splited_on_channel_batch,\n    axis=0\n)\nNow you need to modify the offsets variable so that it goes from -x to x where x is a new boundary depending on the original image dimensions and the padding dimensions. You can calculate it like:\noffset = offset * original_image_dimension / padded_image_dimension\nFinally for the extract_glimpse use :\nglimpses = tf.image.extract_glimpse(\n    input=img_batch_padded,\n    size = glimpse_dim,\n    offsets=offset,\n    centered=True,\n    normalized=True\n)\nI'm not sure if this is the best solution but it keeps all calculations in Tensorflow what was my goal. Hope this helps until the fix for zero padding get implemented.", "body": "It is possible to use extract_glimpse with zero padding by playing around with resize_image_with_crop_or_pad first. \r\n\r\nIf the img_batch variable is a tensor of shape [batch_size,img_width,img_height,channels] you could do first something like this:\r\n\r\n```python\r\n # unstack images in batch\r\nimg_batch_unstacked = tf.unstack(img_batch , axis= 0)\r\n\r\n # stack images on channels\r\nconcat_on_channel_batch = tf.concat(img_batch_unstacked, axis= 2)\r\n\r\n # pad the image with max glimpse width/height\r\nresized_img_batch = tf.image.resize_image_with_crop_or_pad(\r\n    image= concat_on_channel_batch,\r\n    target_width= conf.get_padded_img_width(), \r\n    target_height= conf.get_padded_img_height() \r\n)\r\n\r\n # undo the opeartions to get the original batch\r\n # first split images on channels \r\nsplited_on_channel_batch = tf.split( \r\n    resized_img_batch, \r\n    num_or_size_splits=conf.batch_size, \r\n    axis=2\r\n)\r\n\r\n # combine the images back to the original shape\r\nimg_batch_padded = tf.stack(\r\n    splited_on_channel_batch,\r\n    axis=0\r\n)\r\n```\r\n\r\nNow you need to modify the offsets variable so that it goes from -x to x where x is a new boundary depending on the original image dimensions and the padding dimensions. You can calculate it like: \r\n\r\n```python\r\noffset = offset * original_image_dimension / padded_image_dimension\r\n```\r\n\r\nFinally for the extract_glimpse use : \r\n\r\n```python\r\nglimpses = tf.image.extract_glimpse(\r\n    input=img_batch_padded,\r\n    size = glimpse_dim,\r\n    offsets=offset,\r\n    centered=True,\r\n    normalized=True\r\n)\r\n```\r\n\r\nI'm not sure if this is the best solution but it keeps all calculations in Tensorflow what was my goal. Hope this helps until the fix for zero padding get implemented. "}