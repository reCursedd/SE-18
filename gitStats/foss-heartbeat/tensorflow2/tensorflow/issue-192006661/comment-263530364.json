{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263530364", "html_url": "https://github.com/tensorflow/tensorflow/issues/5902#issuecomment-263530364", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5902", "id": 263530364, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MzUzMDM2NA==", "user": {"login": "larsmennen", "id": 1162951, "node_id": "MDQ6VXNlcjExNjI5NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1162951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/larsmennen", "html_url": "https://github.com/larsmennen", "followers_url": "https://api.github.com/users/larsmennen/followers", "following_url": "https://api.github.com/users/larsmennen/following{/other_user}", "gists_url": "https://api.github.com/users/larsmennen/gists{/gist_id}", "starred_url": "https://api.github.com/users/larsmennen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/larsmennen/subscriptions", "organizations_url": "https://api.github.com/users/larsmennen/orgs", "repos_url": "https://api.github.com/users/larsmennen/repos", "events_url": "https://api.github.com/users/larsmennen/events{/privacy}", "received_events_url": "https://api.github.com/users/larsmennen/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-29T10:13:56Z", "updated_at": "2016-11-29T10:13:56Z", "author_association": "NONE", "body_html": "<p>Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15676913\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/poxvoculi\">@poxvoculi</a> for your quick reply and detailed explanation.</p>\n<p>I understand that reading from/to disk etc. into GPU memory without passing through CPU memory is not feasible. However, that is not what I am trying to do. I am trying to combine a TF progam with a non-TF program that both run on GPU, as you mention.</p>\n<p>Your last suggestion (using Vars) seems feasible, but it also seems like a bit of a workaround. Especially in high-performance environments, I can imagine that I would not be the only one using this functionality.</p>\n<p>The fact that data is copied to CPU memory and then back to GPU memory when running a graph with an input tensor on GPU memory, suggests to me that TF is detecting that this tensor is on GPU memory.<br>\nSo wouldn't it be easier to directly work from an input tensor if it is on GPU memory, and transfer it CPU -&gt; GPU if it is on CPU memory?<br>\nSimilarly there could be an option I think to specify whether output tensors should be copied back to CPU memory or not.<br>\nThis would give the flexibility needed I think.</p>\n<p>Thanks and looking forward to hear your thoughts.</p>", "body_text": "Thanks @poxvoculi for your quick reply and detailed explanation.\nI understand that reading from/to disk etc. into GPU memory without passing through CPU memory is not feasible. However, that is not what I am trying to do. I am trying to combine a TF progam with a non-TF program that both run on GPU, as you mention.\nYour last suggestion (using Vars) seems feasible, but it also seems like a bit of a workaround. Especially in high-performance environments, I can imagine that I would not be the only one using this functionality.\nThe fact that data is copied to CPU memory and then back to GPU memory when running a graph with an input tensor on GPU memory, suggests to me that TF is detecting that this tensor is on GPU memory.\nSo wouldn't it be easier to directly work from an input tensor if it is on GPU memory, and transfer it CPU -> GPU if it is on CPU memory?\nSimilarly there could be an option I think to specify whether output tensors should be copied back to CPU memory or not.\nThis would give the flexibility needed I think.\nThanks and looking forward to hear your thoughts.", "body": "Thanks @poxvoculi for your quick reply and detailed explanation.\r\n\r\nI understand that reading from/to disk etc. into GPU memory without passing through CPU memory is not feasible. However, that is not what I am trying to do. I am trying to combine a TF progam with a non-TF program that both run on GPU, as you mention.\r\n\r\nYour last suggestion (using Vars) seems feasible, but it also seems like a bit of a workaround. Especially in high-performance environments, I can imagine that I would not be the only one using this functionality.\r\n\r\nThe fact that data is copied to CPU memory and then back to GPU memory when running a graph with an input tensor on GPU memory, suggests to me that TF is detecting that this tensor is on GPU memory.\r\nSo wouldn't it be easier to directly work from an input tensor if it is on GPU memory, and transfer it CPU -> GPU if it is on CPU memory?\r\nSimilarly there could be an option I think to specify whether output tensors should be copied back to CPU memory or not.\r\nThis would give the flexibility needed I think.\r\n\r\nThanks and looking forward to hear your thoughts."}