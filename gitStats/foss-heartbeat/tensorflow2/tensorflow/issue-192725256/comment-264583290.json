{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/264583290", "html_url": "https://github.com/tensorflow/tensorflow/issues/5995#issuecomment-264583290", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5995", "id": 264583290, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDU4MzI5MA==", "user": {"login": "camj256", "id": 6239949, "node_id": "MDQ6VXNlcjYyMzk5NDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/6239949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/camj256", "html_url": "https://github.com/camj256", "followers_url": "https://api.github.com/users/camj256/followers", "following_url": "https://api.github.com/users/camj256/following{/other_user}", "gists_url": "https://api.github.com/users/camj256/gists{/gist_id}", "starred_url": "https://api.github.com/users/camj256/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/camj256/subscriptions", "organizations_url": "https://api.github.com/users/camj256/orgs", "repos_url": "https://api.github.com/users/camj256/repos", "events_url": "https://api.github.com/users/camj256/events{/privacy}", "received_events_url": "https://api.github.com/users/camj256/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-02T22:47:39Z", "updated_at": "2016-12-02T22:58:45Z", "author_association": "NONE", "body_html": "<p>I got my linux install fixed and am looking into this right now. Hopefully someone can answer a few rookie questions that are getting in the way of my understanding of this.</p>\n<p>I've noticed that I can just up the batch size to 100k and process a lot quicker than CPU but I'm curious if the batch size has any affect on how the DNN learns? Also, I've noticed if I change the size of the NN to be much larger (512 instead of 32) the accuracy gets stuck at one spot. The GPU usage does go up to about 50% when doing that which leads me to believe there is an IO bottleneck somewhere. Lastly, how many epochs should I run? I've run 10k epochs on this data set in about an hour (with batchsize of 100k) and it seems to bounce around between 60 and 82% acc.</p>\n<p>I'm going to run the timeline thing later tonight. For now, if someone could answer those it would really help my understanding of what I'm trying to do. Also, the docs on the tensorflow seem to assume I already know what everything does. I've not had much luck finding a place that explains that.</p>", "body_text": "I got my linux install fixed and am looking into this right now. Hopefully someone can answer a few rookie questions that are getting in the way of my understanding of this.\nI've noticed that I can just up the batch size to 100k and process a lot quicker than CPU but I'm curious if the batch size has any affect on how the DNN learns? Also, I've noticed if I change the size of the NN to be much larger (512 instead of 32) the accuracy gets stuck at one spot. The GPU usage does go up to about 50% when doing that which leads me to believe there is an IO bottleneck somewhere. Lastly, how many epochs should I run? I've run 10k epochs on this data set in about an hour (with batchsize of 100k) and it seems to bounce around between 60 and 82% acc.\nI'm going to run the timeline thing later tonight. For now, if someone could answer those it would really help my understanding of what I'm trying to do. Also, the docs on the tensorflow seem to assume I already know what everything does. I've not had much luck finding a place that explains that.", "body": "I got my linux install fixed and am looking into this right now. Hopefully someone can answer a few rookie questions that are getting in the way of my understanding of this.\r\n\r\nI've noticed that I can just up the batch size to 100k and process a lot quicker than CPU but I'm curious if the batch size has any affect on how the DNN learns? Also, I've noticed if I change the size of the NN to be much larger (512 instead of 32) the accuracy gets stuck at one spot. The GPU usage does go up to about 50% when doing that which leads me to believe there is an IO bottleneck somewhere. Lastly, how many epochs should I run? I've run 10k epochs on this data set in about an hour (with batchsize of 100k) and it seems to bounce around between 60 and 82% acc. \r\n\r\nI'm going to run the timeline thing later tonight. For now, if someone could answer those it would really help my understanding of what I'm trying to do. Also, the docs on the tensorflow seem to assume I already know what everything does. I've not had much luck finding a place that explains that."}