{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1757", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1757/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1757/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1757/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1757", "id": 145538107, "node_id": "MDU6SXNzdWUxNDU1MzgxMDc=", "number": 1757, "title": "Running out of memory, even on small network", "user": {"login": "johnrowlay", "id": 17486673, "node_id": "MDQ6VXNlcjE3NDg2Njcz", "avatar_url": "https://avatars3.githubusercontent.com/u/17486673?v=4", "gravatar_id": "", "url": "https://api.github.com/users/johnrowlay", "html_url": "https://github.com/johnrowlay", "followers_url": "https://api.github.com/users/johnrowlay/followers", "following_url": "https://api.github.com/users/johnrowlay/following{/other_user}", "gists_url": "https://api.github.com/users/johnrowlay/gists{/gist_id}", "starred_url": "https://api.github.com/users/johnrowlay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/johnrowlay/subscriptions", "organizations_url": "https://api.github.com/users/johnrowlay/orgs", "repos_url": "https://api.github.com/users/johnrowlay/repos", "events_url": "https://api.github.com/users/johnrowlay/events{/privacy}", "received_events_url": "https://api.github.com/users/johnrowlay/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2016-04-03T20:36:09Z", "updated_at": "2018-08-27T05:49:46Z", "closed_at": "2016-04-06T00:11:27Z", "author_association": "NONE", "body_html": "<p>Operating System: Ubuntu 14.04 on a PC<br>\nPip Installation: 64-bit, GPU-enabled, Version 0.7.1</p>\n<hr>\n<p>My issue is that Tensor Flow is running out of memory when building my network, even though based on my calculations, there should easily be sufficient room on my GPU.</p>\n<p>Below is a minimal example of my code, which is based on the Tensor Flow MNIST tutorial. The network is a two-layer fully-connected network, and the number of nodes in the hidden layer is defined by the variable <code>n</code>. The size of the training minibatch is 1. Here is my code:</p>\n<pre><code>n = 23000\n\nmnist = read_data_sets('MINST_Data', one_hot=True)\nsession = tf.InteractiveSession()\nx = tf.placeholder(tf.float32, [None, 784])\nW1 = tf.Variable(tf.truncated_normal([784, n], stddev=0.1))\nb1 = tf.Variable(tf.constant(0.1, shape=[n]))\nnn1 = tf.matmul(x, W1) + b1\nW2 = tf.Variable(tf.truncated_normal([n, 10], stddev=0.1))\nb2 = tf.Variable(tf.constant(0.1, shape=[10]))\nnn2 = tf.matmul(nn1, W2) + b2\ny = tf.nn.softmax(nn2)\ny_ = tf.placeholder(tf.float32, [None, 10])\ncross_entropy = -tf.reduce_sum(y_*tf.log(y))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\nfor i in range(1000):\n  batch_xs, batch_ys = mnist.train.next_batch(1)\n  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n</code></pre>\n<p>Now, if <code>n &lt;= 22000</code>, then the network runs fine. However, if <code>n &gt;= 23000</code>, I get the following error:</p>\n<pre><code>W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state\nW tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n</code></pre>\n<p>However, according to my calculations, there should not be a problem with the memory. The number of parameters in the network is as follows:</p>\n<pre><code>First layer weights: 784 * n\nFirst layer biases: n\nSecond layer weights: 10 * n\nSecond layer biases: 10\nTotal: 795n + 10\n</code></pre>\n<p>So with <code>n = 23000</code>, and using <code>float32</code> data, the total memory required for the network should therefore be 73.1 MB.</p>\n<p>Now, my graphics card is the NVIDIA GeForce GTX 780 Ti, which has 3072 MB of memory. After finding my graphics card, Tensor Flow prints out the following:</p>\n<pre><code>Total memory: 3.00GiB\nFree memory: 2.32GiB\n</code></pre>\n<p>So, there should be around 2.32 GB memory available, which is far greater than the 73.1 MB calculated above. The minibatch size is 1, so this has minimal effect. Why am I getting this error?</p>\n<hr>\n<p>I have also now tried this on my laptop, which has an NVIDIA GeForce GTX 880M GPU. Here, Tensor Flow reads out <code>Free memory: 7.60GiB</code>. Running the same code as above, it gives me a memory error at around <code>n = 700,000</code>, which is equivalent to 2.2 GB. This makes a bit more sense, and is significantly higher than the point at which my PC code breaks. However, it is still puzzling to me why it does not break closer to the 7.6 GB mark.</p>\n<hr>\n<p>The full output from Tensor Flow whilst running the above code on my PC, with <code>n = 23000</code>, is:</p>\n<pre><code>I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 780 Ti\nmajor: 3 minor: 5 memoryClockRate (GHz) 1.0455\npciBusID 0000:01:00.0\nTotal memory: 3.00GiB\nFree memory: 2.32GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 2.03GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb04720000 extends to 0xb86295000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (256):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (131072):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (524288):    Total Chunks: 2, Chunks in use: 0 819.0KiB allocated for chunks. 390.6KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (134217728):     Total Chunks: 1, Chunks in use: 0 68.79MiB allocated for chunks. 29.91MiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (536870912):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1073741824):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2147483648):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4294967296):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:450] Bin for 877.38MiB was 1.00GiB, Chunk State: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d239400 of size 80128\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7600 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d24cd00 of size 438528\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a302800 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15d58800 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736b00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7f00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15e39200 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c16b00 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c61500 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736d00 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8100 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c4ad00 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736a00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7e00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7900 of size 400128\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720200 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736c00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7600 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3300 of size 1810570496\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1c0c00 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c00300 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7800 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720100 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7700 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7400 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb11781700 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77d00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77e00 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:468]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 16 Chunks of size 256 totalling 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 80128 totalling 78.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 92160 totalling 450.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 400128 totalling 390.8KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 438528 totalling 428.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 4 Chunks of size 920064 totalling 3.51MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 72128000 totalling 343.93MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 1810570496 totalling 1.69GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:475] Sum Total of in-use chunks: 2.03GiB\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state\nW tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x50f40e0 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_97_range_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: Cast/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_96_Cast\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py\", line 232, in &lt;module&gt;\n    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 315, in run\n    return self._run(None, fetches, feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 511, in _run\n    feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _do_run\n    target_list)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 586, in _do_call\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_97_range_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'add', defined at:\n  File \"/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py\", line 215, in &lt;module&gt;\n    nn1 = tf.matmul(x, W1) + b1\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 468, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 44, in add\n    return _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()\n</code></pre>", "body_text": "Operating System: Ubuntu 14.04 on a PC\nPip Installation: 64-bit, GPU-enabled, Version 0.7.1\n\nMy issue is that Tensor Flow is running out of memory when building my network, even though based on my calculations, there should easily be sufficient room on my GPU.\nBelow is a minimal example of my code, which is based on the Tensor Flow MNIST tutorial. The network is a two-layer fully-connected network, and the number of nodes in the hidden layer is defined by the variable n. The size of the training minibatch is 1. Here is my code:\nn = 23000\n\nmnist = read_data_sets('MINST_Data', one_hot=True)\nsession = tf.InteractiveSession()\nx = tf.placeholder(tf.float32, [None, 784])\nW1 = tf.Variable(tf.truncated_normal([784, n], stddev=0.1))\nb1 = tf.Variable(tf.constant(0.1, shape=[n]))\nnn1 = tf.matmul(x, W1) + b1\nW2 = tf.Variable(tf.truncated_normal([n, 10], stddev=0.1))\nb2 = tf.Variable(tf.constant(0.1, shape=[10]))\nnn2 = tf.matmul(nn1, W2) + b2\ny = tf.nn.softmax(nn2)\ny_ = tf.placeholder(tf.float32, [None, 10])\ncross_entropy = -tf.reduce_sum(y_*tf.log(y))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\nfor i in range(1000):\n  batch_xs, batch_ys = mnist.train.next_batch(1)\n  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\nNow, if n <= 22000, then the network runs fine. However, if n >= 23000, I get the following error:\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state\nW tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n\nHowever, according to my calculations, there should not be a problem with the memory. The number of parameters in the network is as follows:\nFirst layer weights: 784 * n\nFirst layer biases: n\nSecond layer weights: 10 * n\nSecond layer biases: 10\nTotal: 795n + 10\n\nSo with n = 23000, and using float32 data, the total memory required for the network should therefore be 73.1 MB.\nNow, my graphics card is the NVIDIA GeForce GTX 780 Ti, which has 3072 MB of memory. After finding my graphics card, Tensor Flow prints out the following:\nTotal memory: 3.00GiB\nFree memory: 2.32GiB\n\nSo, there should be around 2.32 GB memory available, which is far greater than the 73.1 MB calculated above. The minibatch size is 1, so this has minimal effect. Why am I getting this error?\n\nI have also now tried this on my laptop, which has an NVIDIA GeForce GTX 880M GPU. Here, Tensor Flow reads out Free memory: 7.60GiB. Running the same code as above, it gives me a memory error at around n = 700,000, which is equivalent to 2.2 GB. This makes a bit more sense, and is significantly higher than the point at which my PC code breaks. However, it is still puzzling to me why it does not break closer to the 7.6 GB mark.\n\nThe full output from Tensor Flow whilst running the above code on my PC, with n = 23000, is:\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 780 Ti\nmajor: 3 minor: 5 memoryClockRate (GHz) 1.0455\npciBusID 0000:01:00.0\nTotal memory: 3.00GiB\nFree memory: 2.32GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 2.03GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb04720000 extends to 0xb86295000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (256):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (131072):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (524288):    Total Chunks: 2, Chunks in use: 0 819.0KiB allocated for chunks. 390.6KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (134217728):     Total Chunks: 1, Chunks in use: 0 68.79MiB allocated for chunks. 29.91MiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (536870912):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1073741824):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2147483648):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4294967296):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:450] Bin for 877.38MiB was 1.00GiB, Chunk State: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d239400 of size 80128\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7600 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d24cd00 of size 438528\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a302800 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15d58800 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736b00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7f00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15e39200 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c16b00 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c61500 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736d00 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8100 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c4ad00 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736a00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7e00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7900 of size 400128\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720200 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736c00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7600 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3300 of size 1810570496\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1c0c00 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c00300 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7800 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720100 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7700 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7400 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb11781700 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77d00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77e00 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:468]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 16 Chunks of size 256 totalling 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 80128 totalling 78.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 92160 totalling 450.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 400128 totalling 390.8KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 438528 totalling 428.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 4 Chunks of size 920064 totalling 3.51MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 72128000 totalling 343.93MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 1810570496 totalling 1.69GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:475] Sum Total of in-use chunks: 2.03GiB\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state\nW tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x50f40e0 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_97_range_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: Cast/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_96_Cast\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py\", line 232, in <module>\n    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 315, in run\n    return self._run(None, fetches, feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 511, in _run\n    feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _do_run\n    target_list)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 586, in _do_call\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_97_range_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'add', defined at:\n  File \"/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py\", line 215, in <module>\n    nn1 = tf.matmul(x, W1) + b1\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 468, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 44, in add\n    return _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()", "body": "Operating System: Ubuntu 14.04 on a PC\nPip Installation: 64-bit, GPU-enabled, Version 0.7.1\n\n---\n\nMy issue is that Tensor Flow is running out of memory when building my network, even though based on my calculations, there should easily be sufficient room on my GPU.\n\nBelow is a minimal example of my code, which is based on the Tensor Flow MNIST tutorial. The network is a two-layer fully-connected network, and the number of nodes in the hidden layer is defined by the variable `n`. The size of the training minibatch is 1. Here is my code:\n\n```\nn = 23000\n\nmnist = read_data_sets('MINST_Data', one_hot=True)\nsession = tf.InteractiveSession()\nx = tf.placeholder(tf.float32, [None, 784])\nW1 = tf.Variable(tf.truncated_normal([784, n], stddev=0.1))\nb1 = tf.Variable(tf.constant(0.1, shape=[n]))\nnn1 = tf.matmul(x, W1) + b1\nW2 = tf.Variable(tf.truncated_normal([n, 10], stddev=0.1))\nb2 = tf.Variable(tf.constant(0.1, shape=[10]))\nnn2 = tf.matmul(nn1, W2) + b2\ny = tf.nn.softmax(nn2)\ny_ = tf.placeholder(tf.float32, [None, 10])\ncross_entropy = -tf.reduce_sum(y_*tf.log(y))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\nfor i in range(1000):\n  batch_xs, batch_ys = mnist.train.next_batch(1)\n  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n```\n\nNow, if `n <= 22000`, then the network runs fine. However, if `n >= 23000`, I get the following error:\n\n```\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state\nW tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n```\n\nHowever, according to my calculations, there should not be a problem with the memory. The number of parameters in the network is as follows:\n\n```\nFirst layer weights: 784 * n\nFirst layer biases: n\nSecond layer weights: 10 * n\nSecond layer biases: 10\nTotal: 795n + 10\n```\n\nSo with `n = 23000`, and using `float32` data, the total memory required for the network should therefore be 73.1 MB.\n\nNow, my graphics card is the NVIDIA GeForce GTX 780 Ti, which has 3072 MB of memory. After finding my graphics card, Tensor Flow prints out the following:\n\n```\nTotal memory: 3.00GiB\nFree memory: 2.32GiB\n```\n\nSo, there should be around 2.32 GB memory available, which is far greater than the 73.1 MB calculated above. The minibatch size is 1, so this has minimal effect. Why am I getting this error?\n\n---\n\nI have also now tried this on my laptop, which has an NVIDIA GeForce GTX 880M GPU. Here, Tensor Flow reads out `Free memory: 7.60GiB`. Running the same code as above, it gives me a memory error at around `n = 700,000`, which is equivalent to 2.2 GB. This makes a bit more sense, and is significantly higher than the point at which my PC code breaks. However, it is still puzzling to me why it does not break closer to the 7.6 GB mark.\n\n---\n\nThe full output from Tensor Flow whilst running the above code on my PC, with `n = 23000`, is:\n\n```\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 780 Ti\nmajor: 3 minor: 5 memoryClockRate (GHz) 1.0455\npciBusID 0000:01:00.0\nTotal memory: 3.00GiB\nFree memory: 2.32GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 2.03GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb04720000 extends to 0xb86295000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (256):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (131072):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (524288):    Total Chunks: 2, Chunks in use: 0 819.0KiB allocated for chunks. 390.6KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (134217728):     Total Chunks: 1, Chunks in use: 0 68.79MiB allocated for chunks. 29.91MiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (536870912):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1073741824):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2147483648):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4294967296):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:450] Bin for 877.38MiB was 1.00GiB, Chunk State: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d239400 of size 80128\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7600 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d24cd00 of size 438528\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a302800 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15d58800 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736b00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7f00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15e39200 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c16b00 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c61500 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736d00 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8100 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c4ad00 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736a00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7e00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7900 of size 400128\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720200 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736c00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7600 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3300 of size 1810570496\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1c0c00 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c00300 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7800 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720100 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7700 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7400 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb11781700 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77d00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77e00 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:468]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 16 Chunks of size 256 totalling 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 80128 totalling 78.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 92160 totalling 450.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 400128 totalling 390.8KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 438528 totalling 428.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 4 Chunks of size 920064 totalling 3.51MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 72128000 totalling 343.93MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 1810570496 totalling 1.69GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:475] Sum Total of in-use chunks: 2.03GiB\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state\nW tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x50f40e0 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_97_range_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: Cast/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_96_Cast\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py\", line 232, in <module>\n    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 315, in run\n    return self._run(None, fetches, feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 511, in _run\n    feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _do_run\n    target_list)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 586, in _do_call\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_97_range_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'add', defined at:\n  File \"/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py\", line 215, in <module>\n    nn1 = tf.matmul(x, W1) + b1\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 468, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 44, in add\n    return _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()\n```\n"}