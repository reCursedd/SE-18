{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3754", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3754/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3754/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3754/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3754", "id": 170751309, "node_id": "MDU6SXNzdWUxNzA3NTEzMDk=", "number": 3754, "title": "Unresolved RNN performance issue", "user": {"login": "msevrens", "id": 1441846, "node_id": "MDQ6VXNlcjE0NDE4NDY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1441846?v=4", "gravatar_id": "", "url": "https://api.github.com/users/msevrens", "html_url": "https://github.com/msevrens", "followers_url": "https://api.github.com/users/msevrens/followers", "following_url": "https://api.github.com/users/msevrens/following{/other_user}", "gists_url": "https://api.github.com/users/msevrens/gists{/gist_id}", "starred_url": "https://api.github.com/users/msevrens/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/msevrens/subscriptions", "organizations_url": "https://api.github.com/users/msevrens/orgs", "repos_url": "https://api.github.com/users/msevrens/repos", "events_url": "https://api.github.com/users/msevrens/events{/privacy}", "received_events_url": "https://api.github.com/users/msevrens/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-08-11T21:26:03Z", "updated_at": "2016-08-11T21:28:10Z", "closed_at": "2016-08-11T21:27:20Z", "author_association": "NONE", "body_html": "<p>My previous issue was closed without resolution: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"170529634\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3738\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3738/hovercard?comment_id=239050102&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/3738#issuecomment-239050102\">#3738 (comment)</a></p>\n<p>The tf RNN approach of running up to the maximum length seems to be fundamentally flawed compared to the pycnn approach.</p>\n<p>Even when only calling the LSTM cell on the relevant steps like below the performance issue persists:</p>\n<pre><code>flat_state = nest.flatten(state)\n    flat_zero_output = nest.flatten(zero_output)\n\n    def select_relevant_state(state, mask):\n        c = tf.boolean_mask(state[0], mask)\n        h = tf.boolean_mask(state[1], mask)\n        return (c, h)\n\n    # Function to Perform at Each Time Step\n    def time_step(time, output_ta, state):\n\n        mask = (time &lt; sequence_length)\n        indices = tf.squeeze(tf.to_int32(tf.where(mask)))\n        invert_indices = tf.squeeze(tf.to_int32(tf.where(invert_mask)))\n        invert_indices = tf.to_int32(tf.where(invert_mask))\n        input_t = tuple(ta.read(time) for ta in input_ta)\n\n        # Restore Shape Information\n        for input_, shape in zip(input_t, inputs_got_shape):\n            input_.set_shape(shape[1:])\n\n        input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)\n\n        # Select Only Relevant at This Time Step\n        input_t = tf.boolean_mask(input_t, mask)\n        state = select_relevant_state(state, mask)\n        call_cell = lambda: cell(input_t, state)\n\n        # Call Cell\n        (output, new_state) = call_cell()\n\n        # Fill Unprocessed Steps\n        filler_output = tf.boolean_mask(zero_output, invert_mask)\n        filler_state = select_relevant_state(state, invert_mask)\n\n        output = tf.dynamic_stitch([indices, invert_indices], [output, filler_output])\n        new_state_c = tf.dynamic_stitch([indices, invert_indices], [new_state[0], filler_state[0]])\n        new_state_h = tf.dynamic_stitch([indices, invert_indices], [new_state[1], filler_state[1]])\n        new_state = tf.pack([new_state_c, new_state_h], axis=0)\n\n        # Pack State if Using State Tuples\n        output = nest.flatten(output)\n\n        output_ta = tuple(ta.write(time, out) for ta, out in zip(output_ta, output))\n\n        return (time + 1, output_ta, new_state)\n</code></pre>\n<p>Bucketing is not a reasonable approach in this situation as a LSTM is applied to each token and then a higher level LSTM is applied across combined word and character embeddings for actual tagging. This means that the only available inputs at each training step are the tokens in the sentence and therefore bucketing is not possible.</p>", "body_text": "My previous issue was closed without resolution: #3738 (comment)\nThe tf RNN approach of running up to the maximum length seems to be fundamentally flawed compared to the pycnn approach.\nEven when only calling the LSTM cell on the relevant steps like below the performance issue persists:\nflat_state = nest.flatten(state)\n    flat_zero_output = nest.flatten(zero_output)\n\n    def select_relevant_state(state, mask):\n        c = tf.boolean_mask(state[0], mask)\n        h = tf.boolean_mask(state[1], mask)\n        return (c, h)\n\n    # Function to Perform at Each Time Step\n    def time_step(time, output_ta, state):\n\n        mask = (time < sequence_length)\n        indices = tf.squeeze(tf.to_int32(tf.where(mask)))\n        invert_indices = tf.squeeze(tf.to_int32(tf.where(invert_mask)))\n        invert_indices = tf.to_int32(tf.where(invert_mask))\n        input_t = tuple(ta.read(time) for ta in input_ta)\n\n        # Restore Shape Information\n        for input_, shape in zip(input_t, inputs_got_shape):\n            input_.set_shape(shape[1:])\n\n        input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)\n\n        # Select Only Relevant at This Time Step\n        input_t = tf.boolean_mask(input_t, mask)\n        state = select_relevant_state(state, mask)\n        call_cell = lambda: cell(input_t, state)\n\n        # Call Cell\n        (output, new_state) = call_cell()\n\n        # Fill Unprocessed Steps\n        filler_output = tf.boolean_mask(zero_output, invert_mask)\n        filler_state = select_relevant_state(state, invert_mask)\n\n        output = tf.dynamic_stitch([indices, invert_indices], [output, filler_output])\n        new_state_c = tf.dynamic_stitch([indices, invert_indices], [new_state[0], filler_state[0]])\n        new_state_h = tf.dynamic_stitch([indices, invert_indices], [new_state[1], filler_state[1]])\n        new_state = tf.pack([new_state_c, new_state_h], axis=0)\n\n        # Pack State if Using State Tuples\n        output = nest.flatten(output)\n\n        output_ta = tuple(ta.write(time, out) for ta, out in zip(output_ta, output))\n\n        return (time + 1, output_ta, new_state)\n\nBucketing is not a reasonable approach in this situation as a LSTM is applied to each token and then a higher level LSTM is applied across combined word and character embeddings for actual tagging. This means that the only available inputs at each training step are the tokens in the sentence and therefore bucketing is not possible.", "body": "My previous issue was closed without resolution: https://github.com/tensorflow/tensorflow/issues/3738#issuecomment-239050102\n\nThe tf RNN approach of running up to the maximum length seems to be fundamentally flawed compared to the pycnn approach. \n\nEven when only calling the LSTM cell on the relevant steps like below the performance issue persists:\n\n```\nflat_state = nest.flatten(state)\n    flat_zero_output = nest.flatten(zero_output)\n\n    def select_relevant_state(state, mask):\n        c = tf.boolean_mask(state[0], mask)\n        h = tf.boolean_mask(state[1], mask)\n        return (c, h)\n\n    # Function to Perform at Each Time Step\n    def time_step(time, output_ta, state):\n\n        mask = (time < sequence_length)\n        indices = tf.squeeze(tf.to_int32(tf.where(mask)))\n        invert_indices = tf.squeeze(tf.to_int32(tf.where(invert_mask)))\n        invert_indices = tf.to_int32(tf.where(invert_mask))\n        input_t = tuple(ta.read(time) for ta in input_ta)\n\n        # Restore Shape Information\n        for input_, shape in zip(input_t, inputs_got_shape):\n            input_.set_shape(shape[1:])\n\n        input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)\n\n        # Select Only Relevant at This Time Step\n        input_t = tf.boolean_mask(input_t, mask)\n        state = select_relevant_state(state, mask)\n        call_cell = lambda: cell(input_t, state)\n\n        # Call Cell\n        (output, new_state) = call_cell()\n\n        # Fill Unprocessed Steps\n        filler_output = tf.boolean_mask(zero_output, invert_mask)\n        filler_state = select_relevant_state(state, invert_mask)\n\n        output = tf.dynamic_stitch([indices, invert_indices], [output, filler_output])\n        new_state_c = tf.dynamic_stitch([indices, invert_indices], [new_state[0], filler_state[0]])\n        new_state_h = tf.dynamic_stitch([indices, invert_indices], [new_state[1], filler_state[1]])\n        new_state = tf.pack([new_state_c, new_state_h], axis=0)\n\n        # Pack State if Using State Tuples\n        output = nest.flatten(output)\n\n        output_ta = tuple(ta.write(time, out) for ta, out in zip(output_ta, output))\n\n        return (time + 1, output_ta, new_state)\n```\n\nBucketing is not a reasonable approach in this situation as a LSTM is applied to each token and then a higher level LSTM is applied across combined word and character embeddings for actual tagging. This means that the only available inputs at each training step are the tokens in the sentence and therefore bucketing is not possible.\n"}