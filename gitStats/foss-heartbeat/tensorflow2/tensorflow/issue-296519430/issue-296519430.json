{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16955", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16955/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16955/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16955/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16955", "id": 296519430, "node_id": "MDU6SXNzdWUyOTY1MTk0MzA=", "number": 16955, "title": "Row wise lookup table in Tensorflow", "user": {"login": "abhishek-sehgal", "id": 9486817, "node_id": "MDQ6VXNlcjk0ODY4MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/9486817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhishek-sehgal", "html_url": "https://github.com/abhishek-sehgal", "followers_url": "https://api.github.com/users/abhishek-sehgal/followers", "following_url": "https://api.github.com/users/abhishek-sehgal/following{/other_user}", "gists_url": "https://api.github.com/users/abhishek-sehgal/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhishek-sehgal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhishek-sehgal/subscriptions", "organizations_url": "https://api.github.com/users/abhishek-sehgal/orgs", "repos_url": "https://api.github.com/users/abhishek-sehgal/repos", "events_url": "https://api.github.com/users/abhishek-sehgal/events{/privacy}", "received_events_url": "https://api.github.com/users/abhishek-sehgal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-12T20:50:26Z", "updated_at": "2018-02-18T19:58:06Z", "closed_at": "2018-02-18T19:58:06Z", "author_association": "NONE", "body_html": "<p>Currently I have a matrix in which each row is a lookup table. Corresponding to it I have a coded matrix with the same number of rows as the lookup table. e.g.</p>\n<blockquote>\n<p>LookupTable (matrix size 100, 32)</p>\n</blockquote>\n<blockquote>\n<p>CodedMatrix (matrix size 100, 1000)</p>\n</blockquote>\n<p>So the lookup table values match to the corresponding row of the coded matrix. The code matrix contains numbers from 0 to 31 which have a corresponding value in the Lookup table for that specific row.</p>\n<p>The final output of this should be</p>\n<blockquote>\n<p>DecodedMatrix(matrix size 100, 1000)</p>\n</blockquote>\n<p>In which each value of the row is replaced with it's corresponding lookup output.</p>\n<p>Currently in numpy I use a for loop, because at the end I sum up the decoded matrix along the row axis for the final output. The code looks like this</p>\n<pre><code>   out = sum([C[L] for C,L in zip(CodedMatrix, LookupTable)])\n</code></pre>\n<p>which is a still inefficient. But in Tensorflow I use</p>\n<pre><code> nRows = tf.constant(100, name=\"nRows\")\n n     = tf.Variable(tf.constant(0))\n\n def cond(n, out):\n     return n &lt; nRows\n\n def body(n, out):  \n     out = out + tf.gather(LookupTable[m,:], CodedMatrix[m,:])\n     return n+1, out\n\n out = tf.while_loop(cond, body, [n, out])[1]\n</code></pre>\n<p>This execution takes a lot of time, because each time a new tensor is created and using the loop isn't very efficient.</p>\n<p>Is there a way to do this without using while loop? Does tf.gather have any setup to do lookup like this?</p>\n<p>Have I written custom code - Yes<br>\nOS Platform and Distribution - Mac OS X High Sierra<br>\nTensorFlow installed from - Source<br>\nTensorFlow version - 1.5.0-rc0<br>\nBazel version - 0.5.4<br>\nCUDA/cuDNN version - N/A<br>\nGPU model and memory - N/A<br>\nExact command to reproduce - Provided aboce</p>", "body_text": "Currently I have a matrix in which each row is a lookup table. Corresponding to it I have a coded matrix with the same number of rows as the lookup table. e.g.\n\nLookupTable (matrix size 100, 32)\n\n\nCodedMatrix (matrix size 100, 1000)\n\nSo the lookup table values match to the corresponding row of the coded matrix. The code matrix contains numbers from 0 to 31 which have a corresponding value in the Lookup table for that specific row.\nThe final output of this should be\n\nDecodedMatrix(matrix size 100, 1000)\n\nIn which each value of the row is replaced with it's corresponding lookup output.\nCurrently in numpy I use a for loop, because at the end I sum up the decoded matrix along the row axis for the final output. The code looks like this\n   out = sum([C[L] for C,L in zip(CodedMatrix, LookupTable)])\n\nwhich is a still inefficient. But in Tensorflow I use\n nRows = tf.constant(100, name=\"nRows\")\n n     = tf.Variable(tf.constant(0))\n\n def cond(n, out):\n     return n < nRows\n\n def body(n, out):  \n     out = out + tf.gather(LookupTable[m,:], CodedMatrix[m,:])\n     return n+1, out\n\n out = tf.while_loop(cond, body, [n, out])[1]\n\nThis execution takes a lot of time, because each time a new tensor is created and using the loop isn't very efficient.\nIs there a way to do this without using while loop? Does tf.gather have any setup to do lookup like this?\nHave I written custom code - Yes\nOS Platform and Distribution - Mac OS X High Sierra\nTensorFlow installed from - Source\nTensorFlow version - 1.5.0-rc0\nBazel version - 0.5.4\nCUDA/cuDNN version - N/A\nGPU model and memory - N/A\nExact command to reproduce - Provided aboce", "body": "Currently I have a matrix in which each row is a lookup table. Corresponding to it I have a coded matrix with the same number of rows as the lookup table. e.g.\r\n\r\n> LookupTable (matrix size 100, 32)\r\n\r\n> CodedMatrix (matrix size 100, 1000)\r\n\r\nSo the lookup table values match to the corresponding row of the coded matrix. The code matrix contains numbers from 0 to 31 which have a corresponding value in the Lookup table for that specific row.\r\n\r\nThe final output of this should be \r\n\r\n> DecodedMatrix(matrix size 100, 1000)\r\n\r\nIn which each value of the row is replaced with it's corresponding lookup output.\r\n\r\nCurrently in numpy I use a for loop, because at the end I sum up the decoded matrix along the row axis for the final output. The code looks like this\r\n\r\n       out = sum([C[L] for C,L in zip(CodedMatrix, LookupTable)])\r\n\r\nwhich is a still inefficient. But in Tensorflow I use\r\n\r\n     nRows = tf.constant(100, name=\"nRows\")\r\n     n     = tf.Variable(tf.constant(0))\r\n\r\n     def cond(n, out):\r\n         return n < nRows\r\n\r\n     def body(n, out):  \r\n         out = out + tf.gather(LookupTable[m,:], CodedMatrix[m,:])\r\n         return n+1, out\r\n\r\n     out = tf.while_loop(cond, body, [n, out])[1]\r\n\r\nThis execution takes a lot of time, because each time a new tensor is created and using the loop isn't very efficient.\r\n\r\nIs there a way to do this without using while loop? Does tf.gather have any setup to do lookup like this?\r\n\r\nHave I written custom code - Yes\r\nOS Platform and Distribution - Mac OS X High Sierra\r\nTensorFlow installed from - Source\r\nTensorFlow version - 1.5.0-rc0\r\nBazel version - 0.5.4\r\nCUDA/cuDNN version - N/A\r\nGPU model and memory - N/A\r\nExact command to reproduce - Provided aboce"}