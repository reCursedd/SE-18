{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/344972648", "html_url": "https://github.com/tensorflow/tensorflow/issues/14496#issuecomment-344972648", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14496", "id": 344972648, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NDk3MjY0OA==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-16T16:12:22Z", "updated_at": "2017-11-16T16:12:22Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">In my testing I had the best results with the following settings, cut and\npasted from the document\n&lt;<a href=\"https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu&gt;I\">https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu&gt;I</a>\nwrote.  It can be a different for different models but for resnet and\ninception training this worked well and even for inference.  Intel\nmentioned that slightly higher levels of inter_op might work but my\nguidelines as # of \"sockets\" was reasonable.  If someone gets data for\nother models I am happy to try and find a way to share the info widely.\n\nThere are models and hardware platforms that benefit from different\nsettings. Each variable that impacts performance is discussed below.\n\n   -\n\n   *KMP_BLOCKTIME*: The MKL default is 200ms, which was not optimal in our\n   testing. 0 (0ms) was a good default for CNN based models that were tested.\n   The best performance for AlexNex was achieved at 30ms and both GoogleNet\n   and VGG11 performed best set at 1ms.\n   -\n\n   *KMP_AFFINITY*: The recommended setting is\n   granularity=fine,verbose,compact,1,0.\n   -\n\n   *OMP_NUM_THREADS*: This defaults to the number of physical cores.\n   Adjusting this parameter beyond matching the number of cores can have an\n   impact when using Intel\u00ae Xeon Phi\u2122 (Knights Landing) for some\nmodels. SeeTensorFlow*\n   Optimizations on Modern Intel\u00ae Architecture\n   &lt;<a href=\"https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture\">https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture</a>&gt;\nfor\n   optimal settings.\n   -\n\n   *intra_op_parallelism_threads*: Setting this equal to the number of\n*physical\n   cores* is recommended. Setting the value to 0, which is the default and\n   will result in the value being set to the number of logical cores, is an\n   option to try for some architectures. This value and OMP_NUM_THREADS should\n   be equal.\n   -\n\n   *inter_op_parallelism_threads*: Setting this equal to the number of\n   sockets is recommended. Setting the value to 0, which is the default,\n   results in the value being set to the number of logical cores.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Thu, Nov 16, 2017 at 6:57 AM, georgh ***@***.***&gt; wrote:\n I created two timelines for a very small run, but I am not sure if they\n contain useful informations.\n I tried to create a timeline for a bigger run, but the resulting file is\n 1.3GB big and chrome does not show any information if I try to open it.\n\n timelines.zip\n &lt;<a href=\"https://github.com/tensorflow/tensorflow/files/1478931/timelines.zip\">https://github.com/tensorflow/tensorflow/files/1478931/timelines.zip</a>&gt;\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"273232010\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/14496\" href=\"https://github.com/tensorflow/tensorflow/issues/14496#issuecomment-344946223\">#14496 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AWZeshN8JsICk3B_IfU-v9WbQsIJZxkuks5s3E1WgaJpZM4Qa4-L\">https://github.com/notifications/unsubscribe-auth/AWZeshN8JsICk3B_IfU-v9WbQsIJZxkuks5s3E1WgaJpZM4Qa4-L</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "In my testing I had the best results with the following settings, cut and\npasted from the document\n<https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu>I\nwrote.  It can be a different for different models but for resnet and\ninception training this worked well and even for inference.  Intel\nmentioned that slightly higher levels of inter_op might work but my\nguidelines as # of \"sockets\" was reasonable.  If someone gets data for\nother models I am happy to try and find a way to share the info widely.\n\nThere are models and hardware platforms that benefit from different\nsettings. Each variable that impacts performance is discussed below.\n\n   -\n\n   *KMP_BLOCKTIME*: The MKL default is 200ms, which was not optimal in our\n   testing. 0 (0ms) was a good default for CNN based models that were tested.\n   The best performance for AlexNex was achieved at 30ms and both GoogleNet\n   and VGG11 performed best set at 1ms.\n   -\n\n   *KMP_AFFINITY*: The recommended setting is\n   granularity=fine,verbose,compact,1,0.\n   -\n\n   *OMP_NUM_THREADS*: This defaults to the number of physical cores.\n   Adjusting this parameter beyond matching the number of cores can have an\n   impact when using Intel\u00ae Xeon Phi\u2122 (Knights Landing) for some\nmodels. SeeTensorFlow*\n   Optimizations on Modern Intel\u00ae Architecture\n   <https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture>\nfor\n   optimal settings.\n   -\n\n   *intra_op_parallelism_threads*: Setting this equal to the number of\n*physical\n   cores* is recommended. Setting the value to 0, which is the default and\n   will result in the value being set to the number of logical cores, is an\n   option to try for some architectures. This value and OMP_NUM_THREADS should\n   be equal.\n   -\n\n   *inter_op_parallelism_threads*: Setting this equal to the number of\n   sockets is recommended. Setting the value to 0, which is the default,\n   results in the value being set to the number of logical cores.\n\u2026\nOn Thu, Nov 16, 2017 at 6:57 AM, georgh ***@***.***> wrote:\n I created two timelines for a very small run, but I am not sure if they\n contain useful informations.\n I tried to create a timeline for a bigger run, but the resulting file is\n 1.3GB big and chrome does not show any information if I try to open it.\n\n timelines.zip\n <https://github.com/tensorflow/tensorflow/files/1478931/timelines.zip>\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#14496 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AWZeshN8JsICk3B_IfU-v9WbQsIJZxkuks5s3E1WgaJpZM4Qa4-L>\n .", "body": "In my testing I had the best results with the following settings, cut and\npasted from the document\n<https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu>I\nwrote.  It can be a different for different models but for resnet and\ninception training this worked well and even for inference.  Intel\nmentioned that slightly higher levels of inter_op might work but my\nguidelines as # of \"sockets\" was reasonable.  If someone gets data for\nother models I am happy to try and find a way to share the info widely.\n\nThere are models and hardware platforms that benefit from different\nsettings. Each variable that impacts performance is discussed below.\n\n   -\n\n   *KMP_BLOCKTIME*: The MKL default is 200ms, which was not optimal in our\n   testing. 0 (0ms) was a good default for CNN based models that were tested.\n   The best performance for AlexNex was achieved at 30ms and both GoogleNet\n   and VGG11 performed best set at 1ms.\n   -\n\n   *KMP_AFFINITY*: The recommended setting is\n   granularity=fine,verbose,compact,1,0.\n   -\n\n   *OMP_NUM_THREADS*: This defaults to the number of physical cores.\n   Adjusting this parameter beyond matching the number of cores can have an\n   impact when using Intel\u00ae Xeon Phi\u2122 (Knights Landing) for some\nmodels. SeeTensorFlow*\n   Optimizations on Modern Intel\u00ae Architecture\n   <https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture>\nfor\n   optimal settings.\n   -\n\n   *intra_op_parallelism_threads*: Setting this equal to the number of\n*physical\n   cores* is recommended. Setting the value to 0, which is the default and\n   will result in the value being set to the number of logical cores, is an\n   option to try for some architectures. This value and OMP_NUM_THREADS should\n   be equal.\n   -\n\n   *inter_op_parallelism_threads*: Setting this equal to the number of\n   sockets is recommended. Setting the value to 0, which is the default,\n   results in the value being set to the number of logical cores.\n\n\nOn Thu, Nov 16, 2017 at 6:57 AM, georgh <notifications@github.com> wrote:\n\n> I created two timelines for a very small run, but I am not sure if they\n> contain useful informations.\n> I tried to create a timeline for a bigger run, but the resulting file is\n> 1.3GB big and chrome does not show any information if I try to open it.\n>\n> timelines.zip\n> <https://github.com/tensorflow/tensorflow/files/1478931/timelines.zip>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14496#issuecomment-344946223>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AWZeshN8JsICk3B_IfU-v9WbQsIJZxkuks5s3E1WgaJpZM4Qa4-L>\n> .\n>\n"}