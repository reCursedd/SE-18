{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18705", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18705/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18705/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18705/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18705", "id": 316026364, "node_id": "MDU6SXNzdWUzMTYwMjYzNjQ=", "number": 18705, "title": "dynamic_rnn is much slower then manually using while_loop", "user": {"login": "chrisc36", "id": 1463280, "node_id": "MDQ6VXNlcjE0NjMyODA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1463280?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chrisc36", "html_url": "https://github.com/chrisc36", "followers_url": "https://api.github.com/users/chrisc36/followers", "following_url": "https://api.github.com/users/chrisc36/following{/other_user}", "gists_url": "https://api.github.com/users/chrisc36/gists{/gist_id}", "starred_url": "https://api.github.com/users/chrisc36/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chrisc36/subscriptions", "organizations_url": "https://api.github.com/users/chrisc36/orgs", "repos_url": "https://api.github.com/users/chrisc36/repos", "events_url": "https://api.github.com/users/chrisc36/events{/privacy}", "received_events_url": "https://api.github.com/users/chrisc36/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-04-19T20:20:53Z", "updated_at": "2018-11-17T12:09:56Z", "closed_at": "2018-09-04T13:33:22Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.6.0-rc1</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/</li>\n<li><strong>GPU model and memory</strong>: NVIDIA 1080 TI</li>\n<li><strong>Exact command to reproduce</strong>: (see below)</li>\n</ul>\n<p><code>python benchmark_lstm.py -d 512 -b 60 -t 380 -n 512  -w 20 -i 40</code></p>\n<h3>Describe the problem</h3>\n<p>Tensorflow <code>dynamic_rnn</code> is over twice as slow as <code>static_rnn</code> and using a simple application of <code>tf.while_loop</code>.</p>\n<p>I noticed while doing some profiling that <code>dynamic_rnn</code> was much slower than <code>static_rnn</code>. At first I assumed this was because of something inherently slow about using dynamic length, but then I also noticed naively using <code>tf.while_loop</code> with rnn cell was also much faster and performed comparably to <code>static_rnn</code>.</p>\n<p>I am not sure if there is some special cases <code>dynamic_rnn</code> needs to handle that causes it to be slower, or if there something not equivalent between my <code>while_loop</code> and the <code>dynamic_rnn</code> that I am missing. However a 2x performance change is a big deal and I wanted to report this just in case it points to a possible implementation improvement.</p>\n<h3>Source code / logs</h3>\n<p>Benchmark used:</p>\n<pre><code>import tensorflow as tf\nimport argparse\nimport numpy as np\n\nfrom tqdm import tqdm\n\n\ndef while_loop_rnn(rnn_cell, x):\n    initial_state = rnn_cell.zero_state(tf.shape(x)[0], tf.float32)\n    x_t = tf.transpose(x, [1, 0, 2])\n\n    def compute(i, cur_state, out):\n        output, cur_state = rnn_cell(x_t[i], cur_state)\n        return i+1, cur_state, out.write(i, output)\n\n    time = tf.shape(x_t)[0]\n\n    _, cur_state, out = tf.while_loop(\n        lambda a, b, c: a &lt; time,\n        compute,\n        (0, initial_state, tf.TensorArray(tf.float32, time))\n    )\n    return tf.transpose(out.stack(), [1, 0, 2]), cur_state\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-d\", \"--dim\", required=True, type=int)\n    parser.add_argument(\"-b\", \"--batch\", required=True, type=int)\n    parser.add_argument(\"-t\", \"--time\", required=True, type=int)\n    parser.add_argument(\"-n\", \"--hidden\", required=True, type=int)\n    parser.add_argument(\"-w\", \"--warm_up\", type=int, default=20)\n    parser.add_argument(\"-i\", \"--iterations\", type=int, default=20)\n    args = parser.parse_args()\n\n    cell = tf.nn.rnn_cell.LSTMCell(args.hidden)\n    x = tf.constant(np.random.normal(scale=2, size=(args.batch, args.time, args.dim)).astype(np.float32))\n\n    dynamic = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)[0]\n    static = tf.stack(tf.nn.static_rnn(cell, tf.unstack(x, args.time, axis=1), dtype=tf.float32)[0], axis=1)\n    while_loop = while_loop_rnn(cell, x)[0]\n\n    sess = tf.Session()\n    sess.run(tf.global_variables_initializer())\n\n    print(\"Checking equivalence...\")\n    dynamic_out, static_out, while_out = sess.run([dynamic, static, while_loop])\n\n    if not np.allclose(dynamic_out, static_out):\n        raise RuntimeError()\n    if not np.allclose(dynamic_out, while_out):\n        raise RuntimeError()\n\n    for name, op in zip([\"dynamic\", \"static\", \"while\"], [dynamic, static, while_loop]):\n        print(\"Testing %s\" % name)\n        print(\"Warming up...\")\n        for _ in range(args.warm_up):\n            sess.run(op)\n\n        for _ in tqdm(range(args.iterations), \"run\", ncols=80):\n            sess.run(op)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.6.0-rc1\nPython version: 3.5.2\nBazel version (if compiling from source): 0.11.1\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: 9.0/\nGPU model and memory: NVIDIA 1080 TI\nExact command to reproduce: (see below)\n\npython benchmark_lstm.py -d 512 -b 60 -t 380 -n 512  -w 20 -i 40\nDescribe the problem\nTensorflow dynamic_rnn is over twice as slow as static_rnn and using a simple application of tf.while_loop.\nI noticed while doing some profiling that dynamic_rnn was much slower than static_rnn. At first I assumed this was because of something inherently slow about using dynamic length, but then I also noticed naively using tf.while_loop with rnn cell was also much faster and performed comparably to static_rnn.\nI am not sure if there is some special cases dynamic_rnn needs to handle that causes it to be slower, or if there something not equivalent between my while_loop and the dynamic_rnn that I am missing. However a 2x performance change is a big deal and I wanted to report this just in case it points to a possible implementation improvement.\nSource code / logs\nBenchmark used:\nimport tensorflow as tf\nimport argparse\nimport numpy as np\n\nfrom tqdm import tqdm\n\n\ndef while_loop_rnn(rnn_cell, x):\n    initial_state = rnn_cell.zero_state(tf.shape(x)[0], tf.float32)\n    x_t = tf.transpose(x, [1, 0, 2])\n\n    def compute(i, cur_state, out):\n        output, cur_state = rnn_cell(x_t[i], cur_state)\n        return i+1, cur_state, out.write(i, output)\n\n    time = tf.shape(x_t)[0]\n\n    _, cur_state, out = tf.while_loop(\n        lambda a, b, c: a < time,\n        compute,\n        (0, initial_state, tf.TensorArray(tf.float32, time))\n    )\n    return tf.transpose(out.stack(), [1, 0, 2]), cur_state\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-d\", \"--dim\", required=True, type=int)\n    parser.add_argument(\"-b\", \"--batch\", required=True, type=int)\n    parser.add_argument(\"-t\", \"--time\", required=True, type=int)\n    parser.add_argument(\"-n\", \"--hidden\", required=True, type=int)\n    parser.add_argument(\"-w\", \"--warm_up\", type=int, default=20)\n    parser.add_argument(\"-i\", \"--iterations\", type=int, default=20)\n    args = parser.parse_args()\n\n    cell = tf.nn.rnn_cell.LSTMCell(args.hidden)\n    x = tf.constant(np.random.normal(scale=2, size=(args.batch, args.time, args.dim)).astype(np.float32))\n\n    dynamic = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)[0]\n    static = tf.stack(tf.nn.static_rnn(cell, tf.unstack(x, args.time, axis=1), dtype=tf.float32)[0], axis=1)\n    while_loop = while_loop_rnn(cell, x)[0]\n\n    sess = tf.Session()\n    sess.run(tf.global_variables_initializer())\n\n    print(\"Checking equivalence...\")\n    dynamic_out, static_out, while_out = sess.run([dynamic, static, while_loop])\n\n    if not np.allclose(dynamic_out, static_out):\n        raise RuntimeError()\n    if not np.allclose(dynamic_out, while_out):\n        raise RuntimeError()\n\n    for name, op in zip([\"dynamic\", \"static\", \"while\"], [dynamic, static, while_loop]):\n        print(\"Testing %s\" % name)\n        print(\"Warming up...\")\n        for _ in range(args.warm_up):\n            sess.run(op)\n\n        for _ in tqdm(range(args.iterations), \"run\", ncols=80):\n            sess.run(op)\n\nif __name__ == \"__main__\":\n    main()", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.6.0-rc1\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0/\r\n- **GPU model and memory**: NVIDIA 1080 TI\r\n- **Exact command to reproduce**: (see below)\r\n\r\n``python benchmark_lstm.py -d 512 -b 60 -t 380 -n 512  -w 20 -i 40``\r\n\r\n### Describe the problem\r\nTensorflow `dynamic_rnn` is over twice as slow as `static_rnn` and using a simple application of `tf.while_loop`.\r\n\r\nI noticed while doing some profiling that `dynamic_rnn` was much slower than `static_rnn`. At first I assumed this was because of something inherently slow about using dynamic length, but then I also noticed naively using `tf.while_loop` with rnn cell was also much faster and performed comparably to `static_rnn`.\r\n\r\nI am not sure if there is some special cases `dynamic_rnn` needs to handle that causes it to be slower, or if there something not equivalent between my `while_loop` and the `dynamic_rnn` that I am missing. However a 2x performance change is a big deal and I wanted to report this just in case it points to a possible implementation improvement.\r\n\r\n### Source code / logs\r\nBenchmark used:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport argparse\r\nimport numpy as np\r\n\r\nfrom tqdm import tqdm\r\n\r\n\r\ndef while_loop_rnn(rnn_cell, x):\r\n    initial_state = rnn_cell.zero_state(tf.shape(x)[0], tf.float32)\r\n    x_t = tf.transpose(x, [1, 0, 2])\r\n\r\n    def compute(i, cur_state, out):\r\n        output, cur_state = rnn_cell(x_t[i], cur_state)\r\n        return i+1, cur_state, out.write(i, output)\r\n\r\n    time = tf.shape(x_t)[0]\r\n\r\n    _, cur_state, out = tf.while_loop(\r\n        lambda a, b, c: a < time,\r\n        compute,\r\n        (0, initial_state, tf.TensorArray(tf.float32, time))\r\n    )\r\n    return tf.transpose(out.stack(), [1, 0, 2]), cur_state\r\n\r\n\r\ndef main():\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"-d\", \"--dim\", required=True, type=int)\r\n    parser.add_argument(\"-b\", \"--batch\", required=True, type=int)\r\n    parser.add_argument(\"-t\", \"--time\", required=True, type=int)\r\n    parser.add_argument(\"-n\", \"--hidden\", required=True, type=int)\r\n    parser.add_argument(\"-w\", \"--warm_up\", type=int, default=20)\r\n    parser.add_argument(\"-i\", \"--iterations\", type=int, default=20)\r\n    args = parser.parse_args()\r\n\r\n    cell = tf.nn.rnn_cell.LSTMCell(args.hidden)\r\n    x = tf.constant(np.random.normal(scale=2, size=(args.batch, args.time, args.dim)).astype(np.float32))\r\n\r\n    dynamic = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)[0]\r\n    static = tf.stack(tf.nn.static_rnn(cell, tf.unstack(x, args.time, axis=1), dtype=tf.float32)[0], axis=1)\r\n    while_loop = while_loop_rnn(cell, x)[0]\r\n\r\n    sess = tf.Session()\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    print(\"Checking equivalence...\")\r\n    dynamic_out, static_out, while_out = sess.run([dynamic, static, while_loop])\r\n\r\n    if not np.allclose(dynamic_out, static_out):\r\n        raise RuntimeError()\r\n    if not np.allclose(dynamic_out, while_out):\r\n        raise RuntimeError()\r\n\r\n    for name, op in zip([\"dynamic\", \"static\", \"while\"], [dynamic, static, while_loop]):\r\n        print(\"Testing %s\" % name)\r\n        print(\"Warming up...\")\r\n        for _ in range(args.warm_up):\r\n            sess.run(op)\r\n\r\n        for _ in tqdm(range(args.iterations), \"run\", ncols=80):\r\n            sess.run(op)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n"}