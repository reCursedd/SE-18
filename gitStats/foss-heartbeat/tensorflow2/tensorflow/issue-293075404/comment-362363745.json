{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/362363745", "html_url": "https://github.com/tensorflow/tensorflow/issues/16617#issuecomment-362363745", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16617", "id": 362363745, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjM2Mzc0NQ==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-01T18:47:49Z", "updated_at": "2018-02-01T18:47:49Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8370113\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xinmei9322\">@xinmei9322</a>, <code>tf.device()</code> blocks can be used to force operations on a particular device, even CPU. Also, <code>tf.tensordot</code> is not a primitive TensorFlow operation (in that it is a Python function that composes other existing TensorFlow operations). Note that operations inside a <code>tf.device()</code> block are telling TensorFlow \"these operations <em>must</em> execute on the provided device, or fail otherwise\". Operations placed outside a <code>tf.device()</code> block (or with <code>tf.device(None)</code>) tell TensorFlow \"feel free to pick a device that will work\".</p>\n<p>So the simplest thing for your case would be to just move the <code>tf.tensordot()</code> call outside the <code>with tf.device()</code> block:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.eager <span class=\"pl-k\">as</span> tfe\n\ntfe.enable_eager_execution()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Force a and b to be on GPU</span>\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:0<span class=\"pl-pds\">\"</span></span>):\n  a <span class=\"pl-k\">=</span> tf.ones([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>])\n  b <span class=\"pl-k\">=</span> tf.ones([<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>])\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run tensordor outside the tf.device() block</span>\nc <span class=\"pl-k\">=</span> tf.tensordot(a, b, <span class=\"pl-v\">axes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)</pre></div>\n<p>Hope that helps.</p>", "body_text": "@xinmei9322, tf.device() blocks can be used to force operations on a particular device, even CPU. Also, tf.tensordot is not a primitive TensorFlow operation (in that it is a Python function that composes other existing TensorFlow operations). Note that operations inside a tf.device() block are telling TensorFlow \"these operations must execute on the provided device, or fail otherwise\". Operations placed outside a tf.device() block (or with tf.device(None)) tell TensorFlow \"feel free to pick a device that will work\".\nSo the simplest thing for your case would be to just move the tf.tensordot() call outside the with tf.device() block:\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\ntfe.enable_eager_execution()\n\n# Force a and b to be on GPU\nwith tf.device(\"/gpu:0\"):\n  a = tf.ones([1, 2])\n  b = tf.ones([2, 1])\n# Run tensordor outside the tf.device() block\nc = tf.tensordot(a, b, axes=1)\nHope that helps.", "body": "@xinmei9322, `tf.device()` blocks can be used to force operations on a particular device, even CPU. Also, `tf.tensordot` is not a primitive TensorFlow operation (in that it is a Python function that composes other existing TensorFlow operations). Note that operations inside a `tf.device()` block are telling TensorFlow \"these operations *must* execute on the provided device, or fail otherwise\". Operations placed outside a `tf.device()` block (or with `tf.device(None)`) tell TensorFlow \"feel free to pick a device that will work\".\r\n\r\nSo the simplest thing for your case would be to just move the `tf.tensordot()` call outside the `with tf.device()` block:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\n\r\n# Force a and b to be on GPU\r\nwith tf.device(\"/gpu:0\"):\r\n  a = tf.ones([1, 2])\r\n  b = tf.ones([2, 1])\r\n# Run tensordor outside the tf.device() block\r\nc = tf.tensordot(a, b, axes=1)\r\n```\r\n\r\nHope that helps."}