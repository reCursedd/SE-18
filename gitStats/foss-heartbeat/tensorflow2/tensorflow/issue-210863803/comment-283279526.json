{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/283279526", "html_url": "https://github.com/tensorflow/tensorflow/pull/7948#issuecomment-283279526", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7948", "id": 283279526, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MzI3OTUyNg==", "user": {"login": "persiyanov", "id": 3997997, "node_id": "MDQ6VXNlcjM5OTc5OTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3997997?v=4", "gravatar_id": "", "url": "https://api.github.com/users/persiyanov", "html_url": "https://github.com/persiyanov", "followers_url": "https://api.github.com/users/persiyanov/followers", "following_url": "https://api.github.com/users/persiyanov/following{/other_user}", "gists_url": "https://api.github.com/users/persiyanov/gists{/gist_id}", "starred_url": "https://api.github.com/users/persiyanov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/persiyanov/subscriptions", "organizations_url": "https://api.github.com/users/persiyanov/orgs", "repos_url": "https://api.github.com/users/persiyanov/repos", "events_url": "https://api.github.com/users/persiyanov/events{/privacy}", "received_events_url": "https://api.github.com/users/persiyanov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-01T08:44:18Z", "updated_at": "2017-03-01T10:45:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=70511\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/girving\">@girving</a> tests look okay. What about <code>SparseSoftmaxCrossEntropyGrad</code>? Also, maybe <code>SoftmaxGrad</code> needs to be rewritten? For now, the implementation of it is this:</p>\n<div class=\"highlight highlight-source-python\"><pre>softmax <span class=\"pl-k\">=</span> op.outputs[<span class=\"pl-c1\">0</span>]\ngrad_x <span class=\"pl-k\">=</span> ((grad_softmax <span class=\"pl-k\">-</span> array_ops.reshape(\n    math_ops.reduce_sum(grad_softmax <span class=\"pl-k\">*</span> softmax, [<span class=\"pl-c1\">1</span>]), [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>])) <span class=\"pl-k\">*</span> softmax)\n<span class=\"pl-k\">return</span> grad_x</pre></div>", "body_text": "@girving tests look okay. What about SparseSoftmaxCrossEntropyGrad? Also, maybe SoftmaxGrad needs to be rewritten? For now, the implementation of it is this:\nsoftmax = op.outputs[0]\ngrad_x = ((grad_softmax - array_ops.reshape(\n    math_ops.reduce_sum(grad_softmax * softmax, [1]), [-1, 1])) * softmax)\nreturn grad_x", "body": "@girving tests look okay. What about `SparseSoftmaxCrossEntropyGrad`? Also, maybe `SoftmaxGrad` needs to be rewritten? For now, the implementation of it is this:\r\n```python\r\nsoftmax = op.outputs[0]\r\ngrad_x = ((grad_softmax - array_ops.reshape(\r\n    math_ops.reduce_sum(grad_softmax * softmax, [1]), [-1, 1])) * softmax)\r\nreturn grad_x\r\n```"}