{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6816", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6816/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6816/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6816/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6816", "id": 200501985, "node_id": "MDU6SXNzdWUyMDA1MDE5ODU=", "number": 6816, "title": "Intermittent CUDA_ERROR_ILLEGAL_ADDRESS errors during back propagation for some networks when using XLA.", "user": {"login": "nryant", "id": 716377, "node_id": "MDQ6VXNlcjcxNjM3Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/716377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nryant", "html_url": "https://github.com/nryant", "followers_url": "https://api.github.com/users/nryant/followers", "following_url": "https://api.github.com/users/nryant/following{/other_user}", "gists_url": "https://api.github.com/users/nryant/gists{/gist_id}", "starred_url": "https://api.github.com/users/nryant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nryant/subscriptions", "organizations_url": "https://api.github.com/users/nryant/orgs", "repos_url": "https://api.github.com/users/nryant/repos", "events_url": "https://api.github.com/users/nryant/events{/privacy}", "received_events_url": "https://api.github.com/users/nryant/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-01-12T22:47:50Z", "updated_at": "2017-01-31T19:22:22Z", "closed_at": "2017-01-31T19:22:22Z", "author_association": "NONE", "body_html": "<h3>Summary</h3>\n<p>In playing around with the XLA JIT compiler I've experienced intermittent CUDA_ERROR_ILLEGAL_ADDRESS errors during back propagation for some network structures. While other structures may also fail, I can confirm that this happens with simple fully-connected networks when dropout is applied to the hidden units. I have not, however, observed errors when not using XLA or when using XLA, but no hidden dropout.</p>\n<h3>Environment info</h3>\n<ul>\n<li>\n<p>Operating System: Ubuntu 14.04 LTS</p>\n</li>\n<li>\n<p>GPU: Titan X</p>\n</li>\n<li>\n<p>NVIDIA driver: 375.26</p>\n</li>\n<li>\n<p>CUDA: 8.0</p>\n</li>\n<li>\n<p>cuDNN: 5.1</p>\n</li>\n<li>\n<p>see also: <a href=\"https://github.com/tensorflow/tensorflow/files/703021/cuda_libs.txt\">cuda_libs.txt</a></p>\n</li>\n<li>\n<p>bazel: 4.3</p>\n</li>\n<li>\n<p>TensorFlow: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/f8fcd85b8151d287ad09a9323fabf1c5025775b7/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/f8fcd85b8151d287ad09a9323fabf1c5025775b7\"><tt>f8fcd85</tt></a></p>\n</li>\n<li>\n<p>XLA: Yes</p>\n</li>\n<li>\n<p>TensorFlow compile command:</p>\n<p><code>bazel build --copt=-march=native -c opt  --config=cuda //tensorflow/tools/pip_package:build_pip_package</code></p>\n</li>\n</ul>\n<h3>Minimal reproducible example</h3>\n<p>See <a href=\"https://gist.github.com/nryant/8cea9bb79d7bdb965167e917d8d5aa8b\">https://gist.github.com/nryant/8cea9bb79d7bdb965167e917d8d5aa8b</a> for the script <code>test_dropout.py</code>, which repeatedly builds a small network consisting of a single hidden layer of 512 units and performs 100 fprop/bprop steps. It accepts three command line arguments:</p>\n<ul>\n<li><code>--bprop</code> enables backpropagation (by default, only forward propagation is performed)</li>\n<li><code>--xla</code> enables XLA at the session level</li>\n<li><code>--dropout</code> specifies the dropout proportion</li>\n</ul>\n<p>Also see log files produced from running the script with various arguments:</p>\n<ul>\n<li>No XLA, fprop + bprop, and dropout: <a href=\"https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-noxla_fprop_bprop_dropout-log\">https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-noxla_fprop_bprop_dropout-log</a></li>\n<li>XLA and fprop: <a href=\"https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop-log\">https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop-log</a></li>\n<li>XLA, fprop, and dropout: <a href=\"https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_dropout-log\">https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_dropout-log</a></li>\n<li>XLA, fprop + bprop, and dropout: <a href=\"https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_bprop_dropout-log\">https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_bprop_dropout-log</a></li>\n</ul>\n<p>The only combination for which we ever observe an error is XLA, fprop + bprop, and dropout, which pretty reliable blows up in the first few iterations.</p>", "body_text": "Summary\nIn playing around with the XLA JIT compiler I've experienced intermittent CUDA_ERROR_ILLEGAL_ADDRESS errors during back propagation for some network structures. While other structures may also fail, I can confirm that this happens with simple fully-connected networks when dropout is applied to the hidden units. I have not, however, observed errors when not using XLA or when using XLA, but no hidden dropout.\nEnvironment info\n\n\nOperating System: Ubuntu 14.04 LTS\n\n\nGPU: Titan X\n\n\nNVIDIA driver: 375.26\n\n\nCUDA: 8.0\n\n\ncuDNN: 5.1\n\n\nsee also: cuda_libs.txt\n\n\nbazel: 4.3\n\n\nTensorFlow: f8fcd85\n\n\nXLA: Yes\n\n\nTensorFlow compile command:\nbazel build --copt=-march=native -c opt  --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\n\nMinimal reproducible example\nSee https://gist.github.com/nryant/8cea9bb79d7bdb965167e917d8d5aa8b for the script test_dropout.py, which repeatedly builds a small network consisting of a single hidden layer of 512 units and performs 100 fprop/bprop steps. It accepts three command line arguments:\n\n--bprop enables backpropagation (by default, only forward propagation is performed)\n--xla enables XLA at the session level\n--dropout specifies the dropout proportion\n\nAlso see log files produced from running the script with various arguments:\n\nNo XLA, fprop + bprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-noxla_fprop_bprop_dropout-log\nXLA and fprop: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop-log\nXLA, fprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_dropout-log\nXLA, fprop + bprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_bprop_dropout-log\n\nThe only combination for which we ever observe an error is XLA, fprop + bprop, and dropout, which pretty reliable blows up in the first few iterations.", "body": "### Summary\r\nIn playing around with the XLA JIT compiler I've experienced intermittent CUDA_ERROR_ILLEGAL_ADDRESS errors during back propagation for some network structures. While other structures may also fail, I can confirm that this happens with simple fully-connected networks when dropout is applied to the hidden units. I have not, however, observed errors when not using XLA or when using XLA, but no hidden dropout.\r\n\r\n### Environment info\r\n- Operating System: Ubuntu 14.04 LTS\r\n- GPU: Titan X\r\n- NVIDIA driver: 375.26\r\n- CUDA: 8.0\r\n- cuDNN: 5.1\r\n- see also: [cuda_libs.txt](https://github.com/tensorflow/tensorflow/files/703021/cuda_libs.txt)\r\n-  bazel: 4.3\r\n- TensorFlow: f8fcd85b8151d287ad09a9323fabf1c5025775b7\r\n- XLA: Yes\r\n- TensorFlow compile command:\r\n\r\n    `bazel build --copt=-march=native -c opt  --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\n    \r\n\r\n### Minimal reproducible example \r\nSee https://gist.github.com/nryant/8cea9bb79d7bdb965167e917d8d5aa8b for the script `test_dropout.py`, which repeatedly builds a small network consisting of a single hidden layer of 512 units and performs 100 fprop/bprop steps. It accepts three command line arguments:\r\n\r\n- `--bprop` enables backpropagation (by default, only forward propagation is performed)\r\n- `--xla` enables XLA at the session level\r\n- `--dropout` specifies the dropout proportion\r\n\r\nAlso see log files produced from running the script with various arguments:\r\n\r\n- No XLA, fprop + bprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-noxla_fprop_bprop_dropout-log\r\n- XLA and fprop: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop-log\r\n- XLA, fprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_dropout-log\r\n- XLA, fprop + bprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_bprop_dropout-log\r\n\r\nThe only combination for which we ever observe an error is XLA, fprop + bprop, and dropout, which pretty reliable blows up in the first few iterations."}