{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11297", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11297/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11297/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11297/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11297", "id": 240657471, "node_id": "MDU6SXNzdWUyNDA2NTc0NzE=", "number": 11297, "title": "Matrix Inverse in TensorFlow", "user": {"login": "more-more-tea", "id": 1655774, "node_id": "MDQ6VXNlcjE2NTU3NzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1655774?v=4", "gravatar_id": "", "url": "https://api.github.com/users/more-more-tea", "html_url": "https://github.com/more-more-tea", "followers_url": "https://api.github.com/users/more-more-tea/followers", "following_url": "https://api.github.com/users/more-more-tea/following{/other_user}", "gists_url": "https://api.github.com/users/more-more-tea/gists{/gist_id}", "starred_url": "https://api.github.com/users/more-more-tea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/more-more-tea/subscriptions", "organizations_url": "https://api.github.com/users/more-more-tea/orgs", "repos_url": "https://api.github.com/users/more-more-tea/repos", "events_url": "https://api.github.com/users/more-more-tea/events{/privacy}", "received_events_url": "https://api.github.com/users/more-more-tea/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-07-05T13:50:52Z", "updated_at": "2017-07-05T19:32:34Z", "closed_at": "2017-07-05T19:32:34Z", "author_association": "NONE", "body_html": "<p>I have a problem related to calculating matrix inverse in TensorFlow python interface version 1.1.0 on Linux. What I'm now trying to do is that, I have an input vector as <code>tensorflow.float64</code>, say <code>S</code> and a value <code>V</code>. I augment the vector <code>S</code> to be polynomial fashion in the form <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/30d5a8739f44b6a4cdbcce45cfd97718a2d0357a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e646f776e6c6f61643f41253344253542253230312532432532305325324325323053253545322532432532305325354533253230253544\"><img src=\"https://camo.githubusercontent.com/30d5a8739f44b6a4cdbcce45cfd97718a2d0357a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e646f776e6c6f61643f41253344253542253230312532432532305325324325323053253545322532432532305325354533253230253544\" alt=\"A=[ 1, S, S^2, S^3 ]\" data-canonical-src=\"https://latex.codecogs.com/gif.download?A%3D%5B%201%2C%20S%2C%20S%5E2%2C%20S%5E3%20%5D\" style=\"max-width:100%;\"></a> and want to do a regression on <code>V</code>. I choose to compute the linear regression myself instead of using the infrastructure from tensorflow, where the regression is conducted as <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/3326d79bb904735e62a315efd833850ff7f1d39b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e646f776e6c6f61643f253543626574612533442532384125354554412532392535452537422d31253744412535455425354374696d657325323056\"><img src=\"https://camo.githubusercontent.com/3326d79bb904735e62a315efd833850ff7f1d39b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e646f776e6c6f61643f253543626574612533442532384125354554412532392535452537422d31253744412535455425354374696d657325323056\" alt=\"\\beta=(A^TA)^{-1}A^T\\times V\" data-canonical-src=\"https://latex.codecogs.com/gif.download?%5Cbeta%3D%28A%5ETA%29%5E%7B-1%7DA%5ET%5Ctimes%20V\" style=\"max-width:100%;\"></a>. The problem occurs at the <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/0a23ef57943d6f44591d81c517dee5dc4a200edf/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e646f776e6c6f61643f2532384125354554412532392535452537422d31253744\"><img src=\"https://camo.githubusercontent.com/0a23ef57943d6f44591d81c517dee5dc4a200edf/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e646f776e6c6f61643f2532384125354554412532392535452537422d31253744\" alt=\"(A^TA)^{-1}\" data-canonical-src=\"https://latex.codecogs.com/gif.download?%28A%5ETA%29%5E%7B-1%7D\" style=\"max-width:100%;\"></a> step, where the inverse multiply the original matrix does not give an identity. However, if I feed the <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/6d1e8ae853cfd3072827998145a08eea12225216/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e646f776e6c6f61643f412535455441\"><img src=\"https://camo.githubusercontent.com/6d1e8ae853cfd3072827998145a08eea12225216/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e646f776e6c6f61643f412535455441\" alt=\"A^TA\" data-canonical-src=\"https://latex.codecogs.com/gif.download?A%5ETA\" style=\"max-width:100%;\"></a> as a constant matrix containing the same value as the preprocessed input, the result is really the inverse of itself.</p>\n<p>The code below is a runnable version with parameter <code>control=True</code> turns on the constant input matrix version where the inverse behaves correctly. Three matrices are output by running the program, the original matrix, the \"inverse\" by <code>tf.matrix_inverse</code>, and the multiplication of the \"inverse\" with the original matrix aiming to recover an identify. <code>control=False</code> gives the same original matrix as <code>control=True</code> run, however, the recovered \"identity\" is not correct with <code>control=False</code>. I suspect something wrong with the data flow during preprocessing. However, limited by my experience with TensorFlow, I cannot spot it. Would you mind a help why the <code>tf.matrix_inverse</code> does not work as expected?</p>\n<pre><code>import tensorflow as tf\nimport pprint\n\ndef matrixInverse( control=False ):\n    '''Compute inverse of a matrix.\n\nParameters\n----------\ncontrol : bool\n    whether to use control group or not.\n    '''\n    X = tf.constant( [ [100. , 100., 100., 100.],\n         [ 101.75497118 ,  92.84824314 ,  95.09528336 , 103.24955959],\n         [ 92.33287485 ,  95.86868862 ,  84.70664178 , 107.9505686 ],\n         [ 85.86109085 ,  99.05621029 ,  94.24396596 , 119.60257907] ], dtype=tf.float64 )\n\n    # extract input X\n    s = tf.slice( X, [ 2, 0 ], [ 1, 4 ])\n    s = tf.squeeze(s)\n    s1 = tf.multiply( tf.ones( 4, dtype=tf.float64 ), s )\n    s2 = tf.multiply( s, s )\n    s3 = tf.multiply( tf.multiply( s, s ), s )\n\n    A = tf.concat( [ tf.ones( 4, dtype=tf.float64 ), s1, s2, s3 ], 0 )\n    A = tf.reshape( A, [ 4, 4 ] )\n\n    # filter only the first element in the selected row\n    itm = tf.constant( [ True, False, False, False ], dtype=tf.bool )\n\n    A = tf.boolean_mask( tf.transpose(A), itm )\n\n    if control:\n        ATA = tf.constant([[  1.00000000e+00,   9.23328748e+01,   8.52535978e+03,   7.87170977e+05],\n                     [  9.23328748e+01,   8.52535978e+03,   7.87170977e+05,   7.26817593e+07],\n                     [  8.52535978e+03,   7.87170977e+05,   7.26817593e+07,   6.71091579e+09],\n                     [  7.87170977e+05,   7.26817593e+07,   6.71091579e+09,   6.19638148e+11]], dtype = tf.float64)\n    else:\n        ATA = tf.matmul( tf.transpose( A ), A )\n\n    inverseATA = tf.matrix_inverse( ATA )\n\n    sess = tf.Session()\n    pprint.pprint( sess.run( [ ATA, inverseATA, tf.matmul( ATA, inverseATA ) ] ) )\n</code></pre>", "body_text": "I have a problem related to calculating matrix inverse in TensorFlow python interface version 1.1.0 on Linux. What I'm now trying to do is that, I have an input vector as tensorflow.float64, say S and a value V. I augment the vector S to be polynomial fashion in the form  and want to do a regression on V. I choose to compute the linear regression myself instead of using the infrastructure from tensorflow, where the regression is conducted as . The problem occurs at the  step, where the inverse multiply the original matrix does not give an identity. However, if I feed the  as a constant matrix containing the same value as the preprocessed input, the result is really the inverse of itself.\nThe code below is a runnable version with parameter control=True turns on the constant input matrix version where the inverse behaves correctly. Three matrices are output by running the program, the original matrix, the \"inverse\" by tf.matrix_inverse, and the multiplication of the \"inverse\" with the original matrix aiming to recover an identify. control=False gives the same original matrix as control=True run, however, the recovered \"identity\" is not correct with control=False. I suspect something wrong with the data flow during preprocessing. However, limited by my experience with TensorFlow, I cannot spot it. Would you mind a help why the tf.matrix_inverse does not work as expected?\nimport tensorflow as tf\nimport pprint\n\ndef matrixInverse( control=False ):\n    '''Compute inverse of a matrix.\n\nParameters\n----------\ncontrol : bool\n    whether to use control group or not.\n    '''\n    X = tf.constant( [ [100. , 100., 100., 100.],\n         [ 101.75497118 ,  92.84824314 ,  95.09528336 , 103.24955959],\n         [ 92.33287485 ,  95.86868862 ,  84.70664178 , 107.9505686 ],\n         [ 85.86109085 ,  99.05621029 ,  94.24396596 , 119.60257907] ], dtype=tf.float64 )\n\n    # extract input X\n    s = tf.slice( X, [ 2, 0 ], [ 1, 4 ])\n    s = tf.squeeze(s)\n    s1 = tf.multiply( tf.ones( 4, dtype=tf.float64 ), s )\n    s2 = tf.multiply( s, s )\n    s3 = tf.multiply( tf.multiply( s, s ), s )\n\n    A = tf.concat( [ tf.ones( 4, dtype=tf.float64 ), s1, s2, s3 ], 0 )\n    A = tf.reshape( A, [ 4, 4 ] )\n\n    # filter only the first element in the selected row\n    itm = tf.constant( [ True, False, False, False ], dtype=tf.bool )\n\n    A = tf.boolean_mask( tf.transpose(A), itm )\n\n    if control:\n        ATA = tf.constant([[  1.00000000e+00,   9.23328748e+01,   8.52535978e+03,   7.87170977e+05],\n                     [  9.23328748e+01,   8.52535978e+03,   7.87170977e+05,   7.26817593e+07],\n                     [  8.52535978e+03,   7.87170977e+05,   7.26817593e+07,   6.71091579e+09],\n                     [  7.87170977e+05,   7.26817593e+07,   6.71091579e+09,   6.19638148e+11]], dtype = tf.float64)\n    else:\n        ATA = tf.matmul( tf.transpose( A ), A )\n\n    inverseATA = tf.matrix_inverse( ATA )\n\n    sess = tf.Session()\n    pprint.pprint( sess.run( [ ATA, inverseATA, tf.matmul( ATA, inverseATA ) ] ) )", "body": "I have a problem related to calculating matrix inverse in TensorFlow python interface version 1.1.0 on Linux. What I'm now trying to do is that, I have an input vector as `tensorflow.float64`, say `S` and a value `V`. I augment the vector `S` to be polynomial fashion in the form ![A=[ 1, S, S^2, S^3 ]](https://latex.codecogs.com/gif.download?A%3D%5B%201%2C%20S%2C%20S%5E2%2C%20S%5E3%20%5D) and want to do a regression on `V`. I choose to compute the linear regression myself instead of using the infrastructure from tensorflow, where the regression is conducted as ![\\beta=(A^TA)^{-1}A^T\\times V](https://latex.codecogs.com/gif.download?%5Cbeta%3D%28A%5ETA%29%5E%7B-1%7DA%5ET%5Ctimes%20V). The problem occurs at the ![(A^TA)^{-1}](https://latex.codecogs.com/gif.download?%28A%5ETA%29%5E%7B-1%7D) step, where the inverse multiply the original matrix does not give an identity. However, if I feed the ![A^TA](https://latex.codecogs.com/gif.download?A%5ETA) as a constant matrix containing the same value as the preprocessed input, the result is really the inverse of itself.\r\n\r\nThe code below is a runnable version with parameter `control=True` turns on the constant input matrix version where the inverse behaves correctly. Three matrices are output by running the program, the original matrix, the \"inverse\" by `tf.matrix_inverse`, and the multiplication of the \"inverse\" with the original matrix aiming to recover an identify. `control=False` gives the same original matrix as `control=True` run, however, the recovered \"identity\" is not correct with `control=False`. I suspect something wrong with the data flow during preprocessing. However, limited by my experience with TensorFlow, I cannot spot it. Would you mind a help why the `tf.matrix_inverse` does not work as expected?\r\n\r\n\r\n    import tensorflow as tf\r\n    import pprint\r\n    \r\n    def matrixInverse( control=False ):\r\n        '''Compute inverse of a matrix.\r\n    \r\n    Parameters\r\n    ----------\r\n    control : bool\r\n        whether to use control group or not.\r\n        '''\r\n        X = tf.constant( [ [100. , 100., 100., 100.],\r\n             [ 101.75497118 ,  92.84824314 ,  95.09528336 , 103.24955959],\r\n             [ 92.33287485 ,  95.86868862 ,  84.70664178 , 107.9505686 ],\r\n             [ 85.86109085 ,  99.05621029 ,  94.24396596 , 119.60257907] ], dtype=tf.float64 )\r\n    \r\n        # extract input X\r\n        s = tf.slice( X, [ 2, 0 ], [ 1, 4 ])\r\n        s = tf.squeeze(s)\r\n        s1 = tf.multiply( tf.ones( 4, dtype=tf.float64 ), s )\r\n        s2 = tf.multiply( s, s )\r\n        s3 = tf.multiply( tf.multiply( s, s ), s )\r\n    \r\n        A = tf.concat( [ tf.ones( 4, dtype=tf.float64 ), s1, s2, s3 ], 0 )\r\n        A = tf.reshape( A, [ 4, 4 ] )\r\n    \r\n        # filter only the first element in the selected row\r\n        itm = tf.constant( [ True, False, False, False ], dtype=tf.bool )\r\n    \r\n        A = tf.boolean_mask( tf.transpose(A), itm )\r\n    \r\n        if control:\r\n            ATA = tf.constant([[  1.00000000e+00,   9.23328748e+01,   8.52535978e+03,   7.87170977e+05],\r\n                         [  9.23328748e+01,   8.52535978e+03,   7.87170977e+05,   7.26817593e+07],\r\n                         [  8.52535978e+03,   7.87170977e+05,   7.26817593e+07,   6.71091579e+09],\r\n                         [  7.87170977e+05,   7.26817593e+07,   6.71091579e+09,   6.19638148e+11]], dtype = tf.float64)\r\n        else:\r\n            ATA = tf.matmul( tf.transpose( A ), A )\r\n    \r\n        inverseATA = tf.matrix_inverse( ATA )\r\n    \r\n        sess = tf.Session()\r\n        pprint.pprint( sess.run( [ ATA, inverseATA, tf.matmul( ATA, inverseATA ) ] ) )"}