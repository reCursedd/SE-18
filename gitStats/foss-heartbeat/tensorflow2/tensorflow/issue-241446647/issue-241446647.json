{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11373", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11373/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11373/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11373/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11373", "id": 241446647, "node_id": "MDU6SXNzdWUyNDE0NDY2NDc=", "number": 11373, "title": "[Slim] Training accuracy is increasing very slowly", "user": {"login": "redserpent7", "id": 7194031, "node_id": "MDQ6VXNlcjcxOTQwMzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/7194031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redserpent7", "html_url": "https://github.com/redserpent7", "followers_url": "https://api.github.com/users/redserpent7/followers", "following_url": "https://api.github.com/users/redserpent7/following{/other_user}", "gists_url": "https://api.github.com/users/redserpent7/gists{/gist_id}", "starred_url": "https://api.github.com/users/redserpent7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redserpent7/subscriptions", "organizations_url": "https://api.github.com/users/redserpent7/orgs", "repos_url": "https://api.github.com/users/redserpent7/repos", "events_url": "https://api.github.com/users/redserpent7/events{/privacy}", "received_events_url": "https://api.github.com/users/redserpent7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-07-08T12:14:26Z", "updated_at": "2017-07-10T18:03:48Z", "closed_at": "2017-07-10T18:03:48Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I feel something odd is happening with my Inception_Resnet_v2 training. I am what I'm seeing is correct but it seems the training will take forever at the current rate.</p>\n<p>I am training slim against the full Imagenet dataset approx 14M images. The training is running on 8GPUs and the batch size is the default 32. If my calculations are correct this means that each epoch should consist of approximately (54,000 steps):</p>\n<p>14,000,000 / (8 * 32)</p>\n<p>The training has been running for 800,000 steps so far (approx 15 epochs) yet the accuracy just reached 22%.</p>\n<p>I have been evaluating the model after each 100,000 steps and at the start, the accuracy used to increase by 5% after each 100,000 step up until 500,000 steps, yet now it seems to be rapidly slowing down as now I am getting in approximate 0.8% increase every 100,000 steps after reaching the 500,000 steps mark.</p>\n<p>I am not sure if this is expected as I do not have any data to compare it with but at this rate it can take several months, maybe even years to reach a viable accuracy rate. I am trying to reach somewhere above 70% at least.</p>\n<p>Now is this expected? Are there any ways to speed up training beside adding GPUs? And if the latter is my only option, is it possible to continue training on the same checkpoints once the number of GPUs has increased?</p>", "body_text": "Hi,\nI feel something odd is happening with my Inception_Resnet_v2 training. I am what I'm seeing is correct but it seems the training will take forever at the current rate.\nI am training slim against the full Imagenet dataset approx 14M images. The training is running on 8GPUs and the batch size is the default 32. If my calculations are correct this means that each epoch should consist of approximately (54,000 steps):\n14,000,000 / (8 * 32)\nThe training has been running for 800,000 steps so far (approx 15 epochs) yet the accuracy just reached 22%.\nI have been evaluating the model after each 100,000 steps and at the start, the accuracy used to increase by 5% after each 100,000 step up until 500,000 steps, yet now it seems to be rapidly slowing down as now I am getting in approximate 0.8% increase every 100,000 steps after reaching the 500,000 steps mark.\nI am not sure if this is expected as I do not have any data to compare it with but at this rate it can take several months, maybe even years to reach a viable accuracy rate. I am trying to reach somewhere above 70% at least.\nNow is this expected? Are there any ways to speed up training beside adding GPUs? And if the latter is my only option, is it possible to continue training on the same checkpoints once the number of GPUs has increased?", "body": "Hi,\r\n\r\nI feel something odd is happening with my Inception_Resnet_v2 training. I am what I'm seeing is correct but it seems the training will take forever at the current rate. \r\n\r\nI am training slim against the full Imagenet dataset approx 14M images. The training is running on 8GPUs and the batch size is the default 32. If my calculations are correct this means that each epoch should consist of approximately (54,000 steps):\r\n\r\n14,000,000 / (8 * 32) \r\n\r\nThe training has been running for 800,000 steps so far (approx 15 epochs) yet the accuracy just reached 22%.\r\n\r\nI have been evaluating the model after each 100,000 steps and at the start, the accuracy used to increase by 5% after each 100,000 step up until 500,000 steps, yet now it seems to be rapidly slowing down as now I am getting in approximate 0.8% increase every 100,000 steps after reaching the 500,000 steps mark.\r\n\r\nI am not sure if this is expected as I do not have any data to compare it with but at this rate it can take several months, maybe even years to reach a viable accuracy rate. I am trying to reach somewhere above 70% at least.\r\n\r\nNow is this expected? Are there any ways to speed up training beside adding GPUs? And if the latter is my only option, is it possible to continue training on the same checkpoints once the number of GPUs has increased?\r\n\r\n"}