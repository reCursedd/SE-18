{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1045", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1045/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1045/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1045/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1045", "id": 132828533, "node_id": "MDU6SXNzdWUxMzI4Mjg1MzM=", "number": 1045, "title": "tf.train.string_input_producer breaks when num_epochs is set", "user": {"login": "bcarpenter-pub", "id": 16929143, "node_id": "MDQ6VXNlcjE2OTI5MTQz", "avatar_url": "https://avatars1.githubusercontent.com/u/16929143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bcarpenter-pub", "html_url": "https://github.com/bcarpenter-pub", "followers_url": "https://api.github.com/users/bcarpenter-pub/followers", "following_url": "https://api.github.com/users/bcarpenter-pub/following{/other_user}", "gists_url": "https://api.github.com/users/bcarpenter-pub/gists{/gist_id}", "starred_url": "https://api.github.com/users/bcarpenter-pub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bcarpenter-pub/subscriptions", "organizations_url": "https://api.github.com/users/bcarpenter-pub/orgs", "repos_url": "https://api.github.com/users/bcarpenter-pub/repos", "events_url": "https://api.github.com/users/bcarpenter-pub/events{/privacy}", "received_events_url": "https://api.github.com/users/bcarpenter-pub/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "sherrym", "id": 12770037, "node_id": "MDQ6VXNlcjEyNzcwMDM3", "avatar_url": "https://avatars0.githubusercontent.com/u/12770037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sherrym", "html_url": "https://github.com/sherrym", "followers_url": "https://api.github.com/users/sherrym/followers", "following_url": "https://api.github.com/users/sherrym/following{/other_user}", "gists_url": "https://api.github.com/users/sherrym/gists{/gist_id}", "starred_url": "https://api.github.com/users/sherrym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sherrym/subscriptions", "organizations_url": "https://api.github.com/users/sherrym/orgs", "repos_url": "https://api.github.com/users/sherrym/repos", "events_url": "https://api.github.com/users/sherrym/events{/privacy}", "received_events_url": "https://api.github.com/users/sherrym/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sherrym", "id": 12770037, "node_id": "MDQ6VXNlcjEyNzcwMDM3", "avatar_url": "https://avatars0.githubusercontent.com/u/12770037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sherrym", "html_url": "https://github.com/sherrym", "followers_url": "https://api.github.com/users/sherrym/followers", "following_url": "https://api.github.com/users/sherrym/following{/other_user}", "gists_url": "https://api.github.com/users/sherrym/gists{/gist_id}", "starred_url": "https://api.github.com/users/sherrym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sherrym/subscriptions", "organizations_url": "https://api.github.com/users/sherrym/orgs", "repos_url": "https://api.github.com/users/sherrym/repos", "events_url": "https://api.github.com/users/sherrym/events{/privacy}", "received_events_url": "https://api.github.com/users/sherrym/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 28, "created_at": "2016-02-10T21:57:22Z", "updated_at": "2018-01-31T06:03:22Z", "closed_at": "2017-06-16T21:37:00Z", "author_association": "NONE", "body_html": "<p>I'm using a tf.train.string_input_producer to read in data from a file.  when I set num_epochs=1 instead of None it breaks and I get the following error.  My code is below as well.</p>\n<p>Any suggestions for why this is occuring?</p>\n<pre lang=\"text\"><code>I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 8\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc4ba6b0f0 Compute status: Out of range: RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 10, current size 0)\n     [[Node: shuffle_batch = QueueDequeueMany[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc48da9170 Compute status: Out of range: FIFOQueue '_0_file_queue' is closed and has insufficient elements (requested 1, current size 0)\n     [[Node: ReaderRead = ReaderRead[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReader, file_queue)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc4b8dbe20 Compute status: Aborted: Queue '_2_shuffle_batch/random_shuffle_queue' is already closed.\n     [[Node: shuffle_batch/random_shuffle_queue_Close = QueueClose[cancel_pending_enqueues=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue)]]\nTraceback (most recent call last):\n  File \"tensorflow_test.py\", line 51, in &lt;module&gt;\n    coord.join(threads)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 205, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/queue_runner.py\", line 112, in _run\n    sess.run(enqueue_op)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 368, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 444, in _do_run\n    e.code)\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value file_queue/limit_epochs/epochs\n     [[Node: file_queue/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, limit=2, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](file_queue/limit_epochs/epochs)]]\nCaused by op u'file_queue/limit_epochs/CountUpTo', defined at:\n  File \"tensorflow_test.py\", line 6, in &lt;module&gt;\n    filename_queue = tf.train.string_input_producer([\"datasets_top_10_50k/VALIDATION_testset/part-00000..tf\"], num_epochs=2,capacity=10000, name=\"file_queue\")\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 135, in string_input_producer\n    \"fraction_of_%d_full\" % capacity)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 86, in _input_producer\n    input_tensor = limit_epochs(input_tensor, num_epochs)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 77, in limit_epochs\n    counter = epochs.count_up_to(num_epochs)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 414, in count_up_to\n    return state_ops.count_up_to(self._variable, limit=limit)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 110, in count_up_to\n    return _op_def_lib.apply_op(\"CountUpTo\", ref=ref, limit=limit, name=name)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n</code></pre>\n<p>Code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> time\n\nfilename_queue <span class=\"pl-k\">=</span> tf.train.string_input_producer([<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>datasets_top_10_50k/VALIDATION_testset/part-00000..tf<span class=\"pl-pds\">\"</span></span>], <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>,<span class=\"pl-v\">capacity</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10000</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>file_queue<span class=\"pl-pds\">\"</span></span>)\nreader <span class=\"pl-k\">=</span> tf.TFRecordReader()\n_, serialized_example <span class=\"pl-k\">=</span> reader.read(filename_queue)\n\ndata <span class=\"pl-k\">=</span> tf.parse_single_example(\n      serialized_example,\n      <span class=\"pl-v\">dense_keys</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>features<span class=\"pl-pds\">\"</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>labels<span class=\"pl-pds\">\"</span></span>],\n      <span class=\"pl-v\">dense_types</span><span class=\"pl-k\">=</span>[tf.float32, tf.float32],\n      <span class=\"pl-v\">dense_shapes</span><span class=\"pl-k\">=</span>[(<span class=\"pl-c1\">4096</span>),(<span class=\"pl-c1\">10</span>)])\n\nfeatures <span class=\"pl-k\">=</span> data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>features<span class=\"pl-pds\">\"</span></span>]\nlabels <span class=\"pl-k\">=</span> data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>labels<span class=\"pl-pds\">\"</span></span>]\n\nbatch_size<span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>\ncapacity<span class=\"pl-k\">=</span><span class=\"pl-c1\">1000</span>\nmin_after_dequeue<span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>\nexample_batch, label_batch <span class=\"pl-k\">=</span> tf.train.shuffle_batch(\n      [features, labels], \n      <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size, \n      <span class=\"pl-v\">capacity</span><span class=\"pl-k\">=</span>capacity,\n      <span class=\"pl-v\">min_after_dequeue</span><span class=\"pl-k\">=</span>min_after_dequeue)\nnum_examples <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Start populating the filename queue.</span>\n    coord <span class=\"pl-k\">=</span> tf.train.Coordinator()  \n    threads <span class=\"pl-k\">=</span> tf.train.start_queue_runners(<span class=\"pl-v\">coord</span><span class=\"pl-k\">=</span>coord, <span class=\"pl-v\">sess</span><span class=\"pl-k\">=</span>sess)\n\n    <span class=\"pl-k\">try</span>:\n        step <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n        <span class=\"pl-k\">while</span> <span class=\"pl-k\">not</span> coord.should_stop():\n            start_time <span class=\"pl-k\">=</span> time.time()\n            e, l <span class=\"pl-k\">=</span> sess.run([example_batch, label_batch])\n            <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>grabbing<span class=\"pl-pds\">\"</span></span>\n            e, l <span class=\"pl-k\">=</span> sess.run([example_batch, label_batch])\n            num_examples <span class=\"pl-k\">=</span> num_examples <span class=\"pl-k\">+</span> e.shape[<span class=\"pl-c1\">0</span>]\n            <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num_examples = <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> <span class=\"pl-c1\">str</span>(num_examples)\n            duration <span class=\"pl-k\">=</span> time.time() <span class=\"pl-k\">-</span> start_time\n\n    <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Done training for <span class=\"pl-c1\">%d</span> epochs, <span class=\"pl-c1\">%d</span> steps.<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (<span class=\"pl-c1\">FLAGS</span>.num_epochs, step))\n    <span class=\"pl-k\">finally</span>:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> When done, ask the threads to stop.</span>\n        coord.request_stop()\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Wait for threads to finish.</span>\n        coord.join(threads)\n        sess.close()</pre></div>", "body_text": "I'm using a tf.train.string_input_producer to read in data from a file.  when I set num_epochs=1 instead of None it breaks and I get the following error.  My code is below as well.\nAny suggestions for why this is occuring?\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 8\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc4ba6b0f0 Compute status: Out of range: RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 10, current size 0)\n     [[Node: shuffle_batch = QueueDequeueMany[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc48da9170 Compute status: Out of range: FIFOQueue '_0_file_queue' is closed and has insufficient elements (requested 1, current size 0)\n     [[Node: ReaderRead = ReaderRead[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReader, file_queue)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc4b8dbe20 Compute status: Aborted: Queue '_2_shuffle_batch/random_shuffle_queue' is already closed.\n     [[Node: shuffle_batch/random_shuffle_queue_Close = QueueClose[cancel_pending_enqueues=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue)]]\nTraceback (most recent call last):\n  File \"tensorflow_test.py\", line 51, in <module>\n    coord.join(threads)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 205, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/queue_runner.py\", line 112, in _run\n    sess.run(enqueue_op)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 368, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 444, in _do_run\n    e.code)\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value file_queue/limit_epochs/epochs\n     [[Node: file_queue/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, limit=2, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](file_queue/limit_epochs/epochs)]]\nCaused by op u'file_queue/limit_epochs/CountUpTo', defined at:\n  File \"tensorflow_test.py\", line 6, in <module>\n    filename_queue = tf.train.string_input_producer([\"datasets_top_10_50k/VALIDATION_testset/part-00000..tf\"], num_epochs=2,capacity=10000, name=\"file_queue\")\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 135, in string_input_producer\n    \"fraction_of_%d_full\" % capacity)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 86, in _input_producer\n    input_tensor = limit_epochs(input_tensor, num_epochs)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 77, in limit_epochs\n    counter = epochs.count_up_to(num_epochs)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 414, in count_up_to\n    return state_ops.count_up_to(self._variable, limit=limit)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 110, in count_up_to\n    return _op_def_lib.apply_op(\"CountUpTo\", ref=ref, limit=limit, name=name)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n\nCode:\nimport tensorflow as tf\nimport time\n\nfilename_queue = tf.train.string_input_producer([\"datasets_top_10_50k/VALIDATION_testset/part-00000..tf\"], num_epochs=2,capacity=10000, name=\"file_queue\")\nreader = tf.TFRecordReader()\n_, serialized_example = reader.read(filename_queue)\n\ndata = tf.parse_single_example(\n      serialized_example,\n      dense_keys=[\"features\",\"labels\"],\n      dense_types=[tf.float32, tf.float32],\n      dense_shapes=[(4096),(10)])\n\nfeatures = data[\"features\"]\nlabels = data[\"labels\"]\n\nbatch_size=10\ncapacity=1000\nmin_after_dequeue=100\nexample_batch, label_batch = tf.train.shuffle_batch(\n      [features, labels], \n      batch_size=batch_size, \n      capacity=capacity,\n      min_after_dequeue=min_after_dequeue)\nnum_examples = 0\nwith tf.Session() as sess:\n    # Start populating the filename queue.\n    coord = tf.train.Coordinator()  \n    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n\n    try:\n        step = 0\n        while not coord.should_stop():\n            start_time = time.time()\n            e, l = sess.run([example_batch, label_batch])\n            print \"grabbing\"\n            e, l = sess.run([example_batch, label_batch])\n            num_examples = num_examples + e.shape[0]\n            print \"num_examples = \" + str(num_examples)\n            duration = time.time() - start_time\n\n    except tf.errors.OutOfRangeError:\n        print('Done training for %d epochs, %d steps.' % (FLAGS.num_epochs, step))\n    finally:\n        # When done, ask the threads to stop.\n        coord.request_stop()\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()", "body": "I'm using a tf.train.string_input_producer to read in data from a file.  when I set num_epochs=1 instead of None it breaks and I get the following error.  My code is below as well.\n\nAny suggestions for why this is occuring?\n\n``` text\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 8\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc4ba6b0f0 Compute status: Out of range: RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 10, current size 0)\n     [[Node: shuffle_batch = QueueDequeueMany[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc48da9170 Compute status: Out of range: FIFOQueue '_0_file_queue' is closed and has insufficient elements (requested 1, current size 0)\n     [[Node: ReaderRead = ReaderRead[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReader, file_queue)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7fdc4b8dbe20 Compute status: Aborted: Queue '_2_shuffle_batch/random_shuffle_queue' is already closed.\n     [[Node: shuffle_batch/random_shuffle_queue_Close = QueueClose[cancel_pending_enqueues=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue)]]\nTraceback (most recent call last):\n  File \"tensorflow_test.py\", line 51, in <module>\n    coord.join(threads)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 205, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/queue_runner.py\", line 112, in _run\n    sess.run(enqueue_op)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 368, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 444, in _do_run\n    e.code)\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value file_queue/limit_epochs/epochs\n     [[Node: file_queue/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, limit=2, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](file_queue/limit_epochs/epochs)]]\nCaused by op u'file_queue/limit_epochs/CountUpTo', defined at:\n  File \"tensorflow_test.py\", line 6, in <module>\n    filename_queue = tf.train.string_input_producer([\"datasets_top_10_50k/VALIDATION_testset/part-00000..tf\"], num_epochs=2,capacity=10000, name=\"file_queue\")\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 135, in string_input_producer\n    \"fraction_of_%d_full\" % capacity)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 86, in _input_producer\n    input_tensor = limit_epochs(input_tensor, num_epochs)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 77, in limit_epochs\n    counter = epochs.count_up_to(num_epochs)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 414, in count_up_to\n    return state_ops.count_up_to(self._variable, limit=limit)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 110, in count_up_to\n    return _op_def_lib.apply_op(\"CountUpTo\", ref=ref, limit=limit, name=name)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/blakec/virtual_envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n```\n\nCode:\n\n``` python\nimport tensorflow as tf\nimport time\n\nfilename_queue = tf.train.string_input_producer([\"datasets_top_10_50k/VALIDATION_testset/part-00000..tf\"], num_epochs=2,capacity=10000, name=\"file_queue\")\nreader = tf.TFRecordReader()\n_, serialized_example = reader.read(filename_queue)\n\ndata = tf.parse_single_example(\n      serialized_example,\n      dense_keys=[\"features\",\"labels\"],\n      dense_types=[tf.float32, tf.float32],\n      dense_shapes=[(4096),(10)])\n\nfeatures = data[\"features\"]\nlabels = data[\"labels\"]\n\nbatch_size=10\ncapacity=1000\nmin_after_dequeue=100\nexample_batch, label_batch = tf.train.shuffle_batch(\n      [features, labels], \n      batch_size=batch_size, \n      capacity=capacity,\n      min_after_dequeue=min_after_dequeue)\nnum_examples = 0\nwith tf.Session() as sess:\n    # Start populating the filename queue.\n    coord = tf.train.Coordinator()  \n    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n\n    try:\n        step = 0\n        while not coord.should_stop():\n            start_time = time.time()\n            e, l = sess.run([example_batch, label_batch])\n            print \"grabbing\"\n            e, l = sess.run([example_batch, label_batch])\n            num_examples = num_examples + e.shape[0]\n            print \"num_examples = \" + str(num_examples)\n            duration = time.time() - start_time\n\n    except tf.errors.OutOfRangeError:\n        print('Done training for %d epochs, %d steps.' % (FLAGS.num_epochs, step))\n    finally:\n        # When done, ask the threads to stop.\n        coord.request_stop()\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n```\n"}