{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6471", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6471/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6471/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6471/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6471", "id": 197334938, "node_id": "MDU6SXNzdWUxOTczMzQ5Mzg=", "number": 6471, "title": "how to custom learning rate decay policy ?", "user": {"login": "silverlining21", "id": 8264748, "node_id": "MDQ6VXNlcjgyNjQ3NDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/8264748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/silverlining21", "html_url": "https://github.com/silverlining21", "followers_url": "https://api.github.com/users/silverlining21/followers", "following_url": "https://api.github.com/users/silverlining21/following{/other_user}", "gists_url": "https://api.github.com/users/silverlining21/gists{/gist_id}", "starred_url": "https://api.github.com/users/silverlining21/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/silverlining21/subscriptions", "organizations_url": "https://api.github.com/users/silverlining21/orgs", "repos_url": "https://api.github.com/users/silverlining21/repos", "events_url": "https://api.github.com/users/silverlining21/events{/privacy}", "received_events_url": "https://api.github.com/users/silverlining21/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-12-23T09:09:27Z", "updated_at": "2016-12-28T23:58:08Z", "closed_at": "2016-12-28T23:58:02Z", "author_association": "NONE", "body_html": "<p>as it shown in the learning rate deay <strong><a href=\"https://www.tensorflow.org/api_docs/python/train/decaying_the_learning_rate\" rel=\"nofollow\">API doc</a></strong> , there are only 4 kinds of policies. but in caffe  policies are as follows:</p>\n<ol>\n<li>//    - fixed: always return base_lr.</li>\n<li>//    - step: return base_lr * gamma ^ (floor(iter / step))</li>\n<li>//    - exp: return base_lr * gamma ^ iter</li>\n<li>//    - inv: return base_lr * (1 + gamma * iter) ^ (- power)</li>\n<li>//    - multistep: similar to step but it allows non uniform steps defined by</li>\n<li>//      stepvalue</li>\n<li>//    - poly: the effective learning rate follows a polynomial decay, to be</li>\n<li>//      zero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)</li>\n<li>//    - sigmoid: the effective learning rate follows a sigmod decay</li>\n</ol>\n<p>in issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"160805658\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2922\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2922/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2922\">#2922</a> they mentioNed on write a warpper for the existing method, but they did not implemented anything new ?  for example the <strong>inv</strong> <code>[base_lr * (1 + gamma * iter) ^ (- power)]</code> policy in caffe.</p>\n<p>so I wonder if there anyone who can help me out how to custom learning rate decay policy by myself, any suggestions will be sincerely gratitude.</p>", "body_text": "as it shown in the learning rate deay API doc , there are only 4 kinds of policies. but in caffe  policies are as follows:\n\n//    - fixed: always return base_lr.\n//    - step: return base_lr * gamma ^ (floor(iter / step))\n//    - exp: return base_lr * gamma ^ iter\n//    - inv: return base_lr * (1 + gamma * iter) ^ (- power)\n//    - multistep: similar to step but it allows non uniform steps defined by\n//      stepvalue\n//    - poly: the effective learning rate follows a polynomial decay, to be\n//      zero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)\n//    - sigmoid: the effective learning rate follows a sigmod decay\n\nin issue #2922 they mentioNed on write a warpper for the existing method, but they did not implemented anything new ?  for example the inv [base_lr * (1 + gamma * iter) ^ (- power)] policy in caffe.\nso I wonder if there anyone who can help me out how to custom learning rate decay policy by myself, any suggestions will be sincerely gratitude.", "body": "as it shown in the learning rate deay **[API doc](https://www.tensorflow.org/api_docs/python/train/decaying_the_learning_rate)** , there are only 4 kinds of policies. but in caffe  policies are as follows:  \r\n \r\n1.   //    - fixed: always return base_lr.  \r\n2.   //    - step: return base_lr * gamma ^ (floor(iter / step))  \r\n3.   //    - exp: return base_lr * gamma ^ iter  \r\n4.   //    - inv: return base_lr * (1 + gamma * iter) ^ (- power)  \r\n5.   //    - multistep: similar to step but it allows non uniform steps defined by  \r\n6.   //      stepvalue  \r\n7.   //    - poly: the effective learning rate follows a polynomial decay, to be  \r\n8.   //      zero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)  \r\n9.   //    - sigmoid: the effective learning rate follows a sigmod decay  \r\n\r\nin issue #2922 they mentioNed on write a warpper for the existing method, but they did not implemented anything new ?  for example the **inv** `[base_lr * (1 + gamma * iter) ^ (- power)]` policy in caffe.\r\n\r\nso I wonder if there anyone who can help me out how to custom learning rate decay policy by myself, any suggestions will be sincerely gratitude. \r\n\r\n"}