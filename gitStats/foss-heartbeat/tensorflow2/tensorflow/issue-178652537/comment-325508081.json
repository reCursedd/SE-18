{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/325508081", "html_url": "https://github.com/tensorflow/tensorflow/issues/4535#issuecomment-325508081", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4535", "id": 325508081, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNTUwODA4MQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-28T23:08:52Z", "updated_at": "2017-08-28T23:08:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi folks! You might be interested in my <a href=\"https://stackoverflow.com/a/45928467/3574081\" rel=\"nofollow\">answer</a> to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=59132\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/albertz\">@albertz</a>'s question on Stack Overflow. In short, there have been a couple of developments since the 1.3 release that might be useful to people on this thread, and I'd encourage you to try them out:</p>\n<ul>\n<li><a href=\"https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/data/Dataset#from_generator\" rel=\"nofollow\"><code>Dataset.from_generator()</code></a> makes it easy to create a <code>Dataset</code> from a Python generator. This gives you a way to wrap \"feeding\" code by writing a Python function that uses <code>yield</code> (rather than <code>feed_dict</code>) to pass NumPy arrays into the dataset.</li>\n<li><a href=\"https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/data/Dataset#prefetch\" rel=\"nofollow\"><code>Dataset.prefetch()</code></a> makes it easy to create a background thread that preprocesses elements. (You could do this in 1.3, using <code>Dataset.map(lambda x, y, z: (x, y, z), num_threads=1, output_buffer_size=N)</code>, but the new version is simpler and a little more efficient.)</li>\n</ul>\n<p>As an aside, we've upgraded <code>Dataset.map(..., num_threads=N)</code> for <code>N &gt; 1</code> to use a more efficient representation that doesn't actually create a huge number of threads. (The new argument is called <code>num_parallel_calls</code>, but we've kept <code>num_threads</code> for now.) This should make it more efficient to process large numbers of elements in parallel, and we've seen encouraging improvements on our benchmarks for CNN image input pipelines.</p>", "body_text": "Hi folks! You might be interested in my answer to @albertz's question on Stack Overflow. In short, there have been a couple of developments since the 1.3 release that might be useful to people on this thread, and I'd encourage you to try them out:\n\nDataset.from_generator() makes it easy to create a Dataset from a Python generator. This gives you a way to wrap \"feeding\" code by writing a Python function that uses yield (rather than feed_dict) to pass NumPy arrays into the dataset.\nDataset.prefetch() makes it easy to create a background thread that preprocesses elements. (You could do this in 1.3, using Dataset.map(lambda x, y, z: (x, y, z), num_threads=1, output_buffer_size=N), but the new version is simpler and a little more efficient.)\n\nAs an aside, we've upgraded Dataset.map(..., num_threads=N) for N > 1 to use a more efficient representation that doesn't actually create a huge number of threads. (The new argument is called num_parallel_calls, but we've kept num_threads for now.) This should make it more efficient to process large numbers of elements in parallel, and we've seen encouraging improvements on our benchmarks for CNN image input pipelines.", "body": "Hi folks! You might be interested in my [answer](https://stackoverflow.com/a/45928467/3574081) to @albertz's question on Stack Overflow. In short, there have been a couple of developments since the 1.3 release that might be useful to people on this thread, and I'd encourage you to try them out:\r\n\r\n* [`Dataset.from_generator()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/data/Dataset#from_generator) makes it easy to create a `Dataset` from a Python generator. This gives you a way to wrap \"feeding\" code by writing a Python function that uses `yield` (rather than `feed_dict`) to pass NumPy arrays into the dataset.\r\n* [`Dataset.prefetch()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/data/Dataset#prefetch) makes it easy to create a background thread that preprocesses elements. (You could do this in 1.3, using `Dataset.map(lambda x, y, z: (x, y, z), num_threads=1, output_buffer_size=N)`, but the new version is simpler and a little more efficient.)\r\n\r\nAs an aside, we've upgraded `Dataset.map(..., num_threads=N)` for `N > 1` to use a more efficient representation that doesn't actually create a huge number of threads. (The new argument is called `num_parallel_calls`, but we've kept `num_threads` for now.) This should make it more efficient to process large numbers of elements in parallel, and we've seen encouraging improvements on our benchmarks for CNN image input pipelines."}