{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/303129770", "html_url": "https://github.com/tensorflow/tensorflow/issues/4535#issuecomment-303129770", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4535", "id": 303129770, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzEyOTc3MA==", "user": {"login": "albertz", "id": 59132, "node_id": "MDQ6VXNlcjU5MTMy", "avatar_url": "https://avatars0.githubusercontent.com/u/59132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albertz", "html_url": "https://github.com/albertz", "followers_url": "https://api.github.com/users/albertz/followers", "following_url": "https://api.github.com/users/albertz/following{/other_user}", "gists_url": "https://api.github.com/users/albertz/gists{/gist_id}", "starred_url": "https://api.github.com/users/albertz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albertz/subscriptions", "organizations_url": "https://api.github.com/users/albertz/orgs", "repos_url": "https://api.github.com/users/albertz/repos", "events_url": "https://api.github.com/users/albertz/events{/privacy}", "received_events_url": "https://api.github.com/users/albertz/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-22T15:12:43Z", "updated_at": "2017-05-23T10:47:31Z", "author_association": "NONE", "body_html": "<p>That's interesting. I also extended my <a href=\"https://stackoverflow.com/questions/41187745/tensorflow-how-can-i-evaluate-a-validation-data-queue-multiple-times-during-tra/44067467#44067467\" rel=\"nofollow\">StackOverflow answer here</a> to address this.</p>\n<p>Small questions (all also put on StackOverflow, maybe you can answer there):</p>\n<p>When I use <code>repeat</code> (for multiple epochs) together with <code>shuffle</code> (as <code>read_batch_features</code> does internally), how will I notice when some epochs ends, and what the current epoch is? Also, when the epoch ends, will the <code>ShuffleDataset</code> wait first to dequeue everything or will it already be filled with more data from the next epoch? In the last epoch, or if I don't use <code>repeat</code>, will the <code>ShuffleDataset</code> dequeue all remaining data, like <code>tf.RandomShuffleQueue</code> dequeueing does after close?<br>\nI asked this on <a href=\"https://stackoverflow.com/questions/44132307/tf-contrib-data-dataset-repeat-with-shuffle-notice-epoch-end-mixed-epochs\" rel=\"nofollow\">StackOverflow here</a>.</p>\n<p>If I want to have more control, I would not use <code>repeat</code> but go once over the data and use <code>ShuffleDataset</code> to get shuffling like <code>RandomShuffleQueue</code>, and then at some point I get <code>OutOfRangeError</code> and I know that I reached the end of the epoch. Then I reinitializable the iterator, like it is described.</p>\n<p>If I use <code>PaddedBatchDataset</code>, how could I recover the lengths of each sequence in the batch?<br>\nI asked this on <a href=\"https://stackoverflow.com/questions/40675692/get-dynamic-sequence-length-from-paddingfifoqueue\" rel=\"nofollow\">StackOverflow here</a>.</p>\n<p>The way how to get data doesn't really fit any way how I get the data usually. In my case, I have a thread and I receive data there and I don't know in advance when it will end but I see when it ends. Then I wait until I processed all the buffers and then I have finished one epoch. How can I get this logic with the <code>Dataset</code>? I asked this on <a href=\"https://stackoverflow.com/questions/44132579/feed-data-into-a-tf-contrib-data-dataset-like-a-queue\" rel=\"nofollow\">StackOverflow here</a>.</p>\n<p>How can I wrap around a <code>Dataset</code> over a queue? I have some thread with reads some data from somewhere and which can feed it and queue it somehow. How do I get the data into the <code>Dataset</code>? I could repeat some dummy tensor infinite times and then use <code>map</code> to just return my <code>queue.dequeue()</code> but that really only gets me back to all the original problems with the queue, i.e. how to reopen the queue. The second part of my <a href=\"https://stackoverflow.com/questions/44132579/feed-data-into-a-tf-contrib-data-dataset-like-a-queue\" rel=\"nofollow\">StackOverflow question here</a>.</p>", "body_text": "That's interesting. I also extended my StackOverflow answer here to address this.\nSmall questions (all also put on StackOverflow, maybe you can answer there):\nWhen I use repeat (for multiple epochs) together with shuffle (as read_batch_features does internally), how will I notice when some epochs ends, and what the current epoch is? Also, when the epoch ends, will the ShuffleDataset wait first to dequeue everything or will it already be filled with more data from the next epoch? In the last epoch, or if I don't use repeat, will the ShuffleDataset dequeue all remaining data, like tf.RandomShuffleQueue dequeueing does after close?\nI asked this on StackOverflow here.\nIf I want to have more control, I would not use repeat but go once over the data and use ShuffleDataset to get shuffling like RandomShuffleQueue, and then at some point I get OutOfRangeError and I know that I reached the end of the epoch. Then I reinitializable the iterator, like it is described.\nIf I use PaddedBatchDataset, how could I recover the lengths of each sequence in the batch?\nI asked this on StackOverflow here.\nThe way how to get data doesn't really fit any way how I get the data usually. In my case, I have a thread and I receive data there and I don't know in advance when it will end but I see when it ends. Then I wait until I processed all the buffers and then I have finished one epoch. How can I get this logic with the Dataset? I asked this on StackOverflow here.\nHow can I wrap around a Dataset over a queue? I have some thread with reads some data from somewhere and which can feed it and queue it somehow. How do I get the data into the Dataset? I could repeat some dummy tensor infinite times and then use map to just return my queue.dequeue() but that really only gets me back to all the original problems with the queue, i.e. how to reopen the queue. The second part of my StackOverflow question here.", "body": "That's interesting. I also extended my [StackOverflow answer here](https://stackoverflow.com/questions/41187745/tensorflow-how-can-i-evaluate-a-validation-data-queue-multiple-times-during-tra/44067467#44067467) to address this.\r\n\r\nSmall questions (all also put on StackOverflow, maybe you can answer there):\r\n\r\nWhen I use `repeat` (for multiple epochs) together with `shuffle` (as `read_batch_features` does internally), how will I notice when some epochs ends, and what the current epoch is? Also, when the epoch ends, will the `ShuffleDataset` wait first to dequeue everything or will it already be filled with more data from the next epoch? In the last epoch, or if I don't use `repeat`, will the `ShuffleDataset` dequeue all remaining data, like `tf.RandomShuffleQueue` dequeueing does after close?\r\nI asked this on [StackOverflow here](https://stackoverflow.com/questions/44132307/tf-contrib-data-dataset-repeat-with-shuffle-notice-epoch-end-mixed-epochs).\r\n\r\nIf I want to have more control, I would not use `repeat` but go once over the data and use `ShuffleDataset` to get shuffling like `RandomShuffleQueue`, and then at some point I get `OutOfRangeError` and I know that I reached the end of the epoch. Then I reinitializable the iterator, like it is described.\r\n\r\nIf I use `PaddedBatchDataset`, how could I recover the lengths of each sequence in the batch?\r\nI asked this on [StackOverflow here](https://stackoverflow.com/questions/40675692/get-dynamic-sequence-length-from-paddingfifoqueue).\r\n\r\nThe way how to get data doesn't really fit any way how I get the data usually. In my case, I have a thread and I receive data there and I don't know in advance when it will end but I see when it ends. Then I wait until I processed all the buffers and then I have finished one epoch. How can I get this logic with the `Dataset`? I asked this on [StackOverflow here](https://stackoverflow.com/questions/44132579/feed-data-into-a-tf-contrib-data-dataset-like-a-queue).\r\n\r\nHow can I wrap around a `Dataset` over a queue? I have some thread with reads some data from somewhere and which can feed it and queue it somehow. How do I get the data into the `Dataset`? I could repeat some dummy tensor infinite times and then use `map` to just return my `queue.dequeue()` but that really only gets me back to all the original problems with the queue, i.e. how to reopen the queue. The second part of my [StackOverflow question here](https://stackoverflow.com/questions/44132579/feed-data-into-a-tf-contrib-data-dataset-like-a-queue).\r\n"}