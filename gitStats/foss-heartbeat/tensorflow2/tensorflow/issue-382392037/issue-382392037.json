{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23861", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23861/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23861/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23861/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23861", "id": 382392037, "node_id": "MDU6SXNzdWUzODIzOTIwMzc=", "number": 23861, "title": "matmul with large matrices fails with float16, but succeeds with float32", "user": {"login": "ilia-nikiforov", "id": 25756250, "node_id": "MDQ6VXNlcjI1NzU2MjUw", "avatar_url": "https://avatars2.githubusercontent.com/u/25756250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilia-nikiforov", "html_url": "https://github.com/ilia-nikiforov", "followers_url": "https://api.github.com/users/ilia-nikiforov/followers", "following_url": "https://api.github.com/users/ilia-nikiforov/following{/other_user}", "gists_url": "https://api.github.com/users/ilia-nikiforov/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilia-nikiforov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilia-nikiforov/subscriptions", "organizations_url": "https://api.github.com/users/ilia-nikiforov/orgs", "repos_url": "https://api.github.com/users/ilia-nikiforov/repos", "events_url": "https://api.github.com/users/ilia-nikiforov/events{/privacy}", "received_events_url": "https://api.github.com/users/ilia-nikiforov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-19T21:03:56Z", "updated_at": "2018-11-19T21:06:09Z", "closed_at": null, "author_association": "NONE", "body_html": "<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes. see below</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\nThis bug occurs with every version of GPU tensorflow I've tried or built, including several binaries and currently building from source.</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\nv1.12.0-rc0-2836-gd63e3ea</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\n2.7</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\n0.19.1</p>\n</li>\n<li>\n<p><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\n5.4.0</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nCurrently building from source with CUDA 10.0 and cuDNN 7.4, but previously the bug occurred with binaries using CUDA 9.0 and cuDNN 7.4 and cuDNN 7.0</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:<br>\nGeForce GTX 1070 8GB</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\nRun the following python script:</p>\n</li>\n</ul>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nxvar = tf.placeholder (tf.float16, name=\"x\",shape=[None,2])\n\nweight_init = tf.uniform_unit_scaling_initializer (factor=1,dtype=tf.float16)\nW = tf.get_variable (\"W\",[2,2],initializer=weight_init,dtype=tf.float16)\n\noutput = tf.matmul (xvar,W)\n\ninit = tf.global_variables_initializer ()\n\nwith tf.Session () as sess:\n    sess.run (init)\n    o = sess.run (output, feed_dict = {xvar:np.zeros ((8500000,2),dtype=np.float16)})\n</code></pre>\n<h3>Describe the problem</h3>\n<p>Matmul fails with large float16 matrices. If you reduce the size of the matrix to 8e6, the code runs. If you keep the size of the matrix the same, but change all the data types to float32, it runs. The limiting factor seems to be the single largest dimension. For example, doing the matmul with sizes (8e6,100) and (100,100) works in float16</p>\n<p>Perhaps this is not a Tensorflow issue, but an internal CUDA issue?</p>\n<h3>Source code / logs</h3>\n<pre><code>WARNING:tensorflow:From float16_demo.py:6: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\nWARNING:tensorflow:From /home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n2018-11-19 15:49:01.787213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:993] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-11-19 15:49:01.787660: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x4863200 executing computations on platform CUDA. Devices:\n2018-11-19 15:49:01.787676: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1\n2018-11-19 15:49:01.787882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465\npciBusID: 0000:01:00.0\ntotalMemory: 7.92GiB freeMemory: 7.52GiB\n2018-11-19 15:49:01.787894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n2018-11-19 15:49:01.788392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-19 15:49:01.788401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n2018-11-19 15:49:01.788405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n2018-11-19 15:49:01.788537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7316 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-11-19 15:49:03.017490: E tensorflow/stream_executor/cuda/cuda_blas.cc:652] failed to run cuBLAS routine cublasSgemmEx: CUBLAS_STATUS_EXECUTION_FAILED\nTraceback (most recent call last):\n  File \"float16_demo.py\", line 15, in &lt;module&gt;\n    o = sess.run (output, feed_dict = {xvar:np.zeros ((8500000,2),dtype=np.float16)})\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 929, in run\n    run_metadata_ptr)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n    run_metadata)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(8500000, 2), b.shape=(2, 2), m=8500000, n=2, k=2\n\t [[node MatMul (defined at float16_demo.py:9) ]]\n\nCaused by op u'MatMul', defined at:\n  File \"float16_demo.py\", line 9, in &lt;module&gt;\n    output = tf.matmul (xvar,W)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 2272, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4763, in mat_mul\n    name=name)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 512, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3268, in create_op\n    op_def=op_def)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1831, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(8500000, 2), b.shape=(2, 2), m=8500000, n=2, k=2\n\t [[node MatMul (defined at float16_demo.py:9) ]]\n</code></pre>", "body_text": "Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes. see below\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\n\n\nTensorFlow installed from (source or binary):\nThis bug occurs with every version of GPU tensorflow I've tried or built, including several binaries and currently building from source.\n\n\nTensorFlow version (use command below):\nv1.12.0-rc0-2836-gd63e3ea\n\n\nPython version:\n2.7\n\n\nBazel version (if compiling from source):\n0.19.1\n\n\nGCC/Compiler version (if compiling from source):\n5.4.0\n\n\nCUDA/cuDNN version:\nCurrently building from source with CUDA 10.0 and cuDNN 7.4, but previously the bug occurred with binaries using CUDA 9.0 and cuDNN 7.4 and cuDNN 7.0\n\n\nGPU model and memory:\nGeForce GTX 1070 8GB\n\n\nExact command to reproduce:\nRun the following python script:\n\n\nimport numpy as np\nimport tensorflow as tf\n\nxvar = tf.placeholder (tf.float16, name=\"x\",shape=[None,2])\n\nweight_init = tf.uniform_unit_scaling_initializer (factor=1,dtype=tf.float16)\nW = tf.get_variable (\"W\",[2,2],initializer=weight_init,dtype=tf.float16)\n\noutput = tf.matmul (xvar,W)\n\ninit = tf.global_variables_initializer ()\n\nwith tf.Session () as sess:\n    sess.run (init)\n    o = sess.run (output, feed_dict = {xvar:np.zeros ((8500000,2),dtype=np.float16)})\n\nDescribe the problem\nMatmul fails with large float16 matrices. If you reduce the size of the matrix to 8e6, the code runs. If you keep the size of the matrix the same, but change all the data types to float32, it runs. The limiting factor seems to be the single largest dimension. For example, doing the matmul with sizes (8e6,100) and (100,100) works in float16\nPerhaps this is not a Tensorflow issue, but an internal CUDA issue?\nSource code / logs\nWARNING:tensorflow:From float16_demo.py:6: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\nWARNING:tensorflow:From /home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n2018-11-19 15:49:01.787213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:993] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-11-19 15:49:01.787660: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x4863200 executing computations on platform CUDA. Devices:\n2018-11-19 15:49:01.787676: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1\n2018-11-19 15:49:01.787882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465\npciBusID: 0000:01:00.0\ntotalMemory: 7.92GiB freeMemory: 7.52GiB\n2018-11-19 15:49:01.787894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n2018-11-19 15:49:01.788392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-19 15:49:01.788401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n2018-11-19 15:49:01.788405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n2018-11-19 15:49:01.788537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7316 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-11-19 15:49:03.017490: E tensorflow/stream_executor/cuda/cuda_blas.cc:652] failed to run cuBLAS routine cublasSgemmEx: CUBLAS_STATUS_EXECUTION_FAILED\nTraceback (most recent call last):\n  File \"float16_demo.py\", line 15, in <module>\n    o = sess.run (output, feed_dict = {xvar:np.zeros ((8500000,2),dtype=np.float16)})\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 929, in run\n    run_metadata_ptr)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n    run_metadata)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(8500000, 2), b.shape=(2, 2), m=8500000, n=2, k=2\n\t [[node MatMul (defined at float16_demo.py:9) ]]\n\nCaused by op u'MatMul', defined at:\n  File \"float16_demo.py\", line 9, in <module>\n    output = tf.matmul (xvar,W)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 2272, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4763, in mat_mul\n    name=name)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 512, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3268, in create_op\n    op_def=op_def)\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1831, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(8500000, 2), b.shape=(2, 2), m=8500000, n=2, k=2\n\t [[node MatMul (defined at float16_demo.py:9) ]]", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes. see below\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nThis bug occurs with every version of GPU tensorflow I've tried or built, including several binaries and currently building from source.\r\n\r\n- **TensorFlow version (use command below)**:\r\nv1.12.0-rc0-2836-gd63e3ea\r\n\r\n- **Python version**:\r\n2.7\r\n\r\n- **Bazel version (if compiling from source)**:\r\n0.19.1\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\n5.4.0\r\n\r\n- **CUDA/cuDNN version**:\r\nCurrently building from source with CUDA 10.0 and cuDNN 7.4, but previously the bug occurred with binaries using CUDA 9.0 and cuDNN 7.4 and cuDNN 7.0\r\n\r\n- **GPU model and memory**:\r\nGeForce GTX 1070 8GB\r\n\r\n- **Exact command to reproduce**:\r\nRun the following python script:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nxvar = tf.placeholder (tf.float16, name=\"x\",shape=[None,2])\r\n\r\nweight_init = tf.uniform_unit_scaling_initializer (factor=1,dtype=tf.float16)\r\nW = tf.get_variable (\"W\",[2,2],initializer=weight_init,dtype=tf.float16)\r\n\r\noutput = tf.matmul (xvar,W)\r\n\r\ninit = tf.global_variables_initializer ()\r\n\r\nwith tf.Session () as sess:\r\n    sess.run (init)\r\n    o = sess.run (output, feed_dict = {xvar:np.zeros ((8500000,2),dtype=np.float16)})\r\n```\r\n\r\n### Describe the problem\r\nMatmul fails with large float16 matrices. If you reduce the size of the matrix to 8e6, the code runs. If you keep the size of the matrix the same, but change all the data types to float32, it runs. The limiting factor seems to be the single largest dimension. For example, doing the matmul with sizes (8e6,100) and (100,100) works in float16\r\n\r\nPerhaps this is not a Tensorflow issue, but an internal CUDA issue?\r\n\r\n### Source code / logs\r\n```\r\nWARNING:tensorflow:From float16_demo.py:6: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\r\nWARNING:tensorflow:From /home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\n2018-11-19 15:49:01.787213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:993] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-11-19 15:49:01.787660: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x4863200 executing computations on platform CUDA. Devices:\r\n2018-11-19 15:49:01.787676: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1\r\n2018-11-19 15:49:01.787882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.92GiB freeMemory: 7.52GiB\r\n2018-11-19 15:49:01.787894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2018-11-19 15:49:01.788392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-19 15:49:01.788401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2018-11-19 15:49:01.788405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2018-11-19 15:49:01.788537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7316 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-11-19 15:49:03.017490: E tensorflow/stream_executor/cuda/cuda_blas.cc:652] failed to run cuBLAS routine cublasSgemmEx: CUBLAS_STATUS_EXECUTION_FAILED\r\nTraceback (most recent call last):\r\n  File \"float16_demo.py\", line 15, in <module>\r\n    o = sess.run (output, feed_dict = {xvar:np.zeros ((8500000,2),dtype=np.float16)})\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(8500000, 2), b.shape=(2, 2), m=8500000, n=2, k=2\r\n\t [[node MatMul (defined at float16_demo.py:9) ]]\r\n\r\nCaused by op u'MatMul', defined at:\r\n  File \"float16_demo.py\", line 9, in <module>\r\n    output = tf.matmul (xvar,W)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 2272, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4763, in mat_mul\r\n    name=name)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 512, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3268, in create_op\r\n    op_def=op_def)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1831, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(8500000, 2), b.shape=(2, 2), m=8500000, n=2, k=2\r\n\t [[node MatMul (defined at float16_demo.py:9) ]]\r\n```"}