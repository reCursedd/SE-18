{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/409826645", "html_url": "https://github.com/tensorflow/tensorflow/issues/20691#issuecomment-409826645", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20691", "id": 409826645, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTgyNjY0NQ==", "user": {"login": "ShubhamSrivastava93", "id": 33781781, "node_id": "MDQ6VXNlcjMzNzgxNzgx", "avatar_url": "https://avatars1.githubusercontent.com/u/33781781?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ShubhamSrivastava93", "html_url": "https://github.com/ShubhamSrivastava93", "followers_url": "https://api.github.com/users/ShubhamSrivastava93/followers", "following_url": "https://api.github.com/users/ShubhamSrivastava93/following{/other_user}", "gists_url": "https://api.github.com/users/ShubhamSrivastava93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ShubhamSrivastava93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ShubhamSrivastava93/subscriptions", "organizations_url": "https://api.github.com/users/ShubhamSrivastava93/orgs", "repos_url": "https://api.github.com/users/ShubhamSrivastava93/repos", "events_url": "https://api.github.com/users/ShubhamSrivastava93/events{/privacy}", "received_events_url": "https://api.github.com/users/ShubhamSrivastava93/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-02T06:59:21Z", "updated_at": "2018-08-02T06:59:21Z", "author_association": "NONE", "body_html": "<p>Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25754898\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrehentz\">@andrehentz</a>. I tried below command for non-quantized squeezenet model (.pb)</p>\n<pre><code>bazel-bin/tensorflow/contrib/lite/toco/toco \\\n  --input_file=/somePath/xyz.pb \\\n  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\n  --output_file=/somePath/xyz.tflite --inference_type=FLOAT \\\n  --input_type=FLOAT --input_arrays=input_node \\\n  --output_arrays=output_node --input_shapes=1,256,256 \\\n  --quantize_weights \n</code></pre>\n<p>but the size of generated .tflite remains almost same, whereas by using quantized_graph, when I quantized model the size reduced to 1/4 th of the original squeezenet model.(.pb). I want nearly same size reduction in .tflite.  My main aim behind quantization is to reduce size.</p>", "body_text": "Thanks @andrehentz. I tried below command for non-quantized squeezenet model (.pb)\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\n  --input_file=/somePath/xyz.pb \\\n  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\n  --output_file=/somePath/xyz.tflite --inference_type=FLOAT \\\n  --input_type=FLOAT --input_arrays=input_node \\\n  --output_arrays=output_node --input_shapes=1,256,256 \\\n  --quantize_weights \n\nbut the size of generated .tflite remains almost same, whereas by using quantized_graph, when I quantized model the size reduced to 1/4 th of the original squeezenet model.(.pb). I want nearly same size reduction in .tflite.  My main aim behind quantization is to reduce size.", "body": "Thanks @andrehentz. I tried below command for non-quantized squeezenet model (.pb)\r\n```\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n  --input_file=/somePath/xyz.pb \\\r\n  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\r\n  --output_file=/somePath/xyz.tflite --inference_type=FLOAT \\\r\n  --input_type=FLOAT --input_arrays=input_node \\\r\n  --output_arrays=output_node --input_shapes=1,256,256 \\\r\n  --quantize_weights \r\n```\r\nbut the size of generated .tflite remains almost same, whereas by using quantized_graph, when I quantized model the size reduced to 1/4 th of the original squeezenet model.(.pb). I want nearly same size reduction in .tflite.  My main aim behind quantization is to reduce size. "}