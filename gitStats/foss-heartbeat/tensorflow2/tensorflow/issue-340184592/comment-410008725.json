{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/410008725", "html_url": "https://github.com/tensorflow/tensorflow/issues/20691#issuecomment-410008725", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20691", "id": 410008725, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDAwODcyNQ==", "user": {"login": "raghuraman-k", "id": 34699873, "node_id": "MDQ6VXNlcjM0Njk5ODcz", "avatar_url": "https://avatars2.githubusercontent.com/u/34699873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raghuraman-k", "html_url": "https://github.com/raghuraman-k", "followers_url": "https://api.github.com/users/raghuraman-k/followers", "following_url": "https://api.github.com/users/raghuraman-k/following{/other_user}", "gists_url": "https://api.github.com/users/raghuraman-k/gists{/gist_id}", "starred_url": "https://api.github.com/users/raghuraman-k/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raghuraman-k/subscriptions", "organizations_url": "https://api.github.com/users/raghuraman-k/orgs", "repos_url": "https://api.github.com/users/raghuraman-k/repos", "events_url": "https://api.github.com/users/raghuraman-k/events{/privacy}", "received_events_url": "https://api.github.com/users/raghuraman-k/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-02T17:38:21Z", "updated_at": "2018-08-02T17:38:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p>toco does not convert weights into quantized values for small layers, this size is currently set to 1024 at <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/graph_transformations/quantize_weights.cc\">quantized_weights.cc</a>. This should not impact results for squeezenet as most layers are above this limit.  Can you try doing this for mobilenet_v1_1_224 and see if you observe a 4x size reduction? Can you also share the file sizes that you see at the output of toco with and without quantize_weights flag?</p>", "body_text": "toco does not convert weights into quantized values for small layers, this size is currently set to 1024 at quantized_weights.cc. This should not impact results for squeezenet as most layers are above this limit.  Can you try doing this for mobilenet_v1_1_224 and see if you observe a 4x size reduction? Can you also share the file sizes that you see at the output of toco with and without quantize_weights flag?", "body": "toco does not convert weights into quantized values for small layers, this size is currently set to 1024 at [quantized_weights.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/graph_transformations/quantize_weights.cc). This should not impact results for squeezenet as most layers are above this limit.  Can you try doing this for mobilenet_v1_1_224 and see if you observe a 4x size reduction? Can you also share the file sizes that you see at the output of toco with and without quantize_weights flag?"}