{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/222007321", "html_url": "https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-222007321", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2514", "id": 222007321, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMjAwNzMyMQ==", "user": {"login": "markpwoodward", "id": 6820773, "node_id": "MDQ6VXNlcjY4MjA3NzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6820773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markpwoodward", "html_url": "https://github.com/markpwoodward", "followers_url": "https://api.github.com/users/markpwoodward/followers", "following_url": "https://api.github.com/users/markpwoodward/following{/other_user}", "gists_url": "https://api.github.com/users/markpwoodward/gists{/gist_id}", "starred_url": "https://api.github.com/users/markpwoodward/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markpwoodward/subscriptions", "organizations_url": "https://api.github.com/users/markpwoodward/orgs", "repos_url": "https://api.github.com/users/markpwoodward/repos", "events_url": "https://api.github.com/users/markpwoodward/events{/privacy}", "received_events_url": "https://api.github.com/users/markpwoodward/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-26T21:59:04Z", "updated_at": "2016-05-26T21:59:04Z", "author_association": "NONE", "body_html": "<p>Thank you for the suggestion. I guess I stayed away from two graphs to avoid code duplication between train and eval graphs and the accompanying maintenance issues, and because it would require updating the eval model weights with the trained model weights. I could define them both within one graph and share the weights, but that feels messy and still has the duplication.</p>\n<p>With a single model, I can just run <code>sess.run([loss, train_op],...)</code> for training, or leave off train_op for eval <code>sess.run([loss],...)</code>. It seems clean; only one place to modify the model and weights are ready from the previous training invocation.</p>", "body_text": "Thank you for the suggestion. I guess I stayed away from two graphs to avoid code duplication between train and eval graphs and the accompanying maintenance issues, and because it would require updating the eval model weights with the trained model weights. I could define them both within one graph and share the weights, but that feels messy and still has the duplication.\nWith a single model, I can just run sess.run([loss, train_op],...) for training, or leave off train_op for eval sess.run([loss],...). It seems clean; only one place to modify the model and weights are ready from the previous training invocation.", "body": "Thank you for the suggestion. I guess I stayed away from two graphs to avoid code duplication between train and eval graphs and the accompanying maintenance issues, and because it would require updating the eval model weights with the trained model weights. I could define them both within one graph and share the weights, but that feels messy and still has the duplication. \n\nWith a single model, I can just run `sess.run([loss, train_op],...)` for training, or leave off train_op for eval `sess.run([loss],...)`. It seems clean; only one place to modify the model and weights are ready from the previous training invocation.\n"}