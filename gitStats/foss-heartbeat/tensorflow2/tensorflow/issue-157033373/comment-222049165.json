{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/222049165", "html_url": "https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-222049165", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2514", "id": 222049165, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMjA0OTE2NQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-27T03:00:18Z", "updated_at": "2016-05-27T03:00:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>People usually use one method to create the core of the code, and a<br>\nseparate method to take its output and generate the loss and gradients. A<br>\nthird to generate the eval losses.  This way you can share code and<br>\nvariables between the two graphs.  See tf.contrib.learn.<br>\nOn May 26, 2016 3:05 PM, \"Mark Woodward\" <a href=\"mailto:notifications@github.com\">notifications@github.com</a> wrote:</p>\n<blockquote>\n<p>If this isn't how others are structuring their code, then there is no<br>\nurgency/necessity. I have been pre-computing the number of enqueue()'s that<br>\nwill be performed in an epoch, and then running the consumer the<br>\nappropriate number of times, with asserts that the producer is not alive<br>\nand the queue is empty before starting the next epoch.</p>\n<p>\u2014<br>\nYou are receiving this because you were mentioned.<br>\nReply to this email directly or view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"157033373\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2514\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2514/hovercard?comment_id=222008578&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-222008578\">#2514 (comment)</a></p>\n</blockquote>", "body_text": "People usually use one method to create the core of the code, and a\nseparate method to take its output and generate the loss and gradients. A\nthird to generate the eval losses.  This way you can share code and\nvariables between the two graphs.  See tf.contrib.learn.\nOn May 26, 2016 3:05 PM, \"Mark Woodward\" notifications@github.com wrote:\n\nIf this isn't how others are structuring their code, then there is no\nurgency/necessity. I have been pre-computing the number of enqueue()'s that\nwill be performed in an epoch, and then running the consumer the\nappropriate number of times, with asserts that the producer is not alive\nand the queue is empty before starting the next epoch.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n#2514 (comment)", "body": "People usually use one method to create the core of the code, and a\nseparate method to take its output and generate the loss and gradients. A\nthird to generate the eval losses.  This way you can share code and\nvariables between the two graphs.  See tf.contrib.learn.\nOn May 26, 2016 3:05 PM, \"Mark Woodward\" notifications@github.com wrote:\n\n> If this isn't how others are structuring their code, then there is no\n> urgency/necessity. I have been pre-computing the number of enqueue()'s that\n> will be performed in an epoch, and then running the consumer the\n> appropriate number of times, with asserts that the producer is not alive\n> and the queue is empty before starting the next epoch.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-222008578\n"}