{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/304937912", "html_url": "https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-304937912", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2514", "id": 304937912, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNDkzNzkxMg==", "user": {"login": "bsautermeister", "id": 2537736, "node_id": "MDQ6VXNlcjI1Mzc3MzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/2537736?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bsautermeister", "html_url": "https://github.com/bsautermeister", "followers_url": "https://api.github.com/users/bsautermeister/followers", "following_url": "https://api.github.com/users/bsautermeister/following{/other_user}", "gists_url": "https://api.github.com/users/bsautermeister/gists{/gist_id}", "starred_url": "https://api.github.com/users/bsautermeister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bsautermeister/subscriptions", "organizations_url": "https://api.github.com/users/bsautermeister/orgs", "repos_url": "https://api.github.com/users/bsautermeister/repos", "events_url": "https://api.github.com/users/bsautermeister/events{/privacy}", "received_events_url": "https://api.github.com/users/bsautermeister/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-30T16:44:36Z", "updated_at": "2017-05-30T16:46:06Z", "author_association": "NONE", "body_html": "<p>In my opinion, <code>tf.train.maybe_batch()</code> is not working properly yet. By looking at the code, it is exactly the same method as <code>tf.train.batch()</code>. The latter simply uses <em>keep_input=True</em>.</p>\n<p>According to the API documentation, <em>keep_input</em> is a bool Tensor, so it should accept a <code>tf.placeholder(tf.bool)</code> as well, right? But when I use a placeholder, and feed it with the value <em>True</em>, the queue is simply blocking and nothing is happening.</p>\n<p>I tried something like that:</p>\n<pre><code>is_training = tf.placeholder(tf.bool, shape=[])\n\n...\n\nimage_batch, label_batch = tf.cond(is_training,\n                                   true_fn=lambda: tf.train.maybe_batch([train_image, train_label],\n                                                                        keep_input=is_training,\n                                                                        batch_size=BATCH_SIZE),\n                                   false_fn=lambda: tf.train.maybe_batch([test_image, test_label],\n                                                                         keep_input=tf.logical_not(is_training),\n                                                                         batch_size=BATCH_SIZE))\nwith tf.Session() as sess:\n    # initialize the variables\n    sess.run(tf.local_variables_initializer())\n    sess.run(tf.global_variables_initializer())\n\n    # initialize the queue threads to start to shovel data\n    threads = tf.train.start_queue_runners(coord=tf.train.Coordinator())\n\n    for i in range(10):\n        print sess.run(label_batch, feed_dict={is_training: True})\n...\n</code></pre>\n<p>I thought of <code>tf.train.maybe_batch()</code> to be similar to the approach to use <code>tf.cond()</code> to switch between input-queue (for training) and feeding (for validation), but probably without having the <a href=\"https://groups.google.com/a/tensorflow.org/forum/#!msg/discuss/mLrt5qc9_uU/sGNbC7GpAwAJ\" rel=\"nofollow\">downside described here</a>. But it's also possible that I got this wrong...</p>", "body_text": "In my opinion, tf.train.maybe_batch() is not working properly yet. By looking at the code, it is exactly the same method as tf.train.batch(). The latter simply uses keep_input=True.\nAccording to the API documentation, keep_input is a bool Tensor, so it should accept a tf.placeholder(tf.bool) as well, right? But when I use a placeholder, and feed it with the value True, the queue is simply blocking and nothing is happening.\nI tried something like that:\nis_training = tf.placeholder(tf.bool, shape=[])\n\n...\n\nimage_batch, label_batch = tf.cond(is_training,\n                                   true_fn=lambda: tf.train.maybe_batch([train_image, train_label],\n                                                                        keep_input=is_training,\n                                                                        batch_size=BATCH_SIZE),\n                                   false_fn=lambda: tf.train.maybe_batch([test_image, test_label],\n                                                                         keep_input=tf.logical_not(is_training),\n                                                                         batch_size=BATCH_SIZE))\nwith tf.Session() as sess:\n    # initialize the variables\n    sess.run(tf.local_variables_initializer())\n    sess.run(tf.global_variables_initializer())\n\n    # initialize the queue threads to start to shovel data\n    threads = tf.train.start_queue_runners(coord=tf.train.Coordinator())\n\n    for i in range(10):\n        print sess.run(label_batch, feed_dict={is_training: True})\n...\n\nI thought of tf.train.maybe_batch() to be similar to the approach to use tf.cond() to switch between input-queue (for training) and feeding (for validation), but probably without having the downside described here. But it's also possible that I got this wrong...", "body": "In my opinion, `tf.train.maybe_batch()` is not working properly yet. By looking at the code, it is exactly the same method as `tf.train.batch()`. The latter simply uses _keep_input=True_.\r\n\r\nAccording to the API documentation, _keep_input_ is a bool Tensor, so it should accept a `tf.placeholder(tf.bool)` as well, right? But when I use a placeholder, and feed it with the value _True_, the queue is simply blocking and nothing is happening.\r\n\r\nI tried something like that:\r\n\r\n```\r\nis_training = tf.placeholder(tf.bool, shape=[])\r\n\r\n...\r\n\r\nimage_batch, label_batch = tf.cond(is_training,\r\n                                   true_fn=lambda: tf.train.maybe_batch([train_image, train_label],\r\n                                                                        keep_input=is_training,\r\n                                                                        batch_size=BATCH_SIZE),\r\n                                   false_fn=lambda: tf.train.maybe_batch([test_image, test_label],\r\n                                                                         keep_input=tf.logical_not(is_training),\r\n                                                                         batch_size=BATCH_SIZE))\r\nwith tf.Session() as sess:\r\n    # initialize the variables\r\n    sess.run(tf.local_variables_initializer())\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    # initialize the queue threads to start to shovel data\r\n    threads = tf.train.start_queue_runners(coord=tf.train.Coordinator())\r\n\r\n    for i in range(10):\r\n        print sess.run(label_batch, feed_dict={is_training: True})\r\n...\r\n```\r\nI thought of `tf.train.maybe_batch()` to be similar to the approach to use `tf.cond()` to switch between input-queue (for training) and feeding (for validation), but probably without having the [downside described here](https://groups.google.com/a/tensorflow.org/forum/#!msg/discuss/mLrt5qc9_uU/sGNbC7GpAwAJ). But it's also possible that I got this wrong..."}