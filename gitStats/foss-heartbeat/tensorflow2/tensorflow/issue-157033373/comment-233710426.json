{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/233710426", "html_url": "https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-233710426", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2514", "id": 233710426, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMzcxMDQyNg==", "user": {"login": "markpwoodward", "id": 6820773, "node_id": "MDQ6VXNlcjY4MjA3NzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6820773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markpwoodward", "html_url": "https://github.com/markpwoodward", "followers_url": "https://api.github.com/users/markpwoodward/followers", "following_url": "https://api.github.com/users/markpwoodward/following{/other_user}", "gists_url": "https://api.github.com/users/markpwoodward/gists{/gist_id}", "starred_url": "https://api.github.com/users/markpwoodward/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markpwoodward/subscriptions", "organizations_url": "https://api.github.com/users/markpwoodward/orgs", "repos_url": "https://api.github.com/users/markpwoodward/repos", "events_url": "https://api.github.com/users/markpwoodward/events{/privacy}", "received_events_url": "https://api.github.com/users/markpwoodward/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-19T17:43:24Z", "updated_at": "2016-07-19T17:43:24Z", "author_association": "NONE", "body_html": "<p>Christian, just a clarification, doesn't calling make_template twice create<br>\nduplicate operation paths in the graph, one for training and one for<br>\nvalidation? That duplication is probably harmless, it just seems messy when<br>\nall we want to do is switch between two input sources (although I don't<br>\nhave an alternative to propose).</p>\n<p>On Tue, Jul 19, 2016 at 12:05 AM, Christian <a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\nwrote:</p>\n<blockquote>\n<p>With make_template there won't be multiple copies of the graph.<br>\nTensorboard nicely shows that the two queues (one for training data, the<br>\nother for validation data) share one graph with the weights (True, you need<br>\nto have two different smaller pieces of loss expressions that are<br>\nassociated with the queue and are placed on top of the one graph that has<br>\nthe trainable parameters). Deciding which queue is used is done on the<br>\nouter training iteration loop, no tf.cond or any other expression-based<br>\nlogic necessary, you just sess.run the respective loss expression and the<br>\nunderlying queue is polled.</p>\n<p>\u2014<br>\nYou are receiving this because you authored the thread.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"157033373\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2514\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2514/hovercard?comment_id=233548788&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-233548788\">#2514 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/AGgTpRXoUlDAdmhT6zbDrHRd5_ReufOaks5qXHdXgaJpZM4Inwby\">https://github.com/notifications/unsubscribe-auth/AGgTpRXoUlDAdmhT6zbDrHRd5_ReufOaks5qXHdXgaJpZM4Inwby</a><br>\n.</p>\n</blockquote>", "body_text": "Christian, just a clarification, doesn't calling make_template twice create\nduplicate operation paths in the graph, one for training and one for\nvalidation? That duplication is probably harmless, it just seems messy when\nall we want to do is switch between two input sources (although I don't\nhave an alternative to propose).\nOn Tue, Jul 19, 2016 at 12:05 AM, Christian notifications@github.com\nwrote:\n\nWith make_template there won't be multiple copies of the graph.\nTensorboard nicely shows that the two queues (one for training data, the\nother for validation data) share one graph with the weights (True, you need\nto have two different smaller pieces of loss expressions that are\nassociated with the queue and are placed on top of the one graph that has\nthe trainable parameters). Deciding which queue is used is done on the\nouter training iteration loop, no tf.cond or any other expression-based\nlogic necessary, you just sess.run the respective loss expression and the\nunderlying queue is polled.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\n#2514 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGgTpRXoUlDAdmhT6zbDrHRd5_ReufOaks5qXHdXgaJpZM4Inwby\n.", "body": "Christian, just a clarification, doesn't calling make_template twice create\nduplicate operation paths in the graph, one for training and one for\nvalidation? That duplication is probably harmless, it just seems messy when\nall we want to do is switch between two input sources (although I don't\nhave an alternative to propose).\n\nOn Tue, Jul 19, 2016 at 12:05 AM, Christian notifications@github.com\nwrote:\n\n> With make_template there won't be multiple copies of the graph.\n> Tensorboard nicely shows that the two queues (one for training data, the\n> other for validation data) share one graph with the weights (True, you need\n> to have two different smaller pieces of loss expressions that are\n> associated with the queue and are placed on top of the one graph that has\n> the trainable parameters). Deciding which queue is used is done on the\n> outer training iteration loop, no tf.cond or any other expression-based\n> logic necessary, you just sess.run the respective loss expression and the\n> underlying queue is polled.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-233548788,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AGgTpRXoUlDAdmhT6zbDrHRd5_ReufOaks5qXHdXgaJpZM4Inwby\n> .\n"}