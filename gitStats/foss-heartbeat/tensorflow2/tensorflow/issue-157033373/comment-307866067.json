{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/307866067", "html_url": "https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-307866067", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2514", "id": 307866067, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzg2NjA2Nw==", "user": {"login": "danijar", "id": 2111293, "node_id": "MDQ6VXNlcjIxMTEyOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2111293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danijar", "html_url": "https://github.com/danijar", "followers_url": "https://api.github.com/users/danijar/followers", "following_url": "https://api.github.com/users/danijar/following{/other_user}", "gists_url": "https://api.github.com/users/danijar/gists{/gist_id}", "starred_url": "https://api.github.com/users/danijar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danijar/subscriptions", "organizations_url": "https://api.github.com/users/danijar/orgs", "repos_url": "https://api.github.com/users/danijar/repos", "events_url": "https://api.github.com/users/danijar/events{/privacy}", "received_events_url": "https://api.github.com/users/danijar/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-12T17:51:55Z", "updated_at": "2017-06-12T17:52:30Z", "author_association": "MEMBER", "body_html": "<p>Here is a hacky solution using <code>tf.FIFOQueue.from_list()</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">select_batch</span>(<span class=\"pl-smi\">batches</span>, <span class=\"pl-smi\">index</span>):\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">  Select a batch based on the current value of the index. Only the active batch</span>\n<span class=\"pl-s\">  will be consumed. Each batch can be an arbitrarily nested tuple or list.</span>\n<span class=\"pl-s\">  <span class=\"pl-pds\">\"\"\"</span></span>\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">_get_dtypes</span>(<span class=\"pl-smi\">tensors</span>):\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(tensors, (<span class=\"pl-c1\">list</span>, <span class=\"pl-c1\">tuple</span>)):\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">type</span>(tensors)(_get_dtypes(tensor) <span class=\"pl-k\">for</span> tensor <span class=\"pl-k\">in</span> tensors)\n    <span class=\"pl-k\">return</span> tensors.dtype\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">_get_shapes</span>(<span class=\"pl-smi\">tensors</span>):\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(tensors, (<span class=\"pl-c1\">list</span>, <span class=\"pl-c1\">tuple</span>)):\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">type</span>(tensors)(_get_shapes(tensor) <span class=\"pl-k\">for</span> tensor <span class=\"pl-k\">in</span> tensors)\n    <span class=\"pl-k\">return</span> tensors.shape\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">_flatten</span>(<span class=\"pl-smi\">collection</span>):\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(collection, (<span class=\"pl-c1\">list</span>, <span class=\"pl-c1\">tuple</span>)):\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">sum</span>([_flatten(element) <span class=\"pl-k\">for</span> element <span class=\"pl-k\">in</span> collection], [])\n    <span class=\"pl-k\">return</span> [collection]\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">_unflatten</span>(<span class=\"pl-smi\">iterator</span>, <span class=\"pl-smi\">shapes</span>):\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(shapes, (<span class=\"pl-c1\">list</span>, <span class=\"pl-c1\">tuple</span>)):\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">type</span>(shapes)(_unflatten(iterator, shape) <span class=\"pl-k\">for</span> shape <span class=\"pl-k\">in</span> shapes)\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">next</span>(iterator)\n\n  queues <span class=\"pl-k\">=</span> []\n  <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> batches:\n    dtypes, shapes <span class=\"pl-k\">=</span> _get_dtypes(batch), _get_shapes(batch)\n    queue <span class=\"pl-k\">=</span> tf.FIFOQueue(<span class=\"pl-c1\">10</span>, _flatten(dtypes), _flatten(shapes))\n    runner <span class=\"pl-k\">=</span> tf.train.QueueRunner(queue, (queue.enqueue(_flatten(batch)),))\n    tf.train.add_queue_runner(runner)\n    queues.append(queue)\n  batch <span class=\"pl-k\">=</span> tf.FIFOQueue.from_list(index, queues).dequeue()\n  <span class=\"pl-k\">return</span> _unflatten(<span class=\"pl-c1\">iter</span>(batch), shapes)</pre></div>", "body_text": "Here is a hacky solution using tf.FIFOQueue.from_list():\ndef select_batch(batches, index):\n  \"\"\"\n  Select a batch based on the current value of the index. Only the active batch\n  will be consumed. Each batch can be an arbitrarily nested tuple or list.\n  \"\"\"\n\n  def _get_dtypes(tensors):\n    if isinstance(tensors, (list, tuple)):\n      return type(tensors)(_get_dtypes(tensor) for tensor in tensors)\n    return tensors.dtype\n\n  def _get_shapes(tensors):\n    if isinstance(tensors, (list, tuple)):\n      return type(tensors)(_get_shapes(tensor) for tensor in tensors)\n    return tensors.shape\n\n  def _flatten(collection):\n    if isinstance(collection, (list, tuple)):\n      return sum([_flatten(element) for element in collection], [])\n    return [collection]\n\n  def _unflatten(iterator, shapes):\n    if isinstance(shapes, (list, tuple)):\n      return type(shapes)(_unflatten(iterator, shape) for shape in shapes)\n    return next(iterator)\n\n  queues = []\n  for batch in batches:\n    dtypes, shapes = _get_dtypes(batch), _get_shapes(batch)\n    queue = tf.FIFOQueue(10, _flatten(dtypes), _flatten(shapes))\n    runner = tf.train.QueueRunner(queue, (queue.enqueue(_flatten(batch)),))\n    tf.train.add_queue_runner(runner)\n    queues.append(queue)\n  batch = tf.FIFOQueue.from_list(index, queues).dequeue()\n  return _unflatten(iter(batch), shapes)", "body": "Here is a hacky solution using `tf.FIFOQueue.from_list()`:\r\n\r\n```python\r\ndef select_batch(batches, index):\r\n  \"\"\"\r\n  Select a batch based on the current value of the index. Only the active batch\r\n  will be consumed. Each batch can be an arbitrarily nested tuple or list.\r\n  \"\"\"\r\n\r\n  def _get_dtypes(tensors):\r\n    if isinstance(tensors, (list, tuple)):\r\n      return type(tensors)(_get_dtypes(tensor) for tensor in tensors)\r\n    return tensors.dtype\r\n\r\n  def _get_shapes(tensors):\r\n    if isinstance(tensors, (list, tuple)):\r\n      return type(tensors)(_get_shapes(tensor) for tensor in tensors)\r\n    return tensors.shape\r\n\r\n  def _flatten(collection):\r\n    if isinstance(collection, (list, tuple)):\r\n      return sum([_flatten(element) for element in collection], [])\r\n    return [collection]\r\n\r\n  def _unflatten(iterator, shapes):\r\n    if isinstance(shapes, (list, tuple)):\r\n      return type(shapes)(_unflatten(iterator, shape) for shape in shapes)\r\n    return next(iterator)\r\n\r\n  queues = []\r\n  for batch in batches:\r\n    dtypes, shapes = _get_dtypes(batch), _get_shapes(batch)\r\n    queue = tf.FIFOQueue(10, _flatten(dtypes), _flatten(shapes))\r\n    runner = tf.train.QueueRunner(queue, (queue.enqueue(_flatten(batch)),))\r\n    tf.train.add_queue_runner(runner)\r\n    queues.append(queue)\r\n  batch = tf.FIFOQueue.from_list(index, queues).dequeue()\r\n  return _unflatten(iter(batch), shapes)\r\n```"}