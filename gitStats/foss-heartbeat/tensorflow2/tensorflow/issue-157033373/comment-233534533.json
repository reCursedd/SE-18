{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/233534533", "html_url": "https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-233534533", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2514", "id": 233534533, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMzUzNDUzMw==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-19T05:16:52Z", "updated_at": "2016-07-19T05:16:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p>What can work is a cond(filter_predicate, lambda: queue.enqueue(..),<br>\ntf.no_op).  This allows controlling what goes into a queue.  Most other<br>\nways of combining queues and tf.cond usually don't have the behavior you<br>\nwould expect.</p>\n<p>On Jul 18, 2016 8:20 PM, \"Mark Woodward\" <a href=\"mailto:notifications@github.com\">notifications@github.com</a> wrote:</p>\n<blockquote>\n<p>Oops, tf.cond may be the wrong choice, as ebrevdo mentions in the parallel<br>\nthread which I will stop referencing now. From the documentation, it seems<br>\nthat tf.cond executes both paths up to, but not including, the final<br>\noperation, so it wouldn't work as I had hoped.</p>\n<p>Perhaps it could still work if what was passed to tf.cond() was the<br>\nqueue.dequeue(), or queue.dequeue_many(), operations for the train_queue<br>\nand validation_queue. But those may themselves be the end of other tf<br>\noperations, so it might still not work.</p>\n<p>On Mon, Jul 18, 2016 at 5:59 PM, Mark Woodward <a href=\"mailto:mwoodward@cs.stanford.edu\">mwoodward@cs.stanford.edu</a><br>\nwrote:</p>\n<blockquote>\n<p>I ended up doing the switching between validation and train in a python<br>\nproducer thread, and counting the number of elements processed. But I<br>\nhave<br>\nbeen thinking about this a bit, and I am leaning towards a similar (maybe<br>\nsame) idea as yours, where there are two queues (train and validation),<br>\nwith a tf.cond switching between queues, controlled by a placeholder.<br>\nThis<br>\nwould allow for a single model graph (no need for multiple instantiations<br>\nwith shared weights). Funny enough, Rohit Girdhar just emailed the list<br>\nwith a question, and it seems that this is the setup he is using. I<br>\ncopied<br>\nthe relevant portion below.</p>\n<p>\"I'm training a deep network with two data input pipelines, one for<br>\ntraining and one for validation. They use <code>shuffle_batch_join</code> and<br>\n<code>batch_join</code> respectively for parallel data reading. The data stream that<br>\nis used in the network is decided using a <code>tf.cond</code> operation on top of<br>\nthese two pipelines, which is controlled by a <code>is_training</code> placeholder<br>\nthat is set to true for a training iteration and false when doing<br>\nvalidation. I have 4 threads for reading training data and 1 thread for<br>\nvalidation...\"</p>\n<p>On Mon, Jul 18, 2016 at 12:21 PM, Christian <a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\nwrote:</p>\n<blockquote>\n<p>Picking up this old thread, a question: why don't you use make_template<br>\nand have three queues feeding into three automatically shared model<br>\ngraphs?<br>\nTrue, you still need to keep track when an epoch ends and switch over to<br>\nthe e.g. validation queue, but this can be done rather simple by either<br>\ncounting or have the queues return a third element that indicates one<br>\nfull<br>\npass through the data (training or validation data) is done. Or is this<br>\napproach considered harmful in some way?</p>\n<p>\u2014<br>\nYou are receiving this because you authored the thread.<br>\nReply to this email directly, view it on GitHub<br>\n&lt;<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"157033373\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2514\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2514/hovercard?comment_id=233430140&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-233430140\">#2514 (comment)</a><br>\n,<br>\nor mute the thread<br>\n&lt;<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/AGgTpS5Jyv_NEidwew9thKg9x5KTJAiRks5qW9IhgaJpZM4Inwby\">https://github.com/notifications/unsubscribe-auth/AGgTpS5Jyv_NEidwew9thKg9x5KTJAiRks5qW9IhgaJpZM4Inwby</a></p>\n<p>.</p>\n</blockquote>\n</blockquote>\n<p>\u2014<br>\nYou are receiving this because you were mentioned.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"157033373\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2514\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2514/hovercard?comment_id=233519829&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-233519829\">#2514 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim7VModT2soQ10NwRw9Zf7-umSE5Rks5qXEKFgaJpZM4Inwby\">https://github.com/notifications/unsubscribe-auth/ABtim7VModT2soQ10NwRw9Zf7-umSE5Rks5qXEKFgaJpZM4Inwby</a><br>\n.</p>\n</blockquote>", "body_text": "What can work is a cond(filter_predicate, lambda: queue.enqueue(..),\ntf.no_op).  This allows controlling what goes into a queue.  Most other\nways of combining queues and tf.cond usually don't have the behavior you\nwould expect.\nOn Jul 18, 2016 8:20 PM, \"Mark Woodward\" notifications@github.com wrote:\n\nOops, tf.cond may be the wrong choice, as ebrevdo mentions in the parallel\nthread which I will stop referencing now. From the documentation, it seems\nthat tf.cond executes both paths up to, but not including, the final\noperation, so it wouldn't work as I had hoped.\nPerhaps it could still work if what was passed to tf.cond() was the\nqueue.dequeue(), or queue.dequeue_many(), operations for the train_queue\nand validation_queue. But those may themselves be the end of other tf\noperations, so it might still not work.\nOn Mon, Jul 18, 2016 at 5:59 PM, Mark Woodward mwoodward@cs.stanford.edu\nwrote:\n\nI ended up doing the switching between validation and train in a python\nproducer thread, and counting the number of elements processed. But I\nhave\nbeen thinking about this a bit, and I am leaning towards a similar (maybe\nsame) idea as yours, where there are two queues (train and validation),\nwith a tf.cond switching between queues, controlled by a placeholder.\nThis\nwould allow for a single model graph (no need for multiple instantiations\nwith shared weights). Funny enough, Rohit Girdhar just emailed the list\nwith a question, and it seems that this is the setup he is using. I\ncopied\nthe relevant portion below.\n\"I'm training a deep network with two data input pipelines, one for\ntraining and one for validation. They use shuffle_batch_join and\nbatch_join respectively for parallel data reading. The data stream that\nis used in the network is decided using a tf.cond operation on top of\nthese two pipelines, which is controlled by a is_training placeholder\nthat is set to true for a training iteration and false when doing\nvalidation. I have 4 threads for reading training data and 1 thread for\nvalidation...\"\nOn Mon, Jul 18, 2016 at 12:21 PM, Christian notifications@github.com\nwrote:\n\nPicking up this old thread, a question: why don't you use make_template\nand have three queues feeding into three automatically shared model\ngraphs?\nTrue, you still need to keep track when an epoch ends and switch over to\nthe e.g. validation queue, but this can be done rather simple by either\ncounting or have the queues return a third element that indicates one\nfull\npass through the data (training or validation data) is done. Or is this\napproach considered harmful in some way?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\n<\n#2514 (comment)\n,\nor mute the thread\n<\nhttps://github.com/notifications/unsubscribe-auth/AGgTpS5Jyv_NEidwew9thKg9x5KTJAiRks5qW9IhgaJpZM4Inwby\n.\n\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n#2514 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABtim7VModT2soQ10NwRw9Zf7-umSE5Rks5qXEKFgaJpZM4Inwby\n.", "body": "What can work is a cond(filter_predicate, lambda: queue.enqueue(..),\ntf.no_op).  This allows controlling what goes into a queue.  Most other\nways of combining queues and tf.cond usually don't have the behavior you\nwould expect.\n\nOn Jul 18, 2016 8:20 PM, \"Mark Woodward\" notifications@github.com wrote:\n\n> Oops, tf.cond may be the wrong choice, as ebrevdo mentions in the parallel\n> thread which I will stop referencing now. From the documentation, it seems\n> that tf.cond executes both paths up to, but not including, the final\n> operation, so it wouldn't work as I had hoped.\n> \n> Perhaps it could still work if what was passed to tf.cond() was the\n> queue.dequeue(), or queue.dequeue_many(), operations for the train_queue\n> and validation_queue. But those may themselves be the end of other tf\n> operations, so it might still not work.\n> \n> On Mon, Jul 18, 2016 at 5:59 PM, Mark Woodward mwoodward@cs.stanford.edu\n> wrote:\n> \n> > I ended up doing the switching between validation and train in a python\n> > producer thread, and counting the number of elements processed. But I\n> > have\n> > been thinking about this a bit, and I am leaning towards a similar (maybe\n> > same) idea as yours, where there are two queues (train and validation),\n> > with a tf.cond switching between queues, controlled by a placeholder.\n> > This\n> > would allow for a single model graph (no need for multiple instantiations\n> > with shared weights). Funny enough, Rohit Girdhar just emailed the list\n> > with a question, and it seems that this is the setup he is using. I\n> > copied\n> > the relevant portion below.\n> > \n> > \"I'm training a deep network with two data input pipelines, one for\n> > training and one for validation. They use `shuffle_batch_join` and\n> > `batch_join` respectively for parallel data reading. The data stream that\n> > is used in the network is decided using a `tf.cond` operation on top of\n> > these two pipelines, which is controlled by a `is_training` placeholder\n> > that is set to true for a training iteration and false when doing\n> > validation. I have 4 threads for reading training data and 1 thread for\n> > validation...\"\n> > \n> > On Mon, Jul 18, 2016 at 12:21 PM, Christian notifications@github.com\n> > wrote:\n> > \n> > > Picking up this old thread, a question: why don't you use make_template\n> > > and have three queues feeding into three automatically shared model\n> > > graphs?\n> > > True, you still need to keep track when an epoch ends and switch over to\n> > > the e.g. validation queue, but this can be done rather simple by either\n> > > counting or have the queues return a third element that indicates one\n> > > full\n> > > pass through the data (training or validation data) is done. Or is this\n> > > approach considered harmful in some way?\n> > > \n> > > \u2014\n> > > You are receiving this because you authored the thread.\n> > > Reply to this email directly, view it on GitHub\n> > > <\n> > > https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-233430140\n> > > ,\n> > > or mute the thread\n> > > <\n> > > https://github.com/notifications/unsubscribe-auth/AGgTpS5Jyv_NEidwew9thKg9x5KTJAiRks5qW9IhgaJpZM4Inwby\n> > > \n> > > .\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2514#issuecomment-233519829,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim7VModT2soQ10NwRw9Zf7-umSE5Rks5qXEKFgaJpZM4Inwby\n> .\n"}