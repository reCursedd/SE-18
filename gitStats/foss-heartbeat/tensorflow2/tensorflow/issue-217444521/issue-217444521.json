{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8770", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8770/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8770/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8770/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8770", "id": 217444521, "node_id": "MDU6SXNzdWUyMTc0NDQ1MjE=", "number": 8770, "title": "tf.contrib.seq2seq.sequence_loss with tf.nn.sampled_softmax_loss", "user": {"login": "NickPoon", "id": 14728438, "node_id": "MDQ6VXNlcjE0NzI4NDM4", "avatar_url": "https://avatars3.githubusercontent.com/u/14728438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NickPoon", "html_url": "https://github.com/NickPoon", "followers_url": "https://api.github.com/users/NickPoon/followers", "following_url": "https://api.github.com/users/NickPoon/following{/other_user}", "gists_url": "https://api.github.com/users/NickPoon/gists{/gist_id}", "starred_url": "https://api.github.com/users/NickPoon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NickPoon/subscriptions", "organizations_url": "https://api.github.com/users/NickPoon/orgs", "repos_url": "https://api.github.com/users/NickPoon/repos", "events_url": "https://api.github.com/users/NickPoon/events{/privacy}", "received_events_url": "https://api.github.com/users/NickPoon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-03-28T04:24:41Z", "updated_at": "2018-11-09T22:52:37Z", "closed_at": "2018-11-09T22:52:37Z", "author_association": "NONE", "body_html": "<p>There maybe an incompatible matmul when use <code>tf.contrib.seq2seq.sequence_loss</code> together with <code>tf.nn.sampled_softmax_loss</code>. <code>sampled_softmax_loss</code> need a rank 2 tensor as its label, however in <code>sequence_loss</code>, the label has been reshape to [-1], which will raise an error:<br>\nValueError: Shape must be rank 2 but is rank 1 for 'sequence_loss/sampled_softmax_loss/MatMul_1' (op: 'MatMul') with input shapes: [50], [?,20].</p>\n<pre><code>    batch_size = 5\n    max_step = 10\n    dim = 20\n    vocab_size = 100\n\n    logits = tf.constant(np.random.randn(batch_size, max_step, dim),\n                         tf.float32)\n    targets = tf.constant(np.random.randint(vocab_size, size=(batch_size, max_step)),\n                         tf.int32)\n    target_weights = tf.constant(np.ones((batch_size, max_step)), tf.float32)\n    proj_w = tf.constant(np.random.randn(vocab_size, dim), tf.float32)\n    proj_b = tf.constant(np.zeros(vocab_size), tf.float32)\n\n    def _sampled_loss(labels, logits):\n        labels = tf.cast(labels, tf.int64)\n        logits = tf.cast(logits, tf.float32)\n        return tf.cast(\n                        tf.nn.sampled_softmax_loss(\n                            proj_w,\n                            proj_b,\n                            labels,\n                            logits,\n                            num_sampled=20,\n                            num_classes=vocab_size),\n                        tf.float32)\n\n    softmax_loss_f = _sampled_loss\n\n    loss = tf.contrib.seq2seq.sequence_loss(\n                    logits,\n                    targets,\n                    target_weights,\n                    softmax_loss_function=softmax_loss_f)\n\n    sess = tf.Session()\n    print sess.run(loss)\n</code></pre>\n<p>This error can be fixed if the I change line 81 in contrib/seq2seq/python/ops/loss.py:<br>\n<code>crossent = softmax_loss_function(labels=array_ops.reshape(targets, [-1, 1]), logits=logits_flat)</code></p>\n<p>tensorflow version: 1.01</p>", "body_text": "There maybe an incompatible matmul when use tf.contrib.seq2seq.sequence_loss together with tf.nn.sampled_softmax_loss. sampled_softmax_loss need a rank 2 tensor as its label, however in sequence_loss, the label has been reshape to [-1], which will raise an error:\nValueError: Shape must be rank 2 but is rank 1 for 'sequence_loss/sampled_softmax_loss/MatMul_1' (op: 'MatMul') with input shapes: [50], [?,20].\n    batch_size = 5\n    max_step = 10\n    dim = 20\n    vocab_size = 100\n\n    logits = tf.constant(np.random.randn(batch_size, max_step, dim),\n                         tf.float32)\n    targets = tf.constant(np.random.randint(vocab_size, size=(batch_size, max_step)),\n                         tf.int32)\n    target_weights = tf.constant(np.ones((batch_size, max_step)), tf.float32)\n    proj_w = tf.constant(np.random.randn(vocab_size, dim), tf.float32)\n    proj_b = tf.constant(np.zeros(vocab_size), tf.float32)\n\n    def _sampled_loss(labels, logits):\n        labels = tf.cast(labels, tf.int64)\n        logits = tf.cast(logits, tf.float32)\n        return tf.cast(\n                        tf.nn.sampled_softmax_loss(\n                            proj_w,\n                            proj_b,\n                            labels,\n                            logits,\n                            num_sampled=20,\n                            num_classes=vocab_size),\n                        tf.float32)\n\n    softmax_loss_f = _sampled_loss\n\n    loss = tf.contrib.seq2seq.sequence_loss(\n                    logits,\n                    targets,\n                    target_weights,\n                    softmax_loss_function=softmax_loss_f)\n\n    sess = tf.Session()\n    print sess.run(loss)\n\nThis error can be fixed if the I change line 81 in contrib/seq2seq/python/ops/loss.py:\ncrossent = softmax_loss_function(labels=array_ops.reshape(targets, [-1, 1]), logits=logits_flat)\ntensorflow version: 1.01", "body": "There maybe an incompatible matmul when use `tf.contrib.seq2seq.sequence_loss` together with `tf.nn.sampled_softmax_loss`. `sampled_softmax_loss` need a rank 2 tensor as its label, however in `sequence_loss`, the label has been reshape to [-1], which will raise an error:\r\nValueError: Shape must be rank 2 but is rank 1 for 'sequence_loss/sampled_softmax_loss/MatMul_1' (op: 'MatMul') with input shapes: [50], [?,20].\r\n\r\n```\r\n    batch_size = 5\r\n    max_step = 10\r\n    dim = 20\r\n    vocab_size = 100\r\n\r\n    logits = tf.constant(np.random.randn(batch_size, max_step, dim),\r\n                         tf.float32)\r\n    targets = tf.constant(np.random.randint(vocab_size, size=(batch_size, max_step)),\r\n                         tf.int32)\r\n    target_weights = tf.constant(np.ones((batch_size, max_step)), tf.float32)\r\n    proj_w = tf.constant(np.random.randn(vocab_size, dim), tf.float32)\r\n    proj_b = tf.constant(np.zeros(vocab_size), tf.float32)\r\n\r\n    def _sampled_loss(labels, logits):\r\n        labels = tf.cast(labels, tf.int64)\r\n        logits = tf.cast(logits, tf.float32)\r\n        return tf.cast(\r\n                        tf.nn.sampled_softmax_loss(\r\n                            proj_w,\r\n                            proj_b,\r\n                            labels,\r\n                            logits,\r\n                            num_sampled=20,\r\n                            num_classes=vocab_size),\r\n                        tf.float32)\r\n\r\n    softmax_loss_f = _sampled_loss\r\n\r\n    loss = tf.contrib.seq2seq.sequence_loss(\r\n                    logits,\r\n                    targets,\r\n                    target_weights,\r\n                    softmax_loss_function=softmax_loss_f)\r\n\r\n    sess = tf.Session()\r\n    print sess.run(loss)\r\n```\r\nThis error can be fixed if the I change line 81 in contrib/seq2seq/python/ops/loss.py:\r\n`crossent = softmax_loss_function(labels=array_ops.reshape(targets, [-1, 1]), logits=logits_flat)`\r\n\r\ntensorflow version: 1.01"}