{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/229855438", "html_url": "https://github.com/tensorflow/tensorflow/issues/2397#issuecomment-229855438", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2397", "id": 229855438, "node_id": "MDEyOklzc3VlQ29tbWVudDIyOTg1NTQzOA==", "user": {"login": "cmxnono", "id": 4982210, "node_id": "MDQ6VXNlcjQ5ODIyMTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/4982210?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cmxnono", "html_url": "https://github.com/cmxnono", "followers_url": "https://api.github.com/users/cmxnono/followers", "following_url": "https://api.github.com/users/cmxnono/following{/other_user}", "gists_url": "https://api.github.com/users/cmxnono/gists{/gist_id}", "starred_url": "https://api.github.com/users/cmxnono/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cmxnono/subscriptions", "organizations_url": "https://api.github.com/users/cmxnono/orgs", "repos_url": "https://api.github.com/users/cmxnono/repos", "events_url": "https://api.github.com/users/cmxnono/events{/privacy}", "received_events_url": "https://api.github.com/users/cmxnono/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-01T05:12:59Z", "updated_at": "2016-07-01T09:41:35Z", "author_association": "NONE", "body_html": "<p>Hello, i had the same problem while using distributed train.</p>\n<h1><strong>- Hardware</strong></h1>\n<pre><code>4x(Tesla K80)  on GPU-1\n4x(Tesla K40m) on GPU-2\n40 threads of Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz\n96G KiB Mem : 98738064 total\nNetwork speed between two machine 100MB/s\nping gpu-1\n64 bytes from 192.168.1.100: icmp_seq=2 ttl=64 time=4.58 ms\n64 bytes from 192.168.1.100: icmp_seq=4 ttl=64 time=0.359 ms\n64 bytes from 192.168.1.100: icmp_seq=6 ttl=64 time=3.94 ms\n64 bytes from 192.168.1.100: icmp_seq=8 ttl=64 time=0.573 ms\n64 bytes from 192.168.1.100: icmp_seq=10 ttl=64 time=3.97 ms\n64 bytes from 192.168.1.100: icmp_seq=12 ttl=64 time=0.244 ms\n</code></pre>\n<h1><strong>- Script</strong></h1>\n<p>ds.sh</p>\n<pre><code>JOBNAME=$1\nWID=$2\nGPUID=$3\nif [ \"$JOBNAME\" == \"ps\" ]; then\n    CUDA_VISIBLE_DEVICES='' bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=$HOME/imagenet-data --ps_hosts='gpu-1:2050' --worker_hosts='gpu-1:2055,gpu-1:2051,gpu-2:2052,gpu-2:2056' --job_name=''${JOBNAME}'' --task_id=${WID} --gpu_id=${GPUID} --train_dir=/tmp/imagenet_train_4core_dist2\nfi\nCUDA_VISIBLE_DEVICES=''${GPUID}'' bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=$HOME/imagenet-data--ps_hosts='gpu-1:2050' --worker_hosts='gpu-1:2055,gpu-1:2051,gpu-2:2052,gpu-2:2056' --job_name=''${JOBNAME}'' --task_id=${WID} --gpu_id=${GPUID} --train_dir=/tmp/imagenet_train_4core_dist2`\n</code></pre>\n<h1><strong>- TEST</strong></h1>\n<h2>1. Single Core</h2>\n<pre><code>nohup bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --data_dir=$HOME/imagenet-data --train_dir=/tmp/imagenet_train_single &gt; logs/train_single.log &amp;\n 2016-06-30 12:23:25.858032: step 31810, loss = 8.61 (21.4 examples/sec; 1.495 sec/batch)\n 2016-06-30 12:23:40.958675: step 31820, loss = 7.83 (20.9 examples/sec; 1.528 sec/batch)\n 2016-06-30 12:23:55.986678: step 31830, loss = 8.29 (21.4 examples/sec; 1.494 sec/batch)\n 2016-06-30 12:24:11.043151: step 31840, loss = 7.73 (21.5 examples/sec; 1.487 sec/batch)\n 2016-06-30 12:24:26.349167: step 31850, loss = 7.46 (21.1 examples/sec; 1.513 sec/batch)\n 2016-06-30 12:24:41.373939: step 31860, loss = 7.86 (21.3 examples/sec; 1.500 sec/batch)\n 2016-06-30 12:24:56.400347: step 31870, loss = 8.06 (21.3 examples/sec; 1.504 sec/batch)\n 2016-06-30 12:25:11.848877: step 31880, loss = 7.72 (21.6 examples/sec; 1.484 sec/batch)\n 2016-06-30 12:25:26.909544: step 31890, loss = 7.66 (20.8 examples/sec; 1.541 sec/batch)\n 2016-06-30 12:25:42.093352: step 31900, loss = 8.14 (20.7 examples/sec; 1.546 sec/batch)\n</code></pre>\n<h2>2. 2 Cores</h2>\n<pre><code>nohup bazel-bin/inception/imagenet_train --num_gpus=2 --batch_size=64 --train_dir=/tmp/imagenet_train_2core --data_dir=/home/chenxiu/data1/ilsvrc2012 &gt; logs/train_2core.log &amp;\n\n2016-07-01 16:45:55.176167: step 360, loss = 12.96 (37.6 examples/sec; 1.700 sec/batch)\n2016-07-01 16:46:12.253974: step 370, loss = 12.97 (37.6 examples/sec; 1.704 sec/batch)\n2016-07-01 16:46:29.297706: step 380, loss = 13.07 (37.6 examples/sec; 1.701 sec/batch)\n2016-07-01 16:46:46.365005: step 390, loss = 12.96 (37.5 examples/sec; 1.705 sec/batch)\n2016-07-01 16:47:03.472910: step 400, loss = 13.05 (37.4 examples/sec; 1.711 sec/batch)\n2016-07-01 16:47:23.656588: step 410, loss = 13.04 (36.9 examples/sec; 1.734 sec/batch)\n2016-07-01 16:47:40.896221: step 420, loss = 13.00 (37.2 examples/sec; 1.719 sec/batch)\n2016-07-01 16:47:58.285889: step 430, loss = 12.96 (37.5 examples/sec; 1.707 sec/batch)\n2016-07-01 16:48:15.344814: step 440, loss = 12.97 (37.3 examples/sec; 1.716 sec/batch)\n2016-07-01 16:48:32.417732: step 450, loss = 13.04 (37.5 examples/sec; 1.708 sec/batch)\n</code></pre>\n<h2>3. 4 Cores</h2>\n<pre><code>nohup bazel-bin/inception/imagenet_train --num_gpus=4 --batch_size=128 --train_dir=/tmp/imagenet_train_4core --data_dir=/home/chenxiu/data1/ilsvrc2012 &gt; logs/train_4core.log &amp;\n2016-07-01 17:28:45.255619: step 640, loss = 12.69 (35.2 examples/sec; 3.634 sec/batch)\n2016-07-01 17:29:05.687976: step 650, loss = 12.63 (57.5 examples/sec; 2.228 sec/batch)\n2016-07-01 17:29:26.619168: step 660, loss = 12.54 (70.7 examples/sec; 1.810 sec/batch)\n2016-07-01 17:29:46.492567: step 670, loss = 12.68 (45.6 examples/sec; 2.808 sec/batch)\n2016-07-01 17:30:06.778141: step 680, loss = 12.73 (70.2 examples/sec; 1.823 sec/batch)\n2016-07-01 17:30:26.910362: step 690, loss = 12.64 (64.6 examples/sec; 1.982 sec/batch)\n2016-07-01 17:30:48.887897: step 700, loss = 12.51 (70.6 examples/sec; 1.813 sec/batch)\n2016-07-01 17:31:09.440310: step 710, loss = 12.59 (71.1 examples/sec; 1.799 sec/batch)\n2016-07-01 17:31:27.458959: step 720, loss = 12.60 (69.4 examples/sec; 1.846 sec/batch)\n2016-07-01 17:31:46.270831: step 730, loss = 12.70 (71.0 examples/sec; 1.802 sec/batch)\n</code></pre>\n<h2>4.Distributed on GPU1/GPU5</h2>\n<p>GPU-1</p>\n<pre><code>nohup sh ds.sh ps 0 0 &gt; logs/ps.log &amp; \nnohup sh ds.sh worker 0 7 &gt; logs/worker0.log &amp; \nnohup sh ds.sh worker 1 6 &gt; logs/worker1.log &amp;\n</code></pre>\n<p>GPU-2</p>\n<pre><code>nohup sh ds.sh worker 2 1 &gt; logs/worker2.log &amp;\nnohup sh ds.sh worker 3 2 &gt; logs/worker3.log &amp;\n</code></pre>\n<pre><code>tail logs/worker0.log:\n INFO:tensorflow:Worker 0: 2016-07-01 13:03:19.768646: step 360, loss = 12.82(8.3 examples/sec; 3.879  sec/batch)\n INFO:tensorflow:global_step/sec: 0.241671\n INFO:tensorflow:Worker 0: 2016-07-01 13:05:16.359716: step 390, loss = 12.91(8.0 examples/sec; 3.976  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258332\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:07:12.427695: step 420, loss = 12.76(8.2 examples/sec; 3.900  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258331\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:09:10.921383: step 450, loss = 12.85(7.9 examples/sec; 4.056  sec/batch)\n INFO:tensorflow:global_step/sec: 0.257871\n INFO:tensorflow:Worker 0: 2016-07-01 13:11:13.658113: step 480, loss = 12.83(8.3 examples/sec; 3.867  sec/batch)\n INFO:tensorflow:global_step/sec: 0.242095\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:13:11.261521: step 510, loss = 12.66(8.1 examples/sec; 3.930  sec/batch)\n INFO:tensorflow:global_step/sec: 0.250013\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:15:09.110845: step 540, loss = 12.78(8.4 examples/sec; 3.827  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258329\n INFO:tensorflow:Worker 0: 2016-07-01 13:17:07.101986: step 570, loss = 12.66(8.1 examples/sec; 3.951  sec/batch)\n INFO:tensorflow:global_step/sec: 0.250001\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:19:04.647026: step 600, loss = 12.61(8.1 examples/sec; 3.967  sec/batch)\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:21:03.685468: step 630, loss = 12.60(8.1 examples/sec; 3.939  sec/batch)\n</code></pre>\n<h2>5.Distributed on GPU1 with 4 Cores</h2>\n<p>In this case, the sec/batch avg=2.24697</p>\n<p>I had also tried <code>--num_preprocess_threads=4/8/16 --num_readers=4</code>, but useless.</p>", "body_text": "Hello, i had the same problem while using distributed train.\n- Hardware\n4x(Tesla K80)  on GPU-1\n4x(Tesla K40m) on GPU-2\n40 threads of Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz\n96G KiB Mem : 98738064 total\nNetwork speed between two machine 100MB/s\nping gpu-1\n64 bytes from 192.168.1.100: icmp_seq=2 ttl=64 time=4.58 ms\n64 bytes from 192.168.1.100: icmp_seq=4 ttl=64 time=0.359 ms\n64 bytes from 192.168.1.100: icmp_seq=6 ttl=64 time=3.94 ms\n64 bytes from 192.168.1.100: icmp_seq=8 ttl=64 time=0.573 ms\n64 bytes from 192.168.1.100: icmp_seq=10 ttl=64 time=3.97 ms\n64 bytes from 192.168.1.100: icmp_seq=12 ttl=64 time=0.244 ms\n\n- Script\nds.sh\nJOBNAME=$1\nWID=$2\nGPUID=$3\nif [ \"$JOBNAME\" == \"ps\" ]; then\n    CUDA_VISIBLE_DEVICES='' bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=$HOME/imagenet-data --ps_hosts='gpu-1:2050' --worker_hosts='gpu-1:2055,gpu-1:2051,gpu-2:2052,gpu-2:2056' --job_name=''${JOBNAME}'' --task_id=${WID} --gpu_id=${GPUID} --train_dir=/tmp/imagenet_train_4core_dist2\nfi\nCUDA_VISIBLE_DEVICES=''${GPUID}'' bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=$HOME/imagenet-data--ps_hosts='gpu-1:2050' --worker_hosts='gpu-1:2055,gpu-1:2051,gpu-2:2052,gpu-2:2056' --job_name=''${JOBNAME}'' --task_id=${WID} --gpu_id=${GPUID} --train_dir=/tmp/imagenet_train_4core_dist2`\n\n- TEST\n1. Single Core\nnohup bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --data_dir=$HOME/imagenet-data --train_dir=/tmp/imagenet_train_single > logs/train_single.log &\n 2016-06-30 12:23:25.858032: step 31810, loss = 8.61 (21.4 examples/sec; 1.495 sec/batch)\n 2016-06-30 12:23:40.958675: step 31820, loss = 7.83 (20.9 examples/sec; 1.528 sec/batch)\n 2016-06-30 12:23:55.986678: step 31830, loss = 8.29 (21.4 examples/sec; 1.494 sec/batch)\n 2016-06-30 12:24:11.043151: step 31840, loss = 7.73 (21.5 examples/sec; 1.487 sec/batch)\n 2016-06-30 12:24:26.349167: step 31850, loss = 7.46 (21.1 examples/sec; 1.513 sec/batch)\n 2016-06-30 12:24:41.373939: step 31860, loss = 7.86 (21.3 examples/sec; 1.500 sec/batch)\n 2016-06-30 12:24:56.400347: step 31870, loss = 8.06 (21.3 examples/sec; 1.504 sec/batch)\n 2016-06-30 12:25:11.848877: step 31880, loss = 7.72 (21.6 examples/sec; 1.484 sec/batch)\n 2016-06-30 12:25:26.909544: step 31890, loss = 7.66 (20.8 examples/sec; 1.541 sec/batch)\n 2016-06-30 12:25:42.093352: step 31900, loss = 8.14 (20.7 examples/sec; 1.546 sec/batch)\n\n2. 2 Cores\nnohup bazel-bin/inception/imagenet_train --num_gpus=2 --batch_size=64 --train_dir=/tmp/imagenet_train_2core --data_dir=/home/chenxiu/data1/ilsvrc2012 > logs/train_2core.log &\n\n2016-07-01 16:45:55.176167: step 360, loss = 12.96 (37.6 examples/sec; 1.700 sec/batch)\n2016-07-01 16:46:12.253974: step 370, loss = 12.97 (37.6 examples/sec; 1.704 sec/batch)\n2016-07-01 16:46:29.297706: step 380, loss = 13.07 (37.6 examples/sec; 1.701 sec/batch)\n2016-07-01 16:46:46.365005: step 390, loss = 12.96 (37.5 examples/sec; 1.705 sec/batch)\n2016-07-01 16:47:03.472910: step 400, loss = 13.05 (37.4 examples/sec; 1.711 sec/batch)\n2016-07-01 16:47:23.656588: step 410, loss = 13.04 (36.9 examples/sec; 1.734 sec/batch)\n2016-07-01 16:47:40.896221: step 420, loss = 13.00 (37.2 examples/sec; 1.719 sec/batch)\n2016-07-01 16:47:58.285889: step 430, loss = 12.96 (37.5 examples/sec; 1.707 sec/batch)\n2016-07-01 16:48:15.344814: step 440, loss = 12.97 (37.3 examples/sec; 1.716 sec/batch)\n2016-07-01 16:48:32.417732: step 450, loss = 13.04 (37.5 examples/sec; 1.708 sec/batch)\n\n3. 4 Cores\nnohup bazel-bin/inception/imagenet_train --num_gpus=4 --batch_size=128 --train_dir=/tmp/imagenet_train_4core --data_dir=/home/chenxiu/data1/ilsvrc2012 > logs/train_4core.log &\n2016-07-01 17:28:45.255619: step 640, loss = 12.69 (35.2 examples/sec; 3.634 sec/batch)\n2016-07-01 17:29:05.687976: step 650, loss = 12.63 (57.5 examples/sec; 2.228 sec/batch)\n2016-07-01 17:29:26.619168: step 660, loss = 12.54 (70.7 examples/sec; 1.810 sec/batch)\n2016-07-01 17:29:46.492567: step 670, loss = 12.68 (45.6 examples/sec; 2.808 sec/batch)\n2016-07-01 17:30:06.778141: step 680, loss = 12.73 (70.2 examples/sec; 1.823 sec/batch)\n2016-07-01 17:30:26.910362: step 690, loss = 12.64 (64.6 examples/sec; 1.982 sec/batch)\n2016-07-01 17:30:48.887897: step 700, loss = 12.51 (70.6 examples/sec; 1.813 sec/batch)\n2016-07-01 17:31:09.440310: step 710, loss = 12.59 (71.1 examples/sec; 1.799 sec/batch)\n2016-07-01 17:31:27.458959: step 720, loss = 12.60 (69.4 examples/sec; 1.846 sec/batch)\n2016-07-01 17:31:46.270831: step 730, loss = 12.70 (71.0 examples/sec; 1.802 sec/batch)\n\n4.Distributed on GPU1/GPU5\nGPU-1\nnohup sh ds.sh ps 0 0 > logs/ps.log & \nnohup sh ds.sh worker 0 7 > logs/worker0.log & \nnohup sh ds.sh worker 1 6 > logs/worker1.log &\n\nGPU-2\nnohup sh ds.sh worker 2 1 > logs/worker2.log &\nnohup sh ds.sh worker 3 2 > logs/worker3.log &\n\ntail logs/worker0.log:\n INFO:tensorflow:Worker 0: 2016-07-01 13:03:19.768646: step 360, loss = 12.82(8.3 examples/sec; 3.879  sec/batch)\n INFO:tensorflow:global_step/sec: 0.241671\n INFO:tensorflow:Worker 0: 2016-07-01 13:05:16.359716: step 390, loss = 12.91(8.0 examples/sec; 3.976  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258332\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:07:12.427695: step 420, loss = 12.76(8.2 examples/sec; 3.900  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258331\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:09:10.921383: step 450, loss = 12.85(7.9 examples/sec; 4.056  sec/batch)\n INFO:tensorflow:global_step/sec: 0.257871\n INFO:tensorflow:Worker 0: 2016-07-01 13:11:13.658113: step 480, loss = 12.83(8.3 examples/sec; 3.867  sec/batch)\n INFO:tensorflow:global_step/sec: 0.242095\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:13:11.261521: step 510, loss = 12.66(8.1 examples/sec; 3.930  sec/batch)\n INFO:tensorflow:global_step/sec: 0.250013\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:15:09.110845: step 540, loss = 12.78(8.4 examples/sec; 3.827  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258329\n INFO:tensorflow:Worker 0: 2016-07-01 13:17:07.101986: step 570, loss = 12.66(8.1 examples/sec; 3.951  sec/batch)\n INFO:tensorflow:global_step/sec: 0.250001\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:19:04.647026: step 600, loss = 12.61(8.1 examples/sec; 3.967  sec/batch)\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:21:03.685468: step 630, loss = 12.60(8.1 examples/sec; 3.939  sec/batch)\n\n5.Distributed on GPU1 with 4 Cores\nIn this case, the sec/batch avg=2.24697\nI had also tried --num_preprocess_threads=4/8/16 --num_readers=4, but useless.", "body": "Hello, i had the same problem while using distributed train.\n\n# **\\- Hardware**\n\n```\n4x(Tesla K80)  on GPU-1\n4x(Tesla K40m) on GPU-2\n40 threads of Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz\n96G KiB Mem : 98738064 total\nNetwork speed between two machine 100MB/s\nping gpu-1\n64 bytes from 192.168.1.100: icmp_seq=2 ttl=64 time=4.58 ms\n64 bytes from 192.168.1.100: icmp_seq=4 ttl=64 time=0.359 ms\n64 bytes from 192.168.1.100: icmp_seq=6 ttl=64 time=3.94 ms\n64 bytes from 192.168.1.100: icmp_seq=8 ttl=64 time=0.573 ms\n64 bytes from 192.168.1.100: icmp_seq=10 ttl=64 time=3.97 ms\n64 bytes from 192.168.1.100: icmp_seq=12 ttl=64 time=0.244 ms\n```\n\n# **\\- Script**\n\nds.sh\n\n```\nJOBNAME=$1\nWID=$2\nGPUID=$3\nif [ \"$JOBNAME\" == \"ps\" ]; then\n    CUDA_VISIBLE_DEVICES='' bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=$HOME/imagenet-data --ps_hosts='gpu-1:2050' --worker_hosts='gpu-1:2055,gpu-1:2051,gpu-2:2052,gpu-2:2056' --job_name=''${JOBNAME}'' --task_id=${WID} --gpu_id=${GPUID} --train_dir=/tmp/imagenet_train_4core_dist2\nfi\nCUDA_VISIBLE_DEVICES=''${GPUID}'' bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=$HOME/imagenet-data--ps_hosts='gpu-1:2050' --worker_hosts='gpu-1:2055,gpu-1:2051,gpu-2:2052,gpu-2:2056' --job_name=''${JOBNAME}'' --task_id=${WID} --gpu_id=${GPUID} --train_dir=/tmp/imagenet_train_4core_dist2`\n```\n\n# **\\- TEST**\n\n## 1. Single Core\n\n```\nnohup bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --data_dir=$HOME/imagenet-data --train_dir=/tmp/imagenet_train_single > logs/train_single.log &\n 2016-06-30 12:23:25.858032: step 31810, loss = 8.61 (21.4 examples/sec; 1.495 sec/batch)\n 2016-06-30 12:23:40.958675: step 31820, loss = 7.83 (20.9 examples/sec; 1.528 sec/batch)\n 2016-06-30 12:23:55.986678: step 31830, loss = 8.29 (21.4 examples/sec; 1.494 sec/batch)\n 2016-06-30 12:24:11.043151: step 31840, loss = 7.73 (21.5 examples/sec; 1.487 sec/batch)\n 2016-06-30 12:24:26.349167: step 31850, loss = 7.46 (21.1 examples/sec; 1.513 sec/batch)\n 2016-06-30 12:24:41.373939: step 31860, loss = 7.86 (21.3 examples/sec; 1.500 sec/batch)\n 2016-06-30 12:24:56.400347: step 31870, loss = 8.06 (21.3 examples/sec; 1.504 sec/batch)\n 2016-06-30 12:25:11.848877: step 31880, loss = 7.72 (21.6 examples/sec; 1.484 sec/batch)\n 2016-06-30 12:25:26.909544: step 31890, loss = 7.66 (20.8 examples/sec; 1.541 sec/batch)\n 2016-06-30 12:25:42.093352: step 31900, loss = 8.14 (20.7 examples/sec; 1.546 sec/batch)\n```\n\n## 2. 2 Cores\n\n```\nnohup bazel-bin/inception/imagenet_train --num_gpus=2 --batch_size=64 --train_dir=/tmp/imagenet_train_2core --data_dir=/home/chenxiu/data1/ilsvrc2012 > logs/train_2core.log &\n\n2016-07-01 16:45:55.176167: step 360, loss = 12.96 (37.6 examples/sec; 1.700 sec/batch)\n2016-07-01 16:46:12.253974: step 370, loss = 12.97 (37.6 examples/sec; 1.704 sec/batch)\n2016-07-01 16:46:29.297706: step 380, loss = 13.07 (37.6 examples/sec; 1.701 sec/batch)\n2016-07-01 16:46:46.365005: step 390, loss = 12.96 (37.5 examples/sec; 1.705 sec/batch)\n2016-07-01 16:47:03.472910: step 400, loss = 13.05 (37.4 examples/sec; 1.711 sec/batch)\n2016-07-01 16:47:23.656588: step 410, loss = 13.04 (36.9 examples/sec; 1.734 sec/batch)\n2016-07-01 16:47:40.896221: step 420, loss = 13.00 (37.2 examples/sec; 1.719 sec/batch)\n2016-07-01 16:47:58.285889: step 430, loss = 12.96 (37.5 examples/sec; 1.707 sec/batch)\n2016-07-01 16:48:15.344814: step 440, loss = 12.97 (37.3 examples/sec; 1.716 sec/batch)\n2016-07-01 16:48:32.417732: step 450, loss = 13.04 (37.5 examples/sec; 1.708 sec/batch)\n```\n\n## 3. 4 Cores\n\n```\nnohup bazel-bin/inception/imagenet_train --num_gpus=4 --batch_size=128 --train_dir=/tmp/imagenet_train_4core --data_dir=/home/chenxiu/data1/ilsvrc2012 > logs/train_4core.log &\n2016-07-01 17:28:45.255619: step 640, loss = 12.69 (35.2 examples/sec; 3.634 sec/batch)\n2016-07-01 17:29:05.687976: step 650, loss = 12.63 (57.5 examples/sec; 2.228 sec/batch)\n2016-07-01 17:29:26.619168: step 660, loss = 12.54 (70.7 examples/sec; 1.810 sec/batch)\n2016-07-01 17:29:46.492567: step 670, loss = 12.68 (45.6 examples/sec; 2.808 sec/batch)\n2016-07-01 17:30:06.778141: step 680, loss = 12.73 (70.2 examples/sec; 1.823 sec/batch)\n2016-07-01 17:30:26.910362: step 690, loss = 12.64 (64.6 examples/sec; 1.982 sec/batch)\n2016-07-01 17:30:48.887897: step 700, loss = 12.51 (70.6 examples/sec; 1.813 sec/batch)\n2016-07-01 17:31:09.440310: step 710, loss = 12.59 (71.1 examples/sec; 1.799 sec/batch)\n2016-07-01 17:31:27.458959: step 720, loss = 12.60 (69.4 examples/sec; 1.846 sec/batch)\n2016-07-01 17:31:46.270831: step 730, loss = 12.70 (71.0 examples/sec; 1.802 sec/batch)\n```\n\n## 4.Distributed on GPU1/GPU5\n\nGPU-1\n\n```\nnohup sh ds.sh ps 0 0 > logs/ps.log & \nnohup sh ds.sh worker 0 7 > logs/worker0.log & \nnohup sh ds.sh worker 1 6 > logs/worker1.log &\n```\n\nGPU-2\n\n```\nnohup sh ds.sh worker 2 1 > logs/worker2.log &\nnohup sh ds.sh worker 3 2 > logs/worker3.log &\n```\n\n```\ntail logs/worker0.log:\n INFO:tensorflow:Worker 0: 2016-07-01 13:03:19.768646: step 360, loss = 12.82(8.3 examples/sec; 3.879  sec/batch)\n INFO:tensorflow:global_step/sec: 0.241671\n INFO:tensorflow:Worker 0: 2016-07-01 13:05:16.359716: step 390, loss = 12.91(8.0 examples/sec; 3.976  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258332\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:07:12.427695: step 420, loss = 12.76(8.2 examples/sec; 3.900  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258331\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:09:10.921383: step 450, loss = 12.85(7.9 examples/sec; 4.056  sec/batch)\n INFO:tensorflow:global_step/sec: 0.257871\n INFO:tensorflow:Worker 0: 2016-07-01 13:11:13.658113: step 480, loss = 12.83(8.3 examples/sec; 3.867  sec/batch)\n INFO:tensorflow:global_step/sec: 0.242095\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:13:11.261521: step 510, loss = 12.66(8.1 examples/sec; 3.930  sec/batch)\n INFO:tensorflow:global_step/sec: 0.250013\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:15:09.110845: step 540, loss = 12.78(8.4 examples/sec; 3.827  sec/batch)\n INFO:tensorflow:global_step/sec: 0.258329\n INFO:tensorflow:Worker 0: 2016-07-01 13:17:07.101986: step 570, loss = 12.66(8.1 examples/sec; 3.951  sec/batch)\n INFO:tensorflow:global_step/sec: 0.250001\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:19:04.647026: step 600, loss = 12.61(8.1 examples/sec; 3.967  sec/batch)\n INFO:tensorflow:Running Summary operation on the chief.\n INFO:tensorflow:Finished running Summary operation.\n INFO:tensorflow:Worker 0: 2016-07-01 13:21:03.685468: step 630, loss = 12.60(8.1 examples/sec; 3.939  sec/batch)\n```\n\n## 5.Distributed on GPU1 with 4 Cores\n\n  In this case, the sec/batch avg=2.24697\n\nI had also tried `--num_preprocess_threads=4/8/16 --num_readers=4`, but useless.\n"}