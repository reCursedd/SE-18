{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13446", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13446/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13446/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13446/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13446", "id": 262080326, "node_id": "MDU6SXNzdWUyNjIwODAzMjY=", "number": 13446, "title": "Dataset: \"Shuffle\" doesn't work", "user": {"login": "jundengdeng", "id": 8589835, "node_id": "MDQ6VXNlcjg1ODk4MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8589835?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jundengdeng", "html_url": "https://github.com/jundengdeng", "followers_url": "https://api.github.com/users/jundengdeng/followers", "following_url": "https://api.github.com/users/jundengdeng/following{/other_user}", "gists_url": "https://api.github.com/users/jundengdeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/jundengdeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jundengdeng/subscriptions", "organizations_url": "https://api.github.com/users/jundengdeng/orgs", "repos_url": "https://api.github.com/users/jundengdeng/repos", "events_url": "https://api.github.com/users/jundengdeng/events{/privacy}", "received_events_url": "https://api.github.com/users/jundengdeng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-10-02T13:13:38Z", "updated_at": "2017-10-02T21:04:18Z", "closed_at": "2017-10-02T21:04:18Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:  source</li>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n<li><strong>Python version</strong>: python 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\nBuild label: 0.5.4<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Fri Aug 25 10:00:00 2017 (1503655200)<br>\nBuild timestamp: 1503655200<br>\nBuild timestamp as int: 1503655200</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.3.0<br>\ntf.GIT_VERSION = b'v1.3.0-rc1-2408-ge9d5ee1'<br>\ntf.COMPILER_VERSION = b'v1.3.0-rc1-2408-ge9d5ee1'</p>\n<h3>Describe the problem</h3>\n<p>\"Shuffle\" from Dataset doesn't work.</p>\n<h3>Source code / logs</h3>\n<p>The following files can be used to reproduce problem.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\ntf.set_random_seed(<span class=\"pl-c1\">123</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">input_pipeline</span>(<span class=\"pl-smi\">filenames</span>, <span class=\"pl-smi\">batch_size</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Define a `tf.contrib.data.Dataset` for iterating over one epoch of the data.</span>\n    dataset <span class=\"pl-k\">=</span> (tf.contrib.data.TextLineDataset(filenames)\n               .map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">line</span>: tf.decode_csv(\n                    line, <span class=\"pl-v\">record_defaults</span><span class=\"pl-k\">=</span>[[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>1<span class=\"pl-pds\">'</span></span>], [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>1<span class=\"pl-pds\">'</span></span>], [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>1<span class=\"pl-pds\">'</span></span>]], <span class=\"pl-v\">field_delim</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>-<span class=\"pl-pds\">'</span></span>))\n               .shuffle(<span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Equivalent to min_after_dequeue=10.</span>\n               .batch(batch_size))\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Return an *initializable* iterator over the dataset, which will allow us to</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> re-initialize it at the beginning of each epoch.</span>\n    <span class=\"pl-k\">return</span> dataset.make_initializable_iterator()\n\nfilenames<span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>1.txt<span class=\"pl-pds\">'</span></span>]\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\nnum_epochs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\niterator <span class=\"pl-k\">=</span> input_pipeline(filenames, batch_size)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> `a1`, `a2`, and `a3` represent the next element to be retrieved from the iterator.</span>\na1, a2, a3 <span class=\"pl-k\">=</span> iterator.get_next()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-k\">for</span> epoch <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_epochs):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Resets the iterator at the beginning of an epoch.</span>\n        sess.run(iterator.initializer)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>epoch:<span class=\"pl-c1\">%d</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (epoch))\n        <span class=\"pl-k\">try</span>:\n            <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n                a, b, c <span class=\"pl-k\">=</span> sess.run([a1, a2, a3])\n                <span class=\"pl-c1\">print</span>(a, b, c)\n        <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError:\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> This will be raised when you reach the end of an epoch (i.e. the</span>\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> iterator has no more elements).</span>\n            <span class=\"pl-k\">pass</span></pre></div>\n<p>The corresponding file: \"1.txt\"</p>\n<pre><code>1,2-3,4-A\n7,8-9,10-B\n12,13-14,15-C\n17,18-19,20-D\n22,23-24,25-E\n27,28-29,30-F\n32,33-34,35-G\n37,38-39,40-H\n</code></pre>\n<p>The output:</p>\n<pre><code>2017-10-02 15:06:43.523320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-10-02 15:06:43.523788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties: \nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\npciBusID: 0000:01:00.0\ntotalMemory: 5.93GiB freeMemory: 5.44GiB\n2017-10-02 15:06:43.523800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\nepoch:0\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']\nepoch:1\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']\nepoch:2\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary):  source\nTensorFlow version (use command below):\nPython version: python 3.5\nBazel version (if compiling from source):\nBuild label: 0.5.4\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Aug 25 10:00:00 2017 (1503655200)\nBuild timestamp: 1503655200\nBuild timestamp as int: 1503655200\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n== tensorflow import ============================================\ntf.VERSION = 1.3.0\ntf.GIT_VERSION = b'v1.3.0-rc1-2408-ge9d5ee1'\ntf.COMPILER_VERSION = b'v1.3.0-rc1-2408-ge9d5ee1'\nDescribe the problem\n\"Shuffle\" from Dataset doesn't work.\nSource code / logs\nThe following files can be used to reproduce problem.\nimport tensorflow as tf\ntf.set_random_seed(123)\n\ndef input_pipeline(filenames, batch_size):\n    # Define a `tf.contrib.data.Dataset` for iterating over one epoch of the data.\n    dataset = (tf.contrib.data.TextLineDataset(filenames)\n               .map(lambda line: tf.decode_csv(\n                    line, record_defaults=[['1'], ['1'], ['1']], field_delim='-'))\n               .shuffle(buffer_size=10)  # Equivalent to min_after_dequeue=10.\n               .batch(batch_size))\n\n    # Return an *initializable* iterator over the dataset, which will allow us to\n    # re-initialize it at the beginning of each epoch.\n    return dataset.make_initializable_iterator()\n\nfilenames=['1.txt']\nbatch_size = 3\nnum_epochs = 3\niterator = input_pipeline(filenames, batch_size)\n\n# `a1`, `a2`, and `a3` represent the next element to be retrieved from the iterator.\na1, a2, a3 = iterator.get_next()\n\nwith tf.Session() as sess:\n    for epoch in range(num_epochs):\n        # Resets the iterator at the beginning of an epoch.\n        sess.run(iterator.initializer)\n        print('epoch:%d' % (epoch))\n        try:\n            while True:\n                a, b, c = sess.run([a1, a2, a3])\n                print(a, b, c)\n        except tf.errors.OutOfRangeError:\n            # This will be raised when you reach the end of an epoch (i.e. the\n            # iterator has no more elements).\n            pass\nThe corresponding file: \"1.txt\"\n1,2-3,4-A\n7,8-9,10-B\n12,13-14,15-C\n17,18-19,20-D\n22,23-24,25-E\n27,28-29,30-F\n32,33-34,35-G\n37,38-39,40-H\n\nThe output:\n2017-10-02 15:06:43.523320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-10-02 15:06:43.523788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties: \nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\npciBusID: 0000:01:00.0\ntotalMemory: 5.93GiB freeMemory: 5.44GiB\n2017-10-02 15:06:43.523800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\nepoch:0\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']\nepoch:1\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']\nepoch:2\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:  source\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: python 3.5\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.5.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Aug 25 10:00:00 2017 (1503655200)\r\nBuild timestamp: 1503655200\r\nBuild timestamp as int: 1503655200\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n== tensorflow import ============================================      \r\ntf.VERSION = 1.3.0                                                                    \r\ntf.GIT_VERSION = b'v1.3.0-rc1-2408-ge9d5ee1'                             \r\ntf.COMPILER_VERSION = b'v1.3.0-rc1-2408-ge9d5ee1'   \r\n\r\n\r\n### Describe the problem\r\n\"Shuffle\" from Dataset doesn't work. \r\n\r\n### Source code / logs\r\nThe following files can be used to reproduce problem.\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.set_random_seed(123)\r\n\r\ndef input_pipeline(filenames, batch_size):\r\n    # Define a `tf.contrib.data.Dataset` for iterating over one epoch of the data.\r\n    dataset = (tf.contrib.data.TextLineDataset(filenames)\r\n               .map(lambda line: tf.decode_csv(\r\n                    line, record_defaults=[['1'], ['1'], ['1']], field_delim='-'))\r\n               .shuffle(buffer_size=10)  # Equivalent to min_after_dequeue=10.\r\n               .batch(batch_size))\r\n\r\n    # Return an *initializable* iterator over the dataset, which will allow us to\r\n    # re-initialize it at the beginning of each epoch.\r\n    return dataset.make_initializable_iterator()\r\n\r\nfilenames=['1.txt']\r\nbatch_size = 3\r\nnum_epochs = 3\r\niterator = input_pipeline(filenames, batch_size)\r\n\r\n# `a1`, `a2`, and `a3` represent the next element to be retrieved from the iterator.\r\na1, a2, a3 = iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    for epoch in range(num_epochs):\r\n        # Resets the iterator at the beginning of an epoch.\r\n        sess.run(iterator.initializer)\r\n        print('epoch:%d' % (epoch))\r\n        try:\r\n            while True:\r\n                a, b, c = sess.run([a1, a2, a3])\r\n                print(a, b, c)\r\n        except tf.errors.OutOfRangeError:\r\n            # This will be raised when you reach the end of an epoch (i.e. the\r\n            # iterator has no more elements).\r\n            pass\r\n```\r\n\r\nThe corresponding file: \"1.txt\"\r\n\r\n```\r\n1,2-3,4-A\r\n7,8-9,10-B\r\n12,13-14,15-C\r\n17,18-19,20-D\r\n22,23-24,25-E\r\n27,28-29,30-F\r\n32,33-34,35-G\r\n37,38-39,40-H\r\n```\r\n\r\nThe output:\r\n```\r\n2017-10-02 15:06:43.523320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-10-02 15:06:43.523788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 5.93GiB freeMemory: 5.44GiB\r\n2017-10-02 15:06:43.523800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nepoch:0\r\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\r\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\r\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']\r\nepoch:1\r\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\r\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\r\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']\r\nepoch:2\r\n[b'27,28' b'17,18' b'7,8'] [b'29,30' b'19,20' b'9,10'] [b'F' b'D' b'B']\r\n[b'32,33' b'22,23' b'12,13'] [b'34,35' b'24,25' b'14,15'] [b'G' b'E' b'C']\r\n[b'1,2' b'37,38'] [b'3,4' b'39,40'] [b'A' b'H']\r\n```\r\n"}