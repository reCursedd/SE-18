{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/376791901", "html_url": "https://github.com/tensorflow/tensorflow/issues/17855#issuecomment-376791901", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17855", "id": 376791901, "node_id": "MDEyOklzc3VlQ29tbWVudDM3Njc5MTkwMQ==", "user": {"login": "karthick96", "id": 32822620, "node_id": "MDQ6VXNlcjMyODIyNjIw", "avatar_url": "https://avatars3.githubusercontent.com/u/32822620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karthick96", "html_url": "https://github.com/karthick96", "followers_url": "https://api.github.com/users/karthick96/followers", "following_url": "https://api.github.com/users/karthick96/following{/other_user}", "gists_url": "https://api.github.com/users/karthick96/gists{/gist_id}", "starred_url": "https://api.github.com/users/karthick96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karthick96/subscriptions", "organizations_url": "https://api.github.com/users/karthick96/orgs", "repos_url": "https://api.github.com/users/karthick96/repos", "events_url": "https://api.github.com/users/karthick96/events{/privacy}", "received_events_url": "https://api.github.com/users/karthick96/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-28T07:40:44Z", "updated_at": "2018-03-28T07:40:44Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10564822\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vkmenon\">@vkmenon</a> I have used ReLU bro. First I've put None but after batch_normalization, I've used tf.nn.relu. So, it should work.</p>\n<pre><code>   fc = tf.layers.dense(inputs, hidden_units_1, activation=None ,kernel_initializer=initializer)\n   fc=tf.layers.batch_normalization(fc, training=is_training)\n   fc=tf.nn.relu(fc)\n</code></pre>", "body_text": "@vkmenon I have used ReLU bro. First I've put None but after batch_normalization, I've used tf.nn.relu. So, it should work.\n   fc = tf.layers.dense(inputs, hidden_units_1, activation=None ,kernel_initializer=initializer)\n   fc=tf.layers.batch_normalization(fc, training=is_training)\n   fc=tf.nn.relu(fc)", "body": "@vkmenon I have used ReLU bro. First I've put None but after batch_normalization, I've used tf.nn.relu. So, it should work.\r\n      \r\n       fc = tf.layers.dense(inputs, hidden_units_1, activation=None ,kernel_initializer=initializer)\r\n       fc=tf.layers.batch_normalization(fc, training=is_training)\r\n       fc=tf.nn.relu(fc)"}