{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12387", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12387/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12387/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12387/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12387", "id": 251176639, "node_id": "MDU6SXNzdWUyNTExNzY2Mzk=", "number": 12387, "title": "The precision difference between tensorflow and numpy when using tf.reduce_mean and np.mean", "user": {"login": "wenjunpku", "id": 22230272, "node_id": "MDQ6VXNlcjIyMjMwMjcy", "avatar_url": "https://avatars3.githubusercontent.com/u/22230272?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wenjunpku", "html_url": "https://github.com/wenjunpku", "followers_url": "https://api.github.com/users/wenjunpku/followers", "following_url": "https://api.github.com/users/wenjunpku/following{/other_user}", "gists_url": "https://api.github.com/users/wenjunpku/gists{/gist_id}", "starred_url": "https://api.github.com/users/wenjunpku/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wenjunpku/subscriptions", "organizations_url": "https://api.github.com/users/wenjunpku/orgs", "repos_url": "https://api.github.com/users/wenjunpku/repos", "events_url": "https://api.github.com/users/wenjunpku/events{/privacy}", "received_events_url": "https://api.github.com/users/wenjunpku/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-08-18T08:34:47Z", "updated_at": "2017-08-24T19:00:30Z", "closed_at": "2017-08-24T19:00:30Z", "author_association": "NONE", "body_html": "<pre><code>### System information\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\n- **TensorFlow installed from (source or binary)**:binary\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\n== cat /etc/issue ===============================================\nLinux quad6 4.4.0-83-generic #106-Ubuntu SMP Mon Jun 26 17:54:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.1 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.1-2ubuntu1~16.04) 5.4.1 20160904\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux quad6 4.4.0-83-generic #106-Ubuntu SMP Mon Jun 26 17:54:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.3.0)\ntensorflow (1.2.1)\ntensorflow-fold (0.0.1)\ntensorflow-gpu (1.2.1)\ntensorflow-tensorboard (0.1.4)\n\n== check for virtualenv =========================================\nTrue\n\n== tensorflow import ============================================\ntf.VERSION = 1.2.1\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nFri Aug 18 16:14:35 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN Xp            Off  | 0000:05:00.0     Off |                  N/A |\n| 28%   51C    P0    67W / 250W |      0MiB / 12188MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN Xp            Off  | 0000:06:00.0     Off |                  N/A |\n| 31%   55C    P0    66W / 250W |      0MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  TITAN Xp            Off  | 0000:09:00.0     Off |                  N/A |\n| 54%   84C    P2   130W / 250W |  11655MiB / 12189MiB |     52%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  TITAN Xp            Off  | 0000:0A:00.0     Off |                  N/A |\n| 23%   33C    P0    61W / 250W |      0MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    2      5854    C   python3                                      11651MiB |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.27\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n\n\n\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nv1.2.0-5-g435cdfc 1.2.1\n</code></pre>\n<h3>Describe the problem</h3>\n<p>When using <code>tf.reduce_mean</code>, i found the behaviour between <code>tensorflow</code> and <code>numpy</code> was different when dtype was <code>float32</code>. The experiment shows that this maybe caused by the precision problem in <code>tensorflow</code>. When I changed the dtype to <code>tf.float64</code>, the problem fixed.<br>\nOr if I calculate the mean axis by axis, the problem also disappear.<br>\nHowever, if I use <code>numpy</code> array, the result was right no matter the dtype is  <code>float32</code> or <code>float64</code>.<br>\nIs this a normal behaviour or will be fixed later?</p>\n<p>The test code I used as following:</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre>In [<span class=\"pl-c1\">61</span>]: x <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0.6931</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">79804</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\nIn [<span class=\"pl-c1\">62</span>]: y <span class=\"pl-k\">=</span> tf.reduce_mean(x)\n\nIn [<span class=\"pl-c1\">63</span>]: sess.run(y)\nOut[<span class=\"pl-c1\">63</span>]: <span class=\"pl-c1\">0.26278782</span>\n\nIn [<span class=\"pl-c1\">64</span>]: y <span class=\"pl-k\">=</span> tf.reduce_mean(tf.reduce_mean(tf.reduce_mean(x, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>))\n\nIn [<span class=\"pl-c1\">65</span>]: sess.run(y)\nOut[<span class=\"pl-c1\">65</span>]: <span class=\"pl-c1\">0.693142</span>\n\nIn [<span class=\"pl-c1\">66</span>]: x <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0.6931</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">79804</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\nIn [<span class=\"pl-c1\">67</span>]: y <span class=\"pl-k\">=</span> tf.reduce_mean(x)\n\nIn [<span class=\"pl-c1\">68</span>]: sess.run(y)\nOut[<span class=\"pl-c1\">68</span>]: <span class=\"pl-c1\">0.26278782</span>\n\nIn [<span class=\"pl-c1\">69</span>]: x <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0.6931</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">79804</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float64)\n\nIn [<span class=\"pl-c1\">70</span>]: y <span class=\"pl-k\">=</span> tf.reduce_mean(x)\n\nIn [<span class=\"pl-c1\">71</span>]: sess.run(y)\nOut[<span class=\"pl-c1\">71</span>]: <span class=\"pl-c1\">0.6931000008030902</span>\n\nIn [<span class=\"pl-c1\">72</span>]: y <span class=\"pl-k\">=</span> tf.reduce_mean(tf.reduce_mean(tf.reduce_mean(x, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>))\n\nIn [<span class=\"pl-c1\">73</span>]: sess.run(y)\nOut[<span class=\"pl-c1\">73</span>]: <span class=\"pl-c1\">0.69310000000034644</span>\n\nIn [<span class=\"pl-c1\">74</span>]: xn <span class=\"pl-k\">=</span> np.full((<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">79084</span>), <span class=\"pl-c1\">0.6931</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float64)\n\nIn [<span class=\"pl-c1\">75</span>]: yn <span class=\"pl-k\">=</span> np.mean(xn)\n\nIn [<span class=\"pl-c1\">76</span>]: yn\nOut[<span class=\"pl-c1\">76</span>]: <span class=\"pl-c1\">0.69310000000032723</span>\n\nIn [<span class=\"pl-c1\">77</span>]: xn <span class=\"pl-k\">=</span> np.full((<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">79084</span>), <span class=\"pl-c1\">0.6931</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\n\nIn [<span class=\"pl-c1\">78</span>]: yn <span class=\"pl-k\">=</span> np.mean(xn)\n\nIn [<span class=\"pl-c1\">79</span>]: yn <span class=\"pl-k\">=</span> np.mean(xn)\n\nIn [<span class=\"pl-c1\">80</span>]: yn\nOut[<span class=\"pl-c1\">80</span>]: <span class=\"pl-c1\">0.69321907</span></pre></div>", "body_text": "### System information\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\n- **TensorFlow installed from (source or binary)**:binary\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\n== cat /etc/issue ===============================================\nLinux quad6 4.4.0-83-generic #106-Ubuntu SMP Mon Jun 26 17:54:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.1 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.1-2ubuntu1~16.04) 5.4.1 20160904\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux quad6 4.4.0-83-generic #106-Ubuntu SMP Mon Jun 26 17:54:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.3.0)\ntensorflow (1.2.1)\ntensorflow-fold (0.0.1)\ntensorflow-gpu (1.2.1)\ntensorflow-tensorboard (0.1.4)\n\n== check for virtualenv =========================================\nTrue\n\n== tensorflow import ============================================\ntf.VERSION = 1.2.1\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nFri Aug 18 16:14:35 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN Xp            Off  | 0000:05:00.0     Off |                  N/A |\n| 28%   51C    P0    67W / 250W |      0MiB / 12188MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN Xp            Off  | 0000:06:00.0     Off |                  N/A |\n| 31%   55C    P0    66W / 250W |      0MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  TITAN Xp            Off  | 0000:09:00.0     Off |                  N/A |\n| 54%   84C    P2   130W / 250W |  11655MiB / 12189MiB |     52%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  TITAN Xp            Off  | 0000:0A:00.0     Off |                  N/A |\n| 23%   33C    P0    61W / 250W |      0MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    2      5854    C   python3                                      11651MiB |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.27\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n\n\n\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nv1.2.0-5-g435cdfc 1.2.1\n\nDescribe the problem\nWhen using tf.reduce_mean, i found the behaviour between tensorflow and numpy was different when dtype was float32. The experiment shows that this maybe caused by the precision problem in tensorflow. When I changed the dtype to tf.float64, the problem fixed.\nOr if I calculate the mean axis by axis, the problem also disappear.\nHowever, if I use numpy array, the result was right no matter the dtype is  float32 or float64.\nIs this a normal behaviour or will be fixed later?\nThe test code I used as following:\nSource code / logs\nIn [61]: x = tf.constant(0.6931, shape=[32, 100, 79804], dtype=tf.float32)\n\nIn [62]: y = tf.reduce_mean(x)\n\nIn [63]: sess.run(y)\nOut[63]: 0.26278782\n\nIn [64]: y = tf.reduce_mean(tf.reduce_mean(tf.reduce_mean(x, axis=2), axis=-1))\n\nIn [65]: sess.run(y)\nOut[65]: 0.693142\n\nIn [66]: x = tf.constant(0.6931, shape=[32, 100, 79804], dtype=tf.float32)\n\nIn [67]: y = tf.reduce_mean(x)\n\nIn [68]: sess.run(y)\nOut[68]: 0.26278782\n\nIn [69]: x = tf.constant(0.6931, shape=[32, 100, 79804], dtype=tf.float64)\n\nIn [70]: y = tf.reduce_mean(x)\n\nIn [71]: sess.run(y)\nOut[71]: 0.6931000008030902\n\nIn [72]: y = tf.reduce_mean(tf.reduce_mean(tf.reduce_mean(x, axis=2), axis=-1))\n\nIn [73]: sess.run(y)\nOut[73]: 0.69310000000034644\n\nIn [74]: xn = np.full((32, 100, 79084), 0.6931, dtype=np.float64)\n\nIn [75]: yn = np.mean(xn)\n\nIn [76]: yn\nOut[76]: 0.69310000000032723\n\nIn [77]: xn = np.full((32, 100, 79084), 0.6931, dtype=np.float32)\n\nIn [78]: yn = np.mean(xn)\n\nIn [79]: yn = np.mean(xn)\n\nIn [80]: yn\nOut[80]: 0.69321907", "body": "```\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n== cat /etc/issue ===============================================\r\nLinux quad6 4.4.0-83-generic #106-Ubuntu SMP Mon Jun 26 17:54:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.1 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.1-2ubuntu1~16.04) 5.4.1 20160904\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux quad6 4.4.0-83-generic #106-Ubuntu SMP Mon Jun 26 17:54:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\ntensorflow-fold (0.0.1)\r\ntensorflow-gpu (1.2.1)\r\ntensorflow-tensorboard (0.1.4)\r\n\r\n== check for virtualenv =========================================\r\nTrue\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nFri Aug 18 16:14:35 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN Xp            Off  | 0000:05:00.0     Off |                  N/A |\r\n| 28%   51C    P0    67W / 250W |      0MiB / 12188MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN Xp            Off  | 0000:06:00.0     Off |                  N/A |\r\n| 31%   55C    P0    66W / 250W |      0MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  TITAN Xp            Off  | 0000:09:00.0     Off |                  N/A |\r\n| 54%   84C    P2   130W / 250W |  11655MiB / 12189MiB |     52%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  TITAN Xp            Off  | 0000:0A:00.0     Off |                  N/A |\r\n| 23%   33C    P0    61W / 250W |      0MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    2      5854    C   python3                                      11651MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.27\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n\r\n\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nv1.2.0-5-g435cdfc 1.2.1\r\n```\r\n### Describe the problem\r\nWhen using `tf.reduce_mean`, i found the behaviour between `tensorflow` and `numpy` was different when dtype was `float32`. The experiment shows that this maybe caused by the precision problem in `tensorflow`. When I changed the dtype to `tf.float64`, the problem fixed. \r\nOr if I calculate the mean axis by axis, the problem also disappear.\r\nHowever, if I use `numpy` array, the result was right no matter the dtype is  `float32` or `float64`.\r\nIs this a normal behaviour or will be fixed later?\r\n\r\nThe test code I used as following:\r\n### Source code / logs\r\n```Python\r\nIn [61]: x = tf.constant(0.6931, shape=[32, 100, 79804], dtype=tf.float32)\r\n\r\nIn [62]: y = tf.reduce_mean(x)\r\n\r\nIn [63]: sess.run(y)\r\nOut[63]: 0.26278782\r\n\r\nIn [64]: y = tf.reduce_mean(tf.reduce_mean(tf.reduce_mean(x, axis=2), axis=-1))\r\n\r\nIn [65]: sess.run(y)\r\nOut[65]: 0.693142\r\n\r\nIn [66]: x = tf.constant(0.6931, shape=[32, 100, 79804], dtype=tf.float32)\r\n\r\nIn [67]: y = tf.reduce_mean(x)\r\n\r\nIn [68]: sess.run(y)\r\nOut[68]: 0.26278782\r\n\r\nIn [69]: x = tf.constant(0.6931, shape=[32, 100, 79804], dtype=tf.float64)\r\n\r\nIn [70]: y = tf.reduce_mean(x)\r\n\r\nIn [71]: sess.run(y)\r\nOut[71]: 0.6931000008030902\r\n\r\nIn [72]: y = tf.reduce_mean(tf.reduce_mean(tf.reduce_mean(x, axis=2), axis=-1))\r\n\r\nIn [73]: sess.run(y)\r\nOut[73]: 0.69310000000034644\r\n\r\nIn [74]: xn = np.full((32, 100, 79084), 0.6931, dtype=np.float64)\r\n\r\nIn [75]: yn = np.mean(xn)\r\n\r\nIn [76]: yn\r\nOut[76]: 0.69310000000032723\r\n\r\nIn [77]: xn = np.full((32, 100, 79084), 0.6931, dtype=np.float32)\r\n\r\nIn [78]: yn = np.mean(xn)\r\n\r\nIn [79]: yn = np.mean(xn)\r\n\r\nIn [80]: yn\r\nOut[80]: 0.69321907\r\n```"}