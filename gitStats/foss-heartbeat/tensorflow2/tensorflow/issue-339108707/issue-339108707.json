{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20607", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20607/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20607/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20607/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20607", "id": 339108707, "node_id": "MDU6SXNzdWUzMzkxMDg3MDc=", "number": 20607, "title": "Performance drop for CPU graph calculation after upgrading from 1.3 to newer versions", "user": {"login": "TianyiChen", "id": 10559772, "node_id": "MDQ6VXNlcjEwNTU5Nzcy", "avatar_url": "https://avatars1.githubusercontent.com/u/10559772?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TianyiChen", "html_url": "https://github.com/TianyiChen", "followers_url": "https://api.github.com/users/TianyiChen/followers", "following_url": "https://api.github.com/users/TianyiChen/following{/other_user}", "gists_url": "https://api.github.com/users/TianyiChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/TianyiChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TianyiChen/subscriptions", "organizations_url": "https://api.github.com/users/TianyiChen/orgs", "repos_url": "https://api.github.com/users/TianyiChen/repos", "events_url": "https://api.github.com/users/TianyiChen/events{/privacy}", "received_events_url": "https://api.github.com/users/TianyiChen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-07-07T02:01:42Z", "updated_at": "2018-09-22T13:40:11Z", "closed_at": "2018-09-22T13:40:11Z", "author_association": "NONE", "body_html": "<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: CentOS 7</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary (pip)</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4 and newer for CPU</li>\n<li><strong>Python version</strong>: 2.7.5 3.5.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: python test1.py</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Initially I found training using CPU in TensorFlow 1.8 is slow and it appeared only one thread was used. I can confirm multi-threading for individual operations works well (like multiplying two large matrices). But it seems only one operation can be done at the same time. Specifying inter_op_parallelism_threads doesn't help. For version 1.8 and 1.9rc2 and the following test code I wrote, the CPU usage was almost consistently 100% (1 core) according to \"top\". For version 1.3 and 1.0, it was obvious that the following code used multiple cores and ran significantly faster. I reproduced most results with both Python versions. Here are my test results:</p>\n<ul>\n<li>Version time printed</li>\n<li>1.0, 1.3: 20s</li>\n<li>1.4, 1.5: 50s</li>\n<li>1.6: 60s</li>\n<li>1.7, 1.8: 80s</li>\n<li>1.9 rc2: 130s</li>\n</ul>\n<p>The above results were based on a 64GB, 20-core (2x E5 without hyperthreading) machine. I also tried on an AWS t2.2xlarge instance (32GB, 8-core) with Ubuntu 16.04, Python 3.5.2, TensorFlow 1.3 and 1.9 and got similar results.</p>\n<h3>Source code / logs</h3>\n<pre><code>import tensorflow as tf\nimport time\nA=[None]*100000\nB=[None]*100000\nfor i in range(0,2):\n\tA[i]=tf.Variable(tf.random_normal([100,100]))\n\tB[i]=tf.Variable(tf.random_normal([100,100]))\nfor i in range(2,100000):\n\tA[i]=tf.matmul(A[i-1],A[i-2])\n\tB[i]=tf.matmul(B[i-1],B[i-2])\nc=tf.matmul(A[-1],B[-1])\nprint('graph created')\n#the config doesn't help\nconfig=tf.ConfigProto()\nconfig.intra_op_parallelism_threads = 4\nconfig.inter_op_parallelism_threads = 10\nt=time.time()\ns=tf.Session(config=config)\ns.run(tf.global_variables_initializer())\ns.run(c)\nprint(tf.__version__)\nprint(time.time()-t)\n</code></pre>\n<p>Appended:<br>\nI just tried to collect the timeline in 1.3, 1.8 and 1.9rc. They all look similar and reported 5-10 seconds with good parallelism. Maybe the issue is caused by overhead from other parts like scheduling?<br>\nTimeline:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/10559772/42405897-56f3c342-81d0-11e8-9a8b-bf4a08a6a6c7.png\"><img width=\"943\" alt=\"timeline\" src=\"https://user-images.githubusercontent.com/10559772/42405897-56f3c342-81d0-11e8-9a8b-bf4a08a6a6c7.png\" style=\"max-width:100%;\"></a><br>\nTimeline enlarged:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/10559772/42405908-6ec434c0-81d0-11e8-871b-a25a559dc745.PNG\"><img width=\"886\" alt=\"timeline_enlarged\" src=\"https://user-images.githubusercontent.com/10559772/42405908-6ec434c0-81d0-11e8-871b-a25a559dc745.PNG\" style=\"max-width:100%;\"></a></p>", "body_text": "Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\nTensorFlow installed from (source or binary): binary (pip)\nTensorFlow version (use command below): 1.4 and newer for CPU\nPython version: 2.7.5 3.5.4\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: python test1.py\n\nDescribe the problem\nInitially I found training using CPU in TensorFlow 1.8 is slow and it appeared only one thread was used. I can confirm multi-threading for individual operations works well (like multiplying two large matrices). But it seems only one operation can be done at the same time. Specifying inter_op_parallelism_threads doesn't help. For version 1.8 and 1.9rc2 and the following test code I wrote, the CPU usage was almost consistently 100% (1 core) according to \"top\". For version 1.3 and 1.0, it was obvious that the following code used multiple cores and ran significantly faster. I reproduced most results with both Python versions. Here are my test results:\n\nVersion time printed\n1.0, 1.3: 20s\n1.4, 1.5: 50s\n1.6: 60s\n1.7, 1.8: 80s\n1.9 rc2: 130s\n\nThe above results were based on a 64GB, 20-core (2x E5 without hyperthreading) machine. I also tried on an AWS t2.2xlarge instance (32GB, 8-core) with Ubuntu 16.04, Python 3.5.2, TensorFlow 1.3 and 1.9 and got similar results.\nSource code / logs\nimport tensorflow as tf\nimport time\nA=[None]*100000\nB=[None]*100000\nfor i in range(0,2):\n\tA[i]=tf.Variable(tf.random_normal([100,100]))\n\tB[i]=tf.Variable(tf.random_normal([100,100]))\nfor i in range(2,100000):\n\tA[i]=tf.matmul(A[i-1],A[i-2])\n\tB[i]=tf.matmul(B[i-1],B[i-2])\nc=tf.matmul(A[-1],B[-1])\nprint('graph created')\n#the config doesn't help\nconfig=tf.ConfigProto()\nconfig.intra_op_parallelism_threads = 4\nconfig.inter_op_parallelism_threads = 10\nt=time.time()\ns=tf.Session(config=config)\ns.run(tf.global_variables_initializer())\ns.run(c)\nprint(tf.__version__)\nprint(time.time()-t)\n\nAppended:\nI just tried to collect the timeline in 1.3, 1.8 and 1.9rc. They all look similar and reported 5-10 seconds with good parallelism. Maybe the issue is caused by overhead from other parts like scheduling?\nTimeline:\n\nTimeline enlarged:", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS 7\r\n- **TensorFlow installed from (source or binary)**: binary (pip)\r\n- **TensorFlow version (use command below)**: 1.4 and newer for CPU\r\n- **Python version**: 2.7.5 3.5.4\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: python test1.py\r\n\r\n### Describe the problem\r\n\r\nInitially I found training using CPU in TensorFlow 1.8 is slow and it appeared only one thread was used. I can confirm multi-threading for individual operations works well (like multiplying two large matrices). But it seems only one operation can be done at the same time. Specifying inter_op_parallelism_threads doesn't help. For version 1.8 and 1.9rc2 and the following test code I wrote, the CPU usage was almost consistently 100% (1 core) according to \"top\". For version 1.3 and 1.0, it was obvious that the following code used multiple cores and ran significantly faster. I reproduced most results with both Python versions. Here are my test results:\r\n- Version time printed\r\n- 1.0, 1.3: 20s\r\n- 1.4, 1.5: 50s\r\n- 1.6: 60s\r\n- 1.7, 1.8: 80s\r\n- 1.9 rc2: 130s\r\n\r\nThe above results were based on a 64GB, 20-core (2x E5 without hyperthreading) machine. I also tried on an AWS t2.2xlarge instance (32GB, 8-core) with Ubuntu 16.04, Python 3.5.2, TensorFlow 1.3 and 1.9 and got similar results.\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\nimport time\r\nA=[None]*100000\r\nB=[None]*100000\r\nfor i in range(0,2):\r\n\tA[i]=tf.Variable(tf.random_normal([100,100]))\r\n\tB[i]=tf.Variable(tf.random_normal([100,100]))\r\nfor i in range(2,100000):\r\n\tA[i]=tf.matmul(A[i-1],A[i-2])\r\n\tB[i]=tf.matmul(B[i-1],B[i-2])\r\nc=tf.matmul(A[-1],B[-1])\r\nprint('graph created')\r\n#the config doesn't help\r\nconfig=tf.ConfigProto()\r\nconfig.intra_op_parallelism_threads = 4\r\nconfig.inter_op_parallelism_threads = 10\r\nt=time.time()\r\ns=tf.Session(config=config)\r\ns.run(tf.global_variables_initializer())\r\ns.run(c)\r\nprint(tf.__version__)\r\nprint(time.time()-t)\r\n```\r\n\r\nAppended:\r\nI just tried to collect the timeline in 1.3, 1.8 and 1.9rc. They all look similar and reported 5-10 seconds with good parallelism. Maybe the issue is caused by overhead from other parts like scheduling?\r\nTimeline:\r\n<img width=\"943\" alt=\"timeline\" src=\"https://user-images.githubusercontent.com/10559772/42405897-56f3c342-81d0-11e8-9a8b-bf4a08a6a6c7.png\">\r\nTimeline enlarged:\r\n<img width=\"886\" alt=\"timeline_enlarged\" src=\"https://user-images.githubusercontent.com/10559772/42405908-6ec434c0-81d0-11e8-871b-a25a559dc745.PNG\">\r\n"}