{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/274675240", "html_url": "https://github.com/tensorflow/tensorflow/issues/7023#issuecomment-274675240", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7023", "id": 274675240, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NDY3NTI0MA==", "user": {"login": "monajalal", "id": 1892917, "node_id": "MDQ6VXNlcjE4OTI5MTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1892917?v=4", "gravatar_id": "", "url": "https://api.github.com/users/monajalal", "html_url": "https://github.com/monajalal", "followers_url": "https://api.github.com/users/monajalal/followers", "following_url": "https://api.github.com/users/monajalal/following{/other_user}", "gists_url": "https://api.github.com/users/monajalal/gists{/gist_id}", "starred_url": "https://api.github.com/users/monajalal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/monajalal/subscriptions", "organizations_url": "https://api.github.com/users/monajalal/orgs", "repos_url": "https://api.github.com/users/monajalal/repos", "events_url": "https://api.github.com/users/monajalal/events{/privacy}", "received_events_url": "https://api.github.com/users/monajalal/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-24T01:38:06Z", "updated_at": "2017-01-24T01:38:06Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a>  now that I used your line of code, that error is removed, however, I get this new error, can you provide feedback?</p>\n<pre><code>mona@pascal:~/computer_vision$ python human_activity_recognition.py \nUsing TensorFlow backend.\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\nTraceback (most recent call last):\n  File \"human_activity_recognition.py\", line 18, in &lt;module&gt;\n    from regularizers import EigenvalueRegularizer\nImportError: No module named regularizers\nmona@pascal:~/computer_vision$ vi human_activity_recognition.py \nmona@pascal:~/computer_vision$ vi human_activity_recognition.py \nmona@pascal:~/computer_vision$ python human_activity_recognition.py \nUsing TensorFlow backend.\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\nTraceback (most recent call last):\n  File \"human_activity_recognition.py\", line 76, in &lt;module&gt;\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 332, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.py\", line 160, in call\n    dim_ordering=self.dim_ordering)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.py\", line 210, in _pooling_function\n    pool_mode='max')\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 2833, in pool2d\n    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/ops/nn_ops.py\", line 1393, in max_pool\n    name=name)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/ops/gen_nn_ops.py\", line 1595, in _max_pool\n    data_format=data_format, name=name)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2390, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1785, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/common_shapes.py\", line 596, in call_cpp_shape_fn\n    raise ValueError(err.message)\nValueError: Negative dimension size caused by subtracting 2 from 1\n\n</code></pre>\n<p>The code is:<br>\n'''This script reuses pieces of code from the post:<br>\n\"Building powerful image classification models using very little data\"<br>\nfrom blog.keras.io<br>\nand from:<br>\n<a href=\"https://www.kaggle.com/tnhabc/state-farm-distracted-driver-detection/keras-sample\" rel=\"nofollow\">https://www.kaggle.com/tnhabc/state-farm-distracted-driver-detection/keras-sample</a><br>\nThe training data can be downloaded at:<br>\n<a href=\"https://www.kaggle.com/c/state-farm-distracted-driver-detection/data\" rel=\"nofollow\">https://www.kaggle.com/c/state-farm-distracted-driver-detection/data</a><br>\n'''</p>\n<pre><code>import os\nimport h5py\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n#from regularizers import EigenvalueRegularizer\nfrom keras.regularizers import EigenvalueRegularizer\nfrom numpy.random import permutation\nfrom keras.optimizers import SGD\nimport pandas as pd\nimport datetime\nimport glob\nimport cv2\nimport math\nimport pickle\nfrom collections import OrderedDict\nfrom keras import backend as K\n\n\n# Enter here the path to the model weights files:\nweights_path = '/data/wd1/activity_recognition/vgg16_weights.h5'\n# Enter here the path to the top-model weights files:\ntop_model_weights_path = '/data/wd1/activity_recognition/fc_model.h5'\n# Enter here the path for storage of the whole model weights (VGG16+top classifier model):\nwhole_model_weights_path = '/data/wd1/activity_recognition/whole_model.h5'\n# Enter here the name of the folder that contains the folders c0, c1,..., c9, with the training images belonging to classes 0 to 9:\ntrain_data_dir = 'train'\n# Enter here the name of the folder where is the test images (the data evalueted in the private leaderboard):\ntest_data_dir = 'test'\n\ntest_images_path = 'test/test'\n\n# Enter here the features of the data set:\nimg_width, img_height = 224, 224\nnb_train_samples = 22424\nnb_test_samples = 79726\ncolor_type_global = 3\n\n# You can set larger values here, according with the memory of your GPU:\nbatch_size = 32\n\n# Enter here the number of training epochs (with 80 epochs the model was positioned among\n# the 29% best competitors in the private leaderboard of state-farm-distracted-driver-detection)\n# According to our results, this model can achieve a better performance if trained along a larger \n# number of epochs, due to the agressive regularization with Eigenvalue Decay that was adopted.\nnb_epoch = 80\n\n#Enter here the path for the whole model (VGG16+top classifier model):\nwhole_model_weights_path = '/data/wd1/activity_recognition/whole_model.h5'\n\n# build the VGG16 network:\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n# loading the weights of the pre-trained VGG16:\n\nassert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\nf = h5py.File(weights_path)\nfor k in range(f.attrs['nb_layers']):\n    if k &gt;= len(model.layers):\n        break\n    g = f['layer_{}'.format(k)]\n    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n    model.layers[k].set_weights(weights)\nf.close()\nprint('Model loaded.')\n\n# building a classifier model on top of the convolutional model:\n\ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=model.output_shape[1:]))\ntop_model.add(Dense(64, activation='relu', W_regularizer=EigenvalueRegularizer(10)))\ntop_model.add(Dense(10, activation='softmax', W_regularizer=EigenvalueRegularizer(10)))\ntop_model.load_weights(top_model_weights_path)\n\n# add the model on top of the convolutional base\nmodel.add(top_model)\n\n# setting the first 15 layers to non-trainable (the original weights will not be updated)\n    \nfor layer in model.layers[:15]:\n    layer.trainable = False\n\n# Compiling the model with a SGD/momentum optimizer:\n\nmodel.compile(loss = \"categorical_crossentropy\",\n              optimizer=optimizers.SGD(lr=1e-6, momentum=0.9),\n              metrics=['mean_squared_logarithmic_error', 'accuracy'])\n\n# Data augmentation:\n\ntrain_datagen = ImageDataGenerator(shear_range=0.3, zoom_range=0.3, rotation_range=0.3)\ntest_datagen = ImageDataGenerator()\n\nprint('trainning')\ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=32,\n        class_mode='categorical')\n  \n\nprint('testing')\ntest_generator = test_datagen.flow_from_directory(\n        test_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=32,\n        class_mode='categorical',\n        shuffle=False)\n\nclass_dictionary = train_generator.class_indices\nsorted_class_dictionary = OrderedDict(sorted(class_dictionary.items()))\nsorted_class_dictionary = sorted_class_dictionary.values()\nprint(sorted_class_dictionary)\n\n# Fine-tuning the model:\nmodel.fit_generator(\n        train_generator,\n        samples_per_epoch=nb_train_samples,\n        nb_epoch=nb_epoch,\n        validation_data=train_generator,\n        nb_val_samples=nb_train_samples)\n        \nmodel.save_weights(whole_model_weights_path)\n\naux = model.predict_generator(test_generator, nb_test_samples)\npredictions = np.zeros((nb_test_samples, 10))\n\n# Rearranging the predictions:\n\nord = [5, 0, 6, 2, 7, 9, 1, 4, 8, 3]\n\nfor n in range(10):\n    i = ord[n]\n    print(i)\n    print(aux[:, i])\n    predictions[:, n] = aux[:, i]\n\n# Trick to improve the multi-class logarithmic loss (the evaluation metric of state-farm-distracted-driver-detection from Keras):\n\npredictions = 0.985 * predictions + 0.015\n\ndef get_im(path, img_width, img_height, color_type=1):\n    if color_type == 1:\n        img = cv2.imread(path, 0)\n    elif color_type == 3:\n        img = cv2.imread(path)\n    # Reduce size\n    resized = cv2.resize(img, (img_height, img_width))\n    return resized\n\ndef load_test(img_width, img_height, color_type=1):\n    print('Read test images')\n    path = os.path.join(test_images_path, '*.jpg')\n    files = glob.glob(path)\n    X_test = []\n    X_test_id = []\n    total = 0\n    thr = math.floor(len(files)/10)\n    for fl in files:\n        flbase = os.path.basename(fl)\n        img = get_im(fl, img_width, img_height, color_type)\n        X_test.append(img)\n        X_test_id.append(flbase)\n        total += 1\n        if total % thr == 0:\n            print('Read {} images from {}'.format(total, len(files)))\n\n    return X_test, X_test_id\n\nX_test, test_id = load_test(img_width, img_height, color_type_global)\n\ndef create_submission(predictions, test_id):\n    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3',\n                                                 'c4', 'c5', 'c6', 'c7',\n                                                 'c8', 'c9'])\n    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n    now = datetime.datetime.now()\n    if not os.path.isdir('subm'):\n        os.mkdir('subm')\n    suffix = '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n    result1.to_csv(sub_file, index=False)\n\ncreate_submission(predictions, test_id)\n</code></pre>", "body_text": "@fchollet  now that I used your line of code, that error is removed, however, I get this new error, can you provide feedback?\nmona@pascal:~/computer_vision$ python human_activity_recognition.py \nUsing TensorFlow backend.\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\nTraceback (most recent call last):\n  File \"human_activity_recognition.py\", line 18, in <module>\n    from regularizers import EigenvalueRegularizer\nImportError: No module named regularizers\nmona@pascal:~/computer_vision$ vi human_activity_recognition.py \nmona@pascal:~/computer_vision$ vi human_activity_recognition.py \nmona@pascal:~/computer_vision$ python human_activity_recognition.py \nUsing TensorFlow backend.\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\nTraceback (most recent call last):\n  File \"human_activity_recognition.py\", line 76, in <module>\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 332, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.py\", line 160, in call\n    dim_ordering=self.dim_ordering)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.py\", line 210, in _pooling_function\n    pool_mode='max')\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 2833, in pool2d\n    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/ops/nn_ops.py\", line 1393, in max_pool\n    name=name)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/ops/gen_nn_ops.py\", line 1595, in _max_pool\n    data_format=data_format, name=name)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2390, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1785, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/common_shapes.py\", line 596, in call_cpp_shape_fn\n    raise ValueError(err.message)\nValueError: Negative dimension size caused by subtracting 2 from 1\n\n\nThe code is:\n'''This script reuses pieces of code from the post:\n\"Building powerful image classification models using very little data\"\nfrom blog.keras.io\nand from:\nhttps://www.kaggle.com/tnhabc/state-farm-distracted-driver-detection/keras-sample\nThe training data can be downloaded at:\nhttps://www.kaggle.com/c/state-farm-distracted-driver-detection/data\n'''\nimport os\nimport h5py\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n#from regularizers import EigenvalueRegularizer\nfrom keras.regularizers import EigenvalueRegularizer\nfrom numpy.random import permutation\nfrom keras.optimizers import SGD\nimport pandas as pd\nimport datetime\nimport glob\nimport cv2\nimport math\nimport pickle\nfrom collections import OrderedDict\nfrom keras import backend as K\n\n\n# Enter here the path to the model weights files:\nweights_path = '/data/wd1/activity_recognition/vgg16_weights.h5'\n# Enter here the path to the top-model weights files:\ntop_model_weights_path = '/data/wd1/activity_recognition/fc_model.h5'\n# Enter here the path for storage of the whole model weights (VGG16+top classifier model):\nwhole_model_weights_path = '/data/wd1/activity_recognition/whole_model.h5'\n# Enter here the name of the folder that contains the folders c0, c1,..., c9, with the training images belonging to classes 0 to 9:\ntrain_data_dir = 'train'\n# Enter here the name of the folder where is the test images (the data evalueted in the private leaderboard):\ntest_data_dir = 'test'\n\ntest_images_path = 'test/test'\n\n# Enter here the features of the data set:\nimg_width, img_height = 224, 224\nnb_train_samples = 22424\nnb_test_samples = 79726\ncolor_type_global = 3\n\n# You can set larger values here, according with the memory of your GPU:\nbatch_size = 32\n\n# Enter here the number of training epochs (with 80 epochs the model was positioned among\n# the 29% best competitors in the private leaderboard of state-farm-distracted-driver-detection)\n# According to our results, this model can achieve a better performance if trained along a larger \n# number of epochs, due to the agressive regularization with Eigenvalue Decay that was adopted.\nnb_epoch = 80\n\n#Enter here the path for the whole model (VGG16+top classifier model):\nwhole_model_weights_path = '/data/wd1/activity_recognition/whole_model.h5'\n\n# build the VGG16 network:\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n# loading the weights of the pre-trained VGG16:\n\nassert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\nf = h5py.File(weights_path)\nfor k in range(f.attrs['nb_layers']):\n    if k >= len(model.layers):\n        break\n    g = f['layer_{}'.format(k)]\n    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n    model.layers[k].set_weights(weights)\nf.close()\nprint('Model loaded.')\n\n# building a classifier model on top of the convolutional model:\n\ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=model.output_shape[1:]))\ntop_model.add(Dense(64, activation='relu', W_regularizer=EigenvalueRegularizer(10)))\ntop_model.add(Dense(10, activation='softmax', W_regularizer=EigenvalueRegularizer(10)))\ntop_model.load_weights(top_model_weights_path)\n\n# add the model on top of the convolutional base\nmodel.add(top_model)\n\n# setting the first 15 layers to non-trainable (the original weights will not be updated)\n    \nfor layer in model.layers[:15]:\n    layer.trainable = False\n\n# Compiling the model with a SGD/momentum optimizer:\n\nmodel.compile(loss = \"categorical_crossentropy\",\n              optimizer=optimizers.SGD(lr=1e-6, momentum=0.9),\n              metrics=['mean_squared_logarithmic_error', 'accuracy'])\n\n# Data augmentation:\n\ntrain_datagen = ImageDataGenerator(shear_range=0.3, zoom_range=0.3, rotation_range=0.3)\ntest_datagen = ImageDataGenerator()\n\nprint('trainning')\ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=32,\n        class_mode='categorical')\n  \n\nprint('testing')\ntest_generator = test_datagen.flow_from_directory(\n        test_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=32,\n        class_mode='categorical',\n        shuffle=False)\n\nclass_dictionary = train_generator.class_indices\nsorted_class_dictionary = OrderedDict(sorted(class_dictionary.items()))\nsorted_class_dictionary = sorted_class_dictionary.values()\nprint(sorted_class_dictionary)\n\n# Fine-tuning the model:\nmodel.fit_generator(\n        train_generator,\n        samples_per_epoch=nb_train_samples,\n        nb_epoch=nb_epoch,\n        validation_data=train_generator,\n        nb_val_samples=nb_train_samples)\n        \nmodel.save_weights(whole_model_weights_path)\n\naux = model.predict_generator(test_generator, nb_test_samples)\npredictions = np.zeros((nb_test_samples, 10))\n\n# Rearranging the predictions:\n\nord = [5, 0, 6, 2, 7, 9, 1, 4, 8, 3]\n\nfor n in range(10):\n    i = ord[n]\n    print(i)\n    print(aux[:, i])\n    predictions[:, n] = aux[:, i]\n\n# Trick to improve the multi-class logarithmic loss (the evaluation metric of state-farm-distracted-driver-detection from Keras):\n\npredictions = 0.985 * predictions + 0.015\n\ndef get_im(path, img_width, img_height, color_type=1):\n    if color_type == 1:\n        img = cv2.imread(path, 0)\n    elif color_type == 3:\n        img = cv2.imread(path)\n    # Reduce size\n    resized = cv2.resize(img, (img_height, img_width))\n    return resized\n\ndef load_test(img_width, img_height, color_type=1):\n    print('Read test images')\n    path = os.path.join(test_images_path, '*.jpg')\n    files = glob.glob(path)\n    X_test = []\n    X_test_id = []\n    total = 0\n    thr = math.floor(len(files)/10)\n    for fl in files:\n        flbase = os.path.basename(fl)\n        img = get_im(fl, img_width, img_height, color_type)\n        X_test.append(img)\n        X_test_id.append(flbase)\n        total += 1\n        if total % thr == 0:\n            print('Read {} images from {}'.format(total, len(files)))\n\n    return X_test, X_test_id\n\nX_test, test_id = load_test(img_width, img_height, color_type_global)\n\ndef create_submission(predictions, test_id):\n    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3',\n                                                 'c4', 'c5', 'c6', 'c7',\n                                                 'c8', 'c9'])\n    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n    now = datetime.datetime.now()\n    if not os.path.isdir('subm'):\n        os.mkdir('subm')\n    suffix = '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n    result1.to_csv(sub_file, index=False)\n\ncreate_submission(predictions, test_id)", "body": "@fchollet  now that I used your line of code, that error is removed, however, I get this new error, can you provide feedback?\r\n```\r\nmona@pascal:~/computer_vision$ python human_activity_recognition.py \r\nUsing TensorFlow backend.\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\r\nTraceback (most recent call last):\r\n  File \"human_activity_recognition.py\", line 18, in <module>\r\n    from regularizers import EigenvalueRegularizer\r\nImportError: No module named regularizers\r\nmona@pascal:~/computer_vision$ vi human_activity_recognition.py \r\nmona@pascal:~/computer_vision$ vi human_activity_recognition.py \r\nmona@pascal:~/computer_vision$ python human_activity_recognition.py \r\nUsing TensorFlow backend.\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\r\nTraceback (most recent call last):\r\n  File \"human_activity_recognition.py\", line 76, in <module>\r\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 332, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 572, in __call__\r\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 635, in add_inbound_node\r\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 166, in create_node\r\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.py\", line 160, in call\r\n    dim_ordering=self.dim_ordering)\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.py\", line 210, in _pooling_function\r\n    pool_mode='max')\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 2833, in pool2d\r\n    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\r\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/ops/nn_ops.py\", line 1393, in max_pool\r\n    name=name)\r\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/ops/gen_nn_ops.py\", line 1595, in _max_pool\r\n    data_format=data_format, name=name)\r\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2390, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1785, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/home/mona/tensorflow/_python_build/tensorflow/python/framework/common_shapes.py\", line 596, in call_cpp_shape_fn\r\n    raise ValueError(err.message)\r\nValueError: Negative dimension size caused by subtracting 2 from 1\r\n\r\n```\r\n\r\nThe code is:\r\n'''This script reuses pieces of code from the post:\r\n\"Building powerful image classification models using very little data\"\r\nfrom blog.keras.io\r\nand from:\r\nhttps://www.kaggle.com/tnhabc/state-farm-distracted-driver-detection/keras-sample\r\nThe training data can be downloaded at:\r\nhttps://www.kaggle.com/c/state-farm-distracted-driver-detection/data\r\n'''\r\n\r\n```\r\nimport os\r\nimport h5py\r\nimport numpy as np\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras import optimizers\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\r\nfrom keras.layers import Activation, Dropout, Flatten, Dense\r\n#from regularizers import EigenvalueRegularizer\r\nfrom keras.regularizers import EigenvalueRegularizer\r\nfrom numpy.random import permutation\r\nfrom keras.optimizers import SGD\r\nimport pandas as pd\r\nimport datetime\r\nimport glob\r\nimport cv2\r\nimport math\r\nimport pickle\r\nfrom collections import OrderedDict\r\nfrom keras import backend as K\r\n\r\n\r\n# Enter here the path to the model weights files:\r\nweights_path = '/data/wd1/activity_recognition/vgg16_weights.h5'\r\n# Enter here the path to the top-model weights files:\r\ntop_model_weights_path = '/data/wd1/activity_recognition/fc_model.h5'\r\n# Enter here the path for storage of the whole model weights (VGG16+top classifier model):\r\nwhole_model_weights_path = '/data/wd1/activity_recognition/whole_model.h5'\r\n# Enter here the name of the folder that contains the folders c0, c1,..., c9, with the training images belonging to classes 0 to 9:\r\ntrain_data_dir = 'train'\r\n# Enter here the name of the folder where is the test images (the data evalueted in the private leaderboard):\r\ntest_data_dir = 'test'\r\n\r\ntest_images_path = 'test/test'\r\n\r\n# Enter here the features of the data set:\r\nimg_width, img_height = 224, 224\r\nnb_train_samples = 22424\r\nnb_test_samples = 79726\r\ncolor_type_global = 3\r\n\r\n# You can set larger values here, according with the memory of your GPU:\r\nbatch_size = 32\r\n\r\n# Enter here the number of training epochs (with 80 epochs the model was positioned among\r\n# the 29% best competitors in the private leaderboard of state-farm-distracted-driver-detection)\r\n# According to our results, this model can achieve a better performance if trained along a larger \r\n# number of epochs, due to the agressive regularization with Eigenvalue Decay that was adopted.\r\nnb_epoch = 80\r\n\r\n#Enter here the path for the whole model (VGG16+top classifier model):\r\nwhole_model_weights_path = '/data/wd1/activity_recognition/whole_model.h5'\r\n\r\n# build the VGG16 network:\r\nmodel = Sequential()\r\nmodel.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\r\n\r\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\r\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\r\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\r\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\r\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\r\nmodel.add(ZeroPadding2D((1, 1)))\r\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\r\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n\r\n# loading the weights of the pre-trained VGG16:\r\n\r\nassert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\r\nf = h5py.File(weights_path)\r\nfor k in range(f.attrs['nb_layers']):\r\n    if k >= len(model.layers):\r\n        break\r\n    g = f['layer_{}'.format(k)]\r\n    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\r\n    model.layers[k].set_weights(weights)\r\nf.close()\r\nprint('Model loaded.')\r\n\r\n# building a classifier model on top of the convolutional model:\r\n\r\ntop_model = Sequential()\r\ntop_model.add(Flatten(input_shape=model.output_shape[1:]))\r\ntop_model.add(Dense(64, activation='relu', W_regularizer=EigenvalueRegularizer(10)))\r\ntop_model.add(Dense(10, activation='softmax', W_regularizer=EigenvalueRegularizer(10)))\r\ntop_model.load_weights(top_model_weights_path)\r\n\r\n# add the model on top of the convolutional base\r\nmodel.add(top_model)\r\n\r\n# setting the first 15 layers to non-trainable (the original weights will not be updated)\r\n    \r\nfor layer in model.layers[:15]:\r\n    layer.trainable = False\r\n\r\n# Compiling the model with a SGD/momentum optimizer:\r\n\r\nmodel.compile(loss = \"categorical_crossentropy\",\r\n              optimizer=optimizers.SGD(lr=1e-6, momentum=0.9),\r\n              metrics=['mean_squared_logarithmic_error', 'accuracy'])\r\n\r\n# Data augmentation:\r\n\r\ntrain_datagen = ImageDataGenerator(shear_range=0.3, zoom_range=0.3, rotation_range=0.3)\r\ntest_datagen = ImageDataGenerator()\r\n\r\nprint('trainning')\r\ntrain_generator = train_datagen.flow_from_directory(\r\n        train_data_dir,\r\n        target_size=(img_height, img_width),\r\n        batch_size=32,\r\n        class_mode='categorical')\r\n  \r\n\r\nprint('testing')\r\ntest_generator = test_datagen.flow_from_directory(\r\n        test_data_dir,\r\n        target_size=(img_height, img_width),\r\n        batch_size=32,\r\n        class_mode='categorical',\r\n        shuffle=False)\r\n\r\nclass_dictionary = train_generator.class_indices\r\nsorted_class_dictionary = OrderedDict(sorted(class_dictionary.items()))\r\nsorted_class_dictionary = sorted_class_dictionary.values()\r\nprint(sorted_class_dictionary)\r\n\r\n# Fine-tuning the model:\r\nmodel.fit_generator(\r\n        train_generator,\r\n        samples_per_epoch=nb_train_samples,\r\n        nb_epoch=nb_epoch,\r\n        validation_data=train_generator,\r\n        nb_val_samples=nb_train_samples)\r\n        \r\nmodel.save_weights(whole_model_weights_path)\r\n\r\naux = model.predict_generator(test_generator, nb_test_samples)\r\npredictions = np.zeros((nb_test_samples, 10))\r\n\r\n# Rearranging the predictions:\r\n\r\nord = [5, 0, 6, 2, 7, 9, 1, 4, 8, 3]\r\n\r\nfor n in range(10):\r\n    i = ord[n]\r\n    print(i)\r\n    print(aux[:, i])\r\n    predictions[:, n] = aux[:, i]\r\n\r\n# Trick to improve the multi-class logarithmic loss (the evaluation metric of state-farm-distracted-driver-detection from Keras):\r\n\r\npredictions = 0.985 * predictions + 0.015\r\n\r\ndef get_im(path, img_width, img_height, color_type=1):\r\n    if color_type == 1:\r\n        img = cv2.imread(path, 0)\r\n    elif color_type == 3:\r\n        img = cv2.imread(path)\r\n    # Reduce size\r\n    resized = cv2.resize(img, (img_height, img_width))\r\n    return resized\r\n\r\ndef load_test(img_width, img_height, color_type=1):\r\n    print('Read test images')\r\n    path = os.path.join(test_images_path, '*.jpg')\r\n    files = glob.glob(path)\r\n    X_test = []\r\n    X_test_id = []\r\n    total = 0\r\n    thr = math.floor(len(files)/10)\r\n    for fl in files:\r\n        flbase = os.path.basename(fl)\r\n        img = get_im(fl, img_width, img_height, color_type)\r\n        X_test.append(img)\r\n        X_test_id.append(flbase)\r\n        total += 1\r\n        if total % thr == 0:\r\n            print('Read {} images from {}'.format(total, len(files)))\r\n\r\n    return X_test, X_test_id\r\n\r\nX_test, test_id = load_test(img_width, img_height, color_type_global)\r\n\r\ndef create_submission(predictions, test_id):\r\n    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3',\r\n                                                 'c4', 'c5', 'c6', 'c7',\r\n                                                 'c8', 'c9'])\r\n    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\r\n    now = datetime.datetime.now()\r\n    if not os.path.isdir('subm'):\r\n        os.mkdir('subm')\r\n    suffix = '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\r\n    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\r\n    result1.to_csv(sub_file, index=False)\r\n\r\ncreate_submission(predictions, test_id)\r\n```"}