{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11908", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11908/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11908/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11908/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11908", "id": 246759731, "node_id": "MDU6SXNzdWUyNDY3NTk3MzE=", "number": 11908, "title": "Query in lower-level versions of Get/Put involved in EncodeFixed/DecodeFixed", "user": {"login": "namrata-ibm", "id": 21953668, "node_id": "MDQ6VXNlcjIxOTUzNjY4", "avatar_url": "https://avatars3.githubusercontent.com/u/21953668?v=4", "gravatar_id": "", "url": "https://api.github.com/users/namrata-ibm", "html_url": "https://github.com/namrata-ibm", "followers_url": "https://api.github.com/users/namrata-ibm/followers", "following_url": "https://api.github.com/users/namrata-ibm/following{/other_user}", "gists_url": "https://api.github.com/users/namrata-ibm/gists{/gist_id}", "starred_url": "https://api.github.com/users/namrata-ibm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/namrata-ibm/subscriptions", "organizations_url": "https://api.github.com/users/namrata-ibm/orgs", "repos_url": "https://api.github.com/users/namrata-ibm/repos", "events_url": "https://api.github.com/users/namrata-ibm/events{/privacy}", "received_events_url": "https://api.github.com/users/namrata-ibm/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-07-31T13:42:19Z", "updated_at": "2017-08-03T10:02:45Z", "closed_at": "2017-08-02T21:32:09Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 'v1.2.1-0-gb4957ff', '1.2.1'</li>\n<li><strong>Python version</strong>:  2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.4.5</li>\n<li><strong>CUDA/cuDNN version</strong>: No GPU</li>\n<li><strong>GPU model and memory</strong>: No GPU</li>\n<li><strong>Exact command to reproduce</strong>: Run tests from core module.</li>\n</ul>\n<h3>The problem</h3>\n<p>While checking <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/core/coding_test.cc\">coding_test.cc</a> , came across a sub test - <code>TEST(Coding, EncodingOutput)</code> which tests that encoding routines generate little-endian encodings.<br>\nThis test is passing on a big endian machine. So while debugging realized that the <code>EncodeFixed/DecodeFixed</code> functions from <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/core/coding.cc\">coding.cc</a> and <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/core/raw_coding.h\">raw_coding.h</a> encode/decode <code>buf</code> values on big endian incorrectly i.e. the character buffer writing happens in the same way as on a little-endian machine.</p>\n<p>After I made the required changes to correct the same, although 1 test of my interest(<code>TEST(TensorBundleTest, Checksum)</code>) now passes, I could see many others failing on big endian with errors like:</p>\n<ol>\n<li><code>Data loss: block checksum mismatch: perhaps your file is in a different file format and you need to use a different restore operator?</code></li>\n<li><code>\"Data loss: corrupted record at 19\"</code></li>\n<li><code>Segmentation fault</code></li>\n<li><code>Invalid argument: sample_rate must be in (0, 2^32), got: 0</code></li>\n</ol>\n<p>So looks like this change is breaking too many things here.</p>\n<p>Can anyone help in understanding why the correction is causing so many issues?<br>\nWill this change involve too many changes in TensorFlow code to support big endian?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 'v1.2.1-0-gb4957ff', '1.2.1'\nPython version:  2.7.12\nBazel version (if compiling from source): 0.4.5\nCUDA/cuDNN version: No GPU\nGPU model and memory: No GPU\nExact command to reproduce: Run tests from core module.\n\nThe problem\nWhile checking coding_test.cc , came across a sub test - TEST(Coding, EncodingOutput) which tests that encoding routines generate little-endian encodings.\nThis test is passing on a big endian machine. So while debugging realized that the EncodeFixed/DecodeFixed functions from coding.cc and raw_coding.h encode/decode buf values on big endian incorrectly i.e. the character buffer writing happens in the same way as on a little-endian machine.\nAfter I made the required changes to correct the same, although 1 test of my interest(TEST(TensorBundleTest, Checksum)) now passes, I could see many others failing on big endian with errors like:\n\nData loss: block checksum mismatch: perhaps your file is in a different file format and you need to use a different restore operator?\n\"Data loss: corrupted record at 19\"\nSegmentation fault\nInvalid argument: sample_rate must be in (0, 2^32), got: 0\n\nSo looks like this change is breaking too many things here.\nCan anyone help in understanding why the correction is causing so many issues?\nWill this change involve too many changes in TensorFlow code to support big endian?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 'v1.2.1-0-gb4957ff', '1.2.1'\r\n- **Python version**:  2.7.12\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: No GPU\r\n- **GPU model and memory**: No GPU\r\n- **Exact command to reproduce**: Run tests from core module.\r\n\r\n### The problem\r\nWhile checking [coding_test.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/core/coding_test.cc) , came across a sub test - `TEST(Coding, EncodingOutput)` which tests that encoding routines generate little-endian encodings. \r\nThis test is passing on a big endian machine. So while debugging realized that the `EncodeFixed/DecodeFixed` functions from [coding.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/core/coding.cc) and [raw_coding.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/core/raw_coding.h) encode/decode `buf` values on big endian incorrectly i.e. the character buffer writing happens in the same way as on a little-endian machine.\r\n\r\n\r\nAfter I made the required changes to correct the same, although 1 test of my interest(`TEST(TensorBundleTest, Checksum)`) now passes, I could see many others failing on big endian with errors like:\r\n1. `Data loss: block checksum mismatch: perhaps your file is in a different file format and you need to use a different restore operator?`\r\n2. `\"Data loss: corrupted record at 19\"`\r\n3. `Segmentation fault`\r\n4. `Invalid argument: sample_rate must be in (0, 2^32), got: 0`\r\n\r\nSo looks like this change is breaking too many things here. \r\n\r\nCan anyone help in understanding why the correction is causing so many issues? \r\nWill this change involve too many changes in TensorFlow code to support big endian?\r\n"}