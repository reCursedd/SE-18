{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/193973270", "html_url": "https://github.com/tensorflow/tensorflow/issues/620#issuecomment-193973270", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/620", "id": 193973270, "node_id": "MDEyOklzc3VlQ29tbWVudDE5Mzk3MzI3MA==", "user": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-08T21:21:57Z", "updated_at": "2016-03-08T21:21:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is a question for stackoverflow, not an issue with TensorFlow.  If the activations have shape <code>[batch, input]</code> and the weight matrix has shape <code>[input, output]</code>, only <code>tf.matmul(activations, weights)</code> makes sense.  The other way around would be a size error.  You're correct that transposing the entire graph should produce something with the same semantics, but note that <em>every</em> part of the graph needs to be transposed, including the input pipeline, loss ops, etc.</p>", "body_text": "This is a question for stackoverflow, not an issue with TensorFlow.  If the activations have shape [batch, input] and the weight matrix has shape [input, output], only tf.matmul(activations, weights) makes sense.  The other way around would be a size error.  You're correct that transposing the entire graph should produce something with the same semantics, but note that every part of the graph needs to be transposed, including the input pipeline, loss ops, etc.", "body": "This is a question for stackoverflow, not an issue with TensorFlow.  If the activations have shape `[batch, input]` and the weight matrix has shape `[input, output]`, only `tf.matmul(activations, weights)` makes sense.  The other way around would be a size error.  You're correct that transposing the entire graph should produce something with the same semantics, but note that _every_ part of the graph needs to be transposed, including the input pipeline, loss ops, etc.\n"}