{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/377500497", "html_url": "https://github.com/tensorflow/tensorflow/issues/3725#issuecomment-377500497", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3725", "id": 377500497, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzUwMDQ5Nw==", "user": {"login": "ydp", "id": 1532805, "node_id": "MDQ6VXNlcjE1MzI4MDU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1532805?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ydp", "html_url": "https://github.com/ydp", "followers_url": "https://api.github.com/users/ydp/followers", "following_url": "https://api.github.com/users/ydp/following{/other_user}", "gists_url": "https://api.github.com/users/ydp/gists{/gist_id}", "starred_url": "https://api.github.com/users/ydp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ydp/subscriptions", "organizations_url": "https://api.github.com/users/ydp/orgs", "repos_url": "https://api.github.com/users/ydp/repos", "events_url": "https://api.github.com/users/ydp/events{/privacy}", "received_events_url": "https://api.github.com/users/ydp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-30T10:48:48Z", "updated_at": "2018-03-30T10:48:48Z", "author_association": "NONE", "body_html": "<p>hey, sorry to dig the old issue, but go into the implementation, still have some question here.</p>\n<p>tensorflow/core/kernel/training_ops.cc</p>\n<p>class SparseApplyFtrlOp</p>\n<pre><code>          T updated_a = a + g * g;\n          using Eigen::numext::pow;\n          T sigma = pow(updated_a, -lr_power_scalar) - pow(a, -lr_power_scalar);\n          sigma /= lr_scalar;\n          T updated_l = l + g - sigma * v;\n          v = FtrlCompute(updated_a, updated_l, lr_scalar, l1_scalar, l2_scalar,\n                          lr_power_scalar);\n          a = updated_a;\n          l = updated_l;\n</code></pre>\n<p>a/updated_a  -&gt; n<br>\nl/updated_l    -&gt;  z<br>\nv                    -&gt;  w<br>\nlr_scalar        -&gt;  alpha<br>\nl1_scalar        -&gt;  lambda1<br>\nl2_scalar       -&gt;  lambda2</p>\n<p>FtrlCompute</p>\n<pre><code>template &lt;typename T&gt;\ninline T FtrlCompute(const T&amp; accum, const T&amp; linear, const T&amp; lr, const T&amp; l1,\n                     const T&amp; l2, const T&amp; lr_power) {\n  T quadratic;\n  if (lr_power == static_cast&lt;T&gt;(-0.5)) {\n    quadratic = Eigen::numext::sqrt(accum) / lr + static_cast&lt;T&gt;(2) * l2;\n  } else {\n    quadratic =\n        Eigen::numext::pow(accum, -lr_power) / lr + static_cast&lt;T&gt;(2) * l2;\n  }\n  if (Eigen::numext::abs(linear) &gt; l1) {\n    return (l1 * sgn(linear) - linear) / quadratic;\n  } else {\n    return static_cast&lt;T&gt;(0.0);\n  }\n}\n</code></pre>\n<p>linear        -&gt;   z<br>\nl1               -&gt;   lambda1<br>\nl2              -&gt;   lambda2<br>\nlr               -&gt;   alpha<br>\naccum      -&gt;   n</p>\n<p>so , the problem is here</p>\n<pre><code>quadratic = Eigen::numext::sqrt(accum) / lr + static_cast&lt;T&gt;(2) * l2;\n</code></pre>\n<p>why there is <code>a static_cast&lt;T&gt;(2)</code>?  according paper, it is only lambda2.</p>", "body_text": "hey, sorry to dig the old issue, but go into the implementation, still have some question here.\ntensorflow/core/kernel/training_ops.cc\nclass SparseApplyFtrlOp\n          T updated_a = a + g * g;\n          using Eigen::numext::pow;\n          T sigma = pow(updated_a, -lr_power_scalar) - pow(a, -lr_power_scalar);\n          sigma /= lr_scalar;\n          T updated_l = l + g - sigma * v;\n          v = FtrlCompute(updated_a, updated_l, lr_scalar, l1_scalar, l2_scalar,\n                          lr_power_scalar);\n          a = updated_a;\n          l = updated_l;\n\na/updated_a  -> n\nl/updated_l    ->  z\nv                    ->  w\nlr_scalar        ->  alpha\nl1_scalar        ->  lambda1\nl2_scalar       ->  lambda2\nFtrlCompute\ntemplate <typename T>\ninline T FtrlCompute(const T& accum, const T& linear, const T& lr, const T& l1,\n                     const T& l2, const T& lr_power) {\n  T quadratic;\n  if (lr_power == static_cast<T>(-0.5)) {\n    quadratic = Eigen::numext::sqrt(accum) / lr + static_cast<T>(2) * l2;\n  } else {\n    quadratic =\n        Eigen::numext::pow(accum, -lr_power) / lr + static_cast<T>(2) * l2;\n  }\n  if (Eigen::numext::abs(linear) > l1) {\n    return (l1 * sgn(linear) - linear) / quadratic;\n  } else {\n    return static_cast<T>(0.0);\n  }\n}\n\nlinear        ->   z\nl1               ->   lambda1\nl2              ->   lambda2\nlr               ->   alpha\naccum      ->   n\nso , the problem is here\nquadratic = Eigen::numext::sqrt(accum) / lr + static_cast<T>(2) * l2;\n\nwhy there is a static_cast<T>(2)?  according paper, it is only lambda2.", "body": "hey, sorry to dig the old issue, but go into the implementation, still have some question here.\r\n\r\ntensorflow/core/kernel/training_ops.cc\r\n\r\nclass SparseApplyFtrlOp\r\n```\r\n          T updated_a = a + g * g;\r\n          using Eigen::numext::pow;\r\n          T sigma = pow(updated_a, -lr_power_scalar) - pow(a, -lr_power_scalar);\r\n          sigma /= lr_scalar;\r\n          T updated_l = l + g - sigma * v;\r\n          v = FtrlCompute(updated_a, updated_l, lr_scalar, l1_scalar, l2_scalar,\r\n                          lr_power_scalar);\r\n          a = updated_a;\r\n          l = updated_l;\r\n```\r\na/updated_a  -> n\r\nl/updated_l    ->  z\r\nv                    ->  w\r\nlr_scalar        ->  alpha\r\nl1_scalar        ->  lambda1\r\nl2_scalar       ->  lambda2\r\n\r\n\r\nFtrlCompute\r\n```\r\ntemplate <typename T>\r\ninline T FtrlCompute(const T& accum, const T& linear, const T& lr, const T& l1,\r\n                     const T& l2, const T& lr_power) {\r\n  T quadratic;\r\n  if (lr_power == static_cast<T>(-0.5)) {\r\n    quadratic = Eigen::numext::sqrt(accum) / lr + static_cast<T>(2) * l2;\r\n  } else {\r\n    quadratic =\r\n        Eigen::numext::pow(accum, -lr_power) / lr + static_cast<T>(2) * l2;\r\n  }\r\n  if (Eigen::numext::abs(linear) > l1) {\r\n    return (l1 * sgn(linear) - linear) / quadratic;\r\n  } else {\r\n    return static_cast<T>(0.0);\r\n  }\r\n}\r\n```\r\nlinear        ->   z\r\nl1               ->   lambda1\r\nl2              ->   lambda2\r\nlr               ->   alpha\r\naccum      ->   n\r\n\r\nso , the problem is here\r\n```\r\nquadratic = Eigen::numext::sqrt(accum) / lr + static_cast<T>(2) * l2;\r\n```\r\nwhy there is `a static_cast<T>(2)`?  according paper, it is only lambda2.\r\n"}