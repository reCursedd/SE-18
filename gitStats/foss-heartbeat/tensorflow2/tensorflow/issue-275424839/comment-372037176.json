{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/372037176", "html_url": "https://github.com/tensorflow/tensorflow/issues/14731#issuecomment-372037176", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14731", "id": 372037176, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjAzNzE3Ng==", "user": {"login": "madhavajay", "id": 2882739, "node_id": "MDQ6VXNlcjI4ODI3Mzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/2882739?v=4", "gravatar_id": "", "url": "https://api.github.com/users/madhavajay", "html_url": "https://github.com/madhavajay", "followers_url": "https://api.github.com/users/madhavajay/followers", "following_url": "https://api.github.com/users/madhavajay/following{/other_user}", "gists_url": "https://api.github.com/users/madhavajay/gists{/gist_id}", "starred_url": "https://api.github.com/users/madhavajay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/madhavajay/subscriptions", "organizations_url": "https://api.github.com/users/madhavajay/orgs", "repos_url": "https://api.github.com/users/madhavajay/repos", "events_url": "https://api.github.com/users/madhavajay/events{/privacy}", "received_events_url": "https://api.github.com/users/madhavajay/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-10T15:13:57Z", "updated_at": "2018-03-10T15:13:57Z", "author_association": "NONE", "body_html": "<p>This is awesome.<br>\nJust a side thought, is there any interest in providing TF Lite for other platforms like the python client  that run for server side inference?</p>\n<p>It seems to me that the performance gains and memory footprint of TFLite would be welcome in many web based inference scenarios. Not to mention dare I say a JavaScript WebGL based implementation down the track (i bet my left arm you guys already have this in the works).</p>", "body_text": "This is awesome.\nJust a side thought, is there any interest in providing TF Lite for other platforms like the python client  that run for server side inference?\nIt seems to me that the performance gains and memory footprint of TFLite would be welcome in many web based inference scenarios. Not to mention dare I say a JavaScript WebGL based implementation down the track (i bet my left arm you guys already have this in the works).", "body": "This is awesome.\r\nJust a side thought, is there any interest in providing TF Lite for other platforms like the python client  that run for server side inference?\r\n\r\nIt seems to me that the performance gains and memory footprint of TFLite would be welcome in many web based inference scenarios. Not to mention dare I say a JavaScript WebGL based implementation down the track (i bet my left arm you guys already have this in the works).\r\n\r\n\r\n"}