{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/322939371", "html_url": "https://github.com/tensorflow/tensorflow/issues/5719#issuecomment-322939371", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5719", "id": 322939371, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjkzOTM3MQ==", "user": {"login": "ed-alertedh", "id": 24605895, "node_id": "MDQ6VXNlcjI0NjA1ODk1", "avatar_url": "https://avatars1.githubusercontent.com/u/24605895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ed-alertedh", "html_url": "https://github.com/ed-alertedh", "followers_url": "https://api.github.com/users/ed-alertedh/followers", "following_url": "https://api.github.com/users/ed-alertedh/following{/other_user}", "gists_url": "https://api.github.com/users/ed-alertedh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ed-alertedh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ed-alertedh/subscriptions", "organizations_url": "https://api.github.com/users/ed-alertedh/orgs", "repos_url": "https://api.github.com/users/ed-alertedh/repos", "events_url": "https://api.github.com/users/ed-alertedh/events{/privacy}", "received_events_url": "https://api.github.com/users/ed-alertedh/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-17T00:56:19Z", "updated_at": "2017-08-17T00:56:19Z", "author_association": "NONE", "body_html": "<p>I guess it just isn't scaling well for that number of rows. Not really what you'd expect given it should be an \"embarassingly parallel\" problem, but maybe you just need to throw a huge number of rows at it to start seeing the benefit. Perhaps concatenating the matrices rather than using map_fn would change performance? Would likely eat up too much memory though....</p>\n<p>Hard to say for sure because the benchmarks were all run with 128 rows.  Your case of [256,20] is roughly comparable to the benchmarks on [128,10] and [128,100] which all ran faster on CPU. In case you hadn't found them, benchmark results here: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/0b5cce367cf95a5d7fbb6b037e7a8646f6c47b70/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/0b5cce367cf95a5d7fbb6b037e7a8646f6c47b70\"><tt>0b5cce3</tt></a></p>", "body_text": "I guess it just isn't scaling well for that number of rows. Not really what you'd expect given it should be an \"embarassingly parallel\" problem, but maybe you just need to throw a huge number of rows at it to start seeing the benefit. Perhaps concatenating the matrices rather than using map_fn would change performance? Would likely eat up too much memory though....\nHard to say for sure because the benchmarks were all run with 128 rows.  Your case of [256,20] is roughly comparable to the benchmarks on [128,10] and [128,100] which all ran faster on CPU. In case you hadn't found them, benchmark results here: 0b5cce3", "body": "I guess it just isn't scaling well for that number of rows. Not really what you'd expect given it should be an \"embarassingly parallel\" problem, but maybe you just need to throw a huge number of rows at it to start seeing the benefit. Perhaps concatenating the matrices rather than using map_fn would change performance? Would likely eat up too much memory though....\r\n\r\nHard to say for sure because the benchmarks were all run with 128 rows.  Your case of [256,20] is roughly comparable to the benchmarks on [128,10] and [128,100] which all ran faster on CPU. In case you hadn't found them, benchmark results here: https://github.com/tensorflow/tensorflow/commit/0b5cce367cf95a5d7fbb6b037e7a8646f6c47b70"}