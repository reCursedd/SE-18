{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/323267198", "html_url": "https://github.com/tensorflow/tensorflow/issues/5719#issuecomment-323267198", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5719", "id": 323267198, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzI2NzE5OA==", "user": {"login": "ed-alertedh", "id": 24605895, "node_id": "MDQ6VXNlcjI0NjA1ODk1", "avatar_url": "https://avatars1.githubusercontent.com/u/24605895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ed-alertedh", "html_url": "https://github.com/ed-alertedh", "followers_url": "https://api.github.com/users/ed-alertedh/followers", "following_url": "https://api.github.com/users/ed-alertedh/following{/other_user}", "gists_url": "https://api.github.com/users/ed-alertedh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ed-alertedh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ed-alertedh/subscriptions", "organizations_url": "https://api.github.com/users/ed-alertedh/orgs", "repos_url": "https://api.github.com/users/ed-alertedh/repos", "events_url": "https://api.github.com/users/ed-alertedh/events{/privacy}", "received_events_url": "https://api.github.com/users/ed-alertedh/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-18T06:01:20Z", "updated_at": "2017-08-18T06:10:46Z", "author_association": "NONE", "body_html": "<p>It does seem counter-intuitive that performance would be that much worse than CPU on that many rows...<br>\nIf it helps, I was using the following to force a DtoH/HtoD transfer when benchmarking the CPU op so I could better compare CUDA overheads versus the overhead of transferring to CPU:</p>\n<pre><code>from tensorflow.python.platform import benchmark\nfrom tensorflow.python.platform import test\nimport tensorflow as tf\nimport numpy as np\n\nclass TopKBenchmark(test.Benchmark):\n    def benchmark_topk_gpu(self, dims, k, sorted=False):\n        with tf.device('/gpu:0'):\n            test_data = np.random.uniform(size=dims)\n            data = tf.constant(test_data, dtype=tf.float64)\n            k_in = tf.constant(k)\n\n        with tf.device('/gpu:0'):\n            op_under_test = tf.nn.top_k(data, k_in, sorted=sorted)\n\n        # Creates a session with log_device_placement set to True.\n        conf = tf.ConfigProto(log_device_placement=True, allow_soft_placement=False)\n        # Don't perform optimizations for tests so we don't inadvertently run\n        # gpu ops on cpu\n        conf.graph_options.optimizer_options.opt_level = -1\n        sess = tf.Session(config=conf)\n        with sess:\n            return self.run_op_benchmark(\n                sess, op_under_test, min_iters=1000, store_trace=False, name=\"op_benchmark\")\n\n    def benchmark_topk_cpu(self, dims, k, sorted=False):\n        with tf.device('/gpu:0'):\n            test_data = np.random.uniform(size=dims)\n            data = tf.constant(test_data, dtype=tf.float64)\n            k_in = tf.constant(k)\n\n        with tf.device('/cpu:0'):\n            op_under_test = tf.nn.top_k(data, k_in, sorted=sorted)\n\n        # Creates a session with log_device_placement set to True.\n        conf = tf.ConfigProto(log_device_placement=True, allow_soft_placement=False)\n        # Don't perform optimizations for tests so we don't inadvertently run\n        # gpu ops on cpu\n        conf.graph_options.optimizer_options.opt_level = -1\n        sess = tf.Session(config=conf)\n        with sess:\n            return self.run_op_benchmark(\n                sess, op_under_test, min_iters=1000, store_trace=False, name=\"op_benchmark\")\n\n\nbm = TopKBenchmark()\ndims = (10**6, 20)\nk=5\ncpu_res = bm.benchmark_topk_cpu(dims, k)\ngpu_res = bm.benchmark_topk_gpu(dims, k)\nprint('***** CPU TIME:')\nprint(cpu_res)\nprint('***** GPU TIME:')\nprint(gpu_res)\n</code></pre>\n<p>edit: fixed a couple of typos in code above</p>\n<p>I won't pretend to fully understand the current implementation since I've only skim-read it, but the sort implementation looks like it should be parallel on the rows: <a href=\"https://nvlabs.github.io/cub/structcub_1_1_device_segmented_radix_sort.html\" rel=\"nofollow\">https://nvlabs.github.io/cub/structcub_1_1_device_segmented_radix_sort.html</a></p>", "body_text": "It does seem counter-intuitive that performance would be that much worse than CPU on that many rows...\nIf it helps, I was using the following to force a DtoH/HtoD transfer when benchmarking the CPU op so I could better compare CUDA overheads versus the overhead of transferring to CPU:\nfrom tensorflow.python.platform import benchmark\nfrom tensorflow.python.platform import test\nimport tensorflow as tf\nimport numpy as np\n\nclass TopKBenchmark(test.Benchmark):\n    def benchmark_topk_gpu(self, dims, k, sorted=False):\n        with tf.device('/gpu:0'):\n            test_data = np.random.uniform(size=dims)\n            data = tf.constant(test_data, dtype=tf.float64)\n            k_in = tf.constant(k)\n\n        with tf.device('/gpu:0'):\n            op_under_test = tf.nn.top_k(data, k_in, sorted=sorted)\n\n        # Creates a session with log_device_placement set to True.\n        conf = tf.ConfigProto(log_device_placement=True, allow_soft_placement=False)\n        # Don't perform optimizations for tests so we don't inadvertently run\n        # gpu ops on cpu\n        conf.graph_options.optimizer_options.opt_level = -1\n        sess = tf.Session(config=conf)\n        with sess:\n            return self.run_op_benchmark(\n                sess, op_under_test, min_iters=1000, store_trace=False, name=\"op_benchmark\")\n\n    def benchmark_topk_cpu(self, dims, k, sorted=False):\n        with tf.device('/gpu:0'):\n            test_data = np.random.uniform(size=dims)\n            data = tf.constant(test_data, dtype=tf.float64)\n            k_in = tf.constant(k)\n\n        with tf.device('/cpu:0'):\n            op_under_test = tf.nn.top_k(data, k_in, sorted=sorted)\n\n        # Creates a session with log_device_placement set to True.\n        conf = tf.ConfigProto(log_device_placement=True, allow_soft_placement=False)\n        # Don't perform optimizations for tests so we don't inadvertently run\n        # gpu ops on cpu\n        conf.graph_options.optimizer_options.opt_level = -1\n        sess = tf.Session(config=conf)\n        with sess:\n            return self.run_op_benchmark(\n                sess, op_under_test, min_iters=1000, store_trace=False, name=\"op_benchmark\")\n\n\nbm = TopKBenchmark()\ndims = (10**6, 20)\nk=5\ncpu_res = bm.benchmark_topk_cpu(dims, k)\ngpu_res = bm.benchmark_topk_gpu(dims, k)\nprint('***** CPU TIME:')\nprint(cpu_res)\nprint('***** GPU TIME:')\nprint(gpu_res)\n\nedit: fixed a couple of typos in code above\nI won't pretend to fully understand the current implementation since I've only skim-read it, but the sort implementation looks like it should be parallel on the rows: https://nvlabs.github.io/cub/structcub_1_1_device_segmented_radix_sort.html", "body": "It does seem counter-intuitive that performance would be that much worse than CPU on that many rows...\r\nIf it helps, I was using the following to force a DtoH/HtoD transfer when benchmarking the CPU op so I could better compare CUDA overheads versus the overhead of transferring to CPU:\r\n```\r\nfrom tensorflow.python.platform import benchmark\r\nfrom tensorflow.python.platform import test\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass TopKBenchmark(test.Benchmark):\r\n    def benchmark_topk_gpu(self, dims, k, sorted=False):\r\n        with tf.device('/gpu:0'):\r\n            test_data = np.random.uniform(size=dims)\r\n            data = tf.constant(test_data, dtype=tf.float64)\r\n            k_in = tf.constant(k)\r\n\r\n        with tf.device('/gpu:0'):\r\n            op_under_test = tf.nn.top_k(data, k_in, sorted=sorted)\r\n\r\n        # Creates a session with log_device_placement set to True.\r\n        conf = tf.ConfigProto(log_device_placement=True, allow_soft_placement=False)\r\n        # Don't perform optimizations for tests so we don't inadvertently run\r\n        # gpu ops on cpu\r\n        conf.graph_options.optimizer_options.opt_level = -1\r\n        sess = tf.Session(config=conf)\r\n        with sess:\r\n            return self.run_op_benchmark(\r\n                sess, op_under_test, min_iters=1000, store_trace=False, name=\"op_benchmark\")\r\n\r\n    def benchmark_topk_cpu(self, dims, k, sorted=False):\r\n        with tf.device('/gpu:0'):\r\n            test_data = np.random.uniform(size=dims)\r\n            data = tf.constant(test_data, dtype=tf.float64)\r\n            k_in = tf.constant(k)\r\n\r\n        with tf.device('/cpu:0'):\r\n            op_under_test = tf.nn.top_k(data, k_in, sorted=sorted)\r\n\r\n        # Creates a session with log_device_placement set to True.\r\n        conf = tf.ConfigProto(log_device_placement=True, allow_soft_placement=False)\r\n        # Don't perform optimizations for tests so we don't inadvertently run\r\n        # gpu ops on cpu\r\n        conf.graph_options.optimizer_options.opt_level = -1\r\n        sess = tf.Session(config=conf)\r\n        with sess:\r\n            return self.run_op_benchmark(\r\n                sess, op_under_test, min_iters=1000, store_trace=False, name=\"op_benchmark\")\r\n\r\n\r\nbm = TopKBenchmark()\r\ndims = (10**6, 20)\r\nk=5\r\ncpu_res = bm.benchmark_topk_cpu(dims, k)\r\ngpu_res = bm.benchmark_topk_gpu(dims, k)\r\nprint('***** CPU TIME:')\r\nprint(cpu_res)\r\nprint('***** GPU TIME:')\r\nprint(gpu_res)\r\n```\r\nedit: fixed a couple of typos in code above\r\n\r\nI won't pretend to fully understand the current implementation since I've only skim-read it, but the sort implementation looks like it should be parallel on the rows: https://nvlabs.github.io/cub/structcub_1_1_device_segmented_radix_sort.html"}