{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17913", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17913/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17913/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17913/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17913", "id": 307490037, "node_id": "MDU6SXNzdWUzMDc0OTAwMzc=", "number": 17913, "title": "Tensorflow in Android: You must feed a value for placeholder tensor 'Placeholder' with dtype float issue", "user": {"login": "MilicaJankovic", "id": 13006352, "node_id": "MDQ6VXNlcjEzMDA2MzUy", "avatar_url": "https://avatars3.githubusercontent.com/u/13006352?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MilicaJankovic", "html_url": "https://github.com/MilicaJankovic", "followers_url": "https://api.github.com/users/MilicaJankovic/followers", "following_url": "https://api.github.com/users/MilicaJankovic/following{/other_user}", "gists_url": "https://api.github.com/users/MilicaJankovic/gists{/gist_id}", "starred_url": "https://api.github.com/users/MilicaJankovic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MilicaJankovic/subscriptions", "organizations_url": "https://api.github.com/users/MilicaJankovic/orgs", "repos_url": "https://api.github.com/users/MilicaJankovic/repos", "events_url": "https://api.github.com/users/MilicaJankovic/events{/privacy}", "received_events_url": "https://api.github.com/users/MilicaJankovic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-22T03:06:04Z", "updated_at": "2018-03-22T21:36:02Z", "closed_at": "2018-03-22T21:36:00Z", "author_association": "NONE", "body_html": "<p>have a problem with importing Tensorflow model into Android Studio application. I have built a model, froze the model and optimized that frozen model in Python, and now I'm trying to use it in the Android app, but it constantly returns me that same error that I must feed a value for a placeholder. This is happening in the Android app when I run inferenceInterface.run(OUTPUT_NODES); function.</p>\n<p>I don't know if the error is it in the model itself, but I'm assuming that python would throw me an error and won't build the model, what he did.</p>\n<p>This is the example of rows of data I'm sending to Tensorflow (in csv file):</p>\n<p>1,26,2091,5,2,0,0,0,0,0,85,105,6,4,0,1<br>\n1,26,47,9,4,0,0,0,0,0,85,0,7,4,1,0</p>\n<p>This is the creating model in Python:</p>\n<hr>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom math import floor, ceil\nfrom pylab import rcParams\n\n\ncolumns = [\"Gender\", \"Age\", \"StepsNum\", \"Still\", \"ContinuousStill\",\n           \"Running\", \"Driving\", \"Cycling\", \"Weather\", \"TargetWeight\",\n           \"Calories\", \"DayOfTheWeek\", \"PartOfTheDay\",\n           \"NotificationType\", \"UserInput\"]\n\nuserinput = ['0','1']\n\n\nactivites_df = pd.read_csv(\"E:\\\\MASTER\\\\PythonPrograms\\\\useractivityInt.csv\", header = None, names=columns)\n\n\n#encode all strings\ndef encode(series): \n    #print(pd.get_dummies(series.astype(str)))\n    return pd.get_dummies(series.astype(str))\n\n\ntrain_x = pd.DataFrame(activites_df, columns = columns, dtype=float)\n# train_x = activites_df\ntrain_y = encode(activites_df.UserInput)\nprint(train_y)\n# train_y = activites_df.iloc[:,-1]\n# print(train_y)\n# train_y = pd.DataFrame(userinput, dtype=float)\n\n\ntrain_size = 0.9\n\ntrain_cnt = floor(train_x.shape[0] * train_size)\n#iloc[0] - first row, iloc[:0] - first column of data frame, iloc[0:n] - first n rows\nx_train = train_x.iloc[0:train_cnt].values\ny_train = train_y.iloc[0:train_cnt].values\n\nx_test = train_x.iloc[train_cnt:].values\ny_test = train_y.iloc[train_cnt:].values\n\n\ndef multilayer_perceptron(x, weights, biases, keep_prob):\n    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n    layer_1 = tf.nn.relu(layer_1)\n    layer_1 = tf.nn.dropout(layer_1, keep_prob)\n    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n    return out_layer\n\n\n#shape[0] - Gives the number of rows in matrix.. shape[1] - numbers of columns \nn_hidden_1 = 38\nn_input = train_x.shape[1]\nn_classes = train_y.shape[1]\n# n_classes = 2\n\nweights = {\n    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]),tf.float32),\n    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes]),tf.float32)\n}\n\nbiases = {\n    'b1': tf.Variable(tf.random_normal([n_hidden_1]),tf.float32),\n    'out': tf.Variable(tf.random_normal([n_classes]),tf.float32)\n}\n\n#keep_prob: A scalar Tensor with the same type as x. The probability that each element is kept.\n# keep_prob = tf.placeholder(\"float\")\nkeep_prob = tf.placeholder(tf.float32)\n\ntraining_epochs = 5000\ndisplay_step = 1000\nbatch_size = 32\n\nx = tf.placeholder(tf.float32, [None, n_input], name='input')\ny = tf.placeholder(tf.float32, [None, n_classes])\n\npredictions = multilayer_perceptron(x, weights, biases, keep_prob)\n\n#_y is name for output node\n#If we take an input of [1, 2, 3, 4, 1, 2, 3], the softmax of that is [0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]. \n# The output has most of its weight where the '4' was in the original input. \n# This is what the function is normally used for: to highlight the largest values and suppress values which are significantly below the maximum value.\n\npred_softmax = tf.nn.softmax(predictions, name=\"y_\")\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n\nLEARNING_RATE = 0.0025\n\noptimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for epoch in range(training_epochs):\n        avg_cost = 0.0\n        total_batch = int(len(x_train) / batch_size)\n        x_batches = np.array_split(x_train, total_batch)\n        y_batches = np.array_split(y_train, total_batch)\n        for i in range(total_batch):\n            batch_x, batch_y = x_batches[i], y_batches[i]\n            _, c = sess.run([optimizer, cost], \n                            feed_dict={\n                                x: batch_x, \n                                y: batch_y, \n                                keep_prob: 0.8\n                            })\n            avg_cost += c / total_batch\n        if epoch % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \\\n                \"{:.9f}\".format(avg_cost))\n    print(\"Optimization Finished!\")\n    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n    print(\"Accuracy:\", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))\n\n    saver = tf.train.Saver()\n    tf.train.write_graph(sess.graph_def, '.', 'E:\\\\MASTER\\\\PythonPrograms\\\\har.pbtxt')  \n    saver.save(sess, save_path = \"E:\\\\MASTER\\\\PythonPrograms\\\\har.ckpt\")\n</code></pre>\n<hr>\n<p>The main parts of the code in Android Studio are those:</p>\n<p>Definition of variables:</p>\n<hr>\n<pre><code>private static final String MODEL_FILE = \"file:///android_asset/optimized_frozen_har.pb\";\n\n    String INPUT_NODE = \"input\";\n    String[] OUTPUT_NODES = {\"y_\"};\n    String OUTPUT_NODE = \"y_\";\n    //I don't know what is input size\n    long[] INPUT_SIZE = {1, 15};\n    int OUTPUT_SIZE = 2;\n\n    private TensorFlowInferenceInterface inferenceInterface;\n</code></pre>\n<hr>\n<p>Initialization and calling function in OnCreate:</p>\n<hr>\n<pre><code>inferenceInterface = new TensorFlowInferenceInterface(appContext.getAssets(), MODEL_FILE);\n\n\n float[] data = {(float)1.0, (float)26.0, (float)1000.0, (float)3.0, (float)1.0,(float)0.0, (float) 0.0, (float)0.0, (float)0.0, (float)0.0, (float)85.0, (float)48.0, (float)7.0, (float)4.0, (float)2.0};\n        float[] out = predictProbabilitiesFloat(data);\n</code></pre>\n<hr>\n<p>Function for returning result from TensorFlow:</p>\n<hr>\n<pre><code>public float[] predictProbabilitiesFloat(float[] data) {\n        float[] result = new float[OUTPUT_SIZE];\n        inferenceInterface.feed(INPUT_NODE, data, INPUT_SIZE);\n        inferenceInterface.run(OUTPUT_NODES);\n        inferenceInterface.fetch(OUTPUT_NODE, result);\n\n        //for us it should be 0 or 1\n        return result;\n    }\n</code></pre>\n<hr>\n<p>If somebody knows how to fix this problem, please help me, I have few more days to finish this as one part of my master thesis.</p>\n<p>Thank you in advance!``</p>", "body_text": "have a problem with importing Tensorflow model into Android Studio application. I have built a model, froze the model and optimized that frozen model in Python, and now I'm trying to use it in the Android app, but it constantly returns me that same error that I must feed a value for a placeholder. This is happening in the Android app when I run inferenceInterface.run(OUTPUT_NODES); function.\nI don't know if the error is it in the model itself, but I'm assuming that python would throw me an error and won't build the model, what he did.\nThis is the example of rows of data I'm sending to Tensorflow (in csv file):\n1,26,2091,5,2,0,0,0,0,0,85,105,6,4,0,1\n1,26,47,9,4,0,0,0,0,0,85,0,7,4,1,0\nThis is the creating model in Python:\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom math import floor, ceil\nfrom pylab import rcParams\n\n\ncolumns = [\"Gender\", \"Age\", \"StepsNum\", \"Still\", \"ContinuousStill\",\n           \"Running\", \"Driving\", \"Cycling\", \"Weather\", \"TargetWeight\",\n           \"Calories\", \"DayOfTheWeek\", \"PartOfTheDay\",\n           \"NotificationType\", \"UserInput\"]\n\nuserinput = ['0','1']\n\n\nactivites_df = pd.read_csv(\"E:\\\\MASTER\\\\PythonPrograms\\\\useractivityInt.csv\", header = None, names=columns)\n\n\n#encode all strings\ndef encode(series): \n    #print(pd.get_dummies(series.astype(str)))\n    return pd.get_dummies(series.astype(str))\n\n\ntrain_x = pd.DataFrame(activites_df, columns = columns, dtype=float)\n# train_x = activites_df\ntrain_y = encode(activites_df.UserInput)\nprint(train_y)\n# train_y = activites_df.iloc[:,-1]\n# print(train_y)\n# train_y = pd.DataFrame(userinput, dtype=float)\n\n\ntrain_size = 0.9\n\ntrain_cnt = floor(train_x.shape[0] * train_size)\n#iloc[0] - first row, iloc[:0] - first column of data frame, iloc[0:n] - first n rows\nx_train = train_x.iloc[0:train_cnt].values\ny_train = train_y.iloc[0:train_cnt].values\n\nx_test = train_x.iloc[train_cnt:].values\ny_test = train_y.iloc[train_cnt:].values\n\n\ndef multilayer_perceptron(x, weights, biases, keep_prob):\n    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n    layer_1 = tf.nn.relu(layer_1)\n    layer_1 = tf.nn.dropout(layer_1, keep_prob)\n    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n    return out_layer\n\n\n#shape[0] - Gives the number of rows in matrix.. shape[1] - numbers of columns \nn_hidden_1 = 38\nn_input = train_x.shape[1]\nn_classes = train_y.shape[1]\n# n_classes = 2\n\nweights = {\n    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]),tf.float32),\n    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes]),tf.float32)\n}\n\nbiases = {\n    'b1': tf.Variable(tf.random_normal([n_hidden_1]),tf.float32),\n    'out': tf.Variable(tf.random_normal([n_classes]),tf.float32)\n}\n\n#keep_prob: A scalar Tensor with the same type as x. The probability that each element is kept.\n# keep_prob = tf.placeholder(\"float\")\nkeep_prob = tf.placeholder(tf.float32)\n\ntraining_epochs = 5000\ndisplay_step = 1000\nbatch_size = 32\n\nx = tf.placeholder(tf.float32, [None, n_input], name='input')\ny = tf.placeholder(tf.float32, [None, n_classes])\n\npredictions = multilayer_perceptron(x, weights, biases, keep_prob)\n\n#_y is name for output node\n#If we take an input of [1, 2, 3, 4, 1, 2, 3], the softmax of that is [0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]. \n# The output has most of its weight where the '4' was in the original input. \n# This is what the function is normally used for: to highlight the largest values and suppress values which are significantly below the maximum value.\n\npred_softmax = tf.nn.softmax(predictions, name=\"y_\")\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n\nLEARNING_RATE = 0.0025\n\noptimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for epoch in range(training_epochs):\n        avg_cost = 0.0\n        total_batch = int(len(x_train) / batch_size)\n        x_batches = np.array_split(x_train, total_batch)\n        y_batches = np.array_split(y_train, total_batch)\n        for i in range(total_batch):\n            batch_x, batch_y = x_batches[i], y_batches[i]\n            _, c = sess.run([optimizer, cost], \n                            feed_dict={\n                                x: batch_x, \n                                y: batch_y, \n                                keep_prob: 0.8\n                            })\n            avg_cost += c / total_batch\n        if epoch % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \\\n                \"{:.9f}\".format(avg_cost))\n    print(\"Optimization Finished!\")\n    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n    print(\"Accuracy:\", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))\n\n    saver = tf.train.Saver()\n    tf.train.write_graph(sess.graph_def, '.', 'E:\\\\MASTER\\\\PythonPrograms\\\\har.pbtxt')  \n    saver.save(sess, save_path = \"E:\\\\MASTER\\\\PythonPrograms\\\\har.ckpt\")\n\n\nThe main parts of the code in Android Studio are those:\nDefinition of variables:\n\nprivate static final String MODEL_FILE = \"file:///android_asset/optimized_frozen_har.pb\";\n\n    String INPUT_NODE = \"input\";\n    String[] OUTPUT_NODES = {\"y_\"};\n    String OUTPUT_NODE = \"y_\";\n    //I don't know what is input size\n    long[] INPUT_SIZE = {1, 15};\n    int OUTPUT_SIZE = 2;\n\n    private TensorFlowInferenceInterface inferenceInterface;\n\n\nInitialization and calling function in OnCreate:\n\ninferenceInterface = new TensorFlowInferenceInterface(appContext.getAssets(), MODEL_FILE);\n\n\n float[] data = {(float)1.0, (float)26.0, (float)1000.0, (float)3.0, (float)1.0,(float)0.0, (float) 0.0, (float)0.0, (float)0.0, (float)0.0, (float)85.0, (float)48.0, (float)7.0, (float)4.0, (float)2.0};\n        float[] out = predictProbabilitiesFloat(data);\n\n\nFunction for returning result from TensorFlow:\n\npublic float[] predictProbabilitiesFloat(float[] data) {\n        float[] result = new float[OUTPUT_SIZE];\n        inferenceInterface.feed(INPUT_NODE, data, INPUT_SIZE);\n        inferenceInterface.run(OUTPUT_NODES);\n        inferenceInterface.fetch(OUTPUT_NODE, result);\n\n        //for us it should be 0 or 1\n        return result;\n    }\n\n\nIf somebody knows how to fix this problem, please help me, I have few more days to finish this as one part of my master thesis.\nThank you in advance!``", "body": " have a problem with importing Tensorflow model into Android Studio application. I have built a model, froze the model and optimized that frozen model in Python, and now I'm trying to use it in the Android app, but it constantly returns me that same error that I must feed a value for a placeholder. This is happening in the Android app when I run inferenceInterface.run(OUTPUT_NODES); function.\r\n\r\nI don't know if the error is it in the model itself, but I'm assuming that python would throw me an error and won't build the model, what he did.\r\n\r\nThis is the example of rows of data I'm sending to Tensorflow (in csv file):\r\n\r\n1,26,2091,5,2,0,0,0,0,0,85,105,6,4,0,1\r\n1,26,47,9,4,0,0,0,0,0,85,0,7,4,1,0\r\n\r\n\r\nThis is the creating model in Python:\r\n*************************************************************************************************\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nimport seaborn as sns\r\nfrom math import floor, ceil\r\nfrom pylab import rcParams\r\n\r\n\r\ncolumns = [\"Gender\", \"Age\", \"StepsNum\", \"Still\", \"ContinuousStill\",\r\n           \"Running\", \"Driving\", \"Cycling\", \"Weather\", \"TargetWeight\",\r\n           \"Calories\", \"DayOfTheWeek\", \"PartOfTheDay\",\r\n           \"NotificationType\", \"UserInput\"]\r\n\r\nuserinput = ['0','1']\r\n\r\n\r\nactivites_df = pd.read_csv(\"E:\\\\MASTER\\\\PythonPrograms\\\\useractivityInt.csv\", header = None, names=columns)\r\n\r\n\r\n#encode all strings\r\ndef encode(series): \r\n    #print(pd.get_dummies(series.astype(str)))\r\n    return pd.get_dummies(series.astype(str))\r\n\r\n\r\ntrain_x = pd.DataFrame(activites_df, columns = columns, dtype=float)\r\n# train_x = activites_df\r\ntrain_y = encode(activites_df.UserInput)\r\nprint(train_y)\r\n# train_y = activites_df.iloc[:,-1]\r\n# print(train_y)\r\n# train_y = pd.DataFrame(userinput, dtype=float)\r\n\r\n\r\ntrain_size = 0.9\r\n\r\ntrain_cnt = floor(train_x.shape[0] * train_size)\r\n#iloc[0] - first row, iloc[:0] - first column of data frame, iloc[0:n] - first n rows\r\nx_train = train_x.iloc[0:train_cnt].values\r\ny_train = train_y.iloc[0:train_cnt].values\r\n\r\nx_test = train_x.iloc[train_cnt:].values\r\ny_test = train_y.iloc[train_cnt:].values\r\n\r\n\r\ndef multilayer_perceptron(x, weights, biases, keep_prob):\r\n    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\r\n    layer_1 = tf.nn.relu(layer_1)\r\n    layer_1 = tf.nn.dropout(layer_1, keep_prob)\r\n    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\r\n    return out_layer\r\n\r\n\r\n#shape[0] - Gives the number of rows in matrix.. shape[1] - numbers of columns \r\nn_hidden_1 = 38\r\nn_input = train_x.shape[1]\r\nn_classes = train_y.shape[1]\r\n# n_classes = 2\r\n\r\nweights = {\r\n    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]),tf.float32),\r\n    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes]),tf.float32)\r\n}\r\n\r\nbiases = {\r\n    'b1': tf.Variable(tf.random_normal([n_hidden_1]),tf.float32),\r\n    'out': tf.Variable(tf.random_normal([n_classes]),tf.float32)\r\n}\r\n\r\n#keep_prob: A scalar Tensor with the same type as x. The probability that each element is kept.\r\n# keep_prob = tf.placeholder(\"float\")\r\nkeep_prob = tf.placeholder(tf.float32)\r\n\r\ntraining_epochs = 5000\r\ndisplay_step = 1000\r\nbatch_size = 32\r\n\r\nx = tf.placeholder(tf.float32, [None, n_input], name='input')\r\ny = tf.placeholder(tf.float32, [None, n_classes])\r\n\r\npredictions = multilayer_perceptron(x, weights, biases, keep_prob)\r\n\r\n#_y is name for output node\r\n#If we take an input of [1, 2, 3, 4, 1, 2, 3], the softmax of that is [0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]. \r\n# The output has most of its weight where the '4' was in the original input. \r\n# This is what the function is normally used for: to highlight the largest values and suppress values which are significantly below the maximum value.\r\n\r\npred_softmax = tf.nn.softmax(predictions, name=\"y_\")\r\n\r\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\r\n\r\nLEARNING_RATE = 0.0025\r\n\r\noptimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for epoch in range(training_epochs):\r\n        avg_cost = 0.0\r\n        total_batch = int(len(x_train) / batch_size)\r\n        x_batches = np.array_split(x_train, total_batch)\r\n        y_batches = np.array_split(y_train, total_batch)\r\n        for i in range(total_batch):\r\n            batch_x, batch_y = x_batches[i], y_batches[i]\r\n            _, c = sess.run([optimizer, cost], \r\n                            feed_dict={\r\n                                x: batch_x, \r\n                                y: batch_y, \r\n                                keep_prob: 0.8\r\n                            })\r\n            avg_cost += c / total_batch\r\n        if epoch % display_step == 0:\r\n            print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \\\r\n                \"{:.9f}\".format(avg_cost))\r\n    print(\"Optimization Finished!\")\r\n    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\r\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\r\n    print(\"Accuracy:\", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))\r\n\r\n    saver = tf.train.Saver()\r\n    tf.train.write_graph(sess.graph_def, '.', 'E:\\\\MASTER\\\\PythonPrograms\\\\har.pbtxt')  \r\n    saver.save(sess, save_path = \"E:\\\\MASTER\\\\PythonPrograms\\\\har.ckpt\")\r\n```\r\n\r\n****************************************************************************************************\r\nThe main parts of the code in Android Studio are those:\r\n\r\nDefinition of variables:\r\n************************************************************************************************\r\n```\r\nprivate static final String MODEL_FILE = \"file:///android_asset/optimized_frozen_har.pb\";\r\n\r\n    String INPUT_NODE = \"input\";\r\n    String[] OUTPUT_NODES = {\"y_\"};\r\n    String OUTPUT_NODE = \"y_\";\r\n    //I don't know what is input size\r\n    long[] INPUT_SIZE = {1, 15};\r\n    int OUTPUT_SIZE = 2;\r\n\r\n    private TensorFlowInferenceInterface inferenceInterface;\r\n```\r\n************************************************************************************************\r\nInitialization and calling function in OnCreate:\r\n************************************************************************************************\r\n```\r\ninferenceInterface = new TensorFlowInferenceInterface(appContext.getAssets(), MODEL_FILE);\r\n\r\n\r\n float[] data = {(float)1.0, (float)26.0, (float)1000.0, (float)3.0, (float)1.0,(float)0.0, (float) 0.0, (float)0.0, (float)0.0, (float)0.0, (float)85.0, (float)48.0, (float)7.0, (float)4.0, (float)2.0};\r\n        float[] out = predictProbabilitiesFloat(data);\r\n```\r\n*************************************************************************************************\r\nFunction for returning result from TensorFlow:\r\n*************************************************************************************************\r\n```\r\npublic float[] predictProbabilitiesFloat(float[] data) {\r\n        float[] result = new float[OUTPUT_SIZE];\r\n        inferenceInterface.feed(INPUT_NODE, data, INPUT_SIZE);\r\n        inferenceInterface.run(OUTPUT_NODES);\r\n        inferenceInterface.fetch(OUTPUT_NODE, result);\r\n\r\n        //for us it should be 0 or 1\r\n        return result;\r\n    }\r\n```\r\n************************************************************************************************\r\n\r\nIf somebody knows how to fix this problem, please help me, I have few more days to finish this as one part of my master thesis.\r\n\r\nThank you in advance!``"}