{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/138747312", "pull_request_review_id": 62584895, "id": 138747312, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzODc0NzMxMg==", "diff_hunk": "@@ -2041,48 +2041,38 @@ def accumulate_n(inputs, shape=None, tensor_dtype=None, name=None):\n     ValueError: If `inputs` don't all have same shape and dtype or the shape\n     cannot be inferred.\n   \"\"\"\n+  _INPUTS_ERR_MSG = ValueError(\"inputs must be a list of at least one Tensor\"\n+                               \"with the same dtype and shape\")\n   if context.in_eager_mode():\n     # TODO(apassos) remove this once the lifetime of eager variables gets\n     # addressed.\n     raise ValueError(\"accumulate_n not supported in eager mode\")\n   if not inputs or not isinstance(inputs, (list, tuple)):\n-    raise ValueError(\"inputs must be a list of at least one Tensor with the \"\n-                     \"same dtype and shape\")\n+    raise _INPUTS_ERR_MSG\n   inputs = ops.convert_n_to_tensor_or_indexed_slices(inputs)\n   if not all(isinstance(x, ops.Tensor) for x in inputs):\n-    raise ValueError(\"inputs must be a list of at least one Tensor with the \"\n-                     \"same dtype and shape\")\n+    raise _INPUTS_ERR_MSG\n   if not all(x.dtype == inputs[0].dtype for x in inputs):\n-    raise ValueError(\"inputs must be a list of at least one Tensor with the \"\n-                     \"same dtype and shape\")\n+    raise _INPUTS_ERR_MSG\n   if shape is not None:\n     shape = tensor_shape.as_shape(shape)\n   else:\n     shape = tensor_shape.unknown_shape()\n   for input_tensor in inputs:\n     if isinstance(input_tensor, ops.Tensor):\n       shape = shape.merge_with(input_tensor.get_shape())\n-  if tensor_dtype is None:\n-    tensor_dtype = inputs[0].dtype\n-  if tensor_dtype != inputs[0].dtype:\n+\n+  # tensor_dtype is for safety only; operator's output type computed in C++\n+  if tensor_dtype is not None and tensor_dtype != inputs[0].dtype:\n     raise TypeError(\"tensor_dtype is {}, but input is of type {}\"\n                     .format(tensor_dtype, inputs[0].dtype))\n-  if len(inputs) == 1:\n+\n+  if len(inputs) == 1 and name is None:\n     return inputs[0]\n-  with ops.name_scope(name, \"AccumulateN\", inputs) as name:", "path": "tensorflow/python/ops/math_ops.py", "position": 42, "original_position": 42, "commit_id": "77f9498601c8246170ba06b97e71460379c64b4c", "original_commit_id": "c6b5de65ce8de611e075725e58a3a92c051dabce", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "body": "Can we separate the change which adds the C++ infrastructure from the change which switches the default implementation of accumulate_n?\r\n\r\nFor now, let's add the new op in contrib somewhere.\r\n\r\nTensorflow tries to maintain forward compatibility (new graphs should work on C++ runtimes which are two weeks old) and adding the new op and switching to use it at the same time breaks it.", "created_at": "2017-09-13T21:41:11Z", "updated_at": "2017-09-13T22:09:48Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13022#discussion_r138747312", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13022", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/138747312"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13022#discussion_r138747312"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13022"}}, "body_html": "<p>Can we separate the change which adds the C++ infrastructure from the change which switches the default implementation of accumulate_n?</p>\n<p>For now, let's add the new op in contrib somewhere.</p>\n<p>Tensorflow tries to maintain forward compatibility (new graphs should work on C++ runtimes which are two weeks old) and adding the new op and switching to use it at the same time breaks it.</p>", "body_text": "Can we separate the change which adds the C++ infrastructure from the change which switches the default implementation of accumulate_n?\nFor now, let's add the new op in contrib somewhere.\nTensorflow tries to maintain forward compatibility (new graphs should work on C++ runtimes which are two weeks old) and adding the new op and switching to use it at the same time breaks it."}