{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/345779525", "html_url": "https://github.com/tensorflow/tensorflow/issues/14583#issuecomment-345779525", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14583", "id": 345779525, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTc3OTUyNQ==", "user": {"login": "s4mpl3d", "id": 5825923, "node_id": "MDQ6VXNlcjU4MjU5MjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5825923?v=4", "gravatar_id": "", "url": "https://api.github.com/users/s4mpl3d", "html_url": "https://github.com/s4mpl3d", "followers_url": "https://api.github.com/users/s4mpl3d/followers", "following_url": "https://api.github.com/users/s4mpl3d/following{/other_user}", "gists_url": "https://api.github.com/users/s4mpl3d/gists{/gist_id}", "starred_url": "https://api.github.com/users/s4mpl3d/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/s4mpl3d/subscriptions", "organizations_url": "https://api.github.com/users/s4mpl3d/orgs", "repos_url": "https://api.github.com/users/s4mpl3d/repos", "events_url": "https://api.github.com/users/s4mpl3d/events{/privacy}", "received_events_url": "https://api.github.com/users/s4mpl3d/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-20T18:07:47Z", "updated_at": "2017-11-20T18:07:47Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">+1</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On 20 Nov 2017 5:14 p.m., \"Linus H\u00e4renstam-Nielsen\" &lt; ***@***.***&gt; wrote:\n in case anyone is interested I use the following code to get around the\n dimensionality requirements:\n\n def frame_wise_op(inputs, operation, **kwargs):\n     inputs_flat = tf.reshape(inputs, [-1] + inputs.shape[2:].as_list())\n\n     outputs_flat = operation(inputs_flat, **kwargs)\n\n     output_shape = tf.concat([tf.shape(inputs)[:2], tf.shape(outputs_flat)[1:]], 0)\n     outputs = tf.reshape(outputs_flat, output_shape)\n\n     return outputs\n\n example use:\n\n conv = frame_wise_op(inputs,\n                      operation=tf.layers.conv2d,\n                      filters=32,\n                      kernel_size=[5, 5])\n net = frame_wise_op(net,\n                     operation=tf.layers.max_pooling2d,\n                     pool_size=[2, 2],\n                     strides=2)\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"274125230\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/14583\" href=\"https://github.com/tensorflow/tensorflow/issues/14583#issuecomment-345744167\">#14583 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AFjlg0M2IwADymzIAUktSfzOlHW5TgUaks5s4aV5gaJpZM4QeyoE\">https://github.com/notifications/unsubscribe-auth/AFjlg0M2IwADymzIAUktSfzOlHW5TgUaks5s4aV5gaJpZM4QeyoE</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "+1\n\u2026\nOn 20 Nov 2017 5:14 p.m., \"Linus H\u00e4renstam-Nielsen\" < ***@***.***> wrote:\n in case anyone is interested I use the following code to get around the\n dimensionality requirements:\n\n def frame_wise_op(inputs, operation, **kwargs):\n     inputs_flat = tf.reshape(inputs, [-1] + inputs.shape[2:].as_list())\n\n     outputs_flat = operation(inputs_flat, **kwargs)\n\n     output_shape = tf.concat([tf.shape(inputs)[:2], tf.shape(outputs_flat)[1:]], 0)\n     outputs = tf.reshape(outputs_flat, output_shape)\n\n     return outputs\n\n example use:\n\n conv = frame_wise_op(inputs,\n                      operation=tf.layers.conv2d,\n                      filters=32,\n                      kernel_size=[5, 5])\n net = frame_wise_op(net,\n                     operation=tf.layers.max_pooling2d,\n                     pool_size=[2, 2],\n                     strides=2)\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#14583 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AFjlg0M2IwADymzIAUktSfzOlHW5TgUaks5s4aV5gaJpZM4QeyoE>\n .", "body": "+1\n\nOn 20 Nov 2017 5:14 p.m., \"Linus H\u00e4renstam-Nielsen\" <\nnotifications@github.com> wrote:\n\n> in case anyone is interested I use the following code to get around the\n> dimensionality requirements:\n>\n> def frame_wise_op(inputs, operation, **kwargs):\n>     inputs_flat = tf.reshape(inputs, [-1] + inputs.shape[2:].as_list())\n>\n>     outputs_flat = operation(inputs_flat, **kwargs)\n>\n>     output_shape = tf.concat([tf.shape(inputs)[:2], tf.shape(outputs_flat)[1:]], 0)\n>     outputs = tf.reshape(outputs_flat, output_shape)\n>\n>     return outputs\n>\n> example use:\n>\n> conv = frame_wise_op(inputs,\n>                      operation=tf.layers.conv2d,\n>                      filters=32,\n>                      kernel_size=[5, 5])\n> net = frame_wise_op(net,\n>                     operation=tf.layers.max_pooling2d,\n>                     pool_size=[2, 2],\n>                     strides=2)\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14583#issuecomment-345744167>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFjlg0M2IwADymzIAUktSfzOlHW5TgUaks5s4aV5gaJpZM4QeyoE>\n> .\n>\n"}