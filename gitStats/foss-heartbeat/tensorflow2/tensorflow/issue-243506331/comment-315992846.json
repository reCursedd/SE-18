{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/315992846", "html_url": "https://github.com/tensorflow/tensorflow/issues/11557#issuecomment-315992846", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11557", "id": 315992846, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTk5Mjg0Ng==", "user": {"login": "junja94", "id": 11274278, "node_id": "MDQ6VXNlcjExMjc0Mjc4", "avatar_url": "https://avatars1.githubusercontent.com/u/11274278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/junja94", "html_url": "https://github.com/junja94", "followers_url": "https://api.github.com/users/junja94/followers", "following_url": "https://api.github.com/users/junja94/following{/other_user}", "gists_url": "https://api.github.com/users/junja94/gists{/gist_id}", "starred_url": "https://api.github.com/users/junja94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/junja94/subscriptions", "organizations_url": "https://api.github.com/users/junja94/orgs", "repos_url": "https://api.github.com/users/junja94/repos", "events_url": "https://api.github.com/users/junja94/events{/privacy}", "received_events_url": "https://api.github.com/users/junja94/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-18T08:19:25Z", "updated_at": "2017-07-18T08:19:37Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a>   I tried as you suggested, and it didn't work.<br>\nThe code I used is as below. I tested several times with different inputs.<br>\nI think the problem is that the function ignores initial_state argument in   <strong>xtest = net.layers[idx+1](inputs = xtest, initial_state = initial_)</strong>  I tried putting weird shaped initial states (like [1, 1000000]) and there was no error.<br>\nCould you check this code please?? Please let me know if I'm using it wrong.</p>\n<p>Thanks</p>\n<pre><code>  self.input = tf.placeholder(dtype, shape=[None, None, dimension[0]],\n                                name=fn.input_names[0])  # Batch, timelen, dim\n    testinput = tf.placeholder(dtype, shape=[None, None, dimension[0]],\n                               name='testin')\n    # Network\n    input_layer = layers.InputLayer(input_tensor=self.input, dtype=dtype)\n    input_layertest = layers.InputLayer(input_tensor=testinput, dtype=dtype)\n\n    x = input_layer.output\n    xtest = input_layertest.output\n\n    num_rnn = 0\n\n    batchnum = tf.shape(self.input)[0]\n    for size in dimension[1:]:\n        recurrent_layer = layers.GRU(units=size, return_sequences=True, trainable = True)\n        x = recurrent_layer(inputs=x)\n        num_rnn += 1\n\n    output = x\n    net = models.Model(inputs=self.input, outputs=output)\n\n   # Initial_state \n\n    for idx,size in enumerate(dimension[1:]):\n        initial_ = tf.random_uniform(shape=[batchnum, size*100000])\n        xtest = net.layers[idx+1](inputs = xtest, initial_state = initial_)\n\n    outputtest = xtest\n    testnet = models.Model(inputs=testinput, outputs=outputtest)\n</code></pre>", "body_text": "@fchollet   I tried as you suggested, and it didn't work.\nThe code I used is as below. I tested several times with different inputs.\nI think the problem is that the function ignores initial_state argument in   xtest = net.layers[idx+1](inputs = xtest, initial_state = initial_)  I tried putting weird shaped initial states (like [1, 1000000]) and there was no error.\nCould you check this code please?? Please let me know if I'm using it wrong.\nThanks\n  self.input = tf.placeholder(dtype, shape=[None, None, dimension[0]],\n                                name=fn.input_names[0])  # Batch, timelen, dim\n    testinput = tf.placeholder(dtype, shape=[None, None, dimension[0]],\n                               name='testin')\n    # Network\n    input_layer = layers.InputLayer(input_tensor=self.input, dtype=dtype)\n    input_layertest = layers.InputLayer(input_tensor=testinput, dtype=dtype)\n\n    x = input_layer.output\n    xtest = input_layertest.output\n\n    num_rnn = 0\n\n    batchnum = tf.shape(self.input)[0]\n    for size in dimension[1:]:\n        recurrent_layer = layers.GRU(units=size, return_sequences=True, trainable = True)\n        x = recurrent_layer(inputs=x)\n        num_rnn += 1\n\n    output = x\n    net = models.Model(inputs=self.input, outputs=output)\n\n   # Initial_state \n\n    for idx,size in enumerate(dimension[1:]):\n        initial_ = tf.random_uniform(shape=[batchnum, size*100000])\n        xtest = net.layers[idx+1](inputs = xtest, initial_state = initial_)\n\n    outputtest = xtest\n    testnet = models.Model(inputs=testinput, outputs=outputtest)", "body": " @fchollet   I tried as you suggested, and it didn't work.\r\nThe code I used is as below. I tested several times with different inputs.\r\nI think the problem is that the function ignores initial_state argument in   **xtest = net.layers[idx+1](inputs = xtest, initial_state = initial_)**  I tried putting weird shaped initial states (like [1, 1000000]) and there was no error.\r\nCould you check this code please?? Please let me know if I'm using it wrong.\r\n\r\nThanks\r\n\r\n\r\n      self.input = tf.placeholder(dtype, shape=[None, None, dimension[0]],\r\n                                    name=fn.input_names[0])  # Batch, timelen, dim\r\n        testinput = tf.placeholder(dtype, shape=[None, None, dimension[0]],\r\n                                   name='testin')\r\n        # Network\r\n        input_layer = layers.InputLayer(input_tensor=self.input, dtype=dtype)\r\n        input_layertest = layers.InputLayer(input_tensor=testinput, dtype=dtype)\r\n\r\n        x = input_layer.output\r\n        xtest = input_layertest.output\r\n\r\n        num_rnn = 0\r\n\r\n        batchnum = tf.shape(self.input)[0]\r\n        for size in dimension[1:]:\r\n            recurrent_layer = layers.GRU(units=size, return_sequences=True, trainable = True)\r\n            x = recurrent_layer(inputs=x)\r\n            num_rnn += 1\r\n\r\n        output = x\r\n        net = models.Model(inputs=self.input, outputs=output)\r\n\r\n       # Initial_state \r\n\r\n        for idx,size in enumerate(dimension[1:]):\r\n            initial_ = tf.random_uniform(shape=[batchnum, size*100000])\r\n            xtest = net.layers[idx+1](inputs = xtest, initial_state = initial_)\r\n\r\n        outputtest = xtest\r\n        testnet = models.Model(inputs=testinput, outputs=outputtest)\r\n\r\n"}