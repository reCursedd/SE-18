{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/314251188", "html_url": "https://github.com/tensorflow/tensorflow/issues/11337#issuecomment-314251188", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11337", "id": 314251188, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNDI1MTE4OA==", "user": {"login": "songhuiming", "id": 1667488, "node_id": "MDQ6VXNlcjE2Njc0ODg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1667488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/songhuiming", "html_url": "https://github.com/songhuiming", "followers_url": "https://api.github.com/users/songhuiming/followers", "following_url": "https://api.github.com/users/songhuiming/following{/other_user}", "gists_url": "https://api.github.com/users/songhuiming/gists{/gist_id}", "starred_url": "https://api.github.com/users/songhuiming/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/songhuiming/subscriptions", "organizations_url": "https://api.github.com/users/songhuiming/orgs", "repos_url": "https://api.github.com/users/songhuiming/repos", "events_url": "https://api.github.com/users/songhuiming/events{/privacy}", "received_events_url": "https://api.github.com/users/songhuiming/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-10T21:24:12Z", "updated_at": "2017-07-10T21:26:12Z", "author_association": "NONE", "body_html": "<p>when I run on tensorflow 1.0.1, with the following change, there is no error message of shape unmatch and the code can run successfully.</p>\n<div class=\"highlight highlight-source-python\"><pre>            base_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.GRUCell(<span class=\"pl-v\">num_units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">RNN_HIDDEN_SIZE</span>,)\n            layered_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.MultiRNNCell([base_cell] <span class=\"pl-k\">*</span> <span class=\"pl-c1\">NUM_LAYERS</span>,<span class=\"pl-v\">state_is_tuple</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">WARNING</span>:tensorflow:<span class=\"pl-k\">&lt;</span>tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper <span class=\"pl-c1\">object</span> at <span class=\"pl-c1\"><span class=\"pl-k\">0x</span>7efe0e913dd0</span><span class=\"pl-k\">&gt;</span>: Using a concatenated state <span class=\"pl-k\">is</span> slower <span class=\"pl-k\">and</span> will soon be deprecated.  Use state_is_tuple<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>.\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Placeholder_3:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Placeholder_3:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">0</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:1<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">1</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_1/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:2<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">2</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_2/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:3<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">3</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_3/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:4<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">4</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_4/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:5<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">5</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_5/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:6<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">6</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_6/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:7<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">7</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_7/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:8<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">8</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_8/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:9<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nthis <span class=\"pl-k\">is</span> <span class=\"pl-k\">for</span> <span class=\"pl-c1\">9</span>\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rnn/attention_cell_wrapper_9/concat_2:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3300</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\nTensor(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unpack_l1:10<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2328</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)</pre></div>", "body_text": "when I run on tensorflow 1.0.1, with the following change, there is no error message of shape unmatch and the code can run successfully.\n            base_cell = tf.contrib.rnn.GRUCell(num_units=RNN_HIDDEN_SIZE,)\n            layered_cell = tf.contrib.rnn.MultiRNNCell([base_cell] * NUM_LAYERS,state_is_tuple=False)\nWARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x7efe0e913dd0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\nTensor(\"Placeholder_3:0\", shape=(1, 3300), dtype=float32)\nTensor(\"Placeholder_3:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:0\", shape=(1, 2328), dtype=float32)\nthis is for 0\nTensor(\"rnn/attention_cell_wrapper/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:1\", shape=(1, 2328), dtype=float32)\nthis is for 1\nTensor(\"rnn/attention_cell_wrapper_1/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:2\", shape=(1, 2328), dtype=float32)\nthis is for 2\nTensor(\"rnn/attention_cell_wrapper_2/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:3\", shape=(1, 2328), dtype=float32)\nthis is for 3\nTensor(\"rnn/attention_cell_wrapper_3/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:4\", shape=(1, 2328), dtype=float32)\nthis is for 4\nTensor(\"rnn/attention_cell_wrapper_4/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:5\", shape=(1, 2328), dtype=float32)\nthis is for 5\nTensor(\"rnn/attention_cell_wrapper_5/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:6\", shape=(1, 2328), dtype=float32)\nthis is for 6\nTensor(\"rnn/attention_cell_wrapper_6/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:7\", shape=(1, 2328), dtype=float32)\nthis is for 7\nTensor(\"rnn/attention_cell_wrapper_7/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:8\", shape=(1, 2328), dtype=float32)\nthis is for 8\nTensor(\"rnn/attention_cell_wrapper_8/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:9\", shape=(1, 2328), dtype=float32)\nthis is for 9\nTensor(\"rnn/attention_cell_wrapper_9/concat_2:0\", shape=(1, 3300), dtype=float32)\nTensor(\"unpack_l1:10\", shape=(1, 2328), dtype=float32)", "body": "when I run on tensorflow 1.0.1, with the following change, there is no error message of shape unmatch and the code can run successfully.\r\n\r\n```python\r\n            base_cell = tf.contrib.rnn.GRUCell(num_units=RNN_HIDDEN_SIZE,)\r\n            layered_cell = tf.contrib.rnn.MultiRNNCell([base_cell] * NUM_LAYERS,state_is_tuple=False)\r\n```\r\n\r\n```python\r\nWARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x7efe0e913dd0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\r\nTensor(\"Placeholder_3:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"Placeholder_3:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:0\", shape=(1, 2328), dtype=float32)\r\nthis is for 0\r\nTensor(\"rnn/attention_cell_wrapper/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:1\", shape=(1, 2328), dtype=float32)\r\nthis is for 1\r\nTensor(\"rnn/attention_cell_wrapper_1/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:2\", shape=(1, 2328), dtype=float32)\r\nthis is for 2\r\nTensor(\"rnn/attention_cell_wrapper_2/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:3\", shape=(1, 2328), dtype=float32)\r\nthis is for 3\r\nTensor(\"rnn/attention_cell_wrapper_3/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:4\", shape=(1, 2328), dtype=float32)\r\nthis is for 4\r\nTensor(\"rnn/attention_cell_wrapper_4/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:5\", shape=(1, 2328), dtype=float32)\r\nthis is for 5\r\nTensor(\"rnn/attention_cell_wrapper_5/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:6\", shape=(1, 2328), dtype=float32)\r\nthis is for 6\r\nTensor(\"rnn/attention_cell_wrapper_6/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:7\", shape=(1, 2328), dtype=float32)\r\nthis is for 7\r\nTensor(\"rnn/attention_cell_wrapper_7/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:8\", shape=(1, 2328), dtype=float32)\r\nthis is for 8\r\nTensor(\"rnn/attention_cell_wrapper_8/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:9\", shape=(1, 2328), dtype=float32)\r\nthis is for 9\r\nTensor(\"rnn/attention_cell_wrapper_9/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:10\", shape=(1, 2328), dtype=float32)\r\n```"}