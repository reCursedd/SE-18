{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/252396212", "html_url": "https://github.com/tensorflow/tensorflow/issues/4663#issuecomment-252396212", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4663", "id": 252396212, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MjM5NjIxMg==", "user": {"login": "eamartin", "id": 287200, "node_id": "MDQ6VXNlcjI4NzIwMA==", "avatar_url": "https://avatars2.githubusercontent.com/u/287200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eamartin", "html_url": "https://github.com/eamartin", "followers_url": "https://api.github.com/users/eamartin/followers", "following_url": "https://api.github.com/users/eamartin/following{/other_user}", "gists_url": "https://api.github.com/users/eamartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eamartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eamartin/subscriptions", "organizations_url": "https://api.github.com/users/eamartin/orgs", "repos_url": "https://api.github.com/users/eamartin/repos", "events_url": "https://api.github.com/users/eamartin/events{/privacy}", "received_events_url": "https://api.github.com/users/eamartin/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-08T02:10:11Z", "updated_at": "2016-10-08T02:10:11Z", "author_association": "NONE", "body_html": "<p>It seems that <code>identity</code> never had a fully defined specification.</p>\n<p>The docs read \"Return a tensor with the same shape and contents as the input tensor or value\", which seems to indicate a copy. When used across devices, it does cause a copy. I haven't tested it, but I believe if I located <code>old_val</code> on a GPU, then the output of <code>sess.run([old_val, new_val])</code> would be <code>[0, 1]</code> rather than <code>[1, 1]</code>. Changing the device on which the op is located shouldn't change the semantics of the control dependency, so this seems like a bug. Additionally, if the official way to make a copy on the same device is to add 0, this seems like a bad spec.</p>\n<p>If I may suggest a spec for identity:<br>\n\"Identity returns the value of the tensor at the time of evaluation.\"<br>\nThis could eventually be optimized to not perform a copy unless needed. For instance, if I did <code>old_val = tf.identity(x); foo = 2 * old_val;</code> and had a control dependency for <code>assign</code> on old_val, I could shift the control dependency to be on <code>foo</code> and not have to make an unnecessary copy of <code>old_val</code>.</p>", "body_text": "It seems that identity never had a fully defined specification.\nThe docs read \"Return a tensor with the same shape and contents as the input tensor or value\", which seems to indicate a copy. When used across devices, it does cause a copy. I haven't tested it, but I believe if I located old_val on a GPU, then the output of sess.run([old_val, new_val]) would be [0, 1] rather than [1, 1]. Changing the device on which the op is located shouldn't change the semantics of the control dependency, so this seems like a bug. Additionally, if the official way to make a copy on the same device is to add 0, this seems like a bad spec.\nIf I may suggest a spec for identity:\n\"Identity returns the value of the tensor at the time of evaluation.\"\nThis could eventually be optimized to not perform a copy unless needed. For instance, if I did old_val = tf.identity(x); foo = 2 * old_val; and had a control dependency for assign on old_val, I could shift the control dependency to be on foo and not have to make an unnecessary copy of old_val.", "body": "It seems that `identity` never had a fully defined specification.\n\nThe docs read \"Return a tensor with the same shape and contents as the input tensor or value\", which seems to indicate a copy. When used across devices, it does cause a copy. I haven't tested it, but I believe if I located `old_val` on a GPU, then the output of `sess.run([old_val, new_val])` would be `[0, 1]` rather than `[1, 1]`. Changing the device on which the op is located shouldn't change the semantics of the control dependency, so this seems like a bug. Additionally, if the official way to make a copy on the same device is to add 0, this seems like a bad spec.\n\nIf I may suggest a spec for identity:\n\"Identity returns the value of the tensor at the time of evaluation.\"\nThis could eventually be optimized to not perform a copy unless needed. For instance, if I did `old_val = tf.identity(x); foo = 2 * old_val;` and had a control dependency for `assign` on old_val, I could shift the control dependency to be on `foo` and not have to make an unnecessary copy of `old_val`.\n"}