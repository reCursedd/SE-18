{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/250634747", "html_url": "https://github.com/tensorflow/tensorflow/issues/4663#issuecomment-250634747", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4663", "id": 250634747, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MDYzNDc0Nw==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-30T01:14:05Z", "updated_at": "2016-09-30T01:14:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hm, that's weird, seems like some kind of optimization for tf.identity that<br>\nonly shows up in the final fetch</p>\n<p>If you add the line below, you'll see that identity op gets executed before<br>\nassignment<br>\nold_val = tf.Print(old_val, [old_val])</p>\n<p>This means you can refer to \"x\" in computation,  and this will refer to old<br>\nvalue as long as control_dependency forces this computation to happen<br>\nbefore tf.assign.</p>\n<p>Note that if you do another op, ie, old_val = tf.square, then this behavior<br>\ndoesn't happen</p>\n<p>On Thu, Sep 29, 2016 at 4:54 PM, Eric Martin <a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\nwrote:</p>\n<blockquote>\n<p>I'm running Tensorflow 0.10.</p>\n<p>The following code</p>\n<p>import tensorflow as tf</p>\n<p>x = tf.Variable(0, dtype=tf.int32)</p>\n<p>old_val = tf.identity(x)with tf.control_dependencies([old_val]):<br>\nnew_val = tf.assign(x, x + 1)<br>\nwith tf.Session() as sess:<br>\nsess.run(tf.initialize_all_variables())</p>\n<pre><code>for i in xrange(3):\n    print sess.run([old_val, new_val, x])\n</code></pre>\n<p>outputs</p>\n<p>[1, 1, 1]<br>\n[2, 2, 2]<br>\n[3, 3, 3]</p>\n<p>From reading the docs on control_dependencies and identity as well as<br>\nStackOverflow, I expected output</p>\n<p>[0, 1, ?]<br>\n[1, 2, ?]<br>\n[2, 3, ?]</p>\n<p>where ? indicates that the variable value is unspecified.</p>\n<p>Is this a bug? If this is not a bug, what is the correct way to refer to<br>\nthe value of variable before and after assignment in a single graph?</p>\n<p>\u2014<br>\nYou are receiving this because you are subscribed to this thread.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"180191179\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4663\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4663/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4663\">#4663</a>, or mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/AABaHMmYr83smkIteubJqVOXJ-r1FLi7ks5qvE_DgaJpZM4KKma6\">https://github.com/notifications/unsubscribe-auth/AABaHMmYr83smkIteubJqVOXJ-r1FLi7ks5qvE_DgaJpZM4KKma6</a><br>\n.</p>\n</blockquote>", "body_text": "Hm, that's weird, seems like some kind of optimization for tf.identity that\nonly shows up in the final fetch\nIf you add the line below, you'll see that identity op gets executed before\nassignment\nold_val = tf.Print(old_val, [old_val])\nThis means you can refer to \"x\" in computation,  and this will refer to old\nvalue as long as control_dependency forces this computation to happen\nbefore tf.assign.\nNote that if you do another op, ie, old_val = tf.square, then this behavior\ndoesn't happen\nOn Thu, Sep 29, 2016 at 4:54 PM, Eric Martin notifications@github.com\nwrote:\n\nI'm running Tensorflow 0.10.\nThe following code\nimport tensorflow as tf\nx = tf.Variable(0, dtype=tf.int32)\nold_val = tf.identity(x)with tf.control_dependencies([old_val]):\nnew_val = tf.assign(x, x + 1)\nwith tf.Session() as sess:\nsess.run(tf.initialize_all_variables())\nfor i in xrange(3):\n    print sess.run([old_val, new_val, x])\n\noutputs\n[1, 1, 1]\n[2, 2, 2]\n[3, 3, 3]\nFrom reading the docs on control_dependencies and identity as well as\nStackOverflow, I expected output\n[0, 1, ?]\n[1, 2, ?]\n[2, 3, ?]\nwhere ? indicates that the variable value is unspecified.\nIs this a bug? If this is not a bug, what is the correct way to refer to\nthe value of variable before and after assignment in a single graph?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\n#4663, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABaHMmYr83smkIteubJqVOXJ-r1FLi7ks5qvE_DgaJpZM4KKma6\n.", "body": "Hm, that's weird, seems like some kind of optimization for tf.identity that\nonly shows up in the final fetch\n\nIf you add the line below, you'll see that identity op gets executed before\nassignment\nold_val = tf.Print(old_val, [old_val])\n\nThis means you can refer to \"x\" in computation,  and this will refer to old\nvalue as long as control_dependency forces this computation to happen\nbefore tf.assign.\n\nNote that if you do another op, ie, old_val = tf.square, then this behavior\ndoesn't happen\n\nOn Thu, Sep 29, 2016 at 4:54 PM, Eric Martin notifications@github.com\nwrote:\n\n> I'm running Tensorflow 0.10.\n> \n> The following code\n> \n> import tensorflow as tf\n> \n> x = tf.Variable(0, dtype=tf.int32)\n> \n> old_val = tf.identity(x)with tf.control_dependencies([old_val]):\n>     new_val = tf.assign(x, x + 1)\n> with tf.Session() as sess:\n>     sess.run(tf.initialize_all_variables())\n> \n> ```\n> for i in xrange(3):\n>     print sess.run([old_val, new_val, x])\n> ```\n> \n> outputs\n> \n> [1, 1, 1]\n> [2, 2, 2]\n> [3, 3, 3]\n> \n> From reading the docs on control_dependencies and identity as well as\n> StackOverflow, I expected output\n> \n> [0, 1, ?]\n> [1, 2, ?]\n> [2, 3, ?]\n> \n> where ? indicates that the variable value is unspecified.\n> \n> Is this a bug? If this is not a bug, what is the correct way to refer to\n> the value of variable before and after assignment in a single graph?\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4663, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHMmYr83smkIteubJqVOXJ-r1FLi7ks5qvE_DgaJpZM4KKma6\n> .\n"}