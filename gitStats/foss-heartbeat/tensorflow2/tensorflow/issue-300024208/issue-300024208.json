{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17259", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17259/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17259/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17259/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17259", "id": 300024208, "node_id": "MDU6SXNzdWUzMDAwMjQyMDg=", "number": 17259, "title": "after restore trained model checkpoint, the prefetch capacity become 500 which is 5 during training", "user": {"login": "amxineohp", "id": 7607120, "node_id": "MDQ6VXNlcjc2MDcxMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/7607120?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amxineohp", "html_url": "https://github.com/amxineohp", "followers_url": "https://api.github.com/users/amxineohp/followers", "following_url": "https://api.github.com/users/amxineohp/following{/other_user}", "gists_url": "https://api.github.com/users/amxineohp/gists{/gist_id}", "starred_url": "https://api.github.com/users/amxineohp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amxineohp/subscriptions", "organizations_url": "https://api.github.com/users/amxineohp/orgs", "repos_url": "https://api.github.com/users/amxineohp/repos", "events_url": "https://api.github.com/users/amxineohp/events{/privacy}", "received_events_url": "https://api.github.com/users/amxineohp/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-25T12:58:44Z", "updated_at": "2018-02-27T10:39:25Z", "closed_at": "2018-02-27T10:39:25Z", "author_association": "NONE", "body_html": "<p>when I restore my trained model and do predict it out of memory problem, how can I restore the original capacity? or how can I reset the capacity after restore?<br>\nI am using python-gpu 1.5<br>\nbelow is the operation information:<br>\nwhen training:<br>\nname: \"prefetch_queue\"<br>\nop: \"PaddingFIFOQueueV2\"<br>\ndevice: \"/device:CPU:0\"<br>\nattr {<br>\nkey: \"capacity\"<br>\nvalue {<br>\ni: 5<br>\n}<br>\n}</p>\n<p>after restore:<br>\nname: \"prefetch_queue\"<br>\nop: \"PaddingFIFOQueueV2\"<br>\nattr {<br>\nkey: \"capacity\"<br>\nvalue {<br>\ni: 500<br>\n}<br>\n}</p>", "body_text": "when I restore my trained model and do predict it out of memory problem, how can I restore the original capacity? or how can I reset the capacity after restore?\nI am using python-gpu 1.5\nbelow is the operation information:\nwhen training:\nname: \"prefetch_queue\"\nop: \"PaddingFIFOQueueV2\"\ndevice: \"/device:CPU:0\"\nattr {\nkey: \"capacity\"\nvalue {\ni: 5\n}\n}\nafter restore:\nname: \"prefetch_queue\"\nop: \"PaddingFIFOQueueV2\"\nattr {\nkey: \"capacity\"\nvalue {\ni: 500\n}\n}", "body": "when I restore my trained model and do predict it out of memory problem, how can I restore the original capacity? or how can I reset the capacity after restore?\r\nI am using python-gpu 1.5\r\nbelow is the operation information:\r\nwhen training:\r\nname: \"prefetch_queue\"\r\nop: \"PaddingFIFOQueueV2\"\r\ndevice: \"/device:CPU:0\"\r\nattr {\r\n  key: \"capacity\"\r\n  value {\r\n    i: 5\r\n  }\r\n}\r\n\r\nafter restore:\r\nname: \"prefetch_queue\"\r\nop: \"PaddingFIFOQueueV2\"\r\nattr {\r\n  key: \"capacity\"\r\n  value {\r\n    i: 500\r\n  }\r\n}\r\n"}