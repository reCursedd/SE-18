{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10629", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10629/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10629/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10629/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/10629", "id": 235048955, "node_id": "MDExOlB1bGxSZXF1ZXN0MTI1MDE2NjI2", "number": 10629, "title": "[WIP] Multi-bus support with NUMA-aware allocator", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 390482148, "node_id": "MDU6TGFiZWwzOTA0ODIxNDg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20review", "name": "awaiting review", "color": "fef2c0", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-06-11T07:25:55Z", "updated_at": "2017-08-29T20:14:42Z", "closed_at": "2017-06-29T18:42:07Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10629", "html_url": "https://github.com/tensorflow/tensorflow/pull/10629", "diff_url": "https://github.com/tensorflow/tensorflow/pull/10629.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/10629.patch"}, "body_html": "<p>As the title suggests, this is a WIP to partially address issues brought by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15676913\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/poxvoculi\">@poxvoculi</a> in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"192615112\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5986\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5986/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5986\">#5986</a>.</p>\n<p>In our testbed, we have a multi-bus topology where 4 K40m GPUs are connected by different PCI-e root, as shown with the following command:</p>\n<pre><code>$ nvidia-smi topo -m\n\tGPU0\tGPU1\tGPU2\tGPU3\tmlx4_0\tCPU Affinity\nGPU0\t X \tPHB\tSOC\tSOC\tSOC\t0-5\nGPU1\tPHB\t X \tSOC\tSOC\tSOC\t0-5\nGPU2\tSOC\tSOC\t X \tPHB\tPHB\t6-11\nGPU3\tSOC\tSOC\tPHB\t X \tPHB\t6-11\nmlx4_0\tSOC\tSOC\tPHB\tPHB\t X\n\nLegend:\n\n  X   = Self\n  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)\n  PIX  = Connection traversing a single PCIe switch\n  NV#  = Connection traversing a bonded set of # NVLinks\n</code></pre>\n<p>Current TF always allocates the host memory used to transfer from/to GPU on NUMA node 0, which is sub-optimal for GPUs with other CPU affinity. This could be further validated by adjusting <code>CUDA_VISIBLE_DEVICES</code> and <code>numactl -m &lt;numa_node&gt; -N &lt;numa_node&gt;</code> prepended to TF process.</p>\n<p>The basic idea is simple: use <code>numa_alloc_onnode</code> and other related functions available in <a href=\"https://linux.die.net/man/3/numa\" rel=\"nofollow\">libnuma</a> to allocate memory for CUDA host allocator. There are some pieces of code, e.g. <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_device.cc#L669\">here</a>, <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc#L951\">there</a>, and <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc#L855\">there</a> to identify bus id and numa node for each device, and I plan to reuse those as much as possible.</p>\n<p>I am wondering if anyone in the TF team could give me some advice so I can start to implement it.</p>", "body_text": "As the title suggests, this is a WIP to partially address issues brought by @poxvoculi in #5986.\nIn our testbed, we have a multi-bus topology where 4 K40m GPUs are connected by different PCI-e root, as shown with the following command:\n$ nvidia-smi topo -m\n\tGPU0\tGPU1\tGPU2\tGPU3\tmlx4_0\tCPU Affinity\nGPU0\t X \tPHB\tSOC\tSOC\tSOC\t0-5\nGPU1\tPHB\t X \tSOC\tSOC\tSOC\t0-5\nGPU2\tSOC\tSOC\t X \tPHB\tPHB\t6-11\nGPU3\tSOC\tSOC\tPHB\t X \tPHB\t6-11\nmlx4_0\tSOC\tSOC\tPHB\tPHB\t X\n\nLegend:\n\n  X   = Self\n  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)\n  PIX  = Connection traversing a single PCIe switch\n  NV#  = Connection traversing a bonded set of # NVLinks\n\nCurrent TF always allocates the host memory used to transfer from/to GPU on NUMA node 0, which is sub-optimal for GPUs with other CPU affinity. This could be further validated by adjusting CUDA_VISIBLE_DEVICES and numactl -m <numa_node> -N <numa_node> prepended to TF process.\nThe basic idea is simple: use numa_alloc_onnode and other related functions available in libnuma to allocate memory for CUDA host allocator. There are some pieces of code, e.g. here, there, and there to identify bus id and numa node for each device, and I plan to reuse those as much as possible.\nI am wondering if anyone in the TF team could give me some advice so I can start to implement it.", "body": "As the title suggests, this is a WIP to partially address issues brought by @poxvoculi in #5986. \r\n\r\nIn our testbed, we have a multi-bus topology where 4 K40m GPUs are connected by different PCI-e root, as shown with the following command:\r\n\r\n```\r\n$ nvidia-smi topo -m\r\n\tGPU0\tGPU1\tGPU2\tGPU3\tmlx4_0\tCPU Affinity\r\nGPU0\t X \tPHB\tSOC\tSOC\tSOC\t0-5\r\nGPU1\tPHB\t X \tSOC\tSOC\tSOC\t0-5\r\nGPU2\tSOC\tSOC\t X \tPHB\tPHB\t6-11\r\nGPU3\tSOC\tSOC\tPHB\t X \tPHB\t6-11\r\nmlx4_0\tSOC\tSOC\tPHB\tPHB\t X\r\n\r\nLegend:\r\n\r\n  X   = Self\r\n  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)\r\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\r\n  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)\r\n  PIX  = Connection traversing a single PCIe switch\r\n  NV#  = Connection traversing a bonded set of # NVLinks\r\n```\r\n\r\nCurrent TF always allocates the host memory used to transfer from/to GPU on NUMA node 0, which is sub-optimal for GPUs with other CPU affinity. This could be further validated by adjusting `CUDA_VISIBLE_DEVICES` and `numactl -m <numa_node> -N <numa_node>` prepended to TF process.\r\n\r\nThe basic idea is simple: use ``numa_alloc_onnode`` and other related functions available in [libnuma](https://linux.die.net/man/3/numa) to allocate memory for CUDA host allocator. There are some pieces of code, e.g. [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_device.cc#L669), [there](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc#L951), and [there](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc#L855) to identify bus id and numa node for each device, and I plan to reuse those as much as possible.\r\n\r\nI am wondering if anyone in the TF team could give me some advice so I can start to implement it."}