{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16257", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16257/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16257/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16257/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16257", "id": 290177222, "node_id": "MDU6SXNzdWUyOTAxNzcyMjI=", "number": 16257, "title": "feature request: KL distance for Gaussian Mixture Model", "user": {"login": "GrifisJP", "id": 22408724, "node_id": "MDQ6VXNlcjIyNDA4NzI0", "avatar_url": "https://avatars0.githubusercontent.com/u/22408724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GrifisJP", "html_url": "https://github.com/GrifisJP", "followers_url": "https://api.github.com/users/GrifisJP/followers", "following_url": "https://api.github.com/users/GrifisJP/following{/other_user}", "gists_url": "https://api.github.com/users/GrifisJP/gists{/gist_id}", "starred_url": "https://api.github.com/users/GrifisJP/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GrifisJP/subscriptions", "organizations_url": "https://api.github.com/users/GrifisJP/orgs", "repos_url": "https://api.github.com/users/GrifisJP/repos", "events_url": "https://api.github.com/users/GrifisJP/events{/privacy}", "received_events_url": "https://api.github.com/users/GrifisJP/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jvdillon", "id": 1137078, "node_id": "MDQ6VXNlcjExMzcwNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1137078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jvdillon", "html_url": "https://github.com/jvdillon", "followers_url": "https://api.github.com/users/jvdillon/followers", "following_url": "https://api.github.com/users/jvdillon/following{/other_user}", "gists_url": "https://api.github.com/users/jvdillon/gists{/gist_id}", "starred_url": "https://api.github.com/users/jvdillon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jvdillon/subscriptions", "organizations_url": "https://api.github.com/users/jvdillon/orgs", "repos_url": "https://api.github.com/users/jvdillon/repos", "events_url": "https://api.github.com/users/jvdillon/events{/privacy}", "received_events_url": "https://api.github.com/users/jvdillon/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jvdillon", "id": 1137078, "node_id": "MDQ6VXNlcjExMzcwNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1137078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jvdillon", "html_url": "https://github.com/jvdillon", "followers_url": "https://api.github.com/users/jvdillon/followers", "following_url": "https://api.github.com/users/jvdillon/following{/other_user}", "gists_url": "https://api.github.com/users/jvdillon/gists{/gist_id}", "starred_url": "https://api.github.com/users/jvdillon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jvdillon/subscriptions", "organizations_url": "https://api.github.com/users/jvdillon/orgs", "repos_url": "https://api.github.com/users/jvdillon/repos", "events_url": "https://api.github.com/users/jvdillon/events{/privacy}", "received_events_url": "https://api.github.com/users/jvdillon/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 15, "created_at": "2018-01-20T08:56:08Z", "updated_at": "2018-06-25T23:06:07Z", "closed_at": "2018-06-25T23:06:06Z", "author_association": "NONE", "body_html": "<p>I am hoping that <strong>tf.contrib.distributions</strong> module is expanded so that we can calculate <strong>KL</strong> divergence between <strong>multivariate Gaussian Mixture Models(GMM)</strong> ,with its paramter list such as weight, mean, covariance given as Tensor Array. Because I think there is going to be a more need for that for many applications. Thank you.</p>\n<p>With current version, either  we can calculate KL divergence for a single gauss, or create GMM object, but not KL for GMM.<br>\n<a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/Mixture\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/Mixture</a><br>\n<a href=\"https://www.tensorflow.org/api_docs/python/tf/distributions/kl_divergence\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tf/distributions/kl_divergence</a></p>\n<p>I tried as shown below, but it didn'T work.</p>\n<pre><code>import tensorflow as tf\nprint('tensorflow ',tf.__version__)  # for Python 3\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nds = tf.contrib.distributions\nkl_divergence=tf.contrib.distributions.kl_divergence\n\n# Gaussian Mixure1\nmix = 0.3# weight\nbimix_gauss1 = ds.Mixture(\ncat=ds.Categorical(probs=[mix, 1.-mix]),#weight\ncomponents=[\n   ds.Normal(loc=-1., scale=0.1),\n   ds.Normal(loc=+1., scale=0.5),\n])\n\n# Gaussian Mixture2\nmix = 0.4# weight\nbimix_gauss2 = ds.Mixture(\n    cat=ds.Categorical(probs=[mix, 1.-mix]),#weight\n    components=[\n        ds.Normal(loc=-0.4, scale=0.2),\n        ds.Normal(loc=+1.2, scale=0.6),\n])\n\n# KL between GM1 and GM2\nkl_value=kl_divergence(\n    distribution_a=bimix_gauss1,\n    distribution_b=bimix_gauss2,\n    allow_nan_stats=True,\n    name=None\n)\n sess = tf.Session() # \n with sess.as_default():\n    x = tf.linspace(-2., 3., int(1e4)).eval()\n    plt.plot(x, bimix_gauss1.prob(x).eval(),'r-')\n    plt.plot(x, bimix_gauss2.prob(x).eval(),'b-')\n    plt.show()\n\n    print('kl_value=',kl_value.eval())`\n</code></pre>\n<p>Then I got this error... <strong>NotImplementedError: No KL(distribution_a || distribution_b) registered for distribution_a type Mixture and distribution_b type Mixture</strong></p>\n<p>I know that with python sklearn without Tensorflow, we can calculate KL for GMM as shown below.<br>\n<a href=\"https://stackoverflow.com/questions/48335823/tensorflow-kl-divergence-for-a-gaussian-mixure\" rel=\"nofollow\">https://stackoverflow.com/questions/48335823/tensorflow-kl-divergence-for-a-gaussian-mixure</a></p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.4</li>\n<li><strong>Python version</strong>: 3</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 8</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>", "body_text": "I am hoping that tf.contrib.distributions module is expanded so that we can calculate KL divergence between multivariate Gaussian Mixture Models(GMM) ,with its paramter list such as weight, mean, covariance given as Tensor Array. Because I think there is going to be a more need for that for many applications. Thank you.\nWith current version, either  we can calculate KL divergence for a single gauss, or create GMM object, but not KL for GMM.\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/distributions/Mixture\nhttps://www.tensorflow.org/api_docs/python/tf/distributions/kl_divergence\nI tried as shown below, but it didn'T work.\nimport tensorflow as tf\nprint('tensorflow ',tf.__version__)  # for Python 3\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nds = tf.contrib.distributions\nkl_divergence=tf.contrib.distributions.kl_divergence\n\n# Gaussian Mixure1\nmix = 0.3# weight\nbimix_gauss1 = ds.Mixture(\ncat=ds.Categorical(probs=[mix, 1.-mix]),#weight\ncomponents=[\n   ds.Normal(loc=-1., scale=0.1),\n   ds.Normal(loc=+1., scale=0.5),\n])\n\n# Gaussian Mixture2\nmix = 0.4# weight\nbimix_gauss2 = ds.Mixture(\n    cat=ds.Categorical(probs=[mix, 1.-mix]),#weight\n    components=[\n        ds.Normal(loc=-0.4, scale=0.2),\n        ds.Normal(loc=+1.2, scale=0.6),\n])\n\n# KL between GM1 and GM2\nkl_value=kl_divergence(\n    distribution_a=bimix_gauss1,\n    distribution_b=bimix_gauss2,\n    allow_nan_stats=True,\n    name=None\n)\n sess = tf.Session() # \n with sess.as_default():\n    x = tf.linspace(-2., 3., int(1e4)).eval()\n    plt.plot(x, bimix_gauss1.prob(x).eval(),'r-')\n    plt.plot(x, bimix_gauss2.prob(x).eval(),'b-')\n    plt.show()\n\n    print('kl_value=',kl_value.eval())`\n\nThen I got this error... NotImplementedError: No KL(distribution_a || distribution_b) registered for distribution_a type Mixture and distribution_b type Mixture\nI know that with python sklearn without Tensorflow, we can calculate KL for GMM as shown below.\nhttps://stackoverflow.com/questions/48335823/tensorflow-kl-divergence-for-a-gaussian-mixure\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below):1.4\nPython version: 3\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 8\nGPU model and memory:\nExact command to reproduce:", "body": "I am hoping that **tf.contrib.distributions** module is expanded so that we can calculate **KL** divergence between **multivariate Gaussian Mixture Models(GMM)** ,with its paramter list such as weight, mean, covariance given as Tensor Array. Because I think there is going to be a more need for that for many applications. Thank you.\r\n\r\nWith current version, either  we can calculate KL divergence for a single gauss, or create GMM object, but not KL for GMM.\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/distributions/Mixture\r\nhttps://www.tensorflow.org/api_docs/python/tf/distributions/kl_divergence\r\n\r\nI tried as shown below, but it didn'T work.\r\n\r\n    import tensorflow as tf\r\n    print('tensorflow ',tf.__version__)  # for Python 3\r\n    import numpy as np\r\n    import matplotlib.pyplot as plt\r\n\r\n    ds = tf.contrib.distributions\r\n    kl_divergence=tf.contrib.distributions.kl_divergence\r\n\r\n    # Gaussian Mixure1\r\n    mix = 0.3# weight\r\n    bimix_gauss1 = ds.Mixture(\r\n    cat=ds.Categorical(probs=[mix, 1.-mix]),#weight\r\n    components=[\r\n       ds.Normal(loc=-1., scale=0.1),\r\n       ds.Normal(loc=+1., scale=0.5),\r\n    ])\r\n\r\n    # Gaussian Mixture2\r\n    mix = 0.4# weight\r\n    bimix_gauss2 = ds.Mixture(\r\n        cat=ds.Categorical(probs=[mix, 1.-mix]),#weight\r\n        components=[\r\n            ds.Normal(loc=-0.4, scale=0.2),\r\n            ds.Normal(loc=+1.2, scale=0.6),\r\n    ])\r\n\r\n    # KL between GM1 and GM2\r\n    kl_value=kl_divergence(\r\n        distribution_a=bimix_gauss1,\r\n        distribution_b=bimix_gauss2,\r\n        allow_nan_stats=True,\r\n        name=None\r\n    )\r\n     sess = tf.Session() # \r\n     with sess.as_default():\r\n        x = tf.linspace(-2., 3., int(1e4)).eval()\r\n        plt.plot(x, bimix_gauss1.prob(x).eval(),'r-')\r\n        plt.plot(x, bimix_gauss2.prob(x).eval(),'b-')\r\n        plt.show()\r\n\r\n        print('kl_value=',kl_value.eval())`\r\n\r\nThen I got this error... **NotImplementedError: No KL(distribution_a || distribution_b) registered for distribution_a type Mixture and distribution_b type Mixture**\r\n\r\nI know that with python sklearn without Tensorflow, we can calculate KL for GMM as shown below.\r\nhttps://stackoverflow.com/questions/48335823/tensorflow-kl-divergence-for-a-gaussian-mixure\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:1.4\r\n- **Python version**: 3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 8\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:"}