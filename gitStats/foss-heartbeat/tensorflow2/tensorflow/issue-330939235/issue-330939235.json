{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19885", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19885/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19885/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19885/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19885", "id": 330939235, "node_id": "MDU6SXNzdWUzMzA5MzkyMzU=", "number": 19885, "title": "Tf summary merge all may cause issues", "user": {"login": "harveyslash", "id": 7107410, "node_id": "MDQ6VXNlcjcxMDc0MTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/7107410?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harveyslash", "html_url": "https://github.com/harveyslash", "followers_url": "https://api.github.com/users/harveyslash/followers", "following_url": "https://api.github.com/users/harveyslash/following{/other_user}", "gists_url": "https://api.github.com/users/harveyslash/gists{/gist_id}", "starred_url": "https://api.github.com/users/harveyslash/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harveyslash/subscriptions", "organizations_url": "https://api.github.com/users/harveyslash/orgs", "repos_url": "https://api.github.com/users/harveyslash/repos", "events_url": "https://api.github.com/users/harveyslash/events{/privacy}", "received_events_url": "https://api.github.com/users/harveyslash/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-06-10T04:23:56Z", "updated_at": "2018-09-17T01:21:21Z", "closed_at": "2018-09-17T01:21:21Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: N/A</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: N/A</li>\n<li><strong>TensorFlow version (use command below)</strong>: N/A</li>\n<li><strong>Python version</strong>: N/A</li>\n<li><strong>Bazel version (if compiling from source)</strong>:N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:N/A</li>\n<li><strong>CUDA/cuDNN version</strong>:N/A</li>\n<li><strong>GPU model and memory</strong>:N/A</li>\n<li><strong>Exact command to reproduce</strong>:N/A</li>\n</ul>\n<p>There are cases in which separate summaries would be good to have, e.g. for a graph that has more than one networks that are somewhat independent.</p>\n<p>In this case, having individual summaries so that they can be individually used is helpful. Most times , scalars + data (images or text) are needed to be logged, so calling <code>tf.summary.merge</code> and having to maintain a handle on all the summary requires a lot of code.</p>\n<p>calling <code>tf.summary.merge_all()</code> requires the data to be present for ALL possible summaries, which may introduce bugs and cause unnecessary computation.</p>\n<p>My proposal is to use a context manager and add the summaries to that context, which can be merged automatically.</p>\n<p>Somewhat along the lines of :</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> tf.merged_summaries() <span class=\"pl-k\">as</span> merged: \n    merged.add_summary(tf.summary.scalar(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>dropout_keep_probability<span class=\"pl-pds\">'</span></span>, keep_prob)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> add scalar</span>\n    merged.add_summary(tf.summary.Image(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>dropout_keep_probability<span class=\"pl-pds\">'</span></span>, some_image)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> add image</span></pre></div>\n<p>then after this block is done , <code>merged</code> can be used somewhat like this :</p>\n<div class=\"highlight highlight-source-python\"><pre>training_only_summary_op <span class=\"pl-k\">=</span> merged.get_op()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> will call `tf.summary.merge()` internally </span></pre></div>\n<p>I can make a pull request for this if this idea is worth exploring</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\nTensorFlow installed from (source or binary): N/A\nTensorFlow version (use command below): N/A\nPython version: N/A\nBazel version (if compiling from source):N/A\nGCC/Compiler version (if compiling from source):N/A\nCUDA/cuDNN version:N/A\nGPU model and memory:N/A\nExact command to reproduce:N/A\n\nThere are cases in which separate summaries would be good to have, e.g. for a graph that has more than one networks that are somewhat independent.\nIn this case, having individual summaries so that they can be individually used is helpful. Most times , scalars + data (images or text) are needed to be logged, so calling tf.summary.merge and having to maintain a handle on all the summary requires a lot of code.\ncalling tf.summary.merge_all() requires the data to be present for ALL possible summaries, which may introduce bugs and cause unnecessary computation.\nMy proposal is to use a context manager and add the summaries to that context, which can be merged automatically.\nSomewhat along the lines of :\nwith tf.merged_summaries() as merged: \n    merged.add_summary(tf.summary.scalar('dropout_keep_probability', keep_prob)) # add scalar\n    merged.add_summary(tf.summary.Image('dropout_keep_probability', some_image)) # add image\nthen after this block is done , merged can be used somewhat like this :\ntraining_only_summary_op = merged.get_op()  # will call `tf.summary.merge()` internally \nI can make a pull request for this if this idea is worth exploring", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**:N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**:N/A\r\n- **Exact command to reproduce**:N/A\r\n\r\n\r\n\r\nThere are cases in which separate summaries would be good to have, e.g. for a graph that has more than one networks that are somewhat independent. \r\n\r\nIn this case, having individual summaries so that they can be individually used is helpful. Most times , scalars + data (images or text) are needed to be logged, so calling `tf.summary.merge` and having to maintain a handle on all the summary requires a lot of code. \r\n\r\ncalling `tf.summary.merge_all()` requires the data to be present for ALL possible summaries, which may introduce bugs and cause unnecessary computation. \r\n\r\nMy proposal is to use a context manager and add the summaries to that context, which can be merged automatically. \r\n\r\nSomewhat along the lines of : \r\n\r\n```python\r\nwith tf.merged_summaries() as merged: \r\n    merged.add_summary(tf.summary.scalar('dropout_keep_probability', keep_prob)) # add scalar\r\n    merged.add_summary(tf.summary.Image('dropout_keep_probability', some_image)) # add image\r\n```\r\nthen after this block is done , `merged` can be used somewhat like this : \r\n\r\n```python\r\ntraining_only_summary_op = merged.get_op()  # will call `tf.summary.merge()` internally \r\n```\r\n\r\nI can make a pull request for this if this idea is worth exploring \r\n"}