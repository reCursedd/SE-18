{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14198", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14198/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14198/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14198/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14198", "id": 270863208, "node_id": "MDU6SXNzdWUyNzA4NjMyMDg=", "number": 14198, "title": "Tensorflow 1.4 Keras issue with respect to model_fn", "user": {"login": "KishoreKarunakaran", "id": 10724627, "node_id": "MDQ6VXNlcjEwNzI0NjI3", "avatar_url": "https://avatars3.githubusercontent.com/u/10724627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KishoreKarunakaran", "html_url": "https://github.com/KishoreKarunakaran", "followers_url": "https://api.github.com/users/KishoreKarunakaran/followers", "following_url": "https://api.github.com/users/KishoreKarunakaran/following{/other_user}", "gists_url": "https://api.github.com/users/KishoreKarunakaran/gists{/gist_id}", "starred_url": "https://api.github.com/users/KishoreKarunakaran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KishoreKarunakaran/subscriptions", "organizations_url": "https://api.github.com/users/KishoreKarunakaran/orgs", "repos_url": "https://api.github.com/users/KishoreKarunakaran/repos", "events_url": "https://api.github.com/users/KishoreKarunakaran/events{/privacy}", "received_events_url": "https://api.github.com/users/KishoreKarunakaran/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-11-03T02:26:47Z", "updated_at": "2017-12-16T09:16:13Z", "closed_at": "2017-11-06T17:26:17Z", "author_association": "NONE", "body_html": "<p>I have a model function which accepts Features, targets and mode but when I add tf.keras layers I'm currently getting Exception <strong><code>pred</code> must be a Tensor, a Variable, or a Python bool.</strong></p>\n<p>But, When I run the same code with out using tf.keras but directly from keras(i.e. <strong>from keras.layers</strong>), It's working.</p>\n<p><strong>Code :</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>):\n\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>:\n        tf.keras.backend.set_learning_phase(<span class=\"pl-c1\">1</span>)\n    <span class=\"pl-k\">else</span>:\n        tf.keras.backend.set_learning_phase(<span class=\"pl-c1\">0</span>)\n\n    input_feature <span class=\"pl-k\">=</span> features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>]\n    table <span class=\"pl-k\">=</span> lookup.index_table_from_file(<span class=\"pl-v\">vocabulary_file</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>vocab.txt<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">num_oov_buckets</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">default_value</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n    text <span class=\"pl-k\">=</span> tf.squeeze(input_feature, [<span class=\"pl-c1\">1</span>])\n    words <span class=\"pl-k\">=</span> tf.string_split(text)\n    densewords <span class=\"pl-k\">=</span> tf.sparse_tensor_to_dense(words, <span class=\"pl-v\">default_value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">PADWORD</span>)\n    numbers <span class=\"pl-k\">=</span> table.lookup(densewords)\n    padding <span class=\"pl-k\">=</span> tf.constant([[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>], [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">MAX_FEATURES</span>]])\n    padded <span class=\"pl-k\">=</span> tf.pad(numbers, padding)\n    sliced <span class=\"pl-k\">=</span> tf.slice(padded, [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>], [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">MAX_FEATURES</span>])\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>words_sliced=<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(words))\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>embeds = tf.keras.layers.Embedding(MAX_FEATURES, 50, input_length=MAX_FEATURES)(sliced)</span>\n    embeds <span class=\"pl-k\">=</span> tf.contrib.layers.embed_sequence(sliced, <span class=\"pl-v\">vocab_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">MAX_FEATURES</span>, <span class=\"pl-v\">embed_dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">50</span>)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>words_embed=<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(embeds))\n\n    f1 <span class=\"pl-k\">=</span> tf.keras.layers.Dropout(<span class=\"pl-c1\">0.2</span>)(embeds)\n    f1 <span class=\"pl-k\">=</span> tf.keras.layers.Conv1D(filters, kernel_size, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>valid<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)(f1)\n    f1 <span class=\"pl-k\">=</span> tf.keras.layers.GlobalAveragePooling1D()(f1)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> f1 = layers.BatchNormalization()(f1)</span>\n    f1 <span class=\"pl-k\">=</span> tf.keras.layers.Dense(hidden_dims)(f1)\n    f1 <span class=\"pl-k\">=</span> tf.keras.layers.Dropout(<span class=\"pl-c1\">0.5</span>)(f1)\n    f1 <span class=\"pl-k\">=</span> tf.keras.layers.Activation(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(f1)\n    logits <span class=\"pl-k\">=</span> tf.keras.layers.Dense(<span class=\"pl-c1\">11</span>)(f1)\n\n    predictions_dict <span class=\"pl-k\">=</span> {\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>class<span class=\"pl-pds\">'</span></span>: tf.argmax(logits, <span class=\"pl-c1\">1</span>),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>prob<span class=\"pl-pds\">'</span></span>: tf.nn.softmax(logits)\n    }\n\n    prediction_output <span class=\"pl-k\">=</span> tf.estimator.export.PredictOutput({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>classes<span class=\"pl-pds\">\"</span></span>: tf.argmax(<span class=\"pl-v\">input</span><span class=\"pl-k\">=</span>logits, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>),\n                                                           <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>probabilities<span class=\"pl-pds\">\"</span></span>: tf.nn.softmax(logits,\n                                                                                          <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>softmax_tensor<span class=\"pl-pds\">\"</span></span>)})\n\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">PREDICT</span>:\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">predictions</span><span class=\"pl-k\">=</span>predictions_dict, <span class=\"pl-v\">export_outputs</span><span class=\"pl-k\">=</span>{\n            tf.saved_model.signature_constants.<span class=\"pl-c1\">DEFAULT_SERVING_SIGNATURE_DEF_KEY</span>: prediction_output\n        })\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> one_hot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=11)</span>\n    loss <span class=\"pl-k\">=</span> tf.losses.sparse_softmax_cross_entropy(labels, <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>logits)\n\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.contrib.learn.ModeKeys.<span class=\"pl-c1\">TRAIN</span>:\n        train_op <span class=\"pl-k\">=</span> tf.contrib.layers.optimize_loss(loss, tf.contrib.framework.get_global_step(), <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Adam<span class=\"pl-pds\">'</span></span>,\n                                                   <span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.001</span>)\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>train_op)\n\n    eval_metrics_ops <span class=\"pl-k\">=</span> {\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>: tf.metrics.accuracy(<span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>labels, <span class=\"pl-v\">predictions</span><span class=\"pl-k\">=</span>predictions_dict[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>class<span class=\"pl-pds\">'</span></span>])\n    }\n    <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">eval_metric_ops</span><span class=\"pl-k\">=</span>eval_metrics_ops)</pre></div>\n<p><strong>Exception:</strong></p>\n<p>File \"D:/PyCharm-Workspace/Keras-Exp/finance-complaints/tensorflow/tf_finance_complaints.py\", line 149, in <br>\nfinance_classifier.train(input_fn=lambda: input_fn('dataset/train.csv', batch_size=32, repeat_count=5, shuffle=True))<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 302, in train<br>\nloss = self._train_model(input_fn, hooks, saving_listeners)<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 711, in _train_model<br>\nfeatures, labels, model_fn_lib.ModeKeys.TRAIN, self.config)<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 694, in _call_model_fn<br>\nmodel_fn_results = self._model_fn(features=features, **kwargs)<br>\nFile \"D:/PyCharm-Workspace/Keras-Exp/finance-complaints/tensorflow/tf_finance_complaints.py\", line 108, in model_fn<br>\nf1 = tf.keras.layers.Dropout(0.2)(embeds)<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras_impl\\keras\\engine\\topology.py\", line 252, in <strong>call</strong><br>\noutput = super(Layer, self).<strong>call</strong>(inputs, **kwargs)<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 575, in <strong>call</strong><br>\noutputs = self.call(inputs, *args, **kwargs)<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras_impl\\keras\\layers\\core.py\", line 118, in call<br>\noutput = super(Dropout, self).call(inputs, training=training)<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 300, in call<br>\nlambda: array_ops.identity(inputs))<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\", line 203, in smart_cond<br>\npred_value = constant_value(pred)<br>\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\", line 233, in constant_value<br>\nraise TypeError('<code>pred</code> must be a Tensor, a Variable, or a Python bool.')<br>\nTypeError: <code>pred</code> must be a Tensor, a Variable, or a Python bool.</p>", "body_text": "I have a model function which accepts Features, targets and mode but when I add tf.keras layers I'm currently getting Exception pred must be a Tensor, a Variable, or a Python bool.\nBut, When I run the same code with out using tf.keras but directly from keras(i.e. from keras.layers), It's working.\nCode :\ndef model_fn(features, labels, mode):\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        tf.keras.backend.set_learning_phase(1)\n    else:\n        tf.keras.backend.set_learning_phase(0)\n\n    input_feature = features['x']\n    table = lookup.index_table_from_file(vocabulary_file='vocab.txt', num_oov_buckets=1, default_value=-1)\n    text = tf.squeeze(input_feature, [1])\n    words = tf.string_split(text)\n    densewords = tf.sparse_tensor_to_dense(words, default_value=PADWORD)\n    numbers = table.lookup(densewords)\n    padding = tf.constant([[0, 0], [0, MAX_FEATURES]])\n    padded = tf.pad(numbers, padding)\n    sliced = tf.slice(padded, [0, 0], [-1, MAX_FEATURES])\n    print('words_sliced={}'.format(words))\n\n    #embeds = tf.keras.layers.Embedding(MAX_FEATURES, 50, input_length=MAX_FEATURES)(sliced)\n    embeds = tf.contrib.layers.embed_sequence(sliced, vocab_size=MAX_FEATURES, embed_dim=50)\n    print('words_embed={}'.format(embeds))\n\n    f1 = tf.keras.layers.Dropout(0.2)(embeds)\n    f1 = tf.keras.layers.Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1)(f1)\n    f1 = tf.keras.layers.GlobalAveragePooling1D()(f1)\n    # f1 = layers.BatchNormalization()(f1)\n    f1 = tf.keras.layers.Dense(hidden_dims)(f1)\n    f1 = tf.keras.layers.Dropout(0.5)(f1)\n    f1 = tf.keras.layers.Activation('relu')(f1)\n    logits = tf.keras.layers.Dense(11)(f1)\n\n    predictions_dict = {\n        'class': tf.argmax(logits, 1),\n        'prob': tf.nn.softmax(logits)\n    }\n\n    prediction_output = tf.estimator.export.PredictOutput({\"classes\": tf.argmax(input=logits, axis=1),\n                                                           \"probabilities\": tf.nn.softmax(logits,\n                                                                                          name=\"softmax_tensor\")})\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions_dict, export_outputs={\n            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_output\n        })\n\n    # one_hot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=11)\n    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits=logits)\n\n    if mode == tf.contrib.learn.ModeKeys.TRAIN:\n        train_op = tf.contrib.layers.optimize_loss(loss, tf.contrib.framework.get_global_step(), optimizer='Adam',\n                                                   learning_rate=0.001)\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    eval_metrics_ops = {\n        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions_dict['class'])\n    }\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics_ops)\nException:\nFile \"D:/PyCharm-Workspace/Keras-Exp/finance-complaints/tensorflow/tf_finance_complaints.py\", line 149, in \nfinance_classifier.train(input_fn=lambda: input_fn('dataset/train.csv', batch_size=32, repeat_count=5, shuffle=True))\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 302, in train\nloss = self._train_model(input_fn, hooks, saving_listeners)\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 711, in _train_model\nfeatures, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 694, in _call_model_fn\nmodel_fn_results = self._model_fn(features=features, **kwargs)\nFile \"D:/PyCharm-Workspace/Keras-Exp/finance-complaints/tensorflow/tf_finance_complaints.py\", line 108, in model_fn\nf1 = tf.keras.layers.Dropout(0.2)(embeds)\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras_impl\\keras\\engine\\topology.py\", line 252, in call\noutput = super(Layer, self).call(inputs, **kwargs)\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 575, in call\noutputs = self.call(inputs, *args, **kwargs)\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras_impl\\keras\\layers\\core.py\", line 118, in call\noutput = super(Dropout, self).call(inputs, training=training)\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 300, in call\nlambda: array_ops.identity(inputs))\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\", line 203, in smart_cond\npred_value = constant_value(pred)\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\", line 233, in constant_value\nraise TypeError('pred must be a Tensor, a Variable, or a Python bool.')\nTypeError: pred must be a Tensor, a Variable, or a Python bool.", "body": "I have a model function which accepts Features, targets and mode but when I add tf.keras layers I'm currently getting Exception **`pred` must be a Tensor, a Variable, or a Python bool.**\r\n\r\nBut, When I run the same code with out using tf.keras but directly from keras(i.e. **from keras.layers**), It's working.\r\n\r\n**Code :**\r\n\r\n```python\r\ndef model_fn(features, labels, mode):\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        tf.keras.backend.set_learning_phase(1)\r\n    else:\r\n        tf.keras.backend.set_learning_phase(0)\r\n\r\n    input_feature = features['x']\r\n    table = lookup.index_table_from_file(vocabulary_file='vocab.txt', num_oov_buckets=1, default_value=-1)\r\n    text = tf.squeeze(input_feature, [1])\r\n    words = tf.string_split(text)\r\n    densewords = tf.sparse_tensor_to_dense(words, default_value=PADWORD)\r\n    numbers = table.lookup(densewords)\r\n    padding = tf.constant([[0, 0], [0, MAX_FEATURES]])\r\n    padded = tf.pad(numbers, padding)\r\n    sliced = tf.slice(padded, [0, 0], [-1, MAX_FEATURES])\r\n    print('words_sliced={}'.format(words))\r\n\r\n    #embeds = tf.keras.layers.Embedding(MAX_FEATURES, 50, input_length=MAX_FEATURES)(sliced)\r\n    embeds = tf.contrib.layers.embed_sequence(sliced, vocab_size=MAX_FEATURES, embed_dim=50)\r\n    print('words_embed={}'.format(embeds))\r\n\r\n    f1 = tf.keras.layers.Dropout(0.2)(embeds)\r\n    f1 = tf.keras.layers.Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1)(f1)\r\n    f1 = tf.keras.layers.GlobalAveragePooling1D()(f1)\r\n    # f1 = layers.BatchNormalization()(f1)\r\n    f1 = tf.keras.layers.Dense(hidden_dims)(f1)\r\n    f1 = tf.keras.layers.Dropout(0.5)(f1)\r\n    f1 = tf.keras.layers.Activation('relu')(f1)\r\n    logits = tf.keras.layers.Dense(11)(f1)\r\n\r\n    predictions_dict = {\r\n        'class': tf.argmax(logits, 1),\r\n        'prob': tf.nn.softmax(logits)\r\n    }\r\n\r\n    prediction_output = tf.estimator.export.PredictOutput({\"classes\": tf.argmax(input=logits, axis=1),\r\n                                                           \"probabilities\": tf.nn.softmax(logits,\r\n                                                                                          name=\"softmax_tensor\")})\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions_dict, export_outputs={\r\n            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_output\r\n        })\r\n\r\n    # one_hot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=11)\r\n    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits=logits)\r\n\r\n    if mode == tf.contrib.learn.ModeKeys.TRAIN:\r\n        train_op = tf.contrib.layers.optimize_loss(loss, tf.contrib.framework.get_global_step(), optimizer='Adam',\r\n                                                   learning_rate=0.001)\r\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\n    eval_metrics_ops = {\r\n        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions_dict['class'])\r\n    }\r\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics_ops)\r\n```\r\n\r\n**Exception:**\r\n\r\n  File \"D:/PyCharm-Workspace/Keras-Exp/finance-complaints/tensorflow/tf_finance_complaints.py\", line 149, in <module>\r\n    finance_classifier.train(input_fn=lambda: input_fn('dataset/train.csv', batch_size=32, repeat_count=5, shuffle=True))\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 302, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 711, in _train_model\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 694, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"D:/PyCharm-Workspace/Keras-Exp/finance-complaints/tensorflow/tf_finance_complaints.py\", line 108, in model_fn\r\n    f1 = tf.keras.layers.Dropout(0.2)(embeds)\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\topology.py\", line 252, in __call__\r\n    output = super(Layer, self).__call__(inputs, **kwargs)\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 575, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\layers\\core.py\", line 118, in call\r\n    output = super(Dropout, self).call(inputs, training=training)\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 300, in call\r\n    lambda: array_ops.identity(inputs))\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\", line 203, in smart_cond\r\n    pred_value = constant_value(pred)\r\n  File \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\", line 233, in constant_value\r\n    raise TypeError('`pred` must be a Tensor, a Variable, or a Python bool.')\r\nTypeError: `pred` must be a Tensor, a Variable, or a Python bool."}