{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/362013281", "html_url": "https://github.com/tensorflow/tensorflow/issues/16627#issuecomment-362013281", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16627", "id": 362013281, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjAxMzI4MQ==", "user": {"login": "nxphi47", "id": 19323568, "node_id": "MDQ6VXNlcjE5MzIzNTY4", "avatar_url": "https://avatars3.githubusercontent.com/u/19323568?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nxphi47", "html_url": "https://github.com/nxphi47", "followers_url": "https://api.github.com/users/nxphi47/followers", "following_url": "https://api.github.com/users/nxphi47/following{/other_user}", "gists_url": "https://api.github.com/users/nxphi47/gists{/gist_id}", "starred_url": "https://api.github.com/users/nxphi47/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nxphi47/subscriptions", "organizations_url": "https://api.github.com/users/nxphi47/orgs", "repos_url": "https://api.github.com/users/nxphi47/repos", "events_url": "https://api.github.com/users/nxphi47/events{/privacy}", "received_events_url": "https://api.github.com/users/nxphi47/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-31T17:47:01Z", "updated_at": "2018-01-31T17:50:59Z", "author_association": "NONE", "body_html": "<p>Can you give the logs of the errors?</p>\n<p>I believe layers.batch_norm only accept is_training of type python bool, it does not accept tf.placeholder. So if you really want to do <code>is_training_var</code>, you may do so,<br>\n`<br>\ntrain_bn = layers.batch_norm(is_training=True) # put them same name, same scope</p>\n<p>inference_bn = layers.batch_norm(is_training=False, reuse=True)</p>\n<p>bn = tf.cond(is_training_var, lambda: train_bn, lambda: inference_bn)<br>\n`</p>", "body_text": "Can you give the logs of the errors?\nI believe layers.batch_norm only accept is_training of type python bool, it does not accept tf.placeholder. So if you really want to do is_training_var, you may do so,\n`\ntrain_bn = layers.batch_norm(is_training=True) # put them same name, same scope\ninference_bn = layers.batch_norm(is_training=False, reuse=True)\nbn = tf.cond(is_training_var, lambda: train_bn, lambda: inference_bn)\n`", "body": "Can you give the logs of the errors?\r\n\r\nI believe layers.batch_norm only accept is_training of type python bool, it does not accept tf.placeholder. So if you really want to do `is_training_var`, you may do so,\r\n`\r\ntrain_bn = layers.batch_norm(is_training=True) # put them same name, same scope  \r\n\r\ninference_bn = layers.batch_norm(is_training=False, reuse=True)  \r\n\r\nbn = tf.cond(is_training_var, lambda: train_bn, lambda: inference_bn)\r\n`"}