{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16627", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16627/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16627/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16627/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16627", "id": 293244835, "node_id": "MDU6SXNzdWUyOTMyNDQ4MzU=", "number": 16627, "title": "TF consumes all available RAM with a particular combination of conv2d, batch_norm and LSTM", "user": {"login": "noammor", "id": 4738203, "node_id": "MDQ6VXNlcjQ3MzgyMDM=", "avatar_url": "https://avatars1.githubusercontent.com/u/4738203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noammor", "html_url": "https://github.com/noammor", "followers_url": "https://api.github.com/users/noammor/followers", "following_url": "https://api.github.com/users/noammor/following{/other_user}", "gists_url": "https://api.github.com/users/noammor/gists{/gist_id}", "starred_url": "https://api.github.com/users/noammor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noammor/subscriptions", "organizations_url": "https://api.github.com/users/noammor/orgs", "repos_url": "https://api.github.com/users/noammor/repos", "events_url": "https://api.github.com/users/noammor/events{/privacy}", "received_events_url": "https://api.github.com/users/noammor/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2018-01-31T17:26:23Z", "updated_at": "2018-02-09T17:40:54Z", "closed_at": "2018-02-09T17:40:53Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.5.0-0-g37aa430d84 1.5.0</li>\n<li><strong>Python version</strong>: 3.6.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0.176 / 7.0.5</li>\n<li><strong>GPU model and memory</strong>: Tesla V100 (AWS P3), 16GB</li>\n<li><strong>Exact command to reproduce</strong>: python debug_tf.py</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When the following code is run on a p3.2xlarge, the python process starts consuming RAM indefinitely, until the entire server RAM is used and the server dies. That's system RAM, not GPU memory.</p>\n<p>It doesn't look it, but the code below is the smallest I could find that produces the bad behavior.</p>\n<ol>\n<li>Replacing residual_conv with a simple convolution makes the code work (i.e not hang).</li>\n<li>Reducing the repetition number in <code>layers.repeat</code> (to e.g 2) makes the code work.</li>\n<li>Removing the batch normalization from residual_conv makes the code work.</li>\n<li>Removing the LSTM makes the code work.</li>\n<li>The weirdest of all, if I set <code>is_training=True</code> in batch_norm instead of <code>is_training=is_training_var</code> whose value is set to <code>True</code> in the feed_dict, then the code works.</li>\n</ol>\n<p>The same code runs successfully on a AWS P2 server with TensorFlow 1.3.</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.layers <span class=\"pl-k\">as</span> layers\n<span class=\"pl-k\">from</span> tensorflow.contrib.framework <span class=\"pl-k\">import</span> arg_scope\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">residual_conv</span>(<span class=\"pl-smi\">incoming</span>, <span class=\"pl-smi\">num_filters</span>, <span class=\"pl-smi\">scope</span>, <span class=\"pl-smi\">bn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>):\n\t<span class=\"pl-k\">with</span> tf.variable_scope(scope):\n\t    input_filters <span class=\"pl-k\">=</span> incoming.get_shape().as_list()[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\n\t    <span class=\"pl-k\">if</span> input_filters <span class=\"pl-k\">!=</span> num_filters:\n\t        incoming <span class=\"pl-k\">=</span> layers.conv2d(incoming, num_filters, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>adjust_conv<span class=\"pl-pds\">'</span></span>)\n\n\t    after_conv1 <span class=\"pl-k\">=</span> layers.conv2d(incoming, num_filters)\n\t    after_conv2 <span class=\"pl-k\">=</span> layers.conv2d(after_conv1, num_filters, <span class=\"pl-v\">normalizer_fn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>)\n\n\t    net <span class=\"pl-k\">=</span> incoming <span class=\"pl-k\">+</span> after_conv2\n\n\t    <span class=\"pl-k\">if</span> bn:\n\t        net <span class=\"pl-k\">=</span> layers.batch_norm(net)\n\n\t    <span class=\"pl-k\">return</span> net\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">tf_bilstm</span>(<span class=\"pl-smi\">incoming</span>, <span class=\"pl-smi\">n_units</span>, <span class=\"pl-smi\">name</span>):\n\tnet <span class=\"pl-k\">=</span> incoming\n\n\tlstm_f <span class=\"pl-k\">=</span> tf.contrib.rnn.LSTMCell(n_units)\n\tlstm_b <span class=\"pl-k\">=</span> tf.contrib.rnn.LSTMCell(n_units)\n\n\t<span class=\"pl-k\">with</span> tf.variable_scope(name):\n\t    results, _ <span class=\"pl-k\">=</span> tf.nn.bidirectional_dynamic_rnn(lstm_f, lstm_b, net, \n\t                                                 <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\t<span class=\"pl-k\">return</span> tf.concat(results, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n\tx_var <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">512</span>))\n\tis_training_var <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">bool</span>)\n\n\tnet <span class=\"pl-k\">=</span> x_var\n\n\t<span class=\"pl-k\">with</span> arg_scope([layers.batch_norm], <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training_var, <span class=\"pl-v\">decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.99</span>, <span class=\"pl-v\">scale</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\n\t               ), \\\n\t     arg_scope([layers.conv2d], <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>)), \\\n\t     arg_scope([layers.max_pool2d], <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>), <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>)):\n\n\t    net <span class=\"pl-k\">=</span> layers.repeat(net, <span class=\"pl-c1\">20</span>, residual_conv, <span class=\"pl-c1\">64</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>block1<span class=\"pl-pds\">'</span></span>)\n\t    net <span class=\"pl-k\">=</span> layers.max_pool2d(net)\n\n\t    net <span class=\"pl-k\">=</span> tf.squeeze(net, <span class=\"pl-c1\">2</span>)\n\t    net <span class=\"pl-k\">=</span> tf.transpose(net, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n\t    net <span class=\"pl-k\">=</span> tf_bilstm(net, <span class=\"pl-c1\">512</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>lstm1<span class=\"pl-pds\">'</span></span>)\n\n\tsess <span class=\"pl-k\">=</span> tf.Session()\n\tsess.run(tf.global_variables_initializer())\n\t\n\tX <span class=\"pl-k\">=</span> np.zeros([<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">512</span>])\n\n\t<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Right before TF call!<span class=\"pl-pds\">'</span></span>)\n\n\ta <span class=\"pl-k\">=</span> sess.run(net, {x_var: X, is_training_var: <span class=\"pl-c1\">True</span>})\n\n\t<span class=\"pl-c1\">print</span>(a)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n\tmain()</pre></div>\n<p>Edited: Simplified the code.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.5.0-0-g37aa430d84 1.5.0\nPython version: 3.6.4\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0.176 / 7.0.5\nGPU model and memory: Tesla V100 (AWS P3), 16GB\nExact command to reproduce: python debug_tf.py\n\nDescribe the problem\nWhen the following code is run on a p3.2xlarge, the python process starts consuming RAM indefinitely, until the entire server RAM is used and the server dies. That's system RAM, not GPU memory.\nIt doesn't look it, but the code below is the smallest I could find that produces the bad behavior.\n\nReplacing residual_conv with a simple convolution makes the code work (i.e not hang).\nReducing the repetition number in layers.repeat (to e.g 2) makes the code work.\nRemoving the batch normalization from residual_conv makes the code work.\nRemoving the LSTM makes the code work.\nThe weirdest of all, if I set is_training=True in batch_norm instead of is_training=is_training_var whose value is set to True in the feed_dict, then the code works.\n\nThe same code runs successfully on a AWS P2 server with TensorFlow 1.3.\nSource code / logs\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.layers as layers\nfrom tensorflow.contrib.framework import arg_scope\n\n\ndef residual_conv(incoming, num_filters, scope, bn=True):\n\twith tf.variable_scope(scope):\n\t    input_filters = incoming.get_shape().as_list()[-1]\n\t    if input_filters != num_filters:\n\t        incoming = layers.conv2d(incoming, num_filters, scope='adjust_conv')\n\n\t    after_conv1 = layers.conv2d(incoming, num_filters)\n\t    after_conv2 = layers.conv2d(after_conv1, num_filters, normalizer_fn=None, activation_fn=None)\n\n\t    net = incoming + after_conv2\n\n\t    if bn:\n\t        net = layers.batch_norm(net)\n\n\t    return net\n\ndef tf_bilstm(incoming, n_units, name):\n\tnet = incoming\n\n\tlstm_f = tf.contrib.rnn.LSTMCell(n_units)\n\tlstm_b = tf.contrib.rnn.LSTMCell(n_units)\n\n\twith tf.variable_scope(name):\n\t    results, _ = tf.nn.bidirectional_dynamic_rnn(lstm_f, lstm_b, net, \n\t                                                 dtype=tf.float32, time_major=True)\n\treturn tf.concat(results, axis=2)\n\ndef main():\n\tx_var = tf.placeholder(dtype=tf.float32, shape=(None, None, None, 512))\n\tis_training_var = tf.placeholder(dtype=bool)\n\n\tnet = x_var\n\n\twith arg_scope([layers.batch_norm], is_training=is_training_var, decay=0.99, scale=True\n\t               ), \\\n\t     arg_scope([layers.conv2d], padding='SAME', kernel_size=(3, 3)), \\\n\t     arg_scope([layers.max_pool2d], padding='SAME', kernel_size=(2, 2), stride=(2, 2)):\n\n\t    net = layers.repeat(net, 20, residual_conv, 64, scope='block1')\n\t    net = layers.max_pool2d(net)\n\n\t    net = tf.squeeze(net, 2)\n\t    net = tf.transpose(net, [1, 0, 2])\n\t    net = tf_bilstm(net, 512, 'lstm1')\n\n\tsess = tf.Session()\n\tsess.run(tf.global_variables_initializer())\n\t\n\tX = np.zeros([10, 100, 2, 512])\n\n\tprint('Right before TF call!')\n\n\ta = sess.run(net, {x_var: X, is_training_var: True})\n\n\tprint(a)\n\n\nif __name__ == '__main__':\n\tmain()\nEdited: Simplified the code.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.5.0-0-g37aa430d84 1.5.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0.176 / 7.0.5\r\n- **GPU model and memory**: Tesla V100 (AWS P3), 16GB\r\n- **Exact command to reproduce**: python debug_tf.py\r\n\r\n### Describe the problem\r\nWhen the following code is run on a p3.2xlarge, the python process starts consuming RAM indefinitely, until the entire server RAM is used and the server dies. That's system RAM, not GPU memory. \r\n\r\nIt doesn't look it, but the code below is the smallest I could find that produces the bad behavior.\r\n\r\n1. Replacing residual_conv with a simple convolution makes the code work (i.e not hang).\r\n2. Reducing the repetition number in `layers.repeat` (to e.g 2) makes the code work.\r\n3. Removing the batch normalization from residual_conv makes the code work.\r\n4. Removing the LSTM makes the code work.\r\n5. The weirdest of all, if I set `is_training=True` in batch_norm instead of `is_training=is_training_var` whose value is set to `True` in the feed_dict, then the code works.\r\n\r\nThe same code runs successfully on a AWS P2 server with TensorFlow 1.3.\r\n\r\n### Source code / logs\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.layers as layers\r\nfrom tensorflow.contrib.framework import arg_scope\r\n\r\n\r\ndef residual_conv(incoming, num_filters, scope, bn=True):\r\n\twith tf.variable_scope(scope):\r\n\t    input_filters = incoming.get_shape().as_list()[-1]\r\n\t    if input_filters != num_filters:\r\n\t        incoming = layers.conv2d(incoming, num_filters, scope='adjust_conv')\r\n\r\n\t    after_conv1 = layers.conv2d(incoming, num_filters)\r\n\t    after_conv2 = layers.conv2d(after_conv1, num_filters, normalizer_fn=None, activation_fn=None)\r\n\r\n\t    net = incoming + after_conv2\r\n\r\n\t    if bn:\r\n\t        net = layers.batch_norm(net)\r\n\r\n\t    return net\r\n\r\ndef tf_bilstm(incoming, n_units, name):\r\n\tnet = incoming\r\n\r\n\tlstm_f = tf.contrib.rnn.LSTMCell(n_units)\r\n\tlstm_b = tf.contrib.rnn.LSTMCell(n_units)\r\n\r\n\twith tf.variable_scope(name):\r\n\t    results, _ = tf.nn.bidirectional_dynamic_rnn(lstm_f, lstm_b, net, \r\n\t                                                 dtype=tf.float32, time_major=True)\r\n\treturn tf.concat(results, axis=2)\r\n\r\ndef main():\r\n\tx_var = tf.placeholder(dtype=tf.float32, shape=(None, None, None, 512))\r\n\tis_training_var = tf.placeholder(dtype=bool)\r\n\r\n\tnet = x_var\r\n\r\n\twith arg_scope([layers.batch_norm], is_training=is_training_var, decay=0.99, scale=True\r\n\t               ), \\\r\n\t     arg_scope([layers.conv2d], padding='SAME', kernel_size=(3, 3)), \\\r\n\t     arg_scope([layers.max_pool2d], padding='SAME', kernel_size=(2, 2), stride=(2, 2)):\r\n\r\n\t    net = layers.repeat(net, 20, residual_conv, 64, scope='block1')\r\n\t    net = layers.max_pool2d(net)\r\n\r\n\t    net = tf.squeeze(net, 2)\r\n\t    net = tf.transpose(net, [1, 0, 2])\r\n\t    net = tf_bilstm(net, 512, 'lstm1')\r\n\r\n\tsess = tf.Session()\r\n\tsess.run(tf.global_variables_initializer())\r\n\t\r\n\tX = np.zeros([10, 100, 2, 512])\r\n\r\n\tprint('Right before TF call!')\r\n\r\n\ta = sess.run(net, {x_var: X, is_training_var: True})\r\n\r\n\tprint(a)\r\n\r\n\r\nif __name__ == '__main__':\r\n\tmain()\r\n```\r\n\r\nEdited: Simplified the code."}