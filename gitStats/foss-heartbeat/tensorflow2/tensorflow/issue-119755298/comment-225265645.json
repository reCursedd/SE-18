{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/225265645", "html_url": "https://github.com/tensorflow/tensorflow/issues/389#issuecomment-225265645", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/389", "id": 225265645, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNTI2NTY0NQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-10T18:51:35Z", "updated_at": "2016-06-10T18:51:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10623722\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yuanpengX\">@yuanpengX</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9168758\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/atamahjoubfar\">@atamahjoubfar</a> is this still an issue?  Is it just the verbose logging that's troubling you?  when you reach the end of the input file, the queue dies and the training is restarted from the beginning.  that may explain all the warnings.</p>", "body_text": "@yuanpengX @atamahjoubfar is this still an issue?  Is it just the verbose logging that's troubling you?  when you reach the end of the input file, the queue dies and the training is restarted from the beginning.  that may explain all the warnings.", "body": "@yuanpengX @atamahjoubfar is this still an issue?  Is it just the verbose logging that's troubling you?  when you reach the end of the input file, the queue dies and the training is restarted from the beginning.  that may explain all the warnings.\n"}