{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19000", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19000/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19000/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19000/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19000", "id": 319196457, "node_id": "MDU6SXNzdWUzMTkxOTY0NTc=", "number": 19000, "title": "Feature Request: get Estimator from binary model (.pb file)", "user": {"login": "AndRossi", "id": 6909990, "node_id": "MDQ6VXNlcjY5MDk5OTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/6909990?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AndRossi", "html_url": "https://github.com/AndRossi", "followers_url": "https://api.github.com/users/AndRossi/followers", "following_url": "https://api.github.com/users/AndRossi/following{/other_user}", "gists_url": "https://api.github.com/users/AndRossi/gists{/gist_id}", "starred_url": "https://api.github.com/users/AndRossi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AndRossi/subscriptions", "organizations_url": "https://api.github.com/users/AndRossi/orgs", "repos_url": "https://api.github.com/users/AndRossi/repos", "events_url": "https://api.github.com/users/AndRossi/events{/privacy}", "received_events_url": "https://api.github.com/users/AndRossi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, {"login": "k-w-w", "id": 31663267, "node_id": "MDQ6VXNlcjMxNjYzMjY3", "avatar_url": "https://avatars2.githubusercontent.com/u/31663267?v=4", "gravatar_id": "", "url": "https://api.github.com/users/k-w-w", "html_url": "https://github.com/k-w-w", "followers_url": "https://api.github.com/users/k-w-w/followers", "following_url": "https://api.github.com/users/k-w-w/following{/other_user}", "gists_url": "https://api.github.com/users/k-w-w/gists{/gist_id}", "starred_url": "https://api.github.com/users/k-w-w/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/k-w-w/subscriptions", "organizations_url": "https://api.github.com/users/k-w-w/orgs", "repos_url": "https://api.github.com/users/k-w-w/repos", "events_url": "https://api.github.com/users/k-w-w/events{/privacy}", "received_events_url": "https://api.github.com/users/k-w-w/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-05-01T13:24:04Z", "updated_at": "2018-10-10T19:59:38Z", "closed_at": "2018-10-10T19:59:38Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOS High Sierra 10.13.4</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary (through pip)</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: -</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: -</li>\n<li><strong>CUDA/cuDNN version</strong>: not using CUDA, just CPU for now</li>\n<li><strong>GPU model and memory</strong>: -</li>\n<li><strong>Exact command to reproduce</strong>: -</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am using the Estimator interface to train and evaluate  my model. It is really cool.<br>\nHowever, since I am developing for mobile, after training I must also freeze, optimize, quantize the model and then port it to TFLite.<br>\nIn these steps, my model must be in binary format (.pb).</p>\n<p>It would be nice to build an Estimator from a .pb file to allow evaluation of binary models.<br>\nFor instance, I need to check how much accuracy I am losing after the quantization step.<br>\nHowever, I believe that at the moment it is not possible to instantiate an Estimator from a binary model.</p>\n<p>I have done some research before opening this issue:</p>\n<ul>\n<li>I have searched the TF documentation but did not find anything about loading a binary model into an Estimator;</li>\n<li>I have tried to ask this question on StackOverflow three weeks ago (here is <a href=\"https://stackoverflow.com/questions/49736537/load-a-frozen-model-into-a-tensorflow-estimator\" rel=\"nofollow\">the link</a>), but got no answers.</li>\n</ul>\n<p>As a consequence, at the moment I am just using the old GraphDef and feed_dict interface to perform evaluation and prediction with binary models.<br>\nHowever using different interfaces for literally the same tasks just seems a bit... off.</p>\n<p>Estimators probably use GraphDef under the hood. So it should be really easy to allow instantiation from a binary model.</p>\n<p>Am I missing something? If not, can you implement this feature please?</p>\n<p>Thanks for your support!<br>\nAndrea</p>", "body_text": "System information\n\nHave I written custom code: No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS High Sierra 10.13.4\nTensorFlow installed from (source or binary): binary (through pip)\nTensorFlow version (use command below): 1.7\nPython version: 3.6\nBazel version (if compiling from source): -\nGCC/Compiler version (if compiling from source): -\nCUDA/cuDNN version: not using CUDA, just CPU for now\nGPU model and memory: -\nExact command to reproduce: -\n\nDescribe the problem\nI am using the Estimator interface to train and evaluate  my model. It is really cool.\nHowever, since I am developing for mobile, after training I must also freeze, optimize, quantize the model and then port it to TFLite.\nIn these steps, my model must be in binary format (.pb).\nIt would be nice to build an Estimator from a .pb file to allow evaluation of binary models.\nFor instance, I need to check how much accuracy I am losing after the quantization step.\nHowever, I believe that at the moment it is not possible to instantiate an Estimator from a binary model.\nI have done some research before opening this issue:\n\nI have searched the TF documentation but did not find anything about loading a binary model into an Estimator;\nI have tried to ask this question on StackOverflow three weeks ago (here is the link), but got no answers.\n\nAs a consequence, at the moment I am just using the old GraphDef and feed_dict interface to perform evaluation and prediction with binary models.\nHowever using different interfaces for literally the same tasks just seems a bit... off.\nEstimators probably use GraphDef under the hood. So it should be really easy to allow instantiation from a binary model.\nAm I missing something? If not, can you implement this feature please?\nThanks for your support!\nAndrea", "body": "### System information\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS High Sierra 10.13.4\r\n- **TensorFlow installed from (source or binary)**: binary (through pip)\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: not using CUDA, just CPU for now\r\n- **GPU model and memory**: - \r\n- **Exact command to reproduce**: -\r\n\r\n### Describe the problem\r\nI am using the Estimator interface to train and evaluate  my model. It is really cool.\r\nHowever, since I am developing for mobile, after training I must also freeze, optimize, quantize the model and then port it to TFLite.  \r\nIn these steps, my model must be in binary format (.pb).\r\n\r\nIt would be nice to build an Estimator from a .pb file to allow evaluation of binary models.\r\nFor instance, I need to check how much accuracy I am losing after the quantization step.\r\nHowever, I believe that at the moment it is not possible to instantiate an Estimator from a binary model.\r\n\r\nI have done some research before opening this issue:\r\n- I have searched the TF documentation but did not find anything about loading a binary model into an Estimator;\r\n- I have tried to ask this question on StackOverflow three weeks ago (here is [the link](https://stackoverflow.com/questions/49736537/load-a-frozen-model-into-a-tensorflow-estimator)), but got no answers.\r\n\r\nAs a consequence, at the moment I am just using the old GraphDef and feed_dict interface to perform evaluation and prediction with binary models. \r\nHowever using different interfaces for literally the same tasks just seems a bit... off.\r\n\r\nEstimators probably use GraphDef under the hood. So it should be really easy to allow instantiation from a binary model.\r\n\r\nAm I missing something? If not, can you implement this feature please?\r\n\r\nThanks for your support!\r\nAndrea"}