{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/270771036", "html_url": "https://github.com/tensorflow/tensorflow/issues/6629#issuecomment-270771036", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6629", "id": 270771036, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MDc3MTAzNg==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-05T22:04:41Z", "updated_at": "2017-01-05T22:04:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Can you give the use-case you need this for? In this specific case, the <code>floatX</code> option doesn't seem to be very useful -- <code>float32</code> support is usually there, but <code>float16/float64</code> is spotty. For non-trivial calculation, switching away from <code>float32</code> type will usually give \"kernel not registered\" error. Also .theanorc has \"device\" setting, but that doesn't seem very applicable to TensorFlow. It was designed to use multiple devices, and the most common case is two devices -- cpu+(1 or more GPUs), the latter being configurable with CUDA_VISIBLE_DEVICES.</p>\n<p>When using distributed TensorFlow, you could have more than one session and use different configs for local vs. grpc session worker vs grpc session ps. The raises the question of global default -- which session they would apply to</p>", "body_text": "Can you give the use-case you need this for? In this specific case, the floatX option doesn't seem to be very useful -- float32 support is usually there, but float16/float64 is spotty. For non-trivial calculation, switching away from float32 type will usually give \"kernel not registered\" error. Also .theanorc has \"device\" setting, but that doesn't seem very applicable to TensorFlow. It was designed to use multiple devices, and the most common case is two devices -- cpu+(1 or more GPUs), the latter being configurable with CUDA_VISIBLE_DEVICES.\nWhen using distributed TensorFlow, you could have more than one session and use different configs for local vs. grpc session worker vs grpc session ps. The raises the question of global default -- which session they would apply to", "body": "Can you give the use-case you need this for? In this specific case, the `floatX` option doesn't seem to be very useful -- `float32` support is usually there, but `float16/float64` is spotty. For non-trivial calculation, switching away from `float32` type will usually give \"kernel not registered\" error. Also .theanorc has \"device\" setting, but that doesn't seem very applicable to TensorFlow. It was designed to use multiple devices, and the most common case is two devices -- cpu+(1 or more GPUs), the latter being configurable with CUDA_VISIBLE_DEVICES.\r\n\r\nWhen using distributed TensorFlow, you could have more than one session and use different configs for local vs. grpc session worker vs grpc session ps. The raises the question of global default -- which session they would apply to"}