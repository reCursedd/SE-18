{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/400212445", "html_url": "https://github.com/tensorflow/tensorflow/issues/20272#issuecomment-400212445", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20272", "id": 400212445, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMDIxMjQ0NQ==", "user": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-26T07:43:57Z", "updated_at": "2018-06-26T07:43:57Z", "author_association": "MEMBER", "body_html": "<p>I see. You are using the correct model, but you should use this toco command to specify quantization:</p>\n<pre><code>bazel build tensorflow/contrib/lite/toco:toco &amp;&amp; \\\n  ./bazel-bin/third_party/tensorflow/contrib/lite/toco/toco \\\n  --input_file=&lt;YOUR_INPUT&gt; \\\n  --output_file=&lt;YOUR_OUTPUT&gt; \\\n  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\n  --inference_type=QUANTIZED_UINT8 \\\n  --input_shape=\"1,224, 224,3\" \\\n  --input_array=input \\\n  --output_array=final_result \\\n  --std_value=128 --mean_value=128\n</code></pre>", "body_text": "I see. You are using the correct model, but you should use this toco command to specify quantization:\nbazel build tensorflow/contrib/lite/toco:toco && \\\n  ./bazel-bin/third_party/tensorflow/contrib/lite/toco/toco \\\n  --input_file=<YOUR_INPUT> \\\n  --output_file=<YOUR_OUTPUT> \\\n  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\n  --inference_type=QUANTIZED_UINT8 \\\n  --input_shape=\"1,224, 224,3\" \\\n  --input_array=input \\\n  --output_array=final_result \\\n  --std_value=128 --mean_value=128", "body": "I see. You are using the correct model, but you should use this toco command to specify quantization:\r\n\r\n```\r\nbazel build tensorflow/contrib/lite/toco:toco && \\\r\n  ./bazel-bin/third_party/tensorflow/contrib/lite/toco/toco \\\r\n  --input_file=<YOUR_INPUT> \\\r\n  --output_file=<YOUR_OUTPUT> \\\r\n  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --input_shape=\"1,224, 224,3\" \\\r\n  --input_array=input \\\r\n  --output_array=final_result \\\r\n  --std_value=128 --mean_value=128\r\n```"}