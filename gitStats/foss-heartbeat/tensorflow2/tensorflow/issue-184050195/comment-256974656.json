{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256974656", "html_url": "https://github.com/tensorflow/tensorflow/pull/5072#issuecomment-256974656", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5072", "id": 256974656, "node_id": "MDEyOklzc3VlQ29tbWVudDI1Njk3NDY1Ng==", "user": {"login": "mkolod", "id": 476135, "node_id": "MDQ6VXNlcjQ3NjEzNQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/476135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mkolod", "html_url": "https://github.com/mkolod", "followers_url": "https://api.github.com/users/mkolod/followers", "following_url": "https://api.github.com/users/mkolod/following{/other_user}", "gists_url": "https://api.github.com/users/mkolod/gists{/gist_id}", "starred_url": "https://api.github.com/users/mkolod/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mkolod/subscriptions", "organizations_url": "https://api.github.com/users/mkolod/orgs", "repos_url": "https://api.github.com/users/mkolod/repos", "events_url": "https://api.github.com/users/mkolod/events{/privacy}", "received_events_url": "https://api.github.com/users/mkolod/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-28T17:05:54Z", "updated_at": "2016-10-28T17:11:51Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=229914\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/keveman\">@keveman</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> I looked at the test and my findings are as follows. There isn't any bug in libjpeg, but, I would argue, the tolerance on the JPEG fixed point test (encode/decode/encode several times and see if there is stability in that the diffs go to zero) is pretty tight. For the first encode-decode, the diff is about 0.55 out of 255, but with the slow IDCT, the diff goes to 0.02 or so on the second encode/decode pass. The fast IDCT does generate more error, this is a known thing. The error is actually basically the same on the first pass in fast and slow IDCT, but the difference is that slow IDCT is more stable on the second decode and re-encode. I'd argue that since TensorFlow is not an image editing platform but a machine learning platform, it would be a real corner case if someone ended up decoding and re-encoding the same image dozens of times over (also in that case, why not use a lossless format?). If there is say one decoding and re-encoding (e.g. due to the need to preprocess an existing dataset offline for more optimized use later, e.g. pre-resizing ImageNet), that would be a single such preprocessing pass, not counting the final decoding at learning time. In case further updates to the offline preprocessing pipeline are needed, they could be recomputed from the original images so there's only one lossy pass, and that one lossy pass is identical between fast and slow IDCT. The only difference is in case of multiple read/write/read passes. So, while the fixed point test would matter a lot for image editing, I don't think it's that important for machine learning applications, because (a) there's usually 1 or 2 decode passes followed by encode at most, and (b) because in a programmatic environment, all changes can be applied to in-memory data before applying a single encoding pass. If you agree that this is a reasonable explanation as to why the tolerance of the fixed point test can be widened. Please let me what you think.</p>", "body_text": "@keveman @drpngx I looked at the test and my findings are as follows. There isn't any bug in libjpeg, but, I would argue, the tolerance on the JPEG fixed point test (encode/decode/encode several times and see if there is stability in that the diffs go to zero) is pretty tight. For the first encode-decode, the diff is about 0.55 out of 255, but with the slow IDCT, the diff goes to 0.02 or so on the second encode/decode pass. The fast IDCT does generate more error, this is a known thing. The error is actually basically the same on the first pass in fast and slow IDCT, but the difference is that slow IDCT is more stable on the second decode and re-encode. I'd argue that since TensorFlow is not an image editing platform but a machine learning platform, it would be a real corner case if someone ended up decoding and re-encoding the same image dozens of times over (also in that case, why not use a lossless format?). If there is say one decoding and re-encoding (e.g. due to the need to preprocess an existing dataset offline for more optimized use later, e.g. pre-resizing ImageNet), that would be a single such preprocessing pass, not counting the final decoding at learning time. In case further updates to the offline preprocessing pipeline are needed, they could be recomputed from the original images so there's only one lossy pass, and that one lossy pass is identical between fast and slow IDCT. The only difference is in case of multiple read/write/read passes. So, while the fixed point test would matter a lot for image editing, I don't think it's that important for machine learning applications, because (a) there's usually 1 or 2 decode passes followed by encode at most, and (b) because in a programmatic environment, all changes can be applied to in-memory data before applying a single encoding pass. If you agree that this is a reasonable explanation as to why the tolerance of the fixed point test can be widened. Please let me what you think.", "body": "@keveman @drpngx I looked at the test and my findings are as follows. There isn't any bug in libjpeg, but, I would argue, the tolerance on the JPEG fixed point test (encode/decode/encode several times and see if there is stability in that the diffs go to zero) is pretty tight. For the first encode-decode, the diff is about 0.55 out of 255, but with the slow IDCT, the diff goes to 0.02 or so on the second encode/decode pass. The fast IDCT does generate more error, this is a known thing. The error is actually basically the same on the first pass in fast and slow IDCT, but the difference is that slow IDCT is more stable on the second decode and re-encode. I'd argue that since TensorFlow is not an image editing platform but a machine learning platform, it would be a real corner case if someone ended up decoding and re-encoding the same image dozens of times over (also in that case, why not use a lossless format?). If there is say one decoding and re-encoding (e.g. due to the need to preprocess an existing dataset offline for more optimized use later, e.g. pre-resizing ImageNet), that would be a single such preprocessing pass, not counting the final decoding at learning time. In case further updates to the offline preprocessing pipeline are needed, they could be recomputed from the original images so there's only one lossy pass, and that one lossy pass is identical between fast and slow IDCT. The only difference is in case of multiple read/write/read passes. So, while the fixed point test would matter a lot for image editing, I don't think it's that important for machine learning applications, because (a) there's usually 1 or 2 decode passes followed by encode at most, and (b) because in a programmatic environment, all changes can be applied to in-memory data before applying a single encoding pass. If you agree that this is a reasonable explanation as to why the tolerance of the fixed point test can be widened. Please let me what you think.\n"}