{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12338", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12338/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12338/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12338/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12338", "id": 250759751, "node_id": "MDU6SXNzdWUyNTA3NTk3NTE=", "number": 12338, "title": "Tensorflow crashes when i try to quantize my output", "user": {"login": "posix4e", "id": 806363, "node_id": "MDQ6VXNlcjgwNjM2Mw==", "avatar_url": "https://avatars0.githubusercontent.com/u/806363?v=4", "gravatar_id": "", "url": "https://api.github.com/users/posix4e", "html_url": "https://github.com/posix4e", "followers_url": "https://api.github.com/users/posix4e/followers", "following_url": "https://api.github.com/users/posix4e/following{/other_user}", "gists_url": "https://api.github.com/users/posix4e/gists{/gist_id}", "starred_url": "https://api.github.com/users/posix4e/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/posix4e/subscriptions", "organizations_url": "https://api.github.com/users/posix4e/orgs", "repos_url": "https://api.github.com/users/posix4e/repos", "events_url": "https://api.github.com/users/posix4e/events{/privacy}", "received_events_url": "https://api.github.com/users/posix4e/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-08-16T21:04:52Z", "updated_at": "2017-08-16T22:45:05Z", "closed_at": "2017-08-16T22:45:05Z", "author_association": "NONE", "body_html": "<p>BUG<br>\n(<a href=\"https://github.com/tensorflow/tensorboard/issues\">https://github.com/tensorflow/tensorboard/issues</a>).</p>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n<li><strong>Python version</strong>:</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n</ul>\n<pre><code>$ lspci -vvv|grep -i nvi\n00:1e.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1) (prog-if 00 [VGA controller])\n        Subsystem: NVIDIA Corporation GM204GL [Tesla M60]\n        Kernel driver in use: nvidia\n        Kernel modules: nvidia_375_drm, nvidia_375\n- **Exact command to reproduce**:\n</code></pre>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>When I tried to quantize my output</p>\n<ul>\n<li>\n<pre><code>       result = SESS.run(layers[0], {'incept/DecodeJpeg/contents:0': f.read()})\n</code></pre>\n</li>\n</ul>\n<ul>\n<li>\n<pre><code>       result = SESS.run(tf.quantize_v2(layers[0], min_range=0, max_range=10, T=tf.quint8), {'incept/DecodeJpeg/contents:0': f.read()})\n</code></pre>\n</li>\n</ul>\n<p>I run out of memory on my GPU</p>\n<pre><code>2017-08-16 20:59:40.313241: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ***********************\n*****************************************************************************\n2017-08-16 20:59:40.313284: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: OOM when al\nlocating tensor with shape[720,1280,3]\nTraceback (most recent call last):\n  File \"generate_hashes.py\", line 89, in &lt;module&gt;\n    for (fn, points) in map_results.result():\n  File \"/usr/local/lib/python2.7/dist-packages/pebble/pool/base_pool.py\", line 208, in next\n    raise result\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[720,\n1280,3]\n         [[Node: incept/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, _device=\"/job:unknown_job/replica:0/task\n:0/gpu:0\"](incept/DecodeJpeg_G511)]]\n         [[Node: incept/pool_3_G513 = _Recv[client_terminated=false, recv_device=\"/job:unknown_job/replica\n:0/task:0/cpu:0\", send_device=\"/job:unknown_job/replica:0/task:0/gpu:0\", send_device_incarnation=-69665892\n98495454362, tensor_name=\"edge_1131_incept/pool_3\", tensor_type=DT_FLOAT, _device=\"/job:unknown_job/replic\na:0/task:0/cpu:0\"]()]]\n\nCaused by op u'incept/Cast', defined at:\n  File \"generate_hashes.py\", line 78, in &lt;module&gt;\n    load_network(False)\n  File \"generate_hashes.py\", line 40, in load_network\n    return tf.import_graph_def(graph_def, name='incept')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 311, in impo\nrt_graph_def\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2506, in create_o\np\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[720,1280,3]\n         [[Node: incept/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, _device=\"/job:unknown_job/replica:0/task\n:0/gpu:0\"](incept/DecodeJpeg_G511)]]\n         [[Node: incept/pool_3_G513 = _Recv[client_terminated=false, recv_device=\"/job:unknown_job/replica\n:0/task:0/cpu:0\", send_device=\"/job:unknown_job/replica:0/task:0/gpu:0\", send_device_incarnation=-69665892\n98495454362, tensor_name=\"edge_1131_incept/pool_3\", tensor_type=DT_FLOAT, _device=\"/job:unknown_job/replic\na:0/task:0/cpu:0\"]()]]\n</code></pre>", "body_text": "BUG\n(https://github.com/tensorflow/tensorboard/issues).\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below):\nPython version:\nBazel version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\n\n$ lspci -vvv|grep -i nvi\n00:1e.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1) (prog-if 00 [VGA controller])\n        Subsystem: NVIDIA Corporation GM204GL [Tesla M60]\n        Kernel driver in use: nvidia\n        Kernel modules: nvidia_375_drm, nvidia_375\n- **Exact command to reproduce**:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nWhen I tried to quantize my output\n\n\n       result = SESS.run(layers[0], {'incept/DecodeJpeg/contents:0': f.read()})\n\n\n\n\n\n       result = SESS.run(tf.quantize_v2(layers[0], min_range=0, max_range=10, T=tf.quint8), {'incept/DecodeJpeg/contents:0': f.read()})\n\n\n\nI run out of memory on my GPU\n2017-08-16 20:59:40.313241: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ***********************\n*****************************************************************************\n2017-08-16 20:59:40.313284: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: OOM when al\nlocating tensor with shape[720,1280,3]\nTraceback (most recent call last):\n  File \"generate_hashes.py\", line 89, in <module>\n    for (fn, points) in map_results.result():\n  File \"/usr/local/lib/python2.7/dist-packages/pebble/pool/base_pool.py\", line 208, in next\n    raise result\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[720,\n1280,3]\n         [[Node: incept/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, _device=\"/job:unknown_job/replica:0/task\n:0/gpu:0\"](incept/DecodeJpeg_G511)]]\n         [[Node: incept/pool_3_G513 = _Recv[client_terminated=false, recv_device=\"/job:unknown_job/replica\n:0/task:0/cpu:0\", send_device=\"/job:unknown_job/replica:0/task:0/gpu:0\", send_device_incarnation=-69665892\n98495454362, tensor_name=\"edge_1131_incept/pool_3\", tensor_type=DT_FLOAT, _device=\"/job:unknown_job/replic\na:0/task:0/cpu:0\"]()]]\n\nCaused by op u'incept/Cast', defined at:\n  File \"generate_hashes.py\", line 78, in <module>\n    load_network(False)\n  File \"generate_hashes.py\", line 40, in load_network\n    return tf.import_graph_def(graph_def, name='incept')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 311, in impo\nrt_graph_def\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2506, in create_o\np\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[720,1280,3]\n         [[Node: incept/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, _device=\"/job:unknown_job/replica:0/task\n:0/gpu:0\"](incept/DecodeJpeg_G511)]]\n         [[Node: incept/pool_3_G513 = _Recv[client_terminated=false, recv_device=\"/job:unknown_job/replica\n:0/task:0/cpu:0\", send_device=\"/job:unknown_job/replica:0/task:0/gpu:0\", send_device_incarnation=-69665892\n98495454362, tensor_name=\"edge_1131_incept/pool_3\", tensor_type=DT_FLOAT, _device=\"/job:unknown_job/replic\na:0/task:0/cpu:0\"]()]]", "body": "BUG\r\n(https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n```\r\n$ lspci -vvv|grep -i nvi\r\n00:1e.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1) (prog-if 00 [VGA controller])\r\n        Subsystem: NVIDIA Corporation GM204GL [Tesla M60]\r\n        Kernel driver in use: nvidia\r\n        Kernel modules: nvidia_375_drm, nvidia_375\r\n- **Exact command to reproduce**:\r\n```\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nWhen I tried to quantize my output\r\n\r\n-            result = SESS.run(layers[0], {'incept/DecodeJpeg/contents:0': f.read()})\r\n+            result = SESS.run(tf.quantize_v2(layers[0], min_range=0, max_range=10, T=tf.quint8), {'incept/DecodeJpeg/contents:0': f.read()})\r\n \r\nI run out of memory on my GPU\r\n\r\n\r\n```\r\n2017-08-16 20:59:40.313241: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ***********************\r\n*****************************************************************************\r\n2017-08-16 20:59:40.313284: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: OOM when al\r\nlocating tensor with shape[720,1280,3]\r\nTraceback (most recent call last):\r\n  File \"generate_hashes.py\", line 89, in <module>\r\n    for (fn, points) in map_results.result():\r\n  File \"/usr/local/lib/python2.7/dist-packages/pebble/pool/base_pool.py\", line 208, in next\r\n    raise result\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[720,\r\n1280,3]\r\n         [[Node: incept/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, _device=\"/job:unknown_job/replica:0/task\r\n:0/gpu:0\"](incept/DecodeJpeg_G511)]]\r\n         [[Node: incept/pool_3_G513 = _Recv[client_terminated=false, recv_device=\"/job:unknown_job/replica\r\n:0/task:0/cpu:0\", send_device=\"/job:unknown_job/replica:0/task:0/gpu:0\", send_device_incarnation=-69665892\r\n98495454362, tensor_name=\"edge_1131_incept/pool_3\", tensor_type=DT_FLOAT, _device=\"/job:unknown_job/replic\r\na:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'incept/Cast', defined at:\r\n  File \"generate_hashes.py\", line 78, in <module>\r\n    load_network(False)\r\n  File \"generate_hashes.py\", line 40, in load_network\r\n    return tf.import_graph_def(graph_def, name='incept')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 311, in impo\r\nrt_graph_def\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2506, in create_o\r\np\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[720,1280,3]\r\n         [[Node: incept/Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, _device=\"/job:unknown_job/replica:0/task\r\n:0/gpu:0\"](incept/DecodeJpeg_G511)]]\r\n         [[Node: incept/pool_3_G513 = _Recv[client_terminated=false, recv_device=\"/job:unknown_job/replica\r\n:0/task:0/cpu:0\", send_device=\"/job:unknown_job/replica:0/task:0/gpu:0\", send_device_incarnation=-69665892\r\n98495454362, tensor_name=\"edge_1131_incept/pool_3\", tensor_type=DT_FLOAT, _device=\"/job:unknown_job/replic\r\na:0/task:0/cpu:0\"]()]]\r\n```\r\n"}