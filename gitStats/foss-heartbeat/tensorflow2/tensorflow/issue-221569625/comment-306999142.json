{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/306999142", "html_url": "https://github.com/tensorflow/tensorflow/pull/9189#issuecomment-306999142", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9189", "id": 306999142, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNjk5OTE0Mg==", "user": {"login": "cwhipkey", "id": 17578177, "node_id": "MDQ6VXNlcjE3NTc4MTc3", "avatar_url": "https://avatars0.githubusercontent.com/u/17578177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cwhipkey", "html_url": "https://github.com/cwhipkey", "followers_url": "https://api.github.com/users/cwhipkey/followers", "following_url": "https://api.github.com/users/cwhipkey/following{/other_user}", "gists_url": "https://api.github.com/users/cwhipkey/gists{/gist_id}", "starred_url": "https://api.github.com/users/cwhipkey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cwhipkey/subscriptions", "organizations_url": "https://api.github.com/users/cwhipkey/orgs", "repos_url": "https://api.github.com/users/cwhipkey/repos", "events_url": "https://api.github.com/users/cwhipkey/events{/privacy}", "received_events_url": "https://api.github.com/users/cwhipkey/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-08T05:03:11Z", "updated_at": "2017-06-08T05:03:11Z", "author_association": "MEMBER", "body_html": "<p>Regarding questions from before:</p>\n<ol>\n<li>\"What else has to be done before I may ask for review?\"</li>\n</ol>\n<p>I think as long as the functionality is complete enough, with the tests, then we can start a review of the code.  Some things may come up during that review.</p>\n<ol start=\"2\">\n<li>\"Additionally, which contrib module should I use?\"</li>\n</ol>\n<p>Does tf.contrib.control_flow seem okay?</p>\n<ol start=\"3\">\n<li>\"Some op kernels, Merge for example, require that all int32 inputs reside in host memory. Why? Should I do the same?\"</li>\n</ol>\n<p>Some background: Some operations are commonly used for operations on shape tensors, which tend to be int32 (although int64 is possible).  If those operations have int32 GPU kernels registered which put the memory on device, then placement of ops to devices will put them on GPU, but it's better to avoid the bouncing back-and-forth from device-to-host for those operations.  Currently, this is avoided by having the int32 GPU kernels request HostMemory for the inputs and outputs; iiuc, this mainly works because int32 is not used often for non-shape tensors on GPU.  So I would guess that your ops should match their switch/merge analogs with this behavior.</p>", "body_text": "Regarding questions from before:\n\n\"What else has to be done before I may ask for review?\"\n\nI think as long as the functionality is complete enough, with the tests, then we can start a review of the code.  Some things may come up during that review.\n\n\"Additionally, which contrib module should I use?\"\n\nDoes tf.contrib.control_flow seem okay?\n\n\"Some op kernels, Merge for example, require that all int32 inputs reside in host memory. Why? Should I do the same?\"\n\nSome background: Some operations are commonly used for operations on shape tensors, which tend to be int32 (although int64 is possible).  If those operations have int32 GPU kernels registered which put the memory on device, then placement of ops to devices will put them on GPU, but it's better to avoid the bouncing back-and-forth from device-to-host for those operations.  Currently, this is avoided by having the int32 GPU kernels request HostMemory for the inputs and outputs; iiuc, this mainly works because int32 is not used often for non-shape tensors on GPU.  So I would guess that your ops should match their switch/merge analogs with this behavior.", "body": "Regarding questions from before:\r\n\r\n1. \"What else has to be done before I may ask for review?\"\r\n\r\nI think as long as the functionality is complete enough, with the tests, then we can start a review of the code.  Some things may come up during that review.\r\n\r\n2. \"Additionally, which contrib module should I use?\"\r\n\r\nDoes tf.contrib.control_flow seem okay?\r\n\r\n3. \"Some op kernels, Merge for example, require that all int32 inputs reside in host memory. Why? Should I do the same?\"\r\n\r\nSome background: Some operations are commonly used for operations on shape tensors, which tend to be int32 (although int64 is possible).  If those operations have int32 GPU kernels registered which put the memory on device, then placement of ops to devices will put them on GPU, but it's better to avoid the bouncing back-and-forth from device-to-host for those operations.  Currently, this is avoided by having the int32 GPU kernels request HostMemory for the inputs and outputs; iiuc, this mainly works because int32 is not used often for non-shape tensors on GPU.  So I would guess that your ops should match their switch/merge analogs with this behavior."}