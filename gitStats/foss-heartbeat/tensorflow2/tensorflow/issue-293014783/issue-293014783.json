{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16611", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16611/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16611/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16611/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16611", "id": 293014783, "node_id": "MDU6SXNzdWUyOTMwMTQ3ODM=", "number": 16611, "title": "Bug: tf.train.monitoredtrainingsession non-chief worker does not start", "user": {"login": "chesschi", "id": 8336814, "node_id": "MDQ6VXNlcjgzMzY4MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8336814?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chesschi", "html_url": "https://github.com/chesschi", "followers_url": "https://api.github.com/users/chesschi/followers", "following_url": "https://api.github.com/users/chesschi/following{/other_user}", "gists_url": "https://api.github.com/users/chesschi/gists{/gist_id}", "starred_url": "https://api.github.com/users/chesschi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chesschi/subscriptions", "organizations_url": "https://api.github.com/users/chesschi/orgs", "repos_url": "https://api.github.com/users/chesschi/repos", "events_url": "https://api.github.com/users/chesschi/events{/privacy}", "received_events_url": "https://api.github.com/users/chesschi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-01-31T02:59:32Z", "updated_at": "2018-10-26T21:06:47Z", "closed_at": "2018-10-26T21:06:35Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 17.10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.4.0-19-ga52c8d9 1.4.1</li>\n<li><strong>Python version</strong>: 3.6.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8</li>\n<li><strong>GPU model and memory</strong>: GTX-1080 11GB (chief) and M2000 4GB (slave)</li>\n<li><strong>Exact command to reproduce</strong>:<br>\nCUDA_VISIBLE_DEVICES='' python3 test.py --job-name ps --task-index 0<br>\nCUDA_VISIBLE_DEVICES=0 python3 test.py --job-name worker --task-index 0<br>\nCUDA_VISIBLE_DEVICES='' python3 test.py --job-name ps --task-index 1<br>\nCUDA_VISIBLE_DEVICES=0 python3 test.py --job-name worker --task-index 1</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am trying to run the <a href=\"https://www.tensorflow.org/deploy/distributed\" rel=\"nofollow\">distributed training</a> and use <a href=\"https://www.tensorflow.org/api_docs/python/tf/train/MonitoredTrainingSession\" rel=\"nofollow\">tf.train.MonitoredTrainingSession</a> with 2 PCs. PC1 has one GTX-1080 11GB and is set as chief, while PC2 has one M2000 4GB and is set as non-chief. They are connected back-to-back without switch/router. The chief worker was running okay but the non-chief worker was stuck at <code>tf.train.MonitoredTrainingSession</code> and did not proceed to execute the code within the session.</p>\n<h3>Source code / logs</h3>\n<pre><code>import argparse\nimport tensorflow as tf\n\ndef parse_command():\n    parser = argparse.ArgumentParser(description='Monitor Training Session Test.')\n    parser.add_argument('--job-name', dest='job_name', default=\"worker\", nargs='?', help='job name [worker|ps]')\n    parser.add_argument('--task-index', dest='task_index', type=int, default=0, help='task index')\n    return parser.parse_args()\n\nif __name__ == '__main__':\n    print(\"Test started...\")\n\n    cluster = {\n        \"ps\" : [\n             \"192.168.0.2:2221\",\n             \"192.168.0.1:2221\"\n             ],\n        \"worker\" : [\n             \"192.168.0.2:2222\",\n             \"192.168.0.1:2222\"\n             ]}\n\n    options = parse_command()\n    cluster_spec = tf.train.ClusterSpec(cluster)\n    server = tf.train.Server(server_or_cluster_def=cluster_spec,\n                             job_name=options.job_name,\n                             task_index=options.task_index)\n\n    if options.job_name == \"ps\":\n        server.join()\n        sys.exit(0)\n\n    is_chief = (options.task_index == 0)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.log_device_placement = True\n    step_size = 5\n\n    print(\"Running \" + options.job_name + \":\" + str(options.task_index))\n\n    with tf.device(tf.train.replica_device_setter(\n        worker_device = \"/job:worker/task:%d\" % options.task_index,\n        cluster = cluster_spec)) :\n\n        global_step = tf.train.get_or_create_global_step()\n        learning_rate = tf.train.exponential_decay(0.1, global_step, step_size, 0.94, staircase=True)\n\n        with tf.train.MonitoredTrainingSession(master=server.target,\n                                               is_chief=is_chief) as session:\n\n            print(\"MonitoredTrainingSession started\")\n\n            for i in range(10):\n                for j in range(step_size):\n                    lr, gstep = session.run([learning_rate, global_step])\n                    print(\"learning rate=\" + str(lr) + \", global step=\" + str(gstep))\n</code></pre>\n<p><strong>PC1 (GTX-1080) Logs</strong></p>\n<pre><code>...\nRunning worker:0\n2018-01-31 10:29:44.888497: I tensorflow/core/distributed_runtime/master_session.cc:1004] Start master session 9a6571b5ba45d49d with config:\nMonitoredTrainingSession started\nlearning rate=0.1, global step=0\nlearning rate=0.1, global step=0\nlearning rate=0.1, global step=0\n...\n</code></pre>\n<p><strong>PC2 (M2000) Logs</strong></p>\n<pre><code>...\n2018-01-31 10:29:37.753239: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222\nRunning worker:1\n(...wait for 1800 secs)\nMonitoredTrainingSession \"Session was not ready after waiting 1800 secs\"\n</code></pre>\n<p>I was using the <a href=\"https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer\" rel=\"nofollow\">tf.train.SyncReplicasOptimizer</a> example to implement between-graph and synchronous training but found that the non-chief worker has never printed <code>MonitoredTrainingSession started</code>. Then I slowly remove all the unnecessary code (which becomes the code provided above) and found that <code>tr.train.MonitoredTrainingSession</code> does not seem to work for the bare minimum configuration. Please can you kindly have a look?</p>\n<p>Many thanks!</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 17.10\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): v1.4.0-19-ga52c8d9 1.4.1\nPython version: 3.6.3\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 8\nGPU model and memory: GTX-1080 11GB (chief) and M2000 4GB (slave)\nExact command to reproduce:\nCUDA_VISIBLE_DEVICES='' python3 test.py --job-name ps --task-index 0\nCUDA_VISIBLE_DEVICES=0 python3 test.py --job-name worker --task-index 0\nCUDA_VISIBLE_DEVICES='' python3 test.py --job-name ps --task-index 1\nCUDA_VISIBLE_DEVICES=0 python3 test.py --job-name worker --task-index 1\n\nDescribe the problem\nI am trying to run the distributed training and use tf.train.MonitoredTrainingSession with 2 PCs. PC1 has one GTX-1080 11GB and is set as chief, while PC2 has one M2000 4GB and is set as non-chief. They are connected back-to-back without switch/router. The chief worker was running okay but the non-chief worker was stuck at tf.train.MonitoredTrainingSession and did not proceed to execute the code within the session.\nSource code / logs\nimport argparse\nimport tensorflow as tf\n\ndef parse_command():\n    parser = argparse.ArgumentParser(description='Monitor Training Session Test.')\n    parser.add_argument('--job-name', dest='job_name', default=\"worker\", nargs='?', help='job name [worker|ps]')\n    parser.add_argument('--task-index', dest='task_index', type=int, default=0, help='task index')\n    return parser.parse_args()\n\nif __name__ == '__main__':\n    print(\"Test started...\")\n\n    cluster = {\n        \"ps\" : [\n             \"192.168.0.2:2221\",\n             \"192.168.0.1:2221\"\n             ],\n        \"worker\" : [\n             \"192.168.0.2:2222\",\n             \"192.168.0.1:2222\"\n             ]}\n\n    options = parse_command()\n    cluster_spec = tf.train.ClusterSpec(cluster)\n    server = tf.train.Server(server_or_cluster_def=cluster_spec,\n                             job_name=options.job_name,\n                             task_index=options.task_index)\n\n    if options.job_name == \"ps\":\n        server.join()\n        sys.exit(0)\n\n    is_chief = (options.task_index == 0)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.log_device_placement = True\n    step_size = 5\n\n    print(\"Running \" + options.job_name + \":\" + str(options.task_index))\n\n    with tf.device(tf.train.replica_device_setter(\n        worker_device = \"/job:worker/task:%d\" % options.task_index,\n        cluster = cluster_spec)) :\n\n        global_step = tf.train.get_or_create_global_step()\n        learning_rate = tf.train.exponential_decay(0.1, global_step, step_size, 0.94, staircase=True)\n\n        with tf.train.MonitoredTrainingSession(master=server.target,\n                                               is_chief=is_chief) as session:\n\n            print(\"MonitoredTrainingSession started\")\n\n            for i in range(10):\n                for j in range(step_size):\n                    lr, gstep = session.run([learning_rate, global_step])\n                    print(\"learning rate=\" + str(lr) + \", global step=\" + str(gstep))\n\nPC1 (GTX-1080) Logs\n...\nRunning worker:0\n2018-01-31 10:29:44.888497: I tensorflow/core/distributed_runtime/master_session.cc:1004] Start master session 9a6571b5ba45d49d with config:\nMonitoredTrainingSession started\nlearning rate=0.1, global step=0\nlearning rate=0.1, global step=0\nlearning rate=0.1, global step=0\n...\n\nPC2 (M2000) Logs\n...\n2018-01-31 10:29:37.753239: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222\nRunning worker:1\n(...wait for 1800 secs)\nMonitoredTrainingSession \"Session was not ready after waiting 1800 secs\"\n\nI was using the tf.train.SyncReplicasOptimizer example to implement between-graph and synchronous training but found that the non-chief worker has never printed MonitoredTrainingSession started. Then I slowly remove all the unnecessary code (which becomes the code provided above) and found that tr.train.MonitoredTrainingSession does not seem to work for the bare minimum configuration. Please can you kindly have a look?\nMany thanks!", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8\r\n- **GPU model and memory**: GTX-1080 11GB (chief) and M2000 4GB (slave)\r\n- **Exact command to reproduce**:\r\nCUDA_VISIBLE_DEVICES='' python3 test.py --job-name ps --task-index 0\r\nCUDA_VISIBLE_DEVICES=0 python3 test.py --job-name worker --task-index 0\r\nCUDA_VISIBLE_DEVICES='' python3 test.py --job-name ps --task-index 1\r\nCUDA_VISIBLE_DEVICES=0 python3 test.py --job-name worker --task-index 1\r\n\r\n### Describe the problem\r\nI am trying to run the [distributed training](https://www.tensorflow.org/deploy/distributed) and use [tf.train.MonitoredTrainingSession](https://www.tensorflow.org/api_docs/python/tf/train/MonitoredTrainingSession) with 2 PCs. PC1 has one GTX-1080 11GB and is set as chief, while PC2 has one M2000 4GB and is set as non-chief. They are connected back-to-back without switch/router. The chief worker was running okay but the non-chief worker was stuck at `tf.train.MonitoredTrainingSession` and did not proceed to execute the code within the session.\r\n\r\n### Source code / logs\r\n```\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\ndef parse_command():\r\n    parser = argparse.ArgumentParser(description='Monitor Training Session Test.')\r\n    parser.add_argument('--job-name', dest='job_name', default=\"worker\", nargs='?', help='job name [worker|ps]')\r\n    parser.add_argument('--task-index', dest='task_index', type=int, default=0, help='task index')\r\n    return parser.parse_args()\r\n\r\nif __name__ == '__main__':\r\n    print(\"Test started...\")\r\n\r\n    cluster = {\r\n        \"ps\" : [\r\n             \"192.168.0.2:2221\",\r\n             \"192.168.0.1:2221\"\r\n             ],\r\n        \"worker\" : [\r\n             \"192.168.0.2:2222\",\r\n             \"192.168.0.1:2222\"\r\n             ]}\r\n\r\n    options = parse_command()\r\n    cluster_spec = tf.train.ClusterSpec(cluster)\r\n    server = tf.train.Server(server_or_cluster_def=cluster_spec,\r\n                             job_name=options.job_name,\r\n                             task_index=options.task_index)\r\n\r\n    if options.job_name == \"ps\":\r\n        server.join()\r\n        sys.exit(0)\r\n\r\n    is_chief = (options.task_index == 0)\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    config.log_device_placement = True\r\n    step_size = 5\r\n\r\n    print(\"Running \" + options.job_name + \":\" + str(options.task_index))\r\n\r\n    with tf.device(tf.train.replica_device_setter(\r\n        worker_device = \"/job:worker/task:%d\" % options.task_index,\r\n        cluster = cluster_spec)) :\r\n\r\n        global_step = tf.train.get_or_create_global_step()\r\n        learning_rate = tf.train.exponential_decay(0.1, global_step, step_size, 0.94, staircase=True)\r\n\r\n        with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                               is_chief=is_chief) as session:\r\n\r\n            print(\"MonitoredTrainingSession started\")\r\n\r\n            for i in range(10):\r\n                for j in range(step_size):\r\n                    lr, gstep = session.run([learning_rate, global_step])\r\n                    print(\"learning rate=\" + str(lr) + \", global step=\" + str(gstep))\r\n```\r\n\r\n**PC1 (GTX-1080) Logs**\r\n\r\n```\r\n...\r\nRunning worker:0\r\n2018-01-31 10:29:44.888497: I tensorflow/core/distributed_runtime/master_session.cc:1004] Start master session 9a6571b5ba45d49d with config:\r\nMonitoredTrainingSession started\r\nlearning rate=0.1, global step=0\r\nlearning rate=0.1, global step=0\r\nlearning rate=0.1, global step=0\r\n...\r\n```\r\n\r\n**PC2 (M2000) Logs**\r\n```\r\n...\r\n2018-01-31 10:29:37.753239: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222\r\nRunning worker:1\r\n(...wait for 1800 secs)\r\nMonitoredTrainingSession \"Session was not ready after waiting 1800 secs\"\r\n```\r\n\r\nI was using the [tf.train.SyncReplicasOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer) example to implement between-graph and synchronous training but found that the non-chief worker has never printed `MonitoredTrainingSession started`. Then I slowly remove all the unnecessary code (which becomes the code provided above) and found that `tr.train.MonitoredTrainingSession` does not seem to work for the bare minimum configuration. Please can you kindly have a look? \r\n\r\nMany thanks!"}