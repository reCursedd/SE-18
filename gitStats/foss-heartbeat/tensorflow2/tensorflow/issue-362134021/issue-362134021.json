{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22408", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22408/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22408/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22408/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22408", "id": 362134021, "node_id": "MDU6SXNzdWUzNjIxMzQwMjE=", "number": 22408, "title": "Tried to read from index 3 but array size is: 3", "user": {"login": "PanXiebit", "id": 24931560, "node_id": "MDQ6VXNlcjI0OTMxNTYw", "avatar_url": "https://avatars2.githubusercontent.com/u/24931560?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PanXiebit", "html_url": "https://github.com/PanXiebit", "followers_url": "https://api.github.com/users/PanXiebit/followers", "following_url": "https://api.github.com/users/PanXiebit/following{/other_user}", "gists_url": "https://api.github.com/users/PanXiebit/gists{/gist_id}", "starred_url": "https://api.github.com/users/PanXiebit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PanXiebit/subscriptions", "organizations_url": "https://api.github.com/users/PanXiebit/orgs", "repos_url": "https://api.github.com/users/PanXiebit/repos", "events_url": "https://api.github.com/users/PanXiebit/events{/privacy}", "received_events_url": "https://api.github.com/users/PanXiebit/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-09-20T11:00:12Z", "updated_at": "2018-09-29T03:00:10Z", "closed_at": "2018-09-29T03:00:10Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<p>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A<br>\nOS Platform and Distribution : Linux Ubuntu 16.04<br>\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A<br>\nTensorFlow installed from (source or binary): N/A<br>\nTensorFlow version (use command below): N/A<br>\nPython version: 3.6<br>\nBazel version (if compiling from source): N/A<br>\nGCC/Compiler version (if compiling from source): N/A<br>\nCUDA/cuDNN version: 8.0<br>\nGPU model and memory: N/A<br>\nExact command to reproduce: N/A</p>\n<h3>Describe the problem\uff1a</h3>\n<p>Hi,<br>\nwhen I am using the tf.data.dataset api, I meet the error, and i am confused.</p>\n<p>the error is :<br>\n<code>InvalidArgumentError (see above for traceback): Tried to read from index 3 but array size is: 3</code></p>\n<p>and my related code is:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">train_input</span>(<span class=\"pl-smi\">sess</span>, <span class=\"pl-smi\">vocab</span>, <span class=\"pl-smi\">rcmodel</span>, <span class=\"pl-smi\">train_or_valid</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>):\n    train_dataset <span class=\"pl-k\">=</span> get_dataset(vocab.word2idx, <span class=\"pl-c1\">FLAGS</span>.train_tfrecord_file, <span class=\"pl-c1\">FLAGS</span>.train_batch_size,\n                                <span class=\"pl-v\">repeat_num</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.num_epochs, <span class=\"pl-v\">shuffle_bufer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">500</span>, <span class=\"pl-v\">prefetch</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n    valid_dataset <span class=\"pl-k\">=</span> get_dataset(vocab.word2idx, <span class=\"pl-c1\">FLAGS</span>.valid_tfrecord_file, <span class=\"pl-c1\">FLAGS</span>.valid_batch_size,\n                                <span class=\"pl-v\">repeat_num</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">shuffle_bufer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">500</span>)\n    train_iterator <span class=\"pl-k\">=</span> train_dataset.make_initializable_iterator()\n    valid_iterator <span class=\"pl-k\">=</span> valid_dataset.make_initializable_iterator()\n    <span class=\"pl-k\">if</span> train_or_valid:\n        data_handle <span class=\"pl-k\">=</span> sess.run(train_iterator.string_handle())\n        sess.run(train_iterator.initializer)\n    <span class=\"pl-k\">else</span>:\n        data_handle <span class=\"pl-k\">=</span> sess.run(valid_iterator.string_handle())\n        sess.run(valid_iterator.initializer)\n        \n    data_iter <span class=\"pl-k\">=</span> tf.data.Iterator.from_string_handle(<span class=\"pl-v\">string_handle</span><span class=\"pl-k\">=</span>data_handle,\n                                                    <span class=\"pl-v\">output_types</span><span class=\"pl-k\">=</span>train_dataset.output_types,\n                                                    <span class=\"pl-v\">output_shapes</span><span class=\"pl-k\">=</span>train_dataset.output_shapes)\n\n    batch_data <span class=\"pl-k\">=</span> data_iter.get_next()\n    feed_data <span class=\"pl-k\">=</span> {rcmodel.passage: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>passage<span class=\"pl-pds\">\"</span></span>].eval(),\n                 rcmodel.passage_len: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>passage_len<span class=\"pl-pds\">\"</span></span>].eval(),\n                 rcmodel.query: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>query<span class=\"pl-pds\">\"</span></span>].eval(),\n                 rcmodel.query_len: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>query_len<span class=\"pl-pds\">\"</span></span>].eval(),\n                 <span class=\"pl-c\"><span class=\"pl-c\">#</span> rcmodel.query_id: batch_data[\"query_id\"],</span>\n                 rcmodel.answer: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>answer<span class=\"pl-pds\">'</span></span>].eval(),\n                 rcmodel.answer_len: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>answer_len<span class=\"pl-pds\">\"</span></span>].eval(),\n                 rcmodel.alter0: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>alter0<span class=\"pl-pds\">\"</span></span>].eval(),\n                 rcmodel.alter1: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>alter1<span class=\"pl-pds\">\"</span></span>].eval(),\n                 rcmodel.alter2: batch_data[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>alter2<span class=\"pl-pds\">\"</span></span>].eval()}\n    <span class=\"pl-k\">return</span> feed_data</pre></div>\n<div class=\"highlight highlight-source-python\"><pre>train_feed <span class=\"pl-k\">=</span> train_input(sess, vocab, rcmodel, <span class=\"pl-c1\">True</span>)\ntrain_feed[rcmodel.dropout_keep_prob] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.dropout_keep_prob\ntrain_summary, _, train_loss, train_ppl_loss, train_acc, step, predict, logits, answer, embedding <span class=\"pl-k\">=</span> sess.run(\n                   [merged, rcmodel.train_op, rcmodel.total_loss, rcmodel.ppl_loss,\n                    rcmodel.accuracy, rcmodel.global_step, rcmodel.predict, rcmodel.logits,\n                    rcmodel.answer, rcmodel.word_embedding],\n                   <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>train_feed)</pre></div>\n<p>I know the error is caused by that: when I try to use<br>\n<code>sess.run(fetches, feed_dict={passage:data_iter[\"passage}, query:data_iter['passage_len'])</code></p>\n<p><code>passage:data_iter[\"passage\"]</code> consumed a batch, and <code>query:data_iter[\"passage_len\"]</code> consumed an other batch. So the data pasage and passage_len is not match.</p>\n<p>So the reason is that when I sess.run one of the content of batch_iter, it will consume one batch. And I know using the string_handle can solve this problem.</p>\n<p>But when I need to do this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">self</span>.passage <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>passage<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.query <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>query<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.answer <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>answer<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.passage_len <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>passage_len<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.query_len <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>query_len<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.query_id <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>query_id<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.answer_len <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>answer_len<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.alter0 <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>alter0<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.alter1 <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>alter1<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">self</span>.alter2 <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>alter2<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p>What can I do to feed this?</p>", "body_text": "System information\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\nOS Platform and Distribution : Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): N/A\nTensorFlow version (use command below): N/A\nPython version: 3.6\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 8.0\nGPU model and memory: N/A\nExact command to reproduce: N/A\nDescribe the problem\uff1a\nHi,\nwhen I am using the tf.data.dataset api, I meet the error, and i am confused.\nthe error is :\nInvalidArgumentError (see above for traceback): Tried to read from index 3 but array size is: 3\nand my related code is:\ndef train_input(sess, vocab, rcmodel, train_or_valid=True):\n    train_dataset = get_dataset(vocab.word2idx, FLAGS.train_tfrecord_file, FLAGS.train_batch_size,\n                                repeat_num=FLAGS.num_epochs, shuffle_bufer=500, prefetch=-1)\n    valid_dataset = get_dataset(vocab.word2idx, FLAGS.valid_tfrecord_file, FLAGS.valid_batch_size,\n                                repeat_num=-1, shuffle_bufer=500)\n    train_iterator = train_dataset.make_initializable_iterator()\n    valid_iterator = valid_dataset.make_initializable_iterator()\n    if train_or_valid:\n        data_handle = sess.run(train_iterator.string_handle())\n        sess.run(train_iterator.initializer)\n    else:\n        data_handle = sess.run(valid_iterator.string_handle())\n        sess.run(valid_iterator.initializer)\n        \n    data_iter = tf.data.Iterator.from_string_handle(string_handle=data_handle,\n                                                    output_types=train_dataset.output_types,\n                                                    output_shapes=train_dataset.output_shapes)\n\n    batch_data = data_iter.get_next()\n    feed_data = {rcmodel.passage: batch_data[\"passage\"].eval(),\n                 rcmodel.passage_len: batch_data[\"passage_len\"].eval(),\n                 rcmodel.query: batch_data[\"query\"].eval(),\n                 rcmodel.query_len: batch_data[\"query_len\"].eval(),\n                 # rcmodel.query_id: batch_data[\"query_id\"],\n                 rcmodel.answer: batch_data['answer'].eval(),\n                 rcmodel.answer_len: batch_data[\"answer_len\"].eval(),\n                 rcmodel.alter0: batch_data[\"alter0\"].eval(),\n                 rcmodel.alter1: batch_data[\"alter1\"].eval(),\n                 rcmodel.alter2: batch_data[\"alter2\"].eval()}\n    return feed_data\ntrain_feed = train_input(sess, vocab, rcmodel, True)\ntrain_feed[rcmodel.dropout_keep_prob] = FLAGS.dropout_keep_prob\ntrain_summary, _, train_loss, train_ppl_loss, train_acc, step, predict, logits, answer, embedding = sess.run(\n                   [merged, rcmodel.train_op, rcmodel.total_loss, rcmodel.ppl_loss,\n                    rcmodel.accuracy, rcmodel.global_step, rcmodel.predict, rcmodel.logits,\n                    rcmodel.answer, rcmodel.word_embedding],\n                   feed_dict=train_feed)\nI know the error is caused by that: when I try to use\nsess.run(fetches, feed_dict={passage:data_iter[\"passage}, query:data_iter['passage_len'])\npassage:data_iter[\"passage\"] consumed a batch, and query:data_iter[\"passage_len\"] consumed an other batch. So the data pasage and passage_len is not match.\nSo the reason is that when I sess.run one of the content of batch_iter, it will consume one batch. And I know using the string_handle can solve this problem.\nBut when I need to do this:\nself.passage = tf.placeholder(tf.int32, [None, None], name=\"passage\")\nself.query = tf.placeholder(tf.int32, [None, None], name=\"query\")\nself.answer = tf.placeholder(tf.int32, [None, None], name=\"answer\")\nself.passage_len = tf.placeholder(tf.int32, [None], name=\"passage_len\")\nself.query_len = tf.placeholder(tf.int32, [None], name=\"query_len\")\nself.query_id = tf.placeholder(tf.int32, [None], name=\"query_id\")\nself.answer_len = tf.placeholder(tf.int32, [None], name=\"answer_len\")\nself.alter0 = tf.placeholder(tf.int32, [None, None], name=\"alter0\")\nself.alter1 = tf.placeholder(tf.int32, [None, None], name=\"alter1\")\nself.alter2 = tf.placeholder(tf.int32, [None, None], name=\"alter2\")\nWhat can I do to feed this?", "body": "### System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\nOS Platform and Distribution : Linux Ubuntu 16.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\nTensorFlow installed from (source or binary): N/A\r\nTensorFlow version (use command below): N/A\r\nPython version: 3.6\r\nBazel version (if compiling from source): N/A\r\nGCC/Compiler version (if compiling from source): N/A\r\nCUDA/cuDNN version: 8.0\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A\r\n\r\n### Describe the problem\uff1a\r\n\r\nHi, \r\nwhen I am using the tf.data.dataset api, I meet the error, and i am confused. \r\n\r\nthe error is :\r\n`InvalidArgumentError (see above for traceback): Tried to read from index 3 but array size is: 3`\r\n\r\nand my related code is:\r\n\r\n```python\r\ndef train_input(sess, vocab, rcmodel, train_or_valid=True):\r\n    train_dataset = get_dataset(vocab.word2idx, FLAGS.train_tfrecord_file, FLAGS.train_batch_size,\r\n                                repeat_num=FLAGS.num_epochs, shuffle_bufer=500, prefetch=-1)\r\n    valid_dataset = get_dataset(vocab.word2idx, FLAGS.valid_tfrecord_file, FLAGS.valid_batch_size,\r\n                                repeat_num=-1, shuffle_bufer=500)\r\n    train_iterator = train_dataset.make_initializable_iterator()\r\n    valid_iterator = valid_dataset.make_initializable_iterator()\r\n    if train_or_valid:\r\n        data_handle = sess.run(train_iterator.string_handle())\r\n        sess.run(train_iterator.initializer)\r\n    else:\r\n        data_handle = sess.run(valid_iterator.string_handle())\r\n        sess.run(valid_iterator.initializer)\r\n        \r\n    data_iter = tf.data.Iterator.from_string_handle(string_handle=data_handle,\r\n                                                    output_types=train_dataset.output_types,\r\n                                                    output_shapes=train_dataset.output_shapes)\r\n\r\n    batch_data = data_iter.get_next()\r\n    feed_data = {rcmodel.passage: batch_data[\"passage\"].eval(),\r\n                 rcmodel.passage_len: batch_data[\"passage_len\"].eval(),\r\n                 rcmodel.query: batch_data[\"query\"].eval(),\r\n                 rcmodel.query_len: batch_data[\"query_len\"].eval(),\r\n                 # rcmodel.query_id: batch_data[\"query_id\"],\r\n                 rcmodel.answer: batch_data['answer'].eval(),\r\n                 rcmodel.answer_len: batch_data[\"answer_len\"].eval(),\r\n                 rcmodel.alter0: batch_data[\"alter0\"].eval(),\r\n                 rcmodel.alter1: batch_data[\"alter1\"].eval(),\r\n                 rcmodel.alter2: batch_data[\"alter2\"].eval()}\r\n    return feed_data\r\n```\r\n\r\n```python\r\ntrain_feed = train_input(sess, vocab, rcmodel, True)\r\ntrain_feed[rcmodel.dropout_keep_prob] = FLAGS.dropout_keep_prob\r\ntrain_summary, _, train_loss, train_ppl_loss, train_acc, step, predict, logits, answer, embedding = sess.run(\r\n                   [merged, rcmodel.train_op, rcmodel.total_loss, rcmodel.ppl_loss,\r\n                    rcmodel.accuracy, rcmodel.global_step, rcmodel.predict, rcmodel.logits,\r\n                    rcmodel.answer, rcmodel.word_embedding],\r\n                   feed_dict=train_feed)\r\n```\r\n\r\nI know the error is caused by that: when I try to use \r\n```sess.run(fetches, feed_dict={passage:data_iter[\"passage}, query:data_iter['passage_len'])```\r\n\r\n```passage:data_iter[\"passage\"]``` consumed a batch, and ```query:data_iter[\"passage_len\"]``` consumed an other batch. So the data pasage and passage_len is not match.\r\n\r\nSo the reason is that when I sess.run one of the content of batch_iter, it will consume one batch. And I know using the string_handle can solve this problem. \r\n\r\nBut when I need to do this:\r\n```python\r\nself.passage = tf.placeholder(tf.int32, [None, None], name=\"passage\")\r\nself.query = tf.placeholder(tf.int32, [None, None], name=\"query\")\r\nself.answer = tf.placeholder(tf.int32, [None, None], name=\"answer\")\r\nself.passage_len = tf.placeholder(tf.int32, [None], name=\"passage_len\")\r\nself.query_len = tf.placeholder(tf.int32, [None], name=\"query_len\")\r\nself.query_id = tf.placeholder(tf.int32, [None], name=\"query_id\")\r\nself.answer_len = tf.placeholder(tf.int32, [None], name=\"answer_len\")\r\nself.alter0 = tf.placeholder(tf.int32, [None, None], name=\"alter0\")\r\nself.alter1 = tf.placeholder(tf.int32, [None, None], name=\"alter1\")\r\nself.alter2 = tf.placeholder(tf.int32, [None, None], name=\"alter2\")\r\n```\r\n\r\nWhat can I do to feed this?\r\n\r\n"}