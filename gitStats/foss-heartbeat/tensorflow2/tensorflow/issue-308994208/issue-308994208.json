{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18016", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18016/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18016/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18016/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18016", "id": 308994208, "node_id": "MDU6SXNzdWUzMDg5OTQyMDg=", "number": 18016, "title": "Feature: evaluating multiple datasets in tf.estimator.Estimator.evaluate without reloading checkpoint", "user": {"login": "cvanweelden", "id": 550080, "node_id": "MDQ6VXNlcjU1MDA4MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/550080?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cvanweelden", "html_url": "https://github.com/cvanweelden", "followers_url": "https://api.github.com/users/cvanweelden/followers", "following_url": "https://api.github.com/users/cvanweelden/following{/other_user}", "gists_url": "https://api.github.com/users/cvanweelden/gists{/gist_id}", "starred_url": "https://api.github.com/users/cvanweelden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cvanweelden/subscriptions", "organizations_url": "https://api.github.com/users/cvanweelden/orgs", "repos_url": "https://api.github.com/users/cvanweelden/repos", "events_url": "https://api.github.com/users/cvanweelden/events{/privacy}", "received_events_url": "https://api.github.com/users/cvanweelden/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-03-27T14:29:21Z", "updated_at": "2018-08-05T14:10:24Z", "closed_at": "2018-04-11T21:35:17Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Fedora release 25 (Twenty Five)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary for CPU</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.6.0-0-gd2e24b6039</li>\n<li><strong>Python version</strong>: 3.5.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>We have several datasets on which we want to track performance during training, corresponding to multiple data splits or different types of data that are processed by the model. To do this we run <code>Estimator.evaluate</code> for each dataset after each epoch of training.</p>\n<p>The problem with this is that <code>Estimator.evaluate</code> reconstructs the graph and loads the variables from checkpoint each time that it is called. In our case, reconstructing the large graph takes longer than doing the evaluation on the relatively small datasets. I'd propose a feature to allow evaluating on multiple datasets without reloading the graph.</p>\n<p>Ideas:</p>\n<ul>\n<li>Add an <code>Estimator.evaluate_multiple</code> method that takes a mapping from name to input_fn.</li>\n<li>Add functionality to explicitly start an evaluation session for an estimator and allow passing this as input to <code>Estimator.evaluate</code></li>\n</ul>\n<h3>Source code / logs</h3>\n<pre><code>model = Estimator(my_model_fn)\nfor epoch in range(n_epochs):\n  estimator.train(train_input_fn, steps=n_steps_per_epoch)\n  for name, eval_input_fn in eval_datasets:\n    # eval_input_fn create one shot iterators\n    estimator.evaluate(eval_input_fn, name=name)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora release 25 (Twenty Five)\nTensorFlow installed from (source or binary): binary for CPU\nTensorFlow version (use command below): v1.6.0-0-gd2e24b6039\nPython version: 3.5.5\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A\n\nDescribe the problem\nWe have several datasets on which we want to track performance during training, corresponding to multiple data splits or different types of data that are processed by the model. To do this we run Estimator.evaluate for each dataset after each epoch of training.\nThe problem with this is that Estimator.evaluate reconstructs the graph and loads the variables from checkpoint each time that it is called. In our case, reconstructing the large graph takes longer than doing the evaluation on the relatively small datasets. I'd propose a feature to allow evaluating on multiple datasets without reloading the graph.\nIdeas:\n\nAdd an Estimator.evaluate_multiple method that takes a mapping from name to input_fn.\nAdd functionality to explicitly start an evaluation session for an estimator and allow passing this as input to Estimator.evaluate\n\nSource code / logs\nmodel = Estimator(my_model_fn)\nfor epoch in range(n_epochs):\n  estimator.train(train_input_fn, steps=n_steps_per_epoch)\n  for name, eval_input_fn in eval_datasets:\n    # eval_input_fn create one shot iterators\n    estimator.evaluate(eval_input_fn, name=name)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora release 25 (Twenty Five)\r\n- **TensorFlow installed from (source or binary)**: binary for CPU\r\n- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039\r\n- **Python version**: 3.5.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nWe have several datasets on which we want to track performance during training, corresponding to multiple data splits or different types of data that are processed by the model. To do this we run `Estimator.evaluate` for each dataset after each epoch of training.\r\n\r\nThe problem with this is that `Estimator.evaluate` reconstructs the graph and loads the variables from checkpoint each time that it is called. In our case, reconstructing the large graph takes longer than doing the evaluation on the relatively small datasets. I'd propose a feature to allow evaluating on multiple datasets without reloading the graph.\r\n\r\nIdeas:\r\n- Add an `Estimator.evaluate_multiple` method that takes a mapping from name to input_fn.\r\n- Add functionality to explicitly start an evaluation session for an estimator and allow passing this as input to `Estimator.evaluate`\r\n\r\n### Source code / logs\r\n```\r\nmodel = Estimator(my_model_fn)\r\nfor epoch in range(n_epochs):\r\n  estimator.train(train_input_fn, steps=n_steps_per_epoch)\r\n  for name, eval_input_fn in eval_datasets:\r\n    # eval_input_fn create one shot iterators\r\n    estimator.evaluate(eval_input_fn, name=name)\r\n```\r\n\r\n"}