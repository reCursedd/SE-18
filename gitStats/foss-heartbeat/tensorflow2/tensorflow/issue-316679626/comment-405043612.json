{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/405043612", "html_url": "https://github.com/tensorflow/tensorflow/issues/18789#issuecomment-405043612", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18789", "id": 405043612, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNTA0MzYxMg==", "user": {"login": "bjacob", "id": 79535, "node_id": "MDQ6VXNlcjc5NTM1", "avatar_url": "https://avatars1.githubusercontent.com/u/79535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjacob", "html_url": "https://github.com/bjacob", "followers_url": "https://api.github.com/users/bjacob/followers", "following_url": "https://api.github.com/users/bjacob/following{/other_user}", "gists_url": "https://api.github.com/users/bjacob/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjacob/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjacob/subscriptions", "organizations_url": "https://api.github.com/users/bjacob/orgs", "repos_url": "https://api.github.com/users/bjacob/repos", "events_url": "https://api.github.com/users/bjacob/events{/privacy}", "received_events_url": "https://api.github.com/users/bjacob/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-14T19:08:36Z", "updated_at": "2018-07-14T19:14:55Z", "author_association": "NONE", "body_html": "<p>The 1x1 kernel case is by far the most important case of Conv. For example, in MobileNets, all Conv nodes have 1x1 kernels.</p>\n<p>The 1x1 kernel case of Conv is the case that is, literally, a matrix multiplication, i.e. is not at all 'convolutional'  (so the whole terminology here is misleading).  Other cases can be reduced to matrix-multiplication with some work, but that 1x1 case does not even require any such reduction work, it is literaly a mat-mul.</p>\n<p>TensorFlow Lite uses specialist libraries to provide the matrix multiplication implementation:</p>\n<ul>\n<li>in floating-point inference, the Eigen library is used:<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/85aae3795775bf648d2e8baa56331f952d12e3e0/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h#L1996\">tensorflow/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 1996\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/85aae3795775bf648d2e8baa56331f952d12e3e0\">85aae37</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L1996\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1996\"></td>\n          <td id=\"LC1996\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c1\">Gemm</span>(filter_matrix_map.<span class=\"pl-c1\">transpose</span>(), im2col_matrix_map, &amp;output_matrix_map); </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</li>\n<li>in quantized inference, the gemmlowp library is used:<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/85aae3795775bf648d2e8baa56331f952d12e3e0/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h#L2122\">tensorflow/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 2122\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/85aae3795775bf648d2e8baa56331f952d12e3e0\">85aae37</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L2122\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2122\"></td>\n          <td id=\"LC2122\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> gemmlowp::GemmWithOutputPipeline&lt;uint8, uint8, </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</li>\n</ul>\n<p>Both of these libraries have NEON-optimized paths.</p>", "body_text": "The 1x1 kernel case is by far the most important case of Conv. For example, in MobileNets, all Conv nodes have 1x1 kernels.\nThe 1x1 kernel case of Conv is the case that is, literally, a matrix multiplication, i.e. is not at all 'convolutional'  (so the whole terminology here is misleading).  Other cases can be reduced to matrix-multiplication with some work, but that 1x1 case does not even require any such reduction work, it is literaly a mat-mul.\nTensorFlow Lite uses specialist libraries to provide the matrix multiplication implementation:\n\nin floating-point inference, the Eigen library is used:\n\n  \n    \n      tensorflow/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h\n    \n    \n         Line 1996\n      in\n      85aae37\n    \n    \n    \n    \n\n        \n          \n           Gemm(filter_matrix_map.transpose(), im2col_matrix_map, &output_matrix_map); \n        \n    \n  \n\n\nin quantized inference, the gemmlowp library is used:\n\n  \n    \n      tensorflow/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h\n    \n    \n         Line 2122\n      in\n      85aae37\n    \n    \n    \n    \n\n        \n          \n           gemmlowp::GemmWithOutputPipeline<uint8, uint8, \n        \n    \n  \n\n\n\nBoth of these libraries have NEON-optimized paths.", "body": "The 1x1 kernel case is by far the most important case of Conv. For example, in MobileNets, all Conv nodes have 1x1 kernels.\r\n\r\nThe 1x1 kernel case of Conv is the case that is, literally, a matrix multiplication, i.e. is not at all 'convolutional'  (so the whole terminology here is misleading).  Other cases can be reduced to matrix-multiplication with some work, but that 1x1 case does not even require any such reduction work, it is literaly a mat-mul.\r\n\r\nTensorFlow Lite uses specialist libraries to provide the matrix multiplication implementation:\r\n - in floating-point inference, the Eigen library is used:\r\nhttps://github.com/tensorflow/tensorflow/blob/85aae3795775bf648d2e8baa56331f952d12e3e0/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h#L1996\r\n  - in quantized inference, the gemmlowp library is used:\r\nhttps://github.com/tensorflow/tensorflow/blob/85aae3795775bf648d2e8baa56331f952d12e3e0/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h#L2122\r\n\r\nBoth of these libraries have NEON-optimized paths."}