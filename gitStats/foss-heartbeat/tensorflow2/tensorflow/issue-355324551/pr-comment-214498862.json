{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/214498862", "pull_request_review_id": 151576078, "id": 214498862, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNDQ5ODg2Mg==", "diff_hunk": "@@ -375,17 +327,18 @@ void CalculateDimensionality(const DeviceDescription &device_description,\n // Compute and return maximum blocks per core (occupancy) based on the\n // device description, some kernel characteristics and the number of threads per\n // block.  If unable to compute occupancy, zero is returned.\n-uint64 CalculateOccupancy(const DeviceDescription &device_description,\n-                          uint64 registers_per_thread,\n-                          uint64 shared_memory_per_block,\n-                          const ThreadDim &thread_dims);\n-\n-// Compute and return the maximum number of registers per thread which\n-// achieves the target occupancy.  If the target is not possible then\n-// zero is returned.\n-uint64 CalculateRegisterLimitForTargetOccupancy(\n-    const DeviceDescription &device_description, uint64 shared_memory_per_block,\n-    const ThreadDim &thread_dims, uint64 target_blocks_per_core);\n+int CalculateOccupancy(const DeviceDescription& device_description,\n+                       uint64 registers_per_thread,\n+                       uint64 shared_memory_per_block,\n+                       const ThreadDim& thread_dims, CUfunction func);\n+\n+// Compute and return the suggested thread count to acheive ideal occupancy.\n+// If the provided thread dimensions match this number, zero is returned.\n+int CompareOccupancy(int* initial_blocks,\n+                     const DeviceDescription& device_description,\n+                     uint64 registers_per_thread,\n+                     uint64 shared_memory_per_block,\n+                     const ThreadDim& thread_dims, CUfunction func);", "path": "tensorflow/stream_executor/device_description.h", "position": null, "original_position": 124, "commit_id": "6a5090b086bc9d665eb9e65f05eb94cdb58baaa2", "original_commit_id": "e93a9f9ccfd9c7a2419bf3fc1d7866765bbcfce3", "user": {"login": "jlebar", "id": 150663, "node_id": "MDQ6VXNlcjE1MDY2Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/150663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlebar", "html_url": "https://github.com/jlebar", "followers_url": "https://api.github.com/users/jlebar/followers", "following_url": "https://api.github.com/users/jlebar/following{/other_user}", "gists_url": "https://api.github.com/users/jlebar/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlebar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlebar/subscriptions", "organizations_url": "https://api.github.com/users/jlebar/orgs", "repos_url": "https://api.github.com/users/jlebar/repos", "events_url": "https://api.github.com/users/jlebar/events{/privacy}", "received_events_url": "https://api.github.com/users/jlebar/received_events", "type": "User", "site_admin": false}, "body": "This file is and these functions are platform-independent.  But the implementations of them are platform-*de*pendent.  So if anyone calls CalculateOccupancy they're going to get the wrong answer (or a crash) if they're not using CUDA.  In fact one were to build without CUDA support, StreamExecutor won't even link, as I read this.\r\n\r\nThis needs to be done somehow in a platform-independent way.", "created_at": "2018-09-01T00:30:16Z", "updated_at": "2018-09-06T20:09:45Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21958#discussion_r214498862", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21958", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/214498862"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21958#discussion_r214498862"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21958"}}, "body_html": "<p>This file is and these functions are platform-independent.  But the implementations of them are platform-<em>de</em>pendent.  So if anyone calls CalculateOccupancy they're going to get the wrong answer (or a crash) if they're not using CUDA.  In fact one were to build without CUDA support, StreamExecutor won't even link, as I read this.</p>\n<p>This needs to be done somehow in a platform-independent way.</p>", "body_text": "This file is and these functions are platform-independent.  But the implementations of them are platform-dependent.  So if anyone calls CalculateOccupancy they're going to get the wrong answer (or a crash) if they're not using CUDA.  In fact one were to build without CUDA support, StreamExecutor won't even link, as I read this.\nThis needs to be done somehow in a platform-independent way."}