{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7311", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7311/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7311/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7311/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7311", "id": 205768541, "node_id": "MDU6SXNzdWUyMDU3Njg1NDE=", "number": 7311, "title": "tfrecords giving parsing error when saved examples are too big", "user": {"login": "loliverhennigh", "id": 4978408, "node_id": "MDQ6VXNlcjQ5Nzg0MDg=", "avatar_url": "https://avatars1.githubusercontent.com/u/4978408?v=4", "gravatar_id": "", "url": "https://api.github.com/users/loliverhennigh", "html_url": "https://github.com/loliverhennigh", "followers_url": "https://api.github.com/users/loliverhennigh/followers", "following_url": "https://api.github.com/users/loliverhennigh/following{/other_user}", "gists_url": "https://api.github.com/users/loliverhennigh/gists{/gist_id}", "starred_url": "https://api.github.com/users/loliverhennigh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/loliverhennigh/subscriptions", "organizations_url": "https://api.github.com/users/loliverhennigh/orgs", "repos_url": "https://api.github.com/users/loliverhennigh/repos", "events_url": "https://api.github.com/users/loliverhennigh/events{/privacy}", "received_events_url": "https://api.github.com/users/loliverhennigh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-02-07T02:34:28Z", "updated_at": "2017-04-24T22:00:49Z", "closed_at": "2017-04-24T22:00:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>When I try to save a example to a tfrecord that is too large a parsing error occurs. I need to save a large sequence of float valued images (states of a fluid flow simulation) and when the states and sequences get too large a parsing error occurs.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>I think that this might be the same error and problem that other people are getting when saving long sequences to tfrecords like seen here <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"185627666\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5234\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5234/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5234\">#5234</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"184889774\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/OliviaMG/xiaomeng/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/OliviaMG/xiaomeng/issues/1/hovercard\" href=\"https://github.com/OliviaMG/xiaomeng/issues/1\">OliviaMG/xiaomeng#1</a>. While both of these threads found solutions the underlining problem does not seem to be found.</p>\n<h3>Environment info</h3>\n<p>Operating System:</p>\n<p>Ubuntu 16.04<br>\nCUDA 8.0<br>\nCUDNN 5.1<br>\nTensorFlow 0.12.1</p>\n<h3>If possible, provide a minimal reproducible example</h3>\n<p>Running this minimal script will cause the error. Lowering the <code>SIZE_RECORD</code> value will cause the script to run with out error.</p>\n<pre><code>from tqdm import tqdm\nimport numpy as np\nimport tensorflow as tf\n\n# this will kill it\nSIZE_RECORD=20000000\n# this will run just fine\n# SIZE_RECORD=2000000\n\nwriter = tf.python_io.TFRecordWriter(\"test.tfrecords\")\n# iterate over 10 times\n# wrap with tqdm for a progress bar\nfor example_idx in tqdm(xrange(2)):\n    features = np.zeros((SIZE_RECORD))\n\n    # construct the Example proto boject\n    example = tf.train.Example(\n        # Example contains a Features proto object\n        features=tf.train.Features(\n          # Features contains a map of string to Feature proto objects\n          feature={\n            # A Feature contains one of either a int64_list,\n            # float_list, or bytes_list\n            'image': tf.train.Feature(\n                float_list=tf.train.FloatList(value=features.astype(\"float\"))),\n    }))\n    # use the proto object to serialize the example to a string\n    serialized = example.SerializeToString()\n    # write the serialized object to disk\n    writer.write(serialized)\nwriter.close()\n\ndef read_and_decode_single_example(filename):\n    # first construct a queue containing a list of filenames.\n    # this lets a user split up there dataset in multiple files to keep\n    # size down\n    filename_queue = tf.train.string_input_producer([filename],\n                                                    num_epochs=None)\n    # Unlike the TFRecordWriter, the TFRecordReader is symbolic\n    reader = tf.TFRecordReader()\n    # One can read a single serialized example from a filename\n    # serialized_example is a Tensor of type string.\n    _, serialized_example = reader.read(filename_queue)\n    # The serialized example is converted back to actual values.\n    # One needs to describe the format of the objects to be returned\n    features = tf.parse_single_example(\n        serialized_example,\n        features={\n            # We know the length of both fields. If not the\n            # tf.VarLenFeature could be used\n            'image': tf.FixedLenFeature([SIZE_RECORD], tf.float32)\n        })\n    # now return the converted data\n    image = features['image']\n    return image\n\n# get single examples\nimage = read_and_decode_single_example(\"test.tfrecords\")\n# groups examples into batches randomly\nimages_batch = tf.train.shuffle_batch(\n    [image], batch_size=1,\n    capacity=3,\n    min_after_dequeue=2)\n\n# simple model\nw = tf.get_variable(\"w1\", [SIZE_RECORD, 1])\ny_pred = tf.matmul(images_batch, w)\nloss = tf.nn.l2_loss(y_pred - 1.0)\n\n# for monitoring\nloss_mean = tf.reduce_mean(loss)\n\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\n\nsess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)\ntf.train.start_queue_runners(sess=sess)\n\n_, loss_val = sess.run([train_op, loss_mean])\nprint loss_val\nprint(\"worked!!!\")\n</code></pre>\n<h3>What other attempted solutions have you tried?</h3>\n<p>I have tried saving the example in a variety of different ways including converting it to a string and breaking up the vector into multiple features.</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>This is the output when the tfrecord is too big</p>\n<p>W tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Could not parse example input, value: '<br>\n\ufffd\ufffd\ufffd&amp;<br>\n\ufffd\ufffd\ufffd&amp;<br>\nimage\ufffd\ufffd\ufffd\ufffd&amp;\ufffd\ufffd\ufffd\ufffd&amp;<br>\n\ufffd\ufffd\ufffd&amp;<br>\nERROR:tensorflow:Exception in QueueRunner: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte<br>\nException in thread Thread-3:<br>\nTraceback (most recent call last):<br>\nFile \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner<br>\nself.run()<br>\nFile \"/usr/lib/python2.7/threading.py\", line 754, in run<br>\nself.__target(*self.__args, **self.__kwargs)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 234, in _run<br>\nsess.run(enqueue_op)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run<br>\nfeed_dict_string, options, run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run<br>\ntarget_list, options, run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1021, in _do_call<br>\nreturn fn(*args)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn<br>\nstatus, run_metadata)<br>\nFile \"/usr/lib/python2.7/contextlib.py\", line 24, in <strong>exit</strong><br>\nself.gen.next()<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 468, in raise_exception_on_not_ok_status<br>\ncompat.as_text(pywrap_tensorflow.TF_Message(status)),<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/compat.py\", line 84, in as_text<br>\nreturn bytes_or_text.decode(encoding)<br>\nFile \"/usr/lib/python2.7/encodings/utf_8.py\", line 16, in decode<br>\nreturn codecs.utf_8_decode(input, errors, True)<br>\nUnicodeDecodeError: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte</p>\n<p>Thank!!!</p>", "body_text": "When I try to save a example to a tfrecord that is too large a parsing error occurs. I need to save a large sequence of float valued images (states of a fluid flow simulation) and when the states and sequences get too large a parsing error occurs.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nI think that this might be the same error and problem that other people are getting when saving long sequences to tfrecords like seen here #5234 and OliviaMG/xiaomeng#1. While both of these threads found solutions the underlining problem does not seem to be found.\nEnvironment info\nOperating System:\nUbuntu 16.04\nCUDA 8.0\nCUDNN 5.1\nTensorFlow 0.12.1\nIf possible, provide a minimal reproducible example\nRunning this minimal script will cause the error. Lowering the SIZE_RECORD value will cause the script to run with out error.\nfrom tqdm import tqdm\nimport numpy as np\nimport tensorflow as tf\n\n# this will kill it\nSIZE_RECORD=20000000\n# this will run just fine\n# SIZE_RECORD=2000000\n\nwriter = tf.python_io.TFRecordWriter(\"test.tfrecords\")\n# iterate over 10 times\n# wrap with tqdm for a progress bar\nfor example_idx in tqdm(xrange(2)):\n    features = np.zeros((SIZE_RECORD))\n\n    # construct the Example proto boject\n    example = tf.train.Example(\n        # Example contains a Features proto object\n        features=tf.train.Features(\n          # Features contains a map of string to Feature proto objects\n          feature={\n            # A Feature contains one of either a int64_list,\n            # float_list, or bytes_list\n            'image': tf.train.Feature(\n                float_list=tf.train.FloatList(value=features.astype(\"float\"))),\n    }))\n    # use the proto object to serialize the example to a string\n    serialized = example.SerializeToString()\n    # write the serialized object to disk\n    writer.write(serialized)\nwriter.close()\n\ndef read_and_decode_single_example(filename):\n    # first construct a queue containing a list of filenames.\n    # this lets a user split up there dataset in multiple files to keep\n    # size down\n    filename_queue = tf.train.string_input_producer([filename],\n                                                    num_epochs=None)\n    # Unlike the TFRecordWriter, the TFRecordReader is symbolic\n    reader = tf.TFRecordReader()\n    # One can read a single serialized example from a filename\n    # serialized_example is a Tensor of type string.\n    _, serialized_example = reader.read(filename_queue)\n    # The serialized example is converted back to actual values.\n    # One needs to describe the format of the objects to be returned\n    features = tf.parse_single_example(\n        serialized_example,\n        features={\n            # We know the length of both fields. If not the\n            # tf.VarLenFeature could be used\n            'image': tf.FixedLenFeature([SIZE_RECORD], tf.float32)\n        })\n    # now return the converted data\n    image = features['image']\n    return image\n\n# get single examples\nimage = read_and_decode_single_example(\"test.tfrecords\")\n# groups examples into batches randomly\nimages_batch = tf.train.shuffle_batch(\n    [image], batch_size=1,\n    capacity=3,\n    min_after_dequeue=2)\n\n# simple model\nw = tf.get_variable(\"w1\", [SIZE_RECORD, 1])\ny_pred = tf.matmul(images_batch, w)\nloss = tf.nn.l2_loss(y_pred - 1.0)\n\n# for monitoring\nloss_mean = tf.reduce_mean(loss)\n\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\n\nsess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)\ntf.train.start_queue_runners(sess=sess)\n\n_, loss_val = sess.run([train_op, loss_mean])\nprint loss_val\nprint(\"worked!!!\")\n\nWhat other attempted solutions have you tried?\nI have tried saving the example in a variety of different ways including converting it to a string and breaking up the vector into multiple features.\nLogs or other output that would be helpful\nThis is the output when the tfrecord is too big\nW tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Could not parse example input, value: '\n\ufffd\ufffd\ufffd&\n\ufffd\ufffd\ufffd&\nimage\ufffd\ufffd\ufffd\ufffd&\ufffd\ufffd\ufffd\ufffd&\n\ufffd\ufffd\ufffd&\nERROR:tensorflow:Exception in QueueRunner: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte\nException in thread Thread-3:\nTraceback (most recent call last):\nFile \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\nself.run()\nFile \"/usr/lib/python2.7/threading.py\", line 754, in run\nself.__target(*self.__args, **self.__kwargs)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 234, in _run\nsess.run(enqueue_op)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\nrun_metadata_ptr)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\nfeed_dict_string, options, run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\ntarget_list, options, run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\nreturn fn(*args)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\nstatus, run_metadata)\nFile \"/usr/lib/python2.7/contextlib.py\", line 24, in exit\nself.gen.next()\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 468, in raise_exception_on_not_ok_status\ncompat.as_text(pywrap_tensorflow.TF_Message(status)),\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/compat.py\", line 84, in as_text\nreturn bytes_or_text.decode(encoding)\nFile \"/usr/lib/python2.7/encodings/utf_8.py\", line 16, in decode\nreturn codecs.utf_8_decode(input, errors, True)\nUnicodeDecodeError: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte\nThank!!!", "body": "\r\nWhen I try to save a example to a tfrecord that is too large a parsing error occurs. I need to save a large sequence of float valued images (states of a fluid flow simulation) and when the states and sequences get too large a parsing error occurs.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI think that this might be the same error and problem that other people are getting when saving long sequences to tfrecords like seen here https://github.com/tensorflow/tensorflow/issues/5234 and https://github.com/OliviaMG/xiaomeng/issues/1. While both of these threads found solutions the underlining problem does not seem to be found.\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nUbuntu 16.04\r\nCUDA 8.0\r\nCUDNN 5.1\r\nTensorFlow 0.12.1\r\n\r\n### If possible, provide a minimal reproducible example\r\n\r\nRunning this minimal script will cause the error. Lowering the ```SIZE_RECORD``` value will cause the script to run with out error.\r\n\r\n```\r\nfrom tqdm import tqdm\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# this will kill it\r\nSIZE_RECORD=20000000\r\n# this will run just fine\r\n# SIZE_RECORD=2000000\r\n\r\nwriter = tf.python_io.TFRecordWriter(\"test.tfrecords\")\r\n# iterate over 10 times\r\n# wrap with tqdm for a progress bar\r\nfor example_idx in tqdm(xrange(2)):\r\n    features = np.zeros((SIZE_RECORD))\r\n\r\n    # construct the Example proto boject\r\n    example = tf.train.Example(\r\n        # Example contains a Features proto object\r\n        features=tf.train.Features(\r\n          # Features contains a map of string to Feature proto objects\r\n          feature={\r\n            # A Feature contains one of either a int64_list,\r\n            # float_list, or bytes_list\r\n            'image': tf.train.Feature(\r\n                float_list=tf.train.FloatList(value=features.astype(\"float\"))),\r\n    }))\r\n    # use the proto object to serialize the example to a string\r\n    serialized = example.SerializeToString()\r\n    # write the serialized object to disk\r\n    writer.write(serialized)\r\nwriter.close()\r\n\r\ndef read_and_decode_single_example(filename):\r\n    # first construct a queue containing a list of filenames.\r\n    # this lets a user split up there dataset in multiple files to keep\r\n    # size down\r\n    filename_queue = tf.train.string_input_producer([filename],\r\n                                                    num_epochs=None)\r\n    # Unlike the TFRecordWriter, the TFRecordReader is symbolic\r\n    reader = tf.TFRecordReader()\r\n    # One can read a single serialized example from a filename\r\n    # serialized_example is a Tensor of type string.\r\n    _, serialized_example = reader.read(filename_queue)\r\n    # The serialized example is converted back to actual values.\r\n    # One needs to describe the format of the objects to be returned\r\n    features = tf.parse_single_example(\r\n        serialized_example,\r\n        features={\r\n            # We know the length of both fields. If not the\r\n            # tf.VarLenFeature could be used\r\n            'image': tf.FixedLenFeature([SIZE_RECORD], tf.float32)\r\n        })\r\n    # now return the converted data\r\n    image = features['image']\r\n    return image\r\n\r\n# get single examples\r\nimage = read_and_decode_single_example(\"test.tfrecords\")\r\n# groups examples into batches randomly\r\nimages_batch = tf.train.shuffle_batch(\r\n    [image], batch_size=1,\r\n    capacity=3,\r\n    min_after_dequeue=2)\r\n\r\n# simple model\r\nw = tf.get_variable(\"w1\", [SIZE_RECORD, 1])\r\ny_pred = tf.matmul(images_batch, w)\r\nloss = tf.nn.l2_loss(y_pred - 1.0)\r\n\r\n# for monitoring\r\nloss_mean = tf.reduce_mean(loss)\r\n\r\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\r\n\r\nsess = tf.Session()\r\ninit = tf.initialize_all_variables()\r\nsess.run(init)\r\ntf.train.start_queue_runners(sess=sess)\r\n\r\n_, loss_val = sess.run([train_op, loss_mean])\r\nprint loss_val\r\nprint(\"worked!!!\")\r\n````\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nI have tried saving the example in a variety of different ways including converting it to a string and breaking up the vector into multiple features.\r\n\r\n### Logs or other output that would be helpful\r\n\r\nThis is the output when the tfrecord is too big\r\n\r\nW tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Could not parse example input, value: '\r\n\ufffd\ufffd\ufffd&\r\n\ufffd\ufffd\ufffd&\r\nimage\u0012\ufffd\ufffd\ufffd&\u0012\ufffd\ufffd\ufffd&\r\n\ufffd\ufffd\ufffd&\r\nERROR:tensorflow:Exception in QueueRunner: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 234, in _run\r\n    sess.run(enqueue_op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\r\n    status, run_metadata)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 468, in raise_exception_on_not_ok_status\r\n    compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/compat.py\", line 84, in as_text\r\n    return bytes_or_text.decode(encoding)\r\n  File \"/usr/lib/python2.7/encodings/utf_8.py\", line 16, in decode\r\n    return codecs.utf_8_decode(input, errors, True)\r\nUnicodeDecodeError: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte\r\n\r\n\r\nThank!!!"}