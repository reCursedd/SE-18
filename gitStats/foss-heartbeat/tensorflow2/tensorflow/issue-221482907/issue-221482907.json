{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9179", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9179/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9179/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9179/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9179", "id": 221482907, "node_id": "MDU6SXNzdWUyMjE0ODI5MDc=", "number": 9179, "title": "Failed to add dependency with tf.identity", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-04-13T07:39:35Z", "updated_at": "2017-07-13T21:53:41Z", "closed_at": "2017-04-13T19:16:25Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System Information</h3>\n<p>ArchLinux, TensorFlow 1.0.1 binary for py3.6</p>\n<ul>\n<li><em>Exact command to reproduce</em>:</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\na <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[])\nupdate_op <span class=\"pl-k\">=</span> a.assign_add(<span class=\"pl-c1\">1.0</span>)\n\ncost <span class=\"pl-k\">=</span> tf.reduce_mean(tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">10</span>]))\n<span class=\"pl-k\">with</span> tf.control_dependencies([update_op]):\n    cost <span class=\"pl-k\">=</span> tf.identity(cost)\n\ntrain <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">0.1</span>).minimize(cost)\nsess <span class=\"pl-k\">=</span> tf.Session()\nsess.run(tf.global_variables_initializer())\n\n<span class=\"pl-k\">for</span> k <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n    sess.run([cost])\n    <span class=\"pl-c1\">print</span>(sess.run([a]))    <span class=\"pl-c\"><span class=\"pl-c\">#</span> a increases</span>\n\n<span class=\"pl-k\">for</span> k <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n    sess.run([train])\n    <span class=\"pl-c1\">print</span>(sess.run([a]))    <span class=\"pl-c\"><span class=\"pl-c\">#</span> a doesn't increase</span></pre></div>\n<p>Looks like the <code>train</code> op doesn't depend on <code>update_op</code>.<br>\nIn terms of computation, backprop doesn't depend on the value of cost.  Is this intended?</p>\n<p>UPDATE: Turns out that <code>tf.gradients</code> doesn't have a dependency over its first argument, although intuitively I thought the opposite. This is a feature. Closing..</p>", "body_text": "System Information\nArchLinux, TensorFlow 1.0.1 binary for py3.6\n\nExact command to reproduce:\n\nimport tensorflow as tf\na = tf.get_variable('a', shape=[])\nupdate_op = a.assign_add(1.0)\n\ncost = tf.reduce_mean(tf.get_variable('x', shape=[10]))\nwith tf.control_dependencies([update_op]):\n    cost = tf.identity(cost)\n\ntrain = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nfor k in range(10):\n    sess.run([cost])\n    print(sess.run([a]))    # a increases\n\nfor k in range(10):\n    sess.run([train])\n    print(sess.run([a]))    # a doesn't increase\nLooks like the train op doesn't depend on update_op.\nIn terms of computation, backprop doesn't depend on the value of cost.  Is this intended?\nUPDATE: Turns out that tf.gradients doesn't have a dependency over its first argument, although intuitively I thought the opposite. This is a feature. Closing..", "body": "### System Information\r\nArchLinux, TensorFlow 1.0.1 binary for py3.6\r\n- *Exact command to reproduce*:\r\n```python\r\nimport tensorflow as tf\r\na = tf.get_variable('a', shape=[])\r\nupdate_op = a.assign_add(1.0)\r\n\r\ncost = tf.reduce_mean(tf.get_variable('x', shape=[10]))\r\nwith tf.control_dependencies([update_op]):\r\n    cost = tf.identity(cost)\r\n\r\ntrain = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\nfor k in range(10):\r\n    sess.run([cost])\r\n    print(sess.run([a]))    # a increases\r\n\r\nfor k in range(10):\r\n    sess.run([train])\r\n    print(sess.run([a]))    # a doesn't increase\r\n```\r\nLooks like the `train` op doesn't depend on `update_op`.\r\nIn terms of computation, backprop doesn't depend on the value of cost.  Is this intended?\r\n\r\nUPDATE: Turns out that `tf.gradients` doesn't have a dependency over its first argument, although intuitively I thought the opposite. This is a feature. Closing.."}