{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10243", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10243/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10243/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10243/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10243", "id": 231785614, "node_id": "MDU6SXNzdWUyMzE3ODU2MTQ=", "number": 10243, "title": "UnimplementedError, if only a word as the input data", "user": {"login": "zengpingweb", "id": 11938568, "node_id": "MDQ6VXNlcjExOTM4NTY4", "avatar_url": "https://avatars2.githubusercontent.com/u/11938568?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zengpingweb", "html_url": "https://github.com/zengpingweb", "followers_url": "https://api.github.com/users/zengpingweb/followers", "following_url": "https://api.github.com/users/zengpingweb/following{/other_user}", "gists_url": "https://api.github.com/users/zengpingweb/gists{/gist_id}", "starred_url": "https://api.github.com/users/zengpingweb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zengpingweb/subscriptions", "organizations_url": "https://api.github.com/users/zengpingweb/orgs", "repos_url": "https://api.github.com/users/zengpingweb/repos", "events_url": "https://api.github.com/users/zengpingweb/events{/privacy}", "received_events_url": "https://api.github.com/users/zengpingweb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-27T08:16:20Z", "updated_at": "2017-05-28T01:12:27Z", "closed_at": "2017-05-28T01:12:27Z", "author_association": "NONE", "body_html": "<p>When the input tensor only contain a word, the program will raise the UnimplementedError.</p>\n<p>`import numpy as np<br>\nimport tensorflow as tf</p>\n<h1>Data settings.</h1>\n<p>num_examples = 10<br>\nnum_words = 1<br>\nnum_features = 100<br>\nnum_tags = 5</p>\n<h1>Random features.</h1>\n<p>x = np.random.rand(num_examples, num_words, num_features).astype(np.float32)</p>\n<h1>Random tag indices representing the gold sequence.</h1>\n<p>y = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)</p>\n<h1>All sequences in this example have the same length, but they can be variable in a real model.</h1>\n<p>sequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)</p>\n<h1>Train and evaluate the model.</h1>\n<p>with tf.Graph().as_default():<br>\nwith tf.Session() as session:<br>\n# Add the data to the TensorFlow graph.<br>\nx_t = tf.constant(x)<br>\ny_t = tf.constant(y)<br>\nsequence_lengths_t = tf.constant(sequence_lengths)</p>\n<pre><code># Compute unary scores from a linear layer.\nweights = tf.get_variable(\"weights\", [num_features, num_tags])\nmatricized_x_t = tf.reshape(x_t, [-1, num_features])\nmatricized_unary_scores = tf.matmul(matricized_x_t, weights)\nunary_scores = tf.reshape(matricized_unary_scores,\n                          [num_examples, num_words, num_tags])\n\n# Compute the log-likelihood of the gold sequences and keep the transition\n# params for inference at test time.\nlog_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n    unary_scores, y_t, sequence_lengths_t)\n\n# Add a training op to tune the parameters.\nloss = tf.reduce_mean(-log_likelihood)\ntrain_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n\n# Train for a fixed number of iterations.\nsession.run(tf.global_variables_initializer())\nfor i in range(1000):\n  tf_unary_scores, tf_transition_params, _ = session.run(\n      [unary_scores, transition_params, train_op])\n  if i % 100 == 0:\n    correct_labels = 0\n    total_labels = 0\n    for tf_unary_scores_, y_, sequence_length_ in zip(tf_unary_scores, y,\n                                                      sequence_lengths):\n      # Remove padding from the scores and tag sequence.\n      tf_unary_scores_ = tf_unary_scores_[:sequence_length_]\n      y_ = y_[:sequence_length_]\n\n      # Compute the highest scoring sequence.\n      viterbi_sequence, _ = tf.contrib.crf.viterbi_decode(\n          tf_unary_scores_, tf_transition_params)\n\n      # Evaluate word-level accuracy.\n      correct_labels += np.sum(np.equal(viterbi_sequence, y_))\n      total_labels += sequence_length_\n    accuracy = 100.0 * correct_labels / float(total_labels)\n    print(\"Accuracy: %.2f%%\" % accuracy)`\n</code></pre>\n<p>UnimplementedError (see above for traceback): TensorArray has size zero, but element shape  is not fully defined. Currently only static shapes are supported when packing zero-size TensorArrays.<br>\n[[Node: gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3 = TensorArrayGatherV3[_class=[\"loc:@rnn/TensorArray_1\"], dtype=DT_FLOAT, element_shape=, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3, rnn/TensorArrayUnstack/range, gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow)]]</p>", "body_text": "When the input tensor only contain a word, the program will raise the UnimplementedError.\n`import numpy as np\nimport tensorflow as tf\nData settings.\nnum_examples = 10\nnum_words = 1\nnum_features = 100\nnum_tags = 5\nRandom features.\nx = np.random.rand(num_examples, num_words, num_features).astype(np.float32)\nRandom tag indices representing the gold sequence.\ny = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\nAll sequences in this example have the same length, but they can be variable in a real model.\nsequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\nTrain and evaluate the model.\nwith tf.Graph().as_default():\nwith tf.Session() as session:\n# Add the data to the TensorFlow graph.\nx_t = tf.constant(x)\ny_t = tf.constant(y)\nsequence_lengths_t = tf.constant(sequence_lengths)\n# Compute unary scores from a linear layer.\nweights = tf.get_variable(\"weights\", [num_features, num_tags])\nmatricized_x_t = tf.reshape(x_t, [-1, num_features])\nmatricized_unary_scores = tf.matmul(matricized_x_t, weights)\nunary_scores = tf.reshape(matricized_unary_scores,\n                          [num_examples, num_words, num_tags])\n\n# Compute the log-likelihood of the gold sequences and keep the transition\n# params for inference at test time.\nlog_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n    unary_scores, y_t, sequence_lengths_t)\n\n# Add a training op to tune the parameters.\nloss = tf.reduce_mean(-log_likelihood)\ntrain_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n\n# Train for a fixed number of iterations.\nsession.run(tf.global_variables_initializer())\nfor i in range(1000):\n  tf_unary_scores, tf_transition_params, _ = session.run(\n      [unary_scores, transition_params, train_op])\n  if i % 100 == 0:\n    correct_labels = 0\n    total_labels = 0\n    for tf_unary_scores_, y_, sequence_length_ in zip(tf_unary_scores, y,\n                                                      sequence_lengths):\n      # Remove padding from the scores and tag sequence.\n      tf_unary_scores_ = tf_unary_scores_[:sequence_length_]\n      y_ = y_[:sequence_length_]\n\n      # Compute the highest scoring sequence.\n      viterbi_sequence, _ = tf.contrib.crf.viterbi_decode(\n          tf_unary_scores_, tf_transition_params)\n\n      # Evaluate word-level accuracy.\n      correct_labels += np.sum(np.equal(viterbi_sequence, y_))\n      total_labels += sequence_length_\n    accuracy = 100.0 * correct_labels / float(total_labels)\n    print(\"Accuracy: %.2f%%\" % accuracy)`\n\nUnimplementedError (see above for traceback): TensorArray has size zero, but element shape  is not fully defined. Currently only static shapes are supported when packing zero-size TensorArrays.\n[[Node: gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3 = TensorArrayGatherV3[_class=[\"loc:@rnn/TensorArray_1\"], dtype=DT_FLOAT, element_shape=, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3, rnn/TensorArrayUnstack/range, gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow)]]", "body": "When the input tensor only contain a word, the program will raise the UnimplementedError.\r\n\r\n`import numpy as np\r\nimport tensorflow as tf\r\n\r\n# Data settings.\r\nnum_examples = 10\r\nnum_words = 1\r\nnum_features = 100\r\nnum_tags = 5\r\n\r\n# Random features.\r\nx = np.random.rand(num_examples, num_words, num_features).astype(np.float32)\r\n\r\n# Random tag indices representing the gold sequence.\r\ny = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\r\n\r\n# All sequences in this example have the same length, but they can be variable in a real model.\r\nsequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\r\n\r\n# Train and evaluate the model.\r\nwith tf.Graph().as_default():\r\n  with tf.Session() as session:\r\n    # Add the data to the TensorFlow graph.\r\n    x_t = tf.constant(x)\r\n    y_t = tf.constant(y)\r\n    sequence_lengths_t = tf.constant(sequence_lengths)\r\n\r\n    # Compute unary scores from a linear layer.\r\n    weights = tf.get_variable(\"weights\", [num_features, num_tags])\r\n    matricized_x_t = tf.reshape(x_t, [-1, num_features])\r\n    matricized_unary_scores = tf.matmul(matricized_x_t, weights)\r\n    unary_scores = tf.reshape(matricized_unary_scores,\r\n                              [num_examples, num_words, num_tags])\r\n\r\n    # Compute the log-likelihood of the gold sequences and keep the transition\r\n    # params for inference at test time.\r\n    log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\r\n        unary_scores, y_t, sequence_lengths_t)\r\n\r\n    # Add a training op to tune the parameters.\r\n    loss = tf.reduce_mean(-log_likelihood)\r\n    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\r\n\r\n    # Train for a fixed number of iterations.\r\n    session.run(tf.global_variables_initializer())\r\n    for i in range(1000):\r\n      tf_unary_scores, tf_transition_params, _ = session.run(\r\n          [unary_scores, transition_params, train_op])\r\n      if i % 100 == 0:\r\n        correct_labels = 0\r\n        total_labels = 0\r\n        for tf_unary_scores_, y_, sequence_length_ in zip(tf_unary_scores, y,\r\n                                                          sequence_lengths):\r\n          # Remove padding from the scores and tag sequence.\r\n          tf_unary_scores_ = tf_unary_scores_[:sequence_length_]\r\n          y_ = y_[:sequence_length_]\r\n\r\n          # Compute the highest scoring sequence.\r\n          viterbi_sequence, _ = tf.contrib.crf.viterbi_decode(\r\n              tf_unary_scores_, tf_transition_params)\r\n\r\n          # Evaluate word-level accuracy.\r\n          correct_labels += np.sum(np.equal(viterbi_sequence, y_))\r\n          total_labels += sequence_length_\r\n        accuracy = 100.0 * correct_labels / float(total_labels)\r\n        print(\"Accuracy: %.2f%%\" % accuracy)`\r\n\r\nUnimplementedError (see above for traceback): TensorArray has size zero, but element shape <unknown> is not fully defined. Currently only static shapes are supported when packing zero-size TensorArrays.\r\n\t [[Node: gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3 = TensorArrayGatherV3[_class=[\"loc:@rnn/TensorArray_1\"], dtype=DT_FLOAT, element_shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3, rnn/TensorArrayUnstack/range, gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow)]]\r\n\r\n"}