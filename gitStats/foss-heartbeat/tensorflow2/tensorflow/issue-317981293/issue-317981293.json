{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18898", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18898/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18898/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18898/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18898", "id": 317981293, "node_id": "MDU6SXNzdWUzMTc5ODEyOTM=", "number": 18898, "title": "[r1.7][TensorRT] INT8 mode calibration is not worked", "user": {"login": "oscarriddle", "id": 13745902, "node_id": "MDQ6VXNlcjEzNzQ1OTAy", "avatar_url": "https://avatars0.githubusercontent.com/u/13745902?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oscarriddle", "html_url": "https://github.com/oscarriddle", "followers_url": "https://api.github.com/users/oscarriddle/followers", "following_url": "https://api.github.com/users/oscarriddle/following{/other_user}", "gists_url": "https://api.github.com/users/oscarriddle/gists{/gist_id}", "starred_url": "https://api.github.com/users/oscarriddle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oscarriddle/subscriptions", "organizations_url": "https://api.github.com/users/oscarriddle/orgs", "repos_url": "https://api.github.com/users/oscarriddle/repos", "events_url": "https://api.github.com/users/oscarriddle/events{/privacy}", "received_events_url": "https://api.github.com/users/oscarriddle/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-04-26T11:08:41Z", "updated_at": "2018-04-27T02:55:49Z", "closed_at": "2018-04-27T02:55:49Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Red Hat 4.8.5-16, Linux version 3.10.0-693.5.2.el7.x86_64</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip (python 2.7)</li>\n<li><strong>TensorFlow version (use command below)</strong>: tensorflow-gpu==1.7.0</li>\n<li><strong>Python version</strong>: python 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: gcc 5.3</li>\n<li><strong>CUDA/cuDNN version</strong>:  CUDA9.0, cuDNN7.0.5</li>\n<li><strong>GPU model and memory</strong>: Tesla P4, 8GB</li>\n<li><strong>Exact command to reproduce</strong>: My own script is coded based on the official test \"tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\", so I think you can reproduce this problem with this test.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I tried to use Tensorflow 1.7 to do the prediction under Python environment, which can integrate the TensorRT to optimize the GraphDef.</p>\n<p>The optimization in FP32 mode is successfully done, but when I tried the INT8 mode, I'm confused about how to do the calibration. I checked the examples both from tensorflow source code and the NVidia dev guide but still not sure.</p>\n<p>Below is part of the example that contained within tensorflow.</p>\n<pre><code>def run_calibration(gdef, dumm_inp):\n  \"\"\"Run given calibration graph multiple times.\"\"\"\n  gpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction=0.50)\n  ops.reset_default_graph()\n  g = ops.Graph()\n  with g.as_default():\n    inp, out = importer.import_graph_def(\n        graph_def=gdef, return_elements=[\"input\", \"output\"])\n    inp = inp.outputs[0]\n    out = out.outputs[0]\n  with csess.Session(\n      config=cpb2.ConfigProto(gpu_options=gpu_options), graph=g) as sess:\n    # run over real calibration data here, we are mimicking a calibration set of\n    # 30 different batches. Use as much calibration data as you want\n    for _ in range(30):\n      val = sess.run(out, {inp: dumm_inp})\n  return val\n############################\n int8_calib_gdef = trt.create_inference_graph(\n     input_graph_def=orig_graph,\n     outputs=[\"output\"],\n     max_batch_size=inp_dims[0],\n     max_workspace_size_bytes=1 &lt;&lt; 25,\n     precision_mode=\"INT8\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\n     minimum_segment_size=2  # minimum number of nodes in an engine\n )\n _ = run_calibration(int8_calib_gdef, dummy_input)\n int8_graph = trt.calib_graph_to_infer_graph(int8_calib_gdef)\n o5 = run_graph(int8_graph, dummy_input)\n</code></pre>\n<p>Above code is copied from tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py<br>\nThe function run_calibration seems just create a session and run 30 times with the same input, and the return of run_calibration seems not used at all.</p>\n<p>How could the calibration be done in this way?</p>\n<p>Thanks,</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Red Hat 4.8.5-16, Linux version 3.10.0-693.5.2.el7.x86_64\nTensorFlow installed from (source or binary): pip (python 2.7)\nTensorFlow version (use command below): tensorflow-gpu==1.7.0\nPython version: python 2.7\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): gcc 5.3\nCUDA/cuDNN version:  CUDA9.0, cuDNN7.0.5\nGPU model and memory: Tesla P4, 8GB\nExact command to reproduce: My own script is coded based on the official test \"tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\", so I think you can reproduce this problem with this test.\n\nDescribe the problem\nI tried to use Tensorflow 1.7 to do the prediction under Python environment, which can integrate the TensorRT to optimize the GraphDef.\nThe optimization in FP32 mode is successfully done, but when I tried the INT8 mode, I'm confused about how to do the calibration. I checked the examples both from tensorflow source code and the NVidia dev guide but still not sure.\nBelow is part of the example that contained within tensorflow.\ndef run_calibration(gdef, dumm_inp):\n  \"\"\"Run given calibration graph multiple times.\"\"\"\n  gpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction=0.50)\n  ops.reset_default_graph()\n  g = ops.Graph()\n  with g.as_default():\n    inp, out = importer.import_graph_def(\n        graph_def=gdef, return_elements=[\"input\", \"output\"])\n    inp = inp.outputs[0]\n    out = out.outputs[0]\n  with csess.Session(\n      config=cpb2.ConfigProto(gpu_options=gpu_options), graph=g) as sess:\n    # run over real calibration data here, we are mimicking a calibration set of\n    # 30 different batches. Use as much calibration data as you want\n    for _ in range(30):\n      val = sess.run(out, {inp: dumm_inp})\n  return val\n############################\n int8_calib_gdef = trt.create_inference_graph(\n     input_graph_def=orig_graph,\n     outputs=[\"output\"],\n     max_batch_size=inp_dims[0],\n     max_workspace_size_bytes=1 << 25,\n     precision_mode=\"INT8\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\n     minimum_segment_size=2  # minimum number of nodes in an engine\n )\n _ = run_calibration(int8_calib_gdef, dummy_input)\n int8_graph = trt.calib_graph_to_infer_graph(int8_calib_gdef)\n o5 = run_graph(int8_graph, dummy_input)\n\nAbove code is copied from tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\nThe function run_calibration seems just create a session and run 30 times with the same input, and the return of run_calibration seems not used at all.\nHow could the calibration be done in this way?\nThanks,", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat 4.8.5-16, Linux version 3.10.0-693.5.2.el7.x86_64\r\n- **TensorFlow installed from (source or binary)**: pip (python 2.7)\r\n- **TensorFlow version (use command below)**: tensorflow-gpu==1.7.0\r\n- **Python version**: python 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: gcc 5.3\r\n- **CUDA/cuDNN version**:  CUDA9.0, cuDNN7.0.5\r\n- **GPU model and memory**: Tesla P4, 8GB\r\n- **Exact command to reproduce**: My own script is coded based on the official test \"tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\", so I think you can reproduce this problem with this test. \r\n\r\n### Describe the problem\r\nI tried to use Tensorflow 1.7 to do the prediction under Python environment, which can integrate the TensorRT to optimize the GraphDef.\r\n\r\nThe optimization in FP32 mode is successfully done, but when I tried the INT8 mode, I'm confused about how to do the calibration. I checked the examples both from tensorflow source code and the NVidia dev guide but still not sure. \r\n\r\nBelow is part of the example that contained within tensorflow.\r\n```\r\ndef run_calibration(gdef, dumm_inp):\r\n  \"\"\"Run given calibration graph multiple times.\"\"\"\r\n  gpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction=0.50)\r\n  ops.reset_default_graph()\r\n  g = ops.Graph()\r\n  with g.as_default():\r\n    inp, out = importer.import_graph_def(\r\n        graph_def=gdef, return_elements=[\"input\", \"output\"])\r\n    inp = inp.outputs[0]\r\n    out = out.outputs[0]\r\n  with csess.Session(\r\n      config=cpb2.ConfigProto(gpu_options=gpu_options), graph=g) as sess:\r\n    # run over real calibration data here, we are mimicking a calibration set of\r\n    # 30 different batches. Use as much calibration data as you want\r\n    for _ in range(30):\r\n      val = sess.run(out, {inp: dumm_inp})\r\n  return val\r\n############################\r\n int8_calib_gdef = trt.create_inference_graph(\r\n     input_graph_def=orig_graph,\r\n     outputs=[\"output\"],\r\n     max_batch_size=inp_dims[0],\r\n     max_workspace_size_bytes=1 << 25,\r\n     precision_mode=\"INT8\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\r\n     minimum_segment_size=2  # minimum number of nodes in an engine\r\n )\r\n _ = run_calibration(int8_calib_gdef, dummy_input)\r\n int8_graph = trt.calib_graph_to_infer_graph(int8_calib_gdef)\r\n o5 = run_graph(int8_graph, dummy_input)\r\n```\r\nAbove code is copied from tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\r\nThe function run_calibration seems just create a session and run 30 times with the same input, and the return of run_calibration seems not used at all. \r\n\r\nHow could the calibration be done in this way? \r\n\r\nThanks,"}