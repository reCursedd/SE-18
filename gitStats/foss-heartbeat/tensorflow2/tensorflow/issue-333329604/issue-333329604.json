{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20098", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20098/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20098/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20098/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20098", "id": 333329604, "node_id": "MDU6SXNzdWUzMzMzMjk2MDQ=", "number": 20098, "title": "Feature Request: Document Best Practice For Feeding New Data to a Restored Metagraph", "user": {"login": "masonk", "id": 449998, "node_id": "MDQ6VXNlcjQ0OTk5OA==", "avatar_url": "https://avatars0.githubusercontent.com/u/449998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/masonk", "html_url": "https://github.com/masonk", "followers_url": "https://api.github.com/users/masonk/followers", "following_url": "https://api.github.com/users/masonk/following{/other_user}", "gists_url": "https://api.github.com/users/masonk/gists{/gist_id}", "starred_url": "https://api.github.com/users/masonk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/masonk/subscriptions", "organizations_url": "https://api.github.com/users/masonk/orgs", "repos_url": "https://api.github.com/users/masonk/repos", "events_url": "https://api.github.com/users/masonk/events{/privacy}", "received_events_url": "https://api.github.com/users/masonk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "saxenasaurabh", "id": 3967488, "node_id": "MDQ6VXNlcjM5Njc0ODg=", "avatar_url": "https://avatars0.githubusercontent.com/u/3967488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saxenasaurabh", "html_url": "https://github.com/saxenasaurabh", "followers_url": "https://api.github.com/users/saxenasaurabh/followers", "following_url": "https://api.github.com/users/saxenasaurabh/following{/other_user}", "gists_url": "https://api.github.com/users/saxenasaurabh/gists{/gist_id}", "starred_url": "https://api.github.com/users/saxenasaurabh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saxenasaurabh/subscriptions", "organizations_url": "https://api.github.com/users/saxenasaurabh/orgs", "repos_url": "https://api.github.com/users/saxenasaurabh/repos", "events_url": "https://api.github.com/users/saxenasaurabh/events{/privacy}", "received_events_url": "https://api.github.com/users/saxenasaurabh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "saxenasaurabh", "id": 3967488, "node_id": "MDQ6VXNlcjM5Njc0ODg=", "avatar_url": "https://avatars0.githubusercontent.com/u/3967488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saxenasaurabh", "html_url": "https://github.com/saxenasaurabh", "followers_url": "https://api.github.com/users/saxenasaurabh/followers", "following_url": "https://api.github.com/users/saxenasaurabh/following{/other_user}", "gists_url": "https://api.github.com/users/saxenasaurabh/gists{/gist_id}", "starred_url": "https://api.github.com/users/saxenasaurabh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saxenasaurabh/subscriptions", "organizations_url": "https://api.github.com/users/saxenasaurabh/orgs", "repos_url": "https://api.github.com/users/saxenasaurabh/repos", "events_url": "https://api.github.com/users/saxenasaurabh/events{/privacy}", "received_events_url": "https://api.github.com/users/saxenasaurabh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-06-18T15:51:38Z", "updated_at": "2018-11-14T19:20:58Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n</ul>\n<p>Yes, custom code</p>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n</ul>\n<p>Linux Ubuntu 16.04</p>\n<ul>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n</ul>\n<p>Binary</p>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n</ul>\n<p>1.7</p>\n<ul>\n<li><strong>Python version</strong>:</li>\n</ul>\n<p>3.x</p>\n<h3>Describe the problem</h3>\n<p>I would like to produce and persist a model, represented by a metagraph, then restore it and feed it from a different data source, such as from a different Dataset. Despite being a natural thing to want to do, it is not easy to find out how to do this from official documentation. In particular, there's no  'best practice' shown anywhere in the docs.</p>\n<p>Today, the only way I have found of doing this is to build the graph with a feedable iterator (as described in the comments to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"244811909\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/11679\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/11679/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/11679\">#11679</a>), and then saving+restoring the iterator <em>handle</em> so that I can feed in new iterator by handle on every train step.</p>\n<p>As a secondary issue, I think it would make more sense to save and restore a reinitializable iterator to the metagraph. Then, in the restored session, I could pull that reinitializable iterator out of the restored metagraph and reinitialize it from a new dataset.  No way that I tried of doing this actually worked. Although I could save the iterator with <code>make_saveable_from_iterator_</code>, the necessary <code>make_initializer</code> function wasn't present on the restored object; it didn't survive the roundtrip to disk.</p>\n<h3>Source code / logs</h3>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4105011\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/annarailton\">@annarailton</a> gives a full source code for the handle-based method of iterator persistence in this comment:<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"244811909\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/11679\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/11679/hovercard?comment_id=395722710&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/11679#issuecomment-395722710\">#11679 (comment)</a></p>\n<p>I independently came up with functionally equivalent code after several hours of work, then found her code by searching to see if anyone else was doing it with feedables. I was searching because it felt wrongish (inefficient) and the docs gave no endorsement for this approach.</p>\n<p>So in the end, I have two related requests:</p>\n<ol>\n<li>Document the current best practice for attaching new data to the inputs of a restored metagraph.</li>\n</ol>\n<p>e.g. <a href=\"https://www.tensorflow.org/programmers_guide/datasets#saving_iterator_state\" rel=\"nofollow\">https://www.tensorflow.org/programmers_guide/datasets#saving_iterator_state</a> should show this best practice. I believe this is by far the most common thing to want to do with a restored metagraph, likely to be far more common than resuming an existing iterator as shown in the docs.</p>\n<ol start=\"2\">\n<li>Provide an efficient way to attach a new data to a restored metagraph.</li>\n</ol>\n<p>It may be that the handle lookup in the feedable iterator method is efficient. In that case, this second request is a no-op.</p>\n<p>Finally, I'm happy to give you a PR for datasets#saving_iterator_state to show the handle based feeding method, if you'd like one.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nYes, custom code\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n\nLinux Ubuntu 16.04\n\nTensorFlow installed from (source or binary):\n\nBinary\n\nTensorFlow version (use command below):\n\n1.7\n\nPython version:\n\n3.x\nDescribe the problem\nI would like to produce and persist a model, represented by a metagraph, then restore it and feed it from a different data source, such as from a different Dataset. Despite being a natural thing to want to do, it is not easy to find out how to do this from official documentation. In particular, there's no  'best practice' shown anywhere in the docs.\nToday, the only way I have found of doing this is to build the graph with a feedable iterator (as described in the comments to #11679), and then saving+restoring the iterator handle so that I can feed in new iterator by handle on every train step.\nAs a secondary issue, I think it would make more sense to save and restore a reinitializable iterator to the metagraph. Then, in the restored session, I could pull that reinitializable iterator out of the restored metagraph and reinitialize it from a new dataset.  No way that I tried of doing this actually worked. Although I could save the iterator with make_saveable_from_iterator_, the necessary make_initializer function wasn't present on the restored object; it didn't survive the roundtrip to disk.\nSource code / logs\n@annarailton gives a full source code for the handle-based method of iterator persistence in this comment:\n#11679 (comment)\nI independently came up with functionally equivalent code after several hours of work, then found her code by searching to see if anyone else was doing it with feedables. I was searching because it felt wrongish (inefficient) and the docs gave no endorsement for this approach.\nSo in the end, I have two related requests:\n\nDocument the current best practice for attaching new data to the inputs of a restored metagraph.\n\ne.g. https://www.tensorflow.org/programmers_guide/datasets#saving_iterator_state should show this best practice. I believe this is by far the most common thing to want to do with a restored metagraph, likely to be far more common than resuming an existing iterator as shown in the docs.\n\nProvide an efficient way to attach a new data to a restored metagraph.\n\nIt may be that the handle lookup in the feedable iterator method is efficient. In that case, this second request is a no-op.\nFinally, I'm happy to give you a PR for datasets#saving_iterator_state to show the handle based feeding method, if you'd like one.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nYes, custom code\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nLinux Ubuntu 16.04\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nBinary\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\n1.7\r\n\r\n- **Python version**: \r\n\r\n3.x\r\n\r\n\r\n### Describe the problem\r\nI would like to produce and persist a model, represented by a metagraph, then restore it and feed it from a different data source, such as from a different Dataset. Despite being a natural thing to want to do, it is not easy to find out how to do this from official documentation. In particular, there's no  'best practice' shown anywhere in the docs.\r\n\r\nToday, the only way I have found of doing this is to build the graph with a feedable iterator (as described in the comments to #11679), and then saving+restoring the iterator _handle_ so that I can feed in new iterator by handle on every train step.\r\n\r\nAs a secondary issue, I think it would make more sense to save and restore a reinitializable iterator to the metagraph. Then, in the restored session, I could pull that reinitializable iterator out of the restored metagraph and reinitialize it from a new dataset.  No way that I tried of doing this actually worked. Although I could save the iterator with `make_saveable_from_iterator_`, the necessary `make_initializer` function wasn't present on the restored object; it didn't survive the roundtrip to disk.\r\n\r\n\r\n### Source code / logs\r\n@annarailton gives a full source code for the handle-based method of iterator persistence in this comment:\r\nhttps://github.com/tensorflow/tensorflow/issues/11679#issuecomment-395722710\r\n\r\nI independently came up with functionally equivalent code after several hours of work, then found her code by searching to see if anyone else was doing it with feedables. I was searching because it felt wrongish (inefficient) and the docs gave no endorsement for this approach.\r\n\r\nSo in the end, I have two related requests:\r\n\r\n1. Document the current best practice for attaching new data to the inputs of a restored metagraph.\r\n\r\ne.g. https://www.tensorflow.org/programmers_guide/datasets#saving_iterator_state should show this best practice. I believe this is by far the most common thing to want to do with a restored metagraph, likely to be far more common than resuming an existing iterator as shown in the docs.\r\n\r\n2. Provide an efficient way to attach a new data to a restored metagraph.\r\n\r\nIt may be that the handle lookup in the feedable iterator method is efficient. In that case, this second request is a no-op. \r\n\r\nFinally, I'm happy to give you a PR for datasets#saving_iterator_state to show the handle based feeding method, if you'd like one."}