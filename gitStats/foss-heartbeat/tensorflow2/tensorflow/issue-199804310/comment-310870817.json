{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/310870817", "html_url": "https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-310870817", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6766", "id": 310870817, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDg3MDgxNw==", "user": {"login": "j-wilson", "id": 6174242, "node_id": "MDQ6VXNlcjYxNzQyNDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/6174242?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-wilson", "html_url": "https://github.com/j-wilson", "followers_url": "https://api.github.com/users/j-wilson/followers", "following_url": "https://api.github.com/users/j-wilson/following{/other_user}", "gists_url": "https://api.github.com/users/j-wilson/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-wilson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-wilson/subscriptions", "organizations_url": "https://api.github.com/users/j-wilson/orgs", "repos_url": "https://api.github.com/users/j-wilson/repos", "events_url": "https://api.github.com/users/j-wilson/events{/privacy}", "received_events_url": "https://api.github.com/users/j-wilson/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-24T23:02:07Z", "updated_at": "2017-06-24T23:02:07Z", "author_association": "NONE", "body_html": "<p>Anyone looking into this? I'm also experiencing this issue using TensorFlow 1.2.0 (v1.2.0-rc2-21-g12f033d). In my case, a <code>tf.while_loop</code> is being used (in conjunction with <code>tf.TensorArray</code>); however, the same error occurs if I swap out the <code>tf.while_loop</code> for a <code>while</code> statement.</p>\n<p><strong>Backtrace</strong> (abbr):</p>\n<pre><code>2017-06-24 05:42:28.894580: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\n2017-06-24 05:42:28.894638: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n2017-06-24 05:42:28.894647: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\n2017-06-24 05:42:28.894657: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n2017-06-24 05:42:28.895314: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\n2017-06-24 05:42:28.895406: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\n2017-06-24 05:42:28.896185: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\n2017-06-24 05:42:28.896209: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\n.\n.\n.\n2017-06-24 05:42:28.905449: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\n2017-06-24 05:42:28.905669: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\n</code></pre>\n<p>A bit further down,</p>\n<pre><code>Caused by op 'while/SoftmaxCrossEntropyWithLogits', defined at:\n  ...\n  File \"scripts/gpu_experiment.py\", line 400, in build_backend\n    backend['o'] = build_outputs(config, backend.get('o', None))\n  File \"scripts/gpu_experiment.py\", line 363, in build_outputs\n    loop_vars = tf.while_loop(loop_cond, _build_outputs, loop_vars)\n    ...\n    cross_ent = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n</code></pre>", "body_text": "Anyone looking into this? I'm also experiencing this issue using TensorFlow 1.2.0 (v1.2.0-rc2-21-g12f033d). In my case, a tf.while_loop is being used (in conjunction with tf.TensorArray); however, the same error occurs if I swap out the tf.while_loop for a while statement.\nBacktrace (abbr):\n2017-06-24 05:42:28.894580: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\n2017-06-24 05:42:28.894638: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n2017-06-24 05:42:28.894647: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\n2017-06-24 05:42:28.894657: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n2017-06-24 05:42:28.895314: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\n2017-06-24 05:42:28.895406: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\n2017-06-24 05:42:28.896185: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\n2017-06-24 05:42:28.896209: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\n.\n.\n.\n2017-06-24 05:42:28.905449: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\n2017-06-24 05:42:28.905669: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\n\nA bit further down,\nCaused by op 'while/SoftmaxCrossEntropyWithLogits', defined at:\n  ...\n  File \"scripts/gpu_experiment.py\", line 400, in build_backend\n    backend['o'] = build_outputs(config, backend.get('o', None))\n  File \"scripts/gpu_experiment.py\", line 363, in build_outputs\n    loop_vars = tf.while_loop(loop_cond, _build_outputs, loop_vars)\n    ...\n    cross_ent = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)", "body": "Anyone looking into this? I'm also experiencing this issue using TensorFlow 1.2.0 (v1.2.0-rc2-21-g12f033d). In my case, a `tf.while_loop` is being used (in conjunction with `tf.TensorArray`); however, the same error occurs if I swap out the `tf.while_loop` for a `while` statement.\r\n\r\n**Backtrace** (abbr):\r\n```\r\n2017-06-24 05:42:28.894580: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\r\n2017-06-24 05:42:28.894638: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2017-06-24 05:42:28.894647: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\r\n2017-06-24 05:42:28.894657: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2017-06-24 05:42:28.895314: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\r\n2017-06-24 05:42:28.895406: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr\r\n2017-06-24 05:42:28.896185: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\r\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\r\n2017-06-24 05:42:28.896209: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\r\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\r\n.\r\n.\r\n.\r\n2017-06-24 05:42:28.905449: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\r\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\r\n2017-06-24 05:42:28.905669: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for\r\n         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Reshape, while/Reshape_1)]]\r\n```\r\n\r\nA bit further down,\r\n```\r\nCaused by op 'while/SoftmaxCrossEntropyWithLogits', defined at:\r\n  ...\r\n  File \"scripts/gpu_experiment.py\", line 400, in build_backend\r\n    backend['o'] = build_outputs(config, backend.get('o', None))\r\n  File \"scripts/gpu_experiment.py\", line 363, in build_outputs\r\n    loop_vars = tf.while_loop(loop_cond, _build_outputs, loop_vars)\r\n    ...\r\n    cross_ent = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\r\n```"}