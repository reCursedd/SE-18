{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/327730201", "html_url": "https://github.com/tensorflow/tensorflow/issues/12849#issuecomment-327730201", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12849", "id": 327730201, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNzczMDIwMQ==", "user": {"login": "qtdaniel", "id": 21170884, "node_id": "MDQ6VXNlcjIxMTcwODg0", "avatar_url": "https://avatars2.githubusercontent.com/u/21170884?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qtdaniel", "html_url": "https://github.com/qtdaniel", "followers_url": "https://api.github.com/users/qtdaniel/followers", "following_url": "https://api.github.com/users/qtdaniel/following{/other_user}", "gists_url": "https://api.github.com/users/qtdaniel/gists{/gist_id}", "starred_url": "https://api.github.com/users/qtdaniel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qtdaniel/subscriptions", "organizations_url": "https://api.github.com/users/qtdaniel/orgs", "repos_url": "https://api.github.com/users/qtdaniel/repos", "events_url": "https://api.github.com/users/qtdaniel/events{/privacy}", "received_events_url": "https://api.github.com/users/qtdaniel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-07T08:32:58Z", "updated_at": "2017-09-07T08:32:58Z", "author_association": "NONE", "body_html": "<p>Yes, it works with <code>TF_DOWNLOAD_MKL=1</code> but this downloads MKL-DNN, not the full MKL. If one wants to build MKL support into Eigen then, I believe, one needs to use the full MKL but maybe MKL support in TensorFlow is limited to MKL-DNN? Comments in the r1.3 <code>configure</code> script seem to imply that it should support the full MKL which is why I tried it.</p>\n<p>By the way, the <a href=\"https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture\" rel=\"nofollow\">instructions on the Intel site</a> for building TensorFlow with MKL (which have also been communicated on various TensorFlow support channels) are, I believe, incorrect. It says one should build with the command <code>bazel build --config=mkl --copt=\"-DEIGEN_USE_VML\" -c opt //tensorflow/tools/pip_package:build_pip_package</code> but this has two potential errors:</p>\n<ol>\n<li>One should include <code>--config=opt</code> in addition to <code>--config=mkl</code> to enable all the regular (non-MKL) CPU optimizations in addition to the MKL features.</li>\n<li>The flag to compile MKL vector operations into Eigen is <code>EIGEN_USE_MKL_VML</code>, not <code>EIGEN_USE_VML</code> (<a href=\"https://eigen.tuxfamily.org/dox/TopicUsingIntelMKL.html\" rel=\"nofollow\">as explained here</a>).</li>\n</ol>\n<p>Correcting the second of these two potential errors yields a new issue in TensorFlow: it fails to compile with a bazel error (something about MKL header files getting included without them being declared in a BUILD file). I don't have the details of that error to hand but it should probably be logged as separate issue anyway and if the MKL build options are changing in the next release maybe it's best to just wait.</p>\n<p>I hope the next version of TensorFlow will make clear which of the nine potential configurations of Eigen and TF each built with one of (no MKL, MKL-DNN, full MKL) is supported. It's also not clear whether the optional use of CUDA is an orthogonal consideration or could interact with the use (or not) of MKL/MKL-DNN.</p>", "body_text": "Yes, it works with TF_DOWNLOAD_MKL=1 but this downloads MKL-DNN, not the full MKL. If one wants to build MKL support into Eigen then, I believe, one needs to use the full MKL but maybe MKL support in TensorFlow is limited to MKL-DNN? Comments in the r1.3 configure script seem to imply that it should support the full MKL which is why I tried it.\nBy the way, the instructions on the Intel site for building TensorFlow with MKL (which have also been communicated on various TensorFlow support channels) are, I believe, incorrect. It says one should build with the command bazel build --config=mkl --copt=\"-DEIGEN_USE_VML\" -c opt //tensorflow/tools/pip_package:build_pip_package but this has two potential errors:\n\nOne should include --config=opt in addition to --config=mkl to enable all the regular (non-MKL) CPU optimizations in addition to the MKL features.\nThe flag to compile MKL vector operations into Eigen is EIGEN_USE_MKL_VML, not EIGEN_USE_VML (as explained here).\n\nCorrecting the second of these two potential errors yields a new issue in TensorFlow: it fails to compile with a bazel error (something about MKL header files getting included without them being declared in a BUILD file). I don't have the details of that error to hand but it should probably be logged as separate issue anyway and if the MKL build options are changing in the next release maybe it's best to just wait.\nI hope the next version of TensorFlow will make clear which of the nine potential configurations of Eigen and TF each built with one of (no MKL, MKL-DNN, full MKL) is supported. It's also not clear whether the optional use of CUDA is an orthogonal consideration or could interact with the use (or not) of MKL/MKL-DNN.", "body": "Yes, it works with `TF_DOWNLOAD_MKL=1` but this downloads MKL-DNN, not the full MKL. If one wants to build MKL support into Eigen then, I believe, one needs to use the full MKL but maybe MKL support in TensorFlow is limited to MKL-DNN? Comments in the r1.3 `configure` script seem to imply that it should support the full MKL which is why I tried it.\r\n\r\nBy the way, the [instructions on the Intel site](https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture) for building TensorFlow with MKL (which have also been communicated on various TensorFlow support channels) are, I believe, incorrect. It says one should build with the command `bazel build --config=mkl --copt=\"-DEIGEN_USE_VML\" -c opt //tensorflow/tools/pip_package:build_pip_package` but this has two potential errors:\r\n\r\n1. One should include `--config=opt` in addition to `--config=mkl` to enable all the regular (non-MKL) CPU optimizations in addition to the MKL features.\r\n2. The flag to compile MKL vector operations into Eigen is `EIGEN_USE_MKL_VML`, not `EIGEN_USE_VML` ([as explained here](https://eigen.tuxfamily.org/dox/TopicUsingIntelMKL.html)).\r\n\r\nCorrecting the second of these two potential errors yields a new issue in TensorFlow: it fails to compile with a bazel error (something about MKL header files getting included without them being declared in a BUILD file). I don't have the details of that error to hand but it should probably be logged as separate issue anyway and if the MKL build options are changing in the next release maybe it's best to just wait.\r\n\r\nI hope the next version of TensorFlow will make clear which of the nine potential configurations of Eigen and TF each built with one of (no MKL, MKL-DNN, full MKL) is supported. It's also not clear whether the optional use of CUDA is an orthogonal consideration or could interact with the use (or not) of MKL/MKL-DNN.\r\n"}