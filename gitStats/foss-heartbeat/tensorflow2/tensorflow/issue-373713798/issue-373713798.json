{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23234", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23234/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23234/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23234/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23234", "id": 373713798, "node_id": "MDU6SXNzdWUzNzM3MTM3OTg=", "number": 23234, "title": "TFLiteConverter produces empty .tflite file", "user": {"login": "Mr-Grieves", "id": 19175336, "node_id": "MDQ6VXNlcjE5MTc1MzM2", "avatar_url": "https://avatars2.githubusercontent.com/u/19175336?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mr-Grieves", "html_url": "https://github.com/Mr-Grieves", "followers_url": "https://api.github.com/users/Mr-Grieves/followers", "following_url": "https://api.github.com/users/Mr-Grieves/following{/other_user}", "gists_url": "https://api.github.com/users/Mr-Grieves/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mr-Grieves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mr-Grieves/subscriptions", "organizations_url": "https://api.github.com/users/Mr-Grieves/orgs", "repos_url": "https://api.github.com/users/Mr-Grieves/repos", "events_url": "https://api.github.com/users/Mr-Grieves/events{/privacy}", "received_events_url": "https://api.github.com/users/Mr-Grieves/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-10-24T23:18:51Z", "updated_at": "2018-10-30T17:08:09Z", "closed_at": "2018-10-30T17:08:09Z", "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Adapted code from <a href=\"https://www.tensorflow.org/lite/convert/python_api#exporting_a_graphdef_from_file_\" rel=\"nofollow\">here</a></li>\n<li>OS Platform and Distribution: Linux Ubuntu 16.04</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): tf-nightly-gpu</li>\n<li>Python version: 3.5</li>\n<li>CUDA/cuDNN version: 9.0</li>\n<li>GPU model and memory: GeForce GTX 980 8GB</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nI am trying to convert a frozen .pb (which I have working with TF Mobile java inference interface) to .tflite format using the python TFLiteConverter API. When I run the code below, it completes without error or warning, except it produces an output file SEGNET.tflite with 0 size.</p>\n<p><strong>Describe the expected behavior</strong><br>\nI would like it you produce a non-zero file...</p>\n<p><strong>Code to reproduce the issue</strong><br>\nI cannot provide the .pb file, but here is the code im using</p>\n<pre><code>import tensorflow as tf\n\ngraph_def_file = \"models/SEGNET.pb\"\ninput_arrays = [\"input_1\"]\noutput_arrays = [\"output_node0\"]\n\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\ntflite_model = converter.convert()\nopen(\"SEGNET.tflite\", \"wb\").write(tflite_model)\n</code></pre>\n<p>I know that both the input and output are correctly named.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Adapted code from here\nOS Platform and Distribution: Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): tf-nightly-gpu\nPython version: 3.5\nCUDA/cuDNN version: 9.0\nGPU model and memory: GeForce GTX 980 8GB\n\nDescribe the current behavior\nI am trying to convert a frozen .pb (which I have working with TF Mobile java inference interface) to .tflite format using the python TFLiteConverter API. When I run the code below, it completes without error or warning, except it produces an output file SEGNET.tflite with 0 size.\nDescribe the expected behavior\nI would like it you produce a non-zero file...\nCode to reproduce the issue\nI cannot provide the .pb file, but here is the code im using\nimport tensorflow as tf\n\ngraph_def_file = \"models/SEGNET.pb\"\ninput_arrays = [\"input_1\"]\noutput_arrays = [\"output_node0\"]\n\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\ntflite_model = converter.convert()\nopen(\"SEGNET.tflite\", \"wb\").write(tflite_model)\n\nI know that both the input and output are correctly named.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Adapted code from [here](https://www.tensorflow.org/lite/convert/python_api#exporting_a_graphdef_from_file_)\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly-gpu\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: 9.0\r\n- GPU model and memory: GeForce GTX 980 8GB\r\n\r\n**Describe the current behavior**\r\nI am trying to convert a frozen .pb (which I have working with TF Mobile java inference interface) to .tflite format using the python TFLiteConverter API. When I run the code below, it completes without error or warning, except it produces an output file SEGNET.tflite with 0 size.\r\n\r\n**Describe the expected behavior**\r\nI would like it you produce a non-zero file...\r\n\r\n**Code to reproduce the issue**\r\nI cannot provide the .pb file, but here is the code im using\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = \"models/SEGNET.pb\"\r\ninput_arrays = [\"input_1\"]\r\noutput_arrays = [\"output_node0\"]\r\n\r\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\r\ntflite_model = converter.convert()\r\nopen(\"SEGNET.tflite\", \"wb\").write(tflite_model)\r\n```\r\nI know that both the input and output are correctly named."}