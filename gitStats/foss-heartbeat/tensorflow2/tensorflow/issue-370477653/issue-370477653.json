{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23011", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23011/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23011/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23011/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/23011", "id": 370477653, "node_id": "MDExOlB1bGxSZXF1ZXN0MjIzMTQ0MTEz", "number": 23011, "title": "Fix multiprocess support in data_utils.py Enqueuer classes", "user": {"login": "calid", "id": 494405, "node_id": "MDQ6VXNlcjQ5NDQwNQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/494405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calid", "html_url": "https://github.com/calid", "followers_url": "https://api.github.com/users/calid/followers", "following_url": "https://api.github.com/users/calid/following{/other_user}", "gists_url": "https://api.github.com/users/calid/gists{/gist_id}", "starred_url": "https://api.github.com/users/calid/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calid/subscriptions", "organizations_url": "https://api.github.com/users/calid/orgs", "repos_url": "https://api.github.com/users/calid/repos", "events_url": "https://api.github.com/users/calid/events{/privacy}", "received_events_url": "https://api.github.com/users/calid/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-10-16T07:37:43Z", "updated_at": "2018-11-08T04:37:12Z", "closed_at": "2018-11-08T04:37:11Z", "author_association": "NONE", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23011", "html_url": "https://github.com/tensorflow/tensorflow/pull/23011", "diff_url": "https://github.com/tensorflow/tensorflow/pull/23011.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/23011.patch"}, "body_html": "<p>This was originally to <span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #22804.\">fix</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"367556284\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/22804\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/22804/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/22804\">#22804</a>, but after some googling it seems multi-process support has been an issue for awhile.  See also:</p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"270849965\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/matterport/Mask_RCNN/issues/13\" data-hovercard-type=\"issue\" data-hovercard-url=\"/matterport/Mask_RCNN/issues/13/hovercard\" href=\"https://github.com/matterport/Mask_RCNN/issues/13\">matterport/Mask_RCNN#13</a></li>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"184592961\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/keras-team/keras/issues/4142\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/4142/hovercard\" href=\"https://github.com/keras-team/keras/issues/4142\">keras-team/keras#4142</a></li>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"131274167\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/keras-team/keras/issues/1638\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/1638/hovercard\" href=\"https://github.com/keras-team/keras/issues/1638\">keras-team/keras#1638</a></li>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"180930070\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/keras-team/keras/issues/3962\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/3962/hovercard\" href=\"https://github.com/keras-team/keras/issues/3962\">keras-team/keras#3962</a></li>\n</ul>\n<p>This PR should address all of these (on Linux) and fixes the Enqueuer classes to use the correct multiprocessing constructs. I've done my best to follow the threading/multiprocessing best-practices in the Python docs.</p>\n<h4>Approach</h4>\n<p>Rather than go down the rabbit hole of complex if/else logic to handle the different threading/multiprocessing use cases I've instead broken the logic out into separate, dedicated classes.  The top level GeneratorEnqueuer and OrderedEnqueuer classes simply dispatch to the appropriate implementation depending on whether the user specifies <code>use_multiprocessing</code> or not.</p>\n<p>In addition to fixing the problems with multi-processing support (hanging, not sharing/synchronizing state correctly), I've also cleaned up and refactored the code to try and eliminate duplicated logic and misc other bugs.  For example I encountered some thread starvation issues due to mistakes with how locks were being used (the tests 'passed' and returned data in the 'right order,' but a peek under the hood showed all or most of the work was actually being done by a single thread).</p>\n<p>Some final points:</p>\n<ul>\n<li>\n<p>I replaced the class global variables that were being used to share state with standard mechanisms from the <code>threading</code> and <code>multiprocessing</code> modules (and class globals don't work across processes anyways)</p>\n</li>\n<li>\n<p>As a side effect of using the right synchronization mechanisms it should no longer matter if generators passed to GeneratorEnqueuer are thread-safe or not, the new implementation should handle things correctly regardless.</p>\n</li>\n<li>\n<p>The tests have mostly been left as-is to show that the API is maintained and none of the regressions break.  One thing I did notice is that the test for the multi-processed GeneratorEnqueuer used the wrong assertion.  I think this is because multi-processing wasn't working and it was done to get the test suite to pass?  Regardless I've updated it to use the same assertion as in the threaded version of the test:</p>\n</li>\n</ul>\n<div class=\"highlight highlight-source-diff\"><pre>   def test_generator_enqueuer_threads(self):\n     enqueuer = keras.utils.data_utils.GeneratorEnqueuer(\n         create_generator_from_sequence_threads(TestSequence([3, 200, 200, 3])),\n         use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n     for _ in range(100):\n       acc.append(int(next(gen_output)[0, 0, 0, 0]))\n\n     self.assertEqual(len(set(acc) - set(range(100))), 0)\n     enqueuer.stop()\n\n   @unittest.skipIf(\n       os.name == 'nt',\n       'use_multiprocessing=True does not work on windows properly.')\n   def test_generator_enqueuer_processes(self):\n     enqueuer = keras.utils.data_utils.GeneratorEnqueuer(\n         create_generator_from_sequence_pcs(TestSequence([3, 200, 200, 3])),\n         use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n     for _ in range(100):\n       acc.append(int(next(gen_output)[0, 0, 0, 0]))\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>    self.assertNotEqual(acc, list(range(100)))</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>    self.assertEqual(len(set(acc) - set(range(100))), 0)</span>\n     enqueuer.stop()</pre></div>\n<p>Tested directly and under bazel using Python 2.7.15 and 3.6.6.</p>\n<p>Any questions, mistakes I've made, or ways I can improve the PR let me know.</p>\n<p>Thanks!</p>", "body_text": "This was originally to fix #22804, but after some googling it seems multi-process support has been an issue for awhile.  See also:\n\nmatterport/Mask_RCNN#13\nkeras-team/keras#4142\nkeras-team/keras#1638\nkeras-team/keras#3962\n\nThis PR should address all of these (on Linux) and fixes the Enqueuer classes to use the correct multiprocessing constructs. I've done my best to follow the threading/multiprocessing best-practices in the Python docs.\nApproach\nRather than go down the rabbit hole of complex if/else logic to handle the different threading/multiprocessing use cases I've instead broken the logic out into separate, dedicated classes.  The top level GeneratorEnqueuer and OrderedEnqueuer classes simply dispatch to the appropriate implementation depending on whether the user specifies use_multiprocessing or not.\nIn addition to fixing the problems with multi-processing support (hanging, not sharing/synchronizing state correctly), I've also cleaned up and refactored the code to try and eliminate duplicated logic and misc other bugs.  For example I encountered some thread starvation issues due to mistakes with how locks were being used (the tests 'passed' and returned data in the 'right order,' but a peek under the hood showed all or most of the work was actually being done by a single thread).\nSome final points:\n\n\nI replaced the class global variables that were being used to share state with standard mechanisms from the threading and multiprocessing modules (and class globals don't work across processes anyways)\n\n\nAs a side effect of using the right synchronization mechanisms it should no longer matter if generators passed to GeneratorEnqueuer are thread-safe or not, the new implementation should handle things correctly regardless.\n\n\nThe tests have mostly been left as-is to show that the API is maintained and none of the regressions break.  One thing I did notice is that the test for the multi-processed GeneratorEnqueuer used the wrong assertion.  I think this is because multi-processing wasn't working and it was done to get the test suite to pass?  Regardless I've updated it to use the same assertion as in the threaded version of the test:\n\n\n   def test_generator_enqueuer_threads(self):\n     enqueuer = keras.utils.data_utils.GeneratorEnqueuer(\n         create_generator_from_sequence_threads(TestSequence([3, 200, 200, 3])),\n         use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n     for _ in range(100):\n       acc.append(int(next(gen_output)[0, 0, 0, 0]))\n\n     self.assertEqual(len(set(acc) - set(range(100))), 0)\n     enqueuer.stop()\n\n   @unittest.skipIf(\n       os.name == 'nt',\n       'use_multiprocessing=True does not work on windows properly.')\n   def test_generator_enqueuer_processes(self):\n     enqueuer = keras.utils.data_utils.GeneratorEnqueuer(\n         create_generator_from_sequence_pcs(TestSequence([3, 200, 200, 3])),\n         use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n     for _ in range(100):\n       acc.append(int(next(gen_output)[0, 0, 0, 0]))\n-    self.assertNotEqual(acc, list(range(100)))\n+    self.assertEqual(len(set(acc) - set(range(100))), 0)\n     enqueuer.stop()\nTested directly and under bazel using Python 2.7.15 and 3.6.6.\nAny questions, mistakes I've made, or ways I can improve the PR let me know.\nThanks!", "body": "This was originally to fix #22804, but after some googling it seems multi-process support has been an issue for awhile.  See also:\r\n\r\n* https://github.com/matterport/Mask_RCNN/issues/13\r\n* https://github.com/keras-team/keras/issues/4142\r\n* https://github.com/keras-team/keras/issues/1638\r\n* https://github.com/keras-team/keras/issues/3962\r\n\r\nThis PR should address all of these (on Linux) and fixes the Enqueuer classes to use the correct multiprocessing constructs. I've done my best to follow the threading/multiprocessing best-practices in the Python docs.\r\n\r\n#### Approach\r\n\r\nRather than go down the rabbit hole of complex if/else logic to handle the different threading/multiprocessing use cases I've instead broken the logic out into separate, dedicated classes.  The top level GeneratorEnqueuer and OrderedEnqueuer classes simply dispatch to the appropriate implementation depending on whether the user specifies `use_multiprocessing` or not.\r\n\r\nIn addition to fixing the problems with multi-processing support (hanging, not sharing/synchronizing state correctly), I've also cleaned up and refactored the code to try and eliminate duplicated logic and misc other bugs.  For example I encountered some thread starvation issues due to mistakes with how locks were being used (the tests 'passed' and returned data in the 'right order,' but a peek under the hood showed all or most of the work was actually being done by a single thread).\r\n\r\nSome final points:\r\n\r\n* I replaced the class global variables that were being used to share state with standard mechanisms from the `threading` and `multiprocessing` modules (and class globals don't work across processes anyways)\r\n\r\n* As a side effect of using the right synchronization mechanisms it should no longer matter if generators passed to GeneratorEnqueuer are thread-safe or not, the new implementation should handle things correctly regardless.\r\n\r\n* The tests have mostly been left as-is to show that the API is maintained and none of the regressions break.  One thing I did notice is that the test for the multi-processed GeneratorEnqueuer used the wrong assertion.  I think this is because multi-processing wasn't working and it was done to get the test suite to pass?  Regardless I've updated it to use the same assertion as in the threaded version of the test:\r\n\r\n```diff\r\n   def test_generator_enqueuer_threads(self):\r\n     enqueuer = keras.utils.data_utils.GeneratorEnqueuer(\r\n         create_generator_from_sequence_threads(TestSequence([3, 200, 200, 3])),\r\n         use_multiprocessing=False)\r\n     enqueuer.start(3, 10)\r\n     gen_output = enqueuer.get()\r\n     acc = []\r\n     for _ in range(100):\r\n       acc.append(int(next(gen_output)[0, 0, 0, 0]))\r\n\r\n     self.assertEqual(len(set(acc) - set(range(100))), 0)\r\n     enqueuer.stop()\r\n\r\n   @unittest.skipIf(\r\n       os.name == 'nt',\r\n       'use_multiprocessing=True does not work on windows properly.')\r\n   def test_generator_enqueuer_processes(self):\r\n     enqueuer = keras.utils.data_utils.GeneratorEnqueuer(\r\n         create_generator_from_sequence_pcs(TestSequence([3, 200, 200, 3])),\r\n         use_multiprocessing=True)\r\n     enqueuer.start(3, 10)\r\n     gen_output = enqueuer.get()\r\n     acc = []\r\n     for _ in range(100):\r\n       acc.append(int(next(gen_output)[0, 0, 0, 0]))\r\n-    self.assertNotEqual(acc, list(range(100)))\r\n+    self.assertEqual(len(set(acc) - set(range(100))), 0)\r\n     enqueuer.stop()\r\n```\r\n\r\nTested directly and under bazel using Python 2.7.15 and 3.6.6.\r\n\r\nAny questions, mistakes I've made, or ways I can improve the PR let me know.\r\n\r\nThanks!\r\n"}