{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/228345133", "pull_request_review_id": 168598940, "id": 228345133, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyODM0NTEzMw==", "diff_hunk": "@@ -467,301 +438,550 @@ class SequenceEnqueuer(object):\n   The `enqueuer.get()` should be an infinite stream of datas.\n   \"\"\"\n \n-  def __init__(self, sequence,\n-               use_multiprocessing=False):\n-    self.sequence = sequence\n-    self.use_multiprocessing = use_multiprocessing\n+  def __init__(self):\n+    self._children = []\n+    self._queue = None\n+    self._stop_event = None\n \n-    global _SEQUENCE_COUNTER\n-    if _SEQUENCE_COUNTER is None:\n-      try:\n-        _SEQUENCE_COUNTER = multiprocessing.Value('i', 0)\n-      except OSError:\n-        # In this case the OS does not allow us to use\n-        # multiprocessing. We resort to an int\n-        # for enqueuer indexing.\n-        _SEQUENCE_COUNTER = 0\n-\n-    if isinstance(_SEQUENCE_COUNTER, int):\n-      self.uid = _SEQUENCE_COUNTER\n-      _SEQUENCE_COUNTER += 1\n-    else:\n-      # Doing Multiprocessing.Value += x is not process-safe.\n-      with _SEQUENCE_COUNTER.get_lock():\n-        self.uid = _SEQUENCE_COUNTER.value\n-        _SEQUENCE_COUNTER.value += 1\n+  @abstractmethod\n+  def start(self, workers=1, max_queue_size=10):\n+    \"\"\"Starts the workers.\n \n-    self.workers = 0\n-    self.executor_fn = None\n-    self.queue = None\n-    self.run_thread = None\n-    self.stop_signal = None\n+    Arguments:\n+        workers: number of workers\n+        max_queue_size: queue size\n+            (when full, threads could block on `put()`).\n+    \"\"\"\n+    raise NotImplementedError\n \n   def is_running(self):\n-    return self.stop_signal is not None and not self.stop_signal.is_set()\n+    \"\"\"Checks if background workers are still running\n \n-  def start(self, workers=1, max_queue_size=10):\n-    \"\"\"Starts the handler's workers.\n+    Returns:\n+        True if workers are still running, False otherwise\n+    \"\"\"\n+    return self._stop_event is not None and not self._stop_event.is_set()\n \n-    Arguments:\n-        workers: Number of workers.\n-        max_queue_size: queue size\n-            (when full, workers could block on `put()`)\n+  def get(self):\n+    \"\"\"Creates a generator to extract data from the queue.\n+\n+    Skip the data if it is `None`.\n+\n+    Returns:\n+        Generator yielding tuples `(inputs, targets)`\n+            or `(inputs, targets, sample_weights)`.\n     \"\"\"\n-    if self.use_multiprocessing:\n-      self.executor_fn = self._get_executor_init(workers)\n-    else:\n-      # We do not need the init since it's threads.\n-      self.executor_fn = lambda _: ThreadPool(workers)\n-    self.workers = workers\n-    self.queue = queue.Queue(max_queue_size)\n-    self.stop_signal = threading.Event()\n-    self.run_thread = threading.Thread(target=self._run)\n-    self.run_thread.daemon = True\n-    self.run_thread.start()\n-\n-  def _send_sequence(self):\n-    \"\"\"Sends current Iterable to all workers.\"\"\"\n-    # For new processes that may spawn\n-    _SHARED_SEQUENCES[self.uid] = self.sequence\n+    while self.is_running():\n+      if not self._queue.empty():\n+        success, value = self._queue.get()\n+        # Rethrow any exceptions found in the queue\n+        if not success:\n+          six.reraise(value.__class__, value, value.__traceback__)\n+        # Yield regular values\n+        if value is not None:\n+          yield value\n+      else:\n+        all_finished = all([not child.is_alive() for child in self._children])\n+        if all_finished and self._queue.empty():\n+          return\n+        time.sleep(self._wait_time)\n+\n+    # Make sure to rethrow the first exception in the queue, if any\n+    while not self._queue.empty():\n+      success, value = self._queue.get()\n+      if not success:\n+        six.reraise(value.__class__, value, value.__traceback__)\n \n   def stop(self, timeout=None):\n-    \"\"\"Stops running threads and wait for them to exit, if necessary.\n+    \"\"\"Stops background workers and waits for them to exit, if necessary.\n \n     Should be called by the same thread which called `start()`.\n \n     Arguments:\n-        timeout: maximum time to wait on `thread.join()`\n+        timeout: maximum time to wait on `join()`\n+    \"\"\"\n+    if self.is_running():\n+      # let the children know we're done\n+      self._stop_event.set()\n+\n+    for child in self._children:\n+      while child.is_alive():\n+        # drain any remaining messages, otherwise join will block\n+        self._drain_queue()\n+        time.sleep(self._wait_time)\n+      child.join(timeout)\n+\n+    self._children = []\n+    self._queue = None\n+    self._stop_event = None\n+\n+  def _drain_queue(self):\n+    while not self._queue.empty():\n+      success, value = self._queue.get()\n+      if not success:\n+        six.reraise(value.__class__, value, value.__traceback__)\n+\n+class DelegateEnqueuer(object):\n+  \"\"\"Delegates SequenceEnqeurer operations to an underlying implementation\"\"\"\n+\n+  def __init__(self, instance):\n+    \"\"\"Arguments:\n+        instance: An object that implements SequenceEnqueuer\n+\n+    See: MultiProcEnqueuer, ThreadedEnqueuer\n     \"\"\"\n-    self.stop_signal.set()\n-    with self.queue.mutex:\n-      self.queue.queue.clear()\n-      self.queue.unfinished_tasks = 0\n-      self.queue.not_full.notify()\n-    self.run_thread.join(timeout)\n-    _SHARED_SEQUENCES[self.uid] = None\n-\n-  @abstractmethod\n-  def _run(self):\n-    \"\"\"Submits request to the executor and queue the `Future` objects.\"\"\"\n-    raise NotImplementedError\n \n-  @abstractmethod\n-  def _get_executor_init(self, workers):\n-    \"\"\"Gets the Pool initializer for multiprocessing.\n+    self._instance = instance\n \n-    Arguments:\n-        workers: Number of workers.\n+  def start(self, *args):\n+    self._instance.start(*args)\n \n-    Returns:\n-        Function, a Function to initialize the pool\n-    \"\"\"\n-    raise NotImplementedError\n+  def is_running(self):\n+    return self._instance.is_running()\n \n-  @abstractmethod\n   def get(self):\n-    \"\"\"Creates a generator to extract data from the queue.\n+    return self._instance.get()\n \n-    Skip the data if it is `None`.\n-    # Returns\n-        Generator yielding tuples `(inputs, targets)`\n-            or `(inputs, targets, sample_weights)`.\n-    \"\"\"\n-    raise NotImplementedError\n+  def stop(self):\n+    self._instance.stop()\n+\n+@tf_export('keras.utils.GeneratorEnqueuer')\n+class GeneratorEnqueuer(DelegateEnqueuer):\n+  \"\"\"Builds a queue out of a data generator.\n \n+  The provided generator can be finite in which case the class will throw\n+  a `StopIteration` exception.\n+\n+  Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n+\n+  Arguments:\n+      generator: a generator function which yields data\n+      use_multiprocessing: use multiprocessing if True, otherwise threading\n+      wait_time: time to sleep waiting for workers to generate data or exit\n+  \"\"\"\n+\n+  def __init__(self, *args, **kwargs):\n+    use_mp = kwargs.pop('use_multiprocessing')", "path": "tensorflow/python/keras/utils/data_utils.py", "position": null, "original_position": 286, "commit_id": "a7545b065422fe0ac6a1d1f42242e392cfaaa9d8", "original_commit_id": "e79d0d7e38fafab7b91282954685f9f17fd62f54", "user": {"login": "Dref360", "id": 8976546, "node_id": "MDQ6VXNlcjg5NzY1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/8976546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dref360", "html_url": "https://github.com/Dref360", "followers_url": "https://api.github.com/users/Dref360/followers", "following_url": "https://api.github.com/users/Dref360/following{/other_user}", "gists_url": "https://api.github.com/users/Dref360/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dref360/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dref360/subscriptions", "organizations_url": "https://api.github.com/users/Dref360/orgs", "repos_url": "https://api.github.com/users/Dref360/repos", "events_url": "https://api.github.com/users/Dref360/events{/privacy}", "received_events_url": "https://api.github.com/users/Dref360/received_events", "type": "User", "site_admin": false}, "body": "please used name parameters when possible", "created_at": "2018-10-25T21:44:19Z", "updated_at": "2018-10-29T02:01:54Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/23011#discussion_r228345133", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23011", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/228345133"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/23011#discussion_r228345133"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23011"}}, "body_html": "<p>please used name parameters when possible</p>", "body_text": "please used name parameters when possible"}