{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2285", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2285/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2285/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2285/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2285", "id": 153736298, "node_id": "MDU6SXNzdWUxNTM3MzYyOTg=", "number": 2285, "title": "the bug of using multiple GPUs, related to tf.Variable pinned to CPU", "user": {"login": "myme5261314", "id": 1814831, "node_id": "MDQ6VXNlcjE4MTQ4MzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1814831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/myme5261314", "html_url": "https://github.com/myme5261314", "followers_url": "https://api.github.com/users/myme5261314/followers", "following_url": "https://api.github.com/users/myme5261314/following{/other_user}", "gists_url": "https://api.github.com/users/myme5261314/gists{/gist_id}", "starred_url": "https://api.github.com/users/myme5261314/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/myme5261314/subscriptions", "organizations_url": "https://api.github.com/users/myme5261314/orgs", "repos_url": "https://api.github.com/users/myme5261314/repos", "events_url": "https://api.github.com/users/myme5261314/events{/privacy}", "received_events_url": "https://api.github.com/users/myme5261314/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2016-05-09T09:27:09Z", "updated_at": "2016-05-11T06:26:45Z", "closed_at": "2016-05-11T06:26:45Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04</p>\n<p>Installed version of CUDA and cuDNN: 7.5 and 4.0.7<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>If installed from sources, provide the commit hash: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/4a4f2461533847dde239851ecebe5056088a828c/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/4a4f2461533847dde239851ecebe5056088a828c\"><tt>4a4f246</tt></a></p>\n<h3>Steps to reproduce</h3>\n<p>Run the following code</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n    a <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">1</span>)\n    init_a <span class=\"pl-k\">=</span> tf.initialize_all_variables()\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(init_a)\n\n    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:0<span class=\"pl-pds\">\"</span></span>):\n        b <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">2</span>)\n        init_b <span class=\"pl-k\">=</span> tf.initialize_all_variables()\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(init_b)\n\n    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/cpu:0<span class=\"pl-pds\">\"</span></span>):\n        c <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">2</span>)\n        init_c <span class=\"pl-k\">=</span> tf.initialize_all_variables()\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(init_c)\n\n    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:0<span class=\"pl-pds\">\"</span></span>):\n        d <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">2</span>)\n        init_d <span class=\"pl-k\">=</span> tf.initialize_all_variables()\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(init_d)\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    main()</pre></div>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.266\npciBusID 0000:05:00.0\nTotal memory: 12.00GiB\nFree memory: 11.02GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX 980\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2785\npciBusID 0000:09:00.0\nTotal memory: 4.00GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nTraceback (most recent call last):\n  File \"test_multi_gpu.py\", line 30, in &lt;module&gt;\n    main()\n  File \"test_multi_gpu.py\", line 26, in main\n    sess.run(init_d)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 332, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 572, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 652, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 672, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'Variable_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available\n     [[Node: Variable_2 = Variable[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\nCaused by op u'Variable_2', defined at:\n  File \"test_multi_gpu.py\", line 30, in &lt;module&gt;\n    main()\n  File \"test_multi_gpu.py\", line 23, in main\n    d = tf.Variable(2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 211, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 292, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py\", line 139, in variable_op\n    container=container, shared_name=shared_name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 351, in _variable\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n</code></pre>\n<p>I also noticed that the documentation for <a href=\"https://www.tensorflow.org/versions/r0.8/how_tos/using_gpu/index.html\" rel=\"nofollow\">Using GPUs</a> doesn't mentioned about tf.Variable, it only involves the tf.constant and tf.matmul.</p>\n<p><strong>OK, I found the documentation from [Convolutional Neural Networks]</strong>(<a href=\"https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html\" rel=\"nofollow\">https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html</a>),<br>\nquotes:</p>\n<pre><code>All variables are pinned to the CPU and accessed via tf.get_variable() in order to share them in a multi-GPU version. See how-to on Sharing Variables.\n</code></pre>\n<p>I want ask that since tf.Variables is pinned to CPU by tensorflow, could we fix this error? Do we need to looking very carefully to exclude the tf.Variable declaration outside the <code>with tf.device('/gpu:xx')</code> scope, or use netsted <code>with tf.device(None)</code> to handle it?</p>", "body_text": "Environment info\nOperating System: Ubuntu 14.04\nInstalled version of CUDA and cuDNN: 7.5 and 4.0.7\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nIf installed from sources, provide the commit hash: 4a4f246\nSteps to reproduce\nRun the following code\nimport tensorflow as tf\n\ndef main():\n    a = tf.Variable(1)\n    init_a = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_a)\n\n    with tf.device(\"/gpu:0\"):\n        b = tf.constant(2)\n        init_b = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_b)\n\n    with tf.device(\"/cpu:0\"):\n        c = tf.Variable(2)\n        init_c = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_c)\n\n    with tf.device(\"/gpu:0\"):\n        d = tf.Variable(2)\n        init_d = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_d)\n\nif __name__ == '__main__':\n    main()\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.266\npciBusID 0000:05:00.0\nTotal memory: 12.00GiB\nFree memory: 11.02GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX 980\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2785\npciBusID 0000:09:00.0\nTotal memory: 4.00GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nTraceback (most recent call last):\n  File \"test_multi_gpu.py\", line 30, in <module>\n    main()\n  File \"test_multi_gpu.py\", line 26, in main\n    sess.run(init_d)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 332, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 572, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 652, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 672, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'Variable_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available\n     [[Node: Variable_2 = Variable[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\nCaused by op u'Variable_2', defined at:\n  File \"test_multi_gpu.py\", line 30, in <module>\n    main()\n  File \"test_multi_gpu.py\", line 23, in main\n    d = tf.Variable(2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 211, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 292, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py\", line 139, in variable_op\n    container=container, shared_name=shared_name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 351, in _variable\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n\nI also noticed that the documentation for Using GPUs doesn't mentioned about tf.Variable, it only involves the tf.constant and tf.matmul.\nOK, I found the documentation from [Convolutional Neural Networks](https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html),\nquotes:\nAll variables are pinned to the CPU and accessed via tf.get_variable() in order to share them in a multi-GPU version. See how-to on Sharing Variables.\n\nI want ask that since tf.Variables is pinned to CPU by tensorflow, could we fix this error? Do we need to looking very carefully to exclude the tf.Variable declaration outside the with tf.device('/gpu:xx') scope, or use netsted with tf.device(None) to handle it?", "body": "### Environment info\n\nOperating System: Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: 7.5 and 4.0.7\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from sources, provide the commit hash: 4a4f2461533847dde239851ecebe5056088a828c\n### Steps to reproduce\n\nRun the following code\n\n``` python\nimport tensorflow as tf\n\ndef main():\n    a = tf.Variable(1)\n    init_a = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_a)\n\n    with tf.device(\"/gpu:0\"):\n        b = tf.constant(2)\n        init_b = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_b)\n\n    with tf.device(\"/cpu:0\"):\n        c = tf.Variable(2)\n        init_c = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_c)\n\n    with tf.device(\"/gpu:0\"):\n        d = tf.Variable(2)\n        init_d = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_d)\n\nif __name__ == '__main__':\n    main()\n```\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.266\npciBusID 0000:05:00.0\nTotal memory: 12.00GiB\nFree memory: 11.02GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX 980\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2785\npciBusID 0000:09:00.0\nTotal memory: 4.00GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)\nTraceback (most recent call last):\n  File \"test_multi_gpu.py\", line 30, in <module>\n    main()\n  File \"test_multi_gpu.py\", line 26, in main\n    sess.run(init_d)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 332, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 572, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 652, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 672, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'Variable_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available\n     [[Node: Variable_2 = Variable[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\nCaused by op u'Variable_2', defined at:\n  File \"test_multi_gpu.py\", line 30, in <module>\n    main()\n  File \"test_multi_gpu.py\", line 23, in main\n    d = tf.Variable(2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 211, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 292, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py\", line 139, in variable_op\n    container=container, shared_name=shared_name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 351, in _variable\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n```\n\nI also noticed that the documentation for [Using GPUs](https://www.tensorflow.org/versions/r0.8/how_tos/using_gpu/index.html) doesn't mentioned about tf.Variable, it only involves the tf.constant and tf.matmul.\n\n**OK, I found the documentation from [Convolutional Neural Networks]**(https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html),\nquotes:\n\n```\nAll variables are pinned to the CPU and accessed via tf.get_variable() in order to share them in a multi-GPU version. See how-to on Sharing Variables.\n```\n\nI want ask that since tf.Variables is pinned to CPU by tensorflow, could we fix this error? Do we need to looking very carefully to exclude the tf.Variable declaration outside the `with tf.device('/gpu:xx')` scope, or use netsted `with tf.device(None)` to handle it?\n"}