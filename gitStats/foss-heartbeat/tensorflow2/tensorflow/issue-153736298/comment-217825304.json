{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/217825304", "html_url": "https://github.com/tensorflow/tensorflow/issues/2285#issuecomment-217825304", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2285", "id": 217825304, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNzgyNTMwNA==", "user": {"login": "myme5261314", "id": 1814831, "node_id": "MDQ6VXNlcjE4MTQ4MzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1814831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/myme5261314", "html_url": "https://github.com/myme5261314", "followers_url": "https://api.github.com/users/myme5261314/followers", "following_url": "https://api.github.com/users/myme5261314/following{/other_user}", "gists_url": "https://api.github.com/users/myme5261314/gists{/gist_id}", "starred_url": "https://api.github.com/users/myme5261314/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/myme5261314/subscriptions", "organizations_url": "https://api.github.com/users/myme5261314/orgs", "repos_url": "https://api.github.com/users/myme5261314/repos", "events_url": "https://api.github.com/users/myme5261314/events{/privacy}", "received_events_url": "https://api.github.com/users/myme5261314/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-09T10:05:35Z", "updated_at": "2016-05-09T10:10:54Z", "author_association": "NONE", "body_html": "<p>So, there are some ops that are not valid for tf.device(), such as tf.nn.local_response_normalization(),<br>\nSee the code below:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:0<span class=\"pl-pds\">\"</span></span>):\n        d <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>float<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">10</span>])\n        <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-c1\">None</span>):\n            lrn1 <span class=\"pl-k\">=</span> tf.nn.local_response_normalization(d, <span class=\"pl-v\">depth_radius</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">alpha</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-4</span>, <span class=\"pl-v\">beta</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.75</span>)\n        lrn2 <span class=\"pl-k\">=</span> tf.nn.local_response_normalization(d, <span class=\"pl-v\">depth_radius</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">alpha</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-4</span>, <span class=\"pl-v\">beta</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.75</span>)\n        init_d <span class=\"pl-k\">=</span> tf.initialize_all_variables()\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(init_d)\n        r <span class=\"pl-k\">=</span> np.random.randn(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">10</span>)\n        sess.run(lrn1, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{d: r}) <span class=\"pl-c\"><span class=\"pl-c\">#</span>Run ok</span>\n        sess.run(lrn2, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{d: r}) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Error</span></pre></div>\n<p>The output is below:</p>\n<pre><code>Traceback (most recent call last):\n  File \"test_multi_gpu.py\", line 44, in &lt;module&gt;\n    main()\n  File \"test_multi_gpu.py\", line 40, in main\n    sess.run(lrn2, feed_dict={d: r})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 332, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 572, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 652, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 672, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'LRN_1': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available\n     [[Node: LRN_1 = LRN[alpha=0.0001, beta=0.75, bias=1, depth_radius=5, _device=\"/device:GPU:0\"](Placeholder)]]\nCaused by op u'LRN_1', defined at:\n  File \"test_multi_gpu.py\", line 44, in &lt;module&gt;\n    main()\n  File \"test_multi_gpu.py\", line 34, in main\n    lrn2 = tf.nn.local_response_normalization(d, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 737, in lrn\n    bias=bias, alpha=alpha, beta=beta, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n</code></pre>\n<p><strong>The reason</strong> of this error might be clear enough I think. There're some internal tf.Variable in the <code>tf.nn.local_response_normalization</code> which we couldn't use outside code to remain the computation node to specified gpu while excluding all the internal variables.</p>\n<p>For now, I think tensorflow should do either of two things below:</p>\n<ol>\n<li>Make tf.Variable not influenced by the tf.device(). (This might be preferred.)</li>\n<li>List the ops out which needs to use <code>tf.device(None)</code> to help user finish their code, right?</li>\n</ol>", "body_text": "So, there are some ops that are not valid for tf.device(), such as tf.nn.local_response_normalization(),\nSee the code below:\n    with tf.device(\"/gpu:0\"):\n        d = tf.placeholder(\"float\", shape=[100, 100, 100, 10])\n        with tf.device(None):\n            lrn1 = tf.nn.local_response_normalization(d, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n        lrn2 = tf.nn.local_response_normalization(d, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n        init_d = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_d)\n        r = np.random.randn(100, 100, 100, 10)\n        sess.run(lrn1, feed_dict={d: r}) #Run ok\n        sess.run(lrn2, feed_dict={d: r}) # Error\nThe output is below:\nTraceback (most recent call last):\n  File \"test_multi_gpu.py\", line 44, in <module>\n    main()\n  File \"test_multi_gpu.py\", line 40, in main\n    sess.run(lrn2, feed_dict={d: r})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 332, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 572, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 652, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 672, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'LRN_1': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available\n     [[Node: LRN_1 = LRN[alpha=0.0001, beta=0.75, bias=1, depth_radius=5, _device=\"/device:GPU:0\"](Placeholder)]]\nCaused by op u'LRN_1', defined at:\n  File \"test_multi_gpu.py\", line 44, in <module>\n    main()\n  File \"test_multi_gpu.py\", line 34, in main\n    lrn2 = tf.nn.local_response_normalization(d, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 737, in lrn\n    bias=bias, alpha=alpha, beta=beta, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n\nThe reason of this error might be clear enough I think. There're some internal tf.Variable in the tf.nn.local_response_normalization which we couldn't use outside code to remain the computation node to specified gpu while excluding all the internal variables.\nFor now, I think tensorflow should do either of two things below:\n\nMake tf.Variable not influenced by the tf.device(). (This might be preferred.)\nList the ops out which needs to use tf.device(None) to help user finish their code, right?", "body": "So, there are some ops that are not valid for tf.device(), such as tf.nn.local_response_normalization(),\nSee the code below:\n\n``` python\n    with tf.device(\"/gpu:0\"):\n        d = tf.placeholder(\"float\", shape=[100, 100, 100, 10])\n        with tf.device(None):\n            lrn1 = tf.nn.local_response_normalization(d, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n        lrn2 = tf.nn.local_response_normalization(d, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n        init_d = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init_d)\n        r = np.random.randn(100, 100, 100, 10)\n        sess.run(lrn1, feed_dict={d: r}) #Run ok\n        sess.run(lrn2, feed_dict={d: r}) # Error\n```\n\nThe output is below:\n\n```\nTraceback (most recent call last):\n  File \"test_multi_gpu.py\", line 44, in <module>\n    main()\n  File \"test_multi_gpu.py\", line 40, in main\n    sess.run(lrn2, feed_dict={d: r})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 332, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 572, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 652, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 672, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'LRN_1': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available\n     [[Node: LRN_1 = LRN[alpha=0.0001, beta=0.75, bias=1, depth_radius=5, _device=\"/device:GPU:0\"](Placeholder)]]\nCaused by op u'LRN_1', defined at:\n  File \"test_multi_gpu.py\", line 44, in <module>\n    main()\n  File \"test_multi_gpu.py\", line 34, in main\n    lrn2 = tf.nn.local_response_normalization(d, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 737, in lrn\n    bias=bias, alpha=alpha, beta=beta, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n```\n\n**The reason** of this error might be clear enough I think. There're some internal tf.Variable in the `tf.nn.local_response_normalization` which we couldn't use outside code to remain the computation node to specified gpu while excluding all the internal variables.\n\nFor now, I think tensorflow should do either of two things below:\n1. Make tf.Variable not influenced by the tf.device(). (This might be preferred.)\n2. List the ops out which needs to use `tf.device(None)` to help user finish their code, right?\n"}