{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4016", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4016/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4016/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4016/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4016", "id": 172940665, "node_id": "MDU6SXNzdWUxNzI5NDA2NjU=", "number": 4016, "title": "Initialize layers.convolution2d from numpy array", "user": {"login": "ivankreso", "id": 2056432, "node_id": "MDQ6VXNlcjIwNTY0MzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2056432?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ivankreso", "html_url": "https://github.com/ivankreso", "followers_url": "https://api.github.com/users/ivankreso/followers", "following_url": "https://api.github.com/users/ivankreso/following{/other_user}", "gists_url": "https://api.github.com/users/ivankreso/gists{/gist_id}", "starred_url": "https://api.github.com/users/ivankreso/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ivankreso/subscriptions", "organizations_url": "https://api.github.com/users/ivankreso/orgs", "repos_url": "https://api.github.com/users/ivankreso/repos", "events_url": "https://api.github.com/users/ivankreso/events{/privacy}", "received_events_url": "https://api.github.com/users/ivankreso/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2016-08-24T12:39:13Z", "updated_at": "2018-07-10T02:37:53Z", "closed_at": "2016-08-26T12:19:03Z", "author_association": "NONE", "body_html": "<p>I can't find a way to pass a numpy tensor to layers.convolution2d weights/bias initialization arguments.<br>\nI added support for this by modifying convolution2d, code is below. I need this feature in order  If you like this solution I can add this feature to other ops also and create a pull request.</p>\n<p>First I tried this:</p>\n<pre><code>import tensorflow as tf\nimport tensorflow.contrib.layers as layers\nimport numpy as np\n\nconv1_1 = np.random.rand(3, 3, 3, 64).astype(dtype=np.float32)\ninputs = tf.placeholder(tf.float32, shape=(32, 96, 96, 3))\nnet = layers.convolution2d(inputs, 64, 3, weights_initializer=conv1_1, scope='conv1_1')\n</code></pre>\n<p>but get_variable method doesn't allow redundant shape argument when initializing from constant.</p>\n<pre><code>Traceback (most recent call last):\n  File \"tf1.py\", line 16, in &lt;module&gt;\n    net = layers.convolution2d(inputs, 64, 3, weights_initializer=conv1_1, scope='conv1_1')\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 406, in convolution2d\n    trainable=trainable)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 266, in model_variable\n    caching_device=caching_device, device=device)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 230, in variable\n    caching_device=caching_device)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 873, in get_variable\n    custom_getter=custom_getter)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 700, in get_variable\n    custom_getter=custom_getter)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 217, in get_variable\n    validate_shape=validate_shape)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 202, in _true_getter\n    caching_device=caching_device, validate_shape=validate_shape)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 479, in _get_single_variable\n    raise ValueError(\"If initializer is a constant, do not specify shape.\")\nValueError: If initializer is a constant, do not specify shape.\n</code></pre>\n<p>I removed redundant arguments but then convolution2d doesn't have default value for them.</p>\n<pre><code>net = layers.convolution2d(inputs, weights_initializer=conv1_1, scope='conv1_1')\n</code></pre>\n<pre><code>Traceback (most recent call last):\n  File \"tf1.py\", line 14, in &lt;module&gt;\n    net = layers.convolution2d(inputs, weights_initializer=conv1_1, scope='conv1_1')\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\nTypeError: convolution2d() missing 2 required positional arguments: 'num_outputs' and 'kernel_size'\n</code></pre>\n<p>I fixed the problem by adding support inside convolution2d code here:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L322\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L322</a><br>\nIt works now and I don't have to pass redundant arguments.</p>\n<pre><code>@add_arg_scope\ndef convolution2d(inputs,\n                  num_outputs=None,\n                  kernel_size=None,\n                  stride=1,\n                  padding='SAME',\n                  rate=1,\n                  activation_fn=nn.relu,\n                  normalizer_fn=None,\n                  normalizer_params=None,\n                  weights_initializer=initializers.xavier_initializer(),\n                  weights_regularizer=None,\n                  biases_initializer=init_ops.zeros_initializer,\n                  biases_regularizer=None,\n                  reuse=None,\n                  variables_collections=None,\n                  outputs_collections=None,\n                  trainable=True,\n                  scope=None):\n  with variable_scope.variable_op_scope([inputs],\n                                        scope, 'Conv', reuse=reuse) as sc:\n    inputs = ops.convert_to_tensor(inputs)\n    dtype = inputs.dtype.base_dtype\n    stride_h, stride_w = utils.two_element_tuple(stride)\n    if rate &gt; 1 and (stride_h &gt; 1 or stride_w &gt; 1):\n      raise ValueError('Only one of rate or stride can be larger than one')\n    num_filters_in = utils.last_dimension(inputs.get_shape(), min_rank=4)\n\n    initializing_from_value = False\n    if weights_initializer is not None and not callable(weights_initializer):\n      initializing_from_value = True\n      weights_shape = None\n    else:\n      if kernel_size == None or num_outputs == None:\n        raise ValueError('Kernel size and number of outputs must be defined')\n      kernel_h, kernel_w = utils.two_element_tuple(kernel_size)\n      weights_shape = [kernel_h, kernel_w,\n                       num_filters_in, num_outputs]\n    if biases_initializer is not None and not callable(biases_initializer):\n      bias_shape = None\n    else:\n      if num_outputs == None:\n        raise ValueError('Number of outputs must be defined')\n      bias_shape = [num_outputs]\n\n    weights_collections = utils.get_variable_collections(\n        variables_collections, 'weights')\n    weights = variables.model_variable('weights',\n                                       shape=weights_shape,\n                                       dtype=dtype,\n                                       initializer=weights_initializer,\n                                       regularizer=weights_regularizer,\n                                       collections=weights_collections,\n                                       trainable=trainable)\n    if rate &gt; 1:\n      outputs = nn.atrous_conv2d(inputs, weights, rate, padding=padding)\n    else:\n      outputs = nn.conv2d(inputs, weights, [1, stride_h, stride_w, 1],\n                          padding=padding)\n    if normalizer_fn:\n      normalizer_params = normalizer_params or {}\n      outputs = normalizer_fn(outputs, **normalizer_params)\n    else:\n      if biases_initializer is not None:\n        biases_collections = utils.get_variable_collections(\n            variables_collections, 'biases')\n        biases = variables.model_variable('biases',\n                                          shape=bias_shape,\n                                          dtype=dtype,\n                                          initializer=biases_initializer,\n                                          regularizer=biases_regularizer,\n                                          collections=biases_collections,\n                                          trainable=trainable)\n        outputs = nn.bias_add(outputs, biases)\n    if activation_fn:\n      outputs = activation_fn(outputs)\n    return utils.collect_named_outputs(outputs_collections, sc.name, outputs)\n</code></pre>", "body_text": "I can't find a way to pass a numpy tensor to layers.convolution2d weights/bias initialization arguments.\nI added support for this by modifying convolution2d, code is below. I need this feature in order  If you like this solution I can add this feature to other ops also and create a pull request.\nFirst I tried this:\nimport tensorflow as tf\nimport tensorflow.contrib.layers as layers\nimport numpy as np\n\nconv1_1 = np.random.rand(3, 3, 3, 64).astype(dtype=np.float32)\ninputs = tf.placeholder(tf.float32, shape=(32, 96, 96, 3))\nnet = layers.convolution2d(inputs, 64, 3, weights_initializer=conv1_1, scope='conv1_1')\n\nbut get_variable method doesn't allow redundant shape argument when initializing from constant.\nTraceback (most recent call last):\n  File \"tf1.py\", line 16, in <module>\n    net = layers.convolution2d(inputs, 64, 3, weights_initializer=conv1_1, scope='conv1_1')\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 406, in convolution2d\n    trainable=trainable)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 266, in model_variable\n    caching_device=caching_device, device=device)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 230, in variable\n    caching_device=caching_device)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 873, in get_variable\n    custom_getter=custom_getter)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 700, in get_variable\n    custom_getter=custom_getter)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 217, in get_variable\n    validate_shape=validate_shape)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 202, in _true_getter\n    caching_device=caching_device, validate_shape=validate_shape)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 479, in _get_single_variable\n    raise ValueError(\"If initializer is a constant, do not specify shape.\")\nValueError: If initializer is a constant, do not specify shape.\n\nI removed redundant arguments but then convolution2d doesn't have default value for them.\nnet = layers.convolution2d(inputs, weights_initializer=conv1_1, scope='conv1_1')\n\nTraceback (most recent call last):\n  File \"tf1.py\", line 14, in <module>\n    net = layers.convolution2d(inputs, weights_initializer=conv1_1, scope='conv1_1')\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\nTypeError: convolution2d() missing 2 required positional arguments: 'num_outputs' and 'kernel_size'\n\nI fixed the problem by adding support inside convolution2d code here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L322\nIt works now and I don't have to pass redundant arguments.\n@add_arg_scope\ndef convolution2d(inputs,\n                  num_outputs=None,\n                  kernel_size=None,\n                  stride=1,\n                  padding='SAME',\n                  rate=1,\n                  activation_fn=nn.relu,\n                  normalizer_fn=None,\n                  normalizer_params=None,\n                  weights_initializer=initializers.xavier_initializer(),\n                  weights_regularizer=None,\n                  biases_initializer=init_ops.zeros_initializer,\n                  biases_regularizer=None,\n                  reuse=None,\n                  variables_collections=None,\n                  outputs_collections=None,\n                  trainable=True,\n                  scope=None):\n  with variable_scope.variable_op_scope([inputs],\n                                        scope, 'Conv', reuse=reuse) as sc:\n    inputs = ops.convert_to_tensor(inputs)\n    dtype = inputs.dtype.base_dtype\n    stride_h, stride_w = utils.two_element_tuple(stride)\n    if rate > 1 and (stride_h > 1 or stride_w > 1):\n      raise ValueError('Only one of rate or stride can be larger than one')\n    num_filters_in = utils.last_dimension(inputs.get_shape(), min_rank=4)\n\n    initializing_from_value = False\n    if weights_initializer is not None and not callable(weights_initializer):\n      initializing_from_value = True\n      weights_shape = None\n    else:\n      if kernel_size == None or num_outputs == None:\n        raise ValueError('Kernel size and number of outputs must be defined')\n      kernel_h, kernel_w = utils.two_element_tuple(kernel_size)\n      weights_shape = [kernel_h, kernel_w,\n                       num_filters_in, num_outputs]\n    if biases_initializer is not None and not callable(biases_initializer):\n      bias_shape = None\n    else:\n      if num_outputs == None:\n        raise ValueError('Number of outputs must be defined')\n      bias_shape = [num_outputs]\n\n    weights_collections = utils.get_variable_collections(\n        variables_collections, 'weights')\n    weights = variables.model_variable('weights',\n                                       shape=weights_shape,\n                                       dtype=dtype,\n                                       initializer=weights_initializer,\n                                       regularizer=weights_regularizer,\n                                       collections=weights_collections,\n                                       trainable=trainable)\n    if rate > 1:\n      outputs = nn.atrous_conv2d(inputs, weights, rate, padding=padding)\n    else:\n      outputs = nn.conv2d(inputs, weights, [1, stride_h, stride_w, 1],\n                          padding=padding)\n    if normalizer_fn:\n      normalizer_params = normalizer_params or {}\n      outputs = normalizer_fn(outputs, **normalizer_params)\n    else:\n      if biases_initializer is not None:\n        biases_collections = utils.get_variable_collections(\n            variables_collections, 'biases')\n        biases = variables.model_variable('biases',\n                                          shape=bias_shape,\n                                          dtype=dtype,\n                                          initializer=biases_initializer,\n                                          regularizer=biases_regularizer,\n                                          collections=biases_collections,\n                                          trainable=trainable)\n        outputs = nn.bias_add(outputs, biases)\n    if activation_fn:\n      outputs = activation_fn(outputs)\n    return utils.collect_named_outputs(outputs_collections, sc.name, outputs)", "body": "I can't find a way to pass a numpy tensor to layers.convolution2d weights/bias initialization arguments.\nI added support for this by modifying convolution2d, code is below. I need this feature in order  If you like this solution I can add this feature to other ops also and create a pull request.\n\nFirst I tried this:\n\n```\nimport tensorflow as tf\nimport tensorflow.contrib.layers as layers\nimport numpy as np\n\nconv1_1 = np.random.rand(3, 3, 3, 64).astype(dtype=np.float32)\ninputs = tf.placeholder(tf.float32, shape=(32, 96, 96, 3))\nnet = layers.convolution2d(inputs, 64, 3, weights_initializer=conv1_1, scope='conv1_1')\n```\n\nbut get_variable method doesn't allow redundant shape argument when initializing from constant.\n\n```\nTraceback (most recent call last):\n  File \"tf1.py\", line 16, in <module>\n    net = layers.convolution2d(inputs, 64, 3, weights_initializer=conv1_1, scope='conv1_1')\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 406, in convolution2d\n    trainable=trainable)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 266, in model_variable\n    caching_device=caching_device, device=device)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 230, in variable\n    caching_device=caching_device)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 873, in get_variable\n    custom_getter=custom_getter)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 700, in get_variable\n    custom_getter=custom_getter)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 217, in get_variable\n    validate_shape=validate_shape)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 202, in _true_getter\n    caching_device=caching_device, validate_shape=validate_shape)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 479, in _get_single_variable\n    raise ValueError(\"If initializer is a constant, do not specify shape.\")\nValueError: If initializer is a constant, do not specify shape.\n```\n\nI removed redundant arguments but then convolution2d doesn't have default value for them. \n\n```\nnet = layers.convolution2d(inputs, weights_initializer=conv1_1, scope='conv1_1')\n```\n\n```\nTraceback (most recent call last):\n  File \"tf1.py\", line 14, in <module>\n    net = layers.convolution2d(inputs, weights_initializer=conv1_1, scope='conv1_1')\n  File \"/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 171, in func_with_args\n    return func(*args, **current_args)\nTypeError: convolution2d() missing 2 required positional arguments: 'num_outputs' and 'kernel_size'\n```\n\nI fixed the problem by adding support inside convolution2d code here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L322\nIt works now and I don't have to pass redundant arguments.\n\n```\n@add_arg_scope\ndef convolution2d(inputs,\n                  num_outputs=None,\n                  kernel_size=None,\n                  stride=1,\n                  padding='SAME',\n                  rate=1,\n                  activation_fn=nn.relu,\n                  normalizer_fn=None,\n                  normalizer_params=None,\n                  weights_initializer=initializers.xavier_initializer(),\n                  weights_regularizer=None,\n                  biases_initializer=init_ops.zeros_initializer,\n                  biases_regularizer=None,\n                  reuse=None,\n                  variables_collections=None,\n                  outputs_collections=None,\n                  trainable=True,\n                  scope=None):\n  with variable_scope.variable_op_scope([inputs],\n                                        scope, 'Conv', reuse=reuse) as sc:\n    inputs = ops.convert_to_tensor(inputs)\n    dtype = inputs.dtype.base_dtype\n    stride_h, stride_w = utils.two_element_tuple(stride)\n    if rate > 1 and (stride_h > 1 or stride_w > 1):\n      raise ValueError('Only one of rate or stride can be larger than one')\n    num_filters_in = utils.last_dimension(inputs.get_shape(), min_rank=4)\n\n    initializing_from_value = False\n    if weights_initializer is not None and not callable(weights_initializer):\n      initializing_from_value = True\n      weights_shape = None\n    else:\n      if kernel_size == None or num_outputs == None:\n        raise ValueError('Kernel size and number of outputs must be defined')\n      kernel_h, kernel_w = utils.two_element_tuple(kernel_size)\n      weights_shape = [kernel_h, kernel_w,\n                       num_filters_in, num_outputs]\n    if biases_initializer is not None and not callable(biases_initializer):\n      bias_shape = None\n    else:\n      if num_outputs == None:\n        raise ValueError('Number of outputs must be defined')\n      bias_shape = [num_outputs]\n\n    weights_collections = utils.get_variable_collections(\n        variables_collections, 'weights')\n    weights = variables.model_variable('weights',\n                                       shape=weights_shape,\n                                       dtype=dtype,\n                                       initializer=weights_initializer,\n                                       regularizer=weights_regularizer,\n                                       collections=weights_collections,\n                                       trainable=trainable)\n    if rate > 1:\n      outputs = nn.atrous_conv2d(inputs, weights, rate, padding=padding)\n    else:\n      outputs = nn.conv2d(inputs, weights, [1, stride_h, stride_w, 1],\n                          padding=padding)\n    if normalizer_fn:\n      normalizer_params = normalizer_params or {}\n      outputs = normalizer_fn(outputs, **normalizer_params)\n    else:\n      if biases_initializer is not None:\n        biases_collections = utils.get_variable_collections(\n            variables_collections, 'biases')\n        biases = variables.model_variable('biases',\n                                          shape=bias_shape,\n                                          dtype=dtype,\n                                          initializer=biases_initializer,\n                                          regularizer=biases_regularizer,\n                                          collections=biases_collections,\n                                          trainable=trainable)\n        outputs = nn.bias_add(outputs, biases)\n    if activation_fn:\n      outputs = activation_fn(outputs)\n    return utils.collect_named_outputs(outputs_collections, sc.name, outputs)\n```\n"}