{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3429", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3429/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3429/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3429/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3429", "id": 166694639, "node_id": "MDU6SXNzdWUxNjY2OTQ2Mzk=", "number": 3429, "title": "[Python][Quantized Inference] 'Zero is not representable' when doing inference from quantized const graph def", "user": {"login": "chunhuizhusc", "id": 20362857, "node_id": "MDQ6VXNlcjIwMzYyODU3", "avatar_url": "https://avatars3.githubusercontent.com/u/20362857?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chunhuizhusc", "html_url": "https://github.com/chunhuizhusc", "followers_url": "https://api.github.com/users/chunhuizhusc/followers", "following_url": "https://api.github.com/users/chunhuizhusc/following{/other_user}", "gists_url": "https://api.github.com/users/chunhuizhusc/gists{/gist_id}", "starred_url": "https://api.github.com/users/chunhuizhusc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chunhuizhusc/subscriptions", "organizations_url": "https://api.github.com/users/chunhuizhusc/orgs", "repos_url": "https://api.github.com/users/chunhuizhusc/repos", "events_url": "https://api.github.com/users/chunhuizhusc/events{/privacy}", "received_events_url": "https://api.github.com/users/chunhuizhusc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2016-07-20T22:12:42Z", "updated_at": "2016-09-28T20:10:12Z", "closed_at": "2016-09-28T20:10:12Z", "author_association": "NONE", "body_html": "<p>I used the checkpoint file and the graph def file to generate the const graph def file using the freeze_graph script. Then I used the quantize_graph tool to generate a quantized model. The output file sizes from these steps seem reasonable. But I failed to run a inference using the generated quantized model.</p>\n<p>Tried both tensorflow 0.8.0 and 0.9.0, they both failed but with different errors though. For 0.80, it will output:</p>\n<p>W tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.\"</p>\n<p>For 0.9.0, it wouldn't load the lib with:<br>\n_quantized_kernels = tf.load_op_library(PATH_TO_KERNAL_OS)<br>\n_quantized_ops = tf.load_op_library(PATH_TO_OPS_OS)<br>\nI got some signature errors.</p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nUbuntu 14.04</p>\n<p>If installed from binary pip package, provide:<br>\nInstalled the 0.8.0, but tried with 0.9.0 as well.</p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Generate a checkpoint file and graph def file</li>\n<li>Using freeze_graph and quantize_graph to generate a quantized const graph def binary file</li>\n<li>Build the quantized_kernels.so and quantized_ops.so</li>\n<li>tf.load_op_library() to load the two libraries. version 0.9.0 will fail at this step</li>\n<li>Extract the input and output node names, feed the input properly and run the session</li>\n<li>version 0.8.0 will fail at this step with the following errors:</li>\n</ol>\n<p>W tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.<br>\nW tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.<br>\nterminate called after throwing an instance of 'std::bad_alloc'<br>\nwhat():  std::bad_alloc<br>\nAborted (core dumped)</p>\n<h3>What have you tried?</h3>\n<p>Described above</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>Added above.</p>", "body_text": "I used the checkpoint file and the graph def file to generate the const graph def file using the freeze_graph script. Then I used the quantize_graph tool to generate a quantized model. The output file sizes from these steps seem reasonable. But I failed to run a inference using the generated quantized model.\nTried both tensorflow 0.8.0 and 0.9.0, they both failed but with different errors though. For 0.80, it will output:\nW tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.\"\nFor 0.9.0, it wouldn't load the lib with:\n_quantized_kernels = tf.load_op_library(PATH_TO_KERNAL_OS)\n_quantized_ops = tf.load_op_library(PATH_TO_OPS_OS)\nI got some signature errors.\nEnvironment info\nOperating System:\nUbuntu 14.04\nIf installed from binary pip package, provide:\nInstalled the 0.8.0, but tried with 0.9.0 as well.\nSteps to reproduce\n\nGenerate a checkpoint file and graph def file\nUsing freeze_graph and quantize_graph to generate a quantized const graph def binary file\nBuild the quantized_kernels.so and quantized_ops.so\ntf.load_op_library() to load the two libraries. version 0.9.0 will fail at this step\nExtract the input and output node names, feed the input properly and run the session\nversion 0.8.0 will fail at this step with the following errors:\n\nW tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.\nW tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.\nterminate called after throwing an instance of 'std::bad_alloc'\nwhat():  std::bad_alloc\nAborted (core dumped)\nWhat have you tried?\nDescribed above\nLogs or other output that would be helpful\nAdded above.", "body": "I used the checkpoint file and the graph def file to generate the const graph def file using the freeze_graph script. Then I used the quantize_graph tool to generate a quantized model. The output file sizes from these steps seem reasonable. But I failed to run a inference using the generated quantized model.\n\nTried both tensorflow 0.8.0 and 0.9.0, they both failed but with different errors though. For 0.80, it will output:\n\nW tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.\"\n\nFor 0.9.0, it wouldn't load the lib with:\n_quantized_kernels = tf.load_op_library(PATH_TO_KERNAL_OS)\n_quantized_ops = tf.load_op_library(PATH_TO_OPS_OS)\nI got some signature errors.\n### Environment info\n\nOperating System:\nUbuntu 14.04\n\nIf installed from binary pip package, provide:\nInstalled the 0.8.0, but tried with 0.9.0 as well.\n### Steps to reproduce\n1. Generate a checkpoint file and graph def file\n2. Using freeze_graph and quantize_graph to generate a quantized const graph def binary file\n3. Build the quantized_kernels.so and quantized_ops.so\n4. tf.load_op_library() to load the two libraries. version 0.9.0 will fail at this step\n5. Extract the input and output node names, feed the input properly and run the session \n6. version 0.8.0 will fail at this step with the following errors:\n\nW tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.\nW tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc:201] Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.\nterminate called after throwing an instance of 'std::bad_alloc'\n  what():  std::bad_alloc\nAborted (core dumped)\n### What have you tried?\n\nDescribed above\n### Logs or other output that would be helpful\n\nAdded above.\n"}