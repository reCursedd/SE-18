{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/429325474", "html_url": "https://github.com/tensorflow/tensorflow/issues/22938#issuecomment-429325474", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22938", "id": 429325474, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTMyNTQ3NA==", "user": {"login": "cjr0106", "id": 32252431, "node_id": "MDQ6VXNlcjMyMjUyNDMx", "avatar_url": "https://avatars3.githubusercontent.com/u/32252431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjr0106", "html_url": "https://github.com/cjr0106", "followers_url": "https://api.github.com/users/cjr0106/followers", "following_url": "https://api.github.com/users/cjr0106/following{/other_user}", "gists_url": "https://api.github.com/users/cjr0106/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjr0106/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjr0106/subscriptions", "organizations_url": "https://api.github.com/users/cjr0106/orgs", "repos_url": "https://api.github.com/users/cjr0106/repos", "events_url": "https://api.github.com/users/cjr0106/events{/privacy}", "received_events_url": "https://api.github.com/users/cjr0106/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-12T13:27:58Z", "updated_at": "2018-10-12T13:27:58Z", "author_association": "NONE", "body_html": "<p>i download the ssd_mobilenet_v1_quantized_coco  model from <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md</a><br>\ni want to quantize it ,then used on mobile,but i got  the error:<br>\n<code>WARNING:tensorflow:From quant.py:9: TocoConverter.from_frozen_graph (from tensorflow.contrib.lite.python.lite) is deprecated and will be removed in a future version. Instructions for updating: Use </code>lite.TFLiteConverter.from_frozen_graph<code>instead. 2018-10-12 13:26:50.610018: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA but ^H^H^HTraceback (most recent call last): File \"quant.py\", line 17, in &lt;module&gt; mobilenet_tflite_file.write_bytes(converter.convert()) File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/lite.py\", line 464, in convert **converter_kwargs) File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 317, in toco_convert_graph_def input_data.SerializeToString()) File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 135, in toco_convert_protos (stdout, stderr)) RuntimeError: TOCO failed see console for info. b'2018-10-12 13:26:54.789335: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1109] Converting unsupported operation: TFLite_Detection_PostProcess\\n2018-10-12 13:26:54.795610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1182] Unable to determine output type for op: TFLite_Detection_PostProcess\\n2018-10-12 13:26:54.838750: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 900 operators, 1352 arrays (0 quantized)\\n2018-10-12 13:26:54.886856: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 900 operators, 1352 arrays (0 quantized)\\n2018-10-12 13:26:56.012297: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 111 operators, 220 arrays (0 quantized)\\n2018-10-12 13:26:56.016248: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 111 operators, 220 arrays (0 quantized)\\n2018-10-12 13:26:56.022161: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 11520000 bytes, theoretical optimal value: 11520000 bytes.\\n2018-10-12 13:26:56.022669: I tensorflow/contrib/lite/toco/toco_tooling.cc:397] Estimated count of arithmetic ops: 2.49483 billion (note that a multiply-add is counted as 2 ops).\\n2018-10-12 13:26:56.023102: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023121: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023129: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023137: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023144: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023152: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023160: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023170: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023179: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023187: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023198: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023207: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023214: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023223: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023234: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023243: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023253: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023261: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023269: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023277: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023285: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023292: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023301: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023309: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023318: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023327: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023336: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023345: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023354: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023363: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023372: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023381: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023389: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023398: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023407: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023416: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023425: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023434: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023443: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023452: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023461: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023469: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023477: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023484: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023491: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023499: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023508: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023519: F tensorflow/contrib/lite/toco/tflite/export.cc:460] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.contrib.lite.TFLiteConverter(). Here is a list of operators for which  you will need custom implementations: TFLite_Detection_PostProcess.\\nAborted (core dumped)\\n' None</code></p>", "body_text": "i download the ssd_mobilenet_v1_quantized_coco  model from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\ni want to quantize it ,then used on mobile,but i got  the error:\nWARNING:tensorflow:From quant.py:9: TocoConverter.from_frozen_graph (from tensorflow.contrib.lite.python.lite) is deprecated and will be removed in a future version. Instructions for updating: Use lite.TFLiteConverter.from_frozen_graphinstead. 2018-10-12 13:26:50.610018: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA but ^H^H^HTraceback (most recent call last): File \"quant.py\", line 17, in <module> mobilenet_tflite_file.write_bytes(converter.convert()) File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/lite.py\", line 464, in convert **converter_kwargs) File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 317, in toco_convert_graph_def input_data.SerializeToString()) File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 135, in toco_convert_protos (stdout, stderr)) RuntimeError: TOCO failed see console for info. b'2018-10-12 13:26:54.789335: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1109] Converting unsupported operation: TFLite_Detection_PostProcess\\n2018-10-12 13:26:54.795610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1182] Unable to determine output type for op: TFLite_Detection_PostProcess\\n2018-10-12 13:26:54.838750: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 900 operators, 1352 arrays (0 quantized)\\n2018-10-12 13:26:54.886856: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 900 operators, 1352 arrays (0 quantized)\\n2018-10-12 13:26:56.012297: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 111 operators, 220 arrays (0 quantized)\\n2018-10-12 13:26:56.016248: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 111 operators, 220 arrays (0 quantized)\\n2018-10-12 13:26:56.022161: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 11520000 bytes, theoretical optimal value: 11520000 bytes.\\n2018-10-12 13:26:56.022669: I tensorflow/contrib/lite/toco/toco_tooling.cc:397] Estimated count of arithmetic ops: 2.49483 billion (note that a multiply-add is counted as 2 ops).\\n2018-10-12 13:26:56.023102: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023121: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023129: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023137: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023144: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023152: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023160: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023170: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023179: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023187: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023198: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023207: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023214: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023223: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023234: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023243: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023253: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023261: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023269: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023277: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023285: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023292: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023301: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023309: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023318: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023327: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023336: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023345: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023354: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023363: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023372: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023381: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023389: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023398: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023407: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023416: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023425: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023434: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023443: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023452: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023461: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023469: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023477: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023484: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023491: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023499: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023508: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023519: F tensorflow/contrib/lite/toco/tflite/export.cc:460] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.contrib.lite.TFLiteConverter(). Here is a list of operators for which  you will need custom implementations: TFLite_Detection_PostProcess.\\nAborted (core dumped)\\n' None", "body": "i download the ssd_mobilenet_v1_quantized_coco  model from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\r\ni want to quantize it ,then used on mobile,but i got  the error:\r\n`WARNING:tensorflow:From quant.py:9: TocoConverter.from_frozen_graph (from tensorflow.contrib.lite.python.lite) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `lite.TFLiteConverter.from_frozen_graph` instead.\r\n2018-10-12 13:26:50.610018: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nbut ^H^H^HTraceback (most recent call last):\r\n  File \"quant.py\", line 17, in <module>\r\n    mobilenet_tflite_file.write_bytes(converter.convert())\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/lite.py\", line 464, in convert\r\n    **converter_kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 317, in toco_convert_graph_def\r\n    input_data.SerializeToString())\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 135, in toco_convert_protos\r\n    (stdout, stderr))\r\nRuntimeError: TOCO failed see console for info.\r\nb'2018-10-12 13:26:54.789335: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1109] Converting unsupported operation: TFLite_Detection_PostProcess\\n2018-10-12 13:26:54.795610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1182] Unable to determine output type for op: TFLite_Detection_PostProcess\\n2018-10-12 13:26:54.838750: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 900 operators, 1352 arrays (0 quantized)\\n2018-10-12 13:26:54.886856: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 900 operators, 1352 arrays (0 quantized)\\n2018-10-12 13:26:56.012297: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 111 operators, 220 arrays (0 quantized)\\n2018-10-12 13:26:56.016248: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 111 operators, 220 arrays (0 quantized)\\n2018-10-12 13:26:56.022161: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 11520000 bytes, theoretical optimal value: 11520000 bytes.\\n2018-10-12 13:26:56.022669: I tensorflow/contrib/lite/toco/toco_tooling.cc:397] Estimated count of arithmetic ops: 2.49483 billion (note that a multiply-add is counted as 2 ops).\\n2018-10-12 13:26:56.023102: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023121: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023129: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023137: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023144: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023152: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023160: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023170: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023179: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023187: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023198: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023207: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023214: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023223: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023234: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023243: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023253: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023261: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023269: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023277: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023285: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023292: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023301: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023309: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023318: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023327: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023336: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023345: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023354: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023363: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023372: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023381: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023389: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023398: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023407: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023416: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023425: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023434: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023443: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023452: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023461: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023469: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023477: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023484: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023491: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023499: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023508: W tensorflow/contrib/lite/toco/tflite/export.cc:423] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\\n2018-10-12 13:26:56.023519: F tensorflow/contrib/lite/toco/tflite/export.cc:460] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.contrib.lite.TFLiteConverter(). Here is a list of operators for which  you will need custom implementations: TFLite_Detection_PostProcess.\\nAborted (core dumped)\\n'\r\nNone\r\n`\r\n\r\n"}