{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14323", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14323/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14323/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14323/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14323", "id": 271882437, "node_id": "MDU6SXNzdWUyNzE4ODI0Mzc=", "number": 14323, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 0", "user": {"login": "stevenhanjun", "id": 4454187, "node_id": "MDQ6VXNlcjQ0NTQxODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/4454187?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stevenhanjun", "html_url": "https://github.com/stevenhanjun", "followers_url": "https://api.github.com/users/stevenhanjun/followers", "following_url": "https://api.github.com/users/stevenhanjun/following{/other_user}", "gists_url": "https://api.github.com/users/stevenhanjun/gists{/gist_id}", "starred_url": "https://api.github.com/users/stevenhanjun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stevenhanjun/subscriptions", "organizations_url": "https://api.github.com/users/stevenhanjun/orgs", "repos_url": "https://api.github.com/users/stevenhanjun/repos", "events_url": "https://api.github.com/users/stevenhanjun/events{/privacy}", "received_events_url": "https://api.github.com/users/stevenhanjun/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-07T15:52:43Z", "updated_at": "2017-11-07T19:27:20Z", "closed_at": "2017-11-07T19:27:20Z", "author_association": "NONE", "body_html": "<p>When I use tensorflow to build my own neural network and run it, I meet a very strange error. The error is that tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 0. Expected [400], got [3200]. I have no idea about how [3200] comes, could anyone can help to fix this problem? The input of the neural network is a 400-dimension vector.</p>\n<p>Here is my code:</p>\n<p>tf.logging.set_verbosity(tf.logging.INFO)</p>\n<p>def _cnn_model_fn(features,labels,mode):<br>\ninput_layer = tf.reshape(features['inputs'],[-1,400])<br>\nprint(features['inputs'].shape)<br>\nfc1 = tf.layers.dense(input_layer,1024,activation=tf.nn.relu)<br>\nfc2 = tf.layers.dense(fc1,1024,activation=tf.nn.relu)<br>\nfc3 = tf.layers.dense(fc2,1024,activation=tf.nn.relu)<br>\nfc4 = tf.layers.dense(fc3,1,activation=tf.nn.sigmoid)<br>\nprint(fc4.shape)<br>\nlabels = tf.reshape(labels,[-1,1])<br>\nfc4 = tf.reshape(fc4,[-1,1])<br>\nprint(labels.shape)<br>\nprint(fc4.shape)<br>\nif mode in (Modes.PREDICT,Modes.EVAL):<br>\nprint(\"P and E\")<br>\npre = fc4<br>\nif mode in (Modes.TRAIN,Modes.EVAL):<br>\nprint('T and E')<br>\nglobal_step = tf.contrib.framework.get_or_create_global_step()<br>\nloss = tf.losses.mean_squared_error(labels=labels,predictions=fc4)<br>\ntf.summary.scalar('OptimizeLoss',loss)<br>\nif mode == Modes.PREDICT:<br>\nprint('P')<br>\npredictions = {<br>\n'vaule': pre<br>\n}<br>\nexport_outputs = {<br>\n'prediction': tf.estimator.export.PredictOutput(predictions)<br>\n}<br>\nreturn tf.estimator.EstimatorSpec(<br>\nmode, predictions=predictions, export_outputs=export_outputs)<br>\nif mode == Modes.TRAIN:<br>\nprint('T')<br>\noptimizer = tf.train.AdamOptimizer(learning_rate=0.01)<br>\nprint('optimizer')<br>\ntrain_op = optimizer.minimize(loss)<br>\nprint('train_op')<br>\nreturn tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)<br>\nif mode == Modes.EVAL:<br>\nprint('E')<br>\neval_metric_ops = {<br>\n'accuracy':tf.metrics.accuray(labels,pre)<br>\n}<br>\nreturn tf.estimator.EstimatorSpec(mode,loss=loss,eval_metric_ops=eval_metric_ops)</p>\n<p>def build_estimator(model_dir):<br>\nreturn tf.estimator.Estimator(<br>\nmodel_fn=_cnn_model_fn,<br>\nmodel_dir=model_dir,<br>\nconfig=tf.contrib.learn.RunConfig(save_checkpoints_secs=60))</p>\n<p>def serving_input_fn():<br>\ninputs = {'inputs': tf.placeholder(tf.float32, [None, 400])}<br>\nreturn tf.estimator.export.ServingInputReceiver(inputs, inputs)</p>\n<p>def read_and_decode(filename_queue):<br>\nreader = tf.TFRecordReader()<br>\n_, serialized_example = reader.read(filename_queue)</p>\n<p>features = tf.parse_single_example(<br>\nserialized_example,<br>\nfeatures={<br>\n'image_raw': tf.FixedLenFeature([], tf.string),<br>\n'label': tf.FixedLenFeature([], tf.float32),<br>\n})</p>\n<p>image = tf.decode_raw(features['image_raw'], tf.uint8)<br>\nimage.set_shape([400])<br>\nprint('image')<br>\nprint(image.shape)<br>\nimage = tf.cast(image, tf.float32)<br>\nlabel = tf.cast(features['label'], tf.float32)<br>\nreturn image, label</p>\n<p>def input_fn(filename, batch_size=100):<br>\nfilename_queue = tf.train.string_input_producer([filename])</p>\n<p>image, label = read_and_decode(filename_queue)<br>\nimages, labels = tf.train.batch(<br>\n[image, label], batch_size=batch_size)<br>\nprint(images.shape)</p>\n<p>return {'inputs': images}, labels</p>\n<p>def get_input_fn(filename, batch_size=100):<br>\nreturn lambda: input_fn(filename, batch_size)</p>\n<p>def generate_experiment_fn(data_dir,<br>\ntrain_batch_size=100,<br>\neval_batch_size=100,<br>\ntrain_steps=5000,<br>\neval_steps=100,<br>\n**experiment_args):</p>\n<p>def _experiment_fn(output_dir):<br>\nreturn Experiment(<br>\nbuild_estimator(output_dir),<br>\ntrain_input_fn=get_input_fn(<br>\nfilename=os.path.join(data_dir, 'train.tfrecords'),<br>\nbatch_size=train_batch_size),<br>\neval_input_fn=get_input_fn(<br>\nfilename=os.path.join(data_dir, 'test.tfrecords'),<br>\nbatch_size=eval_batch_size),<br>\nexport_strategies=[saved_model_export_utils.make_export_strategy(<br>\nserving_input_fn,<br>\ndefault_output_alternative_key=None,<br>\nexports_to_keep=1)],<br>\ntrain_steps=train_steps,<br>\neval_steps=eval_steps,<br>\n**experiment_args<br>\n)<br>\nreturn _experiment_fn</p>\n<p>if <strong>name</strong> == '<strong>main</strong>':<br>\nparser = argparse.ArgumentParser()<br>\nparser.add_argument(<br>\n'--data_dir',<br>\nhelp='GCS or local path to training data',<br>\ntype = str,<br>\ndefault = '/Users/hanjun/Desktop/OS/scripts'<br>\n#required=True<br>\n)<br>\nparser.add_argument(<br>\n'--train_batch_size',<br>\nhelp='Batch size for training steps',<br>\ntype=int,<br>\ndefault=100<br>\n)</p>\n<p>parser.add_argument(<br>\n'--eval_batch_size',<br>\nhelp='Batch size for evaluation steps',<br>\ntype=int,<br>\ndefault=100<br>\n)</p>\n<p>parser.add_argument(<br>\n'--train_steps',<br>\nhelp='Steps to run the training job for.',<br>\ntype=int,<br>\ndefault=5000<br>\n)</p>\n<p>parser.add_argument(<br>\n'--eval_steps',<br>\nhelp='Number of steps to run evalution for at each checkpoint',<br>\ndefault=100,<br>\ntype=int<br>\n)</p>\n<p>parser.add_argument(<br>\n'--output_dir',<br>\nhelp='GCS location to write checkpoints and export models',<br>\ntype = str,<br>\ndefault = '/Users/hanjun/Desktop/OS/Model'<br>\n#required=True<br>\n)<br>\nparser.add_argument(<br>\n'--job-dir',<br>\nhelp='this model ignores this field, but it is required by gcloud',<br>\ndefault='junk'<br>\n)</p>\n<p>parser.add_argument(<br>\n'--eval_delay_secs',<br>\nhelp='How long to wait before running first evaluation',<br>\ndefault=10,<br>\ntype=int<br>\n)<br>\nparser.add_argument(<br>\n'--min_eval_frequency',<br>\nhelp='Minimum number of training steps between evaluations',<br>\ndefault=1,<br>\ntype=int<br>\n)</p>\n<p>args = parser.parse_args()<br>\narguments = args.<strong>dict</strong></p>\n<h1>unused args provided by service</h1>\n<p>arguments.pop('job_dir', None)<br>\narguments.pop('job-dir', None)</p>\n<p>output_dir = arguments.pop('output_dir')</p>\n<h1>Run the training job</h1>\n<p>learn_runner.run(generate_experiment_fn(**arguments), output_dir)</p>", "body_text": "When I use tensorflow to build my own neural network and run it, I meet a very strange error. The error is that tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 0. Expected [400], got [3200]. I have no idea about how [3200] comes, could anyone can help to fix this problem? The input of the neural network is a 400-dimension vector.\nHere is my code:\ntf.logging.set_verbosity(tf.logging.INFO)\ndef _cnn_model_fn(features,labels,mode):\ninput_layer = tf.reshape(features['inputs'],[-1,400])\nprint(features['inputs'].shape)\nfc1 = tf.layers.dense(input_layer,1024,activation=tf.nn.relu)\nfc2 = tf.layers.dense(fc1,1024,activation=tf.nn.relu)\nfc3 = tf.layers.dense(fc2,1024,activation=tf.nn.relu)\nfc4 = tf.layers.dense(fc3,1,activation=tf.nn.sigmoid)\nprint(fc4.shape)\nlabels = tf.reshape(labels,[-1,1])\nfc4 = tf.reshape(fc4,[-1,1])\nprint(labels.shape)\nprint(fc4.shape)\nif mode in (Modes.PREDICT,Modes.EVAL):\nprint(\"P and E\")\npre = fc4\nif mode in (Modes.TRAIN,Modes.EVAL):\nprint('T and E')\nglobal_step = tf.contrib.framework.get_or_create_global_step()\nloss = tf.losses.mean_squared_error(labels=labels,predictions=fc4)\ntf.summary.scalar('OptimizeLoss',loss)\nif mode == Modes.PREDICT:\nprint('P')\npredictions = {\n'vaule': pre\n}\nexport_outputs = {\n'prediction': tf.estimator.export.PredictOutput(predictions)\n}\nreturn tf.estimator.EstimatorSpec(\nmode, predictions=predictions, export_outputs=export_outputs)\nif mode == Modes.TRAIN:\nprint('T')\noptimizer = tf.train.AdamOptimizer(learning_rate=0.01)\nprint('optimizer')\ntrain_op = optimizer.minimize(loss)\nprint('train_op')\nreturn tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)\nif mode == Modes.EVAL:\nprint('E')\neval_metric_ops = {\n'accuracy':tf.metrics.accuray(labels,pre)\n}\nreturn tf.estimator.EstimatorSpec(mode,loss=loss,eval_metric_ops=eval_metric_ops)\ndef build_estimator(model_dir):\nreturn tf.estimator.Estimator(\nmodel_fn=_cnn_model_fn,\nmodel_dir=model_dir,\nconfig=tf.contrib.learn.RunConfig(save_checkpoints_secs=60))\ndef serving_input_fn():\ninputs = {'inputs': tf.placeholder(tf.float32, [None, 400])}\nreturn tf.estimator.export.ServingInputReceiver(inputs, inputs)\ndef read_and_decode(filename_queue):\nreader = tf.TFRecordReader()\n_, serialized_example = reader.read(filename_queue)\nfeatures = tf.parse_single_example(\nserialized_example,\nfeatures={\n'image_raw': tf.FixedLenFeature([], tf.string),\n'label': tf.FixedLenFeature([], tf.float32),\n})\nimage = tf.decode_raw(features['image_raw'], tf.uint8)\nimage.set_shape([400])\nprint('image')\nprint(image.shape)\nimage = tf.cast(image, tf.float32)\nlabel = tf.cast(features['label'], tf.float32)\nreturn image, label\ndef input_fn(filename, batch_size=100):\nfilename_queue = tf.train.string_input_producer([filename])\nimage, label = read_and_decode(filename_queue)\nimages, labels = tf.train.batch(\n[image, label], batch_size=batch_size)\nprint(images.shape)\nreturn {'inputs': images}, labels\ndef get_input_fn(filename, batch_size=100):\nreturn lambda: input_fn(filename, batch_size)\ndef generate_experiment_fn(data_dir,\ntrain_batch_size=100,\neval_batch_size=100,\ntrain_steps=5000,\neval_steps=100,\n**experiment_args):\ndef _experiment_fn(output_dir):\nreturn Experiment(\nbuild_estimator(output_dir),\ntrain_input_fn=get_input_fn(\nfilename=os.path.join(data_dir, 'train.tfrecords'),\nbatch_size=train_batch_size),\neval_input_fn=get_input_fn(\nfilename=os.path.join(data_dir, 'test.tfrecords'),\nbatch_size=eval_batch_size),\nexport_strategies=[saved_model_export_utils.make_export_strategy(\nserving_input_fn,\ndefault_output_alternative_key=None,\nexports_to_keep=1)],\ntrain_steps=train_steps,\neval_steps=eval_steps,\n**experiment_args\n)\nreturn _experiment_fn\nif name == 'main':\nparser = argparse.ArgumentParser()\nparser.add_argument(\n'--data_dir',\nhelp='GCS or local path to training data',\ntype = str,\ndefault = '/Users/hanjun/Desktop/OS/scripts'\n#required=True\n)\nparser.add_argument(\n'--train_batch_size',\nhelp='Batch size for training steps',\ntype=int,\ndefault=100\n)\nparser.add_argument(\n'--eval_batch_size',\nhelp='Batch size for evaluation steps',\ntype=int,\ndefault=100\n)\nparser.add_argument(\n'--train_steps',\nhelp='Steps to run the training job for.',\ntype=int,\ndefault=5000\n)\nparser.add_argument(\n'--eval_steps',\nhelp='Number of steps to run evalution for at each checkpoint',\ndefault=100,\ntype=int\n)\nparser.add_argument(\n'--output_dir',\nhelp='GCS location to write checkpoints and export models',\ntype = str,\ndefault = '/Users/hanjun/Desktop/OS/Model'\n#required=True\n)\nparser.add_argument(\n'--job-dir',\nhelp='this model ignores this field, but it is required by gcloud',\ndefault='junk'\n)\nparser.add_argument(\n'--eval_delay_secs',\nhelp='How long to wait before running first evaluation',\ndefault=10,\ntype=int\n)\nparser.add_argument(\n'--min_eval_frequency',\nhelp='Minimum number of training steps between evaluations',\ndefault=1,\ntype=int\n)\nargs = parser.parse_args()\narguments = args.dict\nunused args provided by service\narguments.pop('job_dir', None)\narguments.pop('job-dir', None)\noutput_dir = arguments.pop('output_dir')\nRun the training job\nlearn_runner.run(generate_experiment_fn(**arguments), output_dir)", "body": "When I use tensorflow to build my own neural network and run it, I meet a very strange error. The error is that tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 0. Expected [400], got [3200]. I have no idea about how [3200] comes, could anyone can help to fix this problem? The input of the neural network is a 400-dimension vector.\r\n\r\nHere is my code:\r\n\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef _cnn_model_fn(features,labels,mode):\r\n  input_layer = tf.reshape(features['inputs'],[-1,400])\r\n  print(features['inputs'].shape)\r\n  fc1 = tf.layers.dense(input_layer,1024,activation=tf.nn.relu)\r\n  fc2 = tf.layers.dense(fc1,1024,activation=tf.nn.relu)\r\n  fc3 = tf.layers.dense(fc2,1024,activation=tf.nn.relu)\r\n  fc4 = tf.layers.dense(fc3,1,activation=tf.nn.sigmoid)\r\n  print(fc4.shape)\r\n  labels = tf.reshape(labels,[-1,1])\r\n  fc4 = tf.reshape(fc4,[-1,1])\r\n  print(labels.shape)\r\n  print(fc4.shape)\r\n  if mode in (Modes.PREDICT,Modes.EVAL):\r\n    print(\"P and E\")\r\n    pre = fc4\r\n  if mode in (Modes.TRAIN,Modes.EVAL):\r\n    print('T and E')\r\n    global_step = tf.contrib.framework.get_or_create_global_step()\r\n    loss = tf.losses.mean_squared_error(labels=labels,predictions=fc4)\r\n    tf.summary.scalar('OptimizeLoss',loss)\r\n  if mode == Modes.PREDICT:\r\n    print('P')\r\n    predictions = {\r\n        'vaule': pre\r\n    }\r\n    export_outputs = {\r\n        'prediction': tf.estimator.export.PredictOutput(predictions)\r\n    }\r\n    return tf.estimator.EstimatorSpec(\r\n        mode, predictions=predictions, export_outputs=export_outputs)\r\n  if mode == Modes.TRAIN:\r\n    print('T')\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\r\n    print('optimizer')\r\n    train_op = optimizer.minimize(loss)\r\n    print('train_op')\r\n    return tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)\r\n  if mode == Modes.EVAL:\r\n    print('E')\r\n    eval_metric_ops = {\r\n    'accuracy':tf.metrics.accuray(labels,pre)\r\n    }\r\n    return tf.estimator.EstimatorSpec(mode,loss=loss,eval_metric_ops=eval_metric_ops)\r\n\r\n\r\ndef build_estimator(model_dir):\r\n  return tf.estimator.Estimator(\r\n      model_fn=_cnn_model_fn,\r\n      model_dir=model_dir,\r\n      config=tf.contrib.learn.RunConfig(save_checkpoints_secs=60))\r\n\r\n\r\ndef serving_input_fn():\r\n  inputs = {'inputs': tf.placeholder(tf.float32, [None, 400])}\r\n  return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n\r\n\r\ndef read_and_decode(filename_queue):\r\n  reader = tf.TFRecordReader()\r\n  _, serialized_example = reader.read(filename_queue)\r\n\r\n  features = tf.parse_single_example(\r\n      serialized_example,\r\n      features={\r\n          'image_raw': tf.FixedLenFeature([], tf.string),\r\n          'label': tf.FixedLenFeature([], tf.float32),\r\n      })\r\n\r\n  image = tf.decode_raw(features['image_raw'], tf.uint8)\r\n  image.set_shape([400])\r\n  print('image')\r\n  print(image.shape)\r\n  image = tf.cast(image, tf.float32)\r\n  label = tf.cast(features['label'], tf.float32)\r\n  return image, label\r\n\r\n\r\ndef input_fn(filename, batch_size=100):\r\n  filename_queue = tf.train.string_input_producer([filename])\r\n\r\n  image, label = read_and_decode(filename_queue)\r\n  images, labels = tf.train.batch(\r\n      [image, label], batch_size=batch_size)\r\n  print(images.shape)\r\n\r\n  return {'inputs': images}, labels\r\n\r\n\r\ndef get_input_fn(filename, batch_size=100):\r\n  return lambda: input_fn(filename, batch_size)\r\n\r\n\r\ndef generate_experiment_fn(data_dir,\r\n                           train_batch_size=100,\r\n                           eval_batch_size=100,\r\n                           train_steps=5000,\r\n                           eval_steps=100,\r\n                           **experiment_args):\r\n\r\n  def _experiment_fn(output_dir):\r\n    return Experiment(\r\n        build_estimator(output_dir),\r\n        train_input_fn=get_input_fn(\r\n            filename=os.path.join(data_dir, 'train.tfrecords'),\r\n            batch_size=train_batch_size),\r\n        eval_input_fn=get_input_fn(\r\n            filename=os.path.join(data_dir, 'test.tfrecords'),\r\n            batch_size=eval_batch_size),\r\n        export_strategies=[saved_model_export_utils.make_export_strategy(\r\n            serving_input_fn,\r\n            default_output_alternative_key=None,\r\n            exports_to_keep=1)],\r\n        train_steps=train_steps,\r\n        eval_steps=eval_steps,\r\n        **experiment_args\r\n    )\r\n  return _experiment_fn\r\n\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '--data_dir',\r\n      help='GCS or local path to training data',\r\n      type = str,\r\n      default = '/Users/hanjun/Desktop/OS/scripts'\r\n      #required=True\r\n  )\r\n  parser.add_argument(\r\n      '--train_batch_size',\r\n      help='Batch size for training steps',\r\n      type=int,\r\n      default=100\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--eval_batch_size',\r\n      help='Batch size for evaluation steps',\r\n      type=int,\r\n      default=100\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--train_steps',\r\n      help='Steps to run the training job for.',\r\n      type=int,\r\n      default=5000\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--eval_steps',\r\n      help='Number of steps to run evalution for at each checkpoint',\r\n      default=100,\r\n      type=int\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--output_dir',\r\n      help='GCS location to write checkpoints and export models',\r\n      type = str,\r\n      default = '/Users/hanjun/Desktop/OS/Model'\r\n      #required=True\r\n  )\r\n  parser.add_argument(\r\n      '--job-dir',\r\n      help='this model ignores this field, but it is required by gcloud',\r\n      default='junk'\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--eval_delay_secs',\r\n      help='How long to wait before running first evaluation',\r\n      default=10,\r\n      type=int\r\n  )\r\n  parser.add_argument(\r\n      '--min_eval_frequency',\r\n      help='Minimum number of training steps between evaluations',\r\n      default=1,\r\n      type=int\r\n  )\r\n\r\n\r\n  args = parser.parse_args()\r\n  arguments = args.__dict__\r\n\r\n  # unused args provided by service\r\n  arguments.pop('job_dir', None)\r\n  arguments.pop('job-dir', None)\r\n\r\n  output_dir = arguments.pop('output_dir')\r\n\r\n  # Run the training job\r\n  learn_runner.run(generate_experiment_fn(**arguments), output_dir)"}