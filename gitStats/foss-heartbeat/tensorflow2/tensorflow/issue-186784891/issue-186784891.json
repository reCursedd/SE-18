{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5354", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5354/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5354/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5354/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5354", "id": 186784891, "node_id": "MDU6SXNzdWUxODY3ODQ4OTE=", "number": 5354, "title": "failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED on a AWS p2.xlarge instance", "user": {"login": "beeva-ivanfernandez", "id": 17572598, "node_id": "MDQ6VXNlcjE3NTcyNTk4", "avatar_url": "https://avatars2.githubusercontent.com/u/17572598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/beeva-ivanfernandez", "html_url": "https://github.com/beeva-ivanfernandez", "followers_url": "https://api.github.com/users/beeva-ivanfernandez/followers", "following_url": "https://api.github.com/users/beeva-ivanfernandez/following{/other_user}", "gists_url": "https://api.github.com/users/beeva-ivanfernandez/gists{/gist_id}", "starred_url": "https://api.github.com/users/beeva-ivanfernandez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/beeva-ivanfernandez/subscriptions", "organizations_url": "https://api.github.com/users/beeva-ivanfernandez/orgs", "repos_url": "https://api.github.com/users/beeva-ivanfernandez/repos", "events_url": "https://api.github.com/users/beeva-ivanfernandez/events{/privacy}", "received_events_url": "https://api.github.com/users/beeva-ivanfernandez/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}, {"id": 473173351, "node_id": "MDU6TGFiZWw0NzMxNzMzNTE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 24, "created_at": "2016-11-02T12:15:08Z", "updated_at": "2018-09-29T05:50:21Z", "closed_at": "2017-01-30T19:12:17Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I have been running docker images on a <strong>Centos 7.0 AWS p2.xlarge</strong> instance. I have previously installed on it:<br>\nCUDA: <strong>cuda-repo-rhel7-8.0.44-1.x86_64.rpm</strong><br>\nNVIDIA <strong>drivers 361.42</strong></p>\n<p>I have also installed <strong>nvidia-docker</strong> <a href=\"https://github.com/NVIDIA/nvidia-docker\">following instructions</a></p>\n<p>I have successfully run all notebooks from Docker images (as fas as I've tried tensorflow/tensorflow:latest-devel-gpu and tensorflow/tensorflow:latest-gpu):</p>\n<p>Running <strong>tensorflow</strong> version within the docker containter: <strong>0.11.0rc2</strong><br>\n<strong>Bazel</strong> version: Build label: <strong>0.3.2</strong><br>\nroot@de73edc73418:~# nvidia-smi -l<br>\nWed Nov  2 12:02:54 2016<br>\n+------------------------------------------------------+<br>\n| NVIDIA-SMI 361.42     Driver Version: 361.42         |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Tesla K80           Off  | 0000:00:1E.0     Off |                    0 |<br>\n| N/A   57C    P0    70W / 149W |  10948MiB / 11519MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>However when I try to launch a <a href=\"https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/5_MultiGPU/multigpu_basics.py\">Single GPU computing example with tensorflow</a> and get the following error:</p>\n<p><code>I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_3: /job:localhost/replica:0/task:0/gpu:0 MatMul_4: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_4: /job:localhost/replica:0/task:0/gpu:0 MatMul_5: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/gpu:0 MatMul_6: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_6: /job:localhost/replica:0/task:0/gpu:0 MatMul_7: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_7: /job:localhost/replica:0/task:0/gpu:0 MatMul_8: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_8: /job:localhost/replica:0/task:0/gpu:0 MatMul_9: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_9: /job:localhost/replica:0/task:0/gpu:0 AddN: /job:localhost/replica:0/task:0/cpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] AddN: /job:localhost/replica:0/task:0/cpu:0 E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED W tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED W tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support </code></p>\n<p>Not sure if is something related to Nvidia drivers, OS or some library mismatch. Any idea?</p>", "body_text": "Hi,\nI have been running docker images on a Centos 7.0 AWS p2.xlarge instance. I have previously installed on it:\nCUDA: cuda-repo-rhel7-8.0.44-1.x86_64.rpm\nNVIDIA drivers 361.42\nI have also installed nvidia-docker following instructions\nI have successfully run all notebooks from Docker images (as fas as I've tried tensorflow/tensorflow:latest-devel-gpu and tensorflow/tensorflow:latest-gpu):\nRunning tensorflow version within the docker containter: 0.11.0rc2\nBazel version: Build label: 0.3.2\nroot@de73edc73418:~# nvidia-smi -l\nWed Nov  2 12:02:54 2016\n+------------------------------------------------------+\n| NVIDIA-SMI 361.42     Driver Version: 361.42         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 0000:00:1E.0     Off |                    0 |\n| N/A   57C    P0    70W / 149W |  10948MiB / 11519MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\nHowever when I try to launch a Single GPU computing example with tensorflow and get the following error:\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_3: /job:localhost/replica:0/task:0/gpu:0 MatMul_4: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_4: /job:localhost/replica:0/task:0/gpu:0 MatMul_5: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/gpu:0 MatMul_6: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_6: /job:localhost/replica:0/task:0/gpu:0 MatMul_7: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_7: /job:localhost/replica:0/task:0/gpu:0 MatMul_8: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_8: /job:localhost/replica:0/task:0/gpu:0 MatMul_9: /job:localhost/replica:0/task:0/gpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_9: /job:localhost/replica:0/task:0/gpu:0 AddN: /job:localhost/replica:0/task:0/cpu:0 I tensorflow/core/common_runtime/simple_placer.cc:819] AddN: /job:localhost/replica:0/task:0/cpu:0 E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED W tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED W tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support \nNot sure if is something related to Nvidia drivers, OS or some library mismatch. Any idea?", "body": "Hi,\r\n\r\nI have been running docker images on a **Centos 7.0 AWS p2.xlarge** instance. I have previously installed on it:\r\nCUDA: **cuda-repo-rhel7-8.0.44-1.x86_64.rpm**\r\nNVIDIA **drivers 361.42**\r\n\r\nI have also installed **nvidia-docker** [following instructions](https://github.com/NVIDIA/nvidia-docker)\r\n\r\nI have successfully run all notebooks from Docker images (as fas as I've tried tensorflow/tensorflow:latest-devel-gpu and tensorflow/tensorflow:latest-gpu):\r\n\r\nRunning **tensorflow** version within the docker containter: **0.11.0rc2**\r\n**Bazel** version: Build label: **0.3.2**\r\nroot@de73edc73418:~# nvidia-smi -l\r\nWed Nov  2 12:02:54 2016       \r\n+------------------------------------------------------+                       \r\n| NVIDIA-SMI 361.42     Driver Version: 361.42         |                       \r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 0000:00:1E.0     Off |                    0 |\r\n| N/A   57C    P0    70W / 149W |  10948MiB / 11519MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\nHowever when I try to launch a [Single GPU computing example with tensorflow](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/5_MultiGPU/multigpu_basics.py) and get the following error:\r\n\r\n`I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_3: /job:localhost/replica:0/task:0/gpu:0\r\nMatMul_4: /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_4: /job:localhost/replica:0/task:0/gpu:0\r\nMatMul_5: /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/gpu:0\r\nMatMul_6: /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_6: /job:localhost/replica:0/task:0/gpu:0\r\nMatMul_7: /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_7: /job:localhost/replica:0/task:0/gpu:0\r\nMatMul_8: /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_8: /job:localhost/replica:0/task:0/gpu:0\r\nMatMul_9: /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_9: /job:localhost/replica:0/task:0/gpu:0\r\nAddN: /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:819] AddN: /job:localhost/replica:0/task:0/cpu:0\r\nE tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\nE tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\n`\r\n\r\nNot sure if is something related to Nvidia drivers, OS or some library mismatch. Any idea?\r\n"}