{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/165853648", "pull_request_review_id": 93853790, "id": 165853648, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NTg1MzY0OA==", "diff_hunk": "@@ -3017,3 +3018,170 @@ def call(self, inputs, state):\n \n       new_state = rnn_cell_impl.LSTMStateTuple(new_c, new_h)\n       return new_h, new_state\n+\n+\n+class NLSTMCell(rnn_cell_impl.RNNCell):\n+  \"\"\"Nested LSTM Cell. Adapted from `rnn_cell_impl.LSTMCell`\n+\n+  The implementation is based on:\n+    https://arxiv.org/abs/1801.10308\n+    JRA. Moniz, D. Krueger.\n+    \"Nested LSTMs\"\n+    ACML, PMLR 77:530-544, 2017\n+  \"\"\"\n+\n+  def __init__(self, num_units, depth, forget_bias=1.0,\n+               state_is_tuple=True, activation=None, reuse=None, name=None):\n+    \"\"\"Initialize the basic NLSTM cell.\n+\n+    Args:\n+      num_units: int, The number of hidden units of each cell state\n+        and hidden state.\n+      depth: int, The number of layers in the nest\n+      forget_bias: float, The bias added to forget gates.\n+      state_is_tuple: If True, accepted and returned states are tuples of\n+        the `h_state` and `c_state`s.  If False, they are concatenated\n+        along the column axis.  The latter behavior will soon be deprecated.\n+      activation: Activation function of the inner states.  Default: `tanh`.\n+      reuse: (optional) Python boolean describing whether to reuse variables\n+        in an existing scope.  If not `True`, and the existing scope already has\n+        the given variables, an error is raised.\n+      name: String, the name of the layer. Layers with the same name will\n+        share weights, but to avoid mistakes we require reuse=True in such\n+        cases.\n+    \"\"\"\n+    super(NLSTMCell, self).__init__(_reuse=reuse, name=name)\n+    if not state_is_tuple:\n+      logging.warn(\"%s: Using a concatenated state is slower and will soon be \"\n+                   \"deprecated.  Use state_is_tuple=True.\", self)\n+\n+    # Inputs must be 2-dimensional.\n+    self.input_spec = base_layer.InputSpec(ndim=2)\n+    self._num_units = num_units\n+    self._forget_bias = forget_bias\n+    self._state_is_tuple = state_is_tuple\n+    self._depth = depth\n+    self._activation = activation or math_ops.tanh\n+    self._kernels = None\n+    self._biases = None\n+    self.built = False\n+\n+  @property\n+  def state_size(self):\n+    if self._state_is_tuple:\n+      return tuple([self._num_units] * (self.depth + 1))\n+    else:\n+      return self._num_units * (self.depth + 1)\n+\n+  @property\n+  def output_size(self):\n+    return self._num_units\n+\n+  @property\n+  def depth(self):\n+    return self._depth\n+\n+  def build(self, inputs_shape):\n+    if inputs_shape[1].value is None:\n+      raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\"\n+                       % inputs_shape)\n+\n+    input_depth = inputs_shape[1].value\n+    h_depth = self._num_units\n+    self._kernels = []\n+    self._biases = []\n+    for i in range(self.depth):\n+      if i == 0:\n+        self._kernels.append(\n+          self.add_variable(\n+            \"kernel_{}\".format(i),\n+            shape=[input_depth + h_depth, 4 * self._num_units]))\n+      else:\n+        self._kernels.append(\n+          self.add_variable(\n+            \"kernel_{}\".format(i),\n+            shape=[2 * h_depth, 4 * self._num_units]))\n+      self._biases.append(\n+        self.add_variable(\n+          \"bias_{}\".format(i),\n+          shape=[4 * self._num_units],\n+          initializer=init_ops.zeros_initializer(dtype=self.dtype)))\n+\n+    self.built = True\n+\n+  def recurrence(self, inputs, hidden_state, cell_states, depth):", "path": "tensorflow/contrib/rnn/python/ops/rnn_cell.py", "position": null, "original_position": 103, "commit_id": "492c8c708017e279e449bc0857ec3e28452c287c", "original_commit_id": "17aab7396efb34c3b0daf6ffee3df1af9953566b", "user": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "body": "Should this be made private, i.e., `_recurrence`?", "created_at": "2018-02-04T18:46:59Z", "updated_at": "2018-02-12T00:40:47Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16736#discussion_r165853648", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16736", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/165853648"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16736#discussion_r165853648"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16736"}}, "body_html": "<p>Should this be made private, i.e., <code>_recurrence</code>?</p>", "body_text": "Should this be made private, i.e., _recurrence?"}