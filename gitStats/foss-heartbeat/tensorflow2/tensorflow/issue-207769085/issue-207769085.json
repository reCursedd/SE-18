{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7523", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7523/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7523/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7523/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7523", "id": 207769085, "node_id": "MDU6SXNzdWUyMDc3NjkwODU=", "number": 7523, "title": "Tensorflow graph transform quantize_weights Compression method creates corrupted graph.", "user": {"login": "Bruczzz", "id": 25055499, "node_id": "MDQ6VXNlcjI1MDU1NDk5", "avatar_url": "https://avatars0.githubusercontent.com/u/25055499?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Bruczzz", "html_url": "https://github.com/Bruczzz", "followers_url": "https://api.github.com/users/Bruczzz/followers", "following_url": "https://api.github.com/users/Bruczzz/following{/other_user}", "gists_url": "https://api.github.com/users/Bruczzz/gists{/gist_id}", "starred_url": "https://api.github.com/users/Bruczzz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Bruczzz/subscriptions", "organizations_url": "https://api.github.com/users/Bruczzz/orgs", "repos_url": "https://api.github.com/users/Bruczzz/repos", "events_url": "https://api.github.com/users/Bruczzz/events{/privacy}", "received_events_url": "https://api.github.com/users/Bruczzz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2017-02-15T10:48:53Z", "updated_at": "2017-02-27T16:47:59Z", "closed_at": "2017-02-27T16:47:59Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I have retrained inception v3 model using retrain.py on classes (People, Animal, Plants, Buildings, Birds) and the size is <strong>87.5 MB</strong>. At this stage, the model works fine when I try classification using label_image example.</p>\n<p>But, model compressed using quantization methods is producing false or incorrect results. As mentioned below, I have tried two ways of model compression using quantized methods, however both of these are producing a corrupted compressed model that gives incorrect classification results.</p>\n<p><strong>Method 1:</strong> Shrinking file size method in graph_transform. GitHub link: <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size</a></p>\n<p><strong>Step 1:</strong> Tried compression with <strong>round_weights</strong> method - size of model was still same <strong>(87.5 MB)</strong> and classification on images works perfectly.</p>\n<p><strong>Step 2:</strong> Compression using <strong>quantize_weights</strong> method - (as suggested by Pete Warden, I ran the command after removing \" and newlines ) quantized model got created with size <strong>(22 MB)</strong> but it is producing false or incorrect results, and giving the same class irrespective of which image is given as input (plant, bird, etc.). Below are sample results for three images none of which were animal images:</p>\n<p>Image 1 (plant)</p>\n<ul>\n<li>Animal (1): 0.999713</li>\n<li>Plants (5): 0.00028519</li>\n<li>Buildings (3): 1.18105e-06</li>\n<li>People (2): 1.77942e-07</li>\n<li>Birds (4): 5.95436e-08</li>\n</ul>\n<p>Image 2 (bird)</p>\n<ul>\n<li>Animal (1): 0.981817</li>\n<li>Plants (5): 0.0170753</li>\n<li>Buildings (3): 0.000743494</li>\n<li>People (2): 0.000190974</li>\n<li>Birds (4): 0.000148184</li>\n</ul>\n<p>Image 3 (building)</p>\n<ul>\n<li>Animal (1): 0.991817</li>\n<li>Plants (5): 0.0070753</li>\n<li>Buildings (3): 0.00143494</li>\n<li>People (2): 0.00090974</li>\n<li>Birds (4): 0.000148184</li>\n</ul>\n<p><strong>Method 2:</strong> Quantization method link : <a href=\"https://www.tensorflow.org/how_tos/quantization/\" rel=\"nofollow\">https://www.tensorflow.org/how_tos/quantization/</a></p>\n<p><code> bazel build tensorflow/contrib/quantization/tools:quantize_graph </code><br>\nERROR: no such package 'tensorflow/contrib/quantization/tools': BUILD       file not found on package path.</p>\n<p>Used <code> bazel build tensorflow/tools/quantization:quantize_graph </code> command for running build.</p>\n<p>On running following command after adding dependencies <em>\"//tensorflow/contrib/quantization:cc_ops\",<br>\n\"//tensorflow/contrib/quantization/kernels:quantized_ops\",</em> to BUILD file of label_image.</p>\n<code>\nbazel-bin/tensorflow/tools/quantization/quantize_graph \\\n--input=Trained_Model/CompressedJunkRetrained_graph.pb \\\n--output_node_names=\"final_result\" --output=/Trained_Model/quantized_graph.pb \\\n--mode=eightbit\n</code>\n<p><strong>Note:</strong> Used <em>final_result</em> in <em>output_node_names</em> instead of <em>softmax</em>.</p>\n<p>This is giving the following error:</p>\n<p>ERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such package 'tensorflow/tools/quantization/kernels': BUILD file not found on package path and referenced by '//tensorflow/examples/label_image:label_image'.<br>\nERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such target '//tensorflow/tools/quantization:cc_ops': target 'cc_ops' not declared in package 'tensorflow/tools/quantization' defined by /tensorflow-master/tensorflow/tools/quantization/BUILD and referenced by '//tensorflow/examples/label_image:label_image'.<br>\nERROR: Analysis of target '//tensorflow/examples/label_image:label_image' failed; build aborted.</p>\n<p>If I run the same command without adding dependencies, it is compressing the model successfully.<br>\nBut again in this quantized model images are getting wrongly classified.</p>", "body_text": "Hi,\nI have retrained inception v3 model using retrain.py on classes (People, Animal, Plants, Buildings, Birds) and the size is 87.5 MB. At this stage, the model works fine when I try classification using label_image example.\nBut, model compressed using quantization methods is producing false or incorrect results. As mentioned below, I have tried two ways of model compression using quantized methods, however both of these are producing a corrupted compressed model that gives incorrect classification results.\nMethod 1: Shrinking file size method in graph_transform. GitHub link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size\nStep 1: Tried compression with round_weights method - size of model was still same (87.5 MB) and classification on images works perfectly.\nStep 2: Compression using quantize_weights method - (as suggested by Pete Warden, I ran the command after removing \" and newlines ) quantized model got created with size (22 MB) but it is producing false or incorrect results, and giving the same class irrespective of which image is given as input (plant, bird, etc.). Below are sample results for three images none of which were animal images:\nImage 1 (plant)\n\nAnimal (1): 0.999713\nPlants (5): 0.00028519\nBuildings (3): 1.18105e-06\nPeople (2): 1.77942e-07\nBirds (4): 5.95436e-08\n\nImage 2 (bird)\n\nAnimal (1): 0.981817\nPlants (5): 0.0170753\nBuildings (3): 0.000743494\nPeople (2): 0.000190974\nBirds (4): 0.000148184\n\nImage 3 (building)\n\nAnimal (1): 0.991817\nPlants (5): 0.0070753\nBuildings (3): 0.00143494\nPeople (2): 0.00090974\nBirds (4): 0.000148184\n\nMethod 2: Quantization method link : https://www.tensorflow.org/how_tos/quantization/\n bazel build tensorflow/contrib/quantization/tools:quantize_graph \nERROR: no such package 'tensorflow/contrib/quantization/tools': BUILD       file not found on package path.\nUsed  bazel build tensorflow/tools/quantization:quantize_graph  command for running build.\nOn running following command after adding dependencies \"//tensorflow/contrib/quantization:cc_ops\",\n\"//tensorflow/contrib/quantization/kernels:quantized_ops\", to BUILD file of label_image.\n\nbazel-bin/tensorflow/tools/quantization/quantize_graph \\\n--input=Trained_Model/CompressedJunkRetrained_graph.pb \\\n--output_node_names=\"final_result\" --output=/Trained_Model/quantized_graph.pb \\\n--mode=eightbit\n\nNote: Used final_result in output_node_names instead of softmax.\nThis is giving the following error:\nERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such package 'tensorflow/tools/quantization/kernels': BUILD file not found on package path and referenced by '//tensorflow/examples/label_image:label_image'.\nERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such target '//tensorflow/tools/quantization:cc_ops': target 'cc_ops' not declared in package 'tensorflow/tools/quantization' defined by /tensorflow-master/tensorflow/tools/quantization/BUILD and referenced by '//tensorflow/examples/label_image:label_image'.\nERROR: Analysis of target '//tensorflow/examples/label_image:label_image' failed; build aborted.\nIf I run the same command without adding dependencies, it is compressing the model successfully.\nBut again in this quantized model images are getting wrongly classified.", "body": "Hi,\r\n   \r\n I have retrained inception v3 model using retrain.py on classes (People, Animal, Plants, Buildings, Birds) and the size is **87.5 MB**. At this stage, the model works fine when I try classification using label_image example.\r\n\r\nBut, model compressed using quantization methods is producing false or incorrect results. As mentioned below, I have tried two ways of model compression using quantized methods, however both of these are producing a corrupted compressed model that gives incorrect classification results.\r\n\r\n**Method 1:** Shrinking file size method in graph_transform. GitHub link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size\r\n\r\n**Step 1:** Tried compression with **round_weights** method - size of model was still same **(87.5 MB)** and classification on images works perfectly.\r\n\r\n**Step 2:** Compression using **quantize_weights** method - (as suggested by Pete Warden, I ran the command after removing \" and newlines ) quantized model got created with size **(22 MB)** but it is producing false or incorrect results, and giving the same class irrespective of which image is given as input (plant, bird, etc.). Below are sample results for three images none of which were animal images:\r\n\r\nImage 1 (plant)\r\n- Animal (1): 0.999713\r\n- Plants (5): 0.00028519\r\n- Buildings (3): 1.18105e-06\r\n- People (2): 1.77942e-07\r\n- Birds (4): 5.95436e-08\r\n\r\nImage 2 (bird)\r\n- Animal (1): 0.981817\r\n- Plants (5): 0.0170753\r\n- Buildings (3): 0.000743494\r\n- People (2): 0.000190974\r\n- Birds (4): 0.000148184\r\n\r\nImage 3 (building)\r\n- Animal (1): 0.991817\r\n- Plants (5): 0.0070753\r\n- Buildings (3): 0.00143494\r\n- People (2): 0.00090974\r\n- Birds (4): 0.000148184\r\n\r\n**Method 2:** Quantization method link : https://www.tensorflow.org/how_tos/quantization/\r\n\r\n<code> bazel build tensorflow/contrib/quantization/tools:quantize_graph </code>\r\nERROR: no such package 'tensorflow/contrib/quantization/tools': BUILD       file not found on package path.\r\n\r\nUsed <code> bazel build tensorflow/tools/quantization:quantize_graph </code> command for running build.\r\n\r\n On running following command after adding dependencies _\"//tensorflow/contrib/quantization:cc_ops\",\r\n\"//tensorflow/contrib/quantization/kernels:quantized_ops\",_ to BUILD file of label_image.\r\n\r\n<code>\r\nbazel-bin/tensorflow/tools/quantization/quantize_graph \\\r\n--input=Trained_Model/CompressedJunkRetrained_graph.pb \\\r\n--output_node_names=\"final_result\" --output=/Trained_Model/quantized_graph.pb \\\r\n--mode=eightbit\r\n</code>\r\n\r\n**Note:** Used _final_result_ in _output_node_names_ instead of _softmax_.\r\n\r\nThis is giving the following error:\r\n\r\nERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such package 'tensorflow/tools/quantization/kernels': BUILD file not found on package path and referenced by '//tensorflow/examples/label_image:label_image'.\r\nERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such target '//tensorflow/tools/quantization:cc_ops': target 'cc_ops' not declared in package 'tensorflow/tools/quantization' defined by /tensorflow-master/tensorflow/tools/quantization/BUILD and referenced by '//tensorflow/examples/label_image:label_image'.\r\nERROR: Analysis of target '//tensorflow/examples/label_image:label_image' failed; build aborted.\r\n\r\n\r\nIf I run the same command without adding dependencies, it is compressing the model successfully.\r\nBut again in this quantized model images are getting wrongly classified. \r\n\r\n"}