{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/348546100", "html_url": "https://github.com/tensorflow/tensorflow/issues/14957#issuecomment-348546100", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14957", "id": 348546100, "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODU0NjEwMA==", "user": {"login": "drasmuss", "id": 1952220, "node_id": "MDQ6VXNlcjE5NTIyMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1952220?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drasmuss", "html_url": "https://github.com/drasmuss", "followers_url": "https://api.github.com/users/drasmuss/followers", "following_url": "https://api.github.com/users/drasmuss/following{/other_user}", "gists_url": "https://api.github.com/users/drasmuss/gists{/gist_id}", "starred_url": "https://api.github.com/users/drasmuss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drasmuss/subscriptions", "organizations_url": "https://api.github.com/users/drasmuss/orgs", "repos_url": "https://api.github.com/users/drasmuss/repos", "events_url": "https://api.github.com/users/drasmuss/events{/privacy}", "received_events_url": "https://api.github.com/users/drasmuss/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-01T16:48:01Z", "updated_at": "2017-12-01T16:53:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm not sure if this is covered under your cases above, but I found another situation where 0B memory usage is reported that seems to have a different cause:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\ngraph <span class=\"pl-k\">=</span> tf.Graph()\n<span class=\"pl-k\">with</span> graph.as_default(), tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/cpu:0<span class=\"pl-pds\">\"</span></span>):\n    a <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">1000</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float64)\n\n    b <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>,), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float64)\n    d <span class=\"pl-k\">=</span> tf.scatter_nd([[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>]], b, (<span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">1000</span>))\n\n    c <span class=\"pl-k\">=</span> a <span class=\"pl-k\">*</span> d\n\n<span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph) <span class=\"pl-k\">as</span> sess:\n    run_options <span class=\"pl-k\">=</span> tf.RunOptions(<span class=\"pl-v\">trace_level</span><span class=\"pl-k\">=</span>tf.RunOptions.<span class=\"pl-c1\">FULL_TRACE</span>)\n    run_metadata <span class=\"pl-k\">=</span> tf.RunMetadata()\n    sess.run(c, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{a: np.ones((<span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">1000</span>)), b: np.ones((<span class=\"pl-c1\">1</span>,))},\n             <span class=\"pl-v\">options</span><span class=\"pl-k\">=</span>run_options, <span class=\"pl-v\">run_metadata</span><span class=\"pl-k\">=</span>run_metadata)\n\n    options <span class=\"pl-k\">=</span> tf.profiler.ProfileOptionBuilder.time_and_memory()\n    options[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>min_bytes<span class=\"pl-pds\">\"</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n    options[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>min_micros<span class=\"pl-pds\">\"</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n    options[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>select<span class=\"pl-pds\">\"</span></span>] <span class=\"pl-k\">=</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>bytes<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_bytes<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>output_bytes<span class=\"pl-pds\">\"</span></span>,\n                         <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>residual_bytes<span class=\"pl-pds\">\"</span></span>)\n    tf.profiler.profile(graph, <span class=\"pl-v\">run_meta</span><span class=\"pl-k\">=</span>run_metadata, <span class=\"pl-v\">cmd</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>scope<span class=\"pl-pds\">\"</span></span>,\n                        <span class=\"pl-v\">options</span><span class=\"pl-k\">=</span>options)</pre></div>\n<p>gives output</p>\n<pre><code>==================Model Analysis Report======================\nnode name | requested bytes | peak bytes | residual bytes | output bytes\n_TFProfRoot (--/8.00MB, --/8.00MB, --/8.00MB, --/24.00MB)\n  ScatterNd (8.00MB/8.00MB, 8.00MB/8.00MB, 8.00MB/8.00MB, 8.00MB/8.00MB)\n    ScatterNd/indices (0B/0B, 0B/0B, 0B/0B, 8B/8B)\n    ScatterNd/shape (0B/0B, 0B/0B, 0B/0B, 8B/8B)\n  mul (0B/0B, 0B/0B, 0B/0B, 8.00MB/8.00MB)\n  _arg_Placeholder_1_0_1 (0B/0B, 0B/0B, 0B/0B, 8B/8B)\n  _arg_Placeholder_0_0 (0B/0B, 0B/0B, 0B/0B, 8.00MB/8.00MB)\n  _retval_mul_0_0 (0B/0B, 0B/0B, 0B/0B, 0B/0B)\n  Placeholder (0B/0B, 0B/0B, 0B/0B, 0B/0B)\n  Placeholder_1 (0B/0B, 0B/0B, 0B/0B, 0B/0B)\n</code></pre>\n<p>Again I'd expect <code>mul</code> to report 8MB memory usage, but it reports 0B.  But if we look at the node stats this time</p>\n<pre><code>    node_stats {\n      node_name: \"mul\"\n      all_start_micros: 1512146558031874\n      op_start_rel_micros: 2\n      op_end_rel_micros: 832\n      all_end_rel_micros: 843\n      memory {\n        allocator_name: \"cpu\"\n      }\n      output {\n        tensor_description {\n          dtype: DT_DOUBLE\n          shape {\n            dim {\n              size: 1000\n            }\n            dim {\n              size: 1000\n            }\n          }\n          allocation_description {\n            requested_bytes: 8000000\n            allocated_bytes: 8000000\n            allocator_name: \"cpu\"\n            allocation_id: 1\n            ptr: 2245408854112\n          }\n        }\n      }\n      timeline_label: \"mul = Mul(_arg_Placeholder_0_0, ScatterNd)\"\n      scheduled_micros: 1512146558031856\n      memory_stats {\n      }\n    }\n</code></pre>\n<p>we can see that the memory usage isn't reported in <code>memory</code> or <code>memory_stats</code>.</p>\n<p>On a different note, the Placeholders also report 0B memory usage, but I'm not sure if that is expected or not (not sure how memory allocation is handled for placeholders).</p>", "body_text": "I'm not sure if this is covered under your cases above, but I found another situation where 0B memory usage is reported that seems to have a different cause:\nimport tensorflow as tf\nimport numpy as np\n\ngraph = tf.Graph()\nwith graph.as_default(), tf.device(\"/cpu:0\"):\n    a = tf.placeholder(shape=(1000, 1000), dtype=tf.float64)\n\n    b = tf.placeholder(shape=(1,), dtype=tf.float64)\n    d = tf.scatter_nd([[0, 0]], b, (1000, 1000))\n\n    c = a * d\n\nwith tf.Session(graph=graph) as sess:\n    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n    run_metadata = tf.RunMetadata()\n    sess.run(c, feed_dict={a: np.ones((1000, 1000)), b: np.ones((1,))},\n             options=run_options, run_metadata=run_metadata)\n\n    options = tf.profiler.ProfileOptionBuilder.time_and_memory()\n    options[\"min_bytes\"] = 0\n    options[\"min_micros\"] = 0\n    options[\"select\"] = (\"bytes\", \"peak_bytes\", \"output_bytes\",\n                         \"residual_bytes\")\n    tf.profiler.profile(graph, run_meta=run_metadata, cmd=\"scope\",\n                        options=options)\ngives output\n==================Model Analysis Report======================\nnode name | requested bytes | peak bytes | residual bytes | output bytes\n_TFProfRoot (--/8.00MB, --/8.00MB, --/8.00MB, --/24.00MB)\n  ScatterNd (8.00MB/8.00MB, 8.00MB/8.00MB, 8.00MB/8.00MB, 8.00MB/8.00MB)\n    ScatterNd/indices (0B/0B, 0B/0B, 0B/0B, 8B/8B)\n    ScatterNd/shape (0B/0B, 0B/0B, 0B/0B, 8B/8B)\n  mul (0B/0B, 0B/0B, 0B/0B, 8.00MB/8.00MB)\n  _arg_Placeholder_1_0_1 (0B/0B, 0B/0B, 0B/0B, 8B/8B)\n  _arg_Placeholder_0_0 (0B/0B, 0B/0B, 0B/0B, 8.00MB/8.00MB)\n  _retval_mul_0_0 (0B/0B, 0B/0B, 0B/0B, 0B/0B)\n  Placeholder (0B/0B, 0B/0B, 0B/0B, 0B/0B)\n  Placeholder_1 (0B/0B, 0B/0B, 0B/0B, 0B/0B)\n\nAgain I'd expect mul to report 8MB memory usage, but it reports 0B.  But if we look at the node stats this time\n    node_stats {\n      node_name: \"mul\"\n      all_start_micros: 1512146558031874\n      op_start_rel_micros: 2\n      op_end_rel_micros: 832\n      all_end_rel_micros: 843\n      memory {\n        allocator_name: \"cpu\"\n      }\n      output {\n        tensor_description {\n          dtype: DT_DOUBLE\n          shape {\n            dim {\n              size: 1000\n            }\n            dim {\n              size: 1000\n            }\n          }\n          allocation_description {\n            requested_bytes: 8000000\n            allocated_bytes: 8000000\n            allocator_name: \"cpu\"\n            allocation_id: 1\n            ptr: 2245408854112\n          }\n        }\n      }\n      timeline_label: \"mul = Mul(_arg_Placeholder_0_0, ScatterNd)\"\n      scheduled_micros: 1512146558031856\n      memory_stats {\n      }\n    }\n\nwe can see that the memory usage isn't reported in memory or memory_stats.\nOn a different note, the Placeholders also report 0B memory usage, but I'm not sure if that is expected or not (not sure how memory allocation is handled for placeholders).", "body": "I'm not sure if this is covered under your cases above, but I found another situation where 0B memory usage is reported that seems to have a different cause:\r\n``` python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ngraph = tf.Graph()\r\nwith graph.as_default(), tf.device(\"/cpu:0\"):\r\n    a = tf.placeholder(shape=(1000, 1000), dtype=tf.float64)\r\n\r\n    b = tf.placeholder(shape=(1,), dtype=tf.float64)\r\n    d = tf.scatter_nd([[0, 0]], b, (1000, 1000))\r\n\r\n    c = a * d\r\n\r\nwith tf.Session(graph=graph) as sess:\r\n    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\n    run_metadata = tf.RunMetadata()\r\n    sess.run(c, feed_dict={a: np.ones((1000, 1000)), b: np.ones((1,))},\r\n             options=run_options, run_metadata=run_metadata)\r\n\r\n    options = tf.profiler.ProfileOptionBuilder.time_and_memory()\r\n    options[\"min_bytes\"] = 0\r\n    options[\"min_micros\"] = 0\r\n    options[\"select\"] = (\"bytes\", \"peak_bytes\", \"output_bytes\",\r\n                         \"residual_bytes\")\r\n    tf.profiler.profile(graph, run_meta=run_metadata, cmd=\"scope\",\r\n                        options=options)\r\n```\r\ngives output\r\n```\r\n==================Model Analysis Report======================\r\nnode name | requested bytes | peak bytes | residual bytes | output bytes\r\n_TFProfRoot (--/8.00MB, --/8.00MB, --/8.00MB, --/24.00MB)\r\n  ScatterNd (8.00MB/8.00MB, 8.00MB/8.00MB, 8.00MB/8.00MB, 8.00MB/8.00MB)\r\n    ScatterNd/indices (0B/0B, 0B/0B, 0B/0B, 8B/8B)\r\n    ScatterNd/shape (0B/0B, 0B/0B, 0B/0B, 8B/8B)\r\n  mul (0B/0B, 0B/0B, 0B/0B, 8.00MB/8.00MB)\r\n  _arg_Placeholder_1_0_1 (0B/0B, 0B/0B, 0B/0B, 8B/8B)\r\n  _arg_Placeholder_0_0 (0B/0B, 0B/0B, 0B/0B, 8.00MB/8.00MB)\r\n  _retval_mul_0_0 (0B/0B, 0B/0B, 0B/0B, 0B/0B)\r\n  Placeholder (0B/0B, 0B/0B, 0B/0B, 0B/0B)\r\n  Placeholder_1 (0B/0B, 0B/0B, 0B/0B, 0B/0B)\r\n```\r\nAgain I'd expect `mul` to report 8MB memory usage, but it reports 0B.  But if we look at the node stats this time\r\n```\r\n    node_stats {\r\n      node_name: \"mul\"\r\n      all_start_micros: 1512146558031874\r\n      op_start_rel_micros: 2\r\n      op_end_rel_micros: 832\r\n      all_end_rel_micros: 843\r\n      memory {\r\n        allocator_name: \"cpu\"\r\n      }\r\n      output {\r\n        tensor_description {\r\n          dtype: DT_DOUBLE\r\n          shape {\r\n            dim {\r\n              size: 1000\r\n            }\r\n            dim {\r\n              size: 1000\r\n            }\r\n          }\r\n          allocation_description {\r\n            requested_bytes: 8000000\r\n            allocated_bytes: 8000000\r\n            allocator_name: \"cpu\"\r\n            allocation_id: 1\r\n            ptr: 2245408854112\r\n          }\r\n        }\r\n      }\r\n      timeline_label: \"mul = Mul(_arg_Placeholder_0_0, ScatterNd)\"\r\n      scheduled_micros: 1512146558031856\r\n      memory_stats {\r\n      }\r\n    }\r\n```\r\nwe can see that the memory usage isn't reported in `memory` or `memory_stats`.\r\n\r\nOn a different note, the Placeholders also report 0B memory usage, but I'm not sure if that is expected or not (not sure how memory allocation is handled for placeholders)."}