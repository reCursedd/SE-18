{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/348053146", "html_url": "https://github.com/tensorflow/tensorflow/issues/14957#issuecomment-348053146", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14957", "id": 348053146, "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODA1MzE0Ng==", "user": {"login": "panyx0718", "id": 2887803, "node_id": "MDQ6VXNlcjI4ODc4MDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2887803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/panyx0718", "html_url": "https://github.com/panyx0718", "followers_url": "https://api.github.com/users/panyx0718/followers", "following_url": "https://api.github.com/users/panyx0718/following{/other_user}", "gists_url": "https://api.github.com/users/panyx0718/gists{/gist_id}", "starred_url": "https://api.github.com/users/panyx0718/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/panyx0718/subscriptions", "organizations_url": "https://api.github.com/users/panyx0718/orgs", "repos_url": "https://api.github.com/users/panyx0718/repos", "events_url": "https://api.github.com/users/panyx0718/events{/privacy}", "received_events_url": "https://api.github.com/users/panyx0718/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-30T01:27:17Z", "updated_at": "2017-11-30T01:27:17Z", "author_association": "NONE", "body_html": "<p>Thanks for reporting it and doing the analysis.</p>\n<p>The constant op memory is recorded in \"memory_stats\" but not in \"memory\". And profiler<br>\nmissed that. I sent out a fix for it.</p>\n<p>Some clean up is needed for the TensorFlow internal memory tracing. Here are some thing I noted down during my code digging:<br>\n// 1. OpKernelConstruction::allocate_xxx is not traced. Below, we only<br>\n//    discuss OpKernelContext-related allocations.<br>\n// 2. allocate_output calls allocate_tensor, which is properly tracked in<br>\n//    'NodeExecStats.memory'.<br>\n// 3. allocate_temp is only tracked through record_xxx_temp. It appears<br>\n//    in 'NodeExecStats.memory_stats'.<br>\n// 4. allocate_persistent calls allocate_tensor, which is properly tracked<br>\n//    in 'NodeExecStats.memory'. However, there is no way to count it as<br>\n//    persistent now.<br>\n// 5. record_xxx_persistent is called when allocate_persistent<br>\n//    is not used. Hence tracks some complementary bytes. It appears in<br>\n//    'NodeExecStats.memory_stats'. It's suspicious. But we should<br>\n//    use it now since it covers constant op.</p>", "body_text": "Thanks for reporting it and doing the analysis.\nThe constant op memory is recorded in \"memory_stats\" but not in \"memory\". And profiler\nmissed that. I sent out a fix for it.\nSome clean up is needed for the TensorFlow internal memory tracing. Here are some thing I noted down during my code digging:\n// 1. OpKernelConstruction::allocate_xxx is not traced. Below, we only\n//    discuss OpKernelContext-related allocations.\n// 2. allocate_output calls allocate_tensor, which is properly tracked in\n//    'NodeExecStats.memory'.\n// 3. allocate_temp is only tracked through record_xxx_temp. It appears\n//    in 'NodeExecStats.memory_stats'.\n// 4. allocate_persistent calls allocate_tensor, which is properly tracked\n//    in 'NodeExecStats.memory'. However, there is no way to count it as\n//    persistent now.\n// 5. record_xxx_persistent is called when allocate_persistent\n//    is not used. Hence tracks some complementary bytes. It appears in\n//    'NodeExecStats.memory_stats'. It's suspicious. But we should\n//    use it now since it covers constant op.", "body": "Thanks for reporting it and doing the analysis.\r\n\r\nThe constant op memory is recorded in \"memory_stats\" but not in \"memory\". And profiler\r\nmissed that. I sent out a fix for it.\r\n\r\n Some clean up is needed for the TensorFlow internal memory tracing. Here are some thing I noted down during my code digging:\r\n  // 1. OpKernelConstruction::allocate_xxx is not traced. Below, we only\r\n  //    discuss OpKernelContext-related allocations.\r\n  // 2. allocate_output calls allocate_tensor, which is properly tracked in\r\n  //    'NodeExecStats.memory'.\r\n  // 3. allocate_temp is only tracked through record_xxx_temp. It appears\r\n  //    in 'NodeExecStats.memory_stats'.\r\n  // 4. allocate_persistent calls allocate_tensor, which is properly tracked\r\n  //    in 'NodeExecStats.memory'. However, there is no way to count it as\r\n  //    persistent now.\r\n  // 5. record_xxx_persistent is called when allocate_persistent\r\n  //    is not used. Hence tracks some complementary bytes. It appears in\r\n  //    'NodeExecStats.memory_stats'. It's suspicious. But we should\r\n  //    use it now since it covers constant op."}