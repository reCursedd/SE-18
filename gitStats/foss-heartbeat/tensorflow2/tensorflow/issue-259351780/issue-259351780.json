{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13200", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13200/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13200/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13200/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13200", "id": 259351780, "node_id": "MDU6SXNzdWUyNTkzNTE3ODA=", "number": 13200, "title": "speech_commands using python speech_recognition as input [working example]", "user": {"login": "absentdream", "id": 3314310, "node_id": "MDQ6VXNlcjMzMTQzMTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/3314310?v=4", "gravatar_id": "", "url": "https://api.github.com/users/absentdream", "html_url": "https://github.com/absentdream", "followers_url": "https://api.github.com/users/absentdream/followers", "following_url": "https://api.github.com/users/absentdream/following{/other_user}", "gists_url": "https://api.github.com/users/absentdream/gists{/gist_id}", "starred_url": "https://api.github.com/users/absentdream/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/absentdream/subscriptions", "organizations_url": "https://api.github.com/users/absentdream/orgs", "repos_url": "https://api.github.com/users/absentdream/repos", "events_url": "https://api.github.com/users/absentdream/events{/privacy}", "received_events_url": "https://api.github.com/users/absentdream/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-21T01:49:20Z", "updated_at": "2017-11-07T22:06:02Z", "closed_at": "2017-11-07T22:06:01Z", "author_association": "NONE", "body_html": "<p>using your sample code /tensorflow/examples/speech_commands/label_wav.py I tweeked to use speech_recognition  as input that dumps wave data to trained network...</p>\n<p>feel free to add to examples for others to use..</p>\n<p>many thanks<br>\ncalvin<br>\n(ubuntu 16.04, python 2.7)</p>\n<pre>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\n\nimport tensorflow as tf\nimport speech_recognition as sr\nfrom tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n\nFLAGS = None\n\n\ndef load_graph(filename):\n  with tf.gfile.FastGFile(filename, 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    tf.import_graph_def(graph_def, name='')\n\n\ndef load_labels(filename):\n  return [line.rstrip() for line in tf.gfile.GFile(filename)]\n\n\ndef run_graph(wav_data, labels, input_layer_name, output_layer_name,\n              num_top_predictions):\n  with tf.Session() as sess:\n    softmax_tensor = sess.graph.get_tensor_by_name(output_layer_name)\n    predictions, = sess.run(softmax_tensor, {input_layer_name: wav_data})\n    top_k = predictions.argsort()[-num_top_predictions:][::-1]\n    for node_id in top_k:\n      human_string = labels[node_id]\n      score = predictions[node_id]\n      print('%s (score = %.5f)' % (human_string, score))\n\n    return 0\n\ndef listen(r,source,labels_list):\n    audio = r.listen(source)\n\t\n    run_graph(audio.get_wav_data(convert_rate = 16000, convert_width = 2), labels_list, FLAGS.input_name,\n            FLAGS.output_name, FLAGS.how_many_labels)\n\ndef main(_):\n  print('start')\n  labels_list = load_labels(FLAGS.labels)\n  load_graph(FLAGS.graph)\n  \n  r = sr.Recognizer()\n  with sr.Microphone() as source:\n    print(\"Say something!\")\n    while 1:\n        listen(r,source,labels_list)\n        print(\"------------------\")\n  print('emd')\n \n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--graph', type=str, default='', help='Model to use for identification.')\n  parser.add_argument(\n      '--labels', type=str, default='', help='Path to file containing labels.')\n  parser.add_argument(\n      '--input_name',\n      type=str,\n      default='wav_data:0',\n      help='Name of WAVE data input node in model.')\n  parser.add_argument(\n      '--output_name',\n      type=str,\n      default='labels_softmax:0',\n      help='Name of node outputting a prediction in the model.')\n  parser.add_argument(\n      '--how_many_labels',\n      type=int,\n      default=3,\n      help='Number of results to show.')\n\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n</pre>", "body_text": "using your sample code /tensorflow/examples/speech_commands/label_wav.py I tweeked to use speech_recognition  as input that dumps wave data to trained network...\nfeel free to add to examples for others to use..\nmany thanks\ncalvin\n(ubuntu 16.04, python 2.7)\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\n\nimport tensorflow as tf\nimport speech_recognition as sr\nfrom tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n\nFLAGS = None\n\n\ndef load_graph(filename):\n  with tf.gfile.FastGFile(filename, 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    tf.import_graph_def(graph_def, name='')\n\n\ndef load_labels(filename):\n  return [line.rstrip() for line in tf.gfile.GFile(filename)]\n\n\ndef run_graph(wav_data, labels, input_layer_name, output_layer_name,\n              num_top_predictions):\n  with tf.Session() as sess:\n    softmax_tensor = sess.graph.get_tensor_by_name(output_layer_name)\n    predictions, = sess.run(softmax_tensor, {input_layer_name: wav_data})\n    top_k = predictions.argsort()[-num_top_predictions:][::-1]\n    for node_id in top_k:\n      human_string = labels[node_id]\n      score = predictions[node_id]\n      print('%s (score = %.5f)' % (human_string, score))\n\n    return 0\n\ndef listen(r,source,labels_list):\n    audio = r.listen(source)\n\t\n    run_graph(audio.get_wav_data(convert_rate = 16000, convert_width = 2), labels_list, FLAGS.input_name,\n            FLAGS.output_name, FLAGS.how_many_labels)\n\ndef main(_):\n  print('start')\n  labels_list = load_labels(FLAGS.labels)\n  load_graph(FLAGS.graph)\n  \n  r = sr.Recognizer()\n  with sr.Microphone() as source:\n    print(\"Say something!\")\n    while 1:\n        listen(r,source,labels_list)\n        print(\"------------------\")\n  print('emd')\n \n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--graph', type=str, default='', help='Model to use for identification.')\n  parser.add_argument(\n      '--labels', type=str, default='', help='Path to file containing labels.')\n  parser.add_argument(\n      '--input_name',\n      type=str,\n      default='wav_data:0',\n      help='Name of WAVE data input node in model.')\n  parser.add_argument(\n      '--output_name',\n      type=str,\n      default='labels_softmax:0',\n      help='Name of node outputting a prediction in the model.')\n  parser.add_argument(\n      '--how_many_labels',\n      type=int,\n      default=3,\n      help='Number of results to show.')\n\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)", "body": "using your sample code /tensorflow/examples/speech_commands/label_wav.py I tweeked to use speech_recognition  as input that dumps wave data to trained network...\r\n\r\nfeel free to add to examples for others to use..\r\n\r\nmany thanks \r\ncalvin\r\n(ubuntu 16.04, python 2.7)\r\n\r\n<pre>\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport sys\r\n\r\nimport tensorflow as tf\r\nimport speech_recognition as sr\r\nfrom tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\r\n\r\nFLAGS = None\r\n\r\n\r\ndef load_graph(filename):\r\n  with tf.gfile.FastGFile(filename, 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    tf.import_graph_def(graph_def, name='')\r\n\r\n\r\ndef load_labels(filename):\r\n  return [line.rstrip() for line in tf.gfile.GFile(filename)]\r\n\r\n\r\ndef run_graph(wav_data, labels, input_layer_name, output_layer_name,\r\n              num_top_predictions):\r\n  with tf.Session() as sess:\r\n    softmax_tensor = sess.graph.get_tensor_by_name(output_layer_name)\r\n    predictions, = sess.run(softmax_tensor, {input_layer_name: wav_data})\r\n    top_k = predictions.argsort()[-num_top_predictions:][::-1]\r\n    for node_id in top_k:\r\n      human_string = labels[node_id]\r\n      score = predictions[node_id]\r\n      print('%s (score = %.5f)' % (human_string, score))\r\n\r\n    return 0\r\n\r\ndef listen(r,source,labels_list):\r\n    audio = r.listen(source)\r\n\t\r\n    run_graph(audio.get_wav_data(convert_rate = 16000, convert_width = 2), labels_list, FLAGS.input_name,\r\n            FLAGS.output_name, FLAGS.how_many_labels)\r\n\r\ndef main(_):\r\n  print('start')\r\n  labels_list = load_labels(FLAGS.labels)\r\n  load_graph(FLAGS.graph)\r\n  \r\n  r = sr.Recognizer()\r\n  with sr.Microphone() as source:\r\n    print(\"Say something!\")\r\n    while 1:\r\n        listen(r,source,labels_list)\r\n        print(\"------------------\")\r\n  print('emd')\r\n \r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '--graph', type=str, default='', help='Model to use for identification.')\r\n  parser.add_argument(\r\n      '--labels', type=str, default='', help='Path to file containing labels.')\r\n  parser.add_argument(\r\n      '--input_name',\r\n      type=str,\r\n      default='wav_data:0',\r\n      help='Name of WAVE data input node in model.')\r\n  parser.add_argument(\r\n      '--output_name',\r\n      type=str,\r\n      default='labels_softmax:0',\r\n      help='Name of node outputting a prediction in the model.')\r\n  parser.add_argument(\r\n      '--how_many_labels',\r\n      type=int,\r\n      default=3,\r\n      help='Number of results to show.')\r\n\r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n</pre>"}