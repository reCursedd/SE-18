{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23627", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23627/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23627/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23627/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23627", "id": 379103285, "node_id": "MDU6SXNzdWUzNzkxMDMyODU=", "number": 23627, "title": "TFLiteConverter.from_saved_model - batchNorm is not supported? ", "user": {"login": "milinddeore", "id": 1849168, "node_id": "MDQ6VXNlcjE4NDkxNjg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1849168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/milinddeore", "html_url": "https://github.com/milinddeore", "followers_url": "https://api.github.com/users/milinddeore/followers", "following_url": "https://api.github.com/users/milinddeore/following{/other_user}", "gists_url": "https://api.github.com/users/milinddeore/gists{/gist_id}", "starred_url": "https://api.github.com/users/milinddeore/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/milinddeore/subscriptions", "organizations_url": "https://api.github.com/users/milinddeore/orgs", "repos_url": "https://api.github.com/users/milinddeore/repos", "events_url": "https://api.github.com/users/milinddeore/events{/privacy}", "received_events_url": "https://api.github.com/users/milinddeore/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "gargn", "id": 1900612, "node_id": "MDQ6VXNlcjE5MDA2MTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1900612?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gargn", "html_url": "https://github.com/gargn", "followers_url": "https://api.github.com/users/gargn/followers", "following_url": "https://api.github.com/users/gargn/following{/other_user}", "gists_url": "https://api.github.com/users/gargn/gists{/gist_id}", "starred_url": "https://api.github.com/users/gargn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gargn/subscriptions", "organizations_url": "https://api.github.com/users/gargn/orgs", "repos_url": "https://api.github.com/users/gargn/repos", "events_url": "https://api.github.com/users/gargn/events{/privacy}", "received_events_url": "https://api.github.com/users/gargn/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gargn", "id": 1900612, "node_id": "MDQ6VXNlcjE5MDA2MTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1900612?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gargn", "html_url": "https://github.com/gargn", "followers_url": "https://api.github.com/users/gargn/followers", "following_url": "https://api.github.com/users/gargn/following{/other_user}", "gists_url": "https://api.github.com/users/gargn/gists{/gist_id}", "starred_url": "https://api.github.com/users/gargn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gargn/subscriptions", "organizations_url": "https://api.github.com/users/gargn/orgs", "repos_url": "https://api.github.com/users/gargn/repos", "events_url": "https://api.github.com/users/gargn/events{/privacy}", "received_events_url": "https://api.github.com/users/gargn/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-11-09T10:21:07Z", "updated_at": "2018-11-11T15:50:41Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>\n<p>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, i have tried tensorflow example code snippet.</p>\n</li>\n<li>\n<p>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Linux bedbba52137a 4.14.65+ <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a> SMP Sun Sep 9 02:18:33 PDT 2018 x86_64 x86_64 x86_64 GNU/Linux)</p>\n</li>\n<li>\n<p>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None</p>\n</li>\n<li>\n<p>TensorFlow installed from (source or binary): pip on google colab, using following command</p>\n</li>\n</ul>\n<pre><code>pip3 install --upgrade tf-nightly\n\n</code></pre>\n<ul>\n<li>TensorFlow version (use command below): version: 1.13.0-dev20181109</li>\n</ul>\n<pre><code>import tensorflow as tf \nprint(tf.__version__)\n\n</code></pre>\n<ul>\n<li>\n<p>Python version: Python 3.6.6</p>\n</li>\n<li>\n<p>Bazel version (if compiling from source): None</p>\n</li>\n<li>\n<p>GCC/Compiler version (if compiling from source): None</p>\n</li>\n<li>\n<p>CUDA/cuDNN version: using command 'nvcc --version'<br>\nnvcc: NVIDIA (R) Cuda compiler driver<br>\nCopyright (c) 2005-2018 NVIDIA Corporation<br>\nBuilt on Tue_Jun_12_23:07:04_CDT_2018<br>\nCuda compilation tools, release 9.2, V9.2.148</p>\n</li>\n<li>\n<p>GPU model and memory:</p>\n</li>\n</ul>\n<p>You can collect some of this information using our environment capture <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">script</a><br>\nYou can also obtain the TensorFlow version with<br>\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<p><strong>Describe the current behavior</strong><br>\nI have a <a href=\"https://drive.google.com/file/d/1mgjhsPpEDKs8Jud1wbtAKfjObAJVO8GL/view?usp=sharing\" rel=\"nofollow\">model here</a>, which is exported SavedModel using following code:</p>\n<pre><code># SavedModel using simple_save()\n\nins = {\"phase_train_placeholder\":phase_train_placeholder}\nouts = {\"embeddings\":embeddings}\ntf.saved_model.simple_save(sess, '/content/generated/', ins, outs)\n\n</code></pre>\n<p>When i convert this SavedModel to TFLite it give me error, the code snippet is as:</p>\n<pre><code>import tensorflow as tf\n\nsaved_model_dir = '/content/generated/'\n\nconverter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes=(1,160,160,3), \n                                                             output_arrays=['embeddings'])\ntflite_model = converter.convert()\nopen(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model)\n</code></pre>\n<p>Following are error logs:</p>\n<pre><code>WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py:61: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\nINFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\nINFO:tensorflow:input tensors info: \nINFO:tensorflow:Tensor's key in saved_model's tensor_map: phase_train_placeholder\nINFO:tensorflow: tensor name: phase_train:0, shape: unknown_rank, type: DT_BOOL\nINFO:tensorflow:output tensors info: \nINFO:tensorflow:Tensor's key in saved_model's tensor_map: embeddings\nINFO:tensorflow: tensor name: embeddings:0, shape: (-1, 512), type: DT_FLOAT\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-4-63a92824a047&gt; in &lt;module&gt;()\n      6 \n      7 converter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes=(1,160,160,3), \n----&gt; 8                                                              output_arrays=['embeddings'])\n      9 tflite_model = converter.convert()\n     10 open(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in from_saved_model(cls, saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\n    342 \n    343     result = _freeze_saved_model(saved_model_dir, input_arrays, input_shapes,\n--&gt; 344                                  output_arrays, tag_set, signature_key)\n    345     return cls(\n    346         graph_def=result[0], input_tensors=result[1], output_tensors=result[2])\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py in freeze_saved_model(saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\n    254     in_tensors = _get_tensors(graph, inputs, input_arrays)\n    255     out_tensors = _get_tensors(graph, outputs, output_arrays)\n--&gt; 256     set_tensor_shapes(in_tensors, input_shapes)\n    257 \n    258     output_names = [node.split(\":\")[0] for node in outputs]\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py in set_tensor_shapes(tensors, shapes)\n    201   if shapes:\n    202     for tensor in tensors:\n--&gt; 203       shape = shapes.get(tensor_name(tensor))\n    204       if shape is not None:\n    205         tensor.set_shape(shape)\n\nAttributeError: 'tuple' object has no attribute 'get'\n</code></pre>\n<p><strong>Updates on 10-Nov-2018</strong></p>\n<p>I have to give input_shape as dictionary in the following way:</p>\n<pre><code>import tensorflow as tf\n\nsaved_model_dir = '/content/generated/'\n\nconverter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes={\"phase_train\":[1,160,160,3]}, output_arrays=['embeddings'])\n\ntflite_model = converter.convert()\nopen(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model) \n</code></pre>\n<p>This fixed the earlier error but now i see a different error and the logs are below:</p>\n<pre><code>INFO:tensorflow:Restoring parameters from /content/generated/variables/variables\nINFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\nINFO:tensorflow:input tensors info: \nINFO:tensorflow:Tensor's key in saved_model's tensor_map: phase_train_placeholder\nINFO:tensorflow: tensor name: phase_train:0, shape: unknown_rank, type: DT_BOOL\nINFO:tensorflow:output tensors info: \nINFO:tensorflow:Tensor's key in saved_model's tensor_map: embeddings\nINFO:tensorflow: tensor name: embeddings:0, shape: (-1, 512), type: DT_FLOAT\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\nINFO:tensorflow:Froze 490 variables.\nINFO:tensorflow:Converted 490 variables to const ops.\n---------------------------------------------------------------------------\nConverterError                            Traceback (most recent call last)\n&lt;ipython-input-53-91d1899f3204&gt; in &lt;module&gt;()\n      8 converter = tf.contrib.lite.TocoConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes={\"phase_train\":[1,160,160,3]}, \n      9                                                    output_arrays=['embeddings'])\n---&gt; 10 tflite_model = converter.convert()\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self)\n    454           input_tensors=self._input_tensors,\n    455           output_tensors=self._output_tensors,\n--&gt; 456           **converter_kwargs)\n    457     else:\n    458       result = _toco_convert_graph_def(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)\n    395   data = toco_convert_protos(model_flags.SerializeToString(),\n    396                              toco_flags.SerializeToString(),\n--&gt; 397                              input_data.SerializeToString())\n    398   return data\n    399 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)\n    170       stderr = _try_convert_to_unicode(stderr)\n    171       raise ConverterError(\n--&gt; 172           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n    173   finally:\n    174     # Must manually cleanup files.\n\nConverterError: TOCO failed. See console for info.\n2018-11-11 08:46:00.208147: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: FIFOQueueV2\n2018-11-11 08:46:00.216527: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2018-11-11 08:46:00.216572: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: QueueDequeueUpToV2\n2018-11-11 08:46:00.216749: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\n2018-11-11 08:46:00.216793: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\n2018-11-11 08:46:00.216846: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\n\n....... logs dropped here \n\n2018-11-11 08:46:00.291969: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\n2018-11-11 08:46:00.292018: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\n2018-11-11 08:46:00.292076: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\n2018-11-11 08:46:00.292113: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\n2018-11-11 08:46:00.937387: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 5600 operators, 9398 arrays (0 quantized)\n2018-11-11 08:46:01.526448: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 3582 operators, 6259 arrays (0 quantized)\n2018-11-11 08:46:01.979950: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 3582 operators, 6259 arrays (0 quantized)\n2018-11-11 08:46:01.982607: F tensorflow/lite/toco/graph_transformations/resolve_batch_normalization.cc:45] Check failed: IsConstantParameterArray(*model, bn_op-&gt;inputs[1]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[2]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\nAborted (core dumped)\n\n</code></pre>\n<p><strong>Describe the expected behavior</strong><br>\nIt should create *.lite file instead.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<p>I have given the <a href=\"https://drive.google.com/file/d/1mgjhsPpEDKs8Jud1wbtAKfjObAJVO8GL/view?usp=sharing\" rel=\"nofollow\">SavedModel</a> and above code snippet to reproduce it.</p>\n<p><strong>Other info / logs</strong><br>\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.</p>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No, i have tried tensorflow example code snippet.\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Linux bedbba52137a 4.14.65+ #1 SMP Sun Sep 9 02:18:33 PDT 2018 x86_64 x86_64 x86_64 GNU/Linux)\n\n\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\n\n\nTensorFlow installed from (source or binary): pip on google colab, using following command\n\n\npip3 install --upgrade tf-nightly\n\n\n\nTensorFlow version (use command below): version: 1.13.0-dev20181109\n\nimport tensorflow as tf \nprint(tf.__version__)\n\n\n\n\nPython version: Python 3.6.6\n\n\nBazel version (if compiling from source): None\n\n\nGCC/Compiler version (if compiling from source): None\n\n\nCUDA/cuDNN version: using command 'nvcc --version'\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2018 NVIDIA Corporation\nBuilt on Tue_Jun_12_23:07:04_CDT_2018\nCuda compilation tools, release 9.2, V9.2.148\n\n\nGPU model and memory:\n\n\nYou can collect some of this information using our environment capture script\nYou can also obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the current behavior\nI have a model here, which is exported SavedModel using following code:\n# SavedModel using simple_save()\n\nins = {\"phase_train_placeholder\":phase_train_placeholder}\nouts = {\"embeddings\":embeddings}\ntf.saved_model.simple_save(sess, '/content/generated/', ins, outs)\n\n\nWhen i convert this SavedModel to TFLite it give me error, the code snippet is as:\nimport tensorflow as tf\n\nsaved_model_dir = '/content/generated/'\n\nconverter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes=(1,160,160,3), \n                                                             output_arrays=['embeddings'])\ntflite_model = converter.convert()\nopen(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model)\n\nFollowing are error logs:\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py:61: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\nINFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\nINFO:tensorflow:input tensors info: \nINFO:tensorflow:Tensor's key in saved_model's tensor_map: phase_train_placeholder\nINFO:tensorflow: tensor name: phase_train:0, shape: unknown_rank, type: DT_BOOL\nINFO:tensorflow:output tensors info: \nINFO:tensorflow:Tensor's key in saved_model's tensor_map: embeddings\nINFO:tensorflow: tensor name: embeddings:0, shape: (-1, 512), type: DT_FLOAT\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n<ipython-input-4-63a92824a047> in <module>()\n      6 \n      7 converter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes=(1,160,160,3), \n----> 8                                                              output_arrays=['embeddings'])\n      9 tflite_model = converter.convert()\n     10 open(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in from_saved_model(cls, saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\n    342 \n    343     result = _freeze_saved_model(saved_model_dir, input_arrays, input_shapes,\n--> 344                                  output_arrays, tag_set, signature_key)\n    345     return cls(\n    346         graph_def=result[0], input_tensors=result[1], output_tensors=result[2])\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py in freeze_saved_model(saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\n    254     in_tensors = _get_tensors(graph, inputs, input_arrays)\n    255     out_tensors = _get_tensors(graph, outputs, output_arrays)\n--> 256     set_tensor_shapes(in_tensors, input_shapes)\n    257 \n    258     output_names = [node.split(\":\")[0] for node in outputs]\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py in set_tensor_shapes(tensors, shapes)\n    201   if shapes:\n    202     for tensor in tensors:\n--> 203       shape = shapes.get(tensor_name(tensor))\n    204       if shape is not None:\n    205         tensor.set_shape(shape)\n\nAttributeError: 'tuple' object has no attribute 'get'\n\nUpdates on 10-Nov-2018\nI have to give input_shape as dictionary in the following way:\nimport tensorflow as tf\n\nsaved_model_dir = '/content/generated/'\n\nconverter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes={\"phase_train\":[1,160,160,3]}, output_arrays=['embeddings'])\n\ntflite_model = converter.convert()\nopen(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model) \n\nThis fixed the earlier error but now i see a different error and the logs are below:\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\nINFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\nINFO:tensorflow:input tensors info: \nINFO:tensorflow:Tensor's key in saved_model's tensor_map: phase_train_placeholder\nINFO:tensorflow: tensor name: phase_train:0, shape: unknown_rank, type: DT_BOOL\nINFO:tensorflow:output tensors info: \nINFO:tensorflow:Tensor's key in saved_model's tensor_map: embeddings\nINFO:tensorflow: tensor name: embeddings:0, shape: (-1, 512), type: DT_FLOAT\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\nINFO:tensorflow:Froze 490 variables.\nINFO:tensorflow:Converted 490 variables to const ops.\n---------------------------------------------------------------------------\nConverterError                            Traceback (most recent call last)\n<ipython-input-53-91d1899f3204> in <module>()\n      8 converter = tf.contrib.lite.TocoConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes={\"phase_train\":[1,160,160,3]}, \n      9                                                    output_arrays=['embeddings'])\n---> 10 tflite_model = converter.convert()\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self)\n    454           input_tensors=self._input_tensors,\n    455           output_tensors=self._output_tensors,\n--> 456           **converter_kwargs)\n    457     else:\n    458       result = _toco_convert_graph_def(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)\n    395   data = toco_convert_protos(model_flags.SerializeToString(),\n    396                              toco_flags.SerializeToString(),\n--> 397                              input_data.SerializeToString())\n    398   return data\n    399 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)\n    170       stderr = _try_convert_to_unicode(stderr)\n    171       raise ConverterError(\n--> 172           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n    173   finally:\n    174     # Must manually cleanup files.\n\nConverterError: TOCO failed. See console for info.\n2018-11-11 08:46:00.208147: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: FIFOQueueV2\n2018-11-11 08:46:00.216527: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2018-11-11 08:46:00.216572: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: QueueDequeueUpToV2\n2018-11-11 08:46:00.216749: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\n2018-11-11 08:46:00.216793: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\n2018-11-11 08:46:00.216846: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\n\n....... logs dropped here \n\n2018-11-11 08:46:00.291969: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\n2018-11-11 08:46:00.292018: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\n2018-11-11 08:46:00.292076: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\n2018-11-11 08:46:00.292113: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\n2018-11-11 08:46:00.937387: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 5600 operators, 9398 arrays (0 quantized)\n2018-11-11 08:46:01.526448: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 3582 operators, 6259 arrays (0 quantized)\n2018-11-11 08:46:01.979950: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 3582 operators, 6259 arrays (0 quantized)\n2018-11-11 08:46:01.982607: F tensorflow/lite/toco/graph_transformations/resolve_batch_normalization.cc:45] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\nAborted (core dumped)\n\n\nDescribe the expected behavior\nIt should create *.lite file instead.\nCode to reproduce the issue\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\nI have given the SavedModel and above code snippet to reproduce it.\nOther info / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, i have tried tensorflow example code snippet. \r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Linux bedbba52137a 4.14.65+ #1 SMP Sun Sep 9 02:18:33 PDT 2018 x86_64 x86_64 x86_64 GNU/Linux)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): pip on google colab, using following command \r\n```\r\npip3 install --upgrade tf-nightly\r\n\r\n```\r\n- TensorFlow version (use command below): version: 1.13.0-dev20181109\r\n```\r\nimport tensorflow as tf \r\nprint(tf.__version__)\r\n\r\n```\r\n- Python version: Python 3.6.6\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: using command 'nvcc --version'\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2018 NVIDIA Corporation\r\nBuilt on Tue_Jun_12_23:07:04_CDT_2018\r\nCuda compilation tools, release 9.2, V9.2.148\r\n\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI have a [model here](https://drive.google.com/file/d/1mgjhsPpEDKs8Jud1wbtAKfjObAJVO8GL/view?usp=sharing), which is exported SavedModel using following code: \r\n\r\n```\r\n# SavedModel using simple_save()\r\n\r\nins = {\"phase_train_placeholder\":phase_train_placeholder}\r\nouts = {\"embeddings\":embeddings}\r\ntf.saved_model.simple_save(sess, '/content/generated/', ins, outs)\r\n\r\n```        \r\n\r\nWhen i convert this SavedModel to TFLite it give me error, the code snippet is as: \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir = '/content/generated/'\r\n\r\nconverter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes=(1,160,160,3), \r\n                                                             output_arrays=['embeddings'])\r\ntflite_model = converter.convert()\r\nopen(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nFollowing are error logs: \r\n\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py:61: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\r\nINFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\r\nINFO:tensorflow:input tensors info: \r\nINFO:tensorflow:Tensor's key in saved_model's tensor_map: phase_train_placeholder\r\nINFO:tensorflow: tensor name: phase_train:0, shape: unknown_rank, type: DT_BOOL\r\nINFO:tensorflow:output tensors info: \r\nINFO:tensorflow:Tensor's key in saved_model's tensor_map: embeddings\r\nINFO:tensorflow: tensor name: embeddings:0, shape: (-1, 512), type: DT_FLOAT\r\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-63a92824a047> in <module>()\r\n      6 \r\n      7 converter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes=(1,160,160,3), \r\n----> 8                                                              output_arrays=['embeddings'])\r\n      9 tflite_model = converter.convert()\r\n     10 open(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in from_saved_model(cls, saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\r\n    342 \r\n    343     result = _freeze_saved_model(saved_model_dir, input_arrays, input_shapes,\r\n--> 344                                  output_arrays, tag_set, signature_key)\r\n    345     return cls(\r\n    346         graph_def=result[0], input_tensors=result[1], output_tensors=result[2])\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py in freeze_saved_model(saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\r\n    254     in_tensors = _get_tensors(graph, inputs, input_arrays)\r\n    255     out_tensors = _get_tensors(graph, outputs, output_arrays)\r\n--> 256     set_tensor_shapes(in_tensors, input_shapes)\r\n    257 \r\n    258     output_names = [node.split(\":\")[0] for node in outputs]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py in set_tensor_shapes(tensors, shapes)\r\n    201   if shapes:\r\n    202     for tensor in tensors:\r\n--> 203       shape = shapes.get(tensor_name(tensor))\r\n    204       if shape is not None:\r\n    205         tensor.set_shape(shape)\r\n\r\nAttributeError: 'tuple' object has no attribute 'get'\r\n```\r\n\r\n**Updates on 10-Nov-2018**\r\n\r\nI have to give input_shape as dictionary in the following way:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir = '/content/generated/'\r\n\r\nconverter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes={\"phase_train\":[1,160,160,3]}, output_arrays=['embeddings'])\r\n\r\ntflite_model = converter.convert()\r\nopen(\"converted_model_savedModel.tflite\", \"wb\").write(tflite_model) \r\n```\r\n\r\nThis fixed the earlier error but now i see a different error and the logs are below: \r\n\r\n```\r\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\r\nINFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\r\nINFO:tensorflow:input tensors info: \r\nINFO:tensorflow:Tensor's key in saved_model's tensor_map: phase_train_placeholder\r\nINFO:tensorflow: tensor name: phase_train:0, shape: unknown_rank, type: DT_BOOL\r\nINFO:tensorflow:output tensors info: \r\nINFO:tensorflow:Tensor's key in saved_model's tensor_map: embeddings\r\nINFO:tensorflow: tensor name: embeddings:0, shape: (-1, 512), type: DT_FLOAT\r\nINFO:tensorflow:Restoring parameters from /content/generated/variables/variables\r\nINFO:tensorflow:Froze 490 variables.\r\nINFO:tensorflow:Converted 490 variables to const ops.\r\n---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-53-91d1899f3204> in <module>()\r\n      8 converter = tf.contrib.lite.TocoConverter.from_saved_model(saved_model_dir, input_arrays=['phase_train'], input_shapes={\"phase_train\":[1,160,160,3]}, \r\n      9                                                    output_arrays=['embeddings'])\r\n---> 10 tflite_model = converter.convert()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self)\r\n    454           input_tensors=self._input_tensors,\r\n    455           output_tensors=self._output_tensors,\r\n--> 456           **converter_kwargs)\r\n    457     else:\r\n    458       result = _toco_convert_graph_def(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)\r\n    395   data = toco_convert_protos(model_flags.SerializeToString(),\r\n    396                              toco_flags.SerializeToString(),\r\n--> 397                              input_data.SerializeToString())\r\n    398   return data\r\n    399 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)\r\n    170       stderr = _try_convert_to_unicode(stderr)\r\n    171       raise ConverterError(\r\n--> 172           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    173   finally:\r\n    174     # Must manually cleanup files.\r\n\r\nConverterError: TOCO failed. See console for info.\r\n2018-11-11 08:46:00.208147: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: FIFOQueueV2\r\n2018-11-11 08:46:00.216527: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2018-11-11 08:46:00.216572: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: QueueDequeueUpToV2\r\n2018-11-11 08:46:00.216749: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\r\n2018-11-11 08:46:00.216793: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\r\n2018-11-11 08:46:00.216846: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\r\n\r\n....... logs dropped here \r\n\r\n2018-11-11 08:46:00.291969: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\r\n2018-11-11 08:46:00.292018: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\r\n2018-11-11 08:46:00.292076: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: RefSwitch\r\n2018-11-11 08:46:00.292113: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: AssignSub\r\n2018-11-11 08:46:00.937387: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 5600 operators, 9398 arrays (0 quantized)\r\n2018-11-11 08:46:01.526448: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 3582 operators, 6259 arrays (0 quantized)\r\n2018-11-11 08:46:01.979950: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 3582 operators, 6259 arrays (0 quantized)\r\n2018-11-11 08:46:01.982607: F tensorflow/lite/toco/graph_transformations/resolve_batch_normalization.cc:45] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\r\nAborted (core dumped)\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\nIt should create *.lite file instead. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nI have given the [SavedModel](https://drive.google.com/file/d/1mgjhsPpEDKs8Jud1wbtAKfjObAJVO8GL/view?usp=sharing) and above code snippet to reproduce it. \r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"}