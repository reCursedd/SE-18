{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/312589307", "html_url": "https://github.com/tensorflow/tensorflow/issues/2107#issuecomment-312589307", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2107", "id": 312589307, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjU4OTMwNw==", "user": {"login": "ducta-qc", "id": 25760767, "node_id": "MDQ6VXNlcjI1NzYwNzY3", "avatar_url": "https://avatars1.githubusercontent.com/u/25760767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ducta-qc", "html_url": "https://github.com/ducta-qc", "followers_url": "https://api.github.com/users/ducta-qc/followers", "following_url": "https://api.github.com/users/ducta-qc/following{/other_user}", "gists_url": "https://api.github.com/users/ducta-qc/gists{/gist_id}", "starred_url": "https://api.github.com/users/ducta-qc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ducta-qc/subscriptions", "organizations_url": "https://api.github.com/users/ducta-qc/orgs", "repos_url": "https://api.github.com/users/ducta-qc/repos", "events_url": "https://api.github.com/users/ducta-qc/events{/privacy}", "received_events_url": "https://api.github.com/users/ducta-qc/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-03T08:58:08Z", "updated_at": "2017-07-03T08:58:08Z", "author_association": "NONE", "body_html": "<p>I also encounter this error. In my case, the forward pass works normally but the backward pass I filtered unsuitable samples (convert from [<code>origin_batch_size</code>, h, w, 3] -&gt; [<code>keep_samples</code>, h, w, 3]) for training and keep them backprop through graph, it makes on some batches has zero sample when run the backward pass (keep_samples=0). I solved my problem by settings contributed loss to zero when <code>keep_samples</code> is zero.</p>", "body_text": "I also encounter this error. In my case, the forward pass works normally but the backward pass I filtered unsuitable samples (convert from [origin_batch_size, h, w, 3] -> [keep_samples, h, w, 3]) for training and keep them backprop through graph, it makes on some batches has zero sample when run the backward pass (keep_samples=0). I solved my problem by settings contributed loss to zero when keep_samples is zero.", "body": "I also encounter this error. In my case, the forward pass works normally but the backward pass I filtered unsuitable samples (convert from [`origin_batch_size`, h, w, 3] -> [`keep_samples`, h, w, 3]) for training and keep them backprop through graph, it makes on some batches has zero sample when run the backward pass (keep_samples=0). I solved my problem by settings contributed loss to zero when `keep_samples` is zero."}