{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19775", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19775/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19775/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19775/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19775", "id": 329464831, "node_id": "MDU6SXNzdWUzMjk0NjQ4MzE=", "number": 19775, "title": "Tensorflow python version incompatibility", "user": {"login": "icebreaker2", "id": 12209674, "node_id": "MDQ6VXNlcjEyMjA5Njc0", "avatar_url": "https://avatars2.githubusercontent.com/u/12209674?v=4", "gravatar_id": "", "url": "https://api.github.com/users/icebreaker2", "html_url": "https://github.com/icebreaker2", "followers_url": "https://api.github.com/users/icebreaker2/followers", "following_url": "https://api.github.com/users/icebreaker2/following{/other_user}", "gists_url": "https://api.github.com/users/icebreaker2/gists{/gist_id}", "starred_url": "https://api.github.com/users/icebreaker2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/icebreaker2/subscriptions", "organizations_url": "https://api.github.com/users/icebreaker2/orgs", "repos_url": "https://api.github.com/users/icebreaker2/repos", "events_url": "https://api.github.com/users/icebreaker2/events{/privacy}", "received_events_url": "https://api.github.com/users/icebreaker2/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2018-06-05T13:48:12Z", "updated_at": "2018-08-08T20:16:16Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hey,</p>\n<p>I use <code>inceptionv3</code> to classify various images. I experienced that images are classified with a different probabillity on different versions of python. I set up three environments:</p>\n<ol>\n<li>Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.6.2 with anaconda (no gpu support) (Windows 10)</li>\n<li>Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 2.7.12 installed via plain pip. (no GPU) (Ubuntu 16.04)</li>\n<li>Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.5.2 installed via plain pip. (no GPU) (Ubuntu 16.04)</li>\n</ol>\n<p>Environment 1 and 3 give the same results. Using python2 gives the lower probabilities on the correct class than given by the other two setups.</p>\n<p>Heres a little example I just created to outline the error and show how the classification performed:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> matplotlib.pyplot <span class=\"pl-k\">as</span> plt\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">PIL</span> <span class=\"pl-k\">import</span> Image\n<span class=\"pl-k\">import</span> json, os\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.slim <span class=\"pl-k\">as</span> slim\n<span class=\"pl-k\">from</span> tensorflow.contrib.slim.nets <span class=\"pl-k\">import</span> inception\n\n<span class=\"pl-c1\">FLAGS</span> <span class=\"pl-k\">=</span> tf.flags.<span class=\"pl-c1\">FLAGS</span>\ntf.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>image_name<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>cropped_panda.jpg<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Image name with file ending.<span class=\"pl-pds\">'</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>top_k<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Top k predictions to print out.<span class=\"pl-pds\">'</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>image_height<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">299</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>The image height for inception_v3 model.<span class=\"pl-pds\">'</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>image_width<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">299</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>The image width for inception_v3 model.<span class=\"pl-pds\">'</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>image_channels<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>The number of channels of for inception_v3 model.<span class=\"pl-pds\">'</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>image_N_classes<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">1000</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>The number of classes in the inception_v3 model.<span class=\"pl-pds\">'</span></span>)\ntf.flags.DEFINE_float(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>weight_decay<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>The weight decay applied to each edge/weight at each update step.<span class=\"pl-pds\">'</span></span>)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">load_images</span>(<span class=\"pl-smi\">batch_shape</span>, <span class=\"pl-smi\">pathPrefix</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>../../images/<span class=\"pl-pds\">'</span></span>):\n    num_images <span class=\"pl-k\">=</span> batch_shape[<span class=\"pl-c1\">0</span>]\n    image_path <span class=\"pl-k\">=</span> os.path.join(pathPrefix, <span class=\"pl-c1\">FLAGS</span>.image_name)\n    image <span class=\"pl-k\">=</span> Image.open(image_path)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> crop</span>\n    wide <span class=\"pl-k\">=</span> image.width <span class=\"pl-k\">&gt;</span> image.height\n    new_w <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.image_width <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> wide <span class=\"pl-k\">else</span> <span class=\"pl-c1\">int</span>(image.width <span class=\"pl-k\">*</span> <span class=\"pl-c1\">FLAGS</span>.image_width <span class=\"pl-k\">/</span> image.height)\n    new_h <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.image_height <span class=\"pl-k\">if</span> wide <span class=\"pl-k\">else</span> <span class=\"pl-c1\">int</span>(image.height <span class=\"pl-k\">*</span> <span class=\"pl-c1\">FLAGS</span>.image_height <span class=\"pl-k\">/</span> image.width)\n\n    images <span class=\"pl-k\">=</span> np.zeros(batch_shape)\n    <span class=\"pl-k\">for</span> idx <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_images):\n        image <span class=\"pl-k\">=</span> image.resize((new_w, new_h)).crop((<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">FLAGS</span>.image_width, <span class=\"pl-c1\">FLAGS</span>.image_height))\n        image <span class=\"pl-k\">=</span> (np.asarray(image) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255.0</span>).astype(np.float32)\n        images[idx, :, :, :] <span class=\"pl-k\">=</span> image\n    <span class=\"pl-k\">return</span> images\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">get_logits</span>(<span class=\"pl-smi\">image_placeholder</span>):\n    preprocessed <span class=\"pl-k\">=</span> tf.multiply(tf.subtract(image_placeholder, <span class=\"pl-c1\">0.5</span>), <span class=\"pl-c1\">2.0</span>)\n    arg_scope <span class=\"pl-k\">=</span> inception.inception_v3_arg_scope(<span class=\"pl-v\">weight_decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.weight_decay)\n    <span class=\"pl-k\">with</span> slim.arg_scope(arg_scope):\n        logits, _ <span class=\"pl-k\">=</span> inception.inception_v3(\n            preprocessed, <span class=\"pl-c1\">FLAGS</span>.image_N_classes <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n        logits <span class=\"pl-k\">=</span> logits[:, <span class=\"pl-c1\">1</span>:]\n        probs <span class=\"pl-k\">=</span> tf.nn.softmax(logits)\n    <span class=\"pl-k\">return</span> logits, probs\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">get_inception_session</span>(<span class=\"pl-smi\">sess</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">pathToInception</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>../../<span class=\"pl-pds\">'</span></span>):\n    saver <span class=\"pl-k\">=</span> tf.train.Saver()\n    saver.restore(sess, os.path.join(pathToInception, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>inception_v3.ckpt<span class=\"pl-pds\">'</span></span>))\n    <span class=\"pl-k\">return</span> sess\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">argsunused</span>):\n    images <span class=\"pl-k\">=</span> load_images((<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">FLAGS</span>.image_height, <span class=\"pl-c1\">FLAGS</span>.image_width, <span class=\"pl-c1\">FLAGS</span>.image_channels))\n    image_placeholder <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, (<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">FLAGS</span>.image_height, <span class=\"pl-c1\">FLAGS</span>.image_width, <span class=\"pl-c1\">FLAGS</span>.image_channels))\n    logits, preds <span class=\"pl-k\">=</span> get_logits(image_placeholder)\n\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess <span class=\"pl-k\">=</span> get_inception_session(sess)\n        top_k <span class=\"pl-k\">=</span> tf.nn.top_k(preds, <span class=\"pl-v\">k</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.top_k)\n        values, indices <span class=\"pl-k\">=</span> sess.run([top_k.values, top_k.indices], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{image_placeholder: images})\n        <span class=\"pl-k\">for</span> (index, value) <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(indices[<span class=\"pl-c1\">0</span>], values[<span class=\"pl-c1\">0</span>]):\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Class <span class=\"pl-c1\">%d</span> with prob: <span class=\"pl-c1\">%f</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (index, value))\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    tf.app.run()</pre></div>\n<p>If I misssused something here, please be so kind and explain my mistake:)</p>\n<p>Regards</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes. Uses the elements shown in the example.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: See above (windows and ubuntu 16.04)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: b'v1.8.0-0-g93bc2e2072' 1.8.0</li>\n<li><strong>Python version</strong>: 2.7.12, 3.5.2, 3.6.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: -</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: -</li>\n<li><strong>CUDA/cuDNN version</strong>: -</li>\n<li><strong>GPU model and memory</strong>: -</li>\n<li><strong>Exact command to reproduce</strong>: -</li>\n</ul>", "body_text": "Hey,\nI use inceptionv3 to classify various images. I experienced that images are classified with a different probabillity on different versions of python. I set up three environments:\n\nTensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.6.2 with anaconda (no gpu support) (Windows 10)\nTensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 2.7.12 installed via plain pip. (no GPU) (Ubuntu 16.04)\nTensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.5.2 installed via plain pip. (no GPU) (Ubuntu 16.04)\n\nEnvironment 1 and 3 give the same results. Using python2 gives the lower probabilities on the correct class than given by the other two setups.\nHeres a little example I just created to outline the error and show how the classification performed:\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport json, os\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nfrom tensorflow.contrib.slim.nets import inception\n\nFLAGS = tf.flags.FLAGS\ntf.flags.DEFINE_string('image_name', 'cropped_panda.jpg', 'Image name with file ending.')\ntf.flags.DEFINE_integer('top_k', 5, 'Top k predictions to print out.')\ntf.flags.DEFINE_integer('image_height', 299, 'The image height for inception_v3 model.')\ntf.flags.DEFINE_integer('image_width', 299, 'The image width for inception_v3 model.')\ntf.flags.DEFINE_integer('image_channels', 3, 'The number of channels of for inception_v3 model.')\ntf.flags.DEFINE_integer('image_N_classes', 1000, 'The number of classes in the inception_v3 model.')\ntf.flags.DEFINE_float('weight_decay', 0.0, 'The weight decay applied to each edge/weight at each update step.')\n\n\ndef load_images(batch_shape, pathPrefix='../../images/'):\n    num_images = batch_shape[0]\n    image_path = os.path.join(pathPrefix, FLAGS.image_name)\n    image = Image.open(image_path)\n\n    # crop\n    wide = image.width > image.height\n    new_w = FLAGS.image_width if not wide else int(image.width * FLAGS.image_width / image.height)\n    new_h = FLAGS.image_height if wide else int(image.height * FLAGS.image_height / image.width)\n\n    images = np.zeros(batch_shape)\n    for idx in range(num_images):\n        image = image.resize((new_w, new_h)).crop((0, 0, FLAGS.image_width, FLAGS.image_height))\n        image = (np.asarray(image) / 255.0).astype(np.float32)\n        images[idx, :, :, :] = image\n    return images\n\n\ndef get_logits(image_placeholder):\n    preprocessed = tf.multiply(tf.subtract(image_placeholder, 0.5), 2.0)\n    arg_scope = inception.inception_v3_arg_scope(weight_decay=FLAGS.weight_decay)\n    with slim.arg_scope(arg_scope):\n        logits, _ = inception.inception_v3(\n            preprocessed, FLAGS.image_N_classes + 1, is_training=False, reuse=False)\n        logits = logits[:, 1:]\n        probs = tf.nn.softmax(logits)\n    return logits, probs\n\n\ndef get_inception_session(sess=None, pathToInception='../../'):\n    saver = tf.train.Saver()\n    saver.restore(sess, os.path.join(pathToInception, 'inception_v3.ckpt'))\n    return sess\n\n\ndef main(argsunused):\n    images = load_images((1, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channels))\n    image_placeholder = tf.placeholder(tf.float32, (1, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channels))\n    logits, preds = get_logits(image_placeholder)\n\n    with tf.Session() as sess:\n        sess = get_inception_session(sess)\n        top_k = tf.nn.top_k(preds, k=FLAGS.top_k)\n        values, indices = sess.run([top_k.values, top_k.indices], feed_dict={image_placeholder: images})\n        for (index, value) in zip(indices[0], values[0]):\n            print(\"Class %d with prob: %f\" % (index, value))\n\n\nif __name__ == '__main__':\n    tf.app.run()\nIf I misssused something here, please be so kind and explain my mistake:)\nRegards\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. Uses the elements shown in the example.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): See above (windows and ubuntu 16.04)\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): b'v1.8.0-0-g93bc2e2072' 1.8.0\nPython version: 2.7.12, 3.5.2, 3.6.2\nBazel version (if compiling from source): -\nGCC/Compiler version (if compiling from source): -\nCUDA/cuDNN version: -\nGPU model and memory: -\nExact command to reproduce: -", "body": "Hey,\r\n\r\nI use `inceptionv3` to classify various images. I experienced that images are classified with a different probabillity on different versions of python. I set up three environments:\r\n1. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.6.2 with anaconda (no gpu support) (Windows 10)\r\n2. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 2.7.12 installed via plain pip. (no GPU) (Ubuntu 16.04)\r\n3. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.5.2 installed via plain pip. (no GPU) (Ubuntu 16.04)\r\n\r\nEnvironment 1 and 3 give the same results. Using python2 gives the lower probabilities on the correct class than given by the other two setups.\r\n\r\nHeres a little example I just created to outline the error and show how the classification performed:\r\n```python\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom PIL import Image\r\nimport json, os\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nfrom tensorflow.contrib.slim.nets import inception\r\n\r\nFLAGS = tf.flags.FLAGS\r\ntf.flags.DEFINE_string('image_name', 'cropped_panda.jpg', 'Image name with file ending.')\r\ntf.flags.DEFINE_integer('top_k', 5, 'Top k predictions to print out.')\r\ntf.flags.DEFINE_integer('image_height', 299, 'The image height for inception_v3 model.')\r\ntf.flags.DEFINE_integer('image_width', 299, 'The image width for inception_v3 model.')\r\ntf.flags.DEFINE_integer('image_channels', 3, 'The number of channels of for inception_v3 model.')\r\ntf.flags.DEFINE_integer('image_N_classes', 1000, 'The number of classes in the inception_v3 model.')\r\ntf.flags.DEFINE_float('weight_decay', 0.0, 'The weight decay applied to each edge/weight at each update step.')\r\n\r\n\r\ndef load_images(batch_shape, pathPrefix='../../images/'):\r\n    num_images = batch_shape[0]\r\n    image_path = os.path.join(pathPrefix, FLAGS.image_name)\r\n    image = Image.open(image_path)\r\n\r\n    # crop\r\n    wide = image.width > image.height\r\n    new_w = FLAGS.image_width if not wide else int(image.width * FLAGS.image_width / image.height)\r\n    new_h = FLAGS.image_height if wide else int(image.height * FLAGS.image_height / image.width)\r\n\r\n    images = np.zeros(batch_shape)\r\n    for idx in range(num_images):\r\n        image = image.resize((new_w, new_h)).crop((0, 0, FLAGS.image_width, FLAGS.image_height))\r\n        image = (np.asarray(image) / 255.0).astype(np.float32)\r\n        images[idx, :, :, :] = image\r\n    return images\r\n\r\n\r\ndef get_logits(image_placeholder):\r\n    preprocessed = tf.multiply(tf.subtract(image_placeholder, 0.5), 2.0)\r\n    arg_scope = inception.inception_v3_arg_scope(weight_decay=FLAGS.weight_decay)\r\n    with slim.arg_scope(arg_scope):\r\n        logits, _ = inception.inception_v3(\r\n            preprocessed, FLAGS.image_N_classes + 1, is_training=False, reuse=False)\r\n        logits = logits[:, 1:]\r\n        probs = tf.nn.softmax(logits)\r\n    return logits, probs\r\n\r\n\r\ndef get_inception_session(sess=None, pathToInception='../../'):\r\n    saver = tf.train.Saver()\r\n    saver.restore(sess, os.path.join(pathToInception, 'inception_v3.ckpt'))\r\n    return sess\r\n\r\n\r\ndef main(argsunused):\r\n    images = load_images((1, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channels))\r\n    image_placeholder = tf.placeholder(tf.float32, (1, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channels))\r\n    logits, preds = get_logits(image_placeholder)\r\n\r\n    with tf.Session() as sess:\r\n        sess = get_inception_session(sess)\r\n        top_k = tf.nn.top_k(preds, k=FLAGS.top_k)\r\n        values, indices = sess.run([top_k.values, top_k.indices], feed_dict={image_placeholder: images})\r\n        for (index, value) in zip(indices[0], values[0]):\r\n            print(\"Class %d with prob: %f\" % (index, value))\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n```\r\nIf I misssused something here, please be so kind and explain my mistake:)\r\n\r\nRegards\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. Uses the elements shown in the example.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: See above (windows and ubuntu 16.04)\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: b'v1.8.0-0-g93bc2e2072' 1.8.0\r\n- **Python version**: 2.7.12, 3.5.2, 3.6.2\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: -"}