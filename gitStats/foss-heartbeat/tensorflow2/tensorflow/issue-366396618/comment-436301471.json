{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/436301471", "html_url": "https://github.com/tensorflow/tensorflow/issues/22697#issuecomment-436301471", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22697", "id": 436301471, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjMwMTQ3MQ==", "user": {"login": "mhwilder", "id": 8092944, "node_id": "MDQ6VXNlcjgwOTI5NDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8092944?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mhwilder", "html_url": "https://github.com/mhwilder", "followers_url": "https://api.github.com/users/mhwilder/followers", "following_url": "https://api.github.com/users/mhwilder/following{/other_user}", "gists_url": "https://api.github.com/users/mhwilder/gists{/gist_id}", "starred_url": "https://api.github.com/users/mhwilder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mhwilder/subscriptions", "organizations_url": "https://api.github.com/users/mhwilder/orgs", "repos_url": "https://api.github.com/users/mhwilder/repos", "events_url": "https://api.github.com/users/mhwilder/events{/privacy}", "received_events_url": "https://api.github.com/users/mhwilder/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-06T15:49:59Z", "updated_at": "2018-11-06T15:49:59Z", "author_association": "NONE", "body_html": "<p>This issue is still a problem but here's the workaround I've been using. It's not really the right solution, but at least my mobilenet V1 and V2 models can be reloaded. I agree with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=714585\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mevatron\">@mevatron</a> that the problem is probably in how the model is being saved (specifically, the format used for the ReLu parameters).</p>\n<p><strong>Temporary Fix:</strong><br>\nAfter the <code>super()</code> call in the ReLu <code>init()</code> function in <em>tensorflow/python/keras/layers/advanced_activations.py</em> (around line 310), add the following lines of code:</p>\n<pre><code>    if type(max_value) is dict:\n        max_value = max_value['value']\n    if type(negative_slope) is dict:\n        negative_slope = negative_slope['value']\n    if type(threshold) is dict:\n        threshold = threshold['value']\n</code></pre>", "body_text": "This issue is still a problem but here's the workaround I've been using. It's not really the right solution, but at least my mobilenet V1 and V2 models can be reloaded. I agree with @mevatron that the problem is probably in how the model is being saved (specifically, the format used for the ReLu parameters).\nTemporary Fix:\nAfter the super() call in the ReLu init() function in tensorflow/python/keras/layers/advanced_activations.py (around line 310), add the following lines of code:\n    if type(max_value) is dict:\n        max_value = max_value['value']\n    if type(negative_slope) is dict:\n        negative_slope = negative_slope['value']\n    if type(threshold) is dict:\n        threshold = threshold['value']", "body": "This issue is still a problem but here's the workaround I've been using. It's not really the right solution, but at least my mobilenet V1 and V2 models can be reloaded. I agree with @mevatron that the problem is probably in how the model is being saved (specifically, the format used for the ReLu parameters).\r\n\r\n**Temporary Fix:**\r\nAfter the ```super()``` call in the ReLu ```init()``` function in _tensorflow/python/keras/layers/advanced\\_activations.py_ (around line 310), add the following lines of code:\r\n```\r\n    if type(max_value) is dict:\r\n        max_value = max_value['value']\r\n    if type(negative_slope) is dict:\r\n        negative_slope = negative_slope['value']\r\n    if type(threshold) is dict:\r\n        threshold = threshold['value']\r\n```"}