{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257956158", "html_url": "https://github.com/tensorflow/tensorflow/issues/5350#issuecomment-257956158", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5350", "id": 257956158, "node_id": "MDEyOklzc3VlQ29tbWVudDI1Nzk1NjE1OA==", "user": {"login": "DavidNemeskey", "id": 690386, "node_id": "MDQ6VXNlcjY5MDM4Ng==", "avatar_url": "https://avatars3.githubusercontent.com/u/690386?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DavidNemeskey", "html_url": "https://github.com/DavidNemeskey", "followers_url": "https://api.github.com/users/DavidNemeskey/followers", "following_url": "https://api.github.com/users/DavidNemeskey/following{/other_user}", "gists_url": "https://api.github.com/users/DavidNemeskey/gists{/gist_id}", "starred_url": "https://api.github.com/users/DavidNemeskey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DavidNemeskey/subscriptions", "organizations_url": "https://api.github.com/users/DavidNemeskey/orgs", "repos_url": "https://api.github.com/users/DavidNemeskey/repos", "events_url": "https://api.github.com/users/DavidNemeskey/events{/privacy}", "received_events_url": "https://api.github.com/users/DavidNemeskey/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-02T18:26:33Z", "updated_at": "2016-11-02T18:26:33Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a> I think out of the two, softmax has the \"logical\" dimensions, not the sampled functions. I preferred a new version / <code>transposed</code> parameter to the sampled functions to changing the softmax signature.</p>\n<p>I also had a quick look at the code, and I am wondering if the problem might be that <code>embedding_lookup</code> is not able to perform a lookup on other than the first axis? I am not familiar with its implementation, but at least numpy can index along any of the axes, so it shouldn't be difficult to fix that.</p>", "body_text": "@aselle I think out of the two, softmax has the \"logical\" dimensions, not the sampled functions. I preferred a new version / transposed parameter to the sampled functions to changing the softmax signature.\nI also had a quick look at the code, and I am wondering if the problem might be that embedding_lookup is not able to perform a lookup on other than the first axis? I am not familiar with its implementation, but at least numpy can index along any of the axes, so it shouldn't be difficult to fix that.", "body": "@aselle I think out of the two, softmax has the \"logical\" dimensions, not the sampled functions. I preferred a new version / `transposed` parameter to the sampled functions to changing the softmax signature.\n\nI also had a quick look at the code, and I am wondering if the problem might be that `embedding_lookup` is not able to perform a lookup on other than the first axis? I am not familiar with its implementation, but at least numpy can index along any of the axes, so it shouldn't be difficult to fix that.\n"}