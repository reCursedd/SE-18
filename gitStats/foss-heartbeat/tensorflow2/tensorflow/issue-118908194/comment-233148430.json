{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/233148430", "html_url": "https://github.com/tensorflow/tensorflow/issues/352#issuecomment-233148430", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/352", "id": 233148430, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMzE0ODQzMA==", "user": {"login": "jiapei100", "id": 154013, "node_id": "MDQ6VXNlcjE1NDAxMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/154013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiapei100", "html_url": "https://github.com/jiapei100", "followers_url": "https://api.github.com/users/jiapei100/followers", "following_url": "https://api.github.com/users/jiapei100/following{/other_user}", "gists_url": "https://api.github.com/users/jiapei100/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiapei100/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiapei100/subscriptions", "organizations_url": "https://api.github.com/users/jiapei100/orgs", "repos_url": "https://api.github.com/users/jiapei100/repos", "events_url": "https://api.github.com/users/jiapei100/events{/privacy}", "received_events_url": "https://api.github.com/users/jiapei100/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-16T20:04:15Z", "updated_at": "2016-07-16T20:04:44Z", "author_association": "NONE", "body_html": "<p>In my case, the same, and I doubt if this Raising pool_size_limit_ will have effects on generator() ? My gosh....</p>\n<blockquote>\n<p>jiapei:peijia$ python train.py<br>\nUsing TensorFlow backend.<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.0.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally<br>\nLoading folder c0...<br>\nLoading folder c1...<br>\nReading training images...<br>\n/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint8<br>\n\"%s to %s\" % (dtypeobj_in, dtypeobj))<br>\nFold 1/(811,)<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: GeForce GTX 980M<br>\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.1265<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 3.93GiB<br>\nFree memory: 3.50GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0)<br>\nWriting model architecture...<br>\nStarting Training...<br>\nfit...<br>\nTrain on 1619 samples, validate on 811 samples<br>\nEpoch 1/32<br>\n1024/1619 [=================&gt;............] - ETA: 12s - loss: 0.8683 - acc: 0.8066I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3897 get requests, put_count=3885 evicted_count=1000 eviction_rate=0.2574 and unsatisfied allocation rate=0.285348<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110</p>\n</blockquote>", "body_text": "In my case, the same, and I doubt if this Raising pool_size_limit_ will have effects on generator() ? My gosh....\n\njiapei:peijia$ python train.py\nUsing TensorFlow backend.\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.0.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally\nLoading folder c0...\nLoading folder c1...\nReading training images...\n/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint8\n\"%s to %s\" % (dtypeobj_in, dtypeobj))\nFold 1/(811,)\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 980M\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.1265\npciBusID 0000:01:00.0\nTotal memory: 3.93GiB\nFree memory: 3.50GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0)\nWriting model architecture...\nStarting Training...\nfit...\nTrain on 1619 samples, validate on 811 samples\nEpoch 1/32\n1024/1619 [=================>............] - ETA: 12s - loss: 0.8683 - acc: 0.8066I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3897 get requests, put_count=3885 evicted_count=1000 eviction_rate=0.2574 and unsatisfied allocation rate=0.285348\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110", "body": "In my case, the same, and I doubt if this Raising pool_size_limit_ will have effects on generator() ? My gosh....\n\n> jiapei:peijia$ python train.py \n> Using TensorFlow backend.\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.0.5 locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally\n> Loading folder c0...\n> Loading folder c1...\n> Reading training images...\n> /usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint8\n>   \"%s to %s\" % (dtypeobj_in, dtypeobj))\n> Fold 1/(811,)\n> I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \n> name: GeForce GTX 980M\n> major: 5 minor: 2 memoryClockRate (GHz) 1.1265\n> pciBusID 0000:01:00.0\n> Total memory: 3.93GiB\n> Free memory: 3.50GiB\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0)\n> Writing model architecture...\n> Starting Training...\n> fit...\n> Train on 1619 samples, validate on 811 samples\n> Epoch 1/32\n> 1024/1619 [=================>............] - ETA: 12s - loss: 0.8683 - acc: 0.8066I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3897 get requests, put_count=3885 evicted_count=1000 eviction_rate=0.2574 and unsatisfied allocation rate=0.285348\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110\n"}