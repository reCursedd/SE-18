{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/321778791", "html_url": "https://github.com/tensorflow/tensorflow/issues/11367#issuecomment-321778791", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11367", "id": 321778791, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMTc3ODc5MQ==", "user": {"login": "nosqlcoco", "id": 3488475, "node_id": "MDQ6VXNlcjM0ODg0NzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3488475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nosqlcoco", "html_url": "https://github.com/nosqlcoco", "followers_url": "https://api.github.com/users/nosqlcoco/followers", "following_url": "https://api.github.com/users/nosqlcoco/following{/other_user}", "gists_url": "https://api.github.com/users/nosqlcoco/gists{/gist_id}", "starred_url": "https://api.github.com/users/nosqlcoco/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nosqlcoco/subscriptions", "organizations_url": "https://api.github.com/users/nosqlcoco/orgs", "repos_url": "https://api.github.com/users/nosqlcoco/repos", "events_url": "https://api.github.com/users/nosqlcoco/events{/privacy}", "received_events_url": "https://api.github.com/users/nosqlcoco/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-11T10:27:23Z", "updated_at": "2017-08-11T10:27:23Z", "author_association": "NONE", "body_html": "<p>I got the same error when i use this code <code>summary,test_accuracy = sess.run([merged, accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})</code></p>\n<p>Info</p>\n<ul>\n<li>OS: Ubuntu 16.04LTS</li>\n<li>TF version : Release 1.2.1</li>\n<li>Python: 3.5.3</li>\n</ul>\n<p>Source code &amp; error log</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib import rnn\nimport numpy as np\nimport random\n\n#==========\n# Data Set\n#==========\nclass HandriseData(object):\n    \"\"\"\n    Load train-set and test-set from csv file\n    \"\"\"\n    def __init__(self):\n        self.data = []\n        self.labels = []\n        self.seq_len = []\n\n        self.test_data = []\n        self.test_labels = []\n        self.test_seq_len = []\n        \n        with open(\"./dataset/train/train.csv\", 'r', newline=\"\") as csv_file:\n            train_sets = [np.array(line.split(\",\"), np.float).tolist() for line in csv_file]\n\n            for i in range(0, len(train_sets), 3):\n                tmp_len = len(train_sets[i])\n                self.seq_len.append(tmp_len)\n\n                train_sets[i].extend([0 for j in range(0, 80 - tmp_len)])\n                train_sets[i + 1].extend([0 for j in range(0, 80 - tmp_len)])\n                train_sets[i + 2].extend([0 for j in range(0, 80 - tmp_len)])\n                self.data.append(np.array(train_sets[i : i + 3]).flatten())\n                \n            self.labels = np.loadtxt(\"./dataset/train/train.label.csv\", dtype = np.int).tolist()\n\n    def next(self, batch_size = 100):\n        \"\"\"\n        input: batch_size\n        output: (x_batch, y_batch, seq_len)\n        \"\"\"\n        if batch_size &lt;= 0:\n            return;\n        \n        x_batch = []\n        y_batch = []\n        #real length\n        seq_len = []\n        \n        rand_list = random.sample(range(0, len(self.data)), batch_size)\n        for j in rand_list:\n            x_batch.append(self.data[j])\n            y_batch.append(self.labels[j])\n            seq_len.append(self.seq_len[j])\n            \n        return (x_batch, y_batch, seq_len)\n    \n    def get_test_set(self):\n        \"\"\"\n        Get test set\n        \"\"\"\n        with open(\"./dataset/test/test.csv\", 'r', newline=\"\") as csv_file:\n            test_sets = [np.array(line.split(\",\"), np.float).tolist() for line in csv_file]\n\n            for i in range(0, len(test_sets), 3):\n                tmp_len = len(test_sets[i])\n                self.test_seq_len.append(tmp_len)\n\n                test_sets[i].extend([0 for j in range(0, 80 - tmp_len)])\n                test_sets[i + 1].extend([0 for j in range(0, 80 - tmp_len)])\n                test_sets[i + 2].extend([0 for j in range(0, 80 - tmp_len)])\n                self.test_data.append(np.array(test_sets[i : i + 3]).flatten())\n                \n            self.test_labels = np.loadtxt(\"./dataset/test/test.label.csv\", dtype = np.int).tolist()\n        return (self.test_data, self.test_labels, self.test_seq_len)\n#==========\n# MODEL\n#==========\n\n#Parameter\ntraining_iters = 1001\nbatch_size = 100\nlearning_rate = 0.01\n\nn_steps = 80 #max steps\nn_input = 3 #input\nn_hidden_unis = 128 #hidden neurons\nn_class = 2 #label (0,1)\n\n\n#Graph input\nx = tf.placeholder(tf.float32, [None, n_steps, n_input], name=\"x_input\") #input \ny = tf.placeholder(tf.int32, [None], name=\"y_label\") #real label\ny_ = tf.one_hot(y, 2) #one hot vector\ninput_seq_len = tf.placeholder(tf.int32, [None], name=\"input_seq_len\")\nkeep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n\n#define weight\nweights = {\n    #(n_input,n_hidden_unis)\n    'in': tf.Variable(tf.random_normal([n_input, n_hidden_unis],stddev=0.1)),\n    #(n_hidden_unis,n_class)\n    'out': tf.Variable(tf.random_normal([n_hidden_unis, n_class],stddev=0.1))\n}\n#define bias\nbiases = {\n    #(n_hidden_unis, )\n    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_unis, ])),\n    #(n_class, )\n    'out': tf.Variable(tf.constant(0.1, shape=[n_class, ]))\n}\n\n#Define RNN(LSTM) neuron networks\ndef LSTM_RNN(x, weights, biases, seq_len, keep_prob = 1, activation_function = tf.nn.softmax):\n    #hidden layer for input to cell\n    #==&gt; (batch_size * n_steps, n_input)\n    x = tf.reshape(x, [-1, n_input])\n    #==&gt;(batch_size * n_steps, n_hidden_unis)\n    x_in = tf.matmul(x, weights['in']) + biases['in']\n    #==&gt;(batch_size, n_steps, n_hidden_unis)\n    x_in = tf.reshape(x_in, [-1, n_steps, n_hidden_unis])\n\n    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_unis, forget_bias=1.0, state_is_tuple=True, reuse=True)\n    _init_state = lstm_cell.zero_state(batch_size, dtype = tf.float32)\n\n    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x_in, time_major=False, sequence_length=seq_len, dtype=tf.float32)\n\n    Wx_plus_b = tf.matmul(states[1], weights['out'] + biases['out'])\n    \n    output = activation_function(Wx_plus_b)\n    \n    output = tf.nn.dropout(output, keep_prob)\n    return output\n\n#==========\n# TRAIN\n#==========\ndef train():\n    pred = LSTM_RNN(x, weights, biases, input_seq_len, keep_prob, tf.nn.softmax)\n    tf.summary.histogram('out',pred)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_))\n    tf.summary.scalar('loss', cost) \n    \n    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n    \n    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y_,1))\n    pred_output = tf.cast(correct_pred, tf.int32, name=\"pred_output\")\n    \n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    \n    merged = tf.summary.merge_all()\n    init = tf.global_variables_initializer()\n    \n    saver = tf.train.Saver(max_to_keep=5)\n    with tf.Session() as sess:\n\n        file_writer = tf.summary.FileWriter('./tensorboard', sess.graph)\n        \n        sess.run(init)\n        train_accuracys = []\n        test_accuracys = []\n        \n        hand_rise = HandriseData()\n       \n        test_data, test_labels, test_seq_len = hand_rise.get_test_set()\n        test_data = np.array(test_data).reshape([-1, n_steps, n_input])\n        \n        for step in range(1, training_iters):\n            x_batch, y_batch, seq_len = hand_rise.next(batch_size)\n            x_batch = np.array(x_batch).reshape([-1, n_steps, n_input])\n            \n            if step % 100 == 0:\n                train_accuracy = sess.run(accuracy, feed_dict={x: x_batch, y: y_batch, input_seq_len: seq_len, keep_prob: 1})\n                train_accuracys.append(train_accuracy)\n                \n                summary,test_accuracy = sess.run([merged,accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\n                test_accuracys.append(test_accuracy)\n                \n                file_writer.add_summary(summary, step)\n                \n                print(\"step:\" + str(step) + \",accuracy:\" + str(train_accuracy))\n                \n            else:\n                sess.run(train_op, feed_dict={x: x_batch, y: y_batch, input_seq_len: seq_len, keep_prob: 0.5})\n                \n        file_writer.close()       \n        print(\"Final test accuracy is \" + str(test_accuracys[-1]))\n        \n        #save checkpoint file\n        saver.save(sess, 'model/model.ckpt', global_step=step)\n        #save pb file\n        output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['pred_output'])\n        with tf.gfile.FastGFile(\"model/handrise.pb\", mode = 'wb') as f:\n            f.write(output_graph_def.SerializeToString())\n</code></pre>\n<p>error</p>\n<pre><code>---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1138     try:\n-&gt; 1139       return fn(*args)\n   1140     except errors.OpError as e:\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n   1120                                  feed_dict, fetch_list, target_list,\n-&gt; 1121                                  status, run_metadata)\n   1122 \n\n/home/ksq/anaconda3/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)\n     65             try:\n---&gt; 66                 next(self.gen)\n     67             except StopIteration:\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--&gt; 466           pywrap_tensorflow.TF_GetCode(status))\n    467   finally:\n\nInvalidArgumentError: Shape [-1,80,3] has negative dimensions\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n&lt;ipython-input-7-a64368429fdf&gt; in &lt;module&gt;()\n    223     plt.show()\n    224 \n--&gt; 225 train()\n\n&lt;ipython-input-7-a64368429fdf&gt; in train()\n    186                 train_accuracys.append(train_accuracy)\n    187 \n--&gt; 188                 summary,test_accuracy = sess.run([merged,accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\n    189                 test_accuracys.append(test_accuracy)\n    190 \n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    787     try:\n    788       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 789                          run_metadata_ptr)\n    790       if run_metadata:\n    791         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    995     if final_fetches or final_targets:\n    996       results = self._do_run(handle, final_targets, final_fetches,\n--&gt; 997                              feed_dict_string, options, run_metadata)\n    998     else:\n    999       results = []\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1130     if handle is None:\n   1131       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n-&gt; 1132                            target_list, options, run_metadata)\n   1133     else:\n   1134       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1150         except KeyError:\n   1151           pass\n-&gt; 1152       raise type(e)(node_def, op, message)\n   1153 \n   1154   def _extend_graph(self):\n\nInvalidArgumentError: Shape [-1,80,3] has negative dimensions\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'x_input_1', defined at:\n  File \"/home/ksq/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ksq/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in &lt;module&gt;\n    app.launch_new_instance()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;ipython-input-2-55a42d5b2ae9&gt;\", line 104, in &lt;module&gt;\n    x = tf.placeholder(tf.float32, [None, n_steps, n_input], name=\"x_input\") #input\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,80,3] has negative dimensions\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\n</code></pre>", "body_text": "I got the same error when i use this code summary,test_accuracy = sess.run([merged, accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\nInfo\n\nOS: Ubuntu 16.04LTS\nTF version : Release 1.2.1\nPython: 3.5.3\n\nSource code & error log\nimport tensorflow as tf\nfrom tensorflow.contrib import rnn\nimport numpy as np\nimport random\n\n#==========\n# Data Set\n#==========\nclass HandriseData(object):\n    \"\"\"\n    Load train-set and test-set from csv file\n    \"\"\"\n    def __init__(self):\n        self.data = []\n        self.labels = []\n        self.seq_len = []\n\n        self.test_data = []\n        self.test_labels = []\n        self.test_seq_len = []\n        \n        with open(\"./dataset/train/train.csv\", 'r', newline=\"\") as csv_file:\n            train_sets = [np.array(line.split(\",\"), np.float).tolist() for line in csv_file]\n\n            for i in range(0, len(train_sets), 3):\n                tmp_len = len(train_sets[i])\n                self.seq_len.append(tmp_len)\n\n                train_sets[i].extend([0 for j in range(0, 80 - tmp_len)])\n                train_sets[i + 1].extend([0 for j in range(0, 80 - tmp_len)])\n                train_sets[i + 2].extend([0 for j in range(0, 80 - tmp_len)])\n                self.data.append(np.array(train_sets[i : i + 3]).flatten())\n                \n            self.labels = np.loadtxt(\"./dataset/train/train.label.csv\", dtype = np.int).tolist()\n\n    def next(self, batch_size = 100):\n        \"\"\"\n        input: batch_size\n        output: (x_batch, y_batch, seq_len)\n        \"\"\"\n        if batch_size <= 0:\n            return;\n        \n        x_batch = []\n        y_batch = []\n        #real length\n        seq_len = []\n        \n        rand_list = random.sample(range(0, len(self.data)), batch_size)\n        for j in rand_list:\n            x_batch.append(self.data[j])\n            y_batch.append(self.labels[j])\n            seq_len.append(self.seq_len[j])\n            \n        return (x_batch, y_batch, seq_len)\n    \n    def get_test_set(self):\n        \"\"\"\n        Get test set\n        \"\"\"\n        with open(\"./dataset/test/test.csv\", 'r', newline=\"\") as csv_file:\n            test_sets = [np.array(line.split(\",\"), np.float).tolist() for line in csv_file]\n\n            for i in range(0, len(test_sets), 3):\n                tmp_len = len(test_sets[i])\n                self.test_seq_len.append(tmp_len)\n\n                test_sets[i].extend([0 for j in range(0, 80 - tmp_len)])\n                test_sets[i + 1].extend([0 for j in range(0, 80 - tmp_len)])\n                test_sets[i + 2].extend([0 for j in range(0, 80 - tmp_len)])\n                self.test_data.append(np.array(test_sets[i : i + 3]).flatten())\n                \n            self.test_labels = np.loadtxt(\"./dataset/test/test.label.csv\", dtype = np.int).tolist()\n        return (self.test_data, self.test_labels, self.test_seq_len)\n#==========\n# MODEL\n#==========\n\n#Parameter\ntraining_iters = 1001\nbatch_size = 100\nlearning_rate = 0.01\n\nn_steps = 80 #max steps\nn_input = 3 #input\nn_hidden_unis = 128 #hidden neurons\nn_class = 2 #label (0,1)\n\n\n#Graph input\nx = tf.placeholder(tf.float32, [None, n_steps, n_input], name=\"x_input\") #input \ny = tf.placeholder(tf.int32, [None], name=\"y_label\") #real label\ny_ = tf.one_hot(y, 2) #one hot vector\ninput_seq_len = tf.placeholder(tf.int32, [None], name=\"input_seq_len\")\nkeep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n\n#define weight\nweights = {\n    #(n_input,n_hidden_unis)\n    'in': tf.Variable(tf.random_normal([n_input, n_hidden_unis],stddev=0.1)),\n    #(n_hidden_unis,n_class)\n    'out': tf.Variable(tf.random_normal([n_hidden_unis, n_class],stddev=0.1))\n}\n#define bias\nbiases = {\n    #(n_hidden_unis, )\n    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_unis, ])),\n    #(n_class, )\n    'out': tf.Variable(tf.constant(0.1, shape=[n_class, ]))\n}\n\n#Define RNN(LSTM) neuron networks\ndef LSTM_RNN(x, weights, biases, seq_len, keep_prob = 1, activation_function = tf.nn.softmax):\n    #hidden layer for input to cell\n    #==> (batch_size * n_steps, n_input)\n    x = tf.reshape(x, [-1, n_input])\n    #==>(batch_size * n_steps, n_hidden_unis)\n    x_in = tf.matmul(x, weights['in']) + biases['in']\n    #==>(batch_size, n_steps, n_hidden_unis)\n    x_in = tf.reshape(x_in, [-1, n_steps, n_hidden_unis])\n\n    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_unis, forget_bias=1.0, state_is_tuple=True, reuse=True)\n    _init_state = lstm_cell.zero_state(batch_size, dtype = tf.float32)\n\n    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x_in, time_major=False, sequence_length=seq_len, dtype=tf.float32)\n\n    Wx_plus_b = tf.matmul(states[1], weights['out'] + biases['out'])\n    \n    output = activation_function(Wx_plus_b)\n    \n    output = tf.nn.dropout(output, keep_prob)\n    return output\n\n#==========\n# TRAIN\n#==========\ndef train():\n    pred = LSTM_RNN(x, weights, biases, input_seq_len, keep_prob, tf.nn.softmax)\n    tf.summary.histogram('out',pred)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_))\n    tf.summary.scalar('loss', cost) \n    \n    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n    \n    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y_,1))\n    pred_output = tf.cast(correct_pred, tf.int32, name=\"pred_output\")\n    \n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    \n    merged = tf.summary.merge_all()\n    init = tf.global_variables_initializer()\n    \n    saver = tf.train.Saver(max_to_keep=5)\n    with tf.Session() as sess:\n\n        file_writer = tf.summary.FileWriter('./tensorboard', sess.graph)\n        \n        sess.run(init)\n        train_accuracys = []\n        test_accuracys = []\n        \n        hand_rise = HandriseData()\n       \n        test_data, test_labels, test_seq_len = hand_rise.get_test_set()\n        test_data = np.array(test_data).reshape([-1, n_steps, n_input])\n        \n        for step in range(1, training_iters):\n            x_batch, y_batch, seq_len = hand_rise.next(batch_size)\n            x_batch = np.array(x_batch).reshape([-1, n_steps, n_input])\n            \n            if step % 100 == 0:\n                train_accuracy = sess.run(accuracy, feed_dict={x: x_batch, y: y_batch, input_seq_len: seq_len, keep_prob: 1})\n                train_accuracys.append(train_accuracy)\n                \n                summary,test_accuracy = sess.run([merged,accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\n                test_accuracys.append(test_accuracy)\n                \n                file_writer.add_summary(summary, step)\n                \n                print(\"step:\" + str(step) + \",accuracy:\" + str(train_accuracy))\n                \n            else:\n                sess.run(train_op, feed_dict={x: x_batch, y: y_batch, input_seq_len: seq_len, keep_prob: 0.5})\n                \n        file_writer.close()       \n        print(\"Final test accuracy is \" + str(test_accuracys[-1]))\n        \n        #save checkpoint file\n        saver.save(sess, 'model/model.ckpt', global_step=step)\n        #save pb file\n        output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['pred_output'])\n        with tf.gfile.FastGFile(\"model/handrise.pb\", mode = 'wb') as f:\n            f.write(output_graph_def.SerializeToString())\n\nerror\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1138     try:\n-> 1139       return fn(*args)\n   1140     except errors.OpError as e:\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n   1120                                  feed_dict, fetch_list, target_list,\n-> 1121                                  status, run_metadata)\n   1122 \n\n/home/ksq/anaconda3/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)\n     65             try:\n---> 66                 next(self.gen)\n     67             except StopIteration:\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 466           pywrap_tensorflow.TF_GetCode(status))\n    467   finally:\n\nInvalidArgumentError: Shape [-1,80,3] has negative dimensions\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-7-a64368429fdf> in <module>()\n    223     plt.show()\n    224 \n--> 225 train()\n\n<ipython-input-7-a64368429fdf> in train()\n    186                 train_accuracys.append(train_accuracy)\n    187 \n--> 188                 summary,test_accuracy = sess.run([merged,accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\n    189                 test_accuracys.append(test_accuracy)\n    190 \n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    787     try:\n    788       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 789                          run_metadata_ptr)\n    790       if run_metadata:\n    791         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    995     if final_fetches or final_targets:\n    996       results = self._do_run(handle, final_targets, final_fetches,\n--> 997                              feed_dict_string, options, run_metadata)\n    998     else:\n    999       results = []\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1130     if handle is None:\n   1131       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n-> 1132                            target_list, options, run_metadata)\n   1133     else:\n   1134       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1150         except KeyError:\n   1151           pass\n-> 1152       raise type(e)(node_def, op, message)\n   1153 \n   1154   def _extend_graph(self):\n\nInvalidArgumentError: Shape [-1,80,3] has negative dimensions\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'x_input_1', defined at:\n  File \"/home/ksq/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ksq/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-55a42d5b2ae9>\", line 104, in <module>\n    x = tf.placeholder(tf.float32, [None, n_steps, n_input], name=\"x_input\") #input\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,80,3] has negative dimensions\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]", "body": "I got the same error when i use this code `summary,test_accuracy = sess.run([merged, accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})`\r\n\r\n Info\r\n- OS: Ubuntu 16.04LTS\r\n- TF version : Release 1.2.1 \r\n- Python: 3.5.3\r\n\r\nSource code & error log\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import rnn\r\nimport numpy as np\r\nimport random\r\n\r\n#==========\r\n# Data Set\r\n#==========\r\nclass HandriseData(object):\r\n    \"\"\"\r\n    Load train-set and test-set from csv file\r\n    \"\"\"\r\n    def __init__(self):\r\n        self.data = []\r\n        self.labels = []\r\n        self.seq_len = []\r\n\r\n        self.test_data = []\r\n        self.test_labels = []\r\n        self.test_seq_len = []\r\n        \r\n        with open(\"./dataset/train/train.csv\", 'r', newline=\"\") as csv_file:\r\n            train_sets = [np.array(line.split(\",\"), np.float).tolist() for line in csv_file]\r\n\r\n            for i in range(0, len(train_sets), 3):\r\n                tmp_len = len(train_sets[i])\r\n                self.seq_len.append(tmp_len)\r\n\r\n                train_sets[i].extend([0 for j in range(0, 80 - tmp_len)])\r\n                train_sets[i + 1].extend([0 for j in range(0, 80 - tmp_len)])\r\n                train_sets[i + 2].extend([0 for j in range(0, 80 - tmp_len)])\r\n                self.data.append(np.array(train_sets[i : i + 3]).flatten())\r\n                \r\n            self.labels = np.loadtxt(\"./dataset/train/train.label.csv\", dtype = np.int).tolist()\r\n\r\n    def next(self, batch_size = 100):\r\n        \"\"\"\r\n        input: batch_size\r\n        output: (x_batch, y_batch, seq_len)\r\n        \"\"\"\r\n        if batch_size <= 0:\r\n            return;\r\n        \r\n        x_batch = []\r\n        y_batch = []\r\n        #real length\r\n        seq_len = []\r\n        \r\n        rand_list = random.sample(range(0, len(self.data)), batch_size)\r\n        for j in rand_list:\r\n            x_batch.append(self.data[j])\r\n            y_batch.append(self.labels[j])\r\n            seq_len.append(self.seq_len[j])\r\n            \r\n        return (x_batch, y_batch, seq_len)\r\n    \r\n    def get_test_set(self):\r\n        \"\"\"\r\n        Get test set\r\n        \"\"\"\r\n        with open(\"./dataset/test/test.csv\", 'r', newline=\"\") as csv_file:\r\n            test_sets = [np.array(line.split(\",\"), np.float).tolist() for line in csv_file]\r\n\r\n            for i in range(0, len(test_sets), 3):\r\n                tmp_len = len(test_sets[i])\r\n                self.test_seq_len.append(tmp_len)\r\n\r\n                test_sets[i].extend([0 for j in range(0, 80 - tmp_len)])\r\n                test_sets[i + 1].extend([0 for j in range(0, 80 - tmp_len)])\r\n                test_sets[i + 2].extend([0 for j in range(0, 80 - tmp_len)])\r\n                self.test_data.append(np.array(test_sets[i : i + 3]).flatten())\r\n                \r\n            self.test_labels = np.loadtxt(\"./dataset/test/test.label.csv\", dtype = np.int).tolist()\r\n        return (self.test_data, self.test_labels, self.test_seq_len)\r\n#==========\r\n# MODEL\r\n#==========\r\n\r\n#Parameter\r\ntraining_iters = 1001\r\nbatch_size = 100\r\nlearning_rate = 0.01\r\n\r\nn_steps = 80 #max steps\r\nn_input = 3 #input\r\nn_hidden_unis = 128 #hidden neurons\r\nn_class = 2 #label (0,1)\r\n\r\n\r\n#Graph input\r\nx = tf.placeholder(tf.float32, [None, n_steps, n_input], name=\"x_input\") #input \r\ny = tf.placeholder(tf.int32, [None], name=\"y_label\") #real label\r\ny_ = tf.one_hot(y, 2) #one hot vector\r\ninput_seq_len = tf.placeholder(tf.int32, [None], name=\"input_seq_len\")\r\nkeep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\r\n\r\n#define weight\r\nweights = {\r\n    #(n_input,n_hidden_unis)\r\n    'in': tf.Variable(tf.random_normal([n_input, n_hidden_unis],stddev=0.1)),\r\n    #(n_hidden_unis,n_class)\r\n    'out': tf.Variable(tf.random_normal([n_hidden_unis, n_class],stddev=0.1))\r\n}\r\n#define bias\r\nbiases = {\r\n    #(n_hidden_unis, )\r\n    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_unis, ])),\r\n    #(n_class, )\r\n    'out': tf.Variable(tf.constant(0.1, shape=[n_class, ]))\r\n}\r\n\r\n#Define RNN(LSTM) neuron networks\r\ndef LSTM_RNN(x, weights, biases, seq_len, keep_prob = 1, activation_function = tf.nn.softmax):\r\n    #hidden layer for input to cell\r\n    #==> (batch_size * n_steps, n_input)\r\n    x = tf.reshape(x, [-1, n_input])\r\n    #==>(batch_size * n_steps, n_hidden_unis)\r\n    x_in = tf.matmul(x, weights['in']) + biases['in']\r\n    #==>(batch_size, n_steps, n_hidden_unis)\r\n    x_in = tf.reshape(x_in, [-1, n_steps, n_hidden_unis])\r\n\r\n    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_unis, forget_bias=1.0, state_is_tuple=True, reuse=True)\r\n    _init_state = lstm_cell.zero_state(batch_size, dtype = tf.float32)\r\n\r\n    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x_in, time_major=False, sequence_length=seq_len, dtype=tf.float32)\r\n\r\n    Wx_plus_b = tf.matmul(states[1], weights['out'] + biases['out'])\r\n    \r\n    output = activation_function(Wx_plus_b)\r\n    \r\n    output = tf.nn.dropout(output, keep_prob)\r\n    return output\r\n\r\n#==========\r\n# TRAIN\r\n#==========\r\ndef train():\r\n    pred = LSTM_RNN(x, weights, biases, input_seq_len, keep_prob, tf.nn.softmax)\r\n    tf.summary.histogram('out',pred)\r\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_))\r\n    tf.summary.scalar('loss', cost) \r\n    \r\n    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\r\n    \r\n    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y_,1))\r\n    pred_output = tf.cast(correct_pred, tf.int32, name=\"pred_output\")\r\n    \r\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r\n    \r\n    merged = tf.summary.merge_all()\r\n    init = tf.global_variables_initializer()\r\n    \r\n    saver = tf.train.Saver(max_to_keep=5)\r\n    with tf.Session() as sess:\r\n\r\n        file_writer = tf.summary.FileWriter('./tensorboard', sess.graph)\r\n        \r\n        sess.run(init)\r\n        train_accuracys = []\r\n        test_accuracys = []\r\n        \r\n        hand_rise = HandriseData()\r\n       \r\n        test_data, test_labels, test_seq_len = hand_rise.get_test_set()\r\n        test_data = np.array(test_data).reshape([-1, n_steps, n_input])\r\n        \r\n        for step in range(1, training_iters):\r\n            x_batch, y_batch, seq_len = hand_rise.next(batch_size)\r\n            x_batch = np.array(x_batch).reshape([-1, n_steps, n_input])\r\n            \r\n            if step % 100 == 0:\r\n                train_accuracy = sess.run(accuracy, feed_dict={x: x_batch, y: y_batch, input_seq_len: seq_len, keep_prob: 1})\r\n                train_accuracys.append(train_accuracy)\r\n                \r\n                summary,test_accuracy = sess.run([merged,accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\r\n                test_accuracys.append(test_accuracy)\r\n                \r\n                file_writer.add_summary(summary, step)\r\n                \r\n                print(\"step:\" + str(step) + \",accuracy:\" + str(train_accuracy))\r\n                \r\n            else:\r\n                sess.run(train_op, feed_dict={x: x_batch, y: y_batch, input_seq_len: seq_len, keep_prob: 0.5})\r\n                \r\n        file_writer.close()       \r\n        print(\"Final test accuracy is \" + str(test_accuracys[-1]))\r\n        \r\n        #save checkpoint file\r\n        saver.save(sess, 'model/model.ckpt', global_step=step)\r\n        #save pb file\r\n        output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['pred_output'])\r\n        with tf.gfile.FastGFile(\"model/handrise.pb\", mode = 'wb') as f:\r\n            f.write(output_graph_def.SerializeToString())\r\n```\r\nerror\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1138     try:\r\n-> 1139       return fn(*args)\r\n   1140     except errors.OpError as e:\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1120                                  feed_dict, fetch_list, target_list,\r\n-> 1121                                  status, run_metadata)\r\n   1122 \r\n\r\n/home/ksq/anaconda3/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)\r\n     65             try:\r\n---> 66                 next(self.gen)\r\n     67             except StopIteration:\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\r\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 466           pywrap_tensorflow.TF_GetCode(status))\r\n    467   finally:\r\n\r\nInvalidArgumentError: Shape [-1,80,3] has negative dimensions\r\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-7-a64368429fdf> in <module>()\r\n    223     plt.show()\r\n    224 \r\n--> 225 train()\r\n\r\n<ipython-input-7-a64368429fdf> in train()\r\n    186                 train_accuracys.append(train_accuracy)\r\n    187 \r\n--> 188                 summary,test_accuracy = sess.run([merged,accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\r\n    189                 test_accuracys.append(test_accuracy)\r\n    190 \r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    787     try:\r\n    788       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 789                          run_metadata_ptr)\r\n    790       if run_metadata:\r\n    791         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    995     if final_fetches or final_targets:\r\n    996       results = self._do_run(handle, final_targets, final_fetches,\r\n--> 997                              feed_dict_string, options, run_metadata)\r\n    998     else:\r\n    999       results = []\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1130     if handle is None:\r\n   1131       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\r\n-> 1132                            target_list, options, run_metadata)\r\n   1133     else:\r\n   1134       return self._do_call(_prun_fn, self._session, handle, feed_dict,\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1150         except KeyError:\r\n   1151           pass\r\n-> 1152       raise type(e)(node_def, op, message)\r\n   1153 \r\n   1154   def _extend_graph(self):\r\n\r\nInvalidArgumentError: Shape [-1,80,3] has negative dimensions\r\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op 'x_input_1', defined at:\r\n  File \"/home/ksq/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\r\n    app.start()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-55a42d5b2ae9>\", line 104, in <module>\r\n    x = tf.placeholder(tf.float32, [None, n_steps, n_input], name=\"x_input\") #input\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\r\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\r\n    name=name)\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Shape [-1,80,3] has negative dimensions\r\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n```"}