{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10458", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10458/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10458/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10458/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10458", "id": 233875502, "node_id": "MDU6SXNzdWUyMzM4NzU1MDI=", "number": 10458, "title": "Transform_graph android error ", "user": {"login": "santle", "id": 20354277, "node_id": "MDQ6VXNlcjIwMzU0Mjc3", "avatar_url": "https://avatars0.githubusercontent.com/u/20354277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/santle", "html_url": "https://github.com/santle", "followers_url": "https://api.github.com/users/santle/followers", "following_url": "https://api.github.com/users/santle/following{/other_user}", "gists_url": "https://api.github.com/users/santle/gists{/gist_id}", "starred_url": "https://api.github.com/users/santle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/santle/subscriptions", "organizations_url": "https://api.github.com/users/santle/orgs", "repos_url": "https://api.github.com/users/santle/repos", "events_url": "https://api.github.com/users/santle/events{/privacy}", "received_events_url": "https://api.github.com/users/santle/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2017-06-06T12:28:08Z", "updated_at": "2018-06-08T08:51:23Z", "closed_at": "2018-01-29T22:54:51Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nOne month back I generated my custom TF model (output_graph.pb ) using Tensor Flow 1.0.1. It was working fine after optimization it using optimize_for_interface.</p>\n<p>Now I plan to reduce its size and improve execution speed, I downloaded Tensor Flow 1.2.0.  I used transform_graph as<br>\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph <br>\n--in_graph=./output_graph.pb <br>\n--out_graph=./transformed_graph.pb <br>\n--inputs='Mul' <br>\n--outputs='final_result' <br>\n--transforms='<br>\nadd_default_attributes<br>\nstrip_unused_nodes(type=float, shape=\"1,299,299,3\")<br>\nremove_nodes(op=Identity, op=CheckNumerics)<br>\nfold_constants(ignore_errors=true)<br>\nfold_batch_norms<br>\nfold_old_batch_norms<br>\nquantize_weights<br>\nquantize_nodes<br>\nstrip_unused_nodes<br>\nsort_by_execution_order'</p>\n<p>I built the APK and ran on a Lenovo Yoga 3 tablet.<br>\nIt generated a run time error:</p>\n<p>W/native  (24951): op_kernel.cc:1165 Invalid argument: computed output size would be negative<br>\nE/TensorFlowInferenceInterface(24951): Failed to run TensorFlow inference with inputs:[Mul], outputs:[final_result]<br>\n--------- beginning of crash<br>\nE/AndroidRuntime(24951): FATAL EXCEPTION: inference<br>\nE/AndroidRuntime(24951): Process: org.tensorflow.demo, PID: 24951<br>\nE/AndroidRuntime(24951): java.lang.IllegalArgumentException: computed output size would be negative<br>\nE/AndroidRuntime(24951): \t [[Node: pool_3/eightbit = QuantizedAvgPool[T=DT_QUINT8, ksize=[1, 8, 8, 1], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](mixed_10/join/eightbit, mixed_10/join/eightbit:1, mixed_10/join/eightbit:2)]]<br>\nE/AndroidRuntime(24951): \tat org.tensorflow.Session.run(Native Method)<br>\nE/AndroidRuntime(24951): \tat org.tensorflow.Session.access$100(Session.java:48)</p>\n<p>In both the cases, the Bazel version is 0.4.5<br>\nAny help to solve this?</p>", "body_text": "Hi,\nOne month back I generated my custom TF model (output_graph.pb ) using Tensor Flow 1.0.1. It was working fine after optimization it using optimize_for_interface.\nNow I plan to reduce its size and improve execution speed, I downloaded Tensor Flow 1.2.0.  I used transform_graph as\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \n--in_graph=./output_graph.pb \n--out_graph=./transformed_graph.pb \n--inputs='Mul' \n--outputs='final_result' \n--transforms='\nadd_default_attributes\nstrip_unused_nodes(type=float, shape=\"1,299,299,3\")\nremove_nodes(op=Identity, op=CheckNumerics)\nfold_constants(ignore_errors=true)\nfold_batch_norms\nfold_old_batch_norms\nquantize_weights\nquantize_nodes\nstrip_unused_nodes\nsort_by_execution_order'\nI built the APK and ran on a Lenovo Yoga 3 tablet.\nIt generated a run time error:\nW/native  (24951): op_kernel.cc:1165 Invalid argument: computed output size would be negative\nE/TensorFlowInferenceInterface(24951): Failed to run TensorFlow inference with inputs:[Mul], outputs:[final_result]\n--------- beginning of crash\nE/AndroidRuntime(24951): FATAL EXCEPTION: inference\nE/AndroidRuntime(24951): Process: org.tensorflow.demo, PID: 24951\nE/AndroidRuntime(24951): java.lang.IllegalArgumentException: computed output size would be negative\nE/AndroidRuntime(24951): \t [[Node: pool_3/eightbit = QuantizedAvgPool[T=DT_QUINT8, ksize=[1, 8, 8, 1], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](mixed_10/join/eightbit, mixed_10/join/eightbit:1, mixed_10/join/eightbit:2)]]\nE/AndroidRuntime(24951): \tat org.tensorflow.Session.run(Native Method)\nE/AndroidRuntime(24951): \tat org.tensorflow.Session.access$100(Session.java:48)\nIn both the cases, the Bazel version is 0.4.5\nAny help to solve this?", "body": "Hi,\r\nOne month back I generated my custom TF model (output_graph.pb ) using Tensor Flow 1.0.1. It was working fine after optimization it using optimize_for_interface.\r\n\r\nNow I plan to reduce its size and improve execution speed, I downloaded Tensor Flow 1.2.0.  I used transform_graph as \r\n bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=./output_graph.pb \\\r\n--out_graph=./transformed_graph.pb \\\r\n--inputs='Mul' \\\r\n--outputs='final_result' \\\r\n--transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=float, shape=\"1,299,299,3\")\r\n  remove_nodes(op=Identity, op=CheckNumerics)\r\n  fold_constants(ignore_errors=true)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  quantize_nodes\r\n  strip_unused_nodes\r\n  sort_by_execution_order'\r\n\r\nI built the APK and ran on a Lenovo Yoga 3 tablet.\r\nIt generated a run time error:\r\n\r\nW/native  (24951): op_kernel.cc:1165 Invalid argument: computed output size would be negative\r\nE/TensorFlowInferenceInterface(24951): Failed to run TensorFlow inference with inputs:[Mul], outputs:[final_result]\r\n--------- beginning of crash\r\nE/AndroidRuntime(24951): FATAL EXCEPTION: inference\r\nE/AndroidRuntime(24951): Process: org.tensorflow.demo, PID: 24951\r\nE/AndroidRuntime(24951): java.lang.IllegalArgumentException: computed output size would be negative\r\nE/AndroidRuntime(24951): \t [[Node: pool_3/eightbit = QuantizedAvgPool[T=DT_QUINT8, ksize=[1, 8, 8, 1], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](mixed_10/join/eightbit, mixed_10/join/eightbit:1, mixed_10/join/eightbit:2)]]\r\nE/AndroidRuntime(24951): \tat org.tensorflow.Session.run(Native Method)\r\nE/AndroidRuntime(24951): \tat org.tensorflow.Session.access$100(Session.java:48)\r\n\r\nIn both the cases, the Bazel version is 0.4.5\r\nAny help to solve this? \r\n\r\n\r\n\r\n"}