{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/309655622", "html_url": "https://github.com/tensorflow/tensorflow/issues/10458#issuecomment-309655622", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10458", "id": 309655622, "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTY1NTYyMg==", "user": {"login": "santle", "id": 20354277, "node_id": "MDQ6VXNlcjIwMzU0Mjc3", "avatar_url": "https://avatars0.githubusercontent.com/u/20354277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/santle", "html_url": "https://github.com/santle", "followers_url": "https://api.github.com/users/santle/followers", "following_url": "https://api.github.com/users/santle/following{/other_user}", "gists_url": "https://api.github.com/users/santle/gists{/gist_id}", "starred_url": "https://api.github.com/users/santle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/santle/subscriptions", "organizations_url": "https://api.github.com/users/santle/orgs", "repos_url": "https://api.github.com/users/santle/repos", "events_url": "https://api.github.com/users/santle/events{/privacy}", "received_events_url": "https://api.github.com/users/santle/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-20T06:17:40Z", "updated_at": "2017-06-20T08:50:18Z", "author_association": "NONE", "body_html": "<pre><code>\"quantize_weights\"\n\"quantize_nodes\" \n</code></pre>\n<p>cause the inaccuracies. Keeping any of them cause incorrect results.<br>\nwhen I remove both of them, the results seems to be correct, but there is no performance gain in terms of size / run time.<br>\nFYI, I used a Lenovo Phab 2 android device. The general tensorflow_inception_graph model runs @ 300 MS / frame, but my custom model without quantization takes 1.5 S/ Frame. Also, without quantization, the APK size is 89 MB and with it, it is 20 MB but showing incorrect results.<br>\nAny suggestion to improve run time as well as size of my TF custom model?</p>", "body_text": "\"quantize_weights\"\n\"quantize_nodes\" \n\ncause the inaccuracies. Keeping any of them cause incorrect results.\nwhen I remove both of them, the results seems to be correct, but there is no performance gain in terms of size / run time.\nFYI, I used a Lenovo Phab 2 android device. The general tensorflow_inception_graph model runs @ 300 MS / frame, but my custom model without quantization takes 1.5 S/ Frame. Also, without quantization, the APK size is 89 MB and with it, it is 20 MB but showing incorrect results.\nAny suggestion to improve run time as well as size of my TF custom model?", "body": "    \"quantize_weights\"\r\n    \"quantize_nodes\" \r\ncause the inaccuracies. Keeping any of them cause incorrect results.\r\nwhen I remove both of them, the results seems to be correct, but there is no performance gain in terms of size / run time.\r\nFYI, I used a Lenovo Phab 2 android device. The general tensorflow_inception_graph model runs @ 300 MS / frame, but my custom model without quantization takes 1.5 S/ Frame. Also, without quantization, the APK size is 89 MB and with it, it is 20 MB but showing incorrect results.     \r\nAny suggestion to improve run time as well as size of my TF custom model? "}