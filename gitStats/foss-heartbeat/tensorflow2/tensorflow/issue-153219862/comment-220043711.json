{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/220043711", "html_url": "https://github.com/tensorflow/tensorflow/issues/2233#issuecomment-220043711", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2233", "id": 220043711, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDA0MzcxMQ==", "user": {"login": "smartcat2010", "id": 10429114, "node_id": "MDQ6VXNlcjEwNDI5MTE0", "avatar_url": "https://avatars1.githubusercontent.com/u/10429114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smartcat2010", "html_url": "https://github.com/smartcat2010", "followers_url": "https://api.github.com/users/smartcat2010/followers", "following_url": "https://api.github.com/users/smartcat2010/following{/other_user}", "gists_url": "https://api.github.com/users/smartcat2010/gists{/gist_id}", "starred_url": "https://api.github.com/users/smartcat2010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smartcat2010/subscriptions", "organizations_url": "https://api.github.com/users/smartcat2010/orgs", "repos_url": "https://api.github.com/users/smartcat2010/repos", "events_url": "https://api.github.com/users/smartcat2010/events{/privacy}", "received_events_url": "https://api.github.com/users/smartcat2010/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-18T14:28:48Z", "updated_at": "2016-05-18T14:37:49Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a><br>\nIn order to make you easier to reproduce the bug, I just take  <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py\">ptb_word_lm.py</a> as example. I added Async-Distributed tensorflow code to it.<br>\nI run it by using 1 ps-server and 2 workers, all of them on the same node:</p>\n<pre><code>CUDA_VISIBLE_DEVICES='' python ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=ps --task_index=0\npython ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=worker --task_index=0 --data_path=.\npython ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=worker --task_index=1 --data_path=.\n</code></pre>\n<p>When I set \"vocab_size\" to bigger than 83887, (83887<em>200</em>4&gt;67108864), it shows the following error(job crash by most cases, but not always crash):</p>\n<pre><code>I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223\nEpoch: 1 Learning rate: 0.000\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 67109600\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 67109600\nTraceback (most recent call last):\n  File \"./ptb_word_lm.py\", line 358, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./ptb_word_lm.py\", line 355, in main\n    run_worker(server, cluster)\n  File \"./ptb_word_lm.py\", line 335, in run_worker\n    verbose=True)\n  File \"./ptb_word_lm.py\", line 264, in run_epoch\n    m.lr : cur_lr })\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.AbortedError: Step 79814040532157923\n     [[Node: model/clip_by_global_norm/model/clip_by_global_norm/_5_S67 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device=\"/job:worker/replica:0/task:0/gpu:0\", send_device_incarnation=67222584234197827, tensor_name=\"edge_9213_model/clip_by_global_norm/model/clip_by_global_norm/_5\", tensor_type=DT_FLOAT, _device=\"/job:ps/replica:0/task:0/cpu:0\"]()]]\n</code></pre>\n<p>When I set \"vocab_size\" to less than but near to 83886, (83886<em>200</em>4&lt;67108864), it shows the warning:</p>\n<pre><code>[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108834\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n</code></pre>\n<p>In our large-scale web mining job, we need to increase the word-embedding vocabulary size to millions of words. So we have no way but to solve this problem.</p>\n<p>My code is here: (<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\">reader.py</a> is just from github and unchanged)<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/270704/ptb_word_lm.py.txt\">ptb_word_lm.py.txt</a></p>", "body_text": "@mrry\nIn order to make you easier to reproduce the bug, I just take  ptb_word_lm.py as example. I added Async-Distributed tensorflow code to it.\nI run it by using 1 ps-server and 2 workers, all of them on the same node:\nCUDA_VISIBLE_DEVICES='' python ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=ps --task_index=0\npython ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=worker --task_index=0 --data_path=.\npython ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=worker --task_index=1 --data_path=.\n\nWhen I set \"vocab_size\" to bigger than 83887, (838872004>67108864), it shows the following error(job crash by most cases, but not always crash):\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223\nEpoch: 1 Learning rate: 0.000\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 67109600\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 67109600\nTraceback (most recent call last):\n  File \"./ptb_word_lm.py\", line 358, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./ptb_word_lm.py\", line 355, in main\n    run_worker(server, cluster)\n  File \"./ptb_word_lm.py\", line 335, in run_worker\n    verbose=True)\n  File \"./ptb_word_lm.py\", line 264, in run_epoch\n    m.lr : cur_lr })\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.AbortedError: Step 79814040532157923\n     [[Node: model/clip_by_global_norm/model/clip_by_global_norm/_5_S67 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device=\"/job:worker/replica:0/task:0/gpu:0\", send_device_incarnation=67222584234197827, tensor_name=\"edge_9213_model/clip_by_global_norm/model/clip_by_global_norm/_5\", tensor_type=DT_FLOAT, _device=\"/job:ps/replica:0/task:0/cpu:0\"]()]]\n\nWhen I set \"vocab_size\" to less than but near to 83886, (838862004<67108864), it shows the warning:\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108834\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n\nIn our large-scale web mining job, we need to increase the word-embedding vocabulary size to millions of words. So we have no way but to solve this problem.\nMy code is here: (reader.py is just from github and unchanged)\nptb_word_lm.py.txt", "body": "@mrry \nIn order to make you easier to reproduce the bug, I just take  [ptb_word_lm.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py) as example. I added Async-Distributed tensorflow code to it.\nI run it by using 1 ps-server and 2 workers, all of them on the same node:\n\n```\nCUDA_VISIBLE_DEVICES='' python ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=ps --task_index=0\npython ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=worker --task_index=0 --data_path=.\npython ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=worker --task_index=1 --data_path=.\n```\n\nWhen I set \"vocab_size\" to bigger than 83887, (83887*200*4>67108864), it shows the following error(job crash by most cases, but not always crash):\n\n```\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223\nEpoch: 1 Learning rate: 0.000\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 67109600\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 67109600\nTraceback (most recent call last):\n  File \"./ptb_word_lm.py\", line 358, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./ptb_word_lm.py\", line 355, in main\n    run_worker(server, cluster)\n  File \"./ptb_word_lm.py\", line 335, in run_worker\n    verbose=True)\n  File \"./ptb_word_lm.py\", line 264, in run_epoch\n    m.lr : cur_lr })\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.AbortedError: Step 79814040532157923\n     [[Node: model/clip_by_global_norm/model/clip_by_global_norm/_5_S67 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device=\"/job:worker/replica:0/task:0/gpu:0\", send_device_incarnation=67222584234197827, tensor_name=\"edge_9213_model/clip_by_global_norm/model/clip_by_global_norm/_5\", tensor_type=DT_FLOAT, _device=\"/job:ps/replica:0/task:0/cpu:0\"]()]]\n```\n\nWhen I set \"vocab_size\" to less than but near to 83886, (83886*200*4<67108864), it shows the warning:\n\n```\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108834\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n```\n\nIn our large-scale web mining job, we need to increase the word-embedding vocabulary size to millions of words. So we have no way but to solve this problem.\n\nMy code is here: ([reader.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py) is just from github and unchanged)\n[ptb_word_lm.py.txt](https://github.com/tensorflow/tensorflow/files/270704/ptb_word_lm.py.txt)\n"}