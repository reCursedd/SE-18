{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/220209807", "html_url": "https://github.com/tensorflow/tensorflow/issues/2233#issuecomment-220209807", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2233", "id": 220209807, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDIwOTgwNw==", "user": {"login": "swlsw", "id": 10173483, "node_id": "MDQ6VXNlcjEwMTczNDgz", "avatar_url": "https://avatars1.githubusercontent.com/u/10173483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/swlsw", "html_url": "https://github.com/swlsw", "followers_url": "https://api.github.com/users/swlsw/followers", "following_url": "https://api.github.com/users/swlsw/following{/other_user}", "gists_url": "https://api.github.com/users/swlsw/gists{/gist_id}", "starred_url": "https://api.github.com/users/swlsw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/swlsw/subscriptions", "organizations_url": "https://api.github.com/users/swlsw/orgs", "repos_url": "https://api.github.com/users/swlsw/repos", "events_url": "https://api.github.com/users/swlsw/events{/privacy}", "received_events_url": "https://api.github.com/users/swlsw/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-19T02:09:30Z", "updated_at": "2016-05-19T02:09:30Z", "author_association": "NONE", "body_html": "<p>Did you solve this problem? I have similar problem with my async-distributed word2vec.(79840 vocab, 300 dim)</p>\n<pre><code>I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -&gt; {localhost:2422}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -&gt; {50.1.100.102:2432, 50.1.100.108:2432}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2422\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 95808000\n</code></pre>", "body_text": "Did you solve this problem? I have similar problem with my async-distributed word2vec.(79840 vocab, 300 dim)\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {localhost:2422}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {50.1.100.102:2432, 50.1.100.108:2432}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2422\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 95808000", "body": "Did you solve this problem? I have similar problem with my async-distributed word2vec.(79840 vocab, 300 dim)\n\n```\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {localhost:2422}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {50.1.100.102:2432, 50.1.100.108:2432}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2422\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 95808000\n```\n"}