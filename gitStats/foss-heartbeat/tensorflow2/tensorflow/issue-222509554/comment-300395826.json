{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300395826", "html_url": "https://github.com/tensorflow/tensorflow/issues/9294#issuecomment-300395826", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9294", "id": 300395826, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDM5NTgyNg==", "user": {"login": "kevinashaw", "id": 7141343, "node_id": "MDQ6VXNlcjcxNDEzNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/7141343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevinashaw", "html_url": "https://github.com/kevinashaw", "followers_url": "https://api.github.com/users/kevinashaw/followers", "following_url": "https://api.github.com/users/kevinashaw/following{/other_user}", "gists_url": "https://api.github.com/users/kevinashaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevinashaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevinashaw/subscriptions", "organizations_url": "https://api.github.com/users/kevinashaw/orgs", "repos_url": "https://api.github.com/users/kevinashaw/repos", "events_url": "https://api.github.com/users/kevinashaw/events{/privacy}", "received_events_url": "https://api.github.com/users/kevinashaw/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-10T07:12:07Z", "updated_at": "2017-05-10T07:12:07Z", "author_association": "NONE", "body_html": "<p>Following the discussion in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"226661793\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/9699\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/9699/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/9699\">#9699</a>, I've at least found a solution to the initial_state problem.  It would probably make sense to reference it in the new tutorial/documentation.   The problem with the initial_state is not that <code>zero_state</code> produces incorrect results :</p>\n<pre><code>initial_state = lstm_cells.zero_state(batch_size, tf.float32)\n</code></pre>\n<p>Its that the batch_size value is a constant.  For the training data, the size of the batch will <em>always</em> match the batch_size.  But for Testing data it usually never will.  Testing is done on a much large set, or atleast a set that has a size that varies from the batch_size.  Hence, for testing data, the <code>initial_state</code> from the test data will still have a size of <code>batch_size</code> but the test data itself will not.<br>\nThe solution is surprisingly simple, just let batch_size vary according to the data set brought in:</p>\n<pre><code>batch_size_var  = tf.shape(Xin)[0]\ninitial_state = lstm_cells.zero_state(batch_size_var, tf.float32) \n</code></pre>\n<p>Where Xin is the data input tensor.  Now <code>initial_state</code> will always match the size of the data set.</p>", "body_text": "Following the discussion in #9699, I've at least found a solution to the initial_state problem.  It would probably make sense to reference it in the new tutorial/documentation.   The problem with the initial_state is not that zero_state produces incorrect results :\ninitial_state = lstm_cells.zero_state(batch_size, tf.float32)\n\nIts that the batch_size value is a constant.  For the training data, the size of the batch will always match the batch_size.  But for Testing data it usually never will.  Testing is done on a much large set, or atleast a set that has a size that varies from the batch_size.  Hence, for testing data, the initial_state from the test data will still have a size of batch_size but the test data itself will not.\nThe solution is surprisingly simple, just let batch_size vary according to the data set brought in:\nbatch_size_var  = tf.shape(Xin)[0]\ninitial_state = lstm_cells.zero_state(batch_size_var, tf.float32) \n\nWhere Xin is the data input tensor.  Now initial_state will always match the size of the data set.", "body": "Following the discussion in #9699, I've at least found a solution to the initial_state problem.  It would probably make sense to reference it in the new tutorial/documentation.   The problem with the initial_state is not that `zero_state` produces incorrect results :\r\n```\r\ninitial_state = lstm_cells.zero_state(batch_size, tf.float32)\r\n```\r\nIts that the batch_size value is a constant.  For the training data, the size of the batch will *always* match the batch_size.  But for Testing data it usually never will.  Testing is done on a much large set, or atleast a set that has a size that varies from the batch_size.  Hence, for testing data, the `initial_state` from the test data will still have a size of `batch_size` but the test data itself will not.\r\nThe solution is surprisingly simple, just let batch_size vary according to the data set brought in:\r\n```\r\nbatch_size_var  = tf.shape(Xin)[0]\r\ninitial_state = lstm_cells.zero_state(batch_size_var, tf.float32) \r\n```\r\nWhere Xin is the data input tensor.  Now `initial_state` will always match the size of the data set."}