{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/326022681", "html_url": "https://github.com/tensorflow/tensorflow/issues/12686#issuecomment-326022681", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12686", "id": 326022681, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjAyMjY4MQ==", "user": {"login": "kbsriram", "id": 1495065, "node_id": "MDQ6VXNlcjE0OTUwNjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/1495065?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kbsriram", "html_url": "https://github.com/kbsriram", "followers_url": "https://api.github.com/users/kbsriram/followers", "following_url": "https://api.github.com/users/kbsriram/following{/other_user}", "gists_url": "https://api.github.com/users/kbsriram/gists{/gist_id}", "starred_url": "https://api.github.com/users/kbsriram/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kbsriram/subscriptions", "organizations_url": "https://api.github.com/users/kbsriram/orgs", "repos_url": "https://api.github.com/users/kbsriram/repos", "events_url": "https://api.github.com/users/kbsriram/events{/privacy}", "received_events_url": "https://api.github.com/users/kbsriram/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-30T15:14:11Z", "updated_at": "2017-08-30T15:15:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1112263\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/facaiy\">@facaiy</a> the outline of the code looks fine, one change would be to use</p>\n<div class=\"highlight highlight-source-c++\"><pre>grad_outputs-&gt;<span class=\"pl-en\">push_back</span>(NoGradient())</pre></div>\n<p>rather than <code>null</code> to indicate gradients should not be propagated.</p>\n<p>One thing you may run into is that that python has various utilities (e.g. <a href=\"https://github.com/tensorflow/tensorflow/tree/77b5f6a956c61e6ada9d4a6c61892f9bd2464fdb/tensorflow/python/framework/tensor_util.py#L695\">tensor_util.constant_value()</a>) that don't yet have equivalents available in C++. Should you find yourself writing  a long stack of utilities, one strategy might be to start with gradients that have  fewer dependencies. Some options might be functions like <a href=\"https://github.com/tensorflow/tensorflow/blob/77b5f6a956c61e6ada9d4a6c61892f9bd2464fdb/tensorflow/python/ops/math_grad.py#L450\">Erf</a> and <a href=\"https://github.com/tensorflow/tensorflow/blob/77b5f6a956c61e6ada9d4a6c61892f9bd2464fdb/tensorflow/python/ops/math_grad.py#L471\">LGamma</a> in <code>math_ops</code>. You can look at c++ implementations like <a href=\"https://github.com/tensorflow/tensorflow/blob/8624ecc9e827a40f9b514ff6b8ed925390ca79cc/tensorflow/cc/gradients/math_grad.cc#L191\">Tanh</a> to see how to structure the code and tests.</p>", "body_text": "@facaiy the outline of the code looks fine, one change would be to use\ngrad_outputs->push_back(NoGradient())\nrather than null to indicate gradients should not be propagated.\nOne thing you may run into is that that python has various utilities (e.g. tensor_util.constant_value()) that don't yet have equivalents available in C++. Should you find yourself writing  a long stack of utilities, one strategy might be to start with gradients that have  fewer dependencies. Some options might be functions like Erf and LGamma in math_ops. You can look at c++ implementations like Tanh to see how to structure the code and tests.", "body": "@facaiy the outline of the code looks fine, one change would be to use\r\n```c++\r\ngrad_outputs->push_back(NoGradient())\r\n```\r\nrather than `null` to indicate gradients should not be propagated.\r\n\r\nOne thing you may run into is that that python has various utilities (e.g. [tensor_util.constant_value()](https://github.com/tensorflow/tensorflow/tree/77b5f6a956c61e6ada9d4a6c61892f9bd2464fdb/tensorflow/python/framework/tensor_util.py#L695)) that don't yet have equivalents available in C++. Should you find yourself writing  a long stack of utilities, one strategy might be to start with gradients that have  fewer dependencies. Some options might be functions like [Erf](https://github.com/tensorflow/tensorflow/blob/77b5f6a956c61e6ada9d4a6c61892f9bd2464fdb/tensorflow/python/ops/math_grad.py#L450) and [LGamma](https://github.com/tensorflow/tensorflow/blob/77b5f6a956c61e6ada9d4a6c61892f9bd2464fdb/tensorflow/python/ops/math_grad.py#L471) in `math_ops`. You can look at c++ implementations like [Tanh](https://github.com/tensorflow/tensorflow/blob/8624ecc9e827a40f9b514ff6b8ed925390ca79cc/tensorflow/cc/gradients/math_grad.cc#L191) to see how to structure the code and tests."}