{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/341388390", "html_url": "https://github.com/tensorflow/tensorflow/issues/12686#issuecomment-341388390", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12686", "id": 341388390, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTM4ODM5MA==", "user": {"login": "pbanavara", "id": 600054, "node_id": "MDQ6VXNlcjYwMDA1NA==", "avatar_url": "https://avatars3.githubusercontent.com/u/600054?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pbanavara", "html_url": "https://github.com/pbanavara", "followers_url": "https://api.github.com/users/pbanavara/followers", "following_url": "https://api.github.com/users/pbanavara/following{/other_user}", "gists_url": "https://api.github.com/users/pbanavara/gists{/gist_id}", "starred_url": "https://api.github.com/users/pbanavara/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pbanavara/subscriptions", "organizations_url": "https://api.github.com/users/pbanavara/orgs", "repos_url": "https://api.github.com/users/pbanavara/repos", "events_url": "https://api.github.com/users/pbanavara/events{/privacy}", "received_events_url": "https://api.github.com/users/pbanavara/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-02T11:06:11Z", "updated_at": "2017-11-02T11:06:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hey guys sorry I couldn't get the test to pass. Help needed. I just copied the test from the Softmax test and made changes. This is what I have</p>\n<pre><code>TEST_F(NNGradTest, SoftmaxCrossEntropyWithLogitsGrad) {\n  TensorShape shape({5,3});\n  auto x = Placeholder(scope_, DT_FLOAT, Placeholder::Shape(shape));\n  auto l = Placeholder(scope_, DT_FLOAT, Placeholder::Shape(shape));\n  auto y = SoftmaxCrossEntropyWithLogits(scope_, x, l).backprop;\n  RunTest(x, shape, y, shape);\n}\n</code></pre>\n<p>Here are my questions:<br>\nI get a compilation error if I just use<br>\n<code>auto y = SoftmaxCrossEntropyWithLogits(scope_, x, l)</code><br>\nSo I made an educated guess to use the backprop - is this wrong ?<br>\nIs there any such thing as enabling debug flag for tests. In the log I just have a failure message.</p>\n<p>Thanks again for all your help.</p>", "body_text": "Hey guys sorry I couldn't get the test to pass. Help needed. I just copied the test from the Softmax test and made changes. This is what I have\nTEST_F(NNGradTest, SoftmaxCrossEntropyWithLogitsGrad) {\n  TensorShape shape({5,3});\n  auto x = Placeholder(scope_, DT_FLOAT, Placeholder::Shape(shape));\n  auto l = Placeholder(scope_, DT_FLOAT, Placeholder::Shape(shape));\n  auto y = SoftmaxCrossEntropyWithLogits(scope_, x, l).backprop;\n  RunTest(x, shape, y, shape);\n}\n\nHere are my questions:\nI get a compilation error if I just use\nauto y = SoftmaxCrossEntropyWithLogits(scope_, x, l)\nSo I made an educated guess to use the backprop - is this wrong ?\nIs there any such thing as enabling debug flag for tests. In the log I just have a failure message.\nThanks again for all your help.", "body": "Hey guys sorry I couldn't get the test to pass. Help needed. I just copied the test from the Softmax test and made changes. This is what I have\r\n\r\n```\r\nTEST_F(NNGradTest, SoftmaxCrossEntropyWithLogitsGrad) {\r\n  TensorShape shape({5,3});\r\n  auto x = Placeholder(scope_, DT_FLOAT, Placeholder::Shape(shape));\r\n  auto l = Placeholder(scope_, DT_FLOAT, Placeholder::Shape(shape));\r\n  auto y = SoftmaxCrossEntropyWithLogits(scope_, x, l).backprop;\r\n  RunTest(x, shape, y, shape);\r\n}\r\n```\r\nHere are my questions:\r\nI get a compilation error if I just use \r\n`auto y = SoftmaxCrossEntropyWithLogits(scope_, x, l)`\r\nSo I made an educated guess to use the backprop - is this wrong ?\r\nIs there any such thing as enabling debug flag for tests. In the log I just have a failure message. \r\n\r\nThanks again for all your help."}