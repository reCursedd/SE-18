{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/196035486", "html_url": "https://github.com/tensorflow/tensorflow/issues/445#issuecomment-196035486", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/445", "id": 196035486, "node_id": "MDEyOklzc3VlQ29tbWVudDE5NjAzNTQ4Ng==", "user": {"login": "samjabrahams", "id": 11607205, "node_id": "MDQ6VXNlcjExNjA3MjA1", "avatar_url": "https://avatars0.githubusercontent.com/u/11607205?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samjabrahams", "html_url": "https://github.com/samjabrahams", "followers_url": "https://api.github.com/users/samjabrahams/followers", "following_url": "https://api.github.com/users/samjabrahams/following{/other_user}", "gists_url": "https://api.github.com/users/samjabrahams/gists{/gist_id}", "starred_url": "https://api.github.com/users/samjabrahams/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samjabrahams/subscriptions", "organizations_url": "https://api.github.com/users/samjabrahams/orgs", "repos_url": "https://api.github.com/users/samjabrahams/repos", "events_url": "https://api.github.com/users/samjabrahams/events{/privacy}", "received_events_url": "https://api.github.com/users/samjabrahams/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-13T19:45:37Z", "updated_at": "2016-03-13T21:23:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Excellent! I was hoping to try out the process on a Pi 2 as well. Couple responses and additional notes</p>\n<ul>\n<li>The GPUBFCAllocator compiling issues are most likely due to changes made in <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/ab6ffc92992f12456d2378f872be17f0ed274083/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/ab6ffc92992f12456d2378f872be17f0ed274083\"><tt>ab6ffc9</tt></a>. On my first go-through (on Friday, just before I pulled in that commit), Bazel didn't complain. The next day (after that commit), I started going through the process again on another Pi to make sure I had it documented properly, but I got errors at gpu_bfc_allocator.cc (probably the same as what you saw).</li>\n<li><del>I think the clock_gettime() linking problem will be a recurring theme- running the MNIST example gives completely inaccurate time-to-train values now.</del> On second glance, things appear to be working correctly for the MNIST training. Disregard this bullet!</li>\n<li>I don't have a good idea of how fast the Pi should be running these models- let me know if you see improvements with NEON!</li>\n<li>I have been able to compile the distributed runtime, so I'm hoping to play with inter-device communication between Pis and a Mac today.</li>\n</ul>", "body_text": "Excellent! I was hoping to try out the process on a Pi 2 as well. Couple responses and additional notes\n\nThe GPUBFCAllocator compiling issues are most likely due to changes made in ab6ffc9. On my first go-through (on Friday, just before I pulled in that commit), Bazel didn't complain. The next day (after that commit), I started going through the process again on another Pi to make sure I had it documented properly, but I got errors at gpu_bfc_allocator.cc (probably the same as what you saw).\nI think the clock_gettime() linking problem will be a recurring theme- running the MNIST example gives completely inaccurate time-to-train values now. On second glance, things appear to be working correctly for the MNIST training. Disregard this bullet!\nI don't have a good idea of how fast the Pi should be running these models- let me know if you see improvements with NEON!\nI have been able to compile the distributed runtime, so I'm hoping to play with inter-device communication between Pis and a Mac today.", "body": "Excellent! I was hoping to try out the process on a Pi 2 as well. Couple responses and additional notes\n- The GPUBFCAllocator compiling issues are most likely due to changes made in ab6ffc92992f124. On my first go-through (on Friday, just before I pulled in that commit), Bazel didn't complain. The next day (after that commit), I started going through the process again on another Pi to make sure I had it documented properly, but I got errors at gpu_bfc_allocator.cc (probably the same as what you saw). \n- ~~I think the clock_gettime() linking problem will be a recurring theme- running the MNIST example gives completely inaccurate time-to-train values now.~~ On second glance, things appear to be working correctly for the MNIST training. Disregard this bullet!\n- I don't have a good idea of how fast the Pi should be running these models- let me know if you see improvements with NEON!\n- I have been able to compile the distributed runtime, so I'm hoping to play with inter-device communication between Pis and a Mac today.\n"}