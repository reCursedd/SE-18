{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/383253234", "html_url": "https://github.com/tensorflow/tensorflow/issues/18740#issuecomment-383253234", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18740", "id": 383253234, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MzI1MzIzNA==", "user": {"login": "RichDubielzig", "id": 24554323, "node_id": "MDQ6VXNlcjI0NTU0MzIz", "avatar_url": "https://avatars2.githubusercontent.com/u/24554323?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RichDubielzig", "html_url": "https://github.com/RichDubielzig", "followers_url": "https://api.github.com/users/RichDubielzig/followers", "following_url": "https://api.github.com/users/RichDubielzig/following{/other_user}", "gists_url": "https://api.github.com/users/RichDubielzig/gists{/gist_id}", "starred_url": "https://api.github.com/users/RichDubielzig/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RichDubielzig/subscriptions", "organizations_url": "https://api.github.com/users/RichDubielzig/orgs", "repos_url": "https://api.github.com/users/RichDubielzig/repos", "events_url": "https://api.github.com/users/RichDubielzig/events{/privacy}", "received_events_url": "https://api.github.com/users/RichDubielzig/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-21T00:25:11Z", "updated_at": "2018-04-21T00:25:11Z", "author_association": "NONE", "body_html": "<p>The problem appears to be related to some sort of settling of the internet connection between our build servers and github.  When I run bazel a <em>second</em> time from the same container (after running bazel clean and deleting the .cache folder), the download works and the build continues as normal.</p>\n<p>A weak workaround is to add a 'sleep 30' command to the docker RUN statement between the ./configure and 'bazel' calls.  When I do this, the build succeeds 50% of the time.  I also want to try to just wget the file directly to ~/.cache/bazel/_bazel_root/0726af6ab00d84b2e399e1660b859bdb/external/llvm before running bazel, as wget always seems to work.</p>\n<p>I'm not sure there is anything here for anyone outside our company to support, so feel free to close this if you don't have any input.  I mostly wanted to problem and possible workaround documented on the internet for the next person who ran into the issue.</p>", "body_text": "The problem appears to be related to some sort of settling of the internet connection between our build servers and github.  When I run bazel a second time from the same container (after running bazel clean and deleting the .cache folder), the download works and the build continues as normal.\nA weak workaround is to add a 'sleep 30' command to the docker RUN statement between the ./configure and 'bazel' calls.  When I do this, the build succeeds 50% of the time.  I also want to try to just wget the file directly to ~/.cache/bazel/_bazel_root/0726af6ab00d84b2e399e1660b859bdb/external/llvm before running bazel, as wget always seems to work.\nI'm not sure there is anything here for anyone outside our company to support, so feel free to close this if you don't have any input.  I mostly wanted to problem and possible workaround documented on the internet for the next person who ran into the issue.", "body": "The problem appears to be related to some sort of settling of the internet connection between our build servers and github.  When I run bazel a *second* time from the same container (after running bazel clean and deleting the .cache folder), the download works and the build continues as normal.\r\n\r\nA weak workaround is to add a 'sleep 30' command to the docker RUN statement between the ./configure and 'bazel' calls.  When I do this, the build succeeds 50% of the time.  I also want to try to just wget the file directly to ~/.cache/bazel/_bazel_root/0726af6ab00d84b2e399e1660b859bdb/external/llvm before running bazel, as wget always seems to work.\r\n\r\nI'm not sure there is anything here for anyone outside our company to support, so feel free to close this if you don't have any input.  I mostly wanted to problem and possible workaround documented on the internet for the next person who ran into the issue."}