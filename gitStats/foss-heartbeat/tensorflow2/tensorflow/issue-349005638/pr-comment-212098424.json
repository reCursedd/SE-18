{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/212098424", "pull_request_review_id": 148656061, "id": 212098424, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMjA5ODQyNA==", "diff_hunk": "@@ -544,6 +550,459 @@ def testTrainEvaluateAndPredictWithOnlyIndicatorColumn(self):\n     self.assertEqual(1, ensemble.trees[0].nodes[0].bucketized_split.feature_id)\n     self.assertEqual(0, ensemble.trees[0].nodes[0].bucketized_split.threshold)\n \n+  def testFeatureImportancesWithTrainedEnsemble(self):\n+    input_fn = _make_train_input_fn(is_classification=True)\n+\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=2,\n+        max_depth=5)\n+\n+    # It will stop after 5 steps because of the max depth and num trees.\n+    num_steps = 100\n+    # Train for a few steps, and validate final checkpoint.\n+    est.train(input_fn, steps=num_steps)\n+\n+    feature_names_expected = ['f_0_bucketized', 'f_2_bucketized', 'f_1_bucketized']\n+\n+    feature_names, importances = est.experimental_feature_importances(normalize=False)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.833933, 0.606342, 0.0], importances)\n+\n+    feature_names, importances = est.experimental_feature_importances(normalize=True)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.579010, 0.420990, 0.0], importances)\n+\n+  def testFeatureImportancesOnEmptyEnsemble(self):\n+    input_fn = _make_train_input_fn(is_classification=True)\n+\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=1,\n+        max_depth=5)\n+\n+    class BailOutWithoutTraining(session_run_hook.SessionRunHook):\n+\n+      def before_run(self, run_context):\n+        raise StopIteration('to bail out.')\n+\n+    # The step-0 checkpoint will have only an empty ensemble.\n+    est.train(input_fn,\n+              steps=100,  # must stop at 0 anyway.\n+              hooks=[BailOutWithoutTraining()])\n+\n+    with self.assertRaisesRegexp(ValueError, 'empty serialized string'):\n+      est.experimental_feature_importances(normalize=False)\n+\n+    with self.assertRaisesRegexp(ValueError, 'empty serialized string'):\n+      est.experimental_feature_importances(normalize=True)\n+\n+  def _create_fake_checkpoint_with_tree_ensemble_proto(self, est, tree_ensemble_text):\n+    with ops.Graph().as_default():\n+      with ops.name_scope('boosted_trees') as name:\n+        tree_ensemble = boosted_trees_ops.TreeEnsemble(name=name)\n+        tree_ensemble_proto = boosted_trees_pb2.TreeEnsemble()\n+        text_format.Merge(tree_ensemble_text, tree_ensemble_proto)\n+        stamp_token, _ = tree_ensemble.serialize()\n+        restore_op = tree_ensemble.deserialize(\n+            stamp_token, tree_ensemble_proto.SerializeToString())\n+\n+        with session.Session() as sess:\n+          resources.initialize_resources(resources.shared_resources()).run()\n+          restore_op.run()\n+          saver = saver_lib.Saver()\n+          save_path = os.path.join(est.model_dir, 'model.ckpt')\n+          saver.save(sess, save_path)\n+\n+  def testFeatureImportancesOnNonEmptyEnsemble(self):\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=2,\n+        max_depth=5)\n+\n+    tree_ensemble_text = \"\"\"\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 2\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 2.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 3\n+              right_id: 4\n+            }\n+            metadata {\n+              gain: 3.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 1\n+              left_id: 5\n+              right_id: 6\n+            }\n+            metadata {\n+              gain: 2.0\n+            }\n+          }\n+          nodes {\n+            leaf {\n+              scalar: -0.34\n+            }\n+          }\n+          nodes {\n+            leaf {\n+              scalar: 1.34\n+            }\n+          }\n+          nodes {\n+            leaf {\n+              scalar: 0.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 7\n+              right_id: 8\n+            }\n+            metadata {\n+              gain: 1.0\n+            }\n+          }\n+          nodes {\n+            leaf {\n+              scalar: 3.34\n+            }\n+          }\n+          nodes {\n+            leaf {\n+              scalar: 1.34\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 1.0\n+            }\n+          }\n+          nodes {\n+            leaf {\n+              scalar: 3.34\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 2\n+              left_id: 3\n+              right_id: 4\n+            }\n+            metadata {\n+              gain: 1.0\n+            }\n+          }\n+          nodes {\n+            leaf {\n+              scalar: 3.34\n+            }\n+          }\n+          nodes {\n+            leaf {\n+              scalar: 1.34\n+            }\n+          }\n+        }\n+        tree_weights: 1.0\n+        tree_weights: 1.0\n+        \"\"\"\n+    self._create_fake_checkpoint_with_tree_ensemble_proto(est, tree_ensemble_text)\n+\n+    feature_names_expected = ['f_0_bucketized', 'f_2_bucketized', 'f_1_bucketized']\n+    feature_names, importances = est.experimental_feature_importances(normalize=False)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([5.0, 3.0, 2.0], importances)", "path": "tensorflow/python/estimator/canned/boosted_trees_test.py", "position": null, "original_position": 217, "commit_id": "046c74c8e7c68aaa726977dd6e8a2523f854f9cc", "original_commit_id": "4979d7314dd1f1788751781b2dfbfb9e47c8e20e", "user": {"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}, "body": "a comment for where 5,3,2 is coming from will be helpful.", "created_at": "2018-08-22T20:34:06Z", "updated_at": "2018-09-19T22:45:29Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21509#discussion_r212098424", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21509", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/212098424"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21509#discussion_r212098424"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21509"}}, "body_html": "<p>a comment for where 5,3,2 is coming from will be helpful.</p>", "body_text": "a comment for where 5,3,2 is coming from will be helpful."}