{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/211369917", "pull_request_review_id": 147724729, "id": 211369917, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMTM2OTkxNw==", "diff_hunk": "@@ -544,6 +556,439 @@ def testTrainEvaluateAndPredictWithOnlyIndicatorColumn(self):\n     self.assertEqual(1, ensemble.trees[0].nodes[0].bucketized_split.feature_id)\n     self.assertEqual(0, ensemble.trees[0].nodes[0].bucketized_split.threshold)\n \n+  def testExperimentalFeatureImportancesWithTraining(self):\n+    input_fn = _make_train_input_fn(is_classification=True)\n+\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=1,\n+        max_depth=5)\n+\n+    # It will stop after 5 steps because of the max depth and num trees.\n+    num_steps = 100\n+    # Train for a few steps, and validate final checkpoint.\n+    est.train(input_fn, steps=num_steps)\n+\n+    feature_names_expected = ['f_0_bucketized', 'f_2_bucketized', 'f_1_bucketized']\n+\n+    feature_names, importances = est.experimental_feature_importances(normalize=False)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.2669208, 0.21333334, 0.0], importances)\n+\n+    feature_names, importances = est.experimental_feature_importances(normalize=True)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.55579074, 0.44420926, 0.0], importances)\n+\n+  def _create_fake_checkpoint_with_tree_ensemble_proto(self, est, tree_ensemble_text):\n+    with ops.Graph().as_default():\n+      with ops.name_scope('boosted_trees') as name:\n+        tree_ensemble = boosted_trees_ops.TreeEnsemble(name=name)\n+        tree_ensemble_proto = boosted_trees_pb2.TreeEnsemble()\n+        text_format.Merge(tree_ensemble_text, tree_ensemble_proto)\n+        stamp_token, _ = tree_ensemble.serialize()\n+        restore_op = tree_ensemble.deserialize(\n+            stamp_token, tree_ensemble_proto.SerializeToString())\n+\n+        with session.Session() as sess:\n+          resources.initialize_resources(resources.shared_resources()).run()\n+          restore_op.run()\n+          saver = saver_lib.Saver()\n+          save_path = os.path.join(est.model_dir, 'model.ckpt')\n+          saver.save(sess, save_path)\n+\n+  def testExperimentalCalculateFeatureImportances(self):\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=2,\n+        max_depth=5)\n+\n+    tree_ensemble_text = \"\"\"\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 2\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 2.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 3\n+              right_id: 4\n+            }\n+            metadata {\n+              gain: 3.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 1\n+              left_id: 5\n+              right_id: 6\n+            }\n+            metadata {\n+              gain: 2.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 7\n+              right_id: 8\n+            }\n+            metadata {\n+              gain: 1.0\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 1.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 2\n+              left_id: 3\n+              right_id: 4\n+            }\n+            metadata {\n+              gain: 1.0\n+            }\n+          }\n+        }\n+        tree_weights: 1.0\n+        tree_weights: 1.0\n+        \"\"\"\n+    self._create_fake_checkpoint_with_tree_ensemble_proto(est, tree_ensemble_text)\n+\n+    feature_names_expected = ['f_0_bucketized', 'f_2_bucketized', 'f_1_bucketized']\n+    feature_names, importances = est.experimental_feature_importances(normalize=False)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([2.5, 1.5, 1.0], importances)\n+\n+    feature_names, importances = est.experimental_feature_importances(normalize=True)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.5, 0.3, 0.2], importances)\n+\n+  def testExperimentalCalculateFeatureImportancesWithTreeWeights(self):\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=2,\n+        max_depth=5)\n+\n+    tree_ensemble_text = \"\"\"\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 12.5\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 1\n+              left_id: 3\n+              right_id: 4\n+            }\n+            metadata {\n+              gain: 5.0\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 2\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 5.0\n+            }\n+          }\n+        }\n+        tree_weights: 0.4\n+        tree_weights: 0.6\n+        \"\"\"\n+    self._create_fake_checkpoint_with_tree_ensemble_proto(est, tree_ensemble_text)\n+\n+    feature_names_expected = ['f_0_bucketized', 'f_2_bucketized', 'f_1_bucketized']\n+    feature_names, importances = est.experimental_feature_importances(normalize=False)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([5.0, 3.0, 2.0], importances)\n+\n+    feature_names, importances = est.experimental_feature_importances(normalize=True)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.5, 0.3, 0.2], importances)\n+\n+  def testExperimentalCalculateFeatureImportancesWithEmptyTree(self):\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=2,\n+        max_depth=5)\n+\n+    tree_ensemble_text = \"\"\"\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 2\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 3.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 3\n+              right_id: 4\n+            }\n+            metadata {\n+              gain: 1.0\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            leaf {\n+              scalar: 0.0\n+            }\n+          }\n+        }\n+        tree_weights: 1.0\n+        tree_weights: 1.0\n+        \"\"\"\n+    self._create_fake_checkpoint_with_tree_ensemble_proto(est, tree_ensemble_text)\n+\n+    feature_names_expected = ['f_2_bucketized', 'f_0_bucketized', 'f_1_bucketized']\n+    feature_names, importances = est.experimental_feature_importances(normalize=False)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([1.5, 0.5, 0.0], importances)\n+\n+    feature_names, importances = est.experimental_feature_importances(normalize=True)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.75, 0.25, 0.0], importances)\n+\n+  def testExperimentalCalculateFeatureImportancesWithAllEmptyTree(self):\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=2,\n+        max_depth=5)\n+\n+    tree_ensemble_text = \"\"\"\n+        trees {\n+          nodes {\n+            leaf {\n+              scalar: 0.0\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            leaf {\n+              scalar: 0.0\n+            }\n+          }\n+        }\n+        tree_weights: 1.0\n+        tree_weights: 1.0\n+        \"\"\"\n+    self._create_fake_checkpoint_with_tree_ensemble_proto(est, tree_ensemble_text)\n+\n+    # Reverse order because feature importances are sorted by np.argsort(f)[::-1]\n+    feature_names_expected = ['f_2_bucketized', 'f_1_bucketized', 'f_0_bucketized']\n+    feature_names, importances = est.experimental_feature_importances(normalize=False)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.0, 0.0, 0.0], importances)\n+\n+    with self.assertRaisesRegexp(AssertionError, 'empty or root node'):\n+      est.experimental_feature_importances(normalize=True)\n+\n+  def testExperimentalCalculateFeatureImportancesWithMoreTrees(self):\n+    est = boosted_trees.BoostedTreesClassifier(\n+        feature_columns=self._feature_columns,\n+        n_batches_per_layer=1,\n+        n_trees=5,\n+        max_depth=5)\n+\n+    tree_ensemble_text = \"\"\"\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 2\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 4.0\n+            }\n+          }\n+          nodes {\n+            bucketized_split {\n+              feature_id: 1\n+              left_id: 3\n+              right_id: 4\n+            }\n+            metadata {\n+              gain: 3.0\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 2\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 2.0\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 1\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 1.0\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 8.0\n+            }\n+          }\n+        }\n+        trees {\n+          nodes {\n+            bucketized_split {\n+              feature_id: 0\n+              left_id: 1\n+              right_id: 2\n+            }\n+            metadata {\n+              gain: 2.0\n+            }\n+          }\n+        }\n+        tree_weights: 1.0\n+        tree_weights: 1.0\n+        tree_weights: 1.0\n+        tree_weights: 1.0\n+        tree_weights: 1.0\n+        \"\"\"\n+    self._create_fake_checkpoint_with_tree_ensemble_proto(est, tree_ensemble_text)\n+\n+    feature_names_expected = ['f_0_bucketized', 'f_2_bucketized', 'f_1_bucketized']\n+    feature_names, importances = est.experimental_feature_importances(normalize=False)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([2, 1.2, 0.8], importances)\n+\n+    feature_names, importances = est.experimental_feature_importances(normalize=True)\n+    self.assertAllEqual(feature_names_expected, feature_names)\n+    self.assertAllClose([0.5, 0.3, 0.2], importances)\n+\n+  def testExperimentalFeatureImportancesWithIndicatorColumn(self):", "path": "tensorflow/python/estimator/canned/boosted_trees_test.py", "position": null, "original_position": 409, "commit_id": "046c74c8e7c68aaa726977dd6e8a2523f854f9cc", "original_commit_id": "52d637e604dacd3bff836a27bd991f95966226e8", "user": {"login": "nataliaponomareva", "id": 4313109, "node_id": "MDQ6VXNlcjQzMTMxMDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/4313109?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nataliaponomareva", "html_url": "https://github.com/nataliaponomareva", "followers_url": "https://api.github.com/users/nataliaponomareva/followers", "following_url": "https://api.github.com/users/nataliaponomareva/following{/other_user}", "gists_url": "https://api.github.com/users/nataliaponomareva/gists{/gist_id}", "starred_url": "https://api.github.com/users/nataliaponomareva/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nataliaponomareva/subscriptions", "organizations_url": "https://api.github.com/users/nataliaponomareva/orgs", "repos_url": "https://api.github.com/users/nataliaponomareva/repos", "events_url": "https://api.github.com/users/nataliaponomareva/events{/privacy}", "received_events_url": "https://api.github.com/users/nataliaponomareva/received_events", "type": "User", "site_admin": false}, "body": "May be lets rename it TestFeatureImportancesNamesForCategoricalColumn?", "created_at": "2018-08-20T18:51:28Z", "updated_at": "2018-09-19T22:45:29Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21509#discussion_r211369917", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21509", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/211369917"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21509#discussion_r211369917"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21509"}}, "body_html": "<p>May be lets rename it TestFeatureImportancesNamesForCategoricalColumn?</p>", "body_text": "May be lets rename it TestFeatureImportancesNamesForCategoricalColumn?"}