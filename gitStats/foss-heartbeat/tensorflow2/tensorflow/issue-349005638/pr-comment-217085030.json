{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/217085030", "pull_request_review_id": 154715476, "id": 217085030, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNzA4NTAzMA==", "diff_hunk": "@@ -961,8 +1002,105 @@ def _create_regression_head(label_dimension, weight_column=None):\n   # pylint: enable=protected-access\n \n \n+def _compute_feature_importances_per_tree(tree, num_features):\n+  \"\"\"Computes the importance of each feature in the tree.\"\"\"\n+  importances = np.zeros(num_features)\n+\n+  for node in tree.nodes:\n+    node_type = node.WhichOneof('node')\n+    if node_type == 'bucketized_split':\n+      feature_id = node.bucketized_split.feature_id\n+      importances[feature_id] += node.metadata.gain\n+    elif node_type == 'leaf':\n+      assert node.metadata.gain == 0\n+    else:\n+      raise ValueError('Unexpected split type %s', node_type)\n+\n+  return importances\n+\n+\n+def _compute_feature_importances(tree_ensemble, num_features, normalize):\n+  \"\"\"Computes gain-based feature importances.\n+\n+  The higher the value, the more important the feature.\n+\n+  Args:\n+    tree_ensemble: a trained tree ensemble, instance of proto\n+      boosted_trees.TreeEnsemble.\n+    num_features: The total number of feature ids.\n+    normalize: If True, normalize the feature importances.\n+\n+  Returns:\n+    sorted_feature_idx: A list of feature_id which is sorted\n+      by its feature importance.\n+    feature_importances: A list of corresponding feature importances.\n+\n+  Raises:\n+    AssertionError: If feature importances contain negative value.\n+      Or if normalize = True and normalization is not possible\n+      (e.g. ensemble is empty or trees contain only a root node).\n+  \"\"\"\n+  tree_importances = [_compute_feature_importances_per_tree(tree, num_features)\n+                      for tree in tree_ensemble.trees]\n+  tree_importances = np.array(tree_importances)\n+  tree_weights = np.array(tree_ensemble.tree_weights).reshape(-1, 1)\n+  feature_importances = np.sum(tree_importances * tree_weights, axis=0)\n+  assert np.all(feature_importances >= 0), ('feature_importances '", "path": "tensorflow/python/estimator/canned/boosted_trees.py", "position": null, "original_position": 109, "commit_id": "046c74c8e7c68aaa726977dd6e8a2523f854f9cc", "original_commit_id": "fd41d2c959372d7a068cb4474391362ef6a92fca", "user": {"login": "nataliaponomareva", "id": 4313109, "node_id": "MDQ6VXNlcjQzMTMxMDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/4313109?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nataliaponomareva", "html_url": "https://github.com/nataliaponomareva", "followers_url": "https://api.github.com/users/nataliaponomareva/followers", "following_url": "https://api.github.com/users/nataliaponomareva/following{/other_user}", "gists_url": "https://api.github.com/users/nataliaponomareva/gists{/gist_id}", "starred_url": "https://api.github.com/users/nataliaponomareva/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nataliaponomareva/subscriptions", "organizations_url": "https://api.github.com/users/nataliaponomareva/orgs", "repos_url": "https://api.github.com/users/nataliaponomareva/repos", "events_url": "https://api.github.com/users/nataliaponomareva/events{/privacy}", "received_events_url": "https://api.github.com/users/nataliaponomareva/received_events", "type": "User", "site_admin": false}, "body": "Actually lets remove it. I realized that even though the gain is always non negative (g^2/h) the gains stored in the splits can be negative if people are using complexity regularization (so it will be g^2/h - lambda), and if people provided tree complexity but said no pruning, we can have some features with negative importances. \r\nI will add a check that if tree complexity > 0 they must choose pruning, but it might be still good to remove this assert (and update the raises section)", "created_at": "2018-09-12T15:41:07Z", "updated_at": "2018-09-19T22:45:29Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21509#discussion_r217085030", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21509", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/217085030"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21509#discussion_r217085030"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21509"}}, "body_html": "<p>Actually lets remove it. I realized that even though the gain is always non negative (g^2/h) the gains stored in the splits can be negative if people are using complexity regularization (so it will be g^2/h - lambda), and if people provided tree complexity but said no pruning, we can have some features with negative importances.<br>\nI will add a check that if tree complexity &gt; 0 they must choose pruning, but it might be still good to remove this assert (and update the raises section)</p>", "body_text": "Actually lets remove it. I realized that even though the gain is always non negative (g^2/h) the gains stored in the splits can be negative if people are using complexity regularization (so it will be g^2/h - lambda), and if people provided tree complexity but said no pruning, we can have some features with negative importances.\nI will add a check that if tree complexity > 0 they must choose pruning, but it might be still good to remove this assert (and update the raises section)"}