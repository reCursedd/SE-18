{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/345997925", "html_url": "https://github.com/tensorflow/tensorflow/pull/13274#issuecomment-345997925", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13274", "id": 345997925, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTk5NzkyNQ==", "user": {"login": "tfnub", "id": 33863995, "node_id": "MDQ6VXNlcjMzODYzOTk1", "avatar_url": "https://avatars3.githubusercontent.com/u/33863995?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfnub", "html_url": "https://github.com/tfnub", "followers_url": "https://api.github.com/users/tfnub/followers", "following_url": "https://api.github.com/users/tfnub/following{/other_user}", "gists_url": "https://api.github.com/users/tfnub/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfnub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfnub/subscriptions", "organizations_url": "https://api.github.com/users/tfnub/orgs", "repos_url": "https://api.github.com/users/tfnub/repos", "events_url": "https://api.github.com/users/tfnub/events{/privacy}", "received_events_url": "https://api.github.com/users/tfnub/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-21T11:24:58Z", "updated_at": "2017-11-21T11:26:23Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13562803\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ilya-edrenkin\">@ilya-edrenkin</a> I've run into the problem that this looks to solve and wanted to check a few things to make sure I'm understanding this right. I'm switching over from alternating to joint learning so help and comments would be very much appreciated. My initial thought was to pass a boolean (well, 1/0 int) vector into the loss function as the \"weights\" term, but I'm not sure if the optimizer would understand to zero out those gradients as we want it to.</p>\n<p>In the case that you have a multi-head/task learner and a minibatch of size n, where k of the of the n samples should have their losses masked out for a single task, you would apply a boolean mask of [n, 1] shape to the loss, right? As below:</p>\n<pre><code>## Batch size 2, 3 logits\ntargets = tf.constant([[1.0,1.0,0.0], [0.0,0.0,0.0]], tf.float32)\nlogits = tf.constant([[0.8,0.9,0.2], [0.3,0.3,0.2]], tf.float32)\n\n# Compute the mask\nmask_targets = tf.count_nonzero(targets, 1)\nmask_targets = tf.cast(mask_targets, tf.bool)\n\n#Compute loss components\nlosses = tf.losses.sigmoid_cross_entropy(\n    targets, logits, reduction=tf.losses.Reduction.NONE)\n\n# Apply the mask\nmasked_losses = tf.boolean_mask(losses, mask_targets)\n\n# Reduce\nreduced_loss = tf.reduce_sum(masked_losses)\n\nsess = tf.Session()\nprint(sess.run(reduced_loss))\n</code></pre>\n<p>Is this the order you apply the losses, masks, and reductions in? Also, I assume the <code>reduction=tf.losses.Reduction.NONE</code>kwarg is necessary to be able to apply the masks in the batch dimension? I think that in practice if you tried to take the <code>tf.reduce_mean</code> of a fully masked label vector you would get a nan, is it appropriate here to <code>tf.reduce_sum</code> instead (/ is that what you do in practice to mitigate)?  Thank you!</p>", "body_text": "@ilya-edrenkin I've run into the problem that this looks to solve and wanted to check a few things to make sure I'm understanding this right. I'm switching over from alternating to joint learning so help and comments would be very much appreciated. My initial thought was to pass a boolean (well, 1/0 int) vector into the loss function as the \"weights\" term, but I'm not sure if the optimizer would understand to zero out those gradients as we want it to.\nIn the case that you have a multi-head/task learner and a minibatch of size n, where k of the of the n samples should have their losses masked out for a single task, you would apply a boolean mask of [n, 1] shape to the loss, right? As below:\n## Batch size 2, 3 logits\ntargets = tf.constant([[1.0,1.0,0.0], [0.0,0.0,0.0]], tf.float32)\nlogits = tf.constant([[0.8,0.9,0.2], [0.3,0.3,0.2]], tf.float32)\n\n# Compute the mask\nmask_targets = tf.count_nonzero(targets, 1)\nmask_targets = tf.cast(mask_targets, tf.bool)\n\n#Compute loss components\nlosses = tf.losses.sigmoid_cross_entropy(\n    targets, logits, reduction=tf.losses.Reduction.NONE)\n\n# Apply the mask\nmasked_losses = tf.boolean_mask(losses, mask_targets)\n\n# Reduce\nreduced_loss = tf.reduce_sum(masked_losses)\n\nsess = tf.Session()\nprint(sess.run(reduced_loss))\n\nIs this the order you apply the losses, masks, and reductions in? Also, I assume the reduction=tf.losses.Reduction.NONEkwarg is necessary to be able to apply the masks in the batch dimension? I think that in practice if you tried to take the tf.reduce_mean of a fully masked label vector you would get a nan, is it appropriate here to tf.reduce_sum instead (/ is that what you do in practice to mitigate)?  Thank you!", "body": "@ilya-edrenkin I've run into the problem that this looks to solve and wanted to check a few things to make sure I'm understanding this right. I'm switching over from alternating to joint learning so help and comments would be very much appreciated. My initial thought was to pass a boolean (well, 1/0 int) vector into the loss function as the \"weights\" term, but I'm not sure if the optimizer would understand to zero out those gradients as we want it to.\r\n\r\nIn the case that you have a multi-head/task learner and a minibatch of size n, where k of the of the n samples should have their losses masked out for a single task, you would apply a boolean mask of [n, 1] shape to the loss, right? As below:\r\n\r\n```\r\n## Batch size 2, 3 logits\r\ntargets = tf.constant([[1.0,1.0,0.0], [0.0,0.0,0.0]], tf.float32)\r\nlogits = tf.constant([[0.8,0.9,0.2], [0.3,0.3,0.2]], tf.float32)\r\n\r\n# Compute the mask\r\nmask_targets = tf.count_nonzero(targets, 1)\r\nmask_targets = tf.cast(mask_targets, tf.bool)\r\n\r\n#Compute loss components\r\nlosses = tf.losses.sigmoid_cross_entropy(\r\n    targets, logits, reduction=tf.losses.Reduction.NONE)\r\n\r\n# Apply the mask\r\nmasked_losses = tf.boolean_mask(losses, mask_targets)\r\n\r\n# Reduce\r\nreduced_loss = tf.reduce_sum(masked_losses)\r\n\r\nsess = tf.Session()\r\nprint(sess.run(reduced_loss))\r\n```\r\n\r\nIs this the order you apply the losses, masks, and reductions in? Also, I assume the `reduction=tf.losses.Reduction.NONE`kwarg is necessary to be able to apply the masks in the batch dimension? I think that in practice if you tried to take the `tf.reduce_mean` of a fully masked label vector you would get a nan, is it appropriate here to `tf.reduce_sum` instead (/ is that what you do in practice to mitigate)?  Thank you!"}