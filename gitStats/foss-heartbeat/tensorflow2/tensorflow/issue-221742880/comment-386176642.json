{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/386176642", "html_url": "https://github.com/tensorflow/tensorflow/issues/9210#issuecomment-386176642", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9210", "id": 386176642, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjE3NjY0Mg==", "user": {"login": "kojino", "id": 6567880, "node_id": "MDQ6VXNlcjY1Njc4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/6567880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kojino", "html_url": "https://github.com/kojino", "followers_url": "https://api.github.com/users/kojino/followers", "following_url": "https://api.github.com/users/kojino/following{/other_user}", "gists_url": "https://api.github.com/users/kojino/gists{/gist_id}", "starred_url": "https://api.github.com/users/kojino/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kojino/subscriptions", "organizations_url": "https://api.github.com/users/kojino/orgs", "repos_url": "https://api.github.com/users/kojino/repos", "events_url": "https://api.github.com/users/kojino/events{/privacy}", "received_events_url": "https://api.github.com/users/kojino/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-03T02:29:10Z", "updated_at": "2018-05-03T02:29:10Z", "author_association": "NONE", "body_html": "<p>I implemented a function that is based off of <code>tf.tensordot</code>. It's long, but I think it works.</p>\n<pre><code>def sparse_tensor_dense_tensordot(sp_a, b, axes, name=None):\n    r\"\"\"Tensor contraction of a and b along specified axes.\n    Tensordot (also known as tensor contraction) sums the product of elements\n    from `a` and `b` over the indices specified by `a_axes` and `b_axes`.\n    The lists `a_axes` and `b_axes` specify those pairs of axes along which to\n    contract the tensors. The axis `a_axes[i]` of `a` must have the same dimension\n    as axis `b_axes[i]` of `b` for all `i` in `range(0, len(a_axes))`. The lists\n    `a_axes` and `b_axes` must have identical length and consist of unique\n    integers that specify valid axes for each of the tensors.\n    This operation corresponds to `numpy.tensordot(a, b, axes)`.\n    Example 1: When `a` and `b` are matrices (order 2), the case `axes = 1`\n    is equivalent to matrix multiplication.\n    Example 2: When `a` and `b` are matrices (order 2), the case\n    `axes = [[1], [0]]` is equivalent to matrix multiplication.\n    Example 3: Suppose that \\\\(a_{ijk}\\\\) and \\\\(b_{lmn}\\\\) represent two\n    tensors of order 3. Then, `contract(a, b, [[0], [2]])` is the order 4 tensor\n    \\\\(c_{jklm}\\\\) whose entry\n    corresponding to the indices \\\\((j,k,l,m)\\\\) is given by:\n    \\\\( c_{jklm} = \\sum_i a_{ijk} b_{lmi} \\\\).\n    In general, `order(c) = order(a) + order(b) - 2*len(axes[0])`.\n    Args:\n        a: `SparseTensor` of type `float32` or `float64`.\n        b: `Tensor` with the same type as `a`.\n        axes: Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k].\n         If axes is a scalar, sum over the last N axes of a and the first N axes\n         of b in order.\n         If axes is a list or `Tensor` the first and second row contain the set of\n         unique integers specifying axes along which the contraction is computed,\n         for `a` and `b`, respectively. The number of axes for `a` and `b` must\n         be equal.\n        name: A name for the operation (optional).\n    Returns:\n        A `Tensor` with the same type as `a`.\n    Raises:\n        ValueError: If the shapes of `a`, `b`, and `axes` are incompatible.\n        IndexError: If the values in axes exceed the rank of the corresponding\n            tensor.\n    \"\"\"\n\n    def _tensordot_reshape(a, axes, flipped=False):\n        \"\"\"Helper method to perform transpose and reshape for contraction op.\n        This method is helpful in reducing `math_tf.tensordot` to `math_tf.matmul`\n        using `tf.transpose` and `tf.reshape`. The method takes a\n        tensor and performs the correct transpose and reshape operation for a given\n        set of indices. It returns the reshaped tensor as well as a list of indices\n        necessary to reshape the tensor again after matrix multiplication.\n        Args:\n            a: `Tensor`.\n            axes: List or `int32` `Tensor` of unique indices specifying valid axes of\n             `a`.\n            flipped: An optional `bool`. Defaults to `False`. If `True`, the method\n                assumes that `a` is the second argument in the contraction operation.\n        Returns:\n            A tuple `(reshaped_a, free_dims, free_dims_static)` where `reshaped_a` is\n            the tensor `a` reshaped to allow contraction via `matmul`, `free_dims` is\n            either a list of integers or an `int32` `Tensor`, depending on whether\n            the shape of a is fully specified, and free_dims_static is either a list\n            of integers and None values, or None, representing the inferred\n            static shape of the free dimensions\n        \"\"\"\n        if a.get_shape().is_fully_defined() and isinstance(axes, (list, tuple)):\n            shape_a = a.get_shape().as_list()\n            axes = [i if i &gt;= 0 else i + len(shape_a) for i in axes]\n            free = [i for i in range(len(shape_a)) if i not in axes]\n            free_dims = [shape_a[i] for i in free]\n            prod_free = int(np.prod([shape_a[i] for i in free]))\n            prod_axes = int(np.prod([shape_a[i] for i in axes]))\n            perm = list(axes) + free if flipped else free + list(axes)\n            new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\n            reshaped_a = tf.reshape(tf.transpose(a, perm), new_shape)\n            return reshaped_a, free_dims, free_dims\n        else:\n            if a.get_shape().ndims is not None and isinstance(axes, (list, tuple)):\n                shape_a = a.get_shape().as_list()\n                axes = [i if i &gt;= 0 else i + len(shape_a) for i in axes]\n                free = [i for i in range(len(shape_a)) if i not in axes]\n                free_dims_static = [shape_a[i] for i in free]\n            else:\n                free_dims_static = None\n            shape_a = tf.shape(a)\n            rank_a = tf.rank(a)\n            axes = tf.convert_to_tensor(axes, dtype=tf.int32, name=\"axes\")\n            axes = tf.cast(axes &gt;= 0, tf.int32) * axes + tf.cast(\n                    axes &lt; 0, tf.int32) * (\n                            axes + rank_a)\n            free, _ = tf.setdiff1d(tf.range(rank_a), axes)\n            free_dims = tf.gather(shape_a, free)\n            axes_dims = tf.gather(shape_a, axes)\n            prod_free_dims = tf.reduce_prod(free_dims)\n            prod_axes_dims = tf.reduce_prod(axes_dims)\n            perm = tf.concat([axes_dims, free_dims], 0)\n            if flipped:\n                perm = tf.concat([axes, free], 0)\n                new_shape = tf.stack([prod_axes_dims, prod_free_dims])\n            else:\n                perm = tf.concat([free, axes], 0)\n                new_shape = tf.stack([prod_free_dims, prod_axes_dims])\n            reshaped_a = tf.reshape(tf.transpose(a, perm), new_shape)\n            return reshaped_a, free_dims, free_dims_static\n\n    def _tensordot_axes(a, axes):\n        \"\"\"Generates two sets of contraction axes for the two tensor arguments.\"\"\"\n        a_shape = a.get_shape()\n        if isinstance(axes, compat.integral_types):\n            if axes &lt; 0:\n                raise ValueError(\"'axes' must be at least 0.\")\n            if a_shape.ndims is not None:\n                if axes &gt; a_shape.ndims:\n                    raise ValueError(\"'axes' must not be larger than the number of \"\n                                                     \"dimensions of tensor %s.\" % a)\n                return (list(range(a_shape.ndims - axes, a_shape.ndims)),\n                                list(range(axes)))\n            else:\n                rank = tf.rank(a)\n                return (range(rank - axes, rank, dtype=tf.int32),\n                                range(axes, dtype=tf.int32))\n        elif isinstance(axes, (list, tuple)):\n            if len(axes) != 2:\n                raise ValueError(\"'axes' must be an integer or have length 2.\")\n            a_axes = axes[0]\n            b_axes = axes[1]\n            if isinstance(a_axes, compat.integral_types) and \\\n                    isinstance(b_axes, compat.integral_types):\n                a_axes = [a_axes]\n                b_axes = [b_axes]\n            if len(a_axes) != len(b_axes):\n                raise ValueError(\n                        \"Different number of contraction axes 'a' and 'b', %s != %s.\" %\n                        (len(a_axes), len(b_axes)))\n            return a_axes, b_axes\n        else:\n            axes = tf.convert_to_tensor(axes, name=\"axes\", dtype=tf.int32)\n        return axes[0], axes[1]\n\n    def _sparse_tensordot_reshape(a, axes, flipped=False):\n        \"\"\"Helper method to perform transpose and reshape for contraction op.\n        This method is helpful in reducing `math_tf.tensordot` to `math_tf.matmul`\n        using `tf.transpose` and `tf.reshape`. The method takes a\n        tensor and performs the correct transpose and reshape operation for a given\n        set of indices. It returns the reshaped tensor as well as a list of indices\n        necessary to reshape the tensor again after matrix multiplication.\n        Args:\n            a: `Tensor`.\n            axes: List or `int32` `Tensor` of unique indices specifying valid axes of\n             `a`.\n            flipped: An optional `bool`. Defaults to `False`. If `True`, the method\n                assumes that `a` is the second argument in the contraction operation.\n        Returns:\n            A tuple `(reshaped_a, free_dims, free_dims_static)` where `reshaped_a` is\n            the tensor `a` reshaped to allow contraction via `matmul`, `free_dims` is\n            either a list of integers or an `int32` `Tensor`, depending on whether\n            the shape of a is fully specified, and free_dims_static is either a list\n            of integers and None values, or None, representing the inferred\n            static shape of the free dimensions\n        \"\"\"\n        if a.get_shape().is_fully_defined() and isinstance(axes, (list, tuple)):\n            shape_a = a.get_shape().as_list()\n            axes = [i if i &gt;= 0 else i + len(shape_a) for i in axes]\n            free = [i for i in range(len(shape_a)) if i not in axes]\n            free_dims = [shape_a[i] for i in free]\n            prod_free = int(np.prod([shape_a[i] for i in free]))\n            prod_axes = int(np.prod([shape_a[i] for i in axes]))\n            perm = list(axes) + free if flipped else free + list(axes)\n            new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\n            reshaped_a = tf.sparse_reshape(tf.sparse_transpose(a, perm), new_shape)\n            return reshaped_a, free_dims, free_dims\n        else:\n            if a.get_shape().ndims is not None and isinstance(axes, (list, tuple)):\n                shape_a = a.get_shape().as_list()\n                axes = [i if i &gt;= 0 else i + len(shape_a) for i in axes]\n                free = [i for i in range(len(shape_a)) if i not in axes]\n                free_dims_static = [shape_a[i] for i in free]\n            else:\n                free_dims_static = None\n            shape_a = tf.shape(a)\n            rank_a = tf.rank(a)\n            axes = tf.convert_to_tensor(axes, dtype=tf.int32, name=\"axes\")\n            axes = tf.cast(axes &gt;= 0, tf.int32) * axes + tf.cast(\n                    axes &lt; 0, tf.int32) * (\n                            axes + rank_a)\n            print(sess.run(rank_a), sess.run(axes))\n            free, _ = tf.setdiff1d(tf.range(rank_a), axes)\n            free_dims = tf.gather(shape_a, free)\n            axes_dims = tf.gather(shape_a, axes)\n            prod_free_dims = tf.reduce_prod(free_dims)\n            prod_axes_dims = tf.reduce_prod(axes_dims)\n            perm = tf.concat([axes_dims, free_dims], 0)\n            if flipped:\n                perm = tf.concat([axes, free], 0)\n                new_shape = tf.stack([prod_axes_dims, prod_free_dims])\n            else:\n                perm = tf.concat([free, axes], 0)\n                new_shape = tf.stack([prod_free_dims, prod_axes_dims])\n            reshaped_a = tf.sparse_reshape(tf.sparse_transpose(a, perm), new_shape)\n            return reshaped_a, free_dims, free_dims_static\n\n    def _sparse_tensordot_axes(a, axes):\n        \"\"\"Generates two sets of contraction axes for the two tensor arguments.\"\"\"\n        a_shape = a.get_shape()\n        if isinstance(axes, tf.compat.integral_types):\n            if axes &lt; 0:\n                raise ValueError(\"'axes' must be at least 0.\")\n            if a_shape.ndims is not None:\n                if axes &gt; a_shape.ndims:\n                    raise ValueError(\"'axes' must not be larger than the number of \"\n                                                     \"dimensions of tensor %s.\" % a)\n                return (list(range(a_shape.ndims - axes, a_shape.ndims)),\n                                list(range(axes)))\n            else:\n                rank = tf.rank(a)\n                return (range(rank - axes, rank, dtype=tf.int32),\n                                range(axes, dtype=tf.int32))\n        elif isinstance(axes, (list, tuple)):\n            if len(axes) != 2:\n                raise ValueError(\"'axes' must be an integer or have length 2.\")\n            a_axes = axes[0]\n            b_axes = axes[1]\n            if isinstance(a_axes, compat.integral_types) and \\\n                    isinstance(b_axes, compat.integral_types):\n                a_axes = [a_axes]\n                b_axes = [b_axes]\n            if len(a_axes) != len(b_axes):\n                raise ValueError(\n                        \"Different number of contraction axes 'a' and 'b', %s != %s.\" %\n                        (len(a_axes), len(b_axes)))\n            return a_axes, b_axes\n        else:\n            axes = tf.convert_to_tensor(axes, name=\"axes\", dtype=tf.int32)\n        return axes[0], axes[1]\n\n    with tf.name_scope(name, \"SparseTensorDenseTensordot\", [sp_a, b, axes]) as name:\n#         a = tf.convert_to_tensor(a, name=\"a\")\n        b = tf.convert_to_tensor(b, name=\"b\")\n        sp_a_axes, b_axes = _sparse_tensordot_axes(sp_a, axes)\n        sp_a_reshape, sp_a_free_dims, sp_a_free_dims_static = _sparse_tensordot_reshape(sp_a, sp_a_axes)\n        b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n                b, b_axes, True)\n        ab_matmul = tf.sparse_tensor_dense_matmul(sp_a_reshape, b_reshape)\n        if isinstance(sp_a_free_dims, list) and isinstance(b_free_dims, list):\n            return tf.reshape(ab_matmul, sp_a_free_dims + b_free_dims, name=name)\n        else:\n            sp_a_free_dims = tf.convert_to_tensor(sp_a_free_dims, dtype=tf.int32)\n            b_free_dims = tf.convert_to_tensor(b_free_dims, dtype=tf.int32)\n            product = tf.reshape(\n                    ab_matmul, tf.concat([sp_a_free_dims, b_free_dims], 0), name=name)\n            if sp_a_free_dims_static is not None and b_free_dims_static is not None:\n                product.set_shape(sp_a_free_dims_static + b_free_dims_static)\n            return product\n</code></pre>", "body_text": "I implemented a function that is based off of tf.tensordot. It's long, but I think it works.\ndef sparse_tensor_dense_tensordot(sp_a, b, axes, name=None):\n    r\"\"\"Tensor contraction of a and b along specified axes.\n    Tensordot (also known as tensor contraction) sums the product of elements\n    from `a` and `b` over the indices specified by `a_axes` and `b_axes`.\n    The lists `a_axes` and `b_axes` specify those pairs of axes along which to\n    contract the tensors. The axis `a_axes[i]` of `a` must have the same dimension\n    as axis `b_axes[i]` of `b` for all `i` in `range(0, len(a_axes))`. The lists\n    `a_axes` and `b_axes` must have identical length and consist of unique\n    integers that specify valid axes for each of the tensors.\n    This operation corresponds to `numpy.tensordot(a, b, axes)`.\n    Example 1: When `a` and `b` are matrices (order 2), the case `axes = 1`\n    is equivalent to matrix multiplication.\n    Example 2: When `a` and `b` are matrices (order 2), the case\n    `axes = [[1], [0]]` is equivalent to matrix multiplication.\n    Example 3: Suppose that \\\\(a_{ijk}\\\\) and \\\\(b_{lmn}\\\\) represent two\n    tensors of order 3. Then, `contract(a, b, [[0], [2]])` is the order 4 tensor\n    \\\\(c_{jklm}\\\\) whose entry\n    corresponding to the indices \\\\((j,k,l,m)\\\\) is given by:\n    \\\\( c_{jklm} = \\sum_i a_{ijk} b_{lmi} \\\\).\n    In general, `order(c) = order(a) + order(b) - 2*len(axes[0])`.\n    Args:\n        a: `SparseTensor` of type `float32` or `float64`.\n        b: `Tensor` with the same type as `a`.\n        axes: Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k].\n         If axes is a scalar, sum over the last N axes of a and the first N axes\n         of b in order.\n         If axes is a list or `Tensor` the first and second row contain the set of\n         unique integers specifying axes along which the contraction is computed,\n         for `a` and `b`, respectively. The number of axes for `a` and `b` must\n         be equal.\n        name: A name for the operation (optional).\n    Returns:\n        A `Tensor` with the same type as `a`.\n    Raises:\n        ValueError: If the shapes of `a`, `b`, and `axes` are incompatible.\n        IndexError: If the values in axes exceed the rank of the corresponding\n            tensor.\n    \"\"\"\n\n    def _tensordot_reshape(a, axes, flipped=False):\n        \"\"\"Helper method to perform transpose and reshape for contraction op.\n        This method is helpful in reducing `math_tf.tensordot` to `math_tf.matmul`\n        using `tf.transpose` and `tf.reshape`. The method takes a\n        tensor and performs the correct transpose and reshape operation for a given\n        set of indices. It returns the reshaped tensor as well as a list of indices\n        necessary to reshape the tensor again after matrix multiplication.\n        Args:\n            a: `Tensor`.\n            axes: List or `int32` `Tensor` of unique indices specifying valid axes of\n             `a`.\n            flipped: An optional `bool`. Defaults to `False`. If `True`, the method\n                assumes that `a` is the second argument in the contraction operation.\n        Returns:\n            A tuple `(reshaped_a, free_dims, free_dims_static)` where `reshaped_a` is\n            the tensor `a` reshaped to allow contraction via `matmul`, `free_dims` is\n            either a list of integers or an `int32` `Tensor`, depending on whether\n            the shape of a is fully specified, and free_dims_static is either a list\n            of integers and None values, or None, representing the inferred\n            static shape of the free dimensions\n        \"\"\"\n        if a.get_shape().is_fully_defined() and isinstance(axes, (list, tuple)):\n            shape_a = a.get_shape().as_list()\n            axes = [i if i >= 0 else i + len(shape_a) for i in axes]\n            free = [i for i in range(len(shape_a)) if i not in axes]\n            free_dims = [shape_a[i] for i in free]\n            prod_free = int(np.prod([shape_a[i] for i in free]))\n            prod_axes = int(np.prod([shape_a[i] for i in axes]))\n            perm = list(axes) + free if flipped else free + list(axes)\n            new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\n            reshaped_a = tf.reshape(tf.transpose(a, perm), new_shape)\n            return reshaped_a, free_dims, free_dims\n        else:\n            if a.get_shape().ndims is not None and isinstance(axes, (list, tuple)):\n                shape_a = a.get_shape().as_list()\n                axes = [i if i >= 0 else i + len(shape_a) for i in axes]\n                free = [i for i in range(len(shape_a)) if i not in axes]\n                free_dims_static = [shape_a[i] for i in free]\n            else:\n                free_dims_static = None\n            shape_a = tf.shape(a)\n            rank_a = tf.rank(a)\n            axes = tf.convert_to_tensor(axes, dtype=tf.int32, name=\"axes\")\n            axes = tf.cast(axes >= 0, tf.int32) * axes + tf.cast(\n                    axes < 0, tf.int32) * (\n                            axes + rank_a)\n            free, _ = tf.setdiff1d(tf.range(rank_a), axes)\n            free_dims = tf.gather(shape_a, free)\n            axes_dims = tf.gather(shape_a, axes)\n            prod_free_dims = tf.reduce_prod(free_dims)\n            prod_axes_dims = tf.reduce_prod(axes_dims)\n            perm = tf.concat([axes_dims, free_dims], 0)\n            if flipped:\n                perm = tf.concat([axes, free], 0)\n                new_shape = tf.stack([prod_axes_dims, prod_free_dims])\n            else:\n                perm = tf.concat([free, axes], 0)\n                new_shape = tf.stack([prod_free_dims, prod_axes_dims])\n            reshaped_a = tf.reshape(tf.transpose(a, perm), new_shape)\n            return reshaped_a, free_dims, free_dims_static\n\n    def _tensordot_axes(a, axes):\n        \"\"\"Generates two sets of contraction axes for the two tensor arguments.\"\"\"\n        a_shape = a.get_shape()\n        if isinstance(axes, compat.integral_types):\n            if axes < 0:\n                raise ValueError(\"'axes' must be at least 0.\")\n            if a_shape.ndims is not None:\n                if axes > a_shape.ndims:\n                    raise ValueError(\"'axes' must not be larger than the number of \"\n                                                     \"dimensions of tensor %s.\" % a)\n                return (list(range(a_shape.ndims - axes, a_shape.ndims)),\n                                list(range(axes)))\n            else:\n                rank = tf.rank(a)\n                return (range(rank - axes, rank, dtype=tf.int32),\n                                range(axes, dtype=tf.int32))\n        elif isinstance(axes, (list, tuple)):\n            if len(axes) != 2:\n                raise ValueError(\"'axes' must be an integer or have length 2.\")\n            a_axes = axes[0]\n            b_axes = axes[1]\n            if isinstance(a_axes, compat.integral_types) and \\\n                    isinstance(b_axes, compat.integral_types):\n                a_axes = [a_axes]\n                b_axes = [b_axes]\n            if len(a_axes) != len(b_axes):\n                raise ValueError(\n                        \"Different number of contraction axes 'a' and 'b', %s != %s.\" %\n                        (len(a_axes), len(b_axes)))\n            return a_axes, b_axes\n        else:\n            axes = tf.convert_to_tensor(axes, name=\"axes\", dtype=tf.int32)\n        return axes[0], axes[1]\n\n    def _sparse_tensordot_reshape(a, axes, flipped=False):\n        \"\"\"Helper method to perform transpose and reshape for contraction op.\n        This method is helpful in reducing `math_tf.tensordot` to `math_tf.matmul`\n        using `tf.transpose` and `tf.reshape`. The method takes a\n        tensor and performs the correct transpose and reshape operation for a given\n        set of indices. It returns the reshaped tensor as well as a list of indices\n        necessary to reshape the tensor again after matrix multiplication.\n        Args:\n            a: `Tensor`.\n            axes: List or `int32` `Tensor` of unique indices specifying valid axes of\n             `a`.\n            flipped: An optional `bool`. Defaults to `False`. If `True`, the method\n                assumes that `a` is the second argument in the contraction operation.\n        Returns:\n            A tuple `(reshaped_a, free_dims, free_dims_static)` where `reshaped_a` is\n            the tensor `a` reshaped to allow contraction via `matmul`, `free_dims` is\n            either a list of integers or an `int32` `Tensor`, depending on whether\n            the shape of a is fully specified, and free_dims_static is either a list\n            of integers and None values, or None, representing the inferred\n            static shape of the free dimensions\n        \"\"\"\n        if a.get_shape().is_fully_defined() and isinstance(axes, (list, tuple)):\n            shape_a = a.get_shape().as_list()\n            axes = [i if i >= 0 else i + len(shape_a) for i in axes]\n            free = [i for i in range(len(shape_a)) if i not in axes]\n            free_dims = [shape_a[i] for i in free]\n            prod_free = int(np.prod([shape_a[i] for i in free]))\n            prod_axes = int(np.prod([shape_a[i] for i in axes]))\n            perm = list(axes) + free if flipped else free + list(axes)\n            new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\n            reshaped_a = tf.sparse_reshape(tf.sparse_transpose(a, perm), new_shape)\n            return reshaped_a, free_dims, free_dims\n        else:\n            if a.get_shape().ndims is not None and isinstance(axes, (list, tuple)):\n                shape_a = a.get_shape().as_list()\n                axes = [i if i >= 0 else i + len(shape_a) for i in axes]\n                free = [i for i in range(len(shape_a)) if i not in axes]\n                free_dims_static = [shape_a[i] for i in free]\n            else:\n                free_dims_static = None\n            shape_a = tf.shape(a)\n            rank_a = tf.rank(a)\n            axes = tf.convert_to_tensor(axes, dtype=tf.int32, name=\"axes\")\n            axes = tf.cast(axes >= 0, tf.int32) * axes + tf.cast(\n                    axes < 0, tf.int32) * (\n                            axes + rank_a)\n            print(sess.run(rank_a), sess.run(axes))\n            free, _ = tf.setdiff1d(tf.range(rank_a), axes)\n            free_dims = tf.gather(shape_a, free)\n            axes_dims = tf.gather(shape_a, axes)\n            prod_free_dims = tf.reduce_prod(free_dims)\n            prod_axes_dims = tf.reduce_prod(axes_dims)\n            perm = tf.concat([axes_dims, free_dims], 0)\n            if flipped:\n                perm = tf.concat([axes, free], 0)\n                new_shape = tf.stack([prod_axes_dims, prod_free_dims])\n            else:\n                perm = tf.concat([free, axes], 0)\n                new_shape = tf.stack([prod_free_dims, prod_axes_dims])\n            reshaped_a = tf.sparse_reshape(tf.sparse_transpose(a, perm), new_shape)\n            return reshaped_a, free_dims, free_dims_static\n\n    def _sparse_tensordot_axes(a, axes):\n        \"\"\"Generates two sets of contraction axes for the two tensor arguments.\"\"\"\n        a_shape = a.get_shape()\n        if isinstance(axes, tf.compat.integral_types):\n            if axes < 0:\n                raise ValueError(\"'axes' must be at least 0.\")\n            if a_shape.ndims is not None:\n                if axes > a_shape.ndims:\n                    raise ValueError(\"'axes' must not be larger than the number of \"\n                                                     \"dimensions of tensor %s.\" % a)\n                return (list(range(a_shape.ndims - axes, a_shape.ndims)),\n                                list(range(axes)))\n            else:\n                rank = tf.rank(a)\n                return (range(rank - axes, rank, dtype=tf.int32),\n                                range(axes, dtype=tf.int32))\n        elif isinstance(axes, (list, tuple)):\n            if len(axes) != 2:\n                raise ValueError(\"'axes' must be an integer or have length 2.\")\n            a_axes = axes[0]\n            b_axes = axes[1]\n            if isinstance(a_axes, compat.integral_types) and \\\n                    isinstance(b_axes, compat.integral_types):\n                a_axes = [a_axes]\n                b_axes = [b_axes]\n            if len(a_axes) != len(b_axes):\n                raise ValueError(\n                        \"Different number of contraction axes 'a' and 'b', %s != %s.\" %\n                        (len(a_axes), len(b_axes)))\n            return a_axes, b_axes\n        else:\n            axes = tf.convert_to_tensor(axes, name=\"axes\", dtype=tf.int32)\n        return axes[0], axes[1]\n\n    with tf.name_scope(name, \"SparseTensorDenseTensordot\", [sp_a, b, axes]) as name:\n#         a = tf.convert_to_tensor(a, name=\"a\")\n        b = tf.convert_to_tensor(b, name=\"b\")\n        sp_a_axes, b_axes = _sparse_tensordot_axes(sp_a, axes)\n        sp_a_reshape, sp_a_free_dims, sp_a_free_dims_static = _sparse_tensordot_reshape(sp_a, sp_a_axes)\n        b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n                b, b_axes, True)\n        ab_matmul = tf.sparse_tensor_dense_matmul(sp_a_reshape, b_reshape)\n        if isinstance(sp_a_free_dims, list) and isinstance(b_free_dims, list):\n            return tf.reshape(ab_matmul, sp_a_free_dims + b_free_dims, name=name)\n        else:\n            sp_a_free_dims = tf.convert_to_tensor(sp_a_free_dims, dtype=tf.int32)\n            b_free_dims = tf.convert_to_tensor(b_free_dims, dtype=tf.int32)\n            product = tf.reshape(\n                    ab_matmul, tf.concat([sp_a_free_dims, b_free_dims], 0), name=name)\n            if sp_a_free_dims_static is not None and b_free_dims_static is not None:\n                product.set_shape(sp_a_free_dims_static + b_free_dims_static)\n            return product", "body": "I implemented a function that is based off of `tf.tensordot`. It's long, but I think it works.\r\n\r\n```\r\ndef sparse_tensor_dense_tensordot(sp_a, b, axes, name=None):\r\n    r\"\"\"Tensor contraction of a and b along specified axes.\r\n    Tensordot (also known as tensor contraction) sums the product of elements\r\n    from `a` and `b` over the indices specified by `a_axes` and `b_axes`.\r\n    The lists `a_axes` and `b_axes` specify those pairs of axes along which to\r\n    contract the tensors. The axis `a_axes[i]` of `a` must have the same dimension\r\n    as axis `b_axes[i]` of `b` for all `i` in `range(0, len(a_axes))`. The lists\r\n    `a_axes` and `b_axes` must have identical length and consist of unique\r\n    integers that specify valid axes for each of the tensors.\r\n    This operation corresponds to `numpy.tensordot(a, b, axes)`.\r\n    Example 1: When `a` and `b` are matrices (order 2), the case `axes = 1`\r\n    is equivalent to matrix multiplication.\r\n    Example 2: When `a` and `b` are matrices (order 2), the case\r\n    `axes = [[1], [0]]` is equivalent to matrix multiplication.\r\n    Example 3: Suppose that \\\\(a_{ijk}\\\\) and \\\\(b_{lmn}\\\\) represent two\r\n    tensors of order 3. Then, `contract(a, b, [[0], [2]])` is the order 4 tensor\r\n    \\\\(c_{jklm}\\\\) whose entry\r\n    corresponding to the indices \\\\((j,k,l,m)\\\\) is given by:\r\n    \\\\( c_{jklm} = \\sum_i a_{ijk} b_{lmi} \\\\).\r\n    In general, `order(c) = order(a) + order(b) - 2*len(axes[0])`.\r\n    Args:\r\n        a: `SparseTensor` of type `float32` or `float64`.\r\n        b: `Tensor` with the same type as `a`.\r\n        axes: Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k].\r\n         If axes is a scalar, sum over the last N axes of a and the first N axes\r\n         of b in order.\r\n         If axes is a list or `Tensor` the first and second row contain the set of\r\n         unique integers specifying axes along which the contraction is computed,\r\n         for `a` and `b`, respectively. The number of axes for `a` and `b` must\r\n         be equal.\r\n        name: A name for the operation (optional).\r\n    Returns:\r\n        A `Tensor` with the same type as `a`.\r\n    Raises:\r\n        ValueError: If the shapes of `a`, `b`, and `axes` are incompatible.\r\n        IndexError: If the values in axes exceed the rank of the corresponding\r\n            tensor.\r\n    \"\"\"\r\n\r\n    def _tensordot_reshape(a, axes, flipped=False):\r\n        \"\"\"Helper method to perform transpose and reshape for contraction op.\r\n        This method is helpful in reducing `math_tf.tensordot` to `math_tf.matmul`\r\n        using `tf.transpose` and `tf.reshape`. The method takes a\r\n        tensor and performs the correct transpose and reshape operation for a given\r\n        set of indices. It returns the reshaped tensor as well as a list of indices\r\n        necessary to reshape the tensor again after matrix multiplication.\r\n        Args:\r\n            a: `Tensor`.\r\n            axes: List or `int32` `Tensor` of unique indices specifying valid axes of\r\n             `a`.\r\n            flipped: An optional `bool`. Defaults to `False`. If `True`, the method\r\n                assumes that `a` is the second argument in the contraction operation.\r\n        Returns:\r\n            A tuple `(reshaped_a, free_dims, free_dims_static)` where `reshaped_a` is\r\n            the tensor `a` reshaped to allow contraction via `matmul`, `free_dims` is\r\n            either a list of integers or an `int32` `Tensor`, depending on whether\r\n            the shape of a is fully specified, and free_dims_static is either a list\r\n            of integers and None values, or None, representing the inferred\r\n            static shape of the free dimensions\r\n        \"\"\"\r\n        if a.get_shape().is_fully_defined() and isinstance(axes, (list, tuple)):\r\n            shape_a = a.get_shape().as_list()\r\n            axes = [i if i >= 0 else i + len(shape_a) for i in axes]\r\n            free = [i for i in range(len(shape_a)) if i not in axes]\r\n            free_dims = [shape_a[i] for i in free]\r\n            prod_free = int(np.prod([shape_a[i] for i in free]))\r\n            prod_axes = int(np.prod([shape_a[i] for i in axes]))\r\n            perm = list(axes) + free if flipped else free + list(axes)\r\n            new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\r\n            reshaped_a = tf.reshape(tf.transpose(a, perm), new_shape)\r\n            return reshaped_a, free_dims, free_dims\r\n        else:\r\n            if a.get_shape().ndims is not None and isinstance(axes, (list, tuple)):\r\n                shape_a = a.get_shape().as_list()\r\n                axes = [i if i >= 0 else i + len(shape_a) for i in axes]\r\n                free = [i for i in range(len(shape_a)) if i not in axes]\r\n                free_dims_static = [shape_a[i] for i in free]\r\n            else:\r\n                free_dims_static = None\r\n            shape_a = tf.shape(a)\r\n            rank_a = tf.rank(a)\r\n            axes = tf.convert_to_tensor(axes, dtype=tf.int32, name=\"axes\")\r\n            axes = tf.cast(axes >= 0, tf.int32) * axes + tf.cast(\r\n                    axes < 0, tf.int32) * (\r\n                            axes + rank_a)\r\n            free, _ = tf.setdiff1d(tf.range(rank_a), axes)\r\n            free_dims = tf.gather(shape_a, free)\r\n            axes_dims = tf.gather(shape_a, axes)\r\n            prod_free_dims = tf.reduce_prod(free_dims)\r\n            prod_axes_dims = tf.reduce_prod(axes_dims)\r\n            perm = tf.concat([axes_dims, free_dims], 0)\r\n            if flipped:\r\n                perm = tf.concat([axes, free], 0)\r\n                new_shape = tf.stack([prod_axes_dims, prod_free_dims])\r\n            else:\r\n                perm = tf.concat([free, axes], 0)\r\n                new_shape = tf.stack([prod_free_dims, prod_axes_dims])\r\n            reshaped_a = tf.reshape(tf.transpose(a, perm), new_shape)\r\n            return reshaped_a, free_dims, free_dims_static\r\n\r\n    def _tensordot_axes(a, axes):\r\n        \"\"\"Generates two sets of contraction axes for the two tensor arguments.\"\"\"\r\n        a_shape = a.get_shape()\r\n        if isinstance(axes, compat.integral_types):\r\n            if axes < 0:\r\n                raise ValueError(\"'axes' must be at least 0.\")\r\n            if a_shape.ndims is not None:\r\n                if axes > a_shape.ndims:\r\n                    raise ValueError(\"'axes' must not be larger than the number of \"\r\n                                                     \"dimensions of tensor %s.\" % a)\r\n                return (list(range(a_shape.ndims - axes, a_shape.ndims)),\r\n                                list(range(axes)))\r\n            else:\r\n                rank = tf.rank(a)\r\n                return (range(rank - axes, rank, dtype=tf.int32),\r\n                                range(axes, dtype=tf.int32))\r\n        elif isinstance(axes, (list, tuple)):\r\n            if len(axes) != 2:\r\n                raise ValueError(\"'axes' must be an integer or have length 2.\")\r\n            a_axes = axes[0]\r\n            b_axes = axes[1]\r\n            if isinstance(a_axes, compat.integral_types) and \\\r\n                    isinstance(b_axes, compat.integral_types):\r\n                a_axes = [a_axes]\r\n                b_axes = [b_axes]\r\n            if len(a_axes) != len(b_axes):\r\n                raise ValueError(\r\n                        \"Different number of contraction axes 'a' and 'b', %s != %s.\" %\r\n                        (len(a_axes), len(b_axes)))\r\n            return a_axes, b_axes\r\n        else:\r\n            axes = tf.convert_to_tensor(axes, name=\"axes\", dtype=tf.int32)\r\n        return axes[0], axes[1]\r\n\r\n    def _sparse_tensordot_reshape(a, axes, flipped=False):\r\n        \"\"\"Helper method to perform transpose and reshape for contraction op.\r\n        This method is helpful in reducing `math_tf.tensordot` to `math_tf.matmul`\r\n        using `tf.transpose` and `tf.reshape`. The method takes a\r\n        tensor and performs the correct transpose and reshape operation for a given\r\n        set of indices. It returns the reshaped tensor as well as a list of indices\r\n        necessary to reshape the tensor again after matrix multiplication.\r\n        Args:\r\n            a: `Tensor`.\r\n            axes: List or `int32` `Tensor` of unique indices specifying valid axes of\r\n             `a`.\r\n            flipped: An optional `bool`. Defaults to `False`. If `True`, the method\r\n                assumes that `a` is the second argument in the contraction operation.\r\n        Returns:\r\n            A tuple `(reshaped_a, free_dims, free_dims_static)` where `reshaped_a` is\r\n            the tensor `a` reshaped to allow contraction via `matmul`, `free_dims` is\r\n            either a list of integers or an `int32` `Tensor`, depending on whether\r\n            the shape of a is fully specified, and free_dims_static is either a list\r\n            of integers and None values, or None, representing the inferred\r\n            static shape of the free dimensions\r\n        \"\"\"\r\n        if a.get_shape().is_fully_defined() and isinstance(axes, (list, tuple)):\r\n            shape_a = a.get_shape().as_list()\r\n            axes = [i if i >= 0 else i + len(shape_a) for i in axes]\r\n            free = [i for i in range(len(shape_a)) if i not in axes]\r\n            free_dims = [shape_a[i] for i in free]\r\n            prod_free = int(np.prod([shape_a[i] for i in free]))\r\n            prod_axes = int(np.prod([shape_a[i] for i in axes]))\r\n            perm = list(axes) + free if flipped else free + list(axes)\r\n            new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\r\n            reshaped_a = tf.sparse_reshape(tf.sparse_transpose(a, perm), new_shape)\r\n            return reshaped_a, free_dims, free_dims\r\n        else:\r\n            if a.get_shape().ndims is not None and isinstance(axes, (list, tuple)):\r\n                shape_a = a.get_shape().as_list()\r\n                axes = [i if i >= 0 else i + len(shape_a) for i in axes]\r\n                free = [i for i in range(len(shape_a)) if i not in axes]\r\n                free_dims_static = [shape_a[i] for i in free]\r\n            else:\r\n                free_dims_static = None\r\n            shape_a = tf.shape(a)\r\n            rank_a = tf.rank(a)\r\n            axes = tf.convert_to_tensor(axes, dtype=tf.int32, name=\"axes\")\r\n            axes = tf.cast(axes >= 0, tf.int32) * axes + tf.cast(\r\n                    axes < 0, tf.int32) * (\r\n                            axes + rank_a)\r\n            print(sess.run(rank_a), sess.run(axes))\r\n            free, _ = tf.setdiff1d(tf.range(rank_a), axes)\r\n            free_dims = tf.gather(shape_a, free)\r\n            axes_dims = tf.gather(shape_a, axes)\r\n            prod_free_dims = tf.reduce_prod(free_dims)\r\n            prod_axes_dims = tf.reduce_prod(axes_dims)\r\n            perm = tf.concat([axes_dims, free_dims], 0)\r\n            if flipped:\r\n                perm = tf.concat([axes, free], 0)\r\n                new_shape = tf.stack([prod_axes_dims, prod_free_dims])\r\n            else:\r\n                perm = tf.concat([free, axes], 0)\r\n                new_shape = tf.stack([prod_free_dims, prod_axes_dims])\r\n            reshaped_a = tf.sparse_reshape(tf.sparse_transpose(a, perm), new_shape)\r\n            return reshaped_a, free_dims, free_dims_static\r\n\r\n    def _sparse_tensordot_axes(a, axes):\r\n        \"\"\"Generates two sets of contraction axes for the two tensor arguments.\"\"\"\r\n        a_shape = a.get_shape()\r\n        if isinstance(axes, tf.compat.integral_types):\r\n            if axes < 0:\r\n                raise ValueError(\"'axes' must be at least 0.\")\r\n            if a_shape.ndims is not None:\r\n                if axes > a_shape.ndims:\r\n                    raise ValueError(\"'axes' must not be larger than the number of \"\r\n                                                     \"dimensions of tensor %s.\" % a)\r\n                return (list(range(a_shape.ndims - axes, a_shape.ndims)),\r\n                                list(range(axes)))\r\n            else:\r\n                rank = tf.rank(a)\r\n                return (range(rank - axes, rank, dtype=tf.int32),\r\n                                range(axes, dtype=tf.int32))\r\n        elif isinstance(axes, (list, tuple)):\r\n            if len(axes) != 2:\r\n                raise ValueError(\"'axes' must be an integer or have length 2.\")\r\n            a_axes = axes[0]\r\n            b_axes = axes[1]\r\n            if isinstance(a_axes, compat.integral_types) and \\\r\n                    isinstance(b_axes, compat.integral_types):\r\n                a_axes = [a_axes]\r\n                b_axes = [b_axes]\r\n            if len(a_axes) != len(b_axes):\r\n                raise ValueError(\r\n                        \"Different number of contraction axes 'a' and 'b', %s != %s.\" %\r\n                        (len(a_axes), len(b_axes)))\r\n            return a_axes, b_axes\r\n        else:\r\n            axes = tf.convert_to_tensor(axes, name=\"axes\", dtype=tf.int32)\r\n        return axes[0], axes[1]\r\n\r\n    with tf.name_scope(name, \"SparseTensorDenseTensordot\", [sp_a, b, axes]) as name:\r\n#         a = tf.convert_to_tensor(a, name=\"a\")\r\n        b = tf.convert_to_tensor(b, name=\"b\")\r\n        sp_a_axes, b_axes = _sparse_tensordot_axes(sp_a, axes)\r\n        sp_a_reshape, sp_a_free_dims, sp_a_free_dims_static = _sparse_tensordot_reshape(sp_a, sp_a_axes)\r\n        b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\r\n                b, b_axes, True)\r\n        ab_matmul = tf.sparse_tensor_dense_matmul(sp_a_reshape, b_reshape)\r\n        if isinstance(sp_a_free_dims, list) and isinstance(b_free_dims, list):\r\n            return tf.reshape(ab_matmul, sp_a_free_dims + b_free_dims, name=name)\r\n        else:\r\n            sp_a_free_dims = tf.convert_to_tensor(sp_a_free_dims, dtype=tf.int32)\r\n            b_free_dims = tf.convert_to_tensor(b_free_dims, dtype=tf.int32)\r\n            product = tf.reshape(\r\n                    ab_matmul, tf.concat([sp_a_free_dims, b_free_dims], 0), name=name)\r\n            if sp_a_free_dims_static is not None and b_free_dims_static is not None:\r\n                product.set_shape(sp_a_free_dims_static + b_free_dims_static)\r\n            return product\r\n```\r\n\r\n"}