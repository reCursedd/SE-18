{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/134365039", "pull_request_review_id": 57647119, "id": 134365039, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNDM2NTAzOQ==", "diff_hunk": "@@ -0,0 +1,578 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#include \"tensorflow/contrib/s3/s3_file_system.h\"\n+#include \"tensorflow/contrib/s3/s3_crypto.h\"\n+#include \"tensorflow/core/lib/io/path.h\"\n+\n+#include <aws/core/Aws.h>\n+#include <aws/core/utils/FileSystemUtils.h>\n+#include <aws/s3/S3Client.h>\n+#include <aws/s3/S3Errors.h>\n+#include <aws/s3/model/CopyObjectRequest.h>\n+#include <aws/s3/model/DeleteObjectRequest.h>\n+#include <aws/s3/model/GetObjectRequest.h>\n+#include <aws/s3/model/HeadBucketRequest.h>\n+#include <aws/s3/model/HeadObjectRequest.h>\n+#include <aws/s3/model/ListObjectsRequest.h>\n+#include <aws/s3/model/PutObjectRequest.h>\n+\n+#include <cstdlib>\n+#include <mutex>\n+\n+namespace tensorflow {\n+\n+static const char* S3FileSystemAllocationTag = \"S3FileSystemAllocation\";\n+static const size_t S3ReadAppendableFileBufferSize = 1024 * 1024;\n+static const int S3GetChildrenMaxKeys = 100;\n+\n+Aws::Client::ClientConfiguration& GetDefaultClientConfig() {\n+  static std::mutex cfg_lock;\n+  static bool init(false);\n+  static Aws::Client::ClientConfiguration cfg;\n+\n+  std::lock_guard<std::mutex> lock(cfg_lock);\n+\n+  if (!init) {\n+    const char* endpoint = getenv(\"TFS3_ENDPOINT\");\n+    if (endpoint) {\n+      cfg.endpointOverride = Aws::String(endpoint);\n+    }\n+    const char* region = getenv(\"TFS3_REGION\");\n+    if (region) {\n+      cfg.region = Aws::String(region);\n+    }\n+    const char* use_https = getenv(\"TFS3_USE_HTTPS\");\n+    if (use_https) {\n+      if (use_https[0] == '0') {\n+        cfg.scheme = Aws::Http::Scheme::HTTP;\n+      } else {\n+        cfg.scheme = Aws::Http::Scheme::HTTPS;\n+      }\n+    }\n+    const char* verify_ssl = getenv(\"TFS3_VERIFY_SSL\");\n+    if (verify_ssl) {\n+      if (verify_ssl[0] == '0') {\n+        cfg.verifySSL = false;\n+      } else {\n+        cfg.verifySSL = true;\n+      }\n+    }\n+\n+    init = true;\n+  }\n+\n+  return cfg;\n+};\n+\n+Status ParseS3Path(const string& fname, bool empty_object_ok, string* bucket,\n+                   string* object) {\n+  if (!bucket || !object) {\n+    return errors::Internal(\"bucket and object cannot be null.\");\n+  }\n+  StringPiece scheme, bucketp, objectp;\n+  io::ParseURI(fname, &scheme, &bucketp, &objectp);\n+  if (scheme != \"s3\") {\n+    return errors::InvalidArgument(\"S3 path doesn't start with 's3://': \",\n+                                   fname);\n+  }\n+  *bucket = bucketp.ToString();\n+  if (bucket->empty() || *bucket == \".\") {\n+    return errors::InvalidArgument(\"S3 path doesn't contain a bucket name: \",\n+                                   fname);\n+  }\n+  objectp.Consume(\"/\");\n+  *object = objectp.ToString();\n+  if (!empty_object_ok && object->empty()) {\n+    return errors::InvalidArgument(\"S3 path doesn't contain an object name: \",\n+                                   fname);\n+  }\n+  return Status::OK();\n+}\n+\n+class S3RandomAccessFile : public RandomAccessFile {\n+ public:\n+  S3RandomAccessFile(const string& bucket, const string& object)\n+      : bucket_(bucket), object_(object) {}\n+\n+  Status Read(uint64 offset, size_t n, StringPiece* result,\n+              char* scratch) const override {\n+    Aws::S3::S3Client s3Client(GetDefaultClientConfig());\n+    Aws::S3::Model::GetObjectRequest getObjectRequest;\n+    getObjectRequest.WithBucket(bucket_.c_str()).WithKey(object_.c_str());\n+    char buffer[50];\n+    memset(buffer, 0x00, sizeof(buffer));\n+    snprintf(buffer, sizeof(buffer) - 1, \"bytes=%lld-%lld\", offset,\n+             offset + n - 1);\n+    getObjectRequest.SetRange(buffer);\n+    getObjectRequest.SetResponseStreamFactory([]() {\n+      return Aws::New<Aws::StringStream>(S3FileSystemAllocationTag);\n+    });\n+    auto getObjectOutcome = s3Client.GetObject(getObjectRequest);\n+    if (!getObjectOutcome.IsSuccess()) {\n+      n = 0;\n+      *result = StringPiece(scratch, n);\n+      return Status(error::OUT_OF_RANGE, \"Read less bytes than requested\");\n+    }\n+    n = getObjectOutcome.GetResult().GetContentLength();\n+    std::stringstream ss;\n+    ss << getObjectOutcome.GetResult().GetBody().rdbuf();\n+    ss.read(scratch, n);\n+\n+    *result = StringPiece(scratch, n);\n+    return Status::OK();\n+  }\n+\n+ private:\n+  string bucket_;\n+  string object_;\n+};\n+\n+class S3WritableFile : public WritableFile {\n+ public:\n+  S3WritableFile(const string& bucket, const string& object)\n+      : bucket_(bucket),\n+        object_(object),\n+        sync_needed_(true),\n+        outfile_(Aws::MakeShared<Aws::Utils::TempFile>(\n+            S3FileSystemAllocationTag, \"/tmp/s3_filesystem_XXXXXX\",\n+            std::ios_base::binary | std::ios_base::trunc | std::ios_base::in |\n+                std::ios_base::out)) {}\n+\n+  Status Append(const StringPiece& data) override {\n+    if (!outfile_) {\n+      return errors::FailedPrecondition(\n+          \"The internal temporary file is not writable.\");\n+    }\n+    sync_needed_ = true;\n+    outfile_->write(data.data(), data.size());\n+    if (!outfile_->good()) {\n+      return errors::Internal(\n+          \"Could not append to the internal temporary file.\");\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Close() override {\n+    if (outfile_) {\n+      TF_RETURN_IF_ERROR(Sync());\n+      outfile_.reset();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Flush() override { return Sync(); }\n+\n+  Status Sync() override {\n+    if (!outfile_) {\n+      return errors::FailedPrecondition(\n+          \"The internal temporary file is not writable.\");\n+    }\n+    if (!sync_needed_) {\n+      return Status::OK();\n+    }\n+    Aws::Client::ClientConfiguration clientConfig = GetDefaultClientConfig();\n+    clientConfig.connectTimeoutMs = 300000;\n+    clientConfig.requestTimeoutMs = 600000;\n+    Aws::S3::S3Client s3Client(clientConfig);\n+    Aws::S3::Model::PutObjectRequest putObjectRequest;\n+    putObjectRequest.WithBucket(bucket_.c_str()).WithKey(object_.c_str());\n+    long offset = outfile_->tellp();\n+    outfile_->seekg(0);\n+    putObjectRequest.SetBody(outfile_);\n+    putObjectRequest.SetContentLength(offset);\n+    auto putObjectOutcome = s3Client.PutObject(putObjectRequest);\n+    outfile_->clear();\n+    outfile_->seekp(offset);\n+    if (!putObjectOutcome.IsSuccess()) {\n+      std::stringstream ss;\n+      ss << putObjectOutcome.GetError().GetExceptionName() << \": \"\n+         << putObjectOutcome.GetError().GetMessage();\n+      return errors::Internal(ss.str());\n+    }\n+    return Status::OK();\n+  }\n+\n+ private:\n+  string bucket_;\n+  string object_;\n+  bool sync_needed_;\n+  std::shared_ptr<Aws::Utils::TempFile> outfile_;\n+};\n+\n+class S3ReadOnlyMemoryRegion : public ReadOnlyMemoryRegion {\n+ public:\n+  S3ReadOnlyMemoryRegion(std::unique_ptr<char[]> data, uint64 length)\n+      : data_(std::move(data)), length_(length) {}\n+  const void* data() override { return reinterpret_cast<void*>(data_.get()); }\n+  uint64 length() override { return length_; }\n+\n+ private:\n+  std::unique_ptr<char[]> data_;\n+  uint64 length_;\n+};\n+\n+S3FileSystem::S3FileSystem() {\n+  Aws::SDKOptions options;\n+  options.loggingOptions.logLevel = Aws::Utils::Logging::LogLevel::Info;\n+  options.cryptoOptions.sha256Factory_create_fn = []() {\n+    return Aws::MakeShared<S3SHA256Factory>(S3CryptoAllocationTag);\n+  };\n+  options.cryptoOptions.sha256HMACFactory_create_fn = []() {\n+    return Aws::MakeShared<S3SHA256HmacFactory>(S3CryptoAllocationTag);\n+  };\n+  Aws::InitAPI(options);\n+}\n+\n+S3FileSystem::~S3FileSystem() {\n+  Aws::SDKOptions options;\n+  options.loggingOptions.logLevel = Aws::Utils::Logging::LogLevel::Info;\n+  Aws::ShutdownAPI(options);\n+}\n+\n+Status S3FileSystem::NewRandomAccessFile(\n+    const string& fname, std::unique_ptr<RandomAccessFile>* result) {\n+  string bucket, object;\n+  TF_RETURN_IF_ERROR(ParseS3Path(fname, false, &bucket, &object));\n+  result->reset(new S3RandomAccessFile(bucket, object));\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::NewWritableFile(const string& fname,\n+                                     std::unique_ptr<WritableFile>* result) {\n+  string bucket, object;\n+  TF_RETURN_IF_ERROR(ParseS3Path(fname, false, &bucket, &object));\n+  result->reset(new S3WritableFile(bucket, object));\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::NewAppendableFile(const string& fname,\n+                                       std::unique_ptr<WritableFile>* result) {\n+  std::unique_ptr<RandomAccessFile> reader;\n+  TF_RETURN_IF_ERROR(NewRandomAccessFile(fname, &reader));\n+  std::unique_ptr<char[]> buffer(new char[S3ReadAppendableFileBufferSize]);\n+  Status status;\n+  uint64 offset = 0;\n+  StringPiece read_chunk;\n+\n+  string bucket, object;\n+  TF_RETURN_IF_ERROR(ParseS3Path(fname, false, &bucket, &object));\n+  result->reset(new S3WritableFile(bucket, object));\n+\n+  while (true) {\n+    status = reader->Read(offset, S3ReadAppendableFileBufferSize, &read_chunk,\n+                          buffer.get());\n+    if (status.ok()) {\n+      (*result)->Append(read_chunk);\n+      offset += S3ReadAppendableFileBufferSize;\n+    } else if (status.code() == error::OUT_OF_RANGE) {\n+      (*result)->Append(read_chunk);\n+      break;\n+    } else {\n+      (*result).reset();\n+      return status;\n+    }\n+  }\n+\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::NewReadOnlyMemoryRegionFromFile(\n+    const string& fname, std::unique_ptr<ReadOnlyMemoryRegion>* result) {\n+  uint64 size;\n+  TF_RETURN_IF_ERROR(GetFileSize(fname, &size));\n+  std::unique_ptr<char[]> data(new char[size]);\n+\n+  std::unique_ptr<RandomAccessFile> file;\n+  TF_RETURN_IF_ERROR(NewRandomAccessFile(fname, &file));\n+\n+  StringPiece piece;\n+  TF_RETURN_IF_ERROR(file->Read(0, size, &piece, data.get()));\n+\n+  result->reset(new S3ReadOnlyMemoryRegion(std::move(data), size));\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::FileExists(const string& fname) {\n+  FileStatistics stats;\n+  TF_RETURN_IF_ERROR(this->Stat(fname, &stats));\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::GetChildren(const string& dir,\n+                                 std::vector<string>* result) {\n+  string bucket, prefix;\n+  TF_RETURN_IF_ERROR(ParseS3Path(dir, false, &bucket, &prefix));\n+\n+  if (prefix.back() != '/') {\n+    prefix.push_back('/');\n+  }\n+\n+  Aws::S3::S3Client s3Client(GetDefaultClientConfig());\n+  Aws::S3::Model::ListObjectsRequest listObjectsRequest;\n+  listObjectsRequest.WithBucket(bucket.c_str())\n+      .WithPrefix(prefix.c_str())\n+      .WithMaxKeys(S3GetChildrenMaxKeys)\n+      .WithDelimiter(\"/\");\n+  listObjectsRequest.SetResponseStreamFactory(\n+      []() { return Aws::New<Aws::StringStream>(S3FileSystemAllocationTag); });\n+\n+  Aws::S3::Model::ListObjectsResult listObjectsResult;\n+  do {\n+    auto listObjectsOutcome = s3Client.ListObjects(listObjectsRequest);\n+    if (!listObjectsOutcome.IsSuccess()) {\n+      std::stringstream ss;\n+      ss << listObjectsOutcome.GetError().GetExceptionName() << \": \"\n+         << listObjectsOutcome.GetError().GetMessage();\n+      return errors::Internal(ss.str());\n+    }\n+\n+    listObjectsResult = listObjectsOutcome.GetResult();\n+    for (const auto& object : listObjectsResult.GetCommonPrefixes()) {\n+      Aws::String s = object.GetPrefix();\n+      s.erase(s.length() - 1);\n+      Aws::String entry = s.substr(strlen(prefix.c_str()));\n+      if (entry.length() > 0) {\n+        result->push_back(entry.c_str());\n+      }\n+    }\n+    for (const auto& object : listObjectsResult.GetContents()) {\n+      Aws::String s = object.GetKey();\n+      Aws::String entry = s.substr(strlen(prefix.c_str()));\n+      if (entry.length() > 0) {\n+        result->push_back(entry.c_str());\n+      }\n+    }\n+    listObjectsRequest.SetMarker(listObjectsResult.GetNextMarker());\n+  } while (listObjectsResult.GetIsTruncated());\n+\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::Stat(const string& fname, FileStatistics* stats) {\n+  string bucket, object;\n+  TF_RETURN_IF_ERROR(ParseS3Path(fname, true, &bucket, &object));\n+\n+  Aws::S3::S3Client s3Client(GetDefaultClientConfig());\n+  if (object.empty()) {\n+    Aws::S3::Model::HeadBucketRequest headBucketRequest;\n+    headBucketRequest.WithBucket(bucket.c_str());\n+    auto headBucketOutcome = s3Client.HeadBucket(headBucketRequest);\n+    if (!headBucketOutcome.IsSuccess()) {\n+      std::stringstream ss;\n+      ss << headBucketOutcome.GetError().GetExceptionName() << \": \"\n+         << headBucketOutcome.GetError().GetMessage();\n+      return errors::Internal(ss.str());\n+    }\n+    stats->length = 0;\n+    stats->is_directory = 1;\n+    return Status::OK();\n+  }\n+\n+  bool found = false;\n+\n+  Aws::S3::Model::HeadObjectRequest headObjectRequest;\n+  headObjectRequest.WithBucket(bucket.c_str()).WithKey(object.c_str());\n+  headObjectRequest.SetResponseStreamFactory(\n+      []() { return Aws::New<Aws::StringStream>(S3FileSystemAllocationTag); });\n+  auto headObjectOutcome = s3Client.HeadObject(headObjectRequest);\n+  if (headObjectOutcome.IsSuccess()) {\n+    stats->length = headObjectOutcome.GetResult().GetContentLength();\n+    stats->is_directory = 0;\n+    stats->mtime_nsec =\n+        headObjectOutcome.GetResult().GetLastModified().Millis() * 1e6;\n+    found = true;\n+  }\n+  string prefix = object;\n+  if (prefix.back() != '/') {\n+    prefix.push_back('/');\n+  }\n+  Aws::S3::Model::ListObjectsRequest listObjectsRequest;\n+  listObjectsRequest.WithBucket(bucket.c_str())\n+      .WithPrefix(prefix.c_str())\n+      .WithMaxKeys(1);\n+  listObjectsRequest.SetResponseStreamFactory(\n+      []() { return Aws::New<Aws::StringStream>(S3FileSystemAllocationTag); });\n+  auto listObjectsOutcome = s3Client.ListObjects(listObjectsRequest);\n+  if (listObjectsOutcome.IsSuccess()) {\n+    if (listObjectsOutcome.GetResult().GetContents().size() > 0) {\n+      stats->length = 0;\n+      stats->is_directory = 1;\n+      found = true;\n+    }\n+  }\n+  if (!found) {\n+    return errors::NotFound(\"Object \", fname, \" does not exist\");\n+  }\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::DeleteFile(const string& fname) {\n+  string bucket, object;\n+  TF_RETURN_IF_ERROR(ParseS3Path(fname, false, &bucket, &object));\n+\n+  Aws::S3::S3Client s3Client(GetDefaultClientConfig());\n+  Aws::S3::Model::DeleteObjectRequest deleteObjectRequest;\n+  deleteObjectRequest.WithBucket(bucket.c_str()).WithKey(object.c_str());\n+\n+  auto deleteObjectOutcome = s3Client.DeleteObject(deleteObjectRequest);\n+  if (!deleteObjectOutcome.IsSuccess()) {\n+    std::stringstream ss;\n+    ss << deleteObjectOutcome.GetError().GetExceptionName() << \": \"\n+       << deleteObjectOutcome.GetError().GetMessage();\n+    return errors::Internal(ss.str());\n+  }\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::CreateDir(const string& dirname) {\n+  string bucket, object;\n+  TF_RETURN_IF_ERROR(ParseS3Path(dirname, true, &bucket, &object));\n+\n+  if (object.empty()) {\n+    Aws::S3::S3Client s3Client(GetDefaultClientConfig());\n+    Aws::S3::Model::HeadBucketRequest headBucketRequest;\n+    headBucketRequest.WithBucket(bucket.c_str());\n+    auto headBucketOutcome = s3Client.HeadBucket(headBucketRequest);\n+    if (!headBucketOutcome.IsSuccess()) {\n+      return errors::NotFound(\"The bucket \", bucket, \" was not found.\");\n+    }\n+    return Status::OK();\n+  }\n+  string filename = dirname;\n+  if (filename.back() != '/') {\n+    filename.push_back('/');\n+  }\n+  std::unique_ptr<WritableFile> file;\n+  TF_RETURN_IF_ERROR(NewWritableFile(filename, &file));\n+  TF_RETURN_IF_ERROR(file->Close());\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::DeleteDir(const string& dirname) {\n+  string bucket, object;\n+  TF_RETURN_IF_ERROR(ParseS3Path(dirname, false, &bucket, &object));\n+\n+  Aws::S3::S3Client s3Client(GetDefaultClientConfig());\n+  string prefix = object;\n+  if (prefix.back() != '/') {\n+    prefix.push_back('/');\n+  }\n+  Aws::S3::Model::ListObjectsRequest listObjectsRequest;\n+  listObjectsRequest.WithBucket(bucket.c_str())\n+      .WithPrefix(prefix.c_str())\n+      .WithMaxKeys(2);\n+  listObjectsRequest.SetResponseStreamFactory(\n+      []() { return Aws::New<Aws::StringStream>(S3FileSystemAllocationTag); });\n+  auto listObjectsOutcome = s3Client.ListObjects(listObjectsRequest);\n+  if (listObjectsOutcome.IsSuccess()) {\n+    auto contents = listObjectsOutcome.GetResult().GetContents();\n+    if (contents.size() > 1 ||\n+        (contents.size() == 1 && contents[0].GetKey() != prefix.c_str())) {\n+      return errors::FailedPrecondition(\"Cannot delete a non-empty directory.\");\n+    }\n+    if (contents.size() == 1 && contents[0].GetKey() == prefix.c_str()) {\n+      string filename = dirname;\n+      if (filename.back() != '/') {\n+        filename.push_back('/');\n+      }\n+      return DeleteFile(filename);\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::GetFileSize(const string& fname, uint64* file_size) {\n+  FileStatistics stats;\n+  TF_RETURN_IF_ERROR(this->Stat(fname, &stats));\n+  *file_size = stats.length;\n+  return Status::OK();\n+}\n+\n+Status S3FileSystem::RenameFile(const string& src, const string& target) {\n+  string src_bucket, src_object, target_bucket, target_object;\n+  TF_RETURN_IF_ERROR(ParseS3Path(src, false, &src_bucket, &src_object));\n+  TF_RETURN_IF_ERROR(\n+      ParseS3Path(target, false, &target_bucket, &target_object));\n+  if (src_object.back() == '/') {\n+    if (target_object.back() != '/') {\n+      target_object.push_back('/');\n+    }\n+  } else {\n+    if (target_object.back() == '/') {\n+      target_object.pop_back();\n+    }\n+  }\n+\n+  Aws::S3::S3Client s3Client(GetDefaultClientConfig());\n+\n+  Aws::S3::Model::CopyObjectRequest copyObjectRequest;\n+  Aws::S3::Model::DeleteObjectRequest deleteObjectRequest;\n+\n+  Aws::S3::Model::ListObjectsRequest listObjectsRequest;", "path": "tensorflow/contrib/s3/s3_file_system.cc", "position": 520, "original_position": 523, "commit_id": "2babd181e9899907f5dd018cc1ca84662c650c26", "original_commit_id": "bb65ec0023eb2264f8c24338d667820f47cd3749", "user": {"login": "yongtang", "id": 6932348, "node_id": "MDQ6VXNlcjY5MzIzNDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6932348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongtang", "html_url": "https://github.com/yongtang", "followers_url": "https://api.github.com/users/yongtang/followers", "following_url": "https://api.github.com/users/yongtang/following{/other_user}", "gists_url": "https://api.github.com/users/yongtang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongtang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongtang/subscriptions", "organizations_url": "https://api.github.com/users/yongtang/orgs", "repos_url": "https://api.github.com/users/yongtang/repos", "events_url": "https://api.github.com/users/yongtang/events{/privacy}", "received_events_url": "https://api.github.com/users/yongtang/received_events", "type": "User", "site_admin": false}, "body": "Thanks @jhseu  In the GCS file systems the RenameFile also does the directory rename:\r\nhttps://github.com/tensorflow/tensorflow/blob/0440c77935915fce0d9286ce5e7407b31c6f4975/tensorflow/core/platform/cloud/gcs_file_system.cc#L1154-L1168\r\n", "created_at": "2017-08-22T01:10:42Z", "updated_at": "2017-09-15T01:53:03Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11089#discussion_r134365039", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11089", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/134365039"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11089#discussion_r134365039"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11089"}}, "body_html": "<p>Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=170179\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jhseu\">@jhseu</a>  In the GCS file systems the RenameFile also does the directory rename:<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/0440c77935915fce0d9286ce5e7407b31c6f4975/tensorflow/core/platform/cloud/gcs_file_system.cc#L1154-L1168\">tensorflow/tensorflow/core/platform/cloud/gcs_file_system.cc</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 1154 to 1168\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/0440c77935915fce0d9286ce5e7407b31c6f4975\">0440c77</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L1154\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1154\"></td>\n          <td id=\"LC1154\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> Status <span class=\"pl-en\">GcsFileSystem::RenameFile</span>(<span class=\"pl-k\">const</span> string&amp; src, <span class=\"pl-k\">const</span> string&amp; target) { </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1155\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1155\"></td>\n          <td id=\"LC1155\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-k\">if</span> (!<span class=\"pl-c1\">IsDirectory</span>(src).<span class=\"pl-c1\">ok</span>()) { </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1156\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1156\"></td>\n          <td id=\"LC1156\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">return</span> <span class=\"pl-c1\">RenameObject</span>(src, target); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1157\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1157\"></td>\n          <td id=\"LC1157\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   } </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1158\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1158\"></td>\n          <td id=\"LC1158\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-c\"><span class=\"pl-c\">//</span> Rename all individual objects in the directory one by one.</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1159\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1159\"></td>\n          <td id=\"LC1159\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   std::vector&lt;string&gt; children; </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1160\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1160\"></td>\n          <td id=\"LC1160\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-c1\">TF_RETURN_IF_ERROR</span>( </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1161\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1161\"></td>\n          <td id=\"LC1161\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">       <span class=\"pl-c1\">GetChildrenBounded</span>(src, UINT64_MAX, &amp;children, <span class=\"pl-c1\">true</span> <span class=\"pl-c\"><span class=\"pl-c\">/*</span> recursively <span class=\"pl-c\">*/</span></span>, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1162\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1162\"></td>\n          <td id=\"LC1162\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">                          <span class=\"pl-c1\">true</span> <span class=\"pl-c\"><span class=\"pl-c\">/*</span> include_self_directory_marker <span class=\"pl-c\">*/</span></span>)); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1163\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1163\"></td>\n          <td id=\"LC1163\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-k\">for</span> (<span class=\"pl-k\">const</span> string&amp; subpath : children) { </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1164\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1164\"></td>\n          <td id=\"LC1164\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-c1\">TF_RETURN_IF_ERROR</span>( </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1165\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1165\"></td>\n          <td id=\"LC1165\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">RenameObject</span>(<span class=\"pl-c1\">JoinGcsPath</span>(src, subpath), <span class=\"pl-c1\">JoinGcsPath</span>(target, subpath))); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1166\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1166\"></td>\n          <td id=\"LC1166\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   } </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1167\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1167\"></td>\n          <td id=\"LC1167\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-k\">return</span> <span class=\"pl-c1\">Status::OK</span>(); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L1168\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1168\"></td>\n          <td id=\"LC1168\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> } </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>", "body_text": "Thanks @jhseu  In the GCS file systems the RenameFile also does the directory rename:\n\n  \n    \n      tensorflow/tensorflow/core/platform/cloud/gcs_file_system.cc\n    \n    \n        Lines 1154 to 1168\n      in\n      0440c77\n    \n    \n    \n    \n\n        \n          \n           Status GcsFileSystem::RenameFile(const string& src, const string& target) { \n        \n\n        \n          \n             if (!IsDirectory(src).ok()) { \n        \n\n        \n          \n               return RenameObject(src, target); \n        \n\n        \n          \n             } \n        \n\n        \n          \n             // Rename all individual objects in the directory one by one. \n        \n\n        \n          \n             std::vector<string> children; \n        \n\n        \n          \n             TF_RETURN_IF_ERROR( \n        \n\n        \n          \n                 GetChildrenBounded(src, UINT64_MAX, &children, true /* recursively */, \n        \n\n        \n          \n                                    true /* include_self_directory_marker */)); \n        \n\n        \n          \n             for (const string& subpath : children) { \n        \n\n        \n          \n               TF_RETURN_IF_ERROR( \n        \n\n        \n          \n                   RenameObject(JoinGcsPath(src, subpath), JoinGcsPath(target, subpath))); \n        \n\n        \n          \n             } \n        \n\n        \n          \n             return Status::OK(); \n        \n\n        \n          \n           }", "in_reply_to_id": 133319647}