{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/127643730", "pull_request_review_id": 50247848, "id": 127643730, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyNzY0MzczMA==", "diff_hunk": "@@ -0,0 +1,546 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#include \"tensorflow/core/lib/io/path.h\"\n+#include \"tensorflow/core/platform/env.h\"\n+\n+#include \"tensorflow/contrib/s3/s3_crypto.h\"\n+\n+#include <aws/core/Aws.h>\n+#include <aws/core/utils/FileSystemUtils.h>\n+#include <aws/s3/S3Client.h>\n+#include <aws/s3/S3Errors.h>\n+#include <aws/s3/model/CopyObjectRequest.h>\n+#include <aws/s3/model/DeleteObjectRequest.h>\n+#include <aws/s3/model/GetObjectRequest.h>\n+#include <aws/s3/model/HeadBucketRequest.h>\n+#include <aws/s3/model/HeadObjectRequest.h>\n+#include <aws/s3/model/ListObjectsV2Request.h>\n+#include <aws/s3/model/PutObjectRequest.h>\n+\n+namespace tensorflow {\n+\n+static const char* S3FileSystemAllocationTag = \"S3FileSystemAllocation\";\n+static const size_t S3ReadAppendableFileBufferSize = 1024 * 1024;\n+static const int S3GetChildrenMaxKeys = 100;\n+\n+Status ParseS3Path(const string& fname, bool empty_object_ok, string* bucket,\n+                   string* object) {\n+  if (!bucket || !object) {\n+    return errors::Internal(\"bucket and object cannot be null.\");\n+  }\n+  StringPiece scheme, bucketp, objectp;\n+  io::ParseURI(fname, &scheme, &bucketp, &objectp);\n+  if (scheme != \"s3\") {\n+    return errors::InvalidArgument(\"S3 path doesn't start with 's3://': \",\n+                                   fname);\n+  }\n+  *bucket = bucketp.ToString();\n+  if (bucket->empty() || *bucket == \".\") {\n+    return errors::InvalidArgument(\"S3 path doesn't contain a bucket name: \",\n+                                   fname);\n+  }\n+  objectp.Consume(\"/\");\n+  *object = objectp.ToString();\n+  if (!empty_object_ok && object->empty()) {\n+    return errors::InvalidArgument(\"S3 path doesn't contain an object name: \",\n+                                   fname);\n+  }\n+  return Status::OK();\n+}\n+\n+class S3RandomAccessFile : public RandomAccessFile {\n+ public:\n+  S3RandomAccessFile(const string& bucket, const string& object)\n+      : bucket_(bucket), object_(object) {}\n+\n+  Status Read(uint64 offset, size_t n, StringPiece* result,\n+              char* scratch) const override {\n+    Aws::S3::S3Client s3Client;\n+    Aws::S3::Model::GetObjectRequest getObjectRequest;\n+    getObjectRequest.WithBucket(bucket_.c_str()).WithKey(object_.c_str());\n+    char buffer[50];\n+    memset(buffer, 0x00, sizeof(buffer));\n+    snprintf(buffer, sizeof(buffer) - 1, \"bytes=%lld-%lld\", offset,\n+             offset + n - 1);\n+    getObjectRequest.SetRange(buffer);\n+    getObjectRequest.SetResponseStreamFactory([]() {\n+      return Aws::New<Aws::StringStream>(S3FileSystemAllocationTag);\n+    });\n+    auto getObjectOutcome = s3Client.GetObject(getObjectRequest);\n+    if (!getObjectOutcome.IsSuccess()) {\n+      std::stringstream ss;\n+      ss << getObjectOutcome.GetError().GetExceptionName() << \": \"\n+         << getObjectOutcome.GetError().GetMessage();\n+      return errors::Internal(ss.str());\n+    }\n+    n = getObjectOutcome.GetResult().GetContentLength();\n+    std::stringstream ss;\n+    ss << getObjectOutcome.GetResult().GetBody().rdbuf();\n+    ss.read(scratch, n);\n+\n+    *result = StringPiece(scratch, n);\n+    return Status::OK();\n+  }\n+\n+ private:\n+  string bucket_;\n+  string object_;\n+};\n+\n+class S3WritableFile : public WritableFile {\n+ public:\n+  S3WritableFile(const string& bucket, const string& object)\n+      : bucket_(bucket),\n+        object_(object),\n+        sync_needed_(true),\n+        outfile_(Aws::MakeShared<Aws::Utils::TempFile>(\n+            S3FileSystemAllocationTag, \"/tmp/s3_filesystem_XXXXXX\",\n+            std::ios_base::binary | std::ios_base::trunc | std::ios_base::in |\n+                std::ios_base::out)) {}\n+\n+  Status Append(const StringPiece& data) override {\n+    if (!outfile_) {\n+      return errors::FailedPrecondition(\n+          \"The internal temporary file is not writable.\");\n+    }\n+    sync_needed_ = true;\n+    outfile_->write(data.data(), data.size());\n+    if (!outfile_->good()) {\n+      return errors::Internal(\n+          \"Could not append to the internal temporary file.\");\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Close() override {\n+    if (outfile_) {\n+      TF_RETURN_IF_ERROR(Sync());\n+      outfile_.reset();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Flush() override { return Sync(); }\n+\n+  Status Sync() override {\n+    if (!outfile_) {\n+      return errors::FailedPrecondition(\n+          \"The internal temporary file is not writable.\");\n+    }\n+    if (!sync_needed_) {\n+      return Status::OK();\n+    }\n+    Aws::Client::ClientConfiguration clientConfig;\n+    clientConfig.connectTimeoutMs = 300000;\n+    clientConfig.requestTimeoutMs = 600000;\n+    Aws::S3::S3Client s3Client(clientConfig);\n+    Aws::S3::Model::PutObjectRequest putObjectRequest;\n+    putObjectRequest.WithBucket(bucket_.c_str()).WithKey(object_.c_str());\n+    long offset = outfile_->tellp();\n+    outfile_->seekg(0);\n+    putObjectRequest.SetBody(outfile_);\n+    putObjectRequest.SetContentLength(offset);\n+    auto putObjectOutcome = s3Client.PutObject(putObjectRequest);\n+    outfile_->clear();\n+    outfile_->seekp(offset);\n+    if (!putObjectOutcome.IsSuccess()) {\n+      std::stringstream ss;\n+      ss << putObjectOutcome.GetError().GetExceptionName() << \": \"\n+         << putObjectOutcome.GetError().GetMessage();\n+      return errors::Internal(ss.str());\n+    }\n+    return Status::OK();\n+  }\n+\n+ private:\n+  string bucket_;\n+  string object_;\n+  bool sync_needed_;\n+  std::shared_ptr<Aws::Utils::TempFile> outfile_;\n+};\n+\n+class S3ReadOnlyMemoryRegion : public ReadOnlyMemoryRegion {\n+ public:\n+  S3ReadOnlyMemoryRegion(std::unique_ptr<char[]> data, uint64 length)\n+      : data_(std::move(data)), length_(length) {}\n+  const void* data() override { return reinterpret_cast<void*>(data_.get()); }\n+  uint64 length() override { return length_; }\n+\n+ private:\n+  std::unique_ptr<char[]> data_;\n+  uint64 length_;\n+};\n+\n+class S3FileSystem : public FileSystem {\n+ public:\n+  S3FileSystem() {\n+    Aws::SDKOptions options;\n+    options.loggingOptions.logLevel = Aws::Utils::Logging::LogLevel::Info;\n+    options.cryptoOptions.sha256Factory_create_fn = []() {\n+      return Aws::MakeShared<S3SHA256Factory>(S3CryptoAllocationTag);\n+    };\n+    options.cryptoOptions.sha256HMACFactory_create_fn = []() {\n+      return Aws::MakeShared<S3SHA256HmacFactory>(S3CryptoAllocationTag);\n+    };\n+    Aws::InitAPI(options);\n+  }\n+  ~S3FileSystem() {\n+    Aws::SDKOptions options;\n+    options.loggingOptions.logLevel = Aws::Utils::Logging::LogLevel::Info;\n+    Aws::ShutdownAPI(options);\n+  }\n+  Status NewRandomAccessFile(\n+      const string& fname, std::unique_ptr<RandomAccessFile>* result) override {\n+    string bucket, object;\n+    TF_RETURN_IF_ERROR(ParseS3Path(fname, false, &bucket, &object));\n+    result->reset(new S3RandomAccessFile(bucket, object));\n+    return Status::OK();\n+  }\n+  Status NewWritableFile(const string& fname,\n+                         std::unique_ptr<WritableFile>* result) override {\n+    string bucket, object;\n+    TF_RETURN_IF_ERROR(ParseS3Path(fname, false, &bucket, &object));\n+    result->reset(new S3WritableFile(bucket, object));\n+    return Status::OK();\n+  }\n+\n+  Status NewAppendableFile(const string& fname,\n+                           std::unique_ptr<WritableFile>* result) override {\n+    std::unique_ptr<RandomAccessFile> reader;\n+    TF_RETURN_IF_ERROR(NewRandomAccessFile(fname, &reader));\n+    std::unique_ptr<char[]> buffer(new char[S3ReadAppendableFileBufferSize]);\n+    Status status;\n+    uint64 offset = 0;\n+    StringPiece read_chunk;\n+\n+    string bucket, object;\n+    TF_RETURN_IF_ERROR(ParseS3Path(fname, false, &bucket, &object));\n+    result->reset(new S3WritableFile(bucket, object));\n+\n+    while (true) {\n+      status = reader->Read(offset, S3ReadAppendableFileBufferSize, &read_chunk,\n+                            buffer.get());\n+      if (status.ok()) {\n+        (*result)->Append(read_chunk);\n+        offset += S3ReadAppendableFileBufferSize;\n+      } else if (status.code() == error::OUT_OF_RANGE) {\n+        (*result)->Append(read_chunk);\n+        break;\n+      } else {\n+        (*result).reset();\n+        return status;\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Status NewReadOnlyMemoryRegionFromFile(\n+      const string& fname,\n+      std::unique_ptr<ReadOnlyMemoryRegion>* result) override {\n+    uint64 size;\n+    TF_RETURN_IF_ERROR(GetFileSize(fname, &size));\n+    std::unique_ptr<char[]> data(new char[size]);\n+\n+    std::unique_ptr<RandomAccessFile> file;\n+    TF_RETURN_IF_ERROR(NewRandomAccessFile(fname, &file));\n+\n+    StringPiece piece;\n+    TF_RETURN_IF_ERROR(file->Read(0, size, &piece, data.get()));\n+\n+    result->reset(new S3ReadOnlyMemoryRegion(std::move(data), size));\n+    return Status::OK();\n+  }\n+\n+  Status FileExists(const string& fname) override {\n+    FileStatistics stats;\n+    TF_RETURN_IF_ERROR(this->Stat(fname, &stats));\n+    return Status::OK();\n+  }\n+\n+  Status GetChildren(const string& dir, std::vector<string>* result) override {\n+    string bucket, prefix;\n+    TF_RETURN_IF_ERROR(ParseS3Path(dir, false, &bucket, &prefix));\n+\n+    if (prefix.back() != '/') {\n+      prefix.push_back('/');\n+    }\n+\n+    Aws::S3::S3Client s3Client;\n+    Aws::S3::Model::ListObjectsV2Request listObjectsV2Request;", "path": "tensorflow/contrib/s3/s3_file_system.cc", "position": null, "original_position": 282, "commit_id": "2babd181e9899907f5dd018cc1ca84662c650c26", "original_commit_id": "41db57724b08b7c36f44b0ec3986229af2d1fb97", "user": {"login": "sswv", "id": 529391, "node_id": "MDQ6VXNlcjUyOTM5MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/529391?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sswv", "html_url": "https://github.com/sswv", "followers_url": "https://api.github.com/users/sswv/followers", "following_url": "https://api.github.com/users/sswv/following{/other_user}", "gists_url": "https://api.github.com/users/sswv/gists{/gist_id}", "starred_url": "https://api.github.com/users/sswv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sswv/subscriptions", "organizations_url": "https://api.github.com/users/sswv/orgs", "repos_url": "https://api.github.com/users/sswv/repos", "events_url": "https://api.github.com/users/sswv/events{/privacy}", "received_events_url": "https://api.github.com/users/sswv/received_events", "type": "User", "site_admin": false}, "body": "I noticed that you used `listObjectV2`. In some compatible S3 implementations from 3rd-party, the new V2 interface is not supported. I think it is better to provide an option for using `listObject` (V1). With the V1 inferface, TensorFlow-S3 can work with more 3rd-party S3 implementations.\r\n\r\nI tried to remove all `V2`, and change `ContinuationToken` into `Marker`. It seems working well.\r\n\r\nThanks!", "created_at": "2017-07-17T07:17:42Z", "updated_at": "2017-09-15T01:53:03Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11089#discussion_r127643730", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11089", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/127643730"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11089#discussion_r127643730"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11089"}}, "body_html": "<p>I noticed that you used <code>listObjectV2</code>. In some compatible S3 implementations from 3rd-party, the new V2 interface is not supported. I think it is better to provide an option for using <code>listObject</code> (V1). With the V1 inferface, TensorFlow-S3 can work with more 3rd-party S3 implementations.</p>\n<p>I tried to remove all <code>V2</code>, and change <code>ContinuationToken</code> into <code>Marker</code>. It seems working well.</p>\n<p>Thanks!</p>", "body_text": "I noticed that you used listObjectV2. In some compatible S3 implementations from 3rd-party, the new V2 interface is not supported. I think it is better to provide an option for using listObject (V1). With the V1 inferface, TensorFlow-S3 can work with more 3rd-party S3 implementations.\nI tried to remove all V2, and change ContinuationToken into Marker. It seems working well.\nThanks!"}