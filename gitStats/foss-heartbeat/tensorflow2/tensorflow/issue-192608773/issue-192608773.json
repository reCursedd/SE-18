{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5984", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5984/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5984/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5984/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5984", "id": 192608773, "node_id": "MDU6SXNzdWUxOTI2MDg3NzM=", "number": 5984, "title": "Bug report : tf.contrib.learn.train API has a problem", "user": {"login": "nido4010", "id": 23404351, "node_id": "MDQ6VXNlcjIzNDA0MzUx", "avatar_url": "https://avatars0.githubusercontent.com/u/23404351?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nido4010", "html_url": "https://github.com/nido4010", "followers_url": "https://api.github.com/users/nido4010/followers", "following_url": "https://api.github.com/users/nido4010/following{/other_user}", "gists_url": "https://api.github.com/users/nido4010/gists{/gist_id}", "starred_url": "https://api.github.com/users/nido4010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nido4010/subscriptions", "organizations_url": "https://api.github.com/users/nido4010/orgs", "repos_url": "https://api.github.com/users/nido4010/repos", "events_url": "https://api.github.com/users/nido4010/events{/privacy}", "received_events_url": "https://api.github.com/users/nido4010/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-11-30T16:16:06Z", "updated_at": "2017-09-12T13:06:59Z", "closed_at": "2017-09-12T13:06:22Z", "author_association": "NONE", "body_html": "<p>Hi, everyone</p>\n<p>First, please understand that I cannot speak English well</p>\n<p>I tried to use high-level API(tf.contrib) for code simplicity.<br>\nWhen I use tf.contrib.learn.train API, I find a problem that execution time per batch increases</p>\n<p>An example code is described as below</p>\n<pre><code>tf.conbrib.learn.train(defualt_graph, FLAGS.train_dir, train_op, loss, global_step, max_steps=300,\n                                            supervisor_save_summaries_steps = 100)\n</code></pre>\n<p>when I run above code, execution time per batch increases after step 100.<br>\nSo, I analyzed tf.contrib.learn.train API</p>\n<p>In <strong>graph_actions.py</strong> file, there is train function and this function calls <strong>_train_internal function</strong> in the same file</p>\n<p>In _train_internal function, _run_with_monitors function is called for execution of train_op and monitor</p>\n<p>_run_with_monitors function is described as below</p>\n<pre><code>  for monitor in monitors:\n    tensors +=  monitor.step_begin(step)\n  tensors = list(set(tensors))\n\n  outputs = session.run(tensors, feed_dict=feed_dict)\n  outputs = dict(zip(\n      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],\n      outputs))\n\n  should_stop = False\n  for monitor in monitors:\n    induce_stop = monitor.step_end(step, outputs)\n    should_stop = should_stop or induce_stop\n  return outputs, should_stop\n</code></pre>\n<p>In this function, I examined two functions in class EveryN(monitors.py) : <strong>monitor.step_begin</strong>,  <strong>monitor.step_end</strong></p>\n<p>In monitor.step_begin function, monitor is executed when the following conditions are fulfilled</p>\n<pre><code>    if (step &lt;= self._first_n_steps or\n        step &gt;= (self._every_n_steps + self._last_active_step) or\n        step == self._max_steps):  # Note: max_steps can be None here.\n      self._every_n_step_begin_called = True\n      return self.every_n_step_begin(step)\n</code></pre>\n<p>and monitor.step_end function is described as follows</p>\n<pre><code>  def step_end(self, step, output):\n    super(EveryN, self).step_end(step, output)\n    if self._every_n_step_begin_called:\n      return self.every_n_step_end(step, output)\n    return False\n</code></pre>\n<p>In these codes, I find <strong>self._last_active_step variable</strong> is not updated.<br>\nSo, I add the <strong>monitor.post_step function</strong> in _run_with_monitors function as follows</p>\n<pre><code>  for monitor in monitors:\n    tensors += monitor.step_begin(step)\n  tensors = list(set(tensors))\n\n  outputs = session.run(tensors, feed_dict=feed_dict)\n  outputs = dict(zip(\n      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],\n      outputs))\n\n  should_stop = False\n  for monitor in monitors:\n    induce_stop = monitor.step_end(step, outputs)\n    monitor.post_step(step, session=session)\n    should_stop = should_stop or induce_stop\n  return outputs, should_stop\n</code></pre>\n<p><strong>monitor.post_step function</strong> performs _last_active_step variable update as follows</p>\n<pre><code>  def post_step(self, step, session):\n    super(EveryN, self).post_step(step, session)\n    if self._every_n_step_begin_called:\n      self.every_n_post_step(step, session)\n      self._last_active_step = step\n    self._last_successful_step = step\n</code></pre>\n<p>When the code is revised above, tf.contrib.learn.train function is well operated.</p>", "body_text": "Hi, everyone\nFirst, please understand that I cannot speak English well\nI tried to use high-level API(tf.contrib) for code simplicity.\nWhen I use tf.contrib.learn.train API, I find a problem that execution time per batch increases\nAn example code is described as below\ntf.conbrib.learn.train(defualt_graph, FLAGS.train_dir, train_op, loss, global_step, max_steps=300,\n                                            supervisor_save_summaries_steps = 100)\n\nwhen I run above code, execution time per batch increases after step 100.\nSo, I analyzed tf.contrib.learn.train API\nIn graph_actions.py file, there is train function and this function calls _train_internal function in the same file\nIn _train_internal function, _run_with_monitors function is called for execution of train_op and monitor\n_run_with_monitors function is described as below\n  for monitor in monitors:\n    tensors +=  monitor.step_begin(step)\n  tensors = list(set(tensors))\n\n  outputs = session.run(tensors, feed_dict=feed_dict)\n  outputs = dict(zip(\n      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],\n      outputs))\n\n  should_stop = False\n  for monitor in monitors:\n    induce_stop = monitor.step_end(step, outputs)\n    should_stop = should_stop or induce_stop\n  return outputs, should_stop\n\nIn this function, I examined two functions in class EveryN(monitors.py) : monitor.step_begin,  monitor.step_end\nIn monitor.step_begin function, monitor is executed when the following conditions are fulfilled\n    if (step <= self._first_n_steps or\n        step >= (self._every_n_steps + self._last_active_step) or\n        step == self._max_steps):  # Note: max_steps can be None here.\n      self._every_n_step_begin_called = True\n      return self.every_n_step_begin(step)\n\nand monitor.step_end function is described as follows\n  def step_end(self, step, output):\n    super(EveryN, self).step_end(step, output)\n    if self._every_n_step_begin_called:\n      return self.every_n_step_end(step, output)\n    return False\n\nIn these codes, I find self._last_active_step variable is not updated.\nSo, I add the monitor.post_step function in _run_with_monitors function as follows\n  for monitor in monitors:\n    tensors += monitor.step_begin(step)\n  tensors = list(set(tensors))\n\n  outputs = session.run(tensors, feed_dict=feed_dict)\n  outputs = dict(zip(\n      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],\n      outputs))\n\n  should_stop = False\n  for monitor in monitors:\n    induce_stop = monitor.step_end(step, outputs)\n    monitor.post_step(step, session=session)\n    should_stop = should_stop or induce_stop\n  return outputs, should_stop\n\nmonitor.post_step function performs _last_active_step variable update as follows\n  def post_step(self, step, session):\n    super(EveryN, self).post_step(step, session)\n    if self._every_n_step_begin_called:\n      self.every_n_post_step(step, session)\n      self._last_active_step = step\n    self._last_successful_step = step\n\nWhen the code is revised above, tf.contrib.learn.train function is well operated.", "body": "Hi, everyone\r\n\r\nFirst, please understand that I cannot speak English well\r\n\r\nI tried to use high-level API(tf.contrib) for code simplicity. \r\nWhen I use tf.contrib.learn.train API, I find a problem that execution time per batch increases\r\n\r\nAn example code is described as below \r\n```\r\ntf.conbrib.learn.train(defualt_graph, FLAGS.train_dir, train_op, loss, global_step, max_steps=300,\r\n                                            supervisor_save_summaries_steps = 100)\r\n```\r\n\r\nwhen I run above code, execution time per batch increases after step 100.\r\nSo, I analyzed tf.contrib.learn.train API\r\n\r\nIn **graph_actions.py** file, there is train function and this function calls **_train_internal function** in the same file\r\n\r\nIn _train_internal function, _run_with_monitors function is called for execution of train_op and monitor\r\n\r\n_run_with_monitors function is described as below\r\n```\r\n  for monitor in monitors:\r\n    tensors +=  monitor.step_begin(step)\r\n  tensors = list(set(tensors))\r\n\r\n  outputs = session.run(tensors, feed_dict=feed_dict)\r\n  outputs = dict(zip(\r\n      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],\r\n      outputs))\r\n\r\n  should_stop = False\r\n  for monitor in monitors:\r\n    induce_stop = monitor.step_end(step, outputs)\r\n    should_stop = should_stop or induce_stop\r\n  return outputs, should_stop\r\n```\r\nIn this function, I examined two functions in class EveryN(monitors.py) : **monitor.step_begin**,  **monitor.step_end**\r\n\r\nIn monitor.step_begin function, monitor is executed when the following conditions are fulfilled\r\n```\r\n    if (step <= self._first_n_steps or\r\n        step >= (self._every_n_steps + self._last_active_step) or\r\n        step == self._max_steps):  # Note: max_steps can be None here.\r\n      self._every_n_step_begin_called = True\r\n      return self.every_n_step_begin(step)\r\n```\r\nand monitor.step_end function is described as follows\r\n```\r\n  def step_end(self, step, output):\r\n    super(EveryN, self).step_end(step, output)\r\n    if self._every_n_step_begin_called:\r\n      return self.every_n_step_end(step, output)\r\n    return False\r\n```\r\nIn these codes, I find **self._last_active_step variable** is not updated.\r\nSo, I add the **monitor.post_step function** in _run_with_monitors function as follows\r\n```\r\n  for monitor in monitors:\r\n    tensors += monitor.step_begin(step)\r\n  tensors = list(set(tensors))\r\n\r\n  outputs = session.run(tensors, feed_dict=feed_dict)\r\n  outputs = dict(zip(\r\n      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],\r\n      outputs))\r\n\r\n  should_stop = False\r\n  for monitor in monitors:\r\n    induce_stop = monitor.step_end(step, outputs)\r\n    monitor.post_step(step, session=session)\r\n    should_stop = should_stop or induce_stop\r\n  return outputs, should_stop\r\n```\r\n**monitor.post_step function** performs _last_active_step variable update as follows\r\n```\r\n  def post_step(self, step, session):\r\n    super(EveryN, self).post_step(step, session)\r\n    if self._every_n_step_begin_called:\r\n      self.every_n_post_step(step, session)\r\n      self._last_active_step = step\r\n    self._last_successful_step = step\r\n```\r\n\r\nWhen the code is revised above, tf.contrib.learn.train function is well operated.\r\n"}