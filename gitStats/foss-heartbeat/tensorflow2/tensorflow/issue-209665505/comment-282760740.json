{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/282760740", "html_url": "https://github.com/tensorflow/tensorflow/issues/7808#issuecomment-282760740", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7808", "id": 282760740, "node_id": "MDEyOklzc3VlQ29tbWVudDI4Mjc2MDc0MA==", "user": {"login": "hawkinsp", "id": 348932, "node_id": "MDQ6VXNlcjM0ODkzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/348932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hawkinsp", "html_url": "https://github.com/hawkinsp", "followers_url": "https://api.github.com/users/hawkinsp/followers", "following_url": "https://api.github.com/users/hawkinsp/following{/other_user}", "gists_url": "https://api.github.com/users/hawkinsp/gists{/gist_id}", "starred_url": "https://api.github.com/users/hawkinsp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hawkinsp/subscriptions", "organizations_url": "https://api.github.com/users/hawkinsp/orgs", "repos_url": "https://api.github.com/users/hawkinsp/repos", "events_url": "https://api.github.com/users/hawkinsp/events{/privacy}", "received_events_url": "https://api.github.com/users/hawkinsp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-27T15:55:39Z", "updated_at": "2017-02-27T15:55:39Z", "author_association": "MEMBER", "body_html": "<p>This is expected but I would agree that it isn't desirable.</p>\n<p>A workaround for now is to build //tensorflow -//tensorflow/compiler/...</p>\n<p>To fix this, the best idea I have is to add xla variants of all the BUILD rules in //tensorflow/compiler/...<br>\ne.g., replace cc_library() rules with xla_cc_library() rules, where xla_cc_library() expands to cc_library() if XLA is enabled, or to nothing, otherwise. This is tedious but should work.</p>\n<p>A lighter-weight variant of the proposal above might be to only wrap the XLA CPU and GPU backends, which are the pieces that depend on LLVM. You would still end up building the common parts of XLA, but those parts of XLA are small and quick to build compared to the big LLVM dependency. I'll try this out and see how feasible it is.</p>", "body_text": "This is expected but I would agree that it isn't desirable.\nA workaround for now is to build //tensorflow -//tensorflow/compiler/...\nTo fix this, the best idea I have is to add xla variants of all the BUILD rules in //tensorflow/compiler/...\ne.g., replace cc_library() rules with xla_cc_library() rules, where xla_cc_library() expands to cc_library() if XLA is enabled, or to nothing, otherwise. This is tedious but should work.\nA lighter-weight variant of the proposal above might be to only wrap the XLA CPU and GPU backends, which are the pieces that depend on LLVM. You would still end up building the common parts of XLA, but those parts of XLA are small and quick to build compared to the big LLVM dependency. I'll try this out and see how feasible it is.", "body": "This is expected but I would agree that it isn't desirable.\r\n\r\nA workaround for now is to build //tensorflow -//tensorflow/compiler/...\r\n\r\nTo fix this, the best idea I have is to add xla variants of all the BUILD rules in //tensorflow/compiler/...\r\ne.g., replace cc_library() rules with xla_cc_library() rules, where xla_cc_library() expands to cc_library() if XLA is enabled, or to nothing, otherwise. This is tedious but should work.\r\n\r\nA lighter-weight variant of the proposal above might be to only wrap the XLA CPU and GPU backends, which are the pieces that depend on LLVM. You would still end up building the common parts of XLA, but those parts of XLA are small and quick to build compared to the big LLVM dependency. I'll try this out and see how feasible it is."}