{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/330987983", "html_url": "https://github.com/tensorflow/tensorflow/issues/6271#issuecomment-330987983", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6271", "id": 330987983, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDk4Nzk4Mw==", "user": {"login": "jorisguerin", "id": 24939106, "node_id": "MDQ6VXNlcjI0OTM5MTA2", "avatar_url": "https://avatars1.githubusercontent.com/u/24939106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorisguerin", "html_url": "https://github.com/jorisguerin", "followers_url": "https://api.github.com/users/jorisguerin/followers", "following_url": "https://api.github.com/users/jorisguerin/following{/other_user}", "gists_url": "https://api.github.com/users/jorisguerin/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorisguerin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorisguerin/subscriptions", "organizations_url": "https://api.github.com/users/jorisguerin/orgs", "repos_url": "https://api.github.com/users/jorisguerin/repos", "events_url": "https://api.github.com/users/jorisguerin/events{/privacy}", "received_events_url": "https://api.github.com/users/jorisguerin/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-20T21:35:36Z", "updated_at": "2017-09-20T21:35:36Z", "author_association": "NONE", "body_html": "<p>Hi everyone,</p>\n<p>I have implemented the spatial softmax as well, in a similar fashion that proposed here.<br>\nIt works well in the forward pass. However, whenever trying to train a network containing this layer, it appears that after a single pass, it outputs either the center point or one of the corners.</p>\n<p>Does anyone have an idea of what might cause this behavior? Any possible fixes?</p>\n<p>The function I use is the following:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">spatial_softArgmax</span>(<span class=\"pl-smi\">filters</span>, <span class=\"pl-smi\">temperature</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1.0</span>):\n    \n    shape <span class=\"pl-k\">=</span> tf.shape(filters)\n    height, width, num_channels <span class=\"pl-k\">=</span> shape[<span class=\"pl-c1\">1</span>], shape[<span class=\"pl-c1\">2</span>], shape[<span class=\"pl-c1\">3</span>]\n    \n    posx, posy <span class=\"pl-k\">=</span> tf.meshgrid(tf.lin_space(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-v\">num</span> <span class=\"pl-k\">=</span> height), \n                             tf.lin_space(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-v\">num</span> <span class=\"pl-k\">=</span> width))\n    \n    posx <span class=\"pl-k\">=</span> tf.reshape(posx, [height <span class=\"pl-k\">*</span> width])\n    posy <span class=\"pl-k\">=</span> tf.reshape(posy, [height <span class=\"pl-k\">*</span> width])\n    \n    filters <span class=\"pl-k\">=</span> tf.reshape(tf.transpose(filters, [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>]), [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, height <span class=\"pl-k\">*</span> width])\n    \n    softmax_attention <span class=\"pl-k\">=</span> tf.nn.softmax(filters <span class=\"pl-k\">/</span> temperature)\n    \n    expected_x <span class=\"pl-k\">=</span> tf.reduce_sum(posx <span class=\"pl-k\">*</span> softmax_attention, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keep_dims</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>)\n    expected_y <span class=\"pl-k\">=</span> tf.reduce_sum(posy <span class=\"pl-k\">*</span> softmax_attention, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keep_dims</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>)\n    \n    expected_xy <span class=\"pl-k\">=</span> tf.concat([expected_x, expected_y], <span class=\"pl-v\">axis</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>)\n    \n    feature_keypoints <span class=\"pl-k\">=</span> tf.reshape(expected_xy, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, num_channels <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span>])\n\n    <span class=\"pl-k\">return</span> feature_keypoints</pre></div>", "body_text": "Hi everyone,\nI have implemented the spatial softmax as well, in a similar fashion that proposed here.\nIt works well in the forward pass. However, whenever trying to train a network containing this layer, it appears that after a single pass, it outputs either the center point or one of the corners.\nDoes anyone have an idea of what might cause this behavior? Any possible fixes?\nThe function I use is the following:\ndef spatial_softArgmax(filters, temperature = 1.0):\n    \n    shape = tf.shape(filters)\n    height, width, num_channels = shape[1], shape[2], shape[3]\n    \n    posx, posy = tf.meshgrid(tf.lin_space(-1., 1., num = height), \n                             tf.lin_space(-1., 1., num = width))\n    \n    posx = tf.reshape(posx, [height * width])\n    posy = tf.reshape(posy, [height * width])\n    \n    filters = tf.reshape(tf.transpose(filters, [0, 3, 1, 2]), [-1, height * width])\n    \n    softmax_attention = tf.nn.softmax(filters / temperature)\n    \n    expected_x = tf.reduce_sum(posx * softmax_attention, 1, keep_dims = True)\n    expected_y = tf.reduce_sum(posy * softmax_attention, 1, keep_dims = True)\n    \n    expected_xy = tf.concat([expected_x, expected_y], axis = 1)\n    \n    feature_keypoints = tf.reshape(expected_xy, [-1, num_channels * 2])\n\n    return feature_keypoints", "body": "Hi everyone,\r\n\r\nI have implemented the spatial softmax as well, in a similar fashion that proposed here.\r\nIt works well in the forward pass. However, whenever trying to train a network containing this layer, it appears that after a single pass, it outputs either the center point or one of the corners.\r\n\r\nDoes anyone have an idea of what might cause this behavior? Any possible fixes?\r\n\r\nThe function I use is the following:\r\n\r\n```python\r\ndef spatial_softArgmax(filters, temperature = 1.0):\r\n    \r\n    shape = tf.shape(filters)\r\n    height, width, num_channels = shape[1], shape[2], shape[3]\r\n    \r\n    posx, posy = tf.meshgrid(tf.lin_space(-1., 1., num = height), \r\n                             tf.lin_space(-1., 1., num = width))\r\n    \r\n    posx = tf.reshape(posx, [height * width])\r\n    posy = tf.reshape(posy, [height * width])\r\n    \r\n    filters = tf.reshape(tf.transpose(filters, [0, 3, 1, 2]), [-1, height * width])\r\n    \r\n    softmax_attention = tf.nn.softmax(filters / temperature)\r\n    \r\n    expected_x = tf.reduce_sum(posx * softmax_attention, 1, keep_dims = True)\r\n    expected_y = tf.reduce_sum(posy * softmax_attention, 1, keep_dims = True)\r\n    \r\n    expected_xy = tf.concat([expected_x, expected_y], axis = 1)\r\n    \r\n    feature_keypoints = tf.reshape(expected_xy, [-1, num_channels * 2])\r\n\r\n    return feature_keypoints\r\n```"}