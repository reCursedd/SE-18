{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6271", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6271/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6271/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6271/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6271", "id": 195137816, "node_id": "MDU6SXNzdWUxOTUxMzc4MTY=", "number": 6271, "title": "Request for spatial softmax implementation", "user": {"login": "ahundt", "id": 55744, "node_id": "MDQ6VXNlcjU1NzQ0", "avatar_url": "https://avatars1.githubusercontent.com/u/55744?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahundt", "html_url": "https://github.com/ahundt", "followers_url": "https://api.github.com/users/ahundt/followers", "following_url": "https://api.github.com/users/ahundt/following{/other_user}", "gists_url": "https://api.github.com/users/ahundt/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahundt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahundt/subscriptions", "organizations_url": "https://api.github.com/users/ahundt/orgs", "repos_url": "https://api.github.com/users/ahundt/repos", "events_url": "https://api.github.com/users/ahundt/events{/privacy}", "received_events_url": "https://api.github.com/users/ahundt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-12-13T01:48:59Z", "updated_at": "2017-11-03T02:06:32Z", "closed_at": "2016-12-13T23:22:36Z", "author_association": "NONE", "body_html": "<p>Spatial softmax is defined in <a href=\"https://arxiv.org/abs/1504.00702\" rel=\"nofollow\">End-to-End Training of Deep Visuomotor Policies</a>. This is a request for an implementation in the TensorFlow API, or if the dimension flag for the <a href=\"https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#softmax\" rel=\"nofollow\">regular softmax</a> does this, could the term and an example be explicitly added to the g3doc?</p>\n<p>It seems this may already be implemented with tf but not yet incorporated upstream according to <a href=\"https://arxiv.org/pdf/1610.00673.pdf\" rel=\"nofollow\">Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search</a>:</p>\n<blockquote>\n<p>This entire system, which we call asynchronous distributed<br>\nguided policy search (ADGPS), was implemented in the<br>\ndistributed machine learning framework TensorFlow [...snip...]<br>\nOur architecture resembles prior work, with the visual features<br>\nrepresented by feature points produced via a spatial softmax<br>\napplied to the last convolutional<br>\nresponse maps.</p>\n</blockquote>", "body_text": "Spatial softmax is defined in End-to-End Training of Deep Visuomotor Policies. This is a request for an implementation in the TensorFlow API, or if the dimension flag for the regular softmax does this, could the term and an example be explicitly added to the g3doc?\nIt seems this may already be implemented with tf but not yet incorporated upstream according to Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search:\n\nThis entire system, which we call asynchronous distributed\nguided policy search (ADGPS), was implemented in the\ndistributed machine learning framework TensorFlow [...snip...]\nOur architecture resembles prior work, with the visual features\nrepresented by feature points produced via a spatial softmax\napplied to the last convolutional\nresponse maps.", "body": "Spatial softmax is defined in [End-to-End Training of Deep Visuomotor Policies](https://arxiv.org/abs/1504.00702). This is a request for an implementation in the TensorFlow API, or if the dimension flag for the [regular softmax](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#softmax) does this, could the term and an example be explicitly added to the g3doc?\r\n\r\nIt seems this may already be implemented with tf but not yet incorporated upstream according to [Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search](https://arxiv.org/pdf/1610.00673.pdf):\r\n\r\n> This entire system, which we call asynchronous distributed\r\nguided policy search (ADGPS), was implemented in the\r\ndistributed machine learning framework TensorFlow [...snip...] \r\nOur architecture resembles prior work, with the visual features \r\nrepresented by feature points produced via a spatial softmax\r\napplied to the last convolutional\r\nresponse maps."}