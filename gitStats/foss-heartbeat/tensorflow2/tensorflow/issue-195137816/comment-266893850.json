{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/266893850", "html_url": "https://github.com/tensorflow/tensorflow/issues/6271#issuecomment-266893850", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6271", "id": 266893850, "node_id": "MDEyOklzc3VlQ29tbWVudDI2Njg5Mzg1MA==", "user": {"login": "kalakris", "id": 372943, "node_id": "MDQ6VXNlcjM3Mjk0Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/372943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kalakris", "html_url": "https://github.com/kalakris", "followers_url": "https://api.github.com/users/kalakris/followers", "following_url": "https://api.github.com/users/kalakris/following{/other_user}", "gists_url": "https://api.github.com/users/kalakris/gists{/gist_id}", "starred_url": "https://api.github.com/users/kalakris/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kalakris/subscriptions", "organizations_url": "https://api.github.com/users/kalakris/orgs", "repos_url": "https://api.github.com/users/kalakris/repos", "events_url": "https://api.github.com/users/kalakris/events{/privacy}", "received_events_url": "https://api.github.com/users/kalakris/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-13T23:20:45Z", "updated_at": "2016-12-13T23:20:45Z", "author_association": "MEMBER", "body_html": "<p>The term \"spatial softmax\" is a bit of a misnomer - it should have probably been called spatial soft-argmax, since it's function is to return the expected pixel locations of each feature map. The softmax with the dim flag is not enough in itself, but is a useful tool in implementing the spatial soft-argmax. This can be achieved using a few lines of code in stock TensorFlow. You can first compute the spatial softmax of the features over the image dimensions with a little reshaping and transposing of the input:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Assume features is of size [N, H, W, C] (batch_size, height, width, channels).</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Transpose it to [N, C, H, W], then reshape to [N * C, H * W] to compute softmax</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> jointly over the image dimensions. </span>\nfeatures <span class=\"pl-k\">=</span> tf.reshape(tf.transpose(features, [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>]), [N <span class=\"pl-k\">*</span> C, H <span class=\"pl-k\">*</span> W])\nsoftmax <span class=\"pl-k\">=</span> tf.nn.softmax(features)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Reshape and transpose back to original format.</span>\nsoftmax <span class=\"pl-k\">=</span> tf.transpose(tf.reshape(softmax, [N, C, H, W]), [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>])</pre></div>\n<p>The above is the spatial softmax, which can be used as weights to compute the mean pixel locations of each channel as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Assume that image_coords is a tensor of size [H, W, 2] representing the image</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> coordinates of each pixel.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Convert softmax to shape [N, H, W, C, 1]</span>\nsoftmax <span class=\"pl-k\">=</span> tf.expand_dims(softmax, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Convert image coords to shape [H, W, 1, 2]</span>\nimage_coords <span class=\"pl-k\">=</span> tf.expand_dims(image_coords, <span class=\"pl-c1\">2</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Multiply (with broadcasting) and reduce over image dimensions to get the result</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> of shape [N, C, 2]</span>\nspatial_soft_argmax <span class=\"pl-k\">=</span> tf.reduce_sum(softmax <span class=\"pl-k\">*</span> image_coords, <span class=\"pl-v\">reduction_indices</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>])</pre></div>\n<p>Hope this helps.</p>", "body_text": "The term \"spatial softmax\" is a bit of a misnomer - it should have probably been called spatial soft-argmax, since it's function is to return the expected pixel locations of each feature map. The softmax with the dim flag is not enough in itself, but is a useful tool in implementing the spatial soft-argmax. This can be achieved using a few lines of code in stock TensorFlow. You can first compute the spatial softmax of the features over the image dimensions with a little reshaping and transposing of the input:\n# Assume features is of size [N, H, W, C] (batch_size, height, width, channels).\n# Transpose it to [N, C, H, W], then reshape to [N * C, H * W] to compute softmax\n# jointly over the image dimensions. \nfeatures = tf.reshape(tf.transpose(features, [0, 3, 1, 2]), [N * C, H * W])\nsoftmax = tf.nn.softmax(features)\n# Reshape and transpose back to original format.\nsoftmax = tf.transpose(tf.reshape(softmax, [N, C, H, W]), [0, 2, 3, 1])\nThe above is the spatial softmax, which can be used as weights to compute the mean pixel locations of each channel as follows:\n# Assume that image_coords is a tensor of size [H, W, 2] representing the image\n# coordinates of each pixel.\n# Convert softmax to shape [N, H, W, C, 1]\nsoftmax = tf.expand_dims(softmax, -1)\n# Convert image coords to shape [H, W, 1, 2]\nimage_coords = tf.expand_dims(image_coords, 2)\n# Multiply (with broadcasting) and reduce over image dimensions to get the result\n# of shape [N, C, 2]\nspatial_soft_argmax = tf.reduce_sum(softmax * image_coords, reduction_indices=[1, 2])\nHope this helps.", "body": "The term \"spatial softmax\" is a bit of a misnomer - it should have probably been called spatial soft-argmax, since it's function is to return the expected pixel locations of each feature map. The softmax with the dim flag is not enough in itself, but is a useful tool in implementing the spatial soft-argmax. This can be achieved using a few lines of code in stock TensorFlow. You can first compute the spatial softmax of the features over the image dimensions with a little reshaping and transposing of the input:\r\n\r\n```python\r\n# Assume features is of size [N, H, W, C] (batch_size, height, width, channels).\r\n# Transpose it to [N, C, H, W], then reshape to [N * C, H * W] to compute softmax\r\n# jointly over the image dimensions. \r\nfeatures = tf.reshape(tf.transpose(features, [0, 3, 1, 2]), [N * C, H * W])\r\nsoftmax = tf.nn.softmax(features)\r\n# Reshape and transpose back to original format.\r\nsoftmax = tf.transpose(tf.reshape(softmax, [N, C, H, W]), [0, 2, 3, 1])\r\n```\r\n\r\nThe above is the spatial softmax, which can be used as weights to compute the mean pixel locations of each channel as follows:\r\n\r\n```python\r\n# Assume that image_coords is a tensor of size [H, W, 2] representing the image\r\n# coordinates of each pixel.\r\n# Convert softmax to shape [N, H, W, C, 1]\r\nsoftmax = tf.expand_dims(softmax, -1)\r\n# Convert image coords to shape [H, W, 1, 2]\r\nimage_coords = tf.expand_dims(image_coords, 2)\r\n# Multiply (with broadcasting) and reduce over image dimensions to get the result\r\n# of shape [N, C, 2]\r\nspatial_soft_argmax = tf.reduce_sum(softmax * image_coords, reduction_indices=[1, 2])\r\n```\r\n\r\nHope this helps."}