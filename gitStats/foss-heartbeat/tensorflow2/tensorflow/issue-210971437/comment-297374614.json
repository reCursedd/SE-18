{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/297374614", "html_url": "https://github.com/tensorflow/tensorflow/issues/7958#issuecomment-297374614", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7958", "id": 297374614, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NzM3NDYxNA==", "user": {"login": "ajtulloch", "id": 1121581, "node_id": "MDQ6VXNlcjExMjE1ODE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1121581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajtulloch", "html_url": "https://github.com/ajtulloch", "followers_url": "https://api.github.com/users/ajtulloch/followers", "following_url": "https://api.github.com/users/ajtulloch/following{/other_user}", "gists_url": "https://api.github.com/users/ajtulloch/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajtulloch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajtulloch/subscriptions", "organizations_url": "https://api.github.com/users/ajtulloch/orgs", "repos_url": "https://api.github.com/users/ajtulloch/repos", "events_url": "https://api.github.com/users/ajtulloch/events{/privacy}", "received_events_url": "https://api.github.com/users/ajtulloch/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-26T11:45:34Z", "updated_at": "2017-04-26T15:59:52Z", "author_association": "NONE", "body_html": "<ul>\n<li>Re. textures - makes sense. When would you use <code>MPSImage</code> in that case? In the C2 approach, all the intermediate states are transient/unobservable, and are only observable via a copy (which is also the synchronization point), so there's no need for textures that persist outside the lifetime of the command buffer (which is what MPSImage would give you?).</li>\n<li>Re. memory management: yes, it seems pretty solid. I experimented with the <a href=\"https://developer.apple.com/reference/metalperformanceshaders/mpstemporaryimage/2097544-prefetchstorage\" rel=\"nofollow\"><code>MPSTemporaryImage:prefetchStorage</code></a> call but didn't get a perf win on any of the models I was using, which seemed surprising and I wonder if I was misusing the API.  Have you got a win out of this API at all?</li>\n<li>Re. double buffering - I was thinking of having an async API that takes a complete metal compute graph, then preallocates a pool of buffers and net/session instances, and spins up a background thread that repeatedly constructs all the commands with respect to the stable pointer and enqueues the resulting <code>MLTCommandBuffer/MTLBuffer</code> back to the caller thread.  Then, the client code just needs to do a memcpy from the caller data -&gt; buffer + encode command buffer + wait, which I believe should be a win in the scenarios I was looking at. Does that make sense? I think a bunch of these applications are caveated on being able to execute the entire computation graph on the Metal device, which is what I was targeting for a bunch of our applications but might not be applicable for other applications.</li>\n</ul>", "body_text": "Re. textures - makes sense. When would you use MPSImage in that case? In the C2 approach, all the intermediate states are transient/unobservable, and are only observable via a copy (which is also the synchronization point), so there's no need for textures that persist outside the lifetime of the command buffer (which is what MPSImage would give you?).\nRe. memory management: yes, it seems pretty solid. I experimented with the MPSTemporaryImage:prefetchStorage call but didn't get a perf win on any of the models I was using, which seemed surprising and I wonder if I was misusing the API.  Have you got a win out of this API at all?\nRe. double buffering - I was thinking of having an async API that takes a complete metal compute graph, then preallocates a pool of buffers and net/session instances, and spins up a background thread that repeatedly constructs all the commands with respect to the stable pointer and enqueues the resulting MLTCommandBuffer/MTLBuffer back to the caller thread.  Then, the client code just needs to do a memcpy from the caller data -> buffer + encode command buffer + wait, which I believe should be a win in the scenarios I was looking at. Does that make sense? I think a bunch of these applications are caveated on being able to execute the entire computation graph on the Metal device, which is what I was targeting for a bunch of our applications but might not be applicable for other applications.", "body": "- Re. textures - makes sense. When would you use `MPSImage` in that case? In the C2 approach, all the intermediate states are transient/unobservable, and are only observable via a copy (which is also the synchronization point), so there's no need for textures that persist outside the lifetime of the command buffer (which is what MPSImage would give you?).\r\n- Re. memory management: yes, it seems pretty solid. I experimented with the [`MPSTemporaryImage:prefetchStorage`](https://developer.apple.com/reference/metalperformanceshaders/mpstemporaryimage/2097544-prefetchstorage) call but didn't get a perf win on any of the models I was using, which seemed surprising and I wonder if I was misusing the API.  Have you got a win out of this API at all?\r\n- Re. double buffering - I was thinking of having an async API that takes a complete metal compute graph, then preallocates a pool of buffers and net/session instances, and spins up a background thread that repeatedly constructs all the commands with respect to the stable pointer and enqueues the resulting `MLTCommandBuffer/MTLBuffer` back to the caller thread.  Then, the client code just needs to do a memcpy from the caller data -> buffer + encode command buffer + wait, which I believe should be a win in the scenarios I was looking at. Does that make sense? I think a bunch of these applications are caveated on being able to execute the entire computation graph on the Metal device, which is what I was targeting for a bunch of our applications but might not be applicable for other applications.\r\n\r\n"}