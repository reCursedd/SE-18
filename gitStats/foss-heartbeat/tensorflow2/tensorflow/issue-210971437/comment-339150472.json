{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/339150472", "html_url": "https://github.com/tensorflow/tensorflow/issues/7958#issuecomment-339150472", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7958", "id": 339150472, "node_id": "MDEyOklzc3VlQ29tbWVudDMzOTE1MDQ3Mg==", "user": {"login": "ajtulloch", "id": 1121581, "node_id": "MDQ6VXNlcjExMjE1ODE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1121581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajtulloch", "html_url": "https://github.com/ajtulloch", "followers_url": "https://api.github.com/users/ajtulloch/followers", "following_url": "https://api.github.com/users/ajtulloch/following{/other_user}", "gists_url": "https://api.github.com/users/ajtulloch/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajtulloch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajtulloch/subscriptions", "organizations_url": "https://api.github.com/users/ajtulloch/orgs", "repos_url": "https://api.github.com/users/ajtulloch/repos", "events_url": "https://api.github.com/users/ajtulloch/events{/privacy}", "received_events_url": "https://api.github.com/users/ajtulloch/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-24T22:11:37Z", "updated_at": "2017-10-24T22:11:37Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=633447\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ofirbb\">@ofirbb</a> interesting.</p>\n<ul>\n<li>Re: prefetching - how did you select the descriptors to prefetch?  Seems to trade off heap size vs time spent allocating right?</li>\n<li>Re: preencoding/double buffering - we do something similar for models like Mask R-CNN, where we run parts of the graph on the CPU and parts on the GPU. Not very cleanly abstrated though.</li>\n<li>Re: texture2d/2d_array - cool stuff. I was thinking of just a minor refactor to go to single kernel and keep using function_constants to select array/non-array, but if there's some nice template abstractions that's pretty neat.</li>\n</ul>", "body_text": "@ofirbb interesting.\n\nRe: prefetching - how did you select the descriptors to prefetch?  Seems to trade off heap size vs time spent allocating right?\nRe: preencoding/double buffering - we do something similar for models like Mask R-CNN, where we run parts of the graph on the CPU and parts on the GPU. Not very cleanly abstrated though.\nRe: texture2d/2d_array - cool stuff. I was thinking of just a minor refactor to go to single kernel and keep using function_constants to select array/non-array, but if there's some nice template abstractions that's pretty neat.", "body": "@ofirbb interesting. \r\n\r\n- Re: prefetching - how did you select the descriptors to prefetch?  Seems to trade off heap size vs time spent allocating right?\r\n- Re: preencoding/double buffering - we do something similar for models like Mask R-CNN, where we run parts of the graph on the CPU and parts on the GPU. Not very cleanly abstrated though.\r\n- Re: texture2d/2d_array - cool stuff. I was thinking of just a minor refactor to go to single kernel and keep using function_constants to select array/non-array, but if there's some nice template abstractions that's pretty neat."}