{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/297063950", "html_url": "https://github.com/tensorflow/tensorflow/issues/7958#issuecomment-297063950", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7958", "id": 297063950, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NzA2Mzk1MA==", "user": {"login": "ajtulloch", "id": 1121581, "node_id": "MDQ6VXNlcjExMjE1ODE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1121581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajtulloch", "html_url": "https://github.com/ajtulloch", "followers_url": "https://api.github.com/users/ajtulloch/followers", "following_url": "https://api.github.com/users/ajtulloch/following{/other_user}", "gists_url": "https://api.github.com/users/ajtulloch/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajtulloch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajtulloch/subscriptions", "organizations_url": "https://api.github.com/users/ajtulloch/orgs", "repos_url": "https://api.github.com/users/ajtulloch/repos", "events_url": "https://api.github.com/users/ajtulloch/events{/privacy}", "received_events_url": "https://api.github.com/users/ajtulloch/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-25T15:16:56Z", "updated_at": "2017-04-25T15:16:56Z", "author_association": "NONE", "body_html": "<p>Hey <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=229914\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/keveman\">@keveman</a>, I wrote the C2 mobile stuff so really interested in the TF approach. How are you thinking of structuring the TF integration? It'd be cool if we can reuse kernel sources and stuff.</p>\n<p>Some decisions/hacks/notes I made that I was kind of unsure about, so I wondered how you'd approach them:</p>\n<ul>\n<li>Using textures (MPSImage, MPSTemporaryImage) vs buffers (MTLBuffer) as the tensor representation. There are a few issues here - standard textures vs buffer stuff, but also some semi-surprising limitations of the implementation (e.g. a maximum of 2800 textures in a <code>texture2d_array</code>, which introduces issues with representing a batch-size 50, 224-channel image. You need the <code>MPSTemporaryImage</code> for the MPSCNN kernels obviously, but these kernels seem to be operating well below peak so I imagine there's space to improve there with a custom implementation.</li>\n<li>Handling of the <code>MTLCommandBuffer</code> object. Instead of the CUDA approach with a reusable stream that you can schedule kernels/events on, this transient object is single use, so there needs to be some initialization and passing it around along with the MPSTemporaryImage in the <a href=\"https://github.com/caffe2/caffe2/blob/d0ce49/caffe2/contrib/mpscnn-fb/mpscnn.mm#L113-L116\"><code>MPSImageWrapper</code></a> struct.</li>\n<li>Memory management - solving it with <code>MPSTemporaryImage</code>'s (<a href=\"https://github.com/caffe2/caffe2/blob/d0ce49/caffe2/contrib/mpscnn-fb/mpscnn.mm#L1778-L1814\">and having a SSA pass to compute the <code>readCount</code> field</a>) vs using a custom allocator with <code>MTLBuffer</code>.</li>\n<li>General object ownership issues, integrating the ARC refcounting model with the DFG style ownership. In the C2 impl, the op maintains a ref on the <code>MPSTemporaryImage</code> which solves the common case but has some ugly corner cases, so it's probably worth fixing it to do proper ARC on the <code>MPSImageWrapper</code> itself.</li>\n<li>Passing compile-time specialization arguments to kernels helped a lot (<a href=\"https://github.com/caffe2/caffe2/blob/d0ce49/caffe2/contrib/mpscnn-fb/MPSCNN.metal#L7-L13\">https://github.com/caffe2/caffe2/blob/d0ce49/caffe2/contrib/mpscnn-fb/MPSCNN.metal#L7-L13</a>), but ideally that would be a bit nicer from a kernel authors perspective without cluttering it up with a lot of single-use structs/syntax.</li>\n<li>Speaking of kernels, the kind of ugly switching/duplication between <code>texture2d</code>/<code>texture2d_array</code> is something that might be good to revisit via some macro sugar or something?</li>\n<li>In general, there were a bunch of good snippets in <a href=\"https://developer.apple.com/videos/play/wwdc2016/606/\" rel=\"nofollow\">https://developer.apple.com/videos/play/wwdc2016/606/</a>.</li>\n<li>Getting the GPU profiler working (via a call to <a href=\"https://developer.apple.com/reference/metal/mtlcommandqueue/1508692-insertdebugcaptureboundary\" rel=\"nofollow\"><code>MTLCommandQueue:insertDebugCaptureBoundary</code></a> after <code>Net::Run</code>/<code>Session::Run</code> was pretty useful for some stuff.</li>\n<li>For some use-cases, the cost of command construction/encoding was nontrivial compared to execution time, so I was thinking of doing some double-buffering wrapper (at a higher level) for latency-sensitive applications.</li>\n</ul>", "body_text": "Hey @keveman, I wrote the C2 mobile stuff so really interested in the TF approach. How are you thinking of structuring the TF integration? It'd be cool if we can reuse kernel sources and stuff.\nSome decisions/hacks/notes I made that I was kind of unsure about, so I wondered how you'd approach them:\n\nUsing textures (MPSImage, MPSTemporaryImage) vs buffers (MTLBuffer) as the tensor representation. There are a few issues here - standard textures vs buffer stuff, but also some semi-surprising limitations of the implementation (e.g. a maximum of 2800 textures in a texture2d_array, which introduces issues with representing a batch-size 50, 224-channel image. You need the MPSTemporaryImage for the MPSCNN kernels obviously, but these kernels seem to be operating well below peak so I imagine there's space to improve there with a custom implementation.\nHandling of the MTLCommandBuffer object. Instead of the CUDA approach with a reusable stream that you can schedule kernels/events on, this transient object is single use, so there needs to be some initialization and passing it around along with the MPSTemporaryImage in the MPSImageWrapper struct.\nMemory management - solving it with MPSTemporaryImage's (and having a SSA pass to compute the readCount field) vs using a custom allocator with MTLBuffer.\nGeneral object ownership issues, integrating the ARC refcounting model with the DFG style ownership. In the C2 impl, the op maintains a ref on the MPSTemporaryImage which solves the common case but has some ugly corner cases, so it's probably worth fixing it to do proper ARC on the MPSImageWrapper itself.\nPassing compile-time specialization arguments to kernels helped a lot (https://github.com/caffe2/caffe2/blob/d0ce49/caffe2/contrib/mpscnn-fb/MPSCNN.metal#L7-L13), but ideally that would be a bit nicer from a kernel authors perspective without cluttering it up with a lot of single-use structs/syntax.\nSpeaking of kernels, the kind of ugly switching/duplication between texture2d/texture2d_array is something that might be good to revisit via some macro sugar or something?\nIn general, there were a bunch of good snippets in https://developer.apple.com/videos/play/wwdc2016/606/.\nGetting the GPU profiler working (via a call to MTLCommandQueue:insertDebugCaptureBoundary after Net::Run/Session::Run was pretty useful for some stuff.\nFor some use-cases, the cost of command construction/encoding was nontrivial compared to execution time, so I was thinking of doing some double-buffering wrapper (at a higher level) for latency-sensitive applications.", "body": "Hey @keveman, I wrote the C2 mobile stuff so really interested in the TF approach. How are you thinking of structuring the TF integration? It'd be cool if we can reuse kernel sources and stuff.\r\n\r\nSome decisions/hacks/notes I made that I was kind of unsure about, so I wondered how you'd approach them:\r\n\r\n- Using textures (MPSImage, MPSTemporaryImage) vs buffers (MTLBuffer) as the tensor representation. There are a few issues here - standard textures vs buffer stuff, but also some semi-surprising limitations of the implementation (e.g. a maximum of 2800 textures in a `texture2d_array`, which introduces issues with representing a batch-size 50, 224-channel image. You need the `MPSTemporaryImage` for the MPSCNN kernels obviously, but these kernels seem to be operating well below peak so I imagine there's space to improve there with a custom implementation.\r\n- Handling of the `MTLCommandBuffer` object. Instead of the CUDA approach with a reusable stream that you can schedule kernels/events on, this transient object is single use, so there needs to be some initialization and passing it around along with the MPSTemporaryImage in the [`MPSImageWrapper`](https://github.com/caffe2/caffe2/blob/d0ce49/caffe2/contrib/mpscnn-fb/mpscnn.mm#L113-L116) struct.\r\n- Memory management - solving it with `MPSTemporaryImage`'s ([and having a SSA pass to compute the `readCount` field](https://github.com/caffe2/caffe2/blob/d0ce49/caffe2/contrib/mpscnn-fb/mpscnn.mm#L1778-L1814)) vs using a custom allocator with `MTLBuffer`.\r\n- General object ownership issues, integrating the ARC refcounting model with the DFG style ownership. In the C2 impl, the op maintains a ref on the `MPSTemporaryImage` which solves the common case but has some ugly corner cases, so it's probably worth fixing it to do proper ARC on the `MPSImageWrapper` itself.\r\n- Passing compile-time specialization arguments to kernels helped a lot (https://github.com/caffe2/caffe2/blob/d0ce49/caffe2/contrib/mpscnn-fb/MPSCNN.metal#L7-L13), but ideally that would be a bit nicer from a kernel authors perspective without cluttering it up with a lot of single-use structs/syntax.\r\n- Speaking of kernels, the kind of ugly switching/duplication between `texture2d`/`texture2d_array` is something that might be good to revisit via some macro sugar or something?\r\n- In general, there were a bunch of good snippets in https://developer.apple.com/videos/play/wwdc2016/606/. \r\n- Getting the GPU profiler working (via a call to [`MTLCommandQueue:insertDebugCaptureBoundary`](https://developer.apple.com/reference/metal/mtlcommandqueue/1508692-insertdebugcaptureboundary) after `Net::Run`/`Session::Run` was pretty useful for some stuff.\r\n- For some use-cases, the cost of command construction/encoding was nontrivial compared to execution time, so I was thinking of doing some double-buffering wrapper (at a higher level) for latency-sensitive applications.\r\n"}