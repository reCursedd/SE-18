{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/135322625", "pull_request_review_id": 58726651, "id": 135322625, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNTMyMjYyNQ==", "diff_hunk": "@@ -0,0 +1,455 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// See docs in ../ops/linalg_ops.cc.\n+// TODO(shamanDevel): Enable complex inputs. This will require additional tests\n+//                    and OP_REQUIRES.\n+#if GOOGLE_CUDA\n+#define EIGEN_USE_GPU\n+\n+#include <algorithm>\n+#include <vector>\n+\n+#include \"tensorflow/core/framework/kernel_def_builder.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/kernels/linalg_ops_common.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/platform/types.h\"\n+#include \"tensorflow/core/kernels/cuda_solvers.h\"\n+#include \"tensorflow/core/platform/stream_executor.h\"\n+#include \"tensorflow/core/util/cuda_kernel_helper.h\"\n+#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n+// I need to transpose V afterwards\n+#include \"tensorflow/core/kernels/transpose_functor.h\"\n+\n+// Logging\n+#include <stdio.h>\n+\n+namespace tensorflow {\n+\n+static const char kErrMsg[] =\n+    \"Singular Value Decomposition was not successful. The input might not be \"\n+    \"valid.\";\n+\n+typedef Eigen::GpuDevice GPUDevice;\n+\n+namespace {\n+  template<class Scalar>\n+  __global__ void ComputeV1Kernel(CudaLaunchConfig config,\n+      int64 m, const Scalar* M, const Scalar* U, const Scalar* S, Scalar* V)\n+  {\n+    CUDA_1D_KERNEL_LOOP(i, config.virtual_thread_count) {\n+      Scalar v = M[i] * U[m*i] * S[0];\n+      //printf(\"i=%d, v=%f\\n\", (int) i, (float) v);\n+      CudaAtomicAdd(V, v);\n+    }\n+  }\n+\n+  template<class Scalar>\n+  __global__ void ComputeV2Kernel(CudaLaunchConfig config, Scalar* V)\n+  {\n+    CUDA_1D_KERNEL_LOOP(i, config.virtual_thread_count) {\n+      //printf(\"V'[%d] = %f\\n\", (int)i, (float)V[i]);\n+      V[i] = (Scalar) copysign(1.0, V[i]);\n+    }\n+  }\n+}\n+\n+// Scalar: The input scalar type (can be complex)\n+// SScalar: The output type for the singular value,\n+//   same as Scalar if real, or the real version if Scalar is complex\n+template <class Scalar, class SScalar>\n+class SvdOpGpu : public AsyncOpKernel {\n+ public:\n+  explicit SvdOpGpu(OpKernelConstruction* context) : AsyncOpKernel(context) {\n+    OP_REQUIRES_OK(context, context->GetAttr(\"compute_uv\", &compute_uv_));\n+    OP_REQUIRES_OK(context, context->GetAttr(\"full_matrices\", &full_matrices_));\n+  }\n+\n+  void RunSVD(OpKernelContext* context, DoneCallback done, int64 m, int64 n,\n+              int64 p, int64 batch_size, Scalar* input_ptr,\n+              SScalar* outputS_ptr, Scalar* outputU_ptr, Scalar* outputVT_ptr,\n+              int* dev_info_ptr, CudaSolver& solver) {\n+\n+    // Needed for the n=1 fix, see below, since SVD destroys the input\n+    Tensor input_copy;\n+    if (compute_uv_ && n==1) {\n+      OP_REQUIRES_OK_ASYNC(\n+        context,\n+        context->allocate_temp(DataTypeToEnum<Scalar>::v(), TensorShape({m}), &input_copy),\n+        done);\n+    }\n+\n+    for (int64 i = 0; i < batch_size; ++i) {\n+      int lda = m;\n+      int ldu = m;\n+      int ldvt = n;\n+      Scalar* input = input_ptr + i * m * n;\n+      SScalar* outputS = outputS_ptr + i * p;\n+      Scalar* outputU = NULL;\n+      Scalar* outputVT = NULL;\n+      signed char jobu = 'N';\n+      signed char jobvt = 'N';\n+\n+      // Save input matrix for n=1 fix\n+      if (compute_uv_ && n==1) {\n+        const GPUDevice& d = context->eigen_device<GPUDevice>();\n+        d.memcpy(input_copy.flat<Scalar>().data(), input,\n+               m * sizeof(Scalar));\n+      }\n+\n+      if (compute_uv_) {\n+        if (full_matrices_) {\n+          outputU = outputU_ptr + i * m * m;\n+          outputVT = outputVT_ptr + i * n * n;\n+          jobu = 'A';\n+          jobvt = 'A';\n+        } else {\n+          outputU = outputU_ptr + i * m * p;\n+          outputVT = outputVT_ptr + i * n * p;\n+          jobu = 'S';\n+          jobvt = 'S';\n+        }\n+      }\n+\n+      OP_REQUIRES_OK_ASYNC(\n+          context, solver.Gesvd(jobu, jobvt, m, n, input, lda, outputS, outputU,\n+                                ldu, outputVT, ldvt, dev_info_ptr + i),\n+          done);\n+\n+      // This is a bug in cuSolver:\n+      // If n is one, then outputVT only contains zeros instead of ones.\n+      // Hence, I need to fill outputVT manually\n+      // The question is: +1 or -1?\n+      // -> Compute U*S and compare sign against M\n+      // But because S is zero except for the first entry, the multiplication simplifies a lot\n+      // However, what happens if M contains zeros? At these indices, it is impossible\n+      // to determine the value of V\n+      // -> Compute V for all rows in M to cope for zeros.\n+      // 1. V' = sum_i (M_i * U_i,1 * S_i)\n+      // 2. V = {1, V'>=0, -1, V'<0}\n+      // TODO: what is with complex values?\n+      if (compute_uv_ && n==1) {\n+        const GPUDevice& d = context->eigen_device<GPUDevice>();\n+        d.memset(outputVT, 0, sizeof(Scalar));\n+        CudaLaunchConfig cfg = GetCudaLaunchConfig(m, d);\n+        ComputeV1Kernel <<<cfg.block_count, \n+                              cfg.thread_per_block, 0, d.stream()>>>\n+            (cfg, m, input_copy.flat<Scalar>().data(), outputU, outputS, outputVT);\n+      }\n+      // For the second part, see below\n+\n+#if 0\n+      // debug\n+      printf(\"m=%d, n=%d\\n\", (int)m, (int)n);\n+      printf(\"M:\\n\");\n+      Scalar* input_cpu = new Scalar[m*n];\n+      cudaMemcpy(input_cpu, input, sizeof(Scalar)*m*n, cudaMemcpyDeviceToHost);\n+      for (int64 i=0; i<m; ++i) {\n+        for (int64 j=0; j<n; ++j) printf(\" %5.3f\", (float)input_cpu[i+j*m]);\n+        printf(\"\\n\");\n+      }\n+      delete[] input_cpu;\n+      if (compute_uv_) {\n+      printf(\"U:\\n\");\n+      Scalar* outputU_cpu = new Scalar[m*m];\n+      cudaMemcpy(outputU_cpu, outputU, sizeof(Scalar)*m*m, cudaMemcpyDeviceToHost);\n+      for (int64 i=0; i<m; ++i) {\n+        for (int64 j=0; j<m; ++j) printf(\" %5.3f\", (float)outputU_cpu[i+j*m]);\n+        printf(\"\\n\");\n+      }\n+      delete[] outputU_cpu;\n+      printf(\"VT:\\n\");\n+      Scalar* outputVT_cpu = new Scalar[n*n];\n+      cudaMemcpy(outputVT_cpu, outputVT, sizeof(Scalar)*n*n, cudaMemcpyDeviceToHost);\n+      for (int64 i=0; i<n; ++i) {\n+        for (int64 j=0; j<n; ++j) printf(\" %5.3f\", (float)outputVT_cpu[i+j*n]);\n+        printf(\"\\n\");\n+      }\n+      delete[] outputVT_cpu;\n+      }\n+#endif\n+\n+    }\n+\n+    // Second part of the n=1 fix: clamp V to -1 or +1\n+    if (compute_uv_ && n==1) {\n+      const GPUDevice& d = context->eigen_device<GPUDevice>();\n+      CudaLaunchConfig cfg = GetCudaLaunchConfig(batch_size, d);\n+      ComputeV2Kernel <<<cfg.block_count, \n+                         cfg.thread_per_block, 0, d.stream()>>>\n+          (cfg, outputVT_ptr);\n+    }\n+  }\n+\n+  void CheckResult(OpKernelContext* context, DoneCallback done,\n+                   const std::vector<DeviceLapackInfo>& dev_info,\n+                   CudaSolver& solver, Tensor& catch1, Tensor& catch2) {\n+    auto info_checker = [context, dev_info, done, catch1, catch2](\n+        const Status& status, const std::vector<HostLapackInfo>& /* unused */) {\n+      Status full_status = status;\n+      if (!full_status.ok()) {\n+        full_status.Update(errors::InvalidArgument(kErrMsg));\n+      }\n+      OP_REQUIRES_OK_ASYNC(context, full_status, done);\n+      done();\n+    };\n+\n+    OP_REQUIRES_OK_ASYNC(context, solver.CopyLapackInfoToHostAsync(\n+                                      dev_info, std::move(info_checker)),\n+                         done);\n+  }\n+\n+  // The SVD if m >= n\n+  void PerformSVD_MgeqN(OpKernelContext* context, DoneCallback done, int64 m,\n+                        int64 n, int64 p, const gtl::ArraySlice<int32>& perm,\n+                        const Tensor& M, Tensor* S, Tensor* U, Tensor* V) {\n+    TensorShape shapeRaw = M.shape();\n+    shapeRaw.RemoveDim(shapeRaw.dims() - 1);\n+    shapeRaw.RemoveDim(shapeRaw.dims() - 1);\n+\n+    // Transpose M, because cuSolver expects it to be column-major\n+    TensorShape input_shape = shapeRaw;\n+    input_shape.AddDim(n);\n+    input_shape.AddDim(m);\n+    Tensor input_copy;\n+    OP_REQUIRES_OK_ASYNC(\n+        context, context->allocate_temp(M.dtype(), input_shape, &input_copy),\n+        done);\n+    auto device = context->eigen_device<GPUDevice>();\n+    OP_REQUIRES_OK_ASYNC(\n+        context, \n+        DoTranspose(device, M, perm, &input_copy),\n+        done);\n+\n+    // I need to transpose U at the end\n+    // Not V, because cuSolver work column-major\n+    Tensor u_copy;\n+    if (compute_uv_) {\n+      TensorShape u_shape;\n+      if (full_matrices_) {\n+        u_shape = U->shape();\n+      } else {\n+        u_shape = shapeRaw;\n+        u_shape.AddDim(p);\n+        u_shape.AddDim(m);\n+      }\n+      OP_REQUIRES_OK_ASYNC(\n+          context, context->allocate_temp(U->dtype(), u_shape, &u_copy), done);\n+    }\n+\n+    // get the pointers to the data\n+    Scalar* input_ptr;\n+    SScalar* outputS_ptr;\n+    Scalar* outputU_ptr = NULL;\n+    Scalar* outputV_ptr = NULL;\n+    auto input_reshaped = input_copy.template flat_inner_dims<Scalar, 3>();\n+    input_ptr = input_reshaped.data();\n+    outputS_ptr = S->template flat_inner_dims<SScalar, 2>().data();\n+    if (compute_uv_) {\n+      outputU_ptr = u_copy.template flat_inner_dims<Scalar, 3>().data();\n+      outputV_ptr = V->template flat_inner_dims<Scalar, 3>().data();\n+    }\n+\n+    // call the SVD\n+    const int64 batch_size = input_reshaped.dimension(0);\n+    std::vector<DeviceLapackInfo> dev_info;\n+    dev_info.emplace_back(context, batch_size, \"gesvd\");\n+    CudaSolver solver(context);\n+    RunSVD(context, done, m, n, p, batch_size, input_ptr, outputS_ptr,\n+           outputU_ptr, outputV_ptr, dev_info.back().mutable_data(), solver);\n+\n+    // Transpose U\n+    if (compute_uv_) {\n+      OP_REQUIRES_OK_ASYNC(\n+          context,\n+          DoTranspose(device, u_copy, perm, U),\n+          done);\n+    }\n+\n+    // now check if the SVD operation succeeded or not\n+    CheckResult(context, done, dev_info, solver, input_copy, u_copy);\n+  }\n+\n+  // The SVD if m < n\n+  void PerformSVD_MlessN(OpKernelContext* context, DoneCallback done, int64 m,", "path": "tensorflow/core/kernels/svd_op_gpu.cu.cc", "position": 253, "original_position": 292, "commit_id": "bfda71b1104c7d1d0210439c22cded14c87c7db7", "original_commit_id": "f222d793af6c6b4c53e11d87e90e3a728d1bc4eb", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "Perhaps put a TODO.", "created_at": "2017-08-25T18:19:56Z", "updated_at": "2017-09-06T05:32:18Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11878#discussion_r135322625", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11878", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/135322625"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11878#discussion_r135322625"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11878"}}, "body_html": "<p>Perhaps put a TODO.</p>", "body_text": "Perhaps put a TODO.", "in_reply_to_id": 135075258}