{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14596", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14596/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14596/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14596/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14596", "id": 274302138, "node_id": "MDU6SXNzdWUyNzQzMDIxMzg=", "number": 14596, "title": "Bug: tf.data.Dataset.map computes unrequested graph parts ", "user": {"login": "boeddeker", "id": 13744128, "node_id": "MDQ6VXNlcjEzNzQ0MTI4", "avatar_url": "https://avatars3.githubusercontent.com/u/13744128?v=4", "gravatar_id": "", "url": "https://api.github.com/users/boeddeker", "html_url": "https://github.com/boeddeker", "followers_url": "https://api.github.com/users/boeddeker/followers", "following_url": "https://api.github.com/users/boeddeker/following{/other_user}", "gists_url": "https://api.github.com/users/boeddeker/gists{/gist_id}", "starred_url": "https://api.github.com/users/boeddeker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/boeddeker/subscriptions", "organizations_url": "https://api.github.com/users/boeddeker/orgs", "repos_url": "https://api.github.com/users/boeddeker/repos", "events_url": "https://api.github.com/users/boeddeker/events{/privacy}", "received_events_url": "https://api.github.com/users/boeddeker/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-11-15T20:58:35Z", "updated_at": "2018-01-03T18:05:05Z", "closed_at": "2018-01-03T18:05:04Z", "author_association": "CONTRIBUTOR", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: See code example at the bottom</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.4.0-rc1-11-g130a514 1.4.0</li>\n<li><strong>Python version</strong>: Python 3.6.1 :: Anaconda custom (64-bit)</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p><strong>Short</strong>: <code>tf.Session.run</code> does not compute unnecessary things that are not requested, except for the case the tensorflow code in inside a <code>tf.data.Dataset.map</code>.<br>\nSo is it possible to add this feature to <code>tf.data.Dataset.map</code>?<br>\nMaybe the problem is in <code>tensorflow.python.framework.function.Defun</code>.</p>\n<p><strong>Long</strong>: I want to build a fully featured input pipeline that provides everything. Than should tensorflow determine what is necessary to compute. When I tried to figure out if this is possible I found that the dataset has some code for parallel execution. So preprocessing should be inside the <code>Dataset</code> pipeline.<br>\nWhen I looked at the source code I think the reason may be connected to <code>tensorflow.python.framework.function.Defun</code>, but I can not find the motivation to use Defun and the initial commit (2017-05-17) under contrib had already <code>Defun</code> used.<br>\nWith my knowledge as a tensorflow beginner, I can only fix this when I ignore parallel execution (i.e. remove all <code>Defun</code>s), but then I can also do the transform after <code>Iterator.get_next()</code>.</p>\n<p>Maybe <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> knows more about this?</p>\n<h3>Source code / logs</h3>\n<p>Here a small example that demonstrates this behavior. (Node the <code>tf_sleep(idx, 0.1)</code> is a open end in the graph and the print should never be executed.)</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> functools\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> -----------------simple print when this is executed------------------------------------</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">sleep</span>(<span class=\"pl-smi\">tensor</span>, <span class=\"pl-smi\">seconds</span>):\n    time.sleep(seconds)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-s\">Sleeped for </span><span class=\"pl-c1\">{</span>seconds<span class=\"pl-c1\">}</span><span class=\"pl-s\">s</span><span class=\"pl-pds\">'</span>)\n    <span class=\"pl-k\">return</span> tensor\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">tf_sleep</span>(<span class=\"pl-smi\">tensor</span>, <span class=\"pl-smi\">seconds</span>):\n    <span class=\"pl-k\">return</span> tf.py_func(sleep, [tensor, seconds], tensor.dtype, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>speep<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ------------------------------------------------------------------------------------------------</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">transform</span>(<span class=\"pl-smi\">idx</span>):    \n    tf_sleep(idx, <span class=\"pl-c1\">0.1</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Dead graph end, should never be executed</span>\n    <span class=\"pl-k\">return</span> tf_sleep(idx, <span class=\"pl-c1\">0.2</span>)\n    \nds <span class=\"pl-k\">=</span> tf.data.Dataset.range(<span class=\"pl-c1\">20</span>)\nds <span class=\"pl-k\">=</span> ds.map(transform)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> will produce \"Sleeped for 0.1s\"</span>\n\niterator <span class=\"pl-k\">=</span> ds.make_one_shot_iterator()\nentry <span class=\"pl-k\">=</span> iterator.get_next()\n\nentry <span class=\"pl-k\">=</span> transform(entry)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> does not produce \"Sleeped for 0.1s\"</span>\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-c1\">print</span>(sess.run(entry))\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Output: </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Sleeped for 0.20000000298023224s</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Sleeped for 0.10000000149011612s  # &lt;-- this should not be printed</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Sleeped for 0.20000000298023224s</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0</span></pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): See code example at the bottom\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.4.0-rc1-11-g130a514 1.4.0\nPython version: Python 3.6.1 :: Anaconda custom (64-bit)\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nShort: tf.Session.run does not compute unnecessary things that are not requested, except for the case the tensorflow code in inside a tf.data.Dataset.map.\nSo is it possible to add this feature to tf.data.Dataset.map?\nMaybe the problem is in tensorflow.python.framework.function.Defun.\nLong: I want to build a fully featured input pipeline that provides everything. Than should tensorflow determine what is necessary to compute. When I tried to figure out if this is possible I found that the dataset has some code for parallel execution. So preprocessing should be inside the Dataset pipeline.\nWhen I looked at the source code I think the reason may be connected to tensorflow.python.framework.function.Defun, but I can not find the motivation to use Defun and the initial commit (2017-05-17) under contrib had already Defun used.\nWith my knowledge as a tensorflow beginner, I can only fix this when I ignore parallel execution (i.e. remove all Defuns), but then I can also do the transform after Iterator.get_next().\nMaybe @mrry knows more about this?\nSource code / logs\nHere a small example that demonstrates this behavior. (Node the tf_sleep(idx, 0.1) is a open end in the graph and the print should never be executed.)\nimport tensorflow as tf\nimport functools\n\n# -----------------simple print when this is executed------------------------------------\ndef sleep(tensor, seconds):\n    time.sleep(seconds)\n    print(f'Sleeped for {seconds}s')\n    return tensor\n\ndef tf_sleep(tensor, seconds):\n    return tf.py_func(sleep, [tensor, seconds], tensor.dtype, name='speep')\n# ------------------------------------------------------------------------------------------------\ndef transform(idx):    \n    tf_sleep(idx, 0.1)  # Dead graph end, should never be executed\n    return tf_sleep(idx, 0.2)\n    \nds = tf.data.Dataset.range(20)\nds = ds.map(transform)  # will produce \"Sleeped for 0.1s\"\n\niterator = ds.make_one_shot_iterator()\nentry = iterator.get_next()\n\nentry = transform(entry)  # does not produce \"Sleeped for 0.1s\"\n\nwith tf.Session() as sess:\n    print(sess.run(entry))\n# Output: \n# Sleeped for 0.20000000298023224s\n# Sleeped for 0.10000000149011612s  # <-- this should not be printed\n# Sleeped for 0.20000000298023224s\n# 0", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: See code example at the bottom\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: Python 3.6.1 :: Anaconda custom (64-bit)\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n**Short**: `tf.Session.run` does not compute unnecessary things that are not requested, except for the case the tensorflow code in inside a `tf.data.Dataset.map`. \r\nSo is it possible to add this feature to `tf.data.Dataset.map`?\r\nMaybe the problem is in `tensorflow.python.framework.function.Defun`.\r\n\r\n**Long**: I want to build a fully featured input pipeline that provides everything. Than should tensorflow determine what is necessary to compute. When I tried to figure out if this is possible I found that the dataset has some code for parallel execution. So preprocessing should be inside the `Dataset` pipeline. \r\nWhen I looked at the source code I think the reason may be connected to `tensorflow.python.framework.function.Defun`, but I can not find the motivation to use Defun and the initial commit (2017-05-17) under contrib had already `Defun` used.\r\nWith my knowledge as a tensorflow beginner, I can only fix this when I ignore parallel execution (i.e. remove all `Defun`s), but then I can also do the transform after `Iterator.get_next()`.\r\n\r\nMaybe @mrry knows more about this?\r\n\r\n### Source code / logs\r\n\r\nHere a small example that demonstrates this behavior. (Node the `tf_sleep(idx, 0.1)` is a open end in the graph and the print should never be executed.)\r\n```python\r\nimport tensorflow as tf\r\nimport functools\r\n\r\n# -----------------simple print when this is executed------------------------------------\r\ndef sleep(tensor, seconds):\r\n    time.sleep(seconds)\r\n    print(f'Sleeped for {seconds}s')\r\n    return tensor\r\n\r\ndef tf_sleep(tensor, seconds):\r\n    return tf.py_func(sleep, [tensor, seconds], tensor.dtype, name='speep')\r\n# ------------------------------------------------------------------------------------------------\r\ndef transform(idx):    \r\n    tf_sleep(idx, 0.1)  # Dead graph end, should never be executed\r\n    return tf_sleep(idx, 0.2)\r\n    \r\nds = tf.data.Dataset.range(20)\r\nds = ds.map(transform)  # will produce \"Sleeped for 0.1s\"\r\n\r\niterator = ds.make_one_shot_iterator()\r\nentry = iterator.get_next()\r\n\r\nentry = transform(entry)  # does not produce \"Sleeped for 0.1s\"\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run(entry))\r\n# Output: \r\n# Sleeped for 0.20000000298023224s\r\n# Sleeped for 0.10000000149011612s  # <-- this should not be printed\r\n# Sleeped for 0.20000000298023224s\r\n# 0\r\n```\r\n"}