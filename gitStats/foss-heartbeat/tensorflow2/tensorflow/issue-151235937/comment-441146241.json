{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/441146241", "html_url": "https://github.com/tensorflow/tensorflow/issues/2118#issuecomment-441146241", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2118", "id": 441146241, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTE0NjI0MQ==", "user": {"login": "guoyejun", "id": 10448440, "node_id": "MDQ6VXNlcjEwNDQ4NDQw", "avatar_url": "https://avatars1.githubusercontent.com/u/10448440?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guoyejun", "html_url": "https://github.com/guoyejun", "followers_url": "https://api.github.com/users/guoyejun/followers", "following_url": "https://api.github.com/users/guoyejun/following{/other_user}", "gists_url": "https://api.github.com/users/guoyejun/gists{/gist_id}", "starred_url": "https://api.github.com/users/guoyejun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guoyejun/subscriptions", "organizations_url": "https://api.github.com/users/guoyejun/orgs", "repos_url": "https://api.github.com/users/guoyejun/repos", "events_url": "https://api.github.com/users/guoyejun/events{/privacy}", "received_events_url": "https://api.github.com/users/guoyejun/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-23T02:43:14Z", "updated_at": "2018-11-23T02:43:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I see it is not invertible, and the desired output shape for conv2d_transposed is necessary.</p>\n<p>But it becomes a common issue when trying to integrate the model in a c program and execute the model via Tensorflow C API, because the model (with conv2d_transposed layer) is tied with the desired output shape which is usually relative to the input image size. And we have to prepare many model files for different possible input image size, it is not feasible.</p>\n<p>Actually, for many cases, the model (for example, with encoder and decoder) is designed to be independent with the input image size, it is expected that a single model file can be used for all kinds of image sizes.</p>\n<p>So, can we add an option for this layer to not set output_shape explicitly?</p>\n<ul>\n<li>\n<p>add a new parameter remainders, and so:<br>\noutput = input * stride + remainder + filter - stride  # VALID<br>\noutput = input * stride + remainder - stride + 1  # SAME</p>\n</li>\n<li>\n<p>if the output_shape is none (or even add a new parameter flag), just do:<br>\noutput = input * stride + filter - stride  # VALID<br>\noutput = input * stride - stride + 1  # SAME</p>\n</li>\n</ul>", "body_text": "I see it is not invertible, and the desired output shape for conv2d_transposed is necessary.\nBut it becomes a common issue when trying to integrate the model in a c program and execute the model via Tensorflow C API, because the model (with conv2d_transposed layer) is tied with the desired output shape which is usually relative to the input image size. And we have to prepare many model files for different possible input image size, it is not feasible.\nActually, for many cases, the model (for example, with encoder and decoder) is designed to be independent with the input image size, it is expected that a single model file can be used for all kinds of image sizes.\nSo, can we add an option for this layer to not set output_shape explicitly?\n\n\nadd a new parameter remainders, and so:\noutput = input * stride + remainder + filter - stride  # VALID\noutput = input * stride + remainder - stride + 1  # SAME\n\n\nif the output_shape is none (or even add a new parameter flag), just do:\noutput = input * stride + filter - stride  # VALID\noutput = input * stride - stride + 1  # SAME", "body": "I see it is not invertible, and the desired output shape for conv2d_transposed is necessary. \r\n\r\nBut it becomes a common issue when trying to integrate the model in a c program and execute the model via Tensorflow C API, because the model (with conv2d_transposed layer) is tied with the desired output shape which is usually relative to the input image size. And we have to prepare many model files for different possible input image size, it is not feasible.\r\n\r\nActually, for many cases, the model (for example, with encoder and decoder) is designed to be independent with the input image size, it is expected that a single model file can be used for all kinds of image sizes.\r\n\r\nSo, can we add an option for this layer to not set output_shape explicitly?\r\n- add a new parameter remainders, and so:\r\noutput = input * stride + remainder + filter - stride  # VALID\r\noutput = input * stride + remainder - stride + 1  # SAME \r\n\r\n- if the output_shape is none (or even add a new parameter flag), just do:\r\noutput = input * stride + filter - stride  # VALID\r\noutput = input * stride - stride + 1  # SAME "}