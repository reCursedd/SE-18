{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/399304472", "html_url": "https://github.com/tensorflow/tensorflow/issues/20187#issuecomment-399304472", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20187", "id": 399304472, "node_id": "MDEyOklzc3VlQ29tbWVudDM5OTMwNDQ3Mg==", "user": {"login": "sfanxiang", "id": 5893440, "node_id": "MDQ6VXNlcjU4OTM0NDA=", "avatar_url": "https://avatars0.githubusercontent.com/u/5893440?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sfanxiang", "html_url": "https://github.com/sfanxiang", "followers_url": "https://api.github.com/users/sfanxiang/followers", "following_url": "https://api.github.com/users/sfanxiang/following{/other_user}", "gists_url": "https://api.github.com/users/sfanxiang/gists{/gist_id}", "starred_url": "https://api.github.com/users/sfanxiang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sfanxiang/subscriptions", "organizations_url": "https://api.github.com/users/sfanxiang/orgs", "repos_url": "https://api.github.com/users/sfanxiang/repos", "events_url": "https://api.github.com/users/sfanxiang/events{/privacy}", "received_events_url": "https://api.github.com/users/sfanxiang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-22T02:48:48Z", "updated_at": "2018-06-22T03:01:38Z", "author_association": "NONE", "body_html": "<p><a href=\"https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/lite/kernels/internal/optimized/multithreaded_conv.h#L55\">multithreaded_conv.h#L55</a> says:</p>\n<blockquote>\n<p>since the underlying resource of CPU cores should be consumed by the operations anyway, it shouldn't affect overall performance.</p>\n</blockquote>\n<p>Is this understanding correct:</p>\n<ul>\n<li>There's little performance gain in increasing the number of threads for a <strong>single invocation</strong>, i.e. by changing <code>thread_count</code> at <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/lite/kernels/internal/optimized/multithreaded_conv.h#L58\">L58</a>.</li>\n<li>There is, however, some performance gain if <strong>several invocations</strong> are run in parallel (e.g. by using one thread for each).</li>\n</ul>\n<hr>\n<p>Hypothetically, apart from the implementation difference between Eigen and gemmlowp, what differs floating point and integer so much that we can't (or shouldn't) even run floating point convolutions from more than <em>4</em> threads? IMO not all models are suitable for quantization.</p>\n<p>Thank you!</p>", "body_text": "multithreaded_conv.h#L55 says:\n\nsince the underlying resource of CPU cores should be consumed by the operations anyway, it shouldn't affect overall performance.\n\nIs this understanding correct:\n\nThere's little performance gain in increasing the number of threads for a single invocation, i.e. by changing thread_count at L58.\nThere is, however, some performance gain if several invocations are run in parallel (e.g. by using one thread for each).\n\n\nHypothetically, apart from the implementation difference between Eigen and gemmlowp, what differs floating point and integer so much that we can't (or shouldn't) even run floating point convolutions from more than 4 threads? IMO not all models are suitable for quantization.\nThank you!", "body": "[multithreaded_conv.h#L55](https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/lite/kernels/internal/optimized/multithreaded_conv.h#L55) says:\r\n> since the underlying resource of CPU cores should be consumed by the operations anyway, it shouldn't affect overall performance.\r\n\r\nIs this understanding correct:\r\n- There's little performance gain in increasing the number of threads for a __single invocation__, i.e. by changing `thread_count` at [L58](https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/lite/kernels/internal/optimized/multithreaded_conv.h#L58).\r\n- There is, however, some performance gain if __several invocations__ are run in parallel (e.g. by using one thread for each).\r\n\r\n---------\r\n\r\nHypothetically, apart from the implementation difference between Eigen and gemmlowp, what differs floating point and integer so much that we can't (or shouldn't) even run floating point convolutions from more than *4* threads? IMO not all models are suitable for quantization.\r\n\r\nThank you!"}