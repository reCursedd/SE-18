{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/95426988", "pull_request_review_id": 15981265, "id": 95426988, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk1NDI2OTg4", "diff_hunk": "@@ -34,6 +41,115 @@\n  * }</pre>\n  */\n public final class Tensor implements AutoCloseable {\n+\n+  /**\n+   * Create a Tensor with data from the given buffer.\n+   *\n+   * <p>Provide a {@link ByteBuffer} to create a Tensor of any datatype.  Note that primitive\n+   * data must be in native byte order. Provide a {@link FloatBuffer}, {@link IntBuffer}, {@link DoubleBuffer},\n+   * or {@link LongBuffer} to create a Tensor with a datatype of {@code FLOAT}, {@code INT32}, {@code DOUBLE},\n+   * or {@code INT64} respectively.\n+   *\n+   * <p> This method copies\n+   * <i>n</i>&nbsp;=&nbsp;<tt>src.remaining()</tt> elements from the given\n+   * buffer into the tensor, starting at the buffer's current position.\n+   * The position of the buffer is then incremented by <i>n</i>.\n+   *\n+   * @param dataType the tensor datatype.\n+   * @param shape the tensor shape.\n+   * @param data a buffer containing the tensor data.\n+   */\n+  public static Tensor create(DataType dataType, long[] shape, Buffer data) {\n+    Tensor t = new Tensor();\n+    t.dtype = dataType;\n+    t.shapeCopy = Arrays.copyOf(shape, shape.length);\n+\n+    int elemsize = 0;\n+    if(data instanceof ByteBuffer) elemsize = 1;\n+    else if(data instanceof IntBuffer) elemsize = Integer.SIZE / Byte.SIZE;\n+    else if(data instanceof FloatBuffer) elemsize = Float.SIZE / Byte.SIZE;\n+    else if(data instanceof DoubleBuffer) elemsize = Double.SIZE / Byte.SIZE;\n+    else if(data instanceof LongBuffer) elemsize = Long.SIZE / Byte.SIZE;\n+    else throwIncompatibleBuffer();\n+\n+    t.nativeHandle = allocate(t.dtype.c(), t.shapeCopy, elemsize * data.remaining());\n+    try {\n+      ByteBuffer dst = getBuffer(t.nativeHandle);\n+      if(data instanceof ByteBuffer) {\n+        dst.put((ByteBuffer) data);\n+      }\n+      else if(data instanceof IntBuffer) {\n+        if(t.dtype != DataType.INT32) throwIncompatibleBuffer();\n+        dst.asIntBuffer().put((IntBuffer) data);\n+      }\n+      else if(data instanceof FloatBuffer) {\n+        if(t.dtype != DataType.FLOAT) throwIncompatibleBuffer();\n+        dst.asFloatBuffer().put((FloatBuffer) data);\n+      }\n+      else if(data instanceof DoubleBuffer) {\n+        if(t.dtype != DataType.DOUBLE) throwIncompatibleBuffer();\n+        dst.asDoubleBuffer().put((DoubleBuffer) data);\n+      }\n+      else if(data instanceof LongBuffer) {\n+        if(t.dtype != DataType.INT64) throwIncompatibleBuffer();\n+        dst.asLongBuffer().put((LongBuffer) data);\n+      }\n+\n+      return t;\n+    }\n+    catch(RuntimeException e) {\n+      delete(t.nativeHandle);\n+      throw e;\n+    }\n+  }\n+\n+  /**\n+   * Gets the size (in bytes) of the tensor data.\n+   *\n+   * <p>Use this size information when constructing a buffer with which to call {@link #readData(Buffer)}.\n+   */\n+  public int getDataByteSize() {\n+    return getBuffer(nativeHandle).remaining();\n+  }\n+    \n+  /**\n+   * Reads the tensor data into the given buffer.\n+   *\n+   * <p>Provide a {@link ByteBuffer} to read a Tensor of any datatype.  Note that primitive\n+   * data is in native byte order. Provide a {@link FloatBuffer}, {@link IntBuffer}, {@link DoubleBuffer},\n+   * or {@link LongBuffer} to read a Tensor with a datatype of {@code FLOAT}, {@code INT32}, {@code DOUBLE},\n+   * or {@code INT64} respectively.\n+   *\n+   * @param dst the destination buffer.\n+   */\n+  public void readData(Buffer dst) {", "path": "tensorflow/java/src/main/java/org/tensorflow/Tensor.java", "position": null, "original_position": 99, "commit_id": "5efc0f25336d5f3b5b5c82ab8d13e5929c3ba894", "original_commit_id": "1a2994b397a9697cefb31da4939e16415694a529", "user": {"login": "EronWright", "id": 1775518, "node_id": "MDQ6VXNlcjE3NzU1MTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1775518?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EronWright", "html_url": "https://github.com/EronWright", "followers_url": "https://api.github.com/users/EronWright/followers", "following_url": "https://api.github.com/users/EronWright/following{/other_user}", "gists_url": "https://api.github.com/users/EronWright/gists{/gist_id}", "starred_url": "https://api.github.com/users/EronWright/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EronWright/subscriptions", "organizations_url": "https://api.github.com/users/EronWright/orgs", "repos_url": "https://api.github.com/users/EronWright/repos", "events_url": "https://api.github.com/users/EronWright/events{/privacy}", "received_events_url": "https://api.github.com/users/EronWright/received_events", "type": "User", "site_admin": false}, "body": "Keep in mind that `FloatBuffer`s that wrap an array are writable, so `copyTo` applied to a float buffer is more efficient than it would be if applied to a `ByteBuffer` (assuming you ultimately want a `float[]` via `FloatBuffer::array()`).\r\n\r\nI agree that the lack of guidance on sizing of typed buffers is inconvenient, but some utility methods might be enough.\r\n\r\nKeeping with the power-over-convenience assumption, I'm inclined to provide optimized transfers.\r\n", "created_at": "2017-01-10T18:31:21Z", "updated_at": "2017-01-29T23:34:08Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/6577#discussion_r95426988", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6577", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/95426988"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/6577#discussion_r95426988"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6577"}}, "body_html": "<p>Keep in mind that <code>FloatBuffer</code>s that wrap an array are writable, so <code>copyTo</code> applied to a float buffer is more efficient than it would be if applied to a <code>ByteBuffer</code> (assuming you ultimately want a <code>float[]</code> via <code>FloatBuffer::array()</code>).</p>\n<p>I agree that the lack of guidance on sizing of typed buffers is inconvenient, but some utility methods might be enough.</p>\n<p>Keeping with the power-over-convenience assumption, I'm inclined to provide optimized transfers.</p>", "body_text": "Keep in mind that FloatBuffers that wrap an array are writable, so copyTo applied to a float buffer is more efficient than it would be if applied to a ByteBuffer (assuming you ultimately want a float[] via FloatBuffer::array()).\nI agree that the lack of guidance on sizing of typed buffers is inconvenient, but some utility methods might be enough.\nKeeping with the power-over-convenience assumption, I'm inclined to provide optimized transfers.", "in_reply_to_id": 95071278}