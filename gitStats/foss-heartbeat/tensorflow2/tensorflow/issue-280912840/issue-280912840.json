{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15261", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15261/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15261/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15261/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15261", "id": 280912840, "node_id": "MDU6SXNzdWUyODA5MTI4NDA=", "number": 15261, "title": "ValueError: Variable Model/LSTMenc/rnn/basic_lstm_cell/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?", "user": {"login": "Achilles-96", "id": 10742413, "node_id": "MDQ6VXNlcjEwNzQyNDEz", "avatar_url": "https://avatars1.githubusercontent.com/u/10742413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Achilles-96", "html_url": "https://github.com/Achilles-96", "followers_url": "https://api.github.com/users/Achilles-96/followers", "following_url": "https://api.github.com/users/Achilles-96/following{/other_user}", "gists_url": "https://api.github.com/users/Achilles-96/gists{/gist_id}", "starred_url": "https://api.github.com/users/Achilles-96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Achilles-96/subscriptions", "organizations_url": "https://api.github.com/users/Achilles-96/orgs", "repos_url": "https://api.github.com/users/Achilles-96/repos", "events_url": "https://api.github.com/users/Achilles-96/events{/privacy}", "received_events_url": "https://api.github.com/users/Achilles-96/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-11T06:59:55Z", "updated_at": "2017-12-11T19:11:20Z", "closed_at": "2017-12-11T19:11:20Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')</li>\n<li><strong>Python version</strong>: 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>If I put reuse=None while creating BasicLSTMCell in the following code, I get this error:</p>\n<pre><code>Traceback (most recent call last):\n  File \"pretrain.py\", line 358, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"pretrain.py\", line 251, in main\n    valid_model = build_model(word_vocab, train=False)\n  File \"pretrain.py\", line 200, in build_model\n    dropout=FLAGS.dropout))\n  File \"/home/raghuram.vadapalli/styletransfer/NeuralSum/model.py\", line 218, in lstm_doc_enc\n    initial_state=initial_rnn_state, dtype=tf.float32)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\n    (output, state) = call_cell()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in &lt;lambda&gt;\n    call_cell = lambda: cell(input_, state)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 235, in __call__\n    with _checked_scope(self, scope or \"basic_lstm_cell\", reuse=self._reuse):\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 93, in _checked_scope\n    \"the argument reuse=True.\" % (scope_name, type(cell).__name__))\nValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'Model/LSTMenc/rnn/basic_lstm_cell'; and the cell was not constructed as BasicLSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.\n</code></pre>\n<p>If I put reuse=True, I get this error</p>\n<pre><code>Traceback (most recent call last):\n  File \"pretrain.py\", line 358, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"pretrain.py\", line 244, in main\n    train_model = build_model(word_vocab, train=True)\n  File \"pretrain.py\", line 146, in build_model\n    dropout=FLAGS.dropout))\n  File \"/home/raghuram.vadapalli/styletransfer/NeuralSum/model.py\", line 218, in lstm_doc_enc\n    initial_state=initial_rnn_state, dtype=tf.float32)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\n    (output, state) = call_cell()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in &lt;lambda&gt;\n    call_cell = lambda: cell(input_, state)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 713, in __call__\n    output, new_state = self._cell(inputs, state, scope)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 241, in __call__\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 1044, in _linear\n    _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size], dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1049, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 948, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 356, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 341, in _true_getter\n    use_resource=use_resource)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 671, in _get_single_variable\n    \"VarScope?\" % name)\nValueError: Variable Model/LSTMenc/rnn/basic_lstm_cell/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\n</code></pre>\n<h3>Source code / logs</h3>\n<pre><code>def lstm_doc_enc(input_cnn,\n                   batch_size=20,\n                   num_rnn_layers=2,\n                   rnn_size=650,\n                   max_doc_length=35,\n                   dropout=0.0):\n\n    # lstm document encoder\n    with tf.variable_scope('LSTMenc') as scope:\n        def create_rnn_cell():\n            cell = tf.contrib.rnn.BasicLSTMCell(rnn_size, state_is_tuple=True, forget_bias=0.0, reuse=True)\n            if dropout &gt; 0.0:\n                cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.-dropout)\n            return cell\n\n        if num_rnn_layers &gt; 1:\n            cell = tf.contrib.rnn.MultiRNNCell([create_rnn_cell() for _ in range(num_rnn_layers)], state_is_tuple=True)\n        else:\n            cell = create_rnn_cell()\n\n        initial_rnn_state = cell.zero_state(batch_size, dtype=tf.float32)\n\n        input_cnn = tf.reshape(input_cnn, [batch_size, max_doc_length, -1])\n        input_cnn2 = [tf.squeeze(x, [1]) for x in tf.split(input_cnn, max_doc_length, 1)]\n\n        outputs, final_rnn_state = tf.contrib.rnn.static_rnn(cell, input_cnn2,\n                                         initial_state=initial_rnn_state, dtype=tf.float32)\n\n    return adict(\n        initial_enc_state=initial_rnn_state,\n        final_enc_state=final_rnn_state,\n        enc_outputs=outputs\n    )\n\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below): ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\nPython version: 2.7.12\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nIf I put reuse=None while creating BasicLSTMCell in the following code, I get this error:\nTraceback (most recent call last):\n  File \"pretrain.py\", line 358, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"pretrain.py\", line 251, in main\n    valid_model = build_model(word_vocab, train=False)\n  File \"pretrain.py\", line 200, in build_model\n    dropout=FLAGS.dropout))\n  File \"/home/raghuram.vadapalli/styletransfer/NeuralSum/model.py\", line 218, in lstm_doc_enc\n    initial_state=initial_rnn_state, dtype=tf.float32)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\n    (output, state) = call_cell()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\n    call_cell = lambda: cell(input_, state)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 235, in __call__\n    with _checked_scope(self, scope or \"basic_lstm_cell\", reuse=self._reuse):\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 93, in _checked_scope\n    \"the argument reuse=True.\" % (scope_name, type(cell).__name__))\nValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'Model/LSTMenc/rnn/basic_lstm_cell'; and the cell was not constructed as BasicLSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.\n\nIf I put reuse=True, I get this error\nTraceback (most recent call last):\n  File \"pretrain.py\", line 358, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"pretrain.py\", line 244, in main\n    train_model = build_model(word_vocab, train=True)\n  File \"pretrain.py\", line 146, in build_model\n    dropout=FLAGS.dropout))\n  File \"/home/raghuram.vadapalli/styletransfer/NeuralSum/model.py\", line 218, in lstm_doc_enc\n    initial_state=initial_rnn_state, dtype=tf.float32)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\n    (output, state) = call_cell()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\n    call_cell = lambda: cell(input_, state)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 713, in __call__\n    output, new_state = self._cell(inputs, state, scope)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 241, in __call__\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 1044, in _linear\n    _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size], dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1049, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 948, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 356, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 341, in _true_getter\n    use_resource=use_resource)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 671, in _get_single_variable\n    \"VarScope?\" % name)\nValueError: Variable Model/LSTMenc/rnn/basic_lstm_cell/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\n\nSource code / logs\ndef lstm_doc_enc(input_cnn,\n                   batch_size=20,\n                   num_rnn_layers=2,\n                   rnn_size=650,\n                   max_doc_length=35,\n                   dropout=0.0):\n\n    # lstm document encoder\n    with tf.variable_scope('LSTMenc') as scope:\n        def create_rnn_cell():\n            cell = tf.contrib.rnn.BasicLSTMCell(rnn_size, state_is_tuple=True, forget_bias=0.0, reuse=True)\n            if dropout > 0.0:\n                cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.-dropout)\n            return cell\n\n        if num_rnn_layers > 1:\n            cell = tf.contrib.rnn.MultiRNNCell([create_rnn_cell() for _ in range(num_rnn_layers)], state_is_tuple=True)\n        else:\n            cell = create_rnn_cell()\n\n        initial_rnn_state = cell.zero_state(batch_size, dtype=tf.float32)\n\n        input_cnn = tf.reshape(input_cnn, [batch_size, max_doc_length, -1])\n        input_cnn2 = [tf.squeeze(x, [1]) for x in tf.split(input_cnn, max_doc_length, 1)]\n\n        outputs, final_rnn_state = tf.contrib.rnn.static_rnn(cell, input_cnn2,\n                                         initial_state=initial_rnn_state, dtype=tf.float32)\n\n    return adict(\n        initial_enc_state=initial_rnn_state,\n        final_enc_state=final_rnn_state,\n        enc_outputs=outputs\n    )", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nIf I put reuse=None while creating BasicLSTMCell in the following code, I get this error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"pretrain.py\", line 358, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"pretrain.py\", line 251, in main\r\n    valid_model = build_model(word_vocab, train=False)\r\n  File \"pretrain.py\", line 200, in build_model\r\n    dropout=FLAGS.dropout))\r\n  File \"/home/raghuram.vadapalli/styletransfer/NeuralSum/model.py\", line 218, in lstm_doc_enc\r\n    initial_state=initial_rnn_state, dtype=tf.float32)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\r\n    (output, state) = call_cell()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\r\n    call_cell = lambda: cell(input_, state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 235, in __call__\r\n    with _checked_scope(self, scope or \"basic_lstm_cell\", reuse=self._reuse):\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 93, in _checked_scope\r\n    \"the argument reuse=True.\" % (scope_name, type(cell).__name__))\r\nValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'Model/LSTMenc/rnn/basic_lstm_cell'; and the cell was not constructed as BasicLSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.\r\n```\r\nIf I put reuse=True, I get this error\r\n```\r\nTraceback (most recent call last):\r\n  File \"pretrain.py\", line 358, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"pretrain.py\", line 244, in main\r\n    train_model = build_model(word_vocab, train=True)\r\n  File \"pretrain.py\", line 146, in build_model\r\n    dropout=FLAGS.dropout))\r\n  File \"/home/raghuram.vadapalli/styletransfer/NeuralSum/model.py\", line 218, in lstm_doc_enc\r\n    initial_state=initial_rnn_state, dtype=tf.float32)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\r\n    (output, state) = call_cell()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\r\n    call_cell = lambda: cell(input_, state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 713, in __call__\r\n    output, new_state = self._cell(inputs, state, scope)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 241, in __call__\r\n    concat = _linear([inputs, h], 4 * self._num_units, True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 1044, in _linear\r\n    _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size], dtype=dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1049, in get_variable\r\n    use_resource=use_resource, custom_getter=custom_getter)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 948, in get_variable\r\n    use_resource=use_resource, custom_getter=custom_getter)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 356, in get_variable\r\n    validate_shape=validate_shape, use_resource=use_resource)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 341, in _true_getter\r\n    use_resource=use_resource)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 671, in _get_single_variable\r\n    \"VarScope?\" % name)\r\nValueError: Variable Model/LSTMenc/rnn/basic_lstm_cell/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\r\n```\r\n### Source code / logs\r\n```\r\ndef lstm_doc_enc(input_cnn,\r\n                   batch_size=20,\r\n                   num_rnn_layers=2,\r\n                   rnn_size=650,\r\n                   max_doc_length=35,\r\n                   dropout=0.0):\r\n\r\n    # lstm document encoder\r\n    with tf.variable_scope('LSTMenc') as scope:\r\n        def create_rnn_cell():\r\n            cell = tf.contrib.rnn.BasicLSTMCell(rnn_size, state_is_tuple=True, forget_bias=0.0, reuse=True)\r\n            if dropout > 0.0:\r\n                cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.-dropout)\r\n            return cell\r\n\r\n        if num_rnn_layers > 1:\r\n            cell = tf.contrib.rnn.MultiRNNCell([create_rnn_cell() for _ in range(num_rnn_layers)], state_is_tuple=True)\r\n        else:\r\n            cell = create_rnn_cell()\r\n\r\n        initial_rnn_state = cell.zero_state(batch_size, dtype=tf.float32)\r\n\r\n        input_cnn = tf.reshape(input_cnn, [batch_size, max_doc_length, -1])\r\n        input_cnn2 = [tf.squeeze(x, [1]) for x in tf.split(input_cnn, max_doc_length, 1)]\r\n\r\n        outputs, final_rnn_state = tf.contrib.rnn.static_rnn(cell, input_cnn2,\r\n                                         initial_state=initial_rnn_state, dtype=tf.float32)\r\n\r\n    return adict(\r\n        initial_enc_state=initial_rnn_state,\r\n        final_enc_state=final_rnn_state,\r\n        enc_outputs=outputs\r\n    )\r\n\r\n```\r\n"}