{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/350464452", "html_url": "https://github.com/tensorflow/tensorflow/issues/14107#issuecomment-350464452", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14107", "id": 350464452, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDQ2NDQ1Mg==", "user": {"login": "codrut3", "id": 10788581, "node_id": "MDQ6VXNlcjEwNzg4NTgx", "avatar_url": "https://avatars1.githubusercontent.com/u/10788581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codrut3", "html_url": "https://github.com/codrut3", "followers_url": "https://api.github.com/users/codrut3/followers", "following_url": "https://api.github.com/users/codrut3/following{/other_user}", "gists_url": "https://api.github.com/users/codrut3/gists{/gist_id}", "starred_url": "https://api.github.com/users/codrut3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codrut3/subscriptions", "organizations_url": "https://api.github.com/users/codrut3/orgs", "repos_url": "https://api.github.com/users/codrut3/repos", "events_url": "https://api.github.com/users/codrut3/events{/privacy}", "received_events_url": "https://api.github.com/users/codrut3/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-09T13:12:35Z", "updated_at": "2017-12-09T13:13:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The OOM issue reported by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15482785\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/johnsrude\">@johnsrude</a> is likely caused by fused batch norm. The documentation incorrectly states that <code>tf.contrib.layers.batch_norm</code> with <code>Fused=None</code> will use the default implementation. This is not true: it will call the newer, fused version, which is more expensive in terms of gpu resources.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15482785\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/johnsrude\">@johnsrude</a>, can you please replace <code>batch_norm_layer</code> in model.py with the following:</p>\n<pre><code>def batch_norm_layer(inputT, is_training, scope):\n  return tf.cond(is_training,\n          lambda: tf.contrib.layers.batch_norm(inputT, is_training=True,\n                           center=False, updates_collections=None, scope=scope+\"_bn\", fused=False),\n          lambda: tf.contrib.layers.batch_norm(inputT, is_training=False,\n                           updates_collections=None, center=False, scope=scope+\"_bn\", reuse = True, fused=False))\n</code></pre>\n<p>Let me know if this solves the OOM problem.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=26190682\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bshao001\">@bshao001</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2109115\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jmaye\">@jmaye</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3680307\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/11maxed11\">@11maxed11</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4436747\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/eyaler\">@eyaler</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4131870\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/songgc\">@songgc</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20071323\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colmantse\">@colmantse</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25878853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NicholaiStaalung\">@NicholaiStaalung</a><br>\nplease consider posting the code that reproduces the issue, otherwise it is very hard to find the root cause.</p>", "body_text": "The OOM issue reported by @johnsrude is likely caused by fused batch norm. The documentation incorrectly states that tf.contrib.layers.batch_norm with Fused=None will use the default implementation. This is not true: it will call the newer, fused version, which is more expensive in terms of gpu resources.\n@johnsrude, can you please replace batch_norm_layer in model.py with the following:\ndef batch_norm_layer(inputT, is_training, scope):\n  return tf.cond(is_training,\n          lambda: tf.contrib.layers.batch_norm(inputT, is_training=True,\n                           center=False, updates_collections=None, scope=scope+\"_bn\", fused=False),\n          lambda: tf.contrib.layers.batch_norm(inputT, is_training=False,\n                           updates_collections=None, center=False, scope=scope+\"_bn\", reuse = True, fused=False))\n\nLet me know if this solves the OOM problem.\n@bshao001 @jmaye @11maxed11 @eyaler @songgc @colmantse @NicholaiStaalung\nplease consider posting the code that reproduces the issue, otherwise it is very hard to find the root cause.", "body": "The OOM issue reported by @johnsrude is likely caused by fused batch norm. The documentation incorrectly states that `tf.contrib.layers.batch_norm` with `Fused=None` will use the default implementation. This is not true: it will call the newer, fused version, which is more expensive in terms of gpu resources.\r\n\r\n@johnsrude, can you please replace `batch_norm_layer` in model.py with the following:\r\n\r\n```\r\ndef batch_norm_layer(inputT, is_training, scope):\r\n  return tf.cond(is_training,\r\n          lambda: tf.contrib.layers.batch_norm(inputT, is_training=True,\r\n                           center=False, updates_collections=None, scope=scope+\"_bn\", fused=False),\r\n          lambda: tf.contrib.layers.batch_norm(inputT, is_training=False,\r\n                           updates_collections=None, center=False, scope=scope+\"_bn\", reuse = True, fused=False))\r\n```\r\n\r\nLet me know if this solves the OOM problem.\r\n\r\n@bshao001 @jmaye @11maxed11 @eyaler @songgc @colmantse @NicholaiStaalung \r\nplease consider posting the code that reproduces the issue, otherwise it is very hard to find the root cause."}