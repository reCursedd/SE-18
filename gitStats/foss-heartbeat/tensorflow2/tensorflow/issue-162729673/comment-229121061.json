{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/229121061", "html_url": "https://github.com/tensorflow/tensorflow/issues/3080#issuecomment-229121061", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3080", "id": 229121061, "node_id": "MDEyOklzc3VlQ29tbWVudDIyOTEyMTA2MQ==", "user": {"login": "SimsGautam", "id": 6364058, "node_id": "MDQ6VXNlcjYzNjQwNTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/6364058?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SimsGautam", "html_url": "https://github.com/SimsGautam", "followers_url": "https://api.github.com/users/SimsGautam/followers", "following_url": "https://api.github.com/users/SimsGautam/following{/other_user}", "gists_url": "https://api.github.com/users/SimsGautam/gists{/gist_id}", "starred_url": "https://api.github.com/users/SimsGautam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SimsGautam/subscriptions", "organizations_url": "https://api.github.com/users/SimsGautam/orgs", "repos_url": "https://api.github.com/users/SimsGautam/repos", "events_url": "https://api.github.com/users/SimsGautam/events{/privacy}", "received_events_url": "https://api.github.com/users/SimsGautam/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-28T17:27:54Z", "updated_at": "2016-06-28T17:27:54Z", "author_association": "NONE", "body_html": "<p>If I run this snippet instead of the one earlier, then <code>model</code> is 2.0M, but <code>model.meta</code> is 8.0K. My question regards why running the earlier code (when weights/biases were initialized with a numpy array) result in both <code>model</code> and <code>model.meta</code> size to be 2.0M, whereas that's not the case here.</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(tf.float32, [None, 1000], name='input')\n\nW = tf.Variable(tf.random_normal([1000,500]))\nb = tf.Variable(tf.random_normal([500]))\n\nfc = tf.matmul(x, W, name='fc1')\nfc = tf.nn.bias_add(fc, b)\ny_pred = tf.nn.softmax(fc, name='output')\n\n# saving model\nsess = tf.Session()\ninit_op = tf.initialize_all_variables()\nsess.run(init_op)\nsaver = tf.train.Saver()\nsaver.save(sess, \"model\")\n</code></pre>", "body_text": "If I run this snippet instead of the one earlier, then model is 2.0M, but model.meta is 8.0K. My question regards why running the earlier code (when weights/biases were initialized with a numpy array) result in both model and model.meta size to be 2.0M, whereas that's not the case here.\nimport tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(tf.float32, [None, 1000], name='input')\n\nW = tf.Variable(tf.random_normal([1000,500]))\nb = tf.Variable(tf.random_normal([500]))\n\nfc = tf.matmul(x, W, name='fc1')\nfc = tf.nn.bias_add(fc, b)\ny_pred = tf.nn.softmax(fc, name='output')\n\n# saving model\nsess = tf.Session()\ninit_op = tf.initialize_all_variables()\nsess.run(init_op)\nsaver = tf.train.Saver()\nsaver.save(sess, \"model\")", "body": "If I run this snippet instead of the one earlier, then `model` is 2.0M, but `model.meta` is 8.0K. My question regards why running the earlier code (when weights/biases were initialized with a numpy array) result in both `model` and `model.meta` size to be 2.0M, whereas that's not the case here.\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(tf.float32, [None, 1000], name='input')\n\nW = tf.Variable(tf.random_normal([1000,500]))\nb = tf.Variable(tf.random_normal([500]))\n\nfc = tf.matmul(x, W, name='fc1')\nfc = tf.nn.bias_add(fc, b)\ny_pred = tf.nn.softmax(fc, name='output')\n\n# saving model\nsess = tf.Session()\ninit_op = tf.initialize_all_variables()\nsess.run(init_op)\nsaver = tf.train.Saver()\nsaver.save(sess, \"model\")\n```\n"}