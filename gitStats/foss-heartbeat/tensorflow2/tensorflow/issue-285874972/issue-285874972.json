{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15831", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15831/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15831/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15831/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15831", "id": 285874972, "node_id": "MDU6SXNzdWUyODU4NzQ5NzI=", "number": 15831, "title": "Using keras and tf.keras has different result", "user": {"login": "rubiagatra", "id": 7299491, "node_id": "MDQ6VXNlcjcyOTk0OTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/7299491?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rubiagatra", "html_url": "https://github.com/rubiagatra", "followers_url": "https://api.github.com/users/rubiagatra/followers", "following_url": "https://api.github.com/users/rubiagatra/following{/other_user}", "gists_url": "https://api.github.com/users/rubiagatra/gists{/gist_id}", "starred_url": "https://api.github.com/users/rubiagatra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rubiagatra/subscriptions", "organizations_url": "https://api.github.com/users/rubiagatra/orgs", "repos_url": "https://api.github.com/users/rubiagatra/repos", "events_url": "https://api.github.com/users/rubiagatra/events{/privacy}", "received_events_url": "https://api.github.com/users/rubiagatra/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2018-01-04T03:52:08Z", "updated_at": "2018-06-22T11:55:00Z", "closed_at": "2018-06-22T11:55:00Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>TensorFlow)</strong>:</li>\n<li><strong>Linux Ubuntu 16.04</strong>:</li>\n<li><strong>TensorFlow installed from Binary</strong>:</li>\n<li><strong>TensorFlow version (1.4)</strong>:</li>\n<li><strong>Python version 3.6.3</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am using tf.keras and keras but it has a different result. I am using the code below for sentiment analysis classification using imdb dataset.</p>\n<h3>Source code / logs</h3>\n<pre><code>model = Sequential()\nmodel.add(Embedding(n_unique_words, n_dim, input_length=max_reviw_length))\nmodel.add(Flatten())\nmodel.add(Dense(n_dense, activation='relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary() \n</code></pre>\n<pre><code>_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 100, 64)           320000    \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 6400)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                409664    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 729,729\nTrainable params: 729,729\nNon-trainable params: 0\n__________________________\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])\n</code></pre>\n<p>preprocessing all exact the same</p>\n<p>tf.keras result</p>\n<pre><code>Train on 25000 samples, validate on 25000 samples\nEpoch 1/4\n25000/25000 [==============================] - 9s - loss: 0.7412 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.50000.4\nEpoch 2/4\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.5000\nEpoch 3/4\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000\nEpoch 4/4\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.4942 - val_loss: 0.6931 - val_acc: 0.5000\n\n&lt;tensorflow.python.keras._impl.keras.callbacks.History at 0x7fad685e7c18&gt;\n</code></pre>\n<p>keras result</p>\n<pre><code>Train on 25000 samples, validate on 25000 samples\nEpoch 1/4\n25000/25000 [==============================] - 9s 344us/step - loss: 0.5607 - acc: 0.6900 - val_loss: 0.3622 - val_acc: 0.8404\nEpoch 2/4\n25000/25000 [==============================] - 8s 308us/step - loss: 0.2849 - acc: 0.8849 - val_loss: 0.3486 - val_acc: 0.8446\nEpoch 3/4\n25000/25000 [==============================] - 8s 305us/step - loss: 0.1179 - acc: 0.9642 - val_loss: 0.4183 - val_acc: 0.8339\nEpoch 4/4\n25000/25000 [==============================] - 8s 307us/step - loss: 0.0252 - acc: 0.9960 - val_loss: 0.5202 - val_acc: 0.8345\n\n&lt;keras.callbacks.History at 0x7f560b85d940&gt;\n\n\n</code></pre>", "body_text": "System information\n\nTensorFlow):\nLinux Ubuntu 16.04:\nTensorFlow installed from Binary:\nTensorFlow version (1.4):\nPython version 3.6.3:\n\nDescribe the problem\nI am using tf.keras and keras but it has a different result. I am using the code below for sentiment analysis classification using imdb dataset.\nSource code / logs\nmodel = Sequential()\nmodel.add(Embedding(n_unique_words, n_dim, input_length=max_reviw_length))\nmodel.add(Flatten())\nmodel.add(Dense(n_dense, activation='relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary() \n\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 100, 64)           320000    \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 6400)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                409664    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 729,729\nTrainable params: 729,729\nNon-trainable params: 0\n__________________________\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])\n\npreprocessing all exact the same\ntf.keras result\nTrain on 25000 samples, validate on 25000 samples\nEpoch 1/4\n25000/25000 [==============================] - 9s - loss: 0.7412 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.50000.4\nEpoch 2/4\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.5000\nEpoch 3/4\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000\nEpoch 4/4\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.4942 - val_loss: 0.6931 - val_acc: 0.5000\n\n<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fad685e7c18>\n\nkeras result\nTrain on 25000 samples, validate on 25000 samples\nEpoch 1/4\n25000/25000 [==============================] - 9s 344us/step - loss: 0.5607 - acc: 0.6900 - val_loss: 0.3622 - val_acc: 0.8404\nEpoch 2/4\n25000/25000 [==============================] - 8s 308us/step - loss: 0.2849 - acc: 0.8849 - val_loss: 0.3486 - val_acc: 0.8446\nEpoch 3/4\n25000/25000 [==============================] - 8s 305us/step - loss: 0.1179 - acc: 0.9642 - val_loss: 0.4183 - val_acc: 0.8339\nEpoch 4/4\n25000/25000 [==============================] - 8s 307us/step - loss: 0.0252 - acc: 0.9960 - val_loss: 0.5202 - val_acc: 0.8345\n\n<keras.callbacks.History at 0x7f560b85d940>", "body": "### System information\r\n- **TensorFlow)**:\r\n- **Linux Ubuntu 16.04**:\r\n- **TensorFlow installed from Binary**:\r\n- **TensorFlow version (1.4)**:\r\n- **Python version 3.6.3**: \r\n\r\n### Describe the problem\r\nI am using tf.keras and keras but it has a different result. I am using the code below for sentiment analysis classification using imdb dataset.\r\n### Source code / logs\r\n```\r\nmodel = Sequential()\r\nmodel.add(Embedding(n_unique_words, n_dim, input_length=max_reviw_length))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(n_dense, activation='relu'))\r\nmodel.add(Dropout(dropout))\r\nmodel.add(Dense(1, activation='sigmoid'))\r\nmodel.summary() \r\n```\r\n\r\n\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nembedding_1 (Embedding)      (None, 100, 64)           320000    \r\n_________________________________________________________________\r\nflatten_1 (Flatten)          (None, 6400)              0         \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 64)                409664    \r\n_________________________________________________________________\r\ndropout_1 (Dropout)          (None, 64)                0         \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 1)                 65        \r\n=================================================================\r\nTotal params: 729,729\r\nTrainable params: 729,729\r\nNon-trainable params: 0\r\n__________________________\r\n\r\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])\r\n```\r\npreprocessing all exact the same\r\n\r\ntf.keras result\r\n\r\n```\r\nTrain on 25000 samples, validate on 25000 samples\r\nEpoch 1/4\r\n25000/25000 [==============================] - 9s - loss: 0.7412 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.50000.4\r\nEpoch 2/4\r\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.5000\r\nEpoch 3/4\r\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000\r\nEpoch 4/4\r\n25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.4942 - val_loss: 0.6931 - val_acc: 0.5000\r\n\r\n<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fad685e7c18>\r\n```\r\n\r\nkeras result\r\n\r\n```\r\nTrain on 25000 samples, validate on 25000 samples\r\nEpoch 1/4\r\n25000/25000 [==============================] - 9s 344us/step - loss: 0.5607 - acc: 0.6900 - val_loss: 0.3622 - val_acc: 0.8404\r\nEpoch 2/4\r\n25000/25000 [==============================] - 8s 308us/step - loss: 0.2849 - acc: 0.8849 - val_loss: 0.3486 - val_acc: 0.8446\r\nEpoch 3/4\r\n25000/25000 [==============================] - 8s 305us/step - loss: 0.1179 - acc: 0.9642 - val_loss: 0.4183 - val_acc: 0.8339\r\nEpoch 4/4\r\n25000/25000 [==============================] - 8s 307us/step - loss: 0.0252 - acc: 0.9960 - val_loss: 0.5202 - val_acc: 0.8345\r\n\r\n<keras.callbacks.History at 0x7f560b85d940>\r\n\r\n\r\n```"}