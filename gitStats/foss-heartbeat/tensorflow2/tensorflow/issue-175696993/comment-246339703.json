{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/246339703", "html_url": "https://github.com/tensorflow/tensorflow/issues/4272#issuecomment-246339703", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4272", "id": 246339703, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NjMzOTcwMw==", "user": {"login": "JianbangZ", "id": 15835199, "node_id": "MDQ6VXNlcjE1ODM1MTk5", "avatar_url": "https://avatars1.githubusercontent.com/u/15835199?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JianbangZ", "html_url": "https://github.com/JianbangZ", "followers_url": "https://api.github.com/users/JianbangZ/followers", "following_url": "https://api.github.com/users/JianbangZ/following{/other_user}", "gists_url": "https://api.github.com/users/JianbangZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/JianbangZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JianbangZ/subscriptions", "organizations_url": "https://api.github.com/users/JianbangZ/orgs", "repos_url": "https://api.github.com/users/JianbangZ/repos", "events_url": "https://api.github.com/users/JianbangZ/events{/privacy}", "received_events_url": "https://api.github.com/users/JianbangZ/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-12T13:01:16Z", "updated_at": "2016-09-12T13:01:16Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7776101\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dashrathc\">@dashrathc</a><br>\nHi, having two queues is fine. It may consume CPU a little bit more, but from my experience, at least for two GPU cards, it works equivalent as one queue.<br>\nOne thing to remember is too adjust the batch_size correctly. For the cifar10 example, batch_size is the size for each GPU card not the overall batch size. So if you are using batch_size=128 for one GPU, you should change batch_size=64 for two GPUs to notice the speed difference.</p>", "body_text": "@dashrathc\nHi, having two queues is fine. It may consume CPU a little bit more, but from my experience, at least for two GPU cards, it works equivalent as one queue.\nOne thing to remember is too adjust the batch_size correctly. For the cifar10 example, batch_size is the size for each GPU card not the overall batch size. So if you are using batch_size=128 for one GPU, you should change batch_size=64 for two GPUs to notice the speed difference.", "body": "@dashrathc \nHi, having two queues is fine. It may consume CPU a little bit more, but from my experience, at least for two GPU cards, it works equivalent as one queue.\nOne thing to remember is too adjust the batch_size correctly. For the cifar10 example, batch_size is the size for each GPU card not the overall batch size. So if you are using batch_size=128 for one GPU, you should change batch_size=64 for two GPUs to notice the speed difference. \n"}