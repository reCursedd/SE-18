{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/435127924", "html_url": "https://github.com/tensorflow/tensorflow/issues/20346#issuecomment-435127924", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20346", "id": 435127924, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTEyNzkyNA==", "user": {"login": "benbotto", "id": 14243981, "node_id": "MDQ6VXNlcjE0MjQzOTgx", "avatar_url": "https://avatars1.githubusercontent.com/u/14243981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benbotto", "html_url": "https://github.com/benbotto", "followers_url": "https://api.github.com/users/benbotto/followers", "following_url": "https://api.github.com/users/benbotto/following{/other_user}", "gists_url": "https://api.github.com/users/benbotto/gists{/gist_id}", "starred_url": "https://api.github.com/users/benbotto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benbotto/subscriptions", "organizations_url": "https://api.github.com/users/benbotto/orgs", "repos_url": "https://api.github.com/users/benbotto/repos", "events_url": "https://api.github.com/users/benbotto/events{/privacy}", "received_events_url": "https://api.github.com/users/benbotto/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-01T17:55:20Z", "updated_at": "2018-11-01T17:55:20Z", "author_association": "NONE", "body_html": "<p>Thanks for the response, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a>.</p>\n<ol>\n<li>Right now I'm not actually creating a session explicitly as I'm using tf.keras which evidently creates a session behind the scenes.  It looks like Keras has the option of using a manually defined session (<code>tf.keras.backend.set_session</code>), so I'll try your config recommendation and see if I can get a better stack dump.</li>\n<li>I'm not using <code>tf.py_func</code> anywhere, no.  As far as I know both machines are using identical version of everything (Tensorflow, Keras, numpy, and all other dependencies).  I'm using virtualenv, and I set up both machines simultaneously.  I'll double check the np version, though.</li>\n</ol>\n<p>I wish I knew how to set up a smaller test case that would reproduce the issue--as a programmer I certainly understand how important that is--but I'm not sure how in this instance.  I don't think my code is doing anything out of the ordinary: I'm generating images, doing some basic processing on those (crop and grayscale and such), then feeding them through a rather trivial network.  I'm not <em>directly</em> using any threading in my code or anything else that would cause a deadlock.  All that is to say I wish I could be of more help (and furthermore I wish the code would run reliably on all my machines!).</p>\n<p>Anyway, I'll try again with the session configured as recommended and see if I can get another stack trace.  It may take a few weeks to lock up again.</p>", "body_text": "Thanks for the response, @mrry.\n\nRight now I'm not actually creating a session explicitly as I'm using tf.keras which evidently creates a session behind the scenes.  It looks like Keras has the option of using a manually defined session (tf.keras.backend.set_session), so I'll try your config recommendation and see if I can get a better stack dump.\nI'm not using tf.py_func anywhere, no.  As far as I know both machines are using identical version of everything (Tensorflow, Keras, numpy, and all other dependencies).  I'm using virtualenv, and I set up both machines simultaneously.  I'll double check the np version, though.\n\nI wish I knew how to set up a smaller test case that would reproduce the issue--as a programmer I certainly understand how important that is--but I'm not sure how in this instance.  I don't think my code is doing anything out of the ordinary: I'm generating images, doing some basic processing on those (crop and grayscale and such), then feeding them through a rather trivial network.  I'm not directly using any threading in my code or anything else that would cause a deadlock.  All that is to say I wish I could be of more help (and furthermore I wish the code would run reliably on all my machines!).\nAnyway, I'll try again with the session configured as recommended and see if I can get another stack trace.  It may take a few weeks to lock up again.", "body": "Thanks for the response, @mrry.\r\n\r\n1. Right now I'm not actually creating a session explicitly as I'm using tf.keras which evidently creates a session behind the scenes.  It looks like Keras has the option of using a manually defined session (`tf.keras.backend.set_session`), so I'll try your config recommendation and see if I can get a better stack dump.\r\n2. I'm not using `tf.py_func` anywhere, no.  As far as I know both machines are using identical version of everything (Tensorflow, Keras, numpy, and all other dependencies).  I'm using virtualenv, and I set up both machines simultaneously.  I'll double check the np version, though.\r\n\r\nI wish I knew how to set up a smaller test case that would reproduce the issue--as a programmer I certainly understand how important that is--but I'm not sure how in this instance.  I don't think my code is doing anything out of the ordinary: I'm generating images, doing some basic processing on those (crop and grayscale and such), then feeding them through a rather trivial network.  I'm not _directly_ using any threading in my code or anything else that would cause a deadlock.  All that is to say I wish I could be of more help (and furthermore I wish the code would run reliably on all my machines!).\r\n\r\nAnyway, I'll try again with the session configured as recommended and see if I can get another stack trace.  It may take a few weeks to lock up again."}