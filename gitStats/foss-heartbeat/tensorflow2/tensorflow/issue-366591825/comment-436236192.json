{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/436236192", "html_url": "https://github.com/tensorflow/tensorflow/pull/22713#issuecomment-436236192", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22713", "id": 436236192, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjIzNjE5Mg==", "user": {"login": "eryshev", "id": 7483130, "node_id": "MDQ6VXNlcjc0ODMxMzA=", "avatar_url": "https://avatars3.githubusercontent.com/u/7483130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eryshev", "html_url": "https://github.com/eryshev", "followers_url": "https://api.github.com/users/eryshev/followers", "following_url": "https://api.github.com/users/eryshev/following{/other_user}", "gists_url": "https://api.github.com/users/eryshev/gists{/gist_id}", "starred_url": "https://api.github.com/users/eryshev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eryshev/subscriptions", "organizations_url": "https://api.github.com/users/eryshev/orgs", "repos_url": "https://api.github.com/users/eryshev/repos", "events_url": "https://api.github.com/users/eryshev/events{/privacy}", "received_events_url": "https://api.github.com/users/eryshev/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-06T12:30:10Z", "updated_at": "2018-11-06T13:11:39Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1647833\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yuefengz\">@yuefengz</a> Hi, I've tested this change and it successfully launches the training.<br>\nHowever I'm a bit of confused as I launched only one TF instance of <code>ps</code> type and it started working without any additional <code>worker</code> task.</p>\n<p>For me it boils down to 2 questions:</p>\n<ol>\n<li>Do I still need to set <code>cluster_spec</code> via <code>TF_CONFIG</code> variable ? As for example</li>\n</ol>\n<pre><code>export TF_CONFIG='{\n    \"cluster\": {\n        \"ps\": [\n            \"localhost: 2222\"\n        ],\n        \"worker\": [\n            \"localhost: 3333\",\n            \"localhost: 3334\"\n        ]\n    },\n    \"task\": {\n        \"type\":\"ps\",\n        \"index\":0\n    }\n}'\n</code></pre>\n<ol start=\"2\">\n<li>Do I need to launch multiple TF instances with different <code>TF_CONFIG</code>(2 workers and PS) when I want to train locally or with the strategy TF will do for me? It seems like TF launches the training but it uses only 1 GPU from two available(note that I set <code>num_gpus_per_worker</code> as 1 on creation of ParameterServerStrategy and task defined in TF_CONFIG has <code>ps</code> type)<br>\nI'm sorry but I haven't seen any note about it in the documentation and I'm not familiar enough with codebase to figure it out by myself.</li>\n</ol>\n<p>Thank for your work.</p>", "body_text": "@yuefengz Hi, I've tested this change and it successfully launches the training.\nHowever I'm a bit of confused as I launched only one TF instance of ps type and it started working without any additional worker task.\nFor me it boils down to 2 questions:\n\nDo I still need to set cluster_spec via TF_CONFIG variable ? As for example\n\nexport TF_CONFIG='{\n    \"cluster\": {\n        \"ps\": [\n            \"localhost: 2222\"\n        ],\n        \"worker\": [\n            \"localhost: 3333\",\n            \"localhost: 3334\"\n        ]\n    },\n    \"task\": {\n        \"type\":\"ps\",\n        \"index\":0\n    }\n}'\n\n\nDo I need to launch multiple TF instances with different TF_CONFIG(2 workers and PS) when I want to train locally or with the strategy TF will do for me? It seems like TF launches the training but it uses only 1 GPU from two available(note that I set num_gpus_per_worker as 1 on creation of ParameterServerStrategy and task defined in TF_CONFIG has ps type)\nI'm sorry but I haven't seen any note about it in the documentation and I'm not familiar enough with codebase to figure it out by myself.\n\nThank for your work.", "body": "@yuefengz Hi, I've tested this change and it successfully launches the training. \r\nHowever I'm a bit of confused as I launched only one TF instance of `ps` type and it started working without any additional `worker` task.\r\n\r\nFor me it boils down to 2 questions:\r\n1. Do I still need to set `cluster_spec` via `TF_CONFIG` variable ? As for example\r\n```\r\nexport TF_CONFIG='{\r\n    \"cluster\": {\r\n        \"ps\": [\r\n            \"localhost: 2222\"\r\n        ],\r\n        \"worker\": [\r\n            \"localhost: 3333\",\r\n            \"localhost: 3334\"\r\n        ]\r\n    },\r\n    \"task\": {\r\n        \"type\":\"ps\",\r\n        \"index\":0\r\n    }\r\n}'\r\n```\r\n2. Do I need to launch multiple TF instances with different `TF_CONFIG`(2 workers and PS) when I want to train locally or with the strategy TF will do for me? It seems like TF launches the training but it uses only 1 GPU from two available(note that I set `num_gpus_per_worker` as 1 on creation of ParameterServerStrategy and task defined in TF_CONFIG has `ps` type)\r\nI'm sorry but I haven't seen any note about it in the documentation and I'm not familiar enough with codebase to figure it out by myself. \r\n\r\nThank for your work."}