{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/437577518", "html_url": "https://github.com/tensorflow/tensorflow/pull/22713#issuecomment-437577518", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22713", "id": 437577518, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzU3NzUxOA==", "user": {"login": "eryshev", "id": 7483130, "node_id": "MDQ6VXNlcjc0ODMxMzA=", "avatar_url": "https://avatars3.githubusercontent.com/u/7483130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eryshev", "html_url": "https://github.com/eryshev", "followers_url": "https://api.github.com/users/eryshev/followers", "following_url": "https://api.github.com/users/eryshev/following{/other_user}", "gists_url": "https://api.github.com/users/eryshev/gists{/gist_id}", "starred_url": "https://api.github.com/users/eryshev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eryshev/subscriptions", "organizations_url": "https://api.github.com/users/eryshev/orgs", "repos_url": "https://api.github.com/users/eryshev/repos", "events_url": "https://api.github.com/users/eryshev/events{/privacy}", "received_events_url": "https://api.github.com/users/eryshev/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-10T11:32:56Z", "updated_at": "2018-11-10T11:35:23Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1647833\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yuefengz\">@yuefengz</a><br>\nThe <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/66dd1e21e7ab6e2aed8413880a7f2dd7f0a20e50/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/66dd1e21e7ab6e2aed8413880a7f2dd7f0a20e50\"><tt>66dd1e2</tt></a> fixes the problem, thank you.<br>\nConcerning my two questions:</p>\n<ol>\n<li>Ok I got how it works for distributed setup (<a href=\"https://www.tensorflow.org/deploy/distributed#putting_it_all_together_example_trainer_program\" rel=\"nofollow\">this section</a> was quite helpful and I was missing it).</li>\n<li>However I'm not sure I understand what it does in local case:</li>\n</ol>\n<ul>\n<li>Does it create multiple workers/sessions?</li>\n<li>Is it between-graph replication?</li>\n<li>Is it in-graph with towers over multiple GPUs?</li>\n<li>Or operations are just split between GPUs and all variables are on CPU?</li>\n</ul>\n<p>Sorry for lots of questions, if you think it's more relevant to ask them on SO, I will.</p>", "body_text": "@yuefengz\nThe 66dd1e2 fixes the problem, thank you.\nConcerning my two questions:\n\nOk I got how it works for distributed setup (this section was quite helpful and I was missing it).\nHowever I'm not sure I understand what it does in local case:\n\n\nDoes it create multiple workers/sessions?\nIs it between-graph replication?\nIs it in-graph with towers over multiple GPUs?\nOr operations are just split between GPUs and all variables are on CPU?\n\nSorry for lots of questions, if you think it's more relevant to ask them on SO, I will.", "body": "@yuefengz \r\nThe 66dd1e2 fixes the problem, thank you.\r\nConcerning my two questions:\r\n1. Ok I got how it works for distributed setup ([this section](https://www.tensorflow.org/deploy/distributed#putting_it_all_together_example_trainer_program) was quite helpful and I was missing it).\r\n2. However I'm not sure I understand what it does in local case:\r\n- Does it create multiple workers/sessions?\r\n- Is it between-graph replication?\r\n- Is it in-graph with towers over multiple GPUs?\r\n- Or operations are just split between GPUs and all variables are on CPU?\r\n\r\nSorry for lots of questions, if you think it's more relevant to ask them on SO, I will.\r\n"}