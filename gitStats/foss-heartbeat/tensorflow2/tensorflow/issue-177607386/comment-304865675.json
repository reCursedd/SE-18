{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/304865675", "html_url": "https://github.com/tensorflow/tensorflow/issues/4427#issuecomment-304865675", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4427", "id": 304865675, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNDg2NTY3NQ==", "user": {"login": "classicCoder16", "id": 9311545, "node_id": "MDQ6VXNlcjkzMTE1NDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9311545?v=4", "gravatar_id": "", "url": "https://api.github.com/users/classicCoder16", "html_url": "https://github.com/classicCoder16", "followers_url": "https://api.github.com/users/classicCoder16/followers", "following_url": "https://api.github.com/users/classicCoder16/following{/other_user}", "gists_url": "https://api.github.com/users/classicCoder16/gists{/gist_id}", "starred_url": "https://api.github.com/users/classicCoder16/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/classicCoder16/subscriptions", "organizations_url": "https://api.github.com/users/classicCoder16/orgs", "repos_url": "https://api.github.com/users/classicCoder16/repos", "events_url": "https://api.github.com/users/classicCoder16/events{/privacy}", "received_events_url": "https://api.github.com/users/classicCoder16/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-30T12:40:36Z", "updated_at": "2017-05-30T12:40:36Z", "author_association": "NONE", "body_html": "<p>Hello, apologies if this might be an obvious question, but I have a basic question regarding applying the AttentionCellWrapper in practice -- in particular it seems that we never specify the memory (e.g. the set of encoder hidden states) during the creation of the wrapper.</p>\n<p>How then does the module know where to attend? Does the memory get passed somehow through the initial state of the decoder? A basic example of how to use the wrapper in practice would definitely be much appreciated. Thanks!</p>", "body_text": "Hello, apologies if this might be an obvious question, but I have a basic question regarding applying the AttentionCellWrapper in practice -- in particular it seems that we never specify the memory (e.g. the set of encoder hidden states) during the creation of the wrapper.\nHow then does the module know where to attend? Does the memory get passed somehow through the initial state of the decoder? A basic example of how to use the wrapper in practice would definitely be much appreciated. Thanks!", "body": "Hello, apologies if this might be an obvious question, but I have a basic question regarding applying the AttentionCellWrapper in practice -- in particular it seems that we never specify the memory (e.g. the set of encoder hidden states) during the creation of the wrapper. \r\n\r\nHow then does the module know where to attend? Does the memory get passed somehow through the initial state of the decoder? A basic example of how to use the wrapper in practice would definitely be much appreciated. Thanks!"}