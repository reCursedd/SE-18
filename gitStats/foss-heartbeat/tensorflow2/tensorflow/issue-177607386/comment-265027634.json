{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/265027634", "html_url": "https://github.com/tensorflow/tensorflow/issues/4427#issuecomment-265027634", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4427", "id": 265027634, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NTAyNzYzNA==", "user": {"login": "jessedaniels", "id": 1547979, "node_id": "MDQ6VXNlcjE1NDc5Nzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1547979?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jessedaniels", "html_url": "https://github.com/jessedaniels", "followers_url": "https://api.github.com/users/jessedaniels/followers", "following_url": "https://api.github.com/users/jessedaniels/following{/other_user}", "gists_url": "https://api.github.com/users/jessedaniels/gists{/gist_id}", "starred_url": "https://api.github.com/users/jessedaniels/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jessedaniels/subscriptions", "organizations_url": "https://api.github.com/users/jessedaniels/orgs", "repos_url": "https://api.github.com/users/jessedaniels/repos", "events_url": "https://api.github.com/users/jessedaniels/events{/privacy}", "received_events_url": "https://api.github.com/users/jessedaniels/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-06T00:53:26Z", "updated_at": "2016-12-06T00:53:26Z", "author_association": "NONE", "body_html": "<p><a href=\"https://theneuralperspective.com/2016/11/20/recurrent-neural-network-rnn-part-4-attentional-interfaces/\" rel=\"nofollow\">This post</a> gives a comprehensive and easy-to-follow overview of the current TF attention implementation in an encoder-decoder context. According to the author the implementation is based on the details at the end of the Bahdanau paper (<a href=\"https://arxiv.org/pdf/1409.0473v7\" rel=\"nofollow\">https://arxiv.org/pdf/1409.0473v7</a>). The author provides a nice walk-through of the details of attention and then goes into depth on the implementation. The discussion includes some detail on the use and motivation of conv2d in the code, which isn't mentioned in any papers that I've seen. Some of the variable names are slightly different but overall it really helped me understand what's going on.</p>", "body_text": "This post gives a comprehensive and easy-to-follow overview of the current TF attention implementation in an encoder-decoder context. According to the author the implementation is based on the details at the end of the Bahdanau paper (https://arxiv.org/pdf/1409.0473v7). The author provides a nice walk-through of the details of attention and then goes into depth on the implementation. The discussion includes some detail on the use and motivation of conv2d in the code, which isn't mentioned in any papers that I've seen. Some of the variable names are slightly different but overall it really helped me understand what's going on.", "body": "[This post](https://theneuralperspective.com/2016/11/20/recurrent-neural-network-rnn-part-4-attentional-interfaces/) gives a comprehensive and easy-to-follow overview of the current TF attention implementation in an encoder-decoder context. According to the author the implementation is based on the details at the end of the Bahdanau paper (https://arxiv.org/pdf/1409.0473v7). The author provides a nice walk-through of the details of attention and then goes into depth on the implementation. The discussion includes some detail on the use and motivation of conv2d in the code, which isn't mentioned in any papers that I've seen. Some of the variable names are slightly different but overall it really helped me understand what's going on."}