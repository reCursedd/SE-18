{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/327363768", "html_url": "https://github.com/tensorflow/tensorflow/issues/10815#issuecomment-327363768", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10815", "id": 327363768, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNzM2Mzc2OA==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-06T03:23:52Z", "updated_at": "2017-09-06T03:23:52Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">I think it's just setting the seed to get consistent samples.  Your\nrandomness is different between the two runs.\n\nAdam Roberts added two new inference helpers for this exact case, but they\nare only in the nightlies, not in tf 1.3.  look for InferenceHelper, which\nyou can use to implement sample-only decoding.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Aug 31, 2017 2:28 AM, \"chococig\" ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> &lt;<a href=\"https://github.com/ebrevdo\">https://github.com/ebrevdo</a>&gt;\n hello, I also have a question about ScheduledOutputTrainingHelper. I'm\n currently doing regression using ScheduledOutputTrainingHelper. But, in the\n inference stage, is it right to set the sampling probability to 1 and use\n an arbitrary input? For the classification case, GreedyEmbeddingHelper can\n be used, but for regression there is no Greedy'Output'Helper.\n\n    - sampling_probability: the probability of sampling from the outputs\n    instead of reading directly from the inputs.\n\n my decoder_input is like Start_value(zeros) + y_target[:-1]\n '''\n x_1 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_1])\n x_2 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_2])\n y_target = tf.placeholder(dtype=tf.float32, shape=[None, n_step, 1])\n\n phase = tf.placeholder(tf.bool) # if True: training / if False: inference\n length = tf.placeholder(dtype=tf.int32, shape=[None,])\n tf_batch_size = tf.placeholder(dtype=tf.int32, shape = [])\n\n encoder_input = tf.concat([x_1,x_2], axis=2)\n like Start_token + target[:-1]\n\n decoder_input = tf.concat([tf.fill([tf_batch_size,1,1], 0.0), # Start by\n Zeros\n y_target[:,:-1,:]], #targets[:-1]\n axis=1)\n '''\n then my decoder is like this\n\n def decoder(encoder_output, decoder_initial_state, decoder_dimension, phase):\n     cell = LayerNormBasicLSTMCell(decoder_dimension)\n\n     cell = AttentionWrapper(cell,\n                             attention_mechanism=BahdanauAttention(decoder_dimension, encoder_output),\n                             initial_cell_state = (LSTMStateTuple(decoder_initial_state, decoder_initial_state)),\n                             alignment_history = True)\n\n     output_cell = OutputProjectionWrapper(cell, output_size=1)\n\n     sampling_prob = tf.cond(phase,\n\n                             #training\n                             lambda :tf.constant(1.0) - tf.train.inverse_time_decay(learning_rate=1.0,\n                                                                                    global_step=global_step,\n                                                                                    decay_steps=1000,\n                                                                                    decay_rate=0.9),\n\n                             #inference\n                             lambda : tf.constant(1.0))\n\n     helper = ScheduledOutputTrainingHelper(decoder_input,\n                                            sequence_length=length,\n                                            sampling_probability=sampling_prob)\n\n     my_decoder = BasicDecoder(cell=output_cell,\n                               helper=helper,\n                               initial_state=output_cell.zero_state(batch_size=tf_batch_size, dtype=tf.float32))\n\n     final_outputs, final_state, final_sequence_length = dynamic_decode(my_decoder, maximum_iterations=24)\n\n     return final_outputs.rnn_output\n ...\n\n In the inference stage, if i feed zero values(or any arbitrary value) to y_target and set sampling_probabilty to 1.0, i think result has to be same as the case when I feed ground truth values to y_target, because sampling_prob=1 means model always sample from the previous outputs, not ground truth value. So what I'm saying is that if the sampling_probability is set to 1.0, is should not matter what value I feed to y_target.\n\n However, result is slightly different like below(but almost same)\n ![image](<a href=\"https://user-images.githubusercontent.com/31504573/29915809-eab1f3ee-8e77-11e7-8a94-006ec10222ae.png\">https://user-images.githubusercontent.com/31504573/29915809-eab1f3ee-8e77-11e7-8a94-006ec10222ae.png</a>)\n\n is this a precision(float32) issue of python? or problem of ScheduledOutputTrainingHelper?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"236800362\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/10815\" href=\"https://github.com/tensorflow/tensorflow/issues/10815#issuecomment-326241575\">#10815 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim9Yc_knnYT_CPG4aWgHY8VfPGgfPks5sdnyggaJpZM4N911G\">https://github.com/notifications/unsubscribe-auth/ABtim9Yc_knnYT_CPG4aWgHY8VfPGgfPks5sdnyggaJpZM4N911G</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "I think it's just setting the seed to get consistent samples.  Your\nrandomness is different between the two runs.\n\nAdam Roberts added two new inference helpers for this exact case, but they\nare only in the nightlies, not in tf 1.3.  look for InferenceHelper, which\nyou can use to implement sample-only decoding.\n\u2026\nOn Aug 31, 2017 2:28 AM, \"chococig\" ***@***.***> wrote:\n @ebrevdo <https://github.com/ebrevdo>\n hello, I also have a question about ScheduledOutputTrainingHelper. I'm\n currently doing regression using ScheduledOutputTrainingHelper. But, in the\n inference stage, is it right to set the sampling probability to 1 and use\n an arbitrary input? For the classification case, GreedyEmbeddingHelper can\n be used, but for regression there is no Greedy'Output'Helper.\n\n    - sampling_probability: the probability of sampling from the outputs\n    instead of reading directly from the inputs.\n\n my decoder_input is like Start_value(zeros) + y_target[:-1]\n '''\n x_1 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_1])\n x_2 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_2])\n y_target = tf.placeholder(dtype=tf.float32, shape=[None, n_step, 1])\n\n phase = tf.placeholder(tf.bool) # if True: training / if False: inference\n length = tf.placeholder(dtype=tf.int32, shape=[None,])\n tf_batch_size = tf.placeholder(dtype=tf.int32, shape = [])\n\n encoder_input = tf.concat([x_1,x_2], axis=2)\n like Start_token + target[:-1]\n\n decoder_input = tf.concat([tf.fill([tf_batch_size,1,1], 0.0), # Start by\n Zeros\n y_target[:,:-1,:]], #targets[:-1]\n axis=1)\n '''\n then my decoder is like this\n\n def decoder(encoder_output, decoder_initial_state, decoder_dimension, phase):\n     cell = LayerNormBasicLSTMCell(decoder_dimension)\n\n     cell = AttentionWrapper(cell,\n                             attention_mechanism=BahdanauAttention(decoder_dimension, encoder_output),\n                             initial_cell_state = (LSTMStateTuple(decoder_initial_state, decoder_initial_state)),\n                             alignment_history = True)\n\n     output_cell = OutputProjectionWrapper(cell, output_size=1)\n\n     sampling_prob = tf.cond(phase,\n\n                             #training\n                             lambda :tf.constant(1.0) - tf.train.inverse_time_decay(learning_rate=1.0,\n                                                                                    global_step=global_step,\n                                                                                    decay_steps=1000,\n                                                                                    decay_rate=0.9),\n\n                             #inference\n                             lambda : tf.constant(1.0))\n\n     helper = ScheduledOutputTrainingHelper(decoder_input,\n                                            sequence_length=length,\n                                            sampling_probability=sampling_prob)\n\n     my_decoder = BasicDecoder(cell=output_cell,\n                               helper=helper,\n                               initial_state=output_cell.zero_state(batch_size=tf_batch_size, dtype=tf.float32))\n\n     final_outputs, final_state, final_sequence_length = dynamic_decode(my_decoder, maximum_iterations=24)\n\n     return final_outputs.rnn_output\n ...\n\n In the inference stage, if i feed zero values(or any arbitrary value) to y_target and set sampling_probabilty to 1.0, i think result has to be same as the case when I feed ground truth values to y_target, because sampling_prob=1 means model always sample from the previous outputs, not ground truth value. So what I'm saying is that if the sampling_probability is set to 1.0, is should not matter what value I feed to y_target.\n\n However, result is slightly different like below(but almost same)\n ![image](https://user-images.githubusercontent.com/31504573/29915809-eab1f3ee-8e77-11e7-8a94-006ec10222ae.png)\n\n is this a precision(float32) issue of python? or problem of ScheduledOutputTrainingHelper?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#10815 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim9Yc_knnYT_CPG4aWgHY8VfPGgfPks5sdnyggaJpZM4N911G>\n .", "body": "I think it's just setting the seed to get consistent samples.  Your\nrandomness is different between the two runs.\n\nAdam Roberts added two new inference helpers for this exact case, but they\nare only in the nightlies, not in tf 1.3.  look for InferenceHelper, which\nyou can use to implement sample-only decoding.\n\nOn Aug 31, 2017 2:28 AM, \"chococig\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo>\n> hello, I also have a question about ScheduledOutputTrainingHelper. I'm\n> currently doing regression using ScheduledOutputTrainingHelper. But, in the\n> inference stage, is it right to set the sampling probability to 1 and use\n> an arbitrary input? For the classification case, GreedyEmbeddingHelper can\n> be used, but for regression there is no Greedy'Output'Helper.\n>\n>    - sampling_probability: the probability of sampling from the outputs\n>    instead of reading directly from the inputs.\n>\n> my decoder_input is like Start_value(zeros) + y_target[:-1]\n> '''\n> x_1 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_1])\n> x_2 = tf.placeholder(dtype=tf.float32, shape=[None, n_step, n_2])\n> y_target = tf.placeholder(dtype=tf.float32, shape=[None, n_step, 1])\n>\n> phase = tf.placeholder(tf.bool) # if True: training / if False: inference\n> length = tf.placeholder(dtype=tf.int32, shape=[None,])\n> tf_batch_size = tf.placeholder(dtype=tf.int32, shape = [])\n>\n> encoder_input = tf.concat([x_1,x_2], axis=2)\n> like Start_token + target[:-1]\n>\n> decoder_input = tf.concat([tf.fill([tf_batch_size,1,1], 0.0), # Start by\n> Zeros\n> y_target[:,:-1,:]], #targets[:-1]\n> axis=1)\n> '''\n> then my decoder is like this\n>\n> def decoder(encoder_output, decoder_initial_state, decoder_dimension, phase):\n>     cell = LayerNormBasicLSTMCell(decoder_dimension)\n>\n>     cell = AttentionWrapper(cell,\n>                             attention_mechanism=BahdanauAttention(decoder_dimension, encoder_output),\n>                             initial_cell_state = (LSTMStateTuple(decoder_initial_state, decoder_initial_state)),\n>                             alignment_history = True)\n>\n>     output_cell = OutputProjectionWrapper(cell, output_size=1)\n>\n>     sampling_prob = tf.cond(phase,\n>\n>                             #training\n>                             lambda :tf.constant(1.0) - tf.train.inverse_time_decay(learning_rate=1.0,\n>                                                                                    global_step=global_step,\n>                                                                                    decay_steps=1000,\n>                                                                                    decay_rate=0.9),\n>\n>                             #inference\n>                             lambda : tf.constant(1.0))\n>\n>     helper = ScheduledOutputTrainingHelper(decoder_input,\n>                                            sequence_length=length,\n>                                            sampling_probability=sampling_prob)\n>\n>     my_decoder = BasicDecoder(cell=output_cell,\n>                               helper=helper,\n>                               initial_state=output_cell.zero_state(batch_size=tf_batch_size, dtype=tf.float32))\n>\n>     final_outputs, final_state, final_sequence_length = dynamic_decode(my_decoder, maximum_iterations=24)\n>\n>     return final_outputs.rnn_output\n> ...\n>\n> In the inference stage, if i feed zero values(or any arbitrary value) to y_target and set sampling_probabilty to 1.0, i think result has to be same as the case when I feed ground truth values to y_target, because sampling_prob=1 means model always sample from the previous outputs, not ground truth value. So what I'm saying is that if the sampling_probability is set to 1.0, is should not matter what value I feed to y_target.\n>\n> However, result is slightly different like below(but almost same)\n> ![image](https://user-images.githubusercontent.com/31504573/29915809-eab1f3ee-8e77-11e7-8a94-006ec10222ae.png)\n>\n> is this a precision(float32) issue of python? or problem of ScheduledOutputTrainingHelper?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10815#issuecomment-326241575>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim9Yc_knnYT_CPG4aWgHY8VfPGgfPks5sdnyggaJpZM4N911G>\n> .\n>\n"}