{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302472456", "html_url": "https://github.com/tensorflow/tensorflow/issues/4907#issuecomment-302472456", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4907", "id": 302472456, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjQ3MjQ1Ng==", "user": {"login": "vilemduha", "id": 6907354, "node_id": "MDQ6VXNlcjY5MDczNTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/6907354?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vilemduha", "html_url": "https://github.com/vilemduha", "followers_url": "https://api.github.com/users/vilemduha/followers", "following_url": "https://api.github.com/users/vilemduha/following{/other_user}", "gists_url": "https://api.github.com/users/vilemduha/gists{/gist_id}", "starred_url": "https://api.github.com/users/vilemduha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vilemduha/subscriptions", "organizations_url": "https://api.github.com/users/vilemduha/orgs", "repos_url": "https://api.github.com/users/vilemduha/repos", "events_url": "https://api.github.com/users/vilemduha/events{/privacy}", "received_events_url": "https://api.github.com/users/vilemduha/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-18T17:02:43Z", "updated_at": "2017-05-18T17:05:31Z", "author_association": "NONE", "body_html": "<p>yaroslavvb -<br>\nExactly...I found that allready by placing a print of the fetches in the session py file.<br>\nbut I don't get why?<br>\nthe code is otherwise actually the same as in tutorial.</p>\n<p>this is start:</p>\n<pre><code>checkpoint_folder = '/media/vilem/RYCHLEJ/nntrain/train/scan3d/all/'\n\n\n    \n# We retrieve our checkpoint fullpath\ncheckpoint = tf.train.get_checkpoint_state(checkpoint_folder)\ninput_checkpoint = checkpoint.model_checkpoint_path\n\n# We clear devices to allow TensorFlow to control on which device it will load operations\nclear_devices = True\n\n# We import the meta graph and retrieve a Saver\nsaver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n\n# We retrieve the protobuf graph definition\n#graph = tf.get_default_graph()\n#graph_def = graph.as_graph_def()\n\n# We start a session and restore the graph weights\nsess = tf.InteractiveSession()\nsaver.restore(sess, input_checkpoint)  \ngraph = sess.graph\ngraph_def = sess.graph_def\n    \nt_input = tf.placeholder(np.float32, name='input') # define the input tensor\nimagenet_mean = 117.0\nt_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\n\n\ntf.import_graph_def(graph_def, {'distort_image/ExpandDims':t_preprocessed})\n</code></pre>\n<p>and this is a function call later:</p>\n<pre><code>\nimg_noise = np.random.uniform(size=(299,299,3)) + 100.0\ndef render_naive(fname, t_obj, img0=img_noise, iter_n=20, step=1.0):\n    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n    \n    \n   \n    \n    img = img0.copy()\n    for i in range(iter_n):\n        g, score = sess.run([t_grad, t_score], {t_input:img0})\n        # normalizing the gradient, so the same step size should work \n        g /= g.std()+1e-8         # for different layers and networks\n        img += g*step\n        print(score, end = ' ')\n    #clear_output()\n    showarray(visstd(img), fname)\n\nrender_naive('outputs/experiments/naive',T(layer)[:,:,:,channel], img_noise, 40)\n</code></pre>", "body_text": "yaroslavvb -\nExactly...I found that allready by placing a print of the fetches in the session py file.\nbut I don't get why?\nthe code is otherwise actually the same as in tutorial.\nthis is start:\ncheckpoint_folder = '/media/vilem/RYCHLEJ/nntrain/train/scan3d/all/'\n\n\n    \n# We retrieve our checkpoint fullpath\ncheckpoint = tf.train.get_checkpoint_state(checkpoint_folder)\ninput_checkpoint = checkpoint.model_checkpoint_path\n\n# We clear devices to allow TensorFlow to control on which device it will load operations\nclear_devices = True\n\n# We import the meta graph and retrieve a Saver\nsaver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n\n# We retrieve the protobuf graph definition\n#graph = tf.get_default_graph()\n#graph_def = graph.as_graph_def()\n\n# We start a session and restore the graph weights\nsess = tf.InteractiveSession()\nsaver.restore(sess, input_checkpoint)  \ngraph = sess.graph\ngraph_def = sess.graph_def\n    \nt_input = tf.placeholder(np.float32, name='input') # define the input tensor\nimagenet_mean = 117.0\nt_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\n\n\ntf.import_graph_def(graph_def, {'distort_image/ExpandDims':t_preprocessed})\n\nand this is a function call later:\n\nimg_noise = np.random.uniform(size=(299,299,3)) + 100.0\ndef render_naive(fname, t_obj, img0=img_noise, iter_n=20, step=1.0):\n    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n    \n    \n   \n    \n    img = img0.copy()\n    for i in range(iter_n):\n        g, score = sess.run([t_grad, t_score], {t_input:img0})\n        # normalizing the gradient, so the same step size should work \n        g /= g.std()+1e-8         # for different layers and networks\n        img += g*step\n        print(score, end = ' ')\n    #clear_output()\n    showarray(visstd(img), fname)\n\nrender_naive('outputs/experiments/naive',T(layer)[:,:,:,channel], img_noise, 40)", "body": "yaroslavvb - \r\nExactly...I found that allready by placing a print of the fetches in the session py file.\r\n but I don't get why?\r\nthe code is otherwise actually the same as in tutorial. \r\n\r\nthis is start:\r\n```\r\ncheckpoint_folder = '/media/vilem/RYCHLEJ/nntrain/train/scan3d/all/'\r\n\r\n\r\n    \r\n# We retrieve our checkpoint fullpath\r\ncheckpoint = tf.train.get_checkpoint_state(checkpoint_folder)\r\ninput_checkpoint = checkpoint.model_checkpoint_path\r\n\r\n# We clear devices to allow TensorFlow to control on which device it will load operations\r\nclear_devices = True\r\n\r\n# We import the meta graph and retrieve a Saver\r\nsaver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\r\n\r\n# We retrieve the protobuf graph definition\r\n#graph = tf.get_default_graph()\r\n#graph_def = graph.as_graph_def()\r\n\r\n# We start a session and restore the graph weights\r\nsess = tf.InteractiveSession()\r\nsaver.restore(sess, input_checkpoint)  \r\ngraph = sess.graph\r\ngraph_def = sess.graph_def\r\n    \r\nt_input = tf.placeholder(np.float32, name='input') # define the input tensor\r\nimagenet_mean = 117.0\r\nt_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\r\n\r\n\r\ntf.import_graph_def(graph_def, {'distort_image/ExpandDims':t_preprocessed})\r\n```\r\n\r\nand this is a function call later:\r\n```\r\n\r\nimg_noise = np.random.uniform(size=(299,299,3)) + 100.0\r\ndef render_naive(fname, t_obj, img0=img_noise, iter_n=20, step=1.0):\r\n    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\r\n    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\r\n    \r\n    \r\n   \r\n    \r\n    img = img0.copy()\r\n    for i in range(iter_n):\r\n        g, score = sess.run([t_grad, t_score], {t_input:img0})\r\n        # normalizing the gradient, so the same step size should work \r\n        g /= g.std()+1e-8         # for different layers and networks\r\n        img += g*step\r\n        print(score, end = ' ')\r\n    #clear_output()\r\n    showarray(visstd(img), fname)\r\n\r\nrender_naive('outputs/experiments/naive',T(layer)[:,:,:,channel], img_noise, 40)\r\n```"}