{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10954", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10954/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10954/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10954/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10954", "id": 237568313, "node_id": "MDU6SXNzdWUyMzc1NjgzMTM=", "number": 10954, "title": "Supervisor: SummaryWriter and Saver stop after some time", "user": {"login": "lhlmgr", "id": 400331, "node_id": "MDQ6VXNlcjQwMDMzMQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/400331?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lhlmgr", "html_url": "https://github.com/lhlmgr", "followers_url": "https://api.github.com/users/lhlmgr/followers", "following_url": "https://api.github.com/users/lhlmgr/following{/other_user}", "gists_url": "https://api.github.com/users/lhlmgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/lhlmgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lhlmgr/subscriptions", "organizations_url": "https://api.github.com/users/lhlmgr/orgs", "repos_url": "https://api.github.com/users/lhlmgr/repos", "events_url": "https://api.github.com/users/lhlmgr/events{/privacy}", "received_events_url": "https://api.github.com/users/lhlmgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-06-21T15:08:47Z", "updated_at": "2017-12-21T15:11:31Z", "closed_at": "2017-12-21T15:11:31Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04 / anaconda3 / python 3.6</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary, (pip install tensorflow-gpu)</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.2.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: -</li>\n<li><strong>CUDA/cuDNN version</strong>: 5.1</li>\n<li><strong>GPU model and memory</strong>: 1080 / Titan X / K80</li>\n<li><strong>Exact command to reproduce</strong>: -</li>\n</ul>\n<p>System information: <a href=\"https://github.com/tensorflow/tensorflow/files/1091842/tf_env.txt\">tf_env.txt</a></p>\n<h3>Describe the problem</h3>\n<p>Hey guys!</p>\n<p>I get the problem on 3 different machines (all on ubuntu 16.04 and the tensorflow 1.2). All experiments were executed on a single machine with a single GPU.<br>\nTo initialize a session I use a <code>tf.Supervisor</code> and <code>supervisor.managed_sessions()</code> with the default<br>\n<code>summary_writer</code> and <code>saver</code>.  It works all well for up to 30mins - 1h30mis. But after that time the<br>\n<code>summary_writer</code> stops to write events, and the <code>saver</code> also stops to save the model parameters. However, the model still runs and produces valid outputs.</p>\n<p>I also checked the python-log for tensorflow with level <code>DEBUG</code>. But all I got was some information logs, until it suddenly stops (see below).</p>\n<p>Is there a way to track the <code>SVSummaryThread</code> / <code>SVTimerCheckpointThread</code>?</p>\n<p>Thanks in advance and keep up the good work!<br>\nCheers</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre>supervisor <span class=\"pl-k\">=</span> tf.train.Supervisor(<span class=\"pl-v\">logdir</span><span class=\"pl-k\">=</span>model_path, <span class=\"pl-v\">save_summaries_secs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">60</span>, <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>model.global_step)\n  sess_config <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">gpu_options</span><span class=\"pl-k\">=</span>tf.GPUOptions(<span class=\"pl-v\">allow_growth</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>), <span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n  <span class=\"pl-k\">with</span> supervisor.managed_session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>sess_config) <span class=\"pl-k\">as</span> sess, sess.as_default():\n    step_time, loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>\n    epoch <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n\n    dataset_size <span class=\"pl-k\">=</span> reader.train_size\n    epoch_time <span class=\"pl-k\">=</span> time.time()\n    avg_lm <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>.\n\n    <span class=\"pl-k\">while</span> epoch <span class=\"pl-k\">&lt;</span> config[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>max_epochs<span class=\"pl-pds\">\"</span></span>]:\n      sess.run(reader.iterator.initializer)\n\n      <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n        <span class=\"pl-k\">try</span>:\n          step_loss, step_lm <span class=\"pl-k\">=</span> model.step(sess)\n          avg_lm <span class=\"pl-k\">+=</span> step_lm <span class=\"pl-k\">/</span> <span class=\"pl-c1\">float</span>(dataset_size) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">float</span>(model.batch_size)\n          loss <span class=\"pl-k\">+=</span> step_loss <span class=\"pl-k\">/</span> <span class=\"pl-c1\">float</span>(dataset_size) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">float</span>(model.batch_size)\n        <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError:\n          <span class=\"pl-k\">break</span>\n</pre></div>\n<p>tensorflow python log:</p>\n<pre><code>017-06-21 15:57:33,386 - tensorflow - INFO - Starting queue runners.\n2017-06-21 15:57:33,393 - tensorflow - INFO - global_step/sec: 0\n2017-06-21 15:57:34,539 - tensorflow - INFO - Recording summary at step 0.\n2017-06-21 15:58:33,385 - tensorflow - INFO - Recording summary at step 15264.\n2017-06-21 15:58:33,391 - tensorflow - INFO - global_step/sec: 254.444\n2017-06-21 15:59:33,384 - tensorflow - INFO - Recording summary at step 31239.\n2017-06-21 15:59:33,391 - tensorflow - INFO - global_step/sec: 266.25\n2017-06-21 16:00:33,385 - tensorflow - INFO - Recording summary at step 47206.\n2017-06-21 16:00:33,391 - tensorflow - INFO - global_step/sec: 266.117\n2017-06-21 16:01:33,385 - tensorflow - INFO - Recording summary at step 62157.\n2017-06-21 16:01:33,391 - tensorflow - INFO - global_step/sec: 249.183\n2017-06-21 16:02:33,384 - tensorflow - INFO - Recording summary at step 77621.\n2017-06-21 16:02:33,391 - tensorflow - INFO - global_step/sec: 257.733\n2017-06-21 16:03:33,383 - tensorflow - INFO - Recording summary at step 93657.\n2017-06-21 16:03:33,391 - tensorflow - INFO - global_step/sec: 267.283\n2017-06-21 16:04:33,391 - tensorflow - INFO - global_step/sec: 263.883\n2017-06-21 16:04:33,545 - tensorflow - INFO - Recording summary at step 109493.\n2017-06-21 16:05:33,391 - tensorflow - INFO - global_step/sec: 262.483\n2017-06-21 16:05:33,558 - tensorflow - INFO - Recording summary at step 125242.\n2017-06-21 16:06:33,383 - tensorflow - INFO - Recording summary at step 141072.\n2017-06-21 16:06:33,391 - tensorflow - INFO - global_step/sec: 263.883\n2017-06-21 16:07:33,384 - tensorflow - INFO - Recording summary at step 157265.\n...\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 / anaconda3 / python 3.6\nTensorFlow installed from (source or binary): binary, (pip install tensorflow-gpu)\nTensorFlow version (use command below): 1.2.0\nBazel version (if compiling from source): -\nCUDA/cuDNN version: 5.1\nGPU model and memory: 1080 / Titan X / K80\nExact command to reproduce: -\n\nSystem information: tf_env.txt\nDescribe the problem\nHey guys!\nI get the problem on 3 different machines (all on ubuntu 16.04 and the tensorflow 1.2). All experiments were executed on a single machine with a single GPU.\nTo initialize a session I use a tf.Supervisor and supervisor.managed_sessions() with the default\nsummary_writer and saver.  It works all well for up to 30mins - 1h30mis. But after that time the\nsummary_writer stops to write events, and the saver also stops to save the model parameters. However, the model still runs and produces valid outputs.\nI also checked the python-log for tensorflow with level DEBUG. But all I got was some information logs, until it suddenly stops (see below).\nIs there a way to track the SVSummaryThread / SVTimerCheckpointThread?\nThanks in advance and keep up the good work!\nCheers\nSource code / logs\nsupervisor = tf.train.Supervisor(logdir=model_path, save_summaries_secs=60, global_step=model.global_step)\n  sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True), allow_soft_placement=True)\n\n  with supervisor.managed_session(config=sess_config) as sess, sess.as_default():\n    step_time, loss = 0.0, 0.0\n    epoch = 0\n\n    dataset_size = reader.train_size\n    epoch_time = time.time()\n    avg_lm = 0.\n\n    while epoch < config[\"max_epochs\"]:\n      sess.run(reader.iterator.initializer)\n\n      while True:\n        try:\n          step_loss, step_lm = model.step(sess)\n          avg_lm += step_lm / float(dataset_size) * float(model.batch_size)\n          loss += step_loss / float(dataset_size) * float(model.batch_size)\n        except tf.errors.OutOfRangeError:\n          break\n\ntensorflow python log:\n017-06-21 15:57:33,386 - tensorflow - INFO - Starting queue runners.\n2017-06-21 15:57:33,393 - tensorflow - INFO - global_step/sec: 0\n2017-06-21 15:57:34,539 - tensorflow - INFO - Recording summary at step 0.\n2017-06-21 15:58:33,385 - tensorflow - INFO - Recording summary at step 15264.\n2017-06-21 15:58:33,391 - tensorflow - INFO - global_step/sec: 254.444\n2017-06-21 15:59:33,384 - tensorflow - INFO - Recording summary at step 31239.\n2017-06-21 15:59:33,391 - tensorflow - INFO - global_step/sec: 266.25\n2017-06-21 16:00:33,385 - tensorflow - INFO - Recording summary at step 47206.\n2017-06-21 16:00:33,391 - tensorflow - INFO - global_step/sec: 266.117\n2017-06-21 16:01:33,385 - tensorflow - INFO - Recording summary at step 62157.\n2017-06-21 16:01:33,391 - tensorflow - INFO - global_step/sec: 249.183\n2017-06-21 16:02:33,384 - tensorflow - INFO - Recording summary at step 77621.\n2017-06-21 16:02:33,391 - tensorflow - INFO - global_step/sec: 257.733\n2017-06-21 16:03:33,383 - tensorflow - INFO - Recording summary at step 93657.\n2017-06-21 16:03:33,391 - tensorflow - INFO - global_step/sec: 267.283\n2017-06-21 16:04:33,391 - tensorflow - INFO - global_step/sec: 263.883\n2017-06-21 16:04:33,545 - tensorflow - INFO - Recording summary at step 109493.\n2017-06-21 16:05:33,391 - tensorflow - INFO - global_step/sec: 262.483\n2017-06-21 16:05:33,558 - tensorflow - INFO - Recording summary at step 125242.\n2017-06-21 16:06:33,383 - tensorflow - INFO - Recording summary at step 141072.\n2017-06-21 16:06:33,391 - tensorflow - INFO - global_step/sec: 263.883\n2017-06-21 16:07:33,384 - tensorflow - INFO - Recording summary at step 157265.\n...", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 / anaconda3 / python 3.6\r\n- **TensorFlow installed from (source or binary)**: binary, (pip install tensorflow-gpu)\r\n- **TensorFlow version (use command below)**: 1.2.0\r\n- **Bazel version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: 5.1\r\n- **GPU model and memory**: 1080 / Titan X / K80\r\n- **Exact command to reproduce**: - \r\n\r\nSystem information: [tf_env.txt](https://github.com/tensorflow/tensorflow/files/1091842/tf_env.txt)\r\n\r\n### Describe the problem\r\nHey guys!\r\n\r\nI get the problem on 3 different machines (all on ubuntu 16.04 and the tensorflow 1.2). All experiments were executed on a single machine with a single GPU.\r\nTo initialize a session I use a `tf.Supervisor` and `supervisor.managed_sessions()` with the default \r\n`summary_writer` and `saver`.  It works all well for up to 30mins - 1h30mis. But after that time the\r\n`summary_writer` stops to write events, and the `saver` also stops to save the model parameters. However, the model still runs and produces valid outputs.\r\n\r\nI also checked the python-log for tensorflow with level `DEBUG`. But all I got was some information logs, until it suddenly stops (see below).\r\n\r\nIs there a way to track the `SVSummaryThread` / `SVTimerCheckpointThread`?\r\n\r\nThanks in advance and keep up the good work!\r\nCheers\r\n\r\n### Source code / logs\r\n\r\n```python\r\nsupervisor = tf.train.Supervisor(logdir=model_path, save_summaries_secs=60, global_step=model.global_step)\r\n  sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True), allow_soft_placement=True)\r\n\r\n  with supervisor.managed_session(config=sess_config) as sess, sess.as_default():\r\n    step_time, loss = 0.0, 0.0\r\n    epoch = 0\r\n\r\n    dataset_size = reader.train_size\r\n    epoch_time = time.time()\r\n    avg_lm = 0.\r\n\r\n    while epoch < config[\"max_epochs\"]:\r\n      sess.run(reader.iterator.initializer)\r\n\r\n      while True:\r\n        try:\r\n          step_loss, step_lm = model.step(sess)\r\n          avg_lm += step_lm / float(dataset_size) * float(model.batch_size)\r\n          loss += step_loss / float(dataset_size) * float(model.batch_size)\r\n        except tf.errors.OutOfRangeError:\r\n          break\r\n\r\n``` \r\n\r\ntensorflow python log:\r\n\r\n```\r\n017-06-21 15:57:33,386 - tensorflow - INFO - Starting queue runners.\r\n2017-06-21 15:57:33,393 - tensorflow - INFO - global_step/sec: 0\r\n2017-06-21 15:57:34,539 - tensorflow - INFO - Recording summary at step 0.\r\n2017-06-21 15:58:33,385 - tensorflow - INFO - Recording summary at step 15264.\r\n2017-06-21 15:58:33,391 - tensorflow - INFO - global_step/sec: 254.444\r\n2017-06-21 15:59:33,384 - tensorflow - INFO - Recording summary at step 31239.\r\n2017-06-21 15:59:33,391 - tensorflow - INFO - global_step/sec: 266.25\r\n2017-06-21 16:00:33,385 - tensorflow - INFO - Recording summary at step 47206.\r\n2017-06-21 16:00:33,391 - tensorflow - INFO - global_step/sec: 266.117\r\n2017-06-21 16:01:33,385 - tensorflow - INFO - Recording summary at step 62157.\r\n2017-06-21 16:01:33,391 - tensorflow - INFO - global_step/sec: 249.183\r\n2017-06-21 16:02:33,384 - tensorflow - INFO - Recording summary at step 77621.\r\n2017-06-21 16:02:33,391 - tensorflow - INFO - global_step/sec: 257.733\r\n2017-06-21 16:03:33,383 - tensorflow - INFO - Recording summary at step 93657.\r\n2017-06-21 16:03:33,391 - tensorflow - INFO - global_step/sec: 267.283\r\n2017-06-21 16:04:33,391 - tensorflow - INFO - global_step/sec: 263.883\r\n2017-06-21 16:04:33,545 - tensorflow - INFO - Recording summary at step 109493.\r\n2017-06-21 16:05:33,391 - tensorflow - INFO - global_step/sec: 262.483\r\n2017-06-21 16:05:33,558 - tensorflow - INFO - Recording summary at step 125242.\r\n2017-06-21 16:06:33,383 - tensorflow - INFO - Recording summary at step 141072.\r\n2017-06-21 16:06:33,391 - tensorflow - INFO - global_step/sec: 263.883\r\n2017-06-21 16:07:33,384 - tensorflow - INFO - Recording summary at step 157265.\r\n...\r\n``` \r\n\r\n\r\n\r\n"}