{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9012", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9012/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9012/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9012/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9012", "id": 219804670, "node_id": "MDU6SXNzdWUyMTk4MDQ2NzA=", "number": 9012, "title": "BiasGradOp mistakenly put on CPU", "user": {"login": "wchen342", "id": 6406743, "node_id": "MDQ6VXNlcjY0MDY3NDM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6406743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wchen342", "html_url": "https://github.com/wchen342", "followers_url": "https://api.github.com/users/wchen342/followers", "following_url": "https://api.github.com/users/wchen342/following{/other_user}", "gists_url": "https://api.github.com/users/wchen342/gists{/gist_id}", "starred_url": "https://api.github.com/users/wchen342/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wchen342/subscriptions", "organizations_url": "https://api.github.com/users/wchen342/orgs", "repos_url": "https://api.github.com/users/wchen342/repos", "events_url": "https://api.github.com/users/wchen342/events{/privacy}", "received_events_url": "https://api.github.com/users/wchen342/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-04-06T07:03:03Z", "updated_at": "2018-01-23T23:50:15Z", "closed_at": "2018-01-23T23:50:15Z", "author_association": "NONE", "body_html": "<p>NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.</p>\n<h3>You must complete this information or else your issue will be closed</h3>\n<ul>\n<li><em>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?</em>:<br>\ncustom code</li>\n<li><em>TensorFlow installed from (source or binary)?</em>: from binary</li>\n<li><em>TensorFlow version</em>: 1.0.1</li>\n<li><em>Bazel version (if compiling from source)</em>: N/A</li>\n<li><em>CUDA/cuDNN version</em>: CUDA 8.0, cuDNN v5.1</li>\n<li><em>GPU Model and Memory</em>: GTX 1080, 8GB</li>\n<li><em>Exact command to reproduce</em>:<br>\nHere is a sample script in Python that can reproduce the problem:</li>\n</ul>\n<pre lang=\"import\" data-meta=\"numpy as np\"><code>import tensorflow as tf\nimport numpy as np\nly = tf.layers\n\n\ndef lrelu(x, leak=0.2, name=\"lrelu\"):\n    with tf.variable_scope(name):\n        f1 = 0.5 * (1 + leak)\n        f2 = 0.5 * (1 - leak)\n        return f1 * x + f2 * tf.abs(x)\n        # return tf.maximum(leak*x, x)\n\nx = np.ones([16, 3, 32, 32], dtype=np.float32)\n\nwith tf.device('/gpu:0'):\n    input = tf.placeholder(tf.float32, shape=[16, 3, 32, 32])\n    output = ly.conv2d(input, 3, kernel_size=1, data_format='channels_first',\n                       strides=1, activation=lrelu)\n    loss = tf.gradients(input - output, input)[0]\n    optimizer = tf.train.AdamOptimizer()\n    gradients = optimizer.compute_gradients(loss)\n    grad_op = optimizer.apply_gradients(gradients)\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    out = sess.run(grad_op, feed_dict={input: x})\n</code></pre>\n<h3>Describe the problem clearly</h3>\n<p>I am on Ubuntu 16.04. While running the above script, despite the device has been specified to be GPU, tensorflow still try to do the <code>BiasGradOp</code> on CPU and will cause an error because of the data format. If I change the implementation of <code>lrelu()</code> to <code>return tf.maximum(leak*x, x)</code> then the problem goes away.</p>\n<h3>Source Code / Logs</h3>\n<p>Here is the output from console:</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.21GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nE tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC.\n\t [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format=\"NCHW\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]\nE tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC.\n\t [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format=\"NCHW\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]\n</code></pre>", "body_text": "NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.\nYou must complete this information or else your issue will be closed\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:\ncustom code\nTensorFlow installed from (source or binary)?: from binary\nTensorFlow version: 1.0.1\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: CUDA 8.0, cuDNN v5.1\nGPU Model and Memory: GTX 1080, 8GB\nExact command to reproduce:\nHere is a sample script in Python that can reproduce the problem:\n\nimport tensorflow as tf\nimport numpy as np\nly = tf.layers\n\n\ndef lrelu(x, leak=0.2, name=\"lrelu\"):\n    with tf.variable_scope(name):\n        f1 = 0.5 * (1 + leak)\n        f2 = 0.5 * (1 - leak)\n        return f1 * x + f2 * tf.abs(x)\n        # return tf.maximum(leak*x, x)\n\nx = np.ones([16, 3, 32, 32], dtype=np.float32)\n\nwith tf.device('/gpu:0'):\n    input = tf.placeholder(tf.float32, shape=[16, 3, 32, 32])\n    output = ly.conv2d(input, 3, kernel_size=1, data_format='channels_first',\n                       strides=1, activation=lrelu)\n    loss = tf.gradients(input - output, input)[0]\n    optimizer = tf.train.AdamOptimizer()\n    gradients = optimizer.compute_gradients(loss)\n    grad_op = optimizer.apply_gradients(gradients)\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    out = sess.run(grad_op, feed_dict={input: x})\n\nDescribe the problem clearly\nI am on Ubuntu 16.04. While running the above script, despite the device has been specified to be GPU, tensorflow still try to do the BiasGradOp on CPU and will cause an error because of the data format. If I change the implementation of lrelu() to return tf.maximum(leak*x, x) then the problem goes away.\nSource Code / Logs\nHere is the output from console:\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.21GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nE tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC.\n\t [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format=\"NCHW\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]\nE tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC.\n\t [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format=\"NCHW\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]", "body": "NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.\r\n\r\n### You must complete this information or else your issue will be closed\r\n- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:\r\ncustom code\r\n- *TensorFlow installed from (source or binary)?*: from binary\r\n- *TensorFlow version*: 1.0.1\r\n- *Bazel version (if compiling from source)*: N/A\r\n- *CUDA/cuDNN version*: CUDA 8.0, cuDNN v5.1\r\n- *GPU Model and Memory*: GTX 1080, 8GB\r\n- *Exact command to reproduce*:\r\nHere is a sample script in Python that can reproduce the problem:\r\n\r\n```import numpy as np\r\nimport tensorflow as tf\r\nimport numpy as np\r\nly = tf.layers\r\n\r\n\r\ndef lrelu(x, leak=0.2, name=\"lrelu\"):\r\n    with tf.variable_scope(name):\r\n        f1 = 0.5 * (1 + leak)\r\n        f2 = 0.5 * (1 - leak)\r\n        return f1 * x + f2 * tf.abs(x)\r\n        # return tf.maximum(leak*x, x)\r\n\r\nx = np.ones([16, 3, 32, 32], dtype=np.float32)\r\n\r\nwith tf.device('/gpu:0'):\r\n    input = tf.placeholder(tf.float32, shape=[16, 3, 32, 32])\r\n    output = ly.conv2d(input, 3, kernel_size=1, data_format='channels_first',\r\n                       strides=1, activation=lrelu)\r\n    loss = tf.gradients(input - output, input)[0]\r\n    optimizer = tf.train.AdamOptimizer()\r\n    gradients = optimizer.compute_gradients(loss)\r\n    grad_op = optimizer.apply_gradients(gradients)\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    out = sess.run(grad_op, feed_dict={input: x})\r\n```\r\n\r\n### Describe the problem clearly\r\nI am on Ubuntu 16.04. While running the above script, despite the device has been specified to be GPU, tensorflow still try to do the `BiasGradOp` on CPU and will cause an error because of the data format. If I change the implementation of `lrelu()` to `return tf.maximum(leak*x, x)` then the problem goes away.\r\n\r\n### Source Code / Logs\r\nHere is the output from console:\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.21GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\r\nE tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC.\r\n\t [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format=\"NCHW\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]\r\nE tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC.\r\n\t [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format=\"NCHW\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]\r\n```\r\n"}