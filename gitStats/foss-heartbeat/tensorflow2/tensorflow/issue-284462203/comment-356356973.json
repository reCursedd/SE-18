{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/356356973", "html_url": "https://github.com/tensorflow/tensorflow/issues/15628#issuecomment-356356973", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15628", "id": 356356973, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjM1Njk3Mw==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-09T17:34:59Z", "updated_at": "2018-01-09T17:34:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The <code>protocol</code> argument that you provide when creating a <code>tf.train.Server</code> and/or in the prefix of the <code>target</code> argument to <code>tf.Session()</code> provides a way to switch to a different transport protocol. As <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15676913\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/poxvoculi\">@poxvoculi</a> notes, we currently support <code>\"grpc\"</code> in the core, but folks have contributed <code>\"grpc+verbs\"</code> and <code>\"grpc+mpi\"</code> implementations of these. It's conceivable that you could use the same extension mechanism for (e.g.) <code>\"http\"</code>. If that's not truly pluggable, please let us know what's missing, and we can then consider the feature request.</p>\n<p>I'm not sure what a \"task encoder\" is in this context. Work items in TensorFlow are typically serialized as <code>GraphDef</code> protocol buffers, which I think should be sufficient, but if you could expand on this point, we might understand better.</p>", "body_text": "The protocol argument that you provide when creating a tf.train.Server and/or in the prefix of the target argument to tf.Session() provides a way to switch to a different transport protocol. As @poxvoculi notes, we currently support \"grpc\" in the core, but folks have contributed \"grpc+verbs\" and \"grpc+mpi\" implementations of these. It's conceivable that you could use the same extension mechanism for (e.g.) \"http\". If that's not truly pluggable, please let us know what's missing, and we can then consider the feature request.\nI'm not sure what a \"task encoder\" is in this context. Work items in TensorFlow are typically serialized as GraphDef protocol buffers, which I think should be sufficient, but if you could expand on this point, we might understand better.", "body": "The `protocol` argument that you provide when creating a `tf.train.Server` and/or in the prefix of the `target` argument to `tf.Session()` provides a way to switch to a different transport protocol. As @poxvoculi notes, we currently support `\"grpc\"` in the core, but folks have contributed `\"grpc+verbs\"` and `\"grpc+mpi\"` implementations of these. It's conceivable that you could use the same extension mechanism for (e.g.) `\"http\"`. If that's not truly pluggable, please let us know what's missing, and we can then consider the feature request.\r\n\r\nI'm not sure what a \"task encoder\" is in this context. Work items in TensorFlow are typically serialized as `GraphDef` protocol buffers, which I think should be sufficient, but if you could expand on this point, we might understand better."}