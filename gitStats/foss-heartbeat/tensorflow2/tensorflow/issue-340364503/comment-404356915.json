{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/404356915", "html_url": "https://github.com/tensorflow/tensorflow/pull/20708#issuecomment-404356915", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20708", "id": 404356915, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDM1NjkxNQ==", "user": {"login": "whchung", "id": 1673574, "node_id": "MDQ6VXNlcjE2NzM1NzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1673574?v=4", "gravatar_id": "", "url": "https://api.github.com/users/whchung", "html_url": "https://github.com/whchung", "followers_url": "https://api.github.com/users/whchung/followers", "following_url": "https://api.github.com/users/whchung/following{/other_user}", "gists_url": "https://api.github.com/users/whchung/gists{/gist_id}", "starred_url": "https://api.github.com/users/whchung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/whchung/subscriptions", "organizations_url": "https://api.github.com/users/whchung/orgs", "repos_url": "https://api.github.com/users/whchung/repos", "events_url": "https://api.github.com/users/whchung/events{/privacy}", "received_events_url": "https://api.github.com/users/whchung/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-12T01:02:59Z", "updated_at": "2018-07-12T01:05:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12801049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/daniellowell\">@daniellowell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8866610\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dagamayank\">@dagamayank</a> for MIOpen algorithm finding strategy. Please help weigh in.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=150663\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jlebar\">@jlebar</a> Auto-tuning logic works a bit different between CuDNN and MIOpen.</p>\n<p>In CuDNN algorithm finding phase, a vector of available algorithms (via <code>GetConvolveXXXAlgorithms</code> in <code>cuda_dnn.cc</code>  in CUDA StreamExecutor) is iterated, and passed into CuDNN to find the best algorithm with scratch memory, and the one without scratch memory.</p>\n<p>In MIOpen algorithm finding phase, MIOpen <code>FindConvolveXXXAlgorithm</code> API is invoked in ROCm StreamExecutor, <em>without</em> the vector of available algorithms. MIOpen would find the best algorithm based on its pre-computed performance database, and return the ID of the algorithm, plus the size of scratch memory needed for the algorithm back to the client application (TensorFlow).</p>\n<p>It's therefore such an member variable is added in this pull request. And this member variable won't be used in CuDNN path.</p>", "body_text": "@daniellowell @dagamayank for MIOpen algorithm finding strategy. Please help weigh in.\n@jlebar Auto-tuning logic works a bit different between CuDNN and MIOpen.\nIn CuDNN algorithm finding phase, a vector of available algorithms (via GetConvolveXXXAlgorithms in cuda_dnn.cc  in CUDA StreamExecutor) is iterated, and passed into CuDNN to find the best algorithm with scratch memory, and the one without scratch memory.\nIn MIOpen algorithm finding phase, MIOpen FindConvolveXXXAlgorithm API is invoked in ROCm StreamExecutor, without the vector of available algorithms. MIOpen would find the best algorithm based on its pre-computed performance database, and return the ID of the algorithm, plus the size of scratch memory needed for the algorithm back to the client application (TensorFlow).\nIt's therefore such an member variable is added in this pull request. And this member variable won't be used in CuDNN path.", "body": "@daniellowell @dagamayank for MIOpen algorithm finding strategy. Please help weigh in.\r\n\r\n@jlebar Auto-tuning logic works a bit different between CuDNN and MIOpen.\r\n\r\nIn CuDNN algorithm finding phase, a vector of available algorithms (via `GetConvolveXXXAlgorithms` in `cuda_dnn.cc`  in CUDA StreamExecutor) is iterated, and passed into CuDNN to find the best algorithm with scratch memory, and the one without scratch memory.\r\n\r\nIn MIOpen algorithm finding phase, MIOpen `FindConvolveXXXAlgorithm` API is invoked in ROCm StreamExecutor, *without* the vector of available algorithms. MIOpen would find the best algorithm based on its pre-computed performance database, and return the ID of the algorithm, plus the size of scratch memory needed for the algorithm back to the client application (TensorFlow).\r\n\r\nIt's therefore such an member variable is added in this pull request. And this member variable won't be used in CuDNN path."}