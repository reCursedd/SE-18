{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/437188181", "html_url": "https://github.com/tensorflow/tensorflow/issues/23272#issuecomment-437188181", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23272", "id": 437188181, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzE4ODE4MQ==", "user": {"login": "sseveran", "id": 449906, "node_id": "MDQ6VXNlcjQ0OTkwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/449906?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sseveran", "html_url": "https://github.com/sseveran", "followers_url": "https://api.github.com/users/sseveran/followers", "following_url": "https://api.github.com/users/sseveran/following{/other_user}", "gists_url": "https://api.github.com/users/sseveran/gists{/gist_id}", "starred_url": "https://api.github.com/users/sseveran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sseveran/subscriptions", "organizations_url": "https://api.github.com/users/sseveran/orgs", "repos_url": "https://api.github.com/users/sseveran/repos", "events_url": "https://api.github.com/users/sseveran/events{/privacy}", "received_events_url": "https://api.github.com/users/sseveran/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-08T23:02:40Z", "updated_at": "2018-11-08T23:22:07Z", "author_association": "NONE", "body_html": "<p>The stack trace is identical:</p>\n<pre lang=\"#0\" data-meta=\" 0x00007fff7f601bf3 in std::_Function_handler&lt;void (long, long), Eigen::internal::TensorExecutor&lt;Eigen::TensorAssignOp&lt;Eigen::TensorChippingOp&lt;0l, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 2, 1, long&gt;, 16, Eigen::MakePointer&gt; &gt;, Eigen::TensorChippingOp&lt;0l, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 2, 1, long&gt;, 16, Eigen::MakePointer&gt; const&gt; const&gt; const, Eigen::ThreadPoolDevice, true&gt;::run(Eigen::TensorAssignOp&lt;Eigen::TensorChippingOp&lt;0l, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 2, 1, long&gt;, 16, Eigen::MakePointer&gt; &gt;, Eigen::TensorChippingOp&lt;0l, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 2, 1, long&gt;, 16, Eigen::MakePointer&gt; const&gt; const&gt; const&amp;, Eigen::ThreadPoolDevice const&amp;)::{lambda(long, long)#1}&gt;::_M_invoke(std::_Any_data const&amp;, long, long) () from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\"><code>#1  0x00007fff7e87f019 in std::_Function_handler&lt;void (long, long), Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&amp;, std::function&lt;long (long)&gt;, std::function&lt;void (long, long)&gt;) const::{lambda(long, long)#1}&gt;::_M_invoke(std::_Any_data const&amp;, long, long) ()\n   from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#2  0x00007fff7c32693a in Eigen::NonBlockingThreadPoolTempl&lt;tensorflow::thread::EigenEnvironment&gt;::WorkerLoop(int) ()\n   from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\n#3  0x00007fff7c325a02 in std::_Function_handler&lt;void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function&lt;void ()&gt;)::{lambda()#1}&gt;::_M_invoke(std::_Any_data const&amp;) () from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\n#4  0x00007fff9c62ec5c in std::execute_native_thread_routine_compat (__p=&lt;optimized out&gt;)\n    at /opt/conda/conda-bld/compilers_linux-64_1520532893746/work/.build/src/gcc-7.2.0/libstdc++-v3/src/c++11/thread.cc:110\n#5  0x00007ffff7bc16ba in start_thread (arg=0x7fff0ffff700) at pthread_create.c:333\n#6  0x00007ffff78f741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\n</code></pre>\n<p>I would not call it deterministic. I have seen it take differing lengths of time to manifest itself. The <code>map().batch()</code> has not crashed yet. The <code>map_and_batch()</code> always seem the crash  but sometimes it can take quite a while.</p>", "body_text": "The stack trace is identical:\n#1  0x00007fff7e87f019 in std::_Function_handler<void (long, long), Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}>::_M_invoke(std::_Any_data const&, long, long) ()\n   from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#2  0x00007fff7c32693a in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()\n   from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\n#3  0x00007fff7c325a02 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\n#4  0x00007fff9c62ec5c in std::execute_native_thread_routine_compat (__p=<optimized out>)\n    at /opt/conda/conda-bld/compilers_linux-64_1520532893746/work/.build/src/gcc-7.2.0/libstdc++-v3/src/c++11/thread.cc:110\n#5  0x00007ffff7bc16ba in start_thread (arg=0x7fff0ffff700) at pthread_create.c:333\n#6  0x00007ffff78f741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\n\nI would not call it deterministic. I have seen it take differing lengths of time to manifest itself. The map().batch() has not crashed yet. The map_and_batch() always seem the crash  but sometimes it can take quite a while.", "body": "The stack trace is identical:\r\n\r\n```#0  0x00007fff7f601bf3 in std::_Function_handler<void (long, long), Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> >, Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice, true>::run(Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> >, Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const&, Eigen::ThreadPoolDevice const&)::{lambda(long, long)#1}>::_M_invoke(std::_Any_data const&, long, long) () from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#1  0x00007fff7e87f019 in std::_Function_handler<void (long, long), Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}>::_M_invoke(std::_Any_data const&, long, long) ()\r\n   from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007fff7c32693a in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()\r\n   from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\r\n#3  0x00007fff7c325a02 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\r\n#4  0x00007fff9c62ec5c in std::execute_native_thread_routine_compat (__p=<optimized out>)\r\n    at /opt/conda/conda-bld/compilers_linux-64_1520532893746/work/.build/src/gcc-7.2.0/libstdc++-v3/src/c++11/thread.cc:110\r\n#5  0x00007ffff7bc16ba in start_thread (arg=0x7fff0ffff700) at pthread_create.c:333\r\n#6  0x00007ffff78f741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n```\r\n\r\nI would not call it deterministic. I have seen it take differing lengths of time to manifest itself. The `map().batch()` has not crashed yet. The `map_and_batch()` always seem the crash  but sometimes it can take quite a while."}