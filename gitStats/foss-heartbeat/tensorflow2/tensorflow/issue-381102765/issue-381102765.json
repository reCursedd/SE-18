{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23767", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23767/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23767/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23767/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23767", "id": 381102765, "node_id": "MDU6SXNzdWUzODExMDI3NjU=", "number": 23767, "title": "Tensorflow calculates incorrect loss for `tf.keras` models when using Weights.", "user": {"login": "skiler07", "id": 6961787, "node_id": "MDQ6VXNlcjY5NjE3ODc=", "avatar_url": "https://avatars1.githubusercontent.com/u/6961787?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skiler07", "html_url": "https://github.com/skiler07", "followers_url": "https://api.github.com/users/skiler07/followers", "following_url": "https://api.github.com/users/skiler07/following{/other_user}", "gists_url": "https://api.github.com/users/skiler07/gists{/gist_id}", "starred_url": "https://api.github.com/users/skiler07/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skiler07/subscriptions", "organizations_url": "https://api.github.com/users/skiler07/orgs", "repos_url": "https://api.github.com/users/skiler07/repos", "events_url": "https://api.github.com/users/skiler07/events{/privacy}", "received_events_url": "https://api.github.com/users/skiler07/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097546578, "node_id": "MDU6TGFiZWwxMDk3NTQ2NTc4", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:keras", "name": "comp:keras", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-11-15T10:45:36Z", "updated_at": "2018-11-15T23:40:59Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (No):</li>\n<li>OS Platform and Distribution (e.g., MacOS + Google Cloud VMs):</li>\n<li>TensorFlow installed from (source):</li>\n<li>TensorFlow version (1.10 and 1.12):</li>\n<li>Python version: 3.5</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nThe loss calculation is not correct when working with <code>tf.keras.</code>. After building the model, <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/models/Model\" rel=\"nofollow\"><code>tf.keras.fit_generator</code></a> should accept <code>(inputs, targets, sample_weights)</code> as inputs. However, if I multiply the <code>sample_weights</code> by 10000,  the loss doesn't change.</p>\n<p>The bug seems to appear from 1.10 version of Tensorflow onwards e.g. (1.11, 1.12)</p>\n<p><strong>Describe the expected behavior</strong><br>\nIf I increase the weighting by a certain factor, the overall loss of the model should increase by the same factor. Given the model is doing random guessing.</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nWEIGHT_VARIABLE = 1\n\nno_of_features = 10\ntimesteps = 3\nbatch_size = 32\n\ndef data_gen():\n\n    while True:\n        numerical = np.random.randint(5, size=(batch_size, timesteps, no_of_features))\n        y = np.random.randint(2, size=batch_size)\n        w = np.ones(batch_size) * WEIGHT_VARIABLE # or np.where() for imbalanced datasets\n\n        yield {'numeric_input': numerical}, y, w\n\n\ndef build_model():\n    numerical_input = tf.keras.layers.Input(shape=(timesteps, no_of_features), name='numeric_input')\n    rnn_out = tf.keras.layers.GRU(32, return_sequences=False)(numerical_input)\n    dense = tf.keras.layers.Dense(1, activation='sigmoid', name='main_output')(rnn_out)\n\n    model = tf.keras.models.Model(numerical_input, dense)\n\n    params = {\n        'loss': 'binary_crossentropy',\n        'optimizer': tf.keras.optimizers.Adam(),\n        'metrics': [tf.keras.metrics.binary_crossentropy, tf.keras.metrics.binary_accuracy]\n    }\n    model.compile(**params)\n\n    return model\n\n\ndef train_model():\n    gen1 = data_gen()\n    model = build_model()\n\n    model.fit_generator(gen1, epochs=30, steps_per_epoch=10)\n\n\nif __name__ == '__main__':\n    train_model()\n</code></pre>\n<p>In the above code, you simply need to change the <code>WEIGHT_VARIABLE = 1</code> From 1 to 100000 and rerun the file.</p>\n<p><strong>Other info / logs</strong></p>\n<h3>v1.10</h3>\n<p><code>WEIGHT_VARIABLE = 1</code><br>\n10/10 [==============================] - 1s 128ms/step - loss: 0.7407 - binary_crossentropy: 0.7407 - binary_accuracy: 0.5031<br>\nEpoch 2/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7043 - binary_crossentropy: 0.7043 - binary_accuracy: 0.5125<br>\nEpoch 3/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7055 - binary_crossentropy: 0.7055 - binary_accuracy: 0.5219<br>\nEpoch 4/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7002 - binary_crossentropy: 0.7002 - binary_accuracy: 0.5250<br>\nEpoch 5/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.6944 - binary_crossentropy: 0.6944 - binary_accuracy: 0.5375</p>\n<p><code>WEIGHT_VARIABLE = 10000</code></p>\n<p>10/10 [==============================] - 1s 131ms/step - loss: 7235.5976 - binary_crossentropy: 0.7236 - binary_accuracy: 0.4562<br>\nEpoch 2/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 7271.9184 - binary_crossentropy: 0.7272 - binary_accuracy: 0.4844<br>\nEpoch 3/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 7276.9147 - binary_crossentropy: 0.7277 - binary_accuracy: 0.4500<br>\nEpoch 4/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 7052.0121 - binary_crossentropy: 0.7052 - binary_accuracy: 0.4625<br>\nEpoch 5/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 7187.0285 - binary_crossentropy: 0.7187 - binary_accuracy: 0.4969</p>\n<h3>v1.12</h3>\n<p><code>WEIGHT_VARIABLE = 1</code><br>\n10/10 [==============================] - 1s 68ms/step - loss: 0.7188 - binary_crossentropy: 0.7188 - binary_accuracy: 0.5312<br>\nEpoch 2/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7044 - binary_crossentropy: 0.7044 - binary_accuracy: 0.4969<br>\nEpoch 3/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7086 - binary_crossentropy: 0.7086 - binary_accuracy: 0.4844<br>\nEpoch 4/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7075 - binary_crossentropy: 0.7075 - binary_accuracy: 0.4500<br>\nEpoch 5/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.6950 - binary_crossentropy: 0.6950 - binary_accuracy: 0.5187</p>\n<p><code>WEIGHT_VARIABLE = 10000</code></p>\n<p>10/10 [==============================] - 1s 74ms/step - loss: 0.9084 - binary_crossentropy: 0.9084 - binary_accuracy: 0.4719<br>\nEpoch 2/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7120 - binary_crossentropy: 0.7120 - binary_accuracy: 0.5062<br>\nEpoch 3/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7024 - binary_crossentropy: 0.7024 - binary_accuracy: 0.5344<br>\nEpoch 4/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7257 - binary_crossentropy: 0.7257 - binary_accuracy: 0.4500<br>\nEpoch 5/5<br>\n10/10 [==============================] - 0s 4ms/step - loss: 0.7013 - binary_crossentropy: 0.7013 - binary_accuracy: 0.4844</p>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (No):\nOS Platform and Distribution (e.g., MacOS + Google Cloud VMs):\nTensorFlow installed from (source):\nTensorFlow version (1.10 and 1.12):\nPython version: 3.5\n\nDescribe the current behavior\nThe loss calculation is not correct when working with tf.keras.. After building the model, tf.keras.fit_generator should accept (inputs, targets, sample_weights) as inputs. However, if I multiply the sample_weights by 10000,  the loss doesn't change.\nThe bug seems to appear from 1.10 version of Tensorflow onwards e.g. (1.11, 1.12)\nDescribe the expected behavior\nIf I increase the weighting by a certain factor, the overall loss of the model should increase by the same factor. Given the model is doing random guessing.\nCode to reproduce the issue\nimport numpy as np\nimport tensorflow as tf\n\nWEIGHT_VARIABLE = 1\n\nno_of_features = 10\ntimesteps = 3\nbatch_size = 32\n\ndef data_gen():\n\n    while True:\n        numerical = np.random.randint(5, size=(batch_size, timesteps, no_of_features))\n        y = np.random.randint(2, size=batch_size)\n        w = np.ones(batch_size) * WEIGHT_VARIABLE # or np.where() for imbalanced datasets\n\n        yield {'numeric_input': numerical}, y, w\n\n\ndef build_model():\n    numerical_input = tf.keras.layers.Input(shape=(timesteps, no_of_features), name='numeric_input')\n    rnn_out = tf.keras.layers.GRU(32, return_sequences=False)(numerical_input)\n    dense = tf.keras.layers.Dense(1, activation='sigmoid', name='main_output')(rnn_out)\n\n    model = tf.keras.models.Model(numerical_input, dense)\n\n    params = {\n        'loss': 'binary_crossentropy',\n        'optimizer': tf.keras.optimizers.Adam(),\n        'metrics': [tf.keras.metrics.binary_crossentropy, tf.keras.metrics.binary_accuracy]\n    }\n    model.compile(**params)\n\n    return model\n\n\ndef train_model():\n    gen1 = data_gen()\n    model = build_model()\n\n    model.fit_generator(gen1, epochs=30, steps_per_epoch=10)\n\n\nif __name__ == '__main__':\n    train_model()\n\nIn the above code, you simply need to change the WEIGHT_VARIABLE = 1 From 1 to 100000 and rerun the file.\nOther info / logs\nv1.10\nWEIGHT_VARIABLE = 1\n10/10 [==============================] - 1s 128ms/step - loss: 0.7407 - binary_crossentropy: 0.7407 - binary_accuracy: 0.5031\nEpoch 2/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7043 - binary_crossentropy: 0.7043 - binary_accuracy: 0.5125\nEpoch 3/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7055 - binary_crossentropy: 0.7055 - binary_accuracy: 0.5219\nEpoch 4/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7002 - binary_crossentropy: 0.7002 - binary_accuracy: 0.5250\nEpoch 5/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.6944 - binary_crossentropy: 0.6944 - binary_accuracy: 0.5375\nWEIGHT_VARIABLE = 10000\n10/10 [==============================] - 1s 131ms/step - loss: 7235.5976 - binary_crossentropy: 0.7236 - binary_accuracy: 0.4562\nEpoch 2/5\n10/10 [==============================] - 0s 4ms/step - loss: 7271.9184 - binary_crossentropy: 0.7272 - binary_accuracy: 0.4844\nEpoch 3/5\n10/10 [==============================] - 0s 4ms/step - loss: 7276.9147 - binary_crossentropy: 0.7277 - binary_accuracy: 0.4500\nEpoch 4/5\n10/10 [==============================] - 0s 4ms/step - loss: 7052.0121 - binary_crossentropy: 0.7052 - binary_accuracy: 0.4625\nEpoch 5/5\n10/10 [==============================] - 0s 4ms/step - loss: 7187.0285 - binary_crossentropy: 0.7187 - binary_accuracy: 0.4969\nv1.12\nWEIGHT_VARIABLE = 1\n10/10 [==============================] - 1s 68ms/step - loss: 0.7188 - binary_crossentropy: 0.7188 - binary_accuracy: 0.5312\nEpoch 2/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7044 - binary_crossentropy: 0.7044 - binary_accuracy: 0.4969\nEpoch 3/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7086 - binary_crossentropy: 0.7086 - binary_accuracy: 0.4844\nEpoch 4/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7075 - binary_crossentropy: 0.7075 - binary_accuracy: 0.4500\nEpoch 5/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.6950 - binary_crossentropy: 0.6950 - binary_accuracy: 0.5187\nWEIGHT_VARIABLE = 10000\n10/10 [==============================] - 1s 74ms/step - loss: 0.9084 - binary_crossentropy: 0.9084 - binary_accuracy: 0.4719\nEpoch 2/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7120 - binary_crossentropy: 0.7120 - binary_accuracy: 0.5062\nEpoch 3/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7024 - binary_crossentropy: 0.7024 - binary_accuracy: 0.5344\nEpoch 4/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7257 - binary_crossentropy: 0.7257 - binary_accuracy: 0.4500\nEpoch 5/5\n10/10 [==============================] - 0s 4ms/step - loss: 0.7013 - binary_crossentropy: 0.7013 - binary_accuracy: 0.4844", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (No):\r\n- OS Platform and Distribution (e.g., MacOS + Google Cloud VMs):\r\n- TensorFlow installed from (source):\r\n- TensorFlow version (1.10 and 1.12):\r\n- Python version: 3.5\r\n\r\n**Describe the current behavior**\r\nThe loss calculation is not correct when working with `tf.keras.`. After building the model, [`tf.keras.fit_generator`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) should accept `(inputs, targets, sample_weights)` as inputs. However, if I multiply the `sample_weights` by 10000,  the loss doesn't change.\r\n\r\nThe bug seems to appear from 1.10 version of Tensorflow onwards e.g. (1.11, 1.12)\r\n\r\n**Describe the expected behavior**\r\nIf I increase the weighting by a certain factor, the overall loss of the model should increase by the same factor. Given the model is doing random guessing. \r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nWEIGHT_VARIABLE = 1\r\n\r\nno_of_features = 10\r\ntimesteps = 3\r\nbatch_size = 32\r\n\r\ndef data_gen():\r\n\r\n    while True:\r\n        numerical = np.random.randint(5, size=(batch_size, timesteps, no_of_features))\r\n        y = np.random.randint(2, size=batch_size)\r\n        w = np.ones(batch_size) * WEIGHT_VARIABLE # or np.where() for imbalanced datasets\r\n\r\n        yield {'numeric_input': numerical}, y, w\r\n\r\n\r\ndef build_model():\r\n    numerical_input = tf.keras.layers.Input(shape=(timesteps, no_of_features), name='numeric_input')\r\n    rnn_out = tf.keras.layers.GRU(32, return_sequences=False)(numerical_input)\r\n    dense = tf.keras.layers.Dense(1, activation='sigmoid', name='main_output')(rnn_out)\r\n\r\n    model = tf.keras.models.Model(numerical_input, dense)\r\n\r\n    params = {\r\n        'loss': 'binary_crossentropy',\r\n        'optimizer': tf.keras.optimizers.Adam(),\r\n        'metrics': [tf.keras.metrics.binary_crossentropy, tf.keras.metrics.binary_accuracy]\r\n    }\r\n    model.compile(**params)\r\n\r\n    return model\r\n\r\n\r\ndef train_model():\r\n    gen1 = data_gen()\r\n    model = build_model()\r\n\r\n    model.fit_generator(gen1, epochs=30, steps_per_epoch=10)\r\n\r\n\r\nif __name__ == '__main__':\r\n    train_model()\r\n```\r\n\r\nIn the above code, you simply need to change the `WEIGHT_VARIABLE = 1` From 1 to 100000 and rerun the file.\r\n\r\n\r\n**Other info / logs**\r\n### v1.10\r\n\r\n`WEIGHT_VARIABLE = 1`\r\n10/10 [==============================] - 1s 128ms/step - loss: 0.7407 - binary_crossentropy: 0.7407 - binary_accuracy: 0.5031\r\nEpoch 2/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7043 - binary_crossentropy: 0.7043 - binary_accuracy: 0.5125\r\nEpoch 3/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7055 - binary_crossentropy: 0.7055 - binary_accuracy: 0.5219\r\nEpoch 4/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7002 - binary_crossentropy: 0.7002 - binary_accuracy: 0.5250\r\nEpoch 5/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.6944 - binary_crossentropy: 0.6944 - binary_accuracy: 0.5375\r\n\r\n`WEIGHT_VARIABLE = 10000`\r\n\r\n10/10 [==============================] - 1s 131ms/step - loss: 7235.5976 - binary_crossentropy: 0.7236 - binary_accuracy: 0.4562\r\nEpoch 2/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 7271.9184 - binary_crossentropy: 0.7272 - binary_accuracy: 0.4844\r\nEpoch 3/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 7276.9147 - binary_crossentropy: 0.7277 - binary_accuracy: 0.4500\r\nEpoch 4/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 7052.0121 - binary_crossentropy: 0.7052 - binary_accuracy: 0.4625\r\nEpoch 5/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 7187.0285 - binary_crossentropy: 0.7187 - binary_accuracy: 0.4969\r\n\r\n\r\n### v1.12\r\n\r\n`WEIGHT_VARIABLE = 1`\r\n10/10 [==============================] - 1s 68ms/step - loss: 0.7188 - binary_crossentropy: 0.7188 - binary_accuracy: 0.5312\r\nEpoch 2/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7044 - binary_crossentropy: 0.7044 - binary_accuracy: 0.4969\r\nEpoch 3/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7086 - binary_crossentropy: 0.7086 - binary_accuracy: 0.4844\r\nEpoch 4/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7075 - binary_crossentropy: 0.7075 - binary_accuracy: 0.4500\r\nEpoch 5/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.6950 - binary_crossentropy: 0.6950 - binary_accuracy: 0.5187\r\n\r\n`WEIGHT_VARIABLE = 10000`\r\n\r\n10/10 [==============================] - 1s 74ms/step - loss: 0.9084 - binary_crossentropy: 0.9084 - binary_accuracy: 0.4719\r\nEpoch 2/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7120 - binary_crossentropy: 0.7120 - binary_accuracy: 0.5062\r\nEpoch 3/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7024 - binary_crossentropy: 0.7024 - binary_accuracy: 0.5344\r\nEpoch 4/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7257 - binary_crossentropy: 0.7257 - binary_accuracy: 0.4500\r\nEpoch 5/5\r\n10/10 [==============================] - 0s 4ms/step - loss: 0.7013 - binary_crossentropy: 0.7013 - binary_accuracy: 0.4844"}