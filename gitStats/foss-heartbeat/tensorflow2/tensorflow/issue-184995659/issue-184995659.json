{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5180", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5180/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5180/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5180/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5180", "id": 184995659, "node_id": "MDU6SXNzdWUxODQ5OTU2NTk=", "number": 5180, "title": "OutOfRangeError ", "user": {"login": "joyjeni", "id": 3896309, "node_id": "MDQ6VXNlcjM4OTYzMDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/3896309?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joyjeni", "html_url": "https://github.com/joyjeni", "followers_url": "https://api.github.com/users/joyjeni/followers", "following_url": "https://api.github.com/users/joyjeni/following{/other_user}", "gists_url": "https://api.github.com/users/joyjeni/gists{/gist_id}", "starred_url": "https://api.github.com/users/joyjeni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joyjeni/subscriptions", "organizations_url": "https://api.github.com/users/joyjeni/orgs", "repos_url": "https://api.github.com/users/joyjeni/repos", "events_url": "https://api.github.com/users/joyjeni/events{/privacy}", "received_events_url": "https://api.github.com/users/joyjeni/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-10-25T01:23:49Z", "updated_at": "2016-10-26T00:01:19Z", "closed_at": "2016-10-26T00:00:58Z", "author_association": "NONE", "body_html": "<hr>\n<p>My input data <a href=\"https://www.kaggle.com/c/titanic/download/train.csv\" rel=\"nofollow\">https://www.kaggle.com/c/titanic/download/train.csv</a></p>\n<p>I get OutOfRangeError while training. Can  someone tell me why out of range  error is thrown for below code.<br>\n`<br>\nimport tensorflow as tf<br>\nimport csv<br>\nimport os</p>\n<h1>initialize variables / model parameters</h1>\n<p>W = tf.Variable(tf.zeros([5,1]),name=\"weights\")<br>\nW=tf.cast(W, tf.float32)<br>\nb=tf.Variable(0.,)</p>\n<h1>Linear Regression inference is now used for combining inputs</h1>\n<p>def combine_inputs(X):<br>\nreturn tf.matmul(X,W)+b</p>\n<h1>New inferred value is the sigmoid applied the output of linear regression</h1>\n<p>def inference(X):<br>\nreturn tf.sigmoid(combine_inputs(X))<br>\ndef loss(X,Y):<br>\nreturn tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(combine_inputs(X), Y))</p>\n<p>def read_csv(batch_size, file_name, record_defaults):<br>\nfilename_queue = tf.train.string_input_producer([os.path.dirname(\"<strong>file</strong>\") + \"/\" + file_name])<br>\nreader = tf.TextLineReader(skip_header_lines=1)<br>\nkey, value = reader.read(filename_queue)<br>\n# decode_csv will convert a Tensor from type string (the text line) in<br>\n# a tuple of tensor columns with the specified defaults, which also<br>\n# sets the data type for each column<br>\ndecoded = tf.decode_csv(value, record_defaults=record_defaults)<br>\n# batch actually reads the file and loads \"batch_size\" rows in a single tensor<br>\nreturn tf.train.shuffle_batch(decoded,<br>\nbatch_size=batch_size,<br>\ncapacity=batch_size * 50,<br>\nmin_after_dequeue=batch_size)<br>\ndef inputs():<br>\npassenger_id,survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = read_csv(100,\"train.csv\", [[0.0], [0.0], [0], [\"\"], [\"\"], [0.0], [0.0], [0.0], [\"\"], [0.0], [\"\"], [\"\"]])<br>\nprint(\"Read Data Success\")<br>\nprint(passenger_id)<br>\n# convert categorical data<br>\nis_first_class = tf.to_float(tf.equal(pclass, [1]))<br>\nis_second_class = tf.to_float(tf.equal(pclass, [2]))<br>\nis_third_class = tf.to_float(tf.equal(pclass, [3]))<br>\ngender = tf.to_float(tf.equal(sex, [\"female\"]))<br>\n# Finally we pack all the features in a single matrix;<br>\n# We then transpose to have a matrix with one example per row and one feature per column.<br>\nfeatures = tf.transpose(tf.pack([is_first_class, is_second_class, is_third_class, gender, age]))<br>\nsurvived = tf.reshape(survived, [100, 1])<br>\nreturn features, survived</p>\n<p>def train(total_loss):<br>\nlearning_rate =0.01<br>\nreturn tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)</p>\n<h1>Calculate Accuracy</h1>\n<p>def evaluate(sess, X, Y):<br>\npredicted = tf.cast(inference(X) &gt; 0.5, tf.float32)<br>\nprint( sess.run(tf.reduce_mean(tf.cast(tf.equal(predicted, Y), tf.float32))))</p>\n<h1>Create saver</h1>\n<p>saver =tf.train.Saver()</p>\n<h1>Launch the graph in a session, setup boilerplate</h1>\n<p>with tf.Session() as sess:<br>\ntf.initialize_all_variables().run()<br>\nX,Y = inputs()<br>\ntotal_loss=loss(X,Y)<br>\ntrain_op=train(total_loss)</p>\n<pre><code>coord=tf.train.Coordinator()\nthreads=tf.train.start_queue_runners(sess=sess,coord=coord)\n\n# Actual Training Loop\ntraining_steps=1000\nfor step in range(training_steps):\n    sess.run([train_op])\n    # for debugging and learning purposes, see how the loss gets decremented through training steps\n    #if step % 10 == 0 :\n    #    print \"loss : \",sess.run([total_loss])\n\nevaluate(sess,X,Y)\n\ncoord.request_stop()\ncoord.join(threads)\n# Store the current values of each variable. By default keep most recent 5 files and delete rest\nsaver.save(sess,'my-model-logistic',global_step=step)\nsess.close()\n</code></pre>\n<p>`</p>\n<hr>\n<p>OutOfRangeError                           Traceback (most recent call last)<br>\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, _args)<br>\n714     try:<br>\n--&gt; 715       return fn(_args)<br>\n716     except errors.OpError as e:</p>\n<p>/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)<br>\n696                                  feed_dict, fetch_list, target_list,<br>\n--&gt; 697                                  status, run_metadata)<br>\n698</p>\n<p>/usr/lib/python3.5/contextlib.py in <strong>exit</strong>(self, type, value, traceback)<br>\n65             try:<br>\n---&gt; 66                 next(self.gen)<br>\n67             except StopIteration:</p>\n<p>/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()<br>\n449           compat.as_text(pywrap_tensorflow.TF_Message(status)),<br>\n--&gt; 450           pywrap_tensorflow.TF_GetCode(status))<br>\n451   finally:</p>\n<p>OutOfRangeError: RandomShuffleQueue '_398_shuffle_batch_16/random_shuffle_queue' is closed and has insufficient elements (requested 100, current size 0)<br>\n[[Node: shuffle_batch_16 = QueueDequeueMany[_class=[\"loc:@shuffle_batch_16/random_shuffle_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT32, DT_STRING, DT_STRING, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_STRING, DT_FLOAT, DT_STRING, DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch_16/random_shuffle_queue, shuffle_batch_16/n)]]</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>OutOfRangeError                           Traceback (most recent call last)<br>\n in ()<br>\n13     training_steps=1000<br>\n14     for step in range(training_steps):<br>\n---&gt; 15         sess.run([train_op])<br>\n16         # for debugging and learning purposes, see how the loss gets decremented through training steps<br>\n17         #if step % 10 == 0 :</p>\n<p>/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)<br>\n370     try:<br>\n371       result = self._run(None, fetches, feed_dict, options_ptr,<br>\n--&gt; 372                          run_metadata_ptr)<br>\n373       if run_metadata:<br>\n374         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)</p>\n<p>/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)<br>\n634     try:<br>\n635       results = self._do_run(handle, target_list, unique_fetches,<br>\n--&gt; 636                              feed_dict_string, options, run_metadata)<br>\n637     finally:<br>\n638       # The movers are no longer used. Delete them.</p>\n<p>/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)<br>\n706     if handle is None:<br>\n707       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,<br>\n--&gt; 708                            target_list, options, run_metadata)<br>\n709     else:<br>\n710       return self._do_call(_prun_fn, self._session, handle, feed_dict,</p>\n<p>/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)<br>\n726         except KeyError:<br>\n727           pass<br>\n--&gt; 728       raise type(e)(node_def, op, message)<br>\n729<br>\n730   def _extend_graph(self):</p>", "body_text": "My input data https://www.kaggle.com/c/titanic/download/train.csv\nI get OutOfRangeError while training. Can  someone tell me why out of range  error is thrown for below code.\n`\nimport tensorflow as tf\nimport csv\nimport os\ninitialize variables / model parameters\nW = tf.Variable(tf.zeros([5,1]),name=\"weights\")\nW=tf.cast(W, tf.float32)\nb=tf.Variable(0.,)\nLinear Regression inference is now used for combining inputs\ndef combine_inputs(X):\nreturn tf.matmul(X,W)+b\nNew inferred value is the sigmoid applied the output of linear regression\ndef inference(X):\nreturn tf.sigmoid(combine_inputs(X))\ndef loss(X,Y):\nreturn tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(combine_inputs(X), Y))\ndef read_csv(batch_size, file_name, record_defaults):\nfilename_queue = tf.train.string_input_producer([os.path.dirname(\"file\") + \"/\" + file_name])\nreader = tf.TextLineReader(skip_header_lines=1)\nkey, value = reader.read(filename_queue)\n# decode_csv will convert a Tensor from type string (the text line) in\n# a tuple of tensor columns with the specified defaults, which also\n# sets the data type for each column\ndecoded = tf.decode_csv(value, record_defaults=record_defaults)\n# batch actually reads the file and loads \"batch_size\" rows in a single tensor\nreturn tf.train.shuffle_batch(decoded,\nbatch_size=batch_size,\ncapacity=batch_size * 50,\nmin_after_dequeue=batch_size)\ndef inputs():\npassenger_id,survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = read_csv(100,\"train.csv\", [[0.0], [0.0], [0], [\"\"], [\"\"], [0.0], [0.0], [0.0], [\"\"], [0.0], [\"\"], [\"\"]])\nprint(\"Read Data Success\")\nprint(passenger_id)\n# convert categorical data\nis_first_class = tf.to_float(tf.equal(pclass, [1]))\nis_second_class = tf.to_float(tf.equal(pclass, [2]))\nis_third_class = tf.to_float(tf.equal(pclass, [3]))\ngender = tf.to_float(tf.equal(sex, [\"female\"]))\n# Finally we pack all the features in a single matrix;\n# We then transpose to have a matrix with one example per row and one feature per column.\nfeatures = tf.transpose(tf.pack([is_first_class, is_second_class, is_third_class, gender, age]))\nsurvived = tf.reshape(survived, [100, 1])\nreturn features, survived\ndef train(total_loss):\nlearning_rate =0.01\nreturn tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\nCalculate Accuracy\ndef evaluate(sess, X, Y):\npredicted = tf.cast(inference(X) > 0.5, tf.float32)\nprint( sess.run(tf.reduce_mean(tf.cast(tf.equal(predicted, Y), tf.float32))))\nCreate saver\nsaver =tf.train.Saver()\nLaunch the graph in a session, setup boilerplate\nwith tf.Session() as sess:\ntf.initialize_all_variables().run()\nX,Y = inputs()\ntotal_loss=loss(X,Y)\ntrain_op=train(total_loss)\ncoord=tf.train.Coordinator()\nthreads=tf.train.start_queue_runners(sess=sess,coord=coord)\n\n# Actual Training Loop\ntraining_steps=1000\nfor step in range(training_steps):\n    sess.run([train_op])\n    # for debugging and learning purposes, see how the loss gets decremented through training steps\n    #if step % 10 == 0 :\n    #    print \"loss : \",sess.run([total_loss])\n\nevaluate(sess,X,Y)\n\ncoord.request_stop()\ncoord.join(threads)\n# Store the current values of each variable. By default keep most recent 5 files and delete rest\nsaver.save(sess,'my-model-logistic',global_step=step)\nsess.close()\n\n`\n\nOutOfRangeError                           Traceback (most recent call last)\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, _args)\n714     try:\n--> 715       return fn(_args)\n716     except errors.OpError as e:\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n696                                  feed_dict, fetch_list, target_list,\n--> 697                                  status, run_metadata)\n698\n/usr/lib/python3.5/contextlib.py in exit(self, type, value, traceback)\n65             try:\n---> 66                 next(self.gen)\n67             except StopIteration:\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()\n449           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 450           pywrap_tensorflow.TF_GetCode(status))\n451   finally:\nOutOfRangeError: RandomShuffleQueue '_398_shuffle_batch_16/random_shuffle_queue' is closed and has insufficient elements (requested 100, current size 0)\n[[Node: shuffle_batch_16 = QueueDequeueMany[_class=[\"loc:@shuffle_batch_16/random_shuffle_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT32, DT_STRING, DT_STRING, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_STRING, DT_FLOAT, DT_STRING, DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch_16/random_shuffle_queue, shuffle_batch_16/n)]]\nDuring handling of the above exception, another exception occurred:\nOutOfRangeError                           Traceback (most recent call last)\n in ()\n13     training_steps=1000\n14     for step in range(training_steps):\n---> 15         sess.run([train_op])\n16         # for debugging and learning purposes, see how the loss gets decremented through training steps\n17         #if step % 10 == 0 :\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n370     try:\n371       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 372                          run_metadata_ptr)\n373       if run_metadata:\n374         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n634     try:\n635       results = self._do_run(handle, target_list, unique_fetches,\n--> 636                              feed_dict_string, options, run_metadata)\n637     finally:\n638       # The movers are no longer used. Delete them.\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n706     if handle is None:\n707       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n--> 708                            target_list, options, run_metadata)\n709     else:\n710       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n726         except KeyError:\n727           pass\n--> 728       raise type(e)(node_def, op, message)\n729\n730   def _extend_graph(self):", "body": "---\n\nMy input data https://www.kaggle.com/c/titanic/download/train.csv\n\nI get OutOfRangeError while training. Can  someone tell me why out of range  error is thrown for below code.\n`\nimport tensorflow as tf\nimport csv\nimport os\n# initialize variables / model parameters\n\nW = tf.Variable(tf.zeros([5,1]),name=\"weights\")\nW=tf.cast(W, tf.float32)\nb=tf.Variable(0.,)\n# Linear Regression inference is now used for combining inputs\n\ndef combine_inputs(X):\n    return tf.matmul(X,W)+b\n# New inferred value is the sigmoid applied the output of linear regression\n\ndef inference(X):\n    return tf.sigmoid(combine_inputs(X))\ndef loss(X,Y):  \n     return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(combine_inputs(X), Y))\n\ndef read_csv(batch_size, file_name, record_defaults):\n    filename_queue = tf.train.string_input_producer([os.path.dirname(\"**file**\") + \"/\" + file_name]) \n    reader = tf.TextLineReader(skip_header_lines=1)  \n    key, value = reader.read(filename_queue) \n    # decode_csv will convert a Tensor from type string (the text line) in  \n    # a tuple of tensor columns with the specified defaults, which also  \n    # sets the data type for each column  \n    decoded = tf.decode_csv(value, record_defaults=record_defaults) \n    # batch actually reads the file and loads \"batch_size\" rows in a single tensor  \n    return tf.train.shuffle_batch(decoded,  \n                                  batch_size=batch_size,\n                                  capacity=batch_size \\* 50,  \n                                  min_after_dequeue=batch_size)\ndef inputs():  \n    passenger_id,survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = read_csv(100,\"train.csv\", [[0.0], [0.0], [0], [\"\"], [\"\"], [0.0], [0.0], [0.0], [\"\"], [0.0], [\"\"], [\"\"]])\n    print(\"Read Data Success\")\n    print(passenger_id)\n    # convert categorical data  \n    is_first_class = tf.to_float(tf.equal(pclass, [1]))  \n    is_second_class = tf.to_float(tf.equal(pclass, [2]))  \n    is_third_class = tf.to_float(tf.equal(pclass, [3]))  \n    gender = tf.to_float(tf.equal(sex, [\"female\"]))  \n    # Finally we pack all the features in a single matrix;  \n    # We then transpose to have a matrix with one example per row and one feature per column.  \n    features = tf.transpose(tf.pack([is_first_class, is_second_class, is_third_class, gender, age]))  \n    survived = tf.reshape(survived, [100, 1]) \n    return features, survived\n\ndef train(total_loss):\n    learning_rate =0.01\n    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n# Calculate Accuracy\n\ndef evaluate(sess, X, Y):  \n    predicted = tf.cast(inference(X) > 0.5, tf.float32)  \n    print( sess.run(tf.reduce_mean(tf.cast(tf.equal(predicted, Y), tf.float32))))\n# Create saver\n\nsaver =tf.train.Saver()\n# Launch the graph in a session, setup boilerplate\n\nwith tf.Session() as sess:\n    tf.initialize_all_variables().run()\n    X,Y = inputs()\n    total_loss=loss(X,Y)\n    train_op=train(total_loss)\n\n```\ncoord=tf.train.Coordinator()\nthreads=tf.train.start_queue_runners(sess=sess,coord=coord)\n\n# Actual Training Loop\ntraining_steps=1000\nfor step in range(training_steps):\n    sess.run([train_op])\n    # for debugging and learning purposes, see how the loss gets decremented through training steps\n    #if step % 10 == 0 :\n    #    print \"loss : \",sess.run([total_loss])\n\nevaluate(sess,X,Y)\n\ncoord.request_stop()\ncoord.join(threads)\n# Store the current values of each variable. By default keep most recent 5 files and delete rest\nsaver.save(sess,'my-model-logistic',global_step=step)\nsess.close()\n```\n\n`\n\n---\n\nOutOfRangeError                           Traceback (most recent call last)\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, _args)\n    714     try:\n--> 715       return fn(_args)\n    716     except errors.OpError as e:\n\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n    696                                  feed_dict, fetch_list, target_list,\n--> 697                                  status, run_metadata)\n    698 \n\n/usr/lib/python3.5/contextlib.py in **exit**(self, type, value, traceback)\n     65             try:\n---> 66                 next(self.gen)\n     67             except StopIteration:\n\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()\n    449           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 450           pywrap_tensorflow.TF_GetCode(status))\n    451   finally:\n\nOutOfRangeError: RandomShuffleQueue '_398_shuffle_batch_16/random_shuffle_queue' is closed and has insufficient elements (requested 100, current size 0)\n     [[Node: shuffle_batch_16 = QueueDequeueMany[_class=[\"loc:@shuffle_batch_16/random_shuffle_queue\"], component_types=[DT_FLOAT, DT_FLOAT, DT_INT32, DT_STRING, DT_STRING, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_STRING, DT_FLOAT, DT_STRING, DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch_16/random_shuffle_queue, shuffle_batch_16/n)]]\n\nDuring handling of the above exception, another exception occurred:\n\nOutOfRangeError                           Traceback (most recent call last)\n<ipython-input-227-58fbb156a050> in <module>()\n     13     training_steps=1000\n     14     for step in range(training_steps):\n---> 15         sess.run([train_op])\n     16         # for debugging and learning purposes, see how the loss gets decremented through training steps\n     17         #if step % 10 == 0 :\n\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    370     try:\n    371       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 372                          run_metadata_ptr)\n    373       if run_metadata:\n    374         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    634     try:\n    635       results = self._do_run(handle, target_list, unique_fetches,\n--> 636                              feed_dict_string, options, run_metadata)\n    637     finally:\n    638       # The movers are no longer used. Delete them.\n\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n    706     if handle is None:\n    707       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n--> 708                            target_list, options, run_metadata)\n    709     else:\n    710       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n    726         except KeyError:\n    727           pass\n--> 728       raise type(e)(node_def, op, message)\n    729 \n    730   def _extend_graph(self):\n"}