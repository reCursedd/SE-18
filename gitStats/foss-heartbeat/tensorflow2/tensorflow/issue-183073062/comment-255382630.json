{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/255382630", "html_url": "https://github.com/tensorflow/tensorflow/issues/4968#issuecomment-255382630", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4968", "id": 255382630, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NTM4MjYzMA==", "user": {"login": "jonasrauber", "id": 5837385, "node_id": "MDQ6VXNlcjU4MzczODU=", "avatar_url": "https://avatars1.githubusercontent.com/u/5837385?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonasrauber", "html_url": "https://github.com/jonasrauber", "followers_url": "https://api.github.com/users/jonasrauber/followers", "following_url": "https://api.github.com/users/jonasrauber/following{/other_user}", "gists_url": "https://api.github.com/users/jonasrauber/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonasrauber/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonasrauber/subscriptions", "organizations_url": "https://api.github.com/users/jonasrauber/orgs", "repos_url": "https://api.github.com/users/jonasrauber/repos", "events_url": "https://api.github.com/users/jonasrauber/events{/privacy}", "received_events_url": "https://api.github.com/users/jonasrauber/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-21T13:52:16Z", "updated_at": "2016-10-21T13:52:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Unfortunately, I see this output:</p>\n<pre><code>root@ce0a1cd826d9:/tmp# python3 memcheck.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: Tesla K40m\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:81:00.0\nTotal memory: 11.25GiB\nFree memory: 11.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K40m, pci bus id: 0000:81:00.0)\n[28218290.0, 28205566.0, 28205566.0, 28218290.0, 28220230.0, 28218290.0, 28205376.0, 28205566.0, 28218290.0, 28207506.0, 28221894.0, 28221212.0, 28219170.0, 28218290.0, 28218290.0, 28220834.0, 28203484.0, 28207506.0, 28207506.0, 28205566.0, 28221212.0, 28217608.0, 28217608.0, 28204444.0, 28204444.0, 28204184.0, 1418863.9, 28204444.0, 28219348.0, 28222026.0, 28221894.0, 2839692.5, 28220834.0, 0.0, 28218290.0, 28220834.0, 28203254.0, 28218290.0, 28220834.0, 28221894.0, 28204444.0, 28205570.0, 28222026.0, 28221894.0, 28220508.0, 28220834.0, 28204444.0, 28220834.0, 28220834.0, 28221894.0, 28204444.0, 28203254.0, 28220834.0, 28221894.0, 28221894.0, 28220834.0, 0.0, 28219480.0, 28220508.0, 28204444.0, 0.0, 28205376.0, 28220834.0, 28205376.0, 28205376.0, 2839692.5, 0.0, 28204444.0, 28221894.0, 28203254.0, 4258556.5, 28205376.0, 28221894.0, 28222026.0, 0.0, 2839692.5, 4258556.5, 2839692.5, 28219480.0, 28204184.0, 28204444.0, 28220834.0, 28219348.0, 28221894.0, 28220834.0, 28220834.0, 28221894.0, 28220834.0, 0.0, 28221894.0, 28204184.0, 28221894.0, 3286809.0, 0.0, 26801648.0, 28220834.0, 2839692.5, 28221894.0, 0.0, 0.0, 28220834.0, 28221894.0, 28221894.0, 28220834.0, 25380614.0, 5679584.0, 0.0, 28221894.0, 4258556.5, 0.0]\n</code></pre>\n<p>At least on one GPU, I get this starting at <strong>5 GB</strong>.</p>\n<p>When I limit the <code>per_process_gpu_memory_fraction</code> to 0.7 (to 8 GB), it works fine until 8 GB (I get zeros!) and for 9 GB and higher, it's out of memory.</p>\n<pre><code>gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\nconfig = tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False)\nwith tf.Session(config=config) as sess:\n</code></pre>\n<p>In principle, I would think it's a hardware or driver issue, but then I should be able to reproduce it with another framework.</p>", "body_text": "Unfortunately, I see this output:\nroot@ce0a1cd826d9:/tmp# python3 memcheck.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: Tesla K40m\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:81:00.0\nTotal memory: 11.25GiB\nFree memory: 11.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:81:00.0)\n[28218290.0, 28205566.0, 28205566.0, 28218290.0, 28220230.0, 28218290.0, 28205376.0, 28205566.0, 28218290.0, 28207506.0, 28221894.0, 28221212.0, 28219170.0, 28218290.0, 28218290.0, 28220834.0, 28203484.0, 28207506.0, 28207506.0, 28205566.0, 28221212.0, 28217608.0, 28217608.0, 28204444.0, 28204444.0, 28204184.0, 1418863.9, 28204444.0, 28219348.0, 28222026.0, 28221894.0, 2839692.5, 28220834.0, 0.0, 28218290.0, 28220834.0, 28203254.0, 28218290.0, 28220834.0, 28221894.0, 28204444.0, 28205570.0, 28222026.0, 28221894.0, 28220508.0, 28220834.0, 28204444.0, 28220834.0, 28220834.0, 28221894.0, 28204444.0, 28203254.0, 28220834.0, 28221894.0, 28221894.0, 28220834.0, 0.0, 28219480.0, 28220508.0, 28204444.0, 0.0, 28205376.0, 28220834.0, 28205376.0, 28205376.0, 2839692.5, 0.0, 28204444.0, 28221894.0, 28203254.0, 4258556.5, 28205376.0, 28221894.0, 28222026.0, 0.0, 2839692.5, 4258556.5, 2839692.5, 28219480.0, 28204184.0, 28204444.0, 28220834.0, 28219348.0, 28221894.0, 28220834.0, 28220834.0, 28221894.0, 28220834.0, 0.0, 28221894.0, 28204184.0, 28221894.0, 3286809.0, 0.0, 26801648.0, 28220834.0, 2839692.5, 28221894.0, 0.0, 0.0, 28220834.0, 28221894.0, 28221894.0, 28220834.0, 25380614.0, 5679584.0, 0.0, 28221894.0, 4258556.5, 0.0]\n\nAt least on one GPU, I get this starting at 5 GB.\nWhen I limit the per_process_gpu_memory_fraction to 0.7 (to 8 GB), it works fine until 8 GB (I get zeros!) and for 9 GB and higher, it's out of memory.\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\nconfig = tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False)\nwith tf.Session(config=config) as sess:\n\nIn principle, I would think it's a hardware or driver issue, but then I should be able to reproduce it with another framework.", "body": "Unfortunately, I see this output:\n\n```\nroot@ce0a1cd826d9:/tmp# python3 memcheck.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: Tesla K40m\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:81:00.0\nTotal memory: 11.25GiB\nFree memory: 11.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:81:00.0)\n[28218290.0, 28205566.0, 28205566.0, 28218290.0, 28220230.0, 28218290.0, 28205376.0, 28205566.0, 28218290.0, 28207506.0, 28221894.0, 28221212.0, 28219170.0, 28218290.0, 28218290.0, 28220834.0, 28203484.0, 28207506.0, 28207506.0, 28205566.0, 28221212.0, 28217608.0, 28217608.0, 28204444.0, 28204444.0, 28204184.0, 1418863.9, 28204444.0, 28219348.0, 28222026.0, 28221894.0, 2839692.5, 28220834.0, 0.0, 28218290.0, 28220834.0, 28203254.0, 28218290.0, 28220834.0, 28221894.0, 28204444.0, 28205570.0, 28222026.0, 28221894.0, 28220508.0, 28220834.0, 28204444.0, 28220834.0, 28220834.0, 28221894.0, 28204444.0, 28203254.0, 28220834.0, 28221894.0, 28221894.0, 28220834.0, 0.0, 28219480.0, 28220508.0, 28204444.0, 0.0, 28205376.0, 28220834.0, 28205376.0, 28205376.0, 2839692.5, 0.0, 28204444.0, 28221894.0, 28203254.0, 4258556.5, 28205376.0, 28221894.0, 28222026.0, 0.0, 2839692.5, 4258556.5, 2839692.5, 28219480.0, 28204184.0, 28204444.0, 28220834.0, 28219348.0, 28221894.0, 28220834.0, 28220834.0, 28221894.0, 28220834.0, 0.0, 28221894.0, 28204184.0, 28221894.0, 3286809.0, 0.0, 26801648.0, 28220834.0, 2839692.5, 28221894.0, 0.0, 0.0, 28220834.0, 28221894.0, 28221894.0, 28220834.0, 25380614.0, 5679584.0, 0.0, 28221894.0, 4258556.5, 0.0]\n```\n\nAt least on one GPU, I get this starting at **5 GB**.\n\nWhen I limit the `per_process_gpu_memory_fraction` to 0.7 (to 8 GB), it works fine until 8 GB (I get zeros!) and for 9 GB and higher, it's out of memory.\n\n```\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\nconfig = tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False)\nwith tf.Session(config=config) as sess:\n```\n\nIn principle, I would think it's a hardware or driver issue, but then I should be able to reproduce it with another framework.\n"}