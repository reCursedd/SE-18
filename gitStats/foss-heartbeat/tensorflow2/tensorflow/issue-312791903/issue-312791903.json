{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18375", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18375/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18375/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18375/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18375", "id": 312791903, "node_id": "MDU6SXNzdWUzMTI3OTE5MDM=", "number": 18375, "title": "Using tensorflow lite invoke inference with multiple input tensors and specifying input node?", "user": {"login": "nickwhsu", "id": 25834973, "node_id": "MDQ6VXNlcjI1ODM0OTcz", "avatar_url": "https://avatars1.githubusercontent.com/u/25834973?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nickwhsu", "html_url": "https://github.com/nickwhsu", "followers_url": "https://api.github.com/users/nickwhsu/followers", "following_url": "https://api.github.com/users/nickwhsu/following{/other_user}", "gists_url": "https://api.github.com/users/nickwhsu/gists{/gist_id}", "starred_url": "https://api.github.com/users/nickwhsu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nickwhsu/subscriptions", "organizations_url": "https://api.github.com/users/nickwhsu/orgs", "repos_url": "https://api.github.com/users/nickwhsu/repos", "events_url": "https://api.github.com/users/nickwhsu/events{/privacy}", "received_events_url": "https://api.github.com/users/nickwhsu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-04-10T06:43:57Z", "updated_at": "2018-04-25T06:48:41Z", "closed_at": "2018-04-25T06:48:40Z", "author_association": "NONE", "body_html": "<p><strong>System information</strong><br>\nHave I written custom code: Yes<br>\nOS Platform and Distribution: Ubuntu  16.04<br>\nTensorFlow installed from: source:Yes<br>\nTensorFlow version: 1.7.0<br>\nPython version: 3.6<br>\nBazel version: 0.11.1<br>\nGCC/Compiler version: N/A<br>\nCUDA/cuDNN version: N/A<br>\nGPU model and memory: N/A</p>\n<p><strong>Describe the problem</strong></p>\n<p>I converted my tflite model foo.tflite with multiple input arrays flag , I got two inputs (decoded_sample_data: FLOAT32[],decoded_sample_data:1 FLOAT32[])</p>\n<p>When invoke inference , I refer to<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md</a><br>\nfloat* input = interpreter-&gt;typed_input_tensor(0)</p>\n<p><strong>My question:</strong><br>\nCan  I assign the data to specific input node  like tensorflow mobile method<br>\nex:</p>\n<p>private static final String INPUT_DATA_NAME = \"decoded_sample_data:0\";<br>\nprivate static final String SAMPLE_RATE_NAME = \"decoded_sample_data:1\"; inferenceInterface.feed(SAMPLE_RATE_NAME, sampleRateList);<br>\ninferenceInterface.feed(INPUT_DATA_NAME, floatInputBuffer, RECORDING_LENGTH, 1)<br>\ninferenceInterface.run(outputScoresNames);</p>\n<p>Thank you!</p>", "body_text": "System information\nHave I written custom code: Yes\nOS Platform and Distribution: Ubuntu  16.04\nTensorFlow installed from: source:Yes\nTensorFlow version: 1.7.0\nPython version: 3.6\nBazel version: 0.11.1\nGCC/Compiler version: N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nDescribe the problem\nI converted my tflite model foo.tflite with multiple input arrays flag , I got two inputs (decoded_sample_data: FLOAT32[],decoded_sample_data:1 FLOAT32[])\nWhen invoke inference , I refer to\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md\nfloat* input = interpreter->typed_input_tensor(0)\nMy question:\nCan  I assign the data to specific input node  like tensorflow mobile method\nex:\nprivate static final String INPUT_DATA_NAME = \"decoded_sample_data:0\";\nprivate static final String SAMPLE_RATE_NAME = \"decoded_sample_data:1\"; inferenceInterface.feed(SAMPLE_RATE_NAME, sampleRateList);\ninferenceInterface.feed(INPUT_DATA_NAME, floatInputBuffer, RECORDING_LENGTH, 1)\ninferenceInterface.run(outputScoresNames);\nThank you!", "body": "**System information**\r\nHave I written custom code: Yes\r\nOS Platform and Distribution: Ubuntu  16.04\r\nTensorFlow installed from: source:Yes\r\nTensorFlow version: 1.7.0\r\nPython version: 3.6\r\nBazel version: 0.11.1\r\nGCC/Compiler version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\n\r\n\r\n**Describe the problem**\r\n\r\nI converted my tflite model foo.tflite with multiple input arrays flag , I got two inputs (decoded_sample_data: FLOAT32[],decoded_sample_data:1 FLOAT32[])\r\n\r\nWhen invoke inference , I refer to \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md\r\nfloat* input = interpreter->typed_input_tensor<float>(0)\r\n\r\n**My question:**\r\nCan  I assign the data to specific input node  like tensorflow mobile method\r\nex: \r\n\r\nprivate static final String INPUT_DATA_NAME = \"decoded_sample_data:0\";\r\nprivate static final String SAMPLE_RATE_NAME = \"decoded_sample_data:1\"; inferenceInterface.feed(SAMPLE_RATE_NAME, sampleRateList);\r\ninferenceInterface.feed(INPUT_DATA_NAME, floatInputBuffer, RECORDING_LENGTH, 1)\r\ninferenceInterface.run(outputScoresNames);\r\n\r\nThank you!\r\n\r\n\r\n \r\n\r\n\r\n"}