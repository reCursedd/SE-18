{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/293631389", "html_url": "https://github.com/tensorflow/tensorflow/issues/2382#issuecomment-293631389", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2382", "id": 293631389, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MzYzMTM4OQ==", "user": {"login": "msampathkumar", "id": 6114993, "node_id": "MDQ6VXNlcjYxMTQ5OTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6114993?v=4", "gravatar_id": "", "url": "https://api.github.com/users/msampathkumar", "html_url": "https://github.com/msampathkumar", "followers_url": "https://api.github.com/users/msampathkumar/followers", "following_url": "https://api.github.com/users/msampathkumar/following{/other_user}", "gists_url": "https://api.github.com/users/msampathkumar/gists{/gist_id}", "starred_url": "https://api.github.com/users/msampathkumar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/msampathkumar/subscriptions", "organizations_url": "https://api.github.com/users/msampathkumar/orgs", "repos_url": "https://api.github.com/users/msampathkumar/repos", "events_url": "https://api.github.com/users/msampathkumar/events{/privacy}", "received_events_url": "https://api.github.com/users/msampathkumar/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-12T16:20:17Z", "updated_at": "2017-04-12T16:20:17Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=18027987\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wangbm\">@wangbm</a>, I was thinking - is there any chance you could reduce your input dimensions it? You may reduce your overall computational cost too.</p>\n<p>Maybe you can split your data into two or more pieces and train models. (I think it was during early periods when researchers doing Image classification &amp; tagging) I heard this method was used when researcher did not sufficient computational memory. Good Luck !</p>", "body_text": "@wangbm, I was thinking - is there any chance you could reduce your input dimensions it? You may reduce your overall computational cost too.\nMaybe you can split your data into two or more pieces and train models. (I think it was during early periods when researchers doing Image classification & tagging) I heard this method was used when researcher did not sufficient computational memory. Good Luck !", "body": "@wangbm, I was thinking - is there any chance you could reduce your input dimensions it? You may reduce your overall computational cost too.\r\n\r\nMaybe you can split your data into two or more pieces and train models. (I think it was during early periods when researchers doing Image classification & tagging) I heard this method was used when researcher did not sufficient computational memory. Good Luck !"}