{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22242", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22242/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22242/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22242/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22242", "id": 359669190, "node_id": "MDU6SXNzdWUzNTk2NjkxOTA=", "number": 22242, "title": "Using TF-TRT doubles the size of frozen protobuf file", "user": {"login": "dhingratul", "id": 4759327, "node_id": "MDQ6VXNlcjQ3NTkzMjc=", "avatar_url": "https://avatars2.githubusercontent.com/u/4759327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhingratul", "html_url": "https://github.com/dhingratul", "followers_url": "https://api.github.com/users/dhingratul/followers", "following_url": "https://api.github.com/users/dhingratul/following{/other_user}", "gists_url": "https://api.github.com/users/dhingratul/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhingratul/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhingratul/subscriptions", "organizations_url": "https://api.github.com/users/dhingratul/orgs", "repos_url": "https://api.github.com/users/dhingratul/repos", "events_url": "https://api.github.com/users/dhingratul/events{/privacy}", "received_events_url": "https://api.github.com/users/dhingratul/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-09-12T22:03:02Z", "updated_at": "2018-11-23T18:39:46Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/a</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: master @ <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/3e137b24b06a81772402b86392dbd158653d487b/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/3e137b24b06a81772402b86392dbd158653d487b\"><tt>3e137b2</tt></a></li>\n<li><strong>Python version</strong>:2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.16.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4.0 20160609</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7.1</li>\n<li><strong>GPU model and memory</strong>: 1080ti/11gb dual</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib import tensorrt as trt\nimport numpy as np\n\nfrom keras import backend as K\ncfg = K.tf.ConfigProto()\ncfg.gpu_options.allow_growth = True\nK.set_session(K.tf.Session(config=cfg))\n\ndef load_graph(frozen_graph_filename):\n    # We load the protobuf file from the disk and parse it to retrieve the\n    # unserialized graph_def\n    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n\n    # Then, we can use again a convenient built-in function to import a graph_def into the\n    # current default Graph\n    with tf.Graph().as_default() as graph:\n        tf.import_graph_def(\n            graph_def,\n            name='', #DEBUG\n        )\n    return graph\n\nfid = \"model.pb\"\noutput_nodenames = 'output1,output2,output3'\noutput_node = list(output_nodenames.split(\",\"))\ng = load_graph(fid)\nwith tf.Session(graph=g) as sess:\n    nodes = [n.name for n in tf.get_default_graph().as_graph_def().node]\n    with open(\"original_graph.txt\", \"w\") as fid:\n        for item in nodes:\n            fid.write(\"%s\\n\" % item)\n    writer = tf.summary.FileWriter(\"logs_viz_orig\", tf.get_default_graph().as_graph_def())\n    trt_graph = trt.create_inference_graph(\n    input_graph_def=tf.get_default_graph().as_graph_def(),\n    outputs=output_node,\n    max_batch_size=1,\n    max_workspace_size_bytes=1 &lt;&lt; 25,\n    precision_mode=\"FP32\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\n    minimum_segment_size=2  # minimum number of nodes in an engine\n    )\n    f = open(\"trt.pb\", 'w')\n    f.write(trt_graph.SerializeToString())\n    f.close()\n</code></pre>\n<p>The original graph as ~1100 ops in total, and trt graph has ~900, even then the original model was ~60mb, whereas the exported trt graph is ~120 mb.</p>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/a\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): master @ 3e137b2\nPython version:2.7\nBazel version (if compiling from source): 0.16.1\nGCC/Compiler version (if compiling from source): 5.4.0 20160609\nCUDA/cuDNN version: 9.0/7.1\nGPU model and memory: 1080ti/11gb dual\nExact command to reproduce:\n\nimport tensorflow as tf\nfrom tensorflow.contrib import tensorrt as trt\nimport numpy as np\n\nfrom keras import backend as K\ncfg = K.tf.ConfigProto()\ncfg.gpu_options.allow_growth = True\nK.set_session(K.tf.Session(config=cfg))\n\ndef load_graph(frozen_graph_filename):\n    # We load the protobuf file from the disk and parse it to retrieve the\n    # unserialized graph_def\n    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n\n    # Then, we can use again a convenient built-in function to import a graph_def into the\n    # current default Graph\n    with tf.Graph().as_default() as graph:\n        tf.import_graph_def(\n            graph_def,\n            name='', #DEBUG\n        )\n    return graph\n\nfid = \"model.pb\"\noutput_nodenames = 'output1,output2,output3'\noutput_node = list(output_nodenames.split(\",\"))\ng = load_graph(fid)\nwith tf.Session(graph=g) as sess:\n    nodes = [n.name for n in tf.get_default_graph().as_graph_def().node]\n    with open(\"original_graph.txt\", \"w\") as fid:\n        for item in nodes:\n            fid.write(\"%s\\n\" % item)\n    writer = tf.summary.FileWriter(\"logs_viz_orig\", tf.get_default_graph().as_graph_def())\n    trt_graph = trt.create_inference_graph(\n    input_graph_def=tf.get_default_graph().as_graph_def(),\n    outputs=output_node,\n    max_batch_size=1,\n    max_workspace_size_bytes=1 << 25,\n    precision_mode=\"FP32\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\n    minimum_segment_size=2  # minimum number of nodes in an engine\n    )\n    f = open(\"trt.pb\", 'w')\n    f.write(trt_graph.SerializeToString())\n    f.close()\n\nThe original graph as ~1100 ops in total, and trt graph has ~900, even then the original model was ~60mb, whereas the exported trt graph is ~120 mb.\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/a\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master @ 3e137b24b06a81772402b86392dbd158653d487b\r\n- **Python version**:2.7\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0 20160609\r\n- **CUDA/cuDNN version**: 9.0/7.1\r\n- **GPU model and memory**: 1080ti/11gb dual\r\n- **Exact command to reproduce**: \r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import tensorrt as trt\r\nimport numpy as np\r\n\r\nfrom keras import backend as K\r\ncfg = K.tf.ConfigProto()\r\ncfg.gpu_options.allow_growth = True\r\nK.set_session(K.tf.Session(config=cfg))\r\n\r\ndef load_graph(frozen_graph_filename):\r\n    # We load the protobuf file from the disk and parse it to retrieve the\r\n    # unserialized graph_def\r\n    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n\r\n    # Then, we can use again a convenient built-in function to import a graph_def into the\r\n    # current default Graph\r\n    with tf.Graph().as_default() as graph:\r\n        tf.import_graph_def(\r\n            graph_def,\r\n            name='', #DEBUG\r\n        )\r\n    return graph\r\n\r\nfid = \"model.pb\"\r\noutput_nodenames = 'output1,output2,output3'\r\noutput_node = list(output_nodenames.split(\",\"))\r\ng = load_graph(fid)\r\nwith tf.Session(graph=g) as sess:\r\n    nodes = [n.name for n in tf.get_default_graph().as_graph_def().node]\r\n    with open(\"original_graph.txt\", \"w\") as fid:\r\n        for item in nodes:\r\n            fid.write(\"%s\\n\" % item)\r\n    writer = tf.summary.FileWriter(\"logs_viz_orig\", tf.get_default_graph().as_graph_def())\r\n    trt_graph = trt.create_inference_graph(\r\n    input_graph_def=tf.get_default_graph().as_graph_def(),\r\n    outputs=output_node,\r\n    max_batch_size=1,\r\n    max_workspace_size_bytes=1 << 25,\r\n    precision_mode=\"FP32\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\r\n    minimum_segment_size=2  # minimum number of nodes in an engine\r\n    )\r\n    f = open(\"trt.pb\", 'w')\r\n    f.write(trt_graph.SerializeToString())\r\n    f.close()\r\n```\r\n  \r\nThe original graph as ~1100 ops in total, and trt graph has ~900, even then the original model was ~60mb, whereas the exported trt graph is ~120 mb. \r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"}