{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19162", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19162/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19162/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19162/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19162", "id": 321373966, "node_id": "MDU6SXNzdWUzMjEzNzM5NjY=", "number": 19162, "title": "Documentation of raw_rnn is wrong", "user": {"login": "Nitinsiwach", "id": 22521841, "node_id": "MDQ6VXNlcjIyNTIxODQx", "avatar_url": "https://avatars3.githubusercontent.com/u/22521841?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nitinsiwach", "html_url": "https://github.com/Nitinsiwach", "followers_url": "https://api.github.com/users/Nitinsiwach/followers", "following_url": "https://api.github.com/users/Nitinsiwach/following{/other_user}", "gists_url": "https://api.github.com/users/Nitinsiwach/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nitinsiwach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nitinsiwach/subscriptions", "organizations_url": "https://api.github.com/users/Nitinsiwach/orgs", "repos_url": "https://api.github.com/users/Nitinsiwach/repos", "events_url": "https://api.github.com/users/Nitinsiwach/events{/privacy}", "received_events_url": "https://api.github.com/users/Nitinsiwach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 284443156, "node_id": "MDU6TGFiZWwyODQ0NDMxNTY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-05-08T22:52:51Z", "updated_at": "2018-07-14T02:59:41Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>In the <a href=\"https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn\" rel=\"nofollow\">official documentation</a> of tf.nn.raw_rnn we have emit structure as the third output of loop_fn when the loop_fn is run for the first time</p>\n<p>later on the emit_structure is used to copy tf.zeros_like(emit_structure) to the minibatch entries that are finished by <code>emit = tf.where(finished, tf.zeros_like(emit_structure), emit)</code></p>\n<p>my lack of understanding is: emit structure is <code>None</code> so <code>tf.where(finished, tf.zeros_like(emit_structure), emit)</code> is going to throw a ValueError as <code>tf.zeros_like(None)</code> does so. Can somebody please fill in what i am missing here?</p>\n<p>basically even the example implementation of dynamic_rnn using raw_rnn is simple wrong<br>\nto quote exact parts:<br>\nin dynamic_rnn implementation shown</p>\n<pre><code>def loop_fn(time, cell_output, cell_state, loop_state):\n  emit_output = cell_output  # == None for time == 0\n</code></pre>\n<p>and in raw_rnn we have:</p>\n<pre><code>time = tf.constant(0, dtype=tf.int32)\n(finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(\n    time=time, cell_output=None, cell_state=None, loop_state=None)\n.\n.\n.\n# Emit zeros and copy forward state for minibatch entries that are finished.\n  state = tf.where(finished, state, next_state)\n  emit = tf.where(finished, tf.zeros_like(emit_structure), emit)\n</code></pre>\n<p>This will fail at the first time step itself. But i have gone through code, this is not how it is implemented. In case of None for emit_structure  cell_output is used.</p>\n<p>raw_rnn is really powerful and once i have understood it there is no going back to dynamic_rnn or any other rnn unfolding mechanism. But the documentation is making is really tough to understand this amazing api. An improvement is in order</p>\n<p>Have I written custom code N/A<br>\nOS Platform and Distribution windows 10<br>\nTensorFlow installed from <a href=\"https://www.tensorflow.org/install/install_windows\" rel=\"nofollow\">https://www.tensorflow.org/install/install_windows</a><br>\nTensorFlow version 1.7<br>\nBazel version NA<br>\nCUDA/cuDNN version NA<br>\nGPU model and memory NA<br>\nExact command to reproduce tf.zeros_like(None)</p>", "body_text": "In the official documentation of tf.nn.raw_rnn we have emit structure as the third output of loop_fn when the loop_fn is run for the first time\nlater on the emit_structure is used to copy tf.zeros_like(emit_structure) to the minibatch entries that are finished by emit = tf.where(finished, tf.zeros_like(emit_structure), emit)\nmy lack of understanding is: emit structure is None so tf.where(finished, tf.zeros_like(emit_structure), emit) is going to throw a ValueError as tf.zeros_like(None) does so. Can somebody please fill in what i am missing here?\nbasically even the example implementation of dynamic_rnn using raw_rnn is simple wrong\nto quote exact parts:\nin dynamic_rnn implementation shown\ndef loop_fn(time, cell_output, cell_state, loop_state):\n  emit_output = cell_output  # == None for time == 0\n\nand in raw_rnn we have:\ntime = tf.constant(0, dtype=tf.int32)\n(finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(\n    time=time, cell_output=None, cell_state=None, loop_state=None)\n.\n.\n.\n# Emit zeros and copy forward state for minibatch entries that are finished.\n  state = tf.where(finished, state, next_state)\n  emit = tf.where(finished, tf.zeros_like(emit_structure), emit)\n\nThis will fail at the first time step itself. But i have gone through code, this is not how it is implemented. In case of None for emit_structure  cell_output is used.\nraw_rnn is really powerful and once i have understood it there is no going back to dynamic_rnn or any other rnn unfolding mechanism. But the documentation is making is really tough to understand this amazing api. An improvement is in order\nHave I written custom code N/A\nOS Platform and Distribution windows 10\nTensorFlow installed from https://www.tensorflow.org/install/install_windows\nTensorFlow version 1.7\nBazel version NA\nCUDA/cuDNN version NA\nGPU model and memory NA\nExact command to reproduce tf.zeros_like(None)", "body": "In the [official documentation][1] of tf.nn.raw_rnn we have emit structure as the third output of loop_fn when the loop_fn is run for the first time\r\n\r\nlater on the emit_structure is used to copy tf.zeros_like(emit_structure) to the minibatch entries that are finished by `emit = tf.where(finished, tf.zeros_like(emit_structure), emit)`\r\n\r\nmy lack of understanding is: emit structure is `None` so `tf.where(finished, tf.zeros_like(emit_structure), emit)` is going to throw a ValueError as `tf.zeros_like(None)` does so. Can somebody please fill in what i am missing here?\r\n\r\nbasically even the example implementation of dynamic_rnn using raw_rnn is simple wrong\r\nto quote exact parts:\r\nin dynamic_rnn implementation shown\r\n```\r\ndef loop_fn(time, cell_output, cell_state, loop_state):\r\n  emit_output = cell_output  # == None for time == 0\r\n```\r\nand in raw_rnn we have:\r\n```\r\ntime = tf.constant(0, dtype=tf.int32)\r\n(finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(\r\n    time=time, cell_output=None, cell_state=None, loop_state=None)\r\n.\r\n.\r\n.\r\n# Emit zeros and copy forward state for minibatch entries that are finished.\r\n  state = tf.where(finished, state, next_state)\r\n  emit = tf.where(finished, tf.zeros_like(emit_structure), emit)\r\n```\r\n\r\nThis will fail at the first time step itself. But i have gone through code, this is not how it is implemented. In case of None for emit_structure  cell_output is used.\r\n\r\nraw_rnn is really powerful and once i have understood it there is no going back to dynamic_rnn or any other rnn unfolding mechanism. But the documentation is making is really tough to understand this amazing api. An improvement is in order\r\n\r\nHave I written custom code N/A\r\nOS Platform and Distribution windows 10\r\nTensorFlow installed from https://www.tensorflow.org/install/install_windows\r\nTensorFlow version 1.7\r\nBazel version NA\r\nCUDA/cuDNN version NA\r\nGPU model and memory NA\r\nExact command to reproduce tf.zeros_like(None)\r\n\r\n\r\n  [1]: https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn"}