{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/417370784", "html_url": "https://github.com/tensorflow/tensorflow/issues/21761#issuecomment-417370784", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21761", "id": 417370784, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNzM3MDc4NA==", "user": {"login": "guillaume-michel", "id": 935309, "node_id": "MDQ6VXNlcjkzNTMwOQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/935309?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guillaume-michel", "html_url": "https://github.com/guillaume-michel", "followers_url": "https://api.github.com/users/guillaume-michel/followers", "following_url": "https://api.github.com/users/guillaume-michel/following{/other_user}", "gists_url": "https://api.github.com/users/guillaume-michel/gists{/gist_id}", "starred_url": "https://api.github.com/users/guillaume-michel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guillaume-michel/subscriptions", "organizations_url": "https://api.github.com/users/guillaume-michel/orgs", "repos_url": "https://api.github.com/users/guillaume-michel/repos", "events_url": "https://api.github.com/users/guillaume-michel/events{/privacy}", "received_events_url": "https://api.github.com/users/guillaume-michel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-30T15:55:55Z", "updated_at": "2018-08-30T15:59:16Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=136291\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/sanjoy\">@sanjoy</a> Thanks for taking some time to investigate. I really appreciate.</p>\n<p>I made the suggested change but XLA is still very slow (same as before).<br>\nDetails:<br>\nI have the same objdump as before:<br>\nobjdump -CT test.so</p>\n<p>test.so: file format elf32-little</p>\n<p>DYNAMIC SYMBOL TABLE:<br>\n00000000 DF UND\t00000000 LIBC __cxa_finalize<br>\n00000000 DF UND\t00000000 LIBC __cxa_atexit<br>\n00000320 g DF .text\t0000cb40 Base run_network<br>\n00674004 g D ABS\t00000000 Base __bss_start<br>\n00674004 g D ABS\t00000000 Base _end<br>\n00674004 g D ABS\t00000000 Base _edata</p>\n<p>For reference I made a test that compare TF, XLA and TFLite on the same network and I have the following results on ARM with tensorflow 1.10:</p>\n<ul>\n<li>TF: 201 ms</li>\n<li>TFLite: 273 ms</li>\n<li>XLA: 4446 ms<br>\nNeural networks outputs for each inference engine are the same so correctness is not an issue and it indicates the same operations are performed for each tests.<br>\nSystem monitoring indicates no other computation are performed in the background.</li>\n</ul>\n<p>I am happy to help if you have other tests I can perform.</p>", "body_text": "@sanjoy Thanks for taking some time to investigate. I really appreciate.\nI made the suggested change but XLA is still very slow (same as before).\nDetails:\nI have the same objdump as before:\nobjdump -CT test.so\ntest.so: file format elf32-little\nDYNAMIC SYMBOL TABLE:\n00000000 DF UND\t00000000 LIBC __cxa_finalize\n00000000 DF UND\t00000000 LIBC __cxa_atexit\n00000320 g DF .text\t0000cb40 Base run_network\n00674004 g D ABS\t00000000 Base __bss_start\n00674004 g D ABS\t00000000 Base _end\n00674004 g D ABS\t00000000 Base _edata\nFor reference I made a test that compare TF, XLA and TFLite on the same network and I have the following results on ARM with tensorflow 1.10:\n\nTF: 201 ms\nTFLite: 273 ms\nXLA: 4446 ms\nNeural networks outputs for each inference engine are the same so correctness is not an issue and it indicates the same operations are performed for each tests.\nSystem monitoring indicates no other computation are performed in the background.\n\nI am happy to help if you have other tests I can perform.", "body": "@sanjoy Thanks for taking some time to investigate. I really appreciate.\r\n\r\nI made the suggested change but XLA is still very slow (same as before).\r\nDetails:\r\nI have the same objdump as before:\r\nobjdump -CT test.so\r\n\r\ntest.so: file format elf32-little\r\n\r\nDYNAMIC SYMBOL TABLE:\r\n00000000 DF UND\t00000000 LIBC __cxa_finalize\r\n00000000 DF UND\t00000000 LIBC __cxa_atexit\r\n00000320 g DF .text\t0000cb40 Base run_network\r\n00674004 g D ABS\t00000000 Base __bss_start\r\n00674004 g D ABS\t00000000 Base _end\r\n00674004 g D ABS\t00000000 Base _edata\r\n\r\nFor reference I made a test that compare TF, XLA and TFLite on the same network and I have the following results on ARM with tensorflow 1.10:\r\n- TF: 201 ms\r\n- TFLite: 273 ms\r\n- XLA: 4446 ms\r\nNeural networks outputs for each inference engine are the same so correctness is not an issue and it indicates the same operations are performed for each tests.\r\nSystem monitoring indicates no other computation are performed in the background.\r\n\r\nI am happy to help if you have other tests I can perform."}