{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17190", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17190/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17190/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17190/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17190", "id": 299263262, "node_id": "MDU6SXNzdWUyOTkyNjMyNjI=", "number": 17190, "title": "tf.contrib.quantize: layer not quantized in absence of activation", "user": {"login": "DominikAuras", "id": 251468, "node_id": "MDQ6VXNlcjI1MTQ2OA==", "avatar_url": "https://avatars0.githubusercontent.com/u/251468?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DominikAuras", "html_url": "https://github.com/DominikAuras", "followers_url": "https://api.github.com/users/DominikAuras/followers", "following_url": "https://api.github.com/users/DominikAuras/following{/other_user}", "gists_url": "https://api.github.com/users/DominikAuras/gists{/gist_id}", "starred_url": "https://api.github.com/users/DominikAuras/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DominikAuras/subscriptions", "organizations_url": "https://api.github.com/users/DominikAuras/orgs", "repos_url": "https://api.github.com/users/DominikAuras/repos", "events_url": "https://api.github.com/users/DominikAuras/events{/privacy}", "received_events_url": "https://api.github.com/users/DominikAuras/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-02-22T08:40:16Z", "updated_at": "2018-10-17T12:44:45Z", "closed_at": "2018-02-22T17:48:37Z", "author_association": "NONE", "body_html": "<p>In absence of an activation function, e.g., <code>tf.layers.Conv2D(...,activation=None,...)</code>, the graph matcher using the <code>activation_pattern</code> at<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/671baf080238025da9698ea980cd9504005f727c/tensorflow/contrib/quantize/python/quantize.py#L185-L192\">tensorflow/tensorflow/contrib/quantize/python/quantize.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 185 to 192\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/671baf080238025da9698ea980cd9504005f727c\">671baf0</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L185\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"185\"></td>\n          <td id=\"LC185\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> activation_pattern <span class=\"pl-k\">=</span> graph_matcher.OpTypePattern( </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L186\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"186\"></td>\n          <td id=\"LC186\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-s\"><span class=\"pl-pds\">'</span>|<span class=\"pl-pds\">'</span></span>.join(<span class=\"pl-c1\">_ACTIVATION_TYPES</span>), </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L187\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"187\"></td>\n          <td id=\"LC187\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>[ </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L188\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"188\"></td>\n          <td id=\"LC188\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         graph_matcher.OneofPattern([ </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L189\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"189\"></td>\n          <td id=\"LC189\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             bias_add_pattern, folded_bias_add_pattern, bypass_pattern_a, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L190\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"190\"></td>\n          <td id=\"LC190\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             bypass_pattern_b </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L191\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"191\"></td>\n          <td id=\"LC191\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         ]) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L192\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"192\"></td>\n          <td id=\"LC192\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     ]) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n<br>\nwon't match the layer that has no activation function, and consequently, that layer won't be quantized.</p>\n<p>Maybe previously, instead of no activation function, <code>tf.identity</code> was used? The package <code>tf.contrib.quantize</code> searches for the identity op.<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/671baf080238025da9698ea980cd9504005f727c/tensorflow/contrib/quantize/python/quantize.py#L35\">tensorflow/tensorflow/contrib/quantize/python/quantize.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 35\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/671baf080238025da9698ea980cd9504005f727c\">671baf0</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L35\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"35\"></td>\n          <td id=\"LC35\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c1\">_ACTIVATION_TYPES</span> <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Relu<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Relu6<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Identity<span class=\"pl-pds\">'</span></span>} </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>Note that if <code>activation = None</code>, then no operation is inserted:<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/671baf080238025da9698ea980cd9504005f727c/tensorflow/python/layers/convolutional.py#L192-L193\">tensorflow/tensorflow/python/layers/convolutional.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 192 to 193\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/671baf080238025da9698ea980cd9504005f727c\">671baf0</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L192\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"192\"></td>\n          <td id=\"LC192\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.activation <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L193\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"193\"></td>\n          <td id=\"LC193\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.activation(outputs) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>Example: Box predictors in SSD from the TF Object Detection API.<br>\n<a href=\"https://github.com/tensorflow/models/blob/be9b80251af1bc798553c9e5135f8b0f19fa0a81/research/object_detection/core/box_predictor.py#L688-L689\">https://github.com/tensorflow/models/blob/be9b80251af1bc798553c9e5135f8b0f19fa0a81/research/object_detection/core/box_predictor.py#L688-L689</a></p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1450614\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/suharshs\">@suharshs</a></p>", "body_text": "In absence of an activation function, e.g., tf.layers.Conv2D(...,activation=None,...), the graph matcher using the activation_pattern at\n\n  \n    \n      tensorflow/tensorflow/contrib/quantize/python/quantize.py\n    \n    \n        Lines 185 to 192\n      in\n      671baf0\n    \n    \n    \n    \n\n        \n          \n           activation_pattern = graph_matcher.OpTypePattern( \n        \n\n        \n          \n               '|'.join(_ACTIVATION_TYPES), \n        \n\n        \n          \n               inputs=[ \n        \n\n        \n          \n                   graph_matcher.OneofPattern([ \n        \n\n        \n          \n                       bias_add_pattern, folded_bias_add_pattern, bypass_pattern_a, \n        \n\n        \n          \n                       bypass_pattern_b \n        \n\n        \n          \n                   ]) \n        \n\n        \n          \n               ]) \n        \n    \n  \n\n\nwon't match the layer that has no activation function, and consequently, that layer won't be quantized.\nMaybe previously, instead of no activation function, tf.identity was used? The package tf.contrib.quantize searches for the identity op.\n\n  \n    \n      tensorflow/tensorflow/contrib/quantize/python/quantize.py\n    \n    \n         Line 35\n      in\n      671baf0\n    \n    \n    \n    \n\n        \n          \n           _ACTIVATION_TYPES = {'Relu', 'Relu6', 'Identity'} \n        \n    \n  \n\n\nNote that if activation = None, then no operation is inserted:\n\n  \n    \n      tensorflow/tensorflow/python/layers/convolutional.py\n    \n    \n        Lines 192 to 193\n      in\n      671baf0\n    \n    \n    \n    \n\n        \n          \n           if self.activation is not None: \n        \n\n        \n          \n             return self.activation(outputs) \n        \n    \n  \n\n\nExample: Box predictors in SSD from the TF Object Detection API.\nhttps://github.com/tensorflow/models/blob/be9b80251af1bc798553c9e5135f8b0f19fa0a81/research/object_detection/core/box_predictor.py#L688-L689\n@suharshs", "body": "In absence of an activation function, e.g., `tf.layers.Conv2D(...,activation=None,...)`, the graph matcher using the `activation_pattern` at\r\nhttps://github.com/tensorflow/tensorflow/blob/671baf080238025da9698ea980cd9504005f727c/tensorflow/contrib/quantize/python/quantize.py#L185-L192\r\nwon't match the layer that has no activation function, and consequently, that layer won't be quantized. \r\n\r\nMaybe previously, instead of no activation function, `tf.identity` was used? The package `tf.contrib.quantize` searches for the identity op.\r\nhttps://github.com/tensorflow/tensorflow/blob/671baf080238025da9698ea980cd9504005f727c/tensorflow/contrib/quantize/python/quantize.py#L35\r\n\r\nNote that if `activation = None`, then no operation is inserted:\r\nhttps://github.com/tensorflow/tensorflow/blob/671baf080238025da9698ea980cd9504005f727c/tensorflow/python/layers/convolutional.py#L192-L193\r\n\r\nExample: Box predictors in SSD from the TF Object Detection API.\r\nhttps://github.com/tensorflow/models/blob/be9b80251af1bc798553c9e5135f8b0f19fa0a81/research/object_detection/core/box_predictor.py#L688-L689\r\n\r\n@suharshs "}