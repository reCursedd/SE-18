{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22975", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22975/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22975/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22975/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22975", "id": 369959912, "node_id": "MDU6SXNzdWUzNjk5NTk5MTI=", "number": 22975, "title": "Intermittent very long latency in XRT operations", "user": {"login": "Keno", "id": 1291671, "node_id": "MDQ6VXNlcjEyOTE2NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1291671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Keno", "html_url": "https://github.com/Keno", "followers_url": "https://api.github.com/users/Keno/followers", "following_url": "https://api.github.com/users/Keno/following{/other_user}", "gists_url": "https://api.github.com/users/Keno/gists{/gist_id}", "starred_url": "https://api.github.com/users/Keno/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Keno/subscriptions", "organizations_url": "https://api.github.com/users/Keno/orgs", "repos_url": "https://api.github.com/users/Keno/repos", "events_url": "https://api.github.com/users/Keno/events{/privacy}", "received_events_url": "https://api.github.com/users/Keno/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097543484, "node_id": "MDU6TGFiZWwxMDk3NTQzNDg0", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:runtime", "name": "comp:runtime", "color": "0052cc", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-10-15T00:19:26Z", "updated_at": "2018-11-09T18:51:41Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 18.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: mater</li>\n<li><strong>Python version</strong>: N/A</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.16.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 7.2.0</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>On occasion, I've seen XRT operations take significantly longer than I'd expect and then they usually do (into the 10s of seconds). Attaching GDB while this is happening reveals that it is spending most of its time in TF Graph level optimization passes, particularly EncapsulateXlaComputations (which don't really make any sense in conjunction with XRT ops). I don't have an exact reproducer for when this happens, but it appears that it's more likely to happen upon the first XRTAllocate after reconnecting after a client crashed. I believe, I managed to capture a log  at VLOG level 2 while this was happening (see gist at <a href=\"https://gist.github.com/Keno/3a5e0dc86d3829f5712c5e1a5f65161b\">https://gist.github.com/Keno/3a5e0dc86d3829f5712c5e1a5f65161b</a>). Hopefully that should aid in figuring out what's going on. At the end of the gist, it tried to dump the serialized representation of the ~500MB sized model into the log, so I interrupted it there. I can try to reproduce it again, letting it finish dumping the serialized model if that would be helpful.</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5376757\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/michaelisard\">@michaelisard</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): mater\nPython version: N/A\nBazel version (if compiling from source): 0.16.1\nGCC/Compiler version (if compiling from source): 7.2.0\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A\n\nDescribe the problem\nOn occasion, I've seen XRT operations take significantly longer than I'd expect and then they usually do (into the 10s of seconds). Attaching GDB while this is happening reveals that it is spending most of its time in TF Graph level optimization passes, particularly EncapsulateXlaComputations (which don't really make any sense in conjunction with XRT ops). I don't have an exact reproducer for when this happens, but it appears that it's more likely to happen upon the first XRTAllocate after reconnecting after a client crashed. I believe, I managed to capture a log  at VLOG level 2 while this was happening (see gist at https://gist.github.com/Keno/3a5e0dc86d3829f5712c5e1a5f65161b). Hopefully that should aid in figuring out what's going on. At the end of the gist, it tried to dump the serialized representation of the ~500MB sized model into the log, so I interrupted it there. I can try to reproduce it again, letting it finish dumping the serialized model if that would be helpful.\ncc @michaelisard", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: mater\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nOn occasion, I've seen XRT operations take significantly longer than I'd expect and then they usually do (into the 10s of seconds). Attaching GDB while this is happening reveals that it is spending most of its time in TF Graph level optimization passes, particularly EncapsulateXlaComputations (which don't really make any sense in conjunction with XRT ops). I don't have an exact reproducer for when this happens, but it appears that it's more likely to happen upon the first XRTAllocate after reconnecting after a client crashed. I believe, I managed to capture a log  at VLOG level 2 while this was happening (see gist at https://gist.github.com/Keno/3a5e0dc86d3829f5712c5e1a5f65161b). Hopefully that should aid in figuring out what's going on. At the end of the gist, it tried to dump the serialized representation of the ~500MB sized model into the log, so I interrupted it there. I can try to reproduce it again, letting it finish dumping the serialized model if that would be helpful.\r\n\r\ncc @michaelisard"}