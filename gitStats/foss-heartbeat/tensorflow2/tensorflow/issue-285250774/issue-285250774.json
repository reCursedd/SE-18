{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15752", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15752/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15752/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15752/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15752", "id": 285250774, "node_id": "MDU6SXNzdWUyODUyNTA3NzQ=", "number": 15752, "title": "Eager: Incompatible rnn model shapes inferred when using more than one CudnnGRU/LSTM", "user": {"login": "traveller59", "id": 28866047, "node_id": "MDQ6VXNlcjI4ODY2MDQ3", "avatar_url": "https://avatars1.githubusercontent.com/u/28866047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/traveller59", "html_url": "https://github.com/traveller59", "followers_url": "https://api.github.com/users/traveller59/followers", "following_url": "https://api.github.com/users/traveller59/following{/other_user}", "gists_url": "https://api.github.com/users/traveller59/gists{/gist_id}", "starred_url": "https://api.github.com/users/traveller59/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/traveller59/subscriptions", "organizations_url": "https://api.github.com/users/traveller59/orgs", "repos_url": "https://api.github.com/users/traveller59/repos", "events_url": "https://api.github.com/users/traveller59/events{/privacy}", "received_events_url": "https://api.github.com/users/traveller59/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 736653459, "node_id": "MDU6TGFiZWw3MzY2NTM0NTk=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:eager", "name": "comp:eager", "color": "0052cc", "default": false}, {"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2017-12-31T10:29:19Z", "updated_at": "2018-02-23T16:53:40Z", "closed_at": "2018-01-09T01:01:22Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Win10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.5.0dev20171230</li>\n<li><strong>Python version</strong>: 3.6</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When I use more than one CudnnGRU in eager, I got an error:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\nInvalidArgumentError                      Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span><span class=\"pl-k\">-</span>f618cd483215<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n     <span class=\"pl-c1\">26</span> <span class=\"pl-k\">with</span> tf.device(device):\n     <span class=\"pl-c1\">27</span>     images <span class=\"pl-k\">=</span> tf.constant(toy_data)\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">28</span>     logits <span class=\"pl-k\">=</span> net(images)\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)</span>\n    <span class=\"pl-c1\">651</span> \n    <span class=\"pl-c1\">652</span>         <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> in_deferred_mode:\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">653</span>           outputs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.call(inputs, <span class=\"pl-k\">*</span>args, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">654</span>           <span class=\"pl-k\">if</span> outputs <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n    <span class=\"pl-c1\">655</span>             <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>A layer<span class=\"pl-cce\">\\'</span>s `call` method should return a Tensor <span class=\"pl-pds\">'</span></span>\n\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span><span class=\"pl-k\">-</span>f618cd483215<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> call(<span class=\"pl-c1\">self</span>, x)\n     <span class=\"pl-c1\">17</span>         <span class=\"pl-v\">x</span> <span class=\"pl-k\">=</span> tf.transpose(x, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n     <span class=\"pl-c1\">18</span>         x, <span class=\"pl-v\">s</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.gru1(x)\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">19</span>         x, <span class=\"pl-v\">s</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.gru2(x)\n     <span class=\"pl-c1\">20</span>         <span class=\"pl-v\">x</span> <span class=\"pl-k\">=</span> tf.transpose(x, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n     <span class=\"pl-c1\">21</span>         <span class=\"pl-v\">x</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.fc(x)\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)</span>\n    <span class=\"pl-c1\">651</span> \n    <span class=\"pl-c1\">652</span>         <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> in_deferred_mode:\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">653</span>           <span class=\"pl-v\">outputs</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.call(inputs, <span class=\"pl-k\">*</span>args, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">654</span>           <span class=\"pl-k\">if</span> outputs <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n    <span class=\"pl-c1\">655</span>             <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>A layer<span class=\"pl-cce\">\\'</span>s `call` method should return a Tensor <span class=\"pl-pds\">'</span></span>\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\layers\\cudnn_rnn.py in call(self, inputs, initial_state, training)</span>\n    <span class=\"pl-c1\">400</span>       <span class=\"pl-v\">c</span> <span class=\"pl-k\">=</span> array_ops.constant([], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype)\n    <span class=\"pl-c1\">401</span>     outputs, (output_h, output_c) <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._forward(inputs, h, c, <span class=\"pl-c1\">self</span>.kernel,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">402</span>                                                   training)\n    <span class=\"pl-c1\">403</span>     <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>._rnn_mode <span class=\"pl-k\">==</span> <span class=\"pl-c1\">CUDNN_LSTM</span>:\n    <span class=\"pl-c1\">404</span>       <span class=\"pl-k\">return</span> outputs, (output_h, output_c)\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\layers\\cudnn_rnn.py in _forward(self, inputs, h, c, opaque_params, training)</span>\n    <span class=\"pl-c1\">475</span>         <span class=\"pl-v\">direction</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._direction,\n    <span class=\"pl-c1\">476</span>         <span class=\"pl-v\">dropout</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._dropout,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">477</span>         <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._seed)\n    <span class=\"pl-c1\">478</span>     <span class=\"pl-k\">return</span> output, (output_h, output_c)\n    <span class=\"pl-c1\">479</span> \n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py in _cudnn_rnn(inputs, input_h, input_c, params, is_training, rnn_mode, input_mode, direction, dropout, seed, name)</span>\n    <span class=\"pl-c1\">858</span>       <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span>seed,\n    <span class=\"pl-c1\">859</span>       <span class=\"pl-v\">seed2</span><span class=\"pl-k\">=</span>seed2,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">860</span>       <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name)\n    <span class=\"pl-c1\">861</span>   <span class=\"pl-k\">return</span> (outputs, output_h, output_c)\n    <span class=\"pl-c1\">862</span> \n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\ops\\gen_cudnn_rnn_ops.py in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)</span>\n    <span class=\"pl-c1\">120</span>               <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>seed2<span class=\"pl-pds\">\"</span></span>, seed2, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>is_training<span class=\"pl-pds\">\"</span></span>, is_training)\n    <span class=\"pl-c1\">121</span>     _result <span class=\"pl-k\">=</span> _execute.execute(<span class=\"pl-s\"><span class=\"pl-k\">b</span><span class=\"pl-pds\">\"</span>CudnnRNN<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>_inputs_flat,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">122</span>                                <span class=\"pl-v\">attrs</span><span class=\"pl-k\">=</span>_attrs, <span class=\"pl-v\">ctx</span><span class=\"pl-k\">=</span>_ctx, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name)\n    <span class=\"pl-c1\">123</span>   _execute.record_gradient(\n    <span class=\"pl-c1\">124</span>       <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CudnnRNN<span class=\"pl-pds\">\"</span></span>, _inputs_flat, _attrs, _result, name)\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)</span>\n     <span class=\"pl-c1\">64</span>     <span class=\"pl-k\">else</span>:\n     <span class=\"pl-c1\">65</span>       message <span class=\"pl-k\">=</span> e.message\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">66</span>     six.raise_from(core._status_to_exception(e.code, message), <span class=\"pl-c1\">None</span>)\n     <span class=\"pl-c1\">67</span>   <span class=\"pl-c\"><span class=\"pl-c\">#</span> pylint: enable=protected-access</span>\n     <span class=\"pl-c1\">68</span>   <span class=\"pl-k\">return</span> tensors\n\n<span class=\"pl-k\">~</span>\\<span class=\"pl-ii\">Anaconda3\\lib\\site-packages\\six.py in raise_from(value, from_value)</span>\n\nInvalidArgumentError: Incompatible rnn model shapes inferred: expecting [num_layers, input_size, num_units, dir_count]: [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">1</span>], getting [num_layers, input_size, num_units, dir_count]: [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">1</span>]. [Op:CudnnRNN]</pre></div>\n<p>If I use same network in graph mode, there is no problem.<br>\nreproduce error code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.eager <span class=\"pl-k\">as</span> tfe\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto()\nconfig.gpu_options.allow_growth<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\ntfe.enable_eager_execution(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config)\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">CudnnCrashNet</span>(<span class=\"pl-e\">tfe</span>.<span class=\"pl-e\">Network</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">name</span>):\n        <span class=\"pl-c1\">super</span>(CudnnCrashNet, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>(name)\n        <span class=\"pl-c1\">self</span>.gru1 <span class=\"pl-k\">=</span> tf.contrib.cudnn_rnn.CudnnGRU(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">100</span>)\n        <span class=\"pl-c1\">self</span>.track_layer(<span class=\"pl-c1\">self</span>.gru1)\n        <span class=\"pl-c1\">self</span>.gru2 <span class=\"pl-k\">=</span> tf.contrib.cudnn_rnn.CudnnGRU(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">100</span>)\n        <span class=\"pl-c1\">self</span>.track_layer(<span class=\"pl-c1\">self</span>.gru2)\n        <span class=\"pl-c1\">self</span>.fc <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.track_layer(tf.layers.Dense(<span class=\"pl-c1\">10</span>))\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">call</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        x <span class=\"pl-k\">=</span> tf.reshape(x, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>])\n        x <span class=\"pl-k\">=</span> tf.transpose(x, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n        x, s <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.gru1(x)\n        x, s <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.gru2(x)\n        x <span class=\"pl-k\">=</span> tf.transpose(x, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.fc(x)\n        <span class=\"pl-k\">return</span> x\ntoy_data <span class=\"pl-k\">=</span> np.ones((<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">784</span>)).astype(np.float32)\ndevice <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu:0<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">if</span> tfe.num_gpus() <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu:0<span class=\"pl-pds\">\"</span></span>\nnet <span class=\"pl-k\">=</span> CudnnCrashNet(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>net<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">with</span> tf.device(device):\n    images <span class=\"pl-k\">=</span> tf.constant(toy_data)\n    logits <span class=\"pl-k\">=</span> net(images)</pre></div>\n<p>normal graph-mode code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">CudnnNormalNet</span>(<span class=\"pl-e\">tf</span>.<span class=\"pl-e\">layers</span>.<span class=\"pl-e\">Layer</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">name</span>):\n        <span class=\"pl-c1\">super</span>(CudnnNormalNet, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>(name)\n        <span class=\"pl-c1\">self</span>.gru1 <span class=\"pl-k\">=</span> tf.contrib.cudnn_rnn.CudnnGRU(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">100</span>)\n        <span class=\"pl-c1\">self</span>.gru2 <span class=\"pl-k\">=</span> tf.contrib.cudnn_rnn.CudnnGRU(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">100</span>)\n        <span class=\"pl-c1\">self</span>.fc <span class=\"pl-k\">=</span> tf.layers.Dense(<span class=\"pl-c1\">10</span>)\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">call</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        x <span class=\"pl-k\">=</span> tf.reshape(x, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>])\n        x <span class=\"pl-k\">=</span> tf.transpose(x, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n        x, s <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.gru1(x)\n        x, s <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.gru2(x)\n        x <span class=\"pl-k\">=</span> tf.transpose(x, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.fc(x)\n        <span class=\"pl-k\">return</span> x\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto()\nconfig.gpu_options.allow_growth<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\ntoy_data <span class=\"pl-k\">=</span> np.ones((<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">784</span>)).astype(np.float32)\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n    net <span class=\"pl-k\">=</span> CudnnNormalNet(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>net<span class=\"pl-pds\">'</span></span>)\n    x_p <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">784</span>])\n    logits <span class=\"pl-k\">=</span> net(x_p)\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(logits, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x_p: toy_data})</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Win10\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.5.0dev20171230\nPython version: 3.6\n\nDescribe the problem\nWhen I use more than one CudnnGRU in eager, I got an error:\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-1-f618cd483215> in <module>()\n     26 with tf.device(device):\n     27     images = tf.constant(toy_data)\n---> 28     logits = net(images)\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)\n    651 \n    652         if not in_deferred_mode:\n--> 653           outputs = self.call(inputs, *args, **kwargs)\n    654           if outputs is None:\n    655             raise ValueError('A layer\\'s `call` method should return a Tensor '\n\n<ipython-input-1-f618cd483215> in call(self, x)\n     17         x = tf.transpose(x, [1, 0, 2])\n     18         x, s = self.gru1(x)\n---> 19         x, s = self.gru2(x)\n     20         x = tf.transpose(x, [1, 0, 2])\n     21         x = self.fc(x)\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)\n    651 \n    652         if not in_deferred_mode:\n--> 653           outputs = self.call(inputs, *args, **kwargs)\n    654           if outputs is None:\n    655             raise ValueError('A layer\\'s `call` method should return a Tensor '\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\layers\\cudnn_rnn.py in call(self, inputs, initial_state, training)\n    400       c = array_ops.constant([], dtype=dtype)\n    401     outputs, (output_h, output_c) = self._forward(inputs, h, c, self.kernel,\n--> 402                                                   training)\n    403     if self._rnn_mode == CUDNN_LSTM:\n    404       return outputs, (output_h, output_c)\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\layers\\cudnn_rnn.py in _forward(self, inputs, h, c, opaque_params, training)\n    475         direction=self._direction,\n    476         dropout=self._dropout,\n--> 477         seed=self._seed)\n    478     return output, (output_h, output_c)\n    479 \n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py in _cudnn_rnn(inputs, input_h, input_c, params, is_training, rnn_mode, input_mode, direction, dropout, seed, name)\n    858       seed=seed,\n    859       seed2=seed2,\n--> 860       name=name)\n    861   return (outputs, output_h, output_c)\n    862 \n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\ops\\gen_cudnn_rnn_ops.py in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\n    120               \"seed2\", seed2, \"is_training\", is_training)\n    121     _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\n--> 122                                attrs=_attrs, ctx=_ctx, name=name)\n    123   _execute.record_gradient(\n    124       \"CudnnRNN\", _inputs_flat, _attrs, _result, name)\n\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     64     else:\n     65       message = e.message\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\n     67   # pylint: enable=protected-access\n     68   return tensors\n\n~\\Anaconda3\\lib\\site-packages\\six.py in raise_from(value, from_value)\n\nInvalidArgumentError: Incompatible rnn model shapes inferred: expecting [num_layers, input_size, num_units, dir_count]: [1, 28, 100, 1], getting [num_layers, input_size, num_units, dir_count]: [1, 100, 100, 1]. [Op:CudnnRNN]\nIf I use same network in graph mode, there is no problem.\nreproduce error code:\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport numpy as np\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth=True\ntfe.enable_eager_execution(config=config)\nclass CudnnCrashNet(tfe.Network):\n    def __init__(self, name):\n        super(CudnnCrashNet, self).__init__(name)\n        self.gru1 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)\n        self.track_layer(self.gru1)\n        self.gru2 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)\n        self.track_layer(self.gru2)\n        self.fc = self.track_layer(tf.layers.Dense(10))\n    def call(self, x):\n        x = tf.reshape(x, [-1, 28, 28])\n        x = tf.transpose(x, [1, 0, 2])\n        x, s = self.gru1(x)\n        x, s = self.gru2(x)\n        x = tf.transpose(x, [1, 0, 2])\n        x = self.fc(x)\n        return x\ntoy_data = np.ones((100, 784)).astype(np.float32)\ndevice = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\nnet = CudnnCrashNet('net')\nwith tf.device(device):\n    images = tf.constant(toy_data)\n    logits = net(images)\nnormal graph-mode code:\nimport tensorflow as tf\nimport numpy as np\nclass CudnnNormalNet(tf.layers.Layer):\n    def __init__(self, name):\n        super(CudnnNormalNet, self).__init__(name)\n        self.gru1 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)\n        self.gru2 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)\n        self.fc = tf.layers.Dense(10)\n    def call(self, x):\n        x = tf.reshape(x, [-1, 28, 28])\n        x = tf.transpose(x, [1, 0, 2])\n        x, s = self.gru1(x)\n        x, s = self.gru2(x)\n        x = tf.transpose(x, [1, 0, 2])\n        x = self.fc(x)\n        return x\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth=True\ntoy_data = np.ones((100, 784)).astype(np.float32)\nwith tf.Graph().as_default():\n    net = CudnnNormalNet('net')\n    x_p = tf.placeholder(tf.float32, [None, 784])\n    logits = net(x_p)\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(logits, feed_dict={x_p: toy_data})", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.5.0dev20171230\r\n- **Python version**: 3.6\r\n\r\n### Describe the problem\r\nWhen I use more than one CudnnGRU in eager, I got an error:\r\n```Python\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-1-f618cd483215> in <module>()\r\n     26 with tf.device(device):\r\n     27     images = tf.constant(toy_data)\r\n---> 28     logits = net(images)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)\r\n    651 \r\n    652         if not in_deferred_mode:\r\n--> 653           outputs = self.call(inputs, *args, **kwargs)\r\n    654           if outputs is None:\r\n    655             raise ValueError('A layer\\'s `call` method should return a Tensor '\r\n\r\n<ipython-input-1-f618cd483215> in call(self, x)\r\n     17         x = tf.transpose(x, [1, 0, 2])\r\n     18         x, s = self.gru1(x)\r\n---> 19         x, s = self.gru2(x)\r\n     20         x = tf.transpose(x, [1, 0, 2])\r\n     21         x = self.fc(x)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)\r\n    651 \r\n    652         if not in_deferred_mode:\r\n--> 653           outputs = self.call(inputs, *args, **kwargs)\r\n    654           if outputs is None:\r\n    655             raise ValueError('A layer\\'s `call` method should return a Tensor '\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\layers\\cudnn_rnn.py in call(self, inputs, initial_state, training)\r\n    400       c = array_ops.constant([], dtype=dtype)\r\n    401     outputs, (output_h, output_c) = self._forward(inputs, h, c, self.kernel,\r\n--> 402                                                   training)\r\n    403     if self._rnn_mode == CUDNN_LSTM:\r\n    404       return outputs, (output_h, output_c)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\layers\\cudnn_rnn.py in _forward(self, inputs, h, c, opaque_params, training)\r\n    475         direction=self._direction,\r\n    476         dropout=self._dropout,\r\n--> 477         seed=self._seed)\r\n    478     return output, (output_h, output_c)\r\n    479 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py in _cudnn_rnn(inputs, input_h, input_c, params, is_training, rnn_mode, input_mode, direction, dropout, seed, name)\r\n    858       seed=seed,\r\n    859       seed2=seed2,\r\n--> 860       name=name)\r\n    861   return (outputs, output_h, output_c)\r\n    862 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\ops\\gen_cudnn_rnn_ops.py in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\r\n    120               \"seed2\", seed2, \"is_training\", is_training)\r\n    121     _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\r\n--> 122                                attrs=_attrs, ctx=_ctx, name=name)\r\n    123   _execute.record_gradient(\r\n    124       \"CudnnRNN\", _inputs_flat, _attrs, _result, name)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     64     else:\r\n     65       message = e.message\r\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     67   # pylint: enable=protected-access\r\n     68   return tensors\r\n\r\n~\\Anaconda3\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: Incompatible rnn model shapes inferred: expecting [num_layers, input_size, num_units, dir_count]: [1, 28, 100, 1], getting [num_layers, input_size, num_units, dir_count]: [1, 100, 100, 1]. [Op:CudnnRNN]\r\n```\r\nIf I use same network in graph mode, there is no problem.\r\nreproduce error code:\r\n```Python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nimport numpy as np\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth=True\r\ntfe.enable_eager_execution(config=config)\r\nclass CudnnCrashNet(tfe.Network):\r\n    def __init__(self, name):\r\n        super(CudnnCrashNet, self).__init__(name)\r\n        self.gru1 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)\r\n        self.track_layer(self.gru1)\r\n        self.gru2 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)\r\n        self.track_layer(self.gru2)\r\n        self.fc = self.track_layer(tf.layers.Dense(10))\r\n    def call(self, x):\r\n        x = tf.reshape(x, [-1, 28, 28])\r\n        x = tf.transpose(x, [1, 0, 2])\r\n        x, s = self.gru1(x)\r\n        x, s = self.gru2(x)\r\n        x = tf.transpose(x, [1, 0, 2])\r\n        x = self.fc(x)\r\n        return x\r\ntoy_data = np.ones((100, 784)).astype(np.float32)\r\ndevice = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\r\nnet = CudnnCrashNet('net')\r\nwith tf.device(device):\r\n    images = tf.constant(toy_data)\r\n    logits = net(images)\r\n```\r\nnormal graph-mode code:\r\n```Python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nclass CudnnNormalNet(tf.layers.Layer):\r\n    def __init__(self, name):\r\n        super(CudnnNormalNet, self).__init__(name)\r\n        self.gru1 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)\r\n        self.gru2 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)\r\n        self.fc = tf.layers.Dense(10)\r\n    def call(self, x):\r\n        x = tf.reshape(x, [-1, 28, 28])\r\n        x = tf.transpose(x, [1, 0, 2])\r\n        x, s = self.gru1(x)\r\n        x, s = self.gru2(x)\r\n        x = tf.transpose(x, [1, 0, 2])\r\n        x = self.fc(x)\r\n        return x\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth=True\r\ntoy_data = np.ones((100, 784)).astype(np.float32)\r\nwith tf.Graph().as_default():\r\n    net = CudnnNormalNet('net')\r\n    x_p = tf.placeholder(tf.float32, [None, 784])\r\n    logits = net(x_p)\r\n    with tf.Session(config=config) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(logits, feed_dict={x_p: toy_data})\r\n```"}