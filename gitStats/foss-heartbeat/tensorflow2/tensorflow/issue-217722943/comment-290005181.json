{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290005181", "html_url": "https://github.com/tensorflow/tensorflow/issues/8786#issuecomment-290005181", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8786", "id": 290005181, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDAwNTE4MQ==", "user": {"login": "Panaetius", "id": 664486, "node_id": "MDQ6VXNlcjY2NDQ4Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/664486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Panaetius", "html_url": "https://github.com/Panaetius", "followers_url": "https://api.github.com/users/Panaetius/followers", "following_url": "https://api.github.com/users/Panaetius/following{/other_user}", "gists_url": "https://api.github.com/users/Panaetius/gists{/gist_id}", "starred_url": "https://api.github.com/users/Panaetius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Panaetius/subscriptions", "organizations_url": "https://api.github.com/users/Panaetius/orgs", "repos_url": "https://api.github.com/users/Panaetius/repos", "events_url": "https://api.github.com/users/Panaetius/events{/privacy}", "received_events_url": "https://api.github.com/users/Panaetius/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-29T07:21:04Z", "updated_at": "2017-03-29T07:21:04Z", "author_association": "NONE", "body_html": "<p>Looking at recent committed changes to image ops and after some testing, it is due to the change in <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/60e7360dfcf8951c4a269cfddd2a9cf2a05d7f91/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/60e7360dfcf8951c4a269cfddd2a9cf2a05d7f91\"><tt>60e7360</tt></a> with clipping float images to [0,1)</p>\n<p>From the commit message, it seems like this was an intended change, though it seems a bit weird to me that float images are clipped to 0,1 by this op to be be consistent with uint8 images, since floats can have a much larger range than uint8. And the documentation of the operation should be updated to reflect that it expects images in the 0,1 range. I'm wondering if this clipping actually makes sense, since usually, standardization/normalization is made as the last step of preprocessing, but if one has a float image with numbers 0.0-255.0, one might need to standardize twice now (before and after image adjustments), since the image adjustment ops could alter the statistics of the image, and I'm not entirely sure how normalizing twice could change the data.</p>\n<p>If this change is working as intended and here to stay, then the <a href=\"https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_input.py\">Cifar 10 tutorial example</a> should be changed, since it also exhibits this problem (and is what I based my code on).</p>", "body_text": "Looking at recent committed changes to image ops and after some testing, it is due to the change in 60e7360 with clipping float images to [0,1)\nFrom the commit message, it seems like this was an intended change, though it seems a bit weird to me that float images are clipped to 0,1 by this op to be be consistent with uint8 images, since floats can have a much larger range than uint8. And the documentation of the operation should be updated to reflect that it expects images in the 0,1 range. I'm wondering if this clipping actually makes sense, since usually, standardization/normalization is made as the last step of preprocessing, but if one has a float image with numbers 0.0-255.0, one might need to standardize twice now (before and after image adjustments), since the image adjustment ops could alter the statistics of the image, and I'm not entirely sure how normalizing twice could change the data.\nIf this change is working as intended and here to stay, then the Cifar 10 tutorial example should be changed, since it also exhibits this problem (and is what I based my code on).", "body": "Looking at recent committed changes to image ops and after some testing, it is due to the change in 60e7360dfcf8951c4a269cfddd2a9cf2a05d7f91 with clipping float images to [0,1)\r\n\r\nFrom the commit message, it seems like this was an intended change, though it seems a bit weird to me that float images are clipped to 0,1 by this op to be be consistent with uint8 images, since floats can have a much larger range than uint8. And the documentation of the operation should be updated to reflect that it expects images in the 0,1 range. I'm wondering if this clipping actually makes sense, since usually, standardization/normalization is made as the last step of preprocessing, but if one has a float image with numbers 0.0-255.0, one might need to standardize twice now (before and after image adjustments), since the image adjustment ops could alter the statistics of the image, and I'm not entirely sure how normalizing twice could change the data.\r\n\r\nIf this change is working as intended and here to stay, then the [Cifar 10 tutorial example](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_input.py) should be changed, since it also exhibits this problem (and is what I based my code on)."}