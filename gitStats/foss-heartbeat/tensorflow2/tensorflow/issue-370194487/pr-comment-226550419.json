{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/226550419", "pull_request_review_id": 166399804, "id": 226550419, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNjU1MDQxOQ==", "diff_hunk": "@@ -276,8 +275,13 @@ Status GdrMemoryManager::Init() {\n     };\n     GPUProcessState::singleton()->AddGPUAllocVisitor(bus_id,\n                                                      cuda_alloc_visitor);\n-    GPUProcessState::singleton()->AddCUDAHostAllocVisitor(bus_id,\n-                                                          alloc_visitor);\n+\n+    for (int numa_idx = 0; numa_idx < port::NUMANumNodes(); ++numa_idx) {", "path": "tensorflow/contrib/gdr/gdr_memory_manager.cc", "position": 24, "original_position": 19, "commit_id": "5c750c20a43148dc02b1677885d950e7e005a0a2", "original_commit_id": "83e61f6060af9066e41dbac7dea44d860d66903a", "user": {"login": "yanivbl6", "id": 24679884, "node_id": "MDQ6VXNlcjI0Njc5ODg0", "avatar_url": "https://avatars2.githubusercontent.com/u/24679884?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yanivbl6", "html_url": "https://github.com/yanivbl6", "followers_url": "https://api.github.com/users/yanivbl6/followers", "following_url": "https://api.github.com/users/yanivbl6/following{/other_user}", "gists_url": "https://api.github.com/users/yanivbl6/gists{/gist_id}", "starred_url": "https://api.github.com/users/yanivbl6/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yanivbl6/subscriptions", "organizations_url": "https://api.github.com/users/yanivbl6/orgs", "repos_url": "https://api.github.com/users/yanivbl6/repos", "events_url": "https://api.github.com/users/yanivbl6/events{/privacy}", "received_events_url": "https://api.github.com/users/yanivbl6/received_events", "type": "User", "site_admin": false}, "body": "GDR is the correct name here. Transporting between GPU's host pinned memory is technically just \"GD\".\r\n\r\nI would like to eventually add the possibility to selectively avoid GPU-direct on slow PCie routes (Like QPI), but I prefer to just focus on hotfixes for now, till the upcoming changes regarding the transport contributions.", "created_at": "2018-10-19T07:06:12Z", "updated_at": "2018-10-22T17:56:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22989#discussion_r226550419", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22989", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/226550419"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22989#discussion_r226550419"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22989"}}, "body_html": "<p>GDR is the correct name here. Transporting between GPU's host pinned memory is technically just \"GD\".</p>\n<p>I would like to eventually add the possibility to selectively avoid GPU-direct on slow PCie routes (Like QPI), but I prefer to just focus on hotfixes for now, till the upcoming changes regarding the transport contributions.</p>", "body_text": "GDR is the correct name here. Transporting between GPU's host pinned memory is technically just \"GD\".\nI would like to eventually add the possibility to selectively avoid GPU-direct on slow PCie routes (Like QPI), but I prefer to just focus on hotfixes for now, till the upcoming changes regarding the transport contributions.", "in_reply_to_id": 226233966}