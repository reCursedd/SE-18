{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9077", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9077/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9077/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9077/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9077", "id": 220450904, "node_id": "MDU6SXNzdWUyMjA0NTA5MDQ=", "number": 9077, "title": "Any idea why \"failed to create cublas handle\"?", "user": {"login": "714586886", "id": 23442848, "node_id": "MDQ6VXNlcjIzNDQyODQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/23442848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/714586886", "html_url": "https://github.com/714586886", "followers_url": "https://api.github.com/users/714586886/followers", "following_url": "https://api.github.com/users/714586886/following{/other_user}", "gists_url": "https://api.github.com/users/714586886/gists{/gist_id}", "starred_url": "https://api.github.com/users/714586886/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/714586886/subscriptions", "organizations_url": "https://api.github.com/users/714586886/orgs", "repos_url": "https://api.github.com/users/714586886/repos", "events_url": "https://api.github.com/users/714586886/events{/privacy}", "received_events_url": "https://api.github.com/users/714586886/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-04-09T06:08:48Z", "updated_at": "2017-11-21T18:56:05Z", "closed_at": "2017-04-14T00:13:50Z", "author_association": "NONE", "body_html": "<p>When I run a demo of Faster R-CNN,I meet an error,I have spend a whole week on it,but not work:</p>\n<p>Env:</p>\n<ul>\n<li><em>OS</em>:Ubuntu16.04</li>\n<li><em>TensorFlow version</em>:1.0.1</li>\n<li><em>TensorFlow installed from (source or binary)?</em>:binary</li>\n<li><em>CUDA/cuDNN version</em>:CUDA8.0 cuDNN5.1</li>\n<li><em>GPU Model and Memory</em>: GTX 950 2G</li>\n<li><em>Exact command to reproduce</em>:python ./tools/demo.py --model model_path</li>\n</ul>\n<p>See <a href=\"https://github.com/smallcorgi/Faster-RCNN_TF\">https://github.com/smallcorgi/Faster-RCNN_TF</a></p>\n<p>The error as follows:</p>\n<p>W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 791.02MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.<br>\nW tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.<br>\nW tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.<br>\nE tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED<br>\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support<br>\nTraceback (most recent call last):<br>\nFile \"./tools/demo.py\", line 126, in <br>\n_, _= im_detect(sess, net, im)<br>\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/fast_rcnn/test.py\", line 179, in im_detect<br>\nrun_metadata=run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 767, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _run<br>\nfeed_dict_string, options, run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1015, in _do_run<br>\ntarget_list, options, run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1035, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=1369, n=18, k=512<br>\n[[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]]<br>\n[[Node: cls_score/cls_score/_109 = _Recv<a href=\"\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_cls_score/cls_score\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"</a>]]</p>\n<p>Caused by op u'rpn_cls_score/Conv2D', defined at:<br>\nFile \"./tools/demo.py\", line 114, in <br>\nnet = get_network(args.demo_net)<br>\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/factory.py\", line 28, in get_network<br>\nreturn networks.VGGnet_test()<br>\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py\", line 16, in <strong>init</strong><br>\nself.setup()<br>\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py\", line 40, in setup<br>\n.conv(1,1,len(anchor_scales)<em>3</em>2,1,1,padding='VALID',relu = False,name='rpn_cls_score'))<br>\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 25, in layer_decorated<br>\nlayer_output = op(self, layer_input, *args, **kwargs)<br>\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 109, in conv<br>\nconv = convolve(input, kernel)<br>\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 100, in <br>\nconvolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d<br>\ndata_format=data_format, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in <strong>init</strong><br>\nself._traceback = _extract_stack()</p>\n<p>InternalError (see above for traceback): Blas SGEMM launch failed : m=1369, n=18, k=512<br>\n[[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]]<br>\n[[Node: cls_score/cls_score/_109 = _Recv<a href=\"\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_cls_score/cls_score\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"</a>]]</p>", "body_text": "When I run a demo of Faster R-CNN,I meet an error,I have spend a whole week on it,but not work:\nEnv:\n\nOS:Ubuntu16.04\nTensorFlow version:1.0.1\nTensorFlow installed from (source or binary)?:binary\nCUDA/cuDNN version:CUDA8.0 cuDNN5.1\nGPU Model and Memory: GTX 950 2G\nExact command to reproduce:python ./tools/demo.py --model model_path\n\nSee https://github.com/smallcorgi/Faster-RCNN_TF\nThe error as follows:\nW tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 791.02MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nE tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support\nTraceback (most recent call last):\nFile \"./tools/demo.py\", line 126, in \n_, _= im_detect(sess, net, im)\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/fast_rcnn/test.py\", line 179, in im_detect\nrun_metadata=run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 767, in run\nrun_metadata_ptr)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _run\nfeed_dict_string, options, run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\ntarget_list, options, run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=1369, n=18, k=512\n[[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]]\n[[Node: cls_score/cls_score/_109 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_cls_score/cls_score\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nCaused by op u'rpn_cls_score/Conv2D', defined at:\nFile \"./tools/demo.py\", line 114, in \nnet = get_network(args.demo_net)\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/factory.py\", line 28, in get_network\nreturn networks.VGGnet_test()\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py\", line 16, in init\nself.setup()\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py\", line 40, in setup\n.conv(1,1,len(anchor_scales)32,1,1,padding='VALID',relu = False,name='rpn_cls_score'))\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 25, in layer_decorated\nlayer_output = op(self, layer_input, *args, **kwargs)\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 109, in conv\nconv = convolve(input, kernel)\nFile \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 100, in \nconvolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d\ndata_format=data_format, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in init\nself._traceback = _extract_stack()\nInternalError (see above for traceback): Blas SGEMM launch failed : m=1369, n=18, k=512\n[[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]]\n[[Node: cls_score/cls_score/_109 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_cls_score/cls_score\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]", "body": "When I run a demo of Faster R-CNN,I meet an error,I have spend a whole week on it,but not work:\r\n\r\nEnv:\r\n- *OS*:Ubuntu16.04\r\n- *TensorFlow version*:1.0.1\r\n- *TensorFlow installed from (source or binary)?*:binary\r\n- *CUDA/cuDNN version*:CUDA8.0 cuDNN5.1\r\n- *GPU Model and Memory*: GTX 950 2G\r\n- *Exact command to reproduce*:python ./tools/demo.py --model model_path\r\n\r\nSee https://github.com/smallcorgi/Faster-RCNN_TF\r\n\r\nThe error as follows:\r\n\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 791.02MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\r\nE tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\nTraceback (most recent call last):\r\n  File \"./tools/demo.py\", line 126, in <module>\r\n    _, _= im_detect(sess, net, im)\r\n  File \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/fast_rcnn/test.py\", line 179, in im_detect\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=1369, n=18, k=512\r\n\t [[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]]\r\n\t [[Node: cls_score/cls_score/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_cls_score/cls_score\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'rpn_cls_score/Conv2D', defined at:\r\n  File \"./tools/demo.py\", line 114, in <module>\r\n    net = get_network(args.demo_net)\r\n  File \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/factory.py\", line 28, in get_network\r\n    return networks.VGGnet_test()\r\n  File \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py\", line 16, in __init__\r\n    self.setup()\r\n  File \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py\", line 40, in setup\r\n    .conv(1,1,len(anchor_scales)*3*2,1,1,padding='VALID',relu = False,name='rpn_cls_score'))\r\n  File \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 25, in layer_decorated\r\n    layer_output = op(self, layer_input, *args, **kwargs)\r\n  File \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 109, in conv\r\n    conv = convolve(input, kernel)\r\n  File \"/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 100, in <lambda>\r\n    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d\r\n    data_format=data_format, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInternalError (see above for traceback): Blas SGEMM launch failed : m=1369, n=18, k=512\r\n\t [[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]]\r\n\t [[Node: cls_score/cls_score/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_357_cls_score/cls_score\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n"}