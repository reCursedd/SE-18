{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9337", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9337/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9337/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9337/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9337", "id": 223078621, "node_id": "MDU6SXNzdWUyMjMwNzg2MjE=", "number": 9337, "title": "wide_n_deep meets kint32max bug.", "user": {"login": "gusuperstar", "id": 7457871, "node_id": "MDQ6VXNlcjc0NTc4NzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/7457871?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gusuperstar", "html_url": "https://github.com/gusuperstar", "followers_url": "https://api.github.com/users/gusuperstar/followers", "following_url": "https://api.github.com/users/gusuperstar/following{/other_user}", "gists_url": "https://api.github.com/users/gusuperstar/gists{/gist_id}", "starred_url": "https://api.github.com/users/gusuperstar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gusuperstar/subscriptions", "organizations_url": "https://api.github.com/users/gusuperstar/orgs", "repos_url": "https://api.github.com/users/gusuperstar/repos", "events_url": "https://api.github.com/users/gusuperstar/events{/privacy}", "received_events_url": "https://api.github.com/users/gusuperstar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-20T14:04:42Z", "updated_at": "2017-04-20T16:32:08Z", "closed_at": "2017-04-20T16:32:08Z", "author_association": "NONE", "body_html": "<p>I am trying to run a wide_n_deep model on a large dataset ------ I copy and paste adult.data 100 times as training data(adult.data.new 3256200 lines), and take adult.test as test data.</p>\n<p>with command:<br>\npython wide_n_deep_tutorial.py --model_type=wide_n_deep --train_data=data/adult.data.new --test_data=data/adult.test</p>\n<p>When I run the same model on original set of this, i.e. ~ 32562 set, the model runs fine. But when it tries on this 3256200 set, it throws up the following stack trace and exits.</p>\n<p>Am I missing something here? The memory stats look fine when the program is running.</p>\n<p>[libprotobuf ERROR google/protobuf/io/zero_copy_stream_impl_lite.cc:173] Cannot allocate buffer larger than kint32max for StringOutputStream.<br>\nTraceback (most recent call last):<br>\nFile \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 234, in <br>\ntf.app.run(main=main, argv=[sys.argv[0]] + unparsed)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run<br>\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))<br>\nFile \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 197, in main<br>\nFLAGS.train_data, FLAGS.test_data)<br>\nFile \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 186, in train_and_eval<br>\nm.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 280, in new_func<br>\nreturn func(*args, **kwargs)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 426, in fit<br>\nloss = self._train_model(input_fn=input_fn, hooks=hooks)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 984, in _train_model<br>\n_, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 462, in run<br>\nrun_metadata=run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 786, in run<br>\nrun_metadata=run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 744, in run<br>\nreturn self._sess.run(*args, **kwargs)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 883, in run<br>\nfeed_dict, options)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 909, in _call_hook_before_run<br>\nrequest = hook.before_run(run_context)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 340, in before_run<br>\n\"graph.pbtxt\")<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_io.py\", line 67, in write_graph<br>\nfile_io.atomic_write_string_to_file(path, str(graph_def))<br>\nValueError: Unable to convert message to str</p>", "body_text": "I am trying to run a wide_n_deep model on a large dataset ------ I copy and paste adult.data 100 times as training data(adult.data.new 3256200 lines), and take adult.test as test data.\nwith command:\npython wide_n_deep_tutorial.py --model_type=wide_n_deep --train_data=data/adult.data.new --test_data=data/adult.test\nWhen I run the same model on original set of this, i.e. ~ 32562 set, the model runs fine. But when it tries on this 3256200 set, it throws up the following stack trace and exits.\nAm I missing something here? The memory stats look fine when the program is running.\n[libprotobuf ERROR google/protobuf/io/zero_copy_stream_impl_lite.cc:173] Cannot allocate buffer larger than kint32max for StringOutputStream.\nTraceback (most recent call last):\nFile \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 234, in \ntf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))\nFile \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 197, in main\nFLAGS.train_data, FLAGS.test_data)\nFile \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 186, in train_and_eval\nm.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 280, in new_func\nreturn func(*args, **kwargs)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 426, in fit\nloss = self._train_model(input_fn=input_fn, hooks=hooks)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 984, in _train_model\n_, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 462, in run\nrun_metadata=run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 786, in run\nrun_metadata=run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 744, in run\nreturn self._sess.run(*args, **kwargs)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 883, in run\nfeed_dict, options)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 909, in _call_hook_before_run\nrequest = hook.before_run(run_context)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 340, in before_run\n\"graph.pbtxt\")\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_io.py\", line 67, in write_graph\nfile_io.atomic_write_string_to_file(path, str(graph_def))\nValueError: Unable to convert message to str", "body": "\r\nI am trying to run a wide_n_deep model on a large dataset ------ I copy and paste adult.data 100 times as training data(adult.data.new 3256200 lines), and take adult.test as test data.\r\n\r\nwith command:\r\npython wide_n_deep_tutorial.py --model_type=wide_n_deep --train_data=data/adult.data.new --test_data=data/adult.test\r\n\r\nWhen I run the same model on original set of this, i.e. ~ 32562 set, the model runs fine. But when it tries on this 3256200 set, it throws up the following stack trace and exits.\r\n\r\nAm I missing something here? The memory stats look fine when the program is running.\r\n\r\n[libprotobuf ERROR google/protobuf/io/zero_copy_stream_impl_lite.cc:173] Cannot allocate buffer larger than kint32max for StringOutputStream.\r\nTraceback (most recent call last):\r\n  File \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 234, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 197, in main\r\n    FLAGS.train_data, FLAGS.test_data)\r\n  File \"/var/dl/runtime/script/wide_n_deep_tutorial.py\", line 186, in train_and_eval\r\n    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 280, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 426, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 984, in _train_model\r\n    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 462, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 786, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 744, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 883, in run\r\n    feed_dict, options)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 909, in _call_hook_before_run\r\n    request = hook.before_run(run_context)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 340, in before_run\r\n    \"graph.pbtxt\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_io.py\", line 67, in write_graph\r\n    file_io.atomic_write_string_to_file(path, str(graph_def))\r\nValueError: Unable to convert message to str"}