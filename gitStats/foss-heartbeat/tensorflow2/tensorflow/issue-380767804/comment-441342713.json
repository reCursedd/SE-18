{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/441342713", "html_url": "https://github.com/tensorflow/tensorflow/issues/23747#issuecomment-441342713", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23747", "id": 441342713, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTM0MjcxMw==", "user": {"login": "SanthoshRajendiran", "id": 41156980, "node_id": "MDQ6VXNlcjQxMTU2OTgw", "avatar_url": "https://avatars3.githubusercontent.com/u/41156980?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SanthoshRajendiran", "html_url": "https://github.com/SanthoshRajendiran", "followers_url": "https://api.github.com/users/SanthoshRajendiran/followers", "following_url": "https://api.github.com/users/SanthoshRajendiran/following{/other_user}", "gists_url": "https://api.github.com/users/SanthoshRajendiran/gists{/gist_id}", "starred_url": "https://api.github.com/users/SanthoshRajendiran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SanthoshRajendiran/subscriptions", "organizations_url": "https://api.github.com/users/SanthoshRajendiran/orgs", "repos_url": "https://api.github.com/users/SanthoshRajendiran/repos", "events_url": "https://api.github.com/users/SanthoshRajendiran/events{/privacy}", "received_events_url": "https://api.github.com/users/SanthoshRajendiran/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-24T04:27:07Z", "updated_at": "2018-11-24T04:27:07Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8277940\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/normandra\">@normandra</a><br>\nWe are going through the same process. Actually, we have been able to overcome the same issue you are facing, by providing the parameters: inference-input type and inference type. For the conversion command, do check out the stack overflow link mentioned above. Actually, we are facing some other issue in tflite conversion as discussed above and are currently waiting for <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1450614\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/suharshs\">@suharshs</a> to reply back.</p>\n<p>In your case, if you have not explicitly mentioned the inference type parameter. by default it will take the input type as inference input type. By default, FLOAT becomes the inference type (You can set it to QUANTIZED UINT8 also). Actually, updates in tflite conversion. forces on usage of Quantized UINT8 and Float data types.</p>", "body_text": "Hi @normandra\nWe are going through the same process. Actually, we have been able to overcome the same issue you are facing, by providing the parameters: inference-input type and inference type. For the conversion command, do check out the stack overflow link mentioned above. Actually, we are facing some other issue in tflite conversion as discussed above and are currently waiting for @suharshs to reply back.\nIn your case, if you have not explicitly mentioned the inference type parameter. by default it will take the input type as inference input type. By default, FLOAT becomes the inference type (You can set it to QUANTIZED UINT8 also). Actually, updates in tflite conversion. forces on usage of Quantized UINT8 and Float data types.", "body": "Hi @normandra \r\nWe are going through the same process. Actually, we have been able to overcome the same issue you are facing, by providing the parameters: inference-input type and inference type. For the conversion command, do check out the stack overflow link mentioned above. Actually, we are facing some other issue in tflite conversion as discussed above and are currently waiting for @suharshs to reply back. \r\n\r\nIn your case, if you have not explicitly mentioned the inference type parameter. by default it will take the input type as inference input type. By default, FLOAT becomes the inference type (You can set it to QUANTIZED UINT8 also). Actually, updates in tflite conversion. forces on usage of Quantized UINT8 and Float data types."}