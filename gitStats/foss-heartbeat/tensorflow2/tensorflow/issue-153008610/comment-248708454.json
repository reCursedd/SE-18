{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/248708454", "html_url": "https://github.com/tensorflow/tensorflow/issues/2218#issuecomment-248708454", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2218", "id": 248708454, "node_id": "MDEyOklzc3VlQ29tbWVudDI0ODcwODQ1NA==", "user": {"login": "jhseu", "id": 170179, "node_id": "MDQ6VXNlcjE3MDE3OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/170179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhseu", "html_url": "https://github.com/jhseu", "followers_url": "https://api.github.com/users/jhseu/followers", "following_url": "https://api.github.com/users/jhseu/following{/other_user}", "gists_url": "https://api.github.com/users/jhseu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhseu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhseu/subscriptions", "organizations_url": "https://api.github.com/users/jhseu/orgs", "repos_url": "https://api.github.com/users/jhseu/repos", "events_url": "https://api.github.com/users/jhseu/events{/privacy}", "received_events_url": "https://api.github.com/users/jhseu/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-21T18:56:57Z", "updated_at": "2016-09-21T18:56:57Z", "author_association": "MEMBER", "body_html": "<p>HDFS support is in master and will be in the 0.11 release. There'll be a how to on the website that's live with 0.11, but I've copied and pasted it below. If you run into any bugs, file an issue and assign it to me.</p>\n<p>I haven't tested Kerberos support. Patches are welcome if any code is needed for that:</p>\n<blockquote>\n<p>To use HDFS with TensorFlow, change the file paths you use to read and write<br>\ndata to an HDFS path. For example:</p>\n<div class=\"highlight highlight-source-python\"><pre>filename_queue <span class=\"pl-k\">=</span> tf.train.string_input_producer([\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hdfs://namenode:8020/path/to/file1.csv<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hdfs://namonode:8020/path/to/file2.csv<span class=\"pl-pds\">\"</span></span>,\n])</pre></div>\n<p>If you want to use the namenode specified in your HDFS configuration files, then<br>\nchange the file prefix to <code>hdfs://default/</code>.</p>\n<p>When launching your TensorFlow program, the following environment variables must<br>\nbe set:</p>\n<ul>\n<li><strong>JAVA_HOME</strong>: The location of your Java installation.</li>\n<li><strong>HADOOP_HDFS_HOME</strong>: The location of your HDFS installation. You can also<br>\nset this environment variable by running:</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">source</span> <span class=\"pl-smi\">$HADOOP_HOME</span>/libexec/hadoop-config.sh</pre></div>\n<ul>\n<li><strong>LD_LIBRARY_PATH</strong>: To include the path to libjvm.so. On Linux:</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span class=\"pl-smi\">$JAVA_HOME</span>/jre/lib/amd64/server</pre></div>\n<ul>\n<li><strong>CLASSPATH</strong>: The Hadoop jars must be added prior to running your<br>\nTensorFlow program. The CLASSPATH set by<br>\n<code>$HADOOP_HOME/libexec/hadoop-config.sh</code> is insufficient. Globs must be<br>\nexpanded as described in the libhdfs documentation:</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>CLASSPATH=<span class=\"pl-s\"><span class=\"pl-pds\">$(</span><span class=\"pl-smi\">$HADOOP_HDFS_HOME</span>/bin/hdfs classpath --glob<span class=\"pl-pds\">)</span></span> python your_script.py</pre></div>\n</blockquote>", "body_text": "HDFS support is in master and will be in the 0.11 release. There'll be a how to on the website that's live with 0.11, but I've copied and pasted it below. If you run into any bugs, file an issue and assign it to me.\nI haven't tested Kerberos support. Patches are welcome if any code is needed for that:\n\nTo use HDFS with TensorFlow, change the file paths you use to read and write\ndata to an HDFS path. For example:\nfilename_queue = tf.train.string_input_producer([\n    \"hdfs://namenode:8020/path/to/file1.csv\",\n    \"hdfs://namonode:8020/path/to/file2.csv\",\n])\nIf you want to use the namenode specified in your HDFS configuration files, then\nchange the file prefix to hdfs://default/.\nWhen launching your TensorFlow program, the following environment variables must\nbe set:\n\nJAVA_HOME: The location of your Java installation.\nHADOOP_HDFS_HOME: The location of your HDFS installation. You can also\nset this environment variable by running:\n\nsource $HADOOP_HOME/libexec/hadoop-config.sh\n\nLD_LIBRARY_PATH: To include the path to libjvm.so. On Linux:\n\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$JAVA_HOME/jre/lib/amd64/server\n\nCLASSPATH: The Hadoop jars must be added prior to running your\nTensorFlow program. The CLASSPATH set by\n$HADOOP_HOME/libexec/hadoop-config.sh is insufficient. Globs must be\nexpanded as described in the libhdfs documentation:\n\nCLASSPATH=$($HADOOP_HDFS_HOME/bin/hdfs classpath --glob) python your_script.py", "body": "HDFS support is in master and will be in the 0.11 release. There'll be a how to on the website that's live with 0.11, but I've copied and pasted it below. If you run into any bugs, file an issue and assign it to me.\n\nI haven't tested Kerberos support. Patches are welcome if any code is needed for that:\n\n> To use HDFS with TensorFlow, change the file paths you use to read and write\n> data to an HDFS path. For example:\n> \n> ``` python\n> filename_queue = tf.train.string_input_producer([\n>     \"hdfs://namenode:8020/path/to/file1.csv\",\n>     \"hdfs://namonode:8020/path/to/file2.csv\",\n> ])\n> ```\n> \n> If you want to use the namenode specified in your HDFS configuration files, then\n> change the file prefix to `hdfs://default/`.\n> \n> When launching your TensorFlow program, the following environment variables must\n> be set:\n> -   **JAVA_HOME**: The location of your Java installation.\n> -   **HADOOP_HDFS_HOME**: The location of your HDFS installation. You can also\n>   set this environment variable by running:\n> \n> ``` shell\n> source $HADOOP_HOME/libexec/hadoop-config.sh\n> ```\n> -   **LD_LIBRARY_PATH**: To include the path to libjvm.so. On Linux:\n> \n> ``` shell\n> export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$JAVA_HOME/jre/lib/amd64/server\n> ```\n> -   **CLASSPATH**: The Hadoop jars must be added prior to running your\n>   TensorFlow program. The CLASSPATH set by\n>   `$HADOOP_HOME/libexec/hadoop-config.sh` is insufficient. Globs must be\n>   expanded as described in the libhdfs documentation:\n> \n> ``` shell\n> CLASSPATH=$($HADOOP_HDFS_HOME/bin/hdfs classpath --glob) python your_script.py\n> ```\n"}