{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/331639832", "html_url": "https://github.com/tensorflow/tensorflow/issues/9489#issuecomment-331639832", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9489", "id": 331639832, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMTYzOTgzMg==", "user": {"login": "jeremy-rutman", "id": 3863744, "node_id": "MDQ6VXNlcjM4NjM3NDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/3863744?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeremy-rutman", "html_url": "https://github.com/jeremy-rutman", "followers_url": "https://api.github.com/users/jeremy-rutman/followers", "following_url": "https://api.github.com/users/jeremy-rutman/following{/other_user}", "gists_url": "https://api.github.com/users/jeremy-rutman/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeremy-rutman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeremy-rutman/subscriptions", "organizations_url": "https://api.github.com/users/jeremy-rutman/orgs", "repos_url": "https://api.github.com/users/jeremy-rutman/repos", "events_url": "https://api.github.com/users/jeremy-rutman/events{/privacy}", "received_events_url": "https://api.github.com/users/jeremy-rutman/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-23T14:39:55Z", "updated_at": "2017-09-23T14:43:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This seems to possibly be an out-of-memory being masked by the CUBLAS_STATUS_NOT_INITIALIZED error. When I have low memory and ask for a new session for detection I hit this error, when I clear the gpu of other processes and free memory then I do not get the cublas error.  Since by default it seems tensorflow sucks up nearly all available memory this could happen a lot I imagine.</p>\n<pre><code>root@746bb093df44:/data/jeremy/tensorflow/models# python /usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\ncwd /data/jeremy/tensorflow/models/object_detection\nusing gpu0\n2017-09-23 14:37:50.992104: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-23 14:37:50.992170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-23 14:37:51.072360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-09-23 14:37:51.072588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \nname: Quadro P6000\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.645\npciBusID 0000:00:05.0\nTotal memory: 23.87GiB\nFree memory: 805.44MiB\n2017-09-23 14:37:51.072625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \n2017-09-23 14:37:51.072643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \n2017-09-23 14:37:51.072664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Quadro P6000, pci bus id: 0000:00:05.0)\n2017-09-23 14:37:56.768781: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n2017-09-23 14:37:56.768888: W tensorflow/stream_executor/stream.cc:1756] attempting to perform BLAS operation using StreamExecutor without BLAS support\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 264, in &lt;module&gt;\n    test_detect()\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 123, in test_detect\n    feed_dict={image_tensor: image_np_expanded})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=36300, n=80, k=64\n\t [[Node: FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/MaxPool_3a_3x3/MaxPool, FirstStageFeatureExtractor/InceptionResnetV2/Conv2d_3b_1x1/weights/read)]]\n\t [[Node: SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat/_391 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_21463_SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution', defined at:\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 70, in &lt;module&gt;\n    tf.import_graph_def(od_graph_def, name='')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas SGEMM launch failed : m=36300, n=80, k=64\n\t [[Node: FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/MaxPool_3a_3x3/MaxPool, FirstStageFeatureExtractor/InceptionResnetV2/Conv2d_3b_1x1/weights/read)]]\n\t [[Node: SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat/_391 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_21463_SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n</code></pre>", "body_text": "This seems to possibly be an out-of-memory being masked by the CUBLAS_STATUS_NOT_INITIALIZED error. When I have low memory and ask for a new session for detection I hit this error, when I clear the gpu of other processes and free memory then I do not get the cublas error.  Since by default it seems tensorflow sucks up nearly all available memory this could happen a lot I imagine.\nroot@746bb093df44:/data/jeremy/tensorflow/models# python /usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\ncwd /data/jeremy/tensorflow/models/object_detection\nusing gpu0\n2017-09-23 14:37:50.992104: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-23 14:37:50.992170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-09-23 14:37:51.072360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-09-23 14:37:51.072588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \nname: Quadro P6000\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.645\npciBusID 0000:00:05.0\nTotal memory: 23.87GiB\nFree memory: 805.44MiB\n2017-09-23 14:37:51.072625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \n2017-09-23 14:37:51.072643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \n2017-09-23 14:37:51.072664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro P6000, pci bus id: 0000:00:05.0)\n2017-09-23 14:37:56.768781: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n2017-09-23 14:37:56.768888: W tensorflow/stream_executor/stream.cc:1756] attempting to perform BLAS operation using StreamExecutor without BLAS support\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 264, in <module>\n    test_detect()\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 123, in test_detect\n    feed_dict={image_tensor: image_np_expanded})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=36300, n=80, k=64\n\t [[Node: FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/MaxPool_3a_3x3/MaxPool, FirstStageFeatureExtractor/InceptionResnetV2/Conv2d_3b_1x1/weights/read)]]\n\t [[Node: SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat/_391 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_21463_SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution', defined at:\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 70, in <module>\n    tf.import_graph_def(od_graph_def, name='')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas SGEMM launch failed : m=36300, n=80, k=64\n\t [[Node: FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/MaxPool_3a_3x3/MaxPool, FirstStageFeatureExtractor/InceptionResnetV2/Conv2d_3b_1x1/weights/read)]]\n\t [[Node: SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat/_391 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_21463_SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]", "body": "This seems to possibly be an out-of-memory being masked by the CUBLAS_STATUS_NOT_INITIALIZED error. When I have low memory and ask for a new session for detection I hit this error, when I clear the gpu of other processes and free memory then I do not get the cublas error.  Since by default it seems tensorflow sucks up nearly all available memory this could happen a lot I imagine.\r\n\r\n\r\n```\r\nroot@746bb093df44:/data/jeremy/tensorflow/models# python /usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\r\ncwd /data/jeremy/tensorflow/models/object_detection\r\nusing gpu0\r\n2017-09-23 14:37:50.992104: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-23 14:37:50.992170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-09-23 14:37:51.072360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-09-23 14:37:51.072588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \r\nname: Quadro P6000\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.645\r\npciBusID 0000:00:05.0\r\nTotal memory: 23.87GiB\r\nFree memory: 805.44MiB\r\n2017-09-23 14:37:51.072625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \r\n2017-09-23 14:37:51.072643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \r\n2017-09-23 14:37:51.072664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro P6000, pci bus id: 0000:00:05.0)\r\n2017-09-23 14:37:56.768781: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2017-09-23 14:37:56.768888: W tensorflow/stream_executor/stream.cc:1756] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 264, in <module>\r\n    test_detect()\r\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 123, in test_detect\r\n    feed_dict={image_tensor: image_np_expanded})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1124, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=36300, n=80, k=64\r\n\t [[Node: FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/MaxPool_3a_3x3/MaxPool, FirstStageFeatureExtractor/InceptionResnetV2/Conv2d_3b_1x1/weights/read)]]\r\n\t [[Node: SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat/_391 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_21463_SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution', defined at:\r\n  File \"/usr/lib/python2.7/dist-packages/variant/ml/tf_detect.py\", line 70, in <module>\r\n    tf.import_graph_def(od_graph_def, name='')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInternalError (see above for traceback): Blas SGEMM launch failed : m=36300, n=80, k=64\r\n\t [[Node: FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_3b_1x1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/MaxPool_3a_3x3/MaxPool, FirstStageFeatureExtractor/InceptionResnetV2/Conv2d_3b_1x1/weights/read)]]\r\n\t [[Node: SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat/_391 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_21463_SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame_52/Scale/concat\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```"}