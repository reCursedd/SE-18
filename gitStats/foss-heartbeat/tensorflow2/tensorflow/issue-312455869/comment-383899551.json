{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/383899551", "html_url": "https://github.com/tensorflow/tensorflow/issues/18342#issuecomment-383899551", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18342", "id": 383899551, "node_id": "MDEyOklzc3VlQ29tbWVudDM4Mzg5OTU1MQ==", "user": {"login": "WenguoLi", "id": 31765154, "node_id": "MDQ6VXNlcjMxNzY1MTU0", "avatar_url": "https://avatars0.githubusercontent.com/u/31765154?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WenguoLi", "html_url": "https://github.com/WenguoLi", "followers_url": "https://api.github.com/users/WenguoLi/followers", "following_url": "https://api.github.com/users/WenguoLi/following{/other_user}", "gists_url": "https://api.github.com/users/WenguoLi/gists{/gist_id}", "starred_url": "https://api.github.com/users/WenguoLi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WenguoLi/subscriptions", "organizations_url": "https://api.github.com/users/WenguoLi/orgs", "repos_url": "https://api.github.com/users/WenguoLi/repos", "events_url": "https://api.github.com/users/WenguoLi/events{/privacy}", "received_events_url": "https://api.github.com/users/WenguoLi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-24T11:37:53Z", "updated_at": "2018-04-24T11:37:53Z", "author_association": "NONE", "body_html": "<p>Hi, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=37242917\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/coutner\">@coutner</a> ,<br>\nI used your steps  to quantize the  ssd_mobilenet_v1, but I had not succeeded in getting the .tflite model.<br>\nThere are the following errors:</p>\n<ol>\n<li>when running optimize_for_inference, some warning had arisen.</li>\n</ol>\n<pre><code>$ bazel run -c opt tensorflow/python/tools/optimize_for_inference -- \\\n&gt;     --input=$DETECT_PB --output=$STRIPPED_PB --frozen_graph=True \\\n&gt;     --input_names=Preprocessor/sub --output_names=concat,concat_1 \\\n&gt;     --toco_compatible=True \\\n&gt;     --alsologtostderr\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/BatchNorm/FusedBatchNorm'\n\n</code></pre>\n<ol start=\"2\">\n<li>When Running toco,</li>\n</ol>\n<pre><code>$ bazel run tensorflow/contrib/lite/toco:toco -- \n&gt;   --input_file=$STRIPPED_PB \\\n&gt;   --output_file=$DETECT_FB \\\n&gt;   --input_format=TENSORFLOW_GRAPHDEF \\\n&gt;   --output_format=TFLITE \\\n&gt;   --inference_type=QUANTIZED_UINT8 \\\n&gt;   --input_shapes=1,300,300,3 \\\n&gt;   --input_arrays=Preprocessor/sub \\\n&gt;   --output_arrays=concat,concat_1 \\\n&gt;   --std_values=128 \\\n&gt;   --mean_values=127 \\\n&gt;   --dump_graphviz=/tmp\n2018-04-24 18:51:51.645315: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 253 operators, 450 arrays (0 quantized)\n2018-04-24 18:51:51.686011: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 253 operators, 450 arrays (0 quantized)\n2018-04-24 18:51:51.774563: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 62 operators, 169 arrays (1 quantized)\n2018-04-24 18:51:51.775525: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 62 operators, 169 arrays (1 quantized)\n2018-04-24 18:51:51.776094: F tensorflow/contrib/lite/toco/tooling_util.cc:1464] Array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\nAborted (core dumped)\n</code></pre>\n<p>Please help me to check!</p>\n<p>Thanks!</p>", "body_text": "Hi, @coutner ,\nI used your steps  to quantize the  ssd_mobilenet_v1, but I had not succeeded in getting the .tflite model.\nThere are the following errors:\n\nwhen running optimize_for_inference, some warning had arisen.\n\n$ bazel run -c opt tensorflow/python/tools/optimize_for_inference -- \\\n>     --input=$DETECT_PB --output=$STRIPPED_PB --frozen_graph=True \\\n>     --input_names=Preprocessor/sub --output_names=concat,concat_1 \\\n>     --toco_compatible=True \\\n>     --alsologtostderr\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/BatchNorm/FusedBatchNorm'\n\n\n\nWhen Running toco,\n\n$ bazel run tensorflow/contrib/lite/toco:toco -- \n>   --input_file=$STRIPPED_PB \\\n>   --output_file=$DETECT_FB \\\n>   --input_format=TENSORFLOW_GRAPHDEF \\\n>   --output_format=TFLITE \\\n>   --inference_type=QUANTIZED_UINT8 \\\n>   --input_shapes=1,300,300,3 \\\n>   --input_arrays=Preprocessor/sub \\\n>   --output_arrays=concat,concat_1 \\\n>   --std_values=128 \\\n>   --mean_values=127 \\\n>   --dump_graphviz=/tmp\n2018-04-24 18:51:51.645315: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 253 operators, 450 arrays (0 quantized)\n2018-04-24 18:51:51.686011: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 253 operators, 450 arrays (0 quantized)\n2018-04-24 18:51:51.774563: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 62 operators, 169 arrays (1 quantized)\n2018-04-24 18:51:51.775525: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 62 operators, 169 arrays (1 quantized)\n2018-04-24 18:51:51.776094: F tensorflow/contrib/lite/toco/tooling_util.cc:1464] Array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\nAborted (core dumped)\n\nPlease help me to check!\nThanks!", "body": "Hi, @coutner , \r\nI used your steps  to quantize the  ssd_mobilenet_v1, but I had not succeeded in getting the .tflite model.\r\nThere are the following errors:\r\n1. when running optimize_for_inference, some warning had arisen. \r\n```\r\n$ bazel run -c opt tensorflow/python/tools/optimize_for_inference -- \\\r\n>     --input=$DETECT_PB --output=$STRIPPED_PB --frozen_graph=True \\\r\n>     --input_names=Preprocessor/sub --output_names=concat,concat_1 \\\r\n>     --toco_compatible=True \\\r\n>     --alsologtostderr\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/BatchNorm/FusedBatchNorm'\r\n\r\n```\r\n2. When Running toco,  \r\n```\r\n$ bazel run tensorflow/contrib/lite/toco:toco -- \r\n>   --input_file=$STRIPPED_PB \\\r\n>   --output_file=$DETECT_FB \\\r\n>   --input_format=TENSORFLOW_GRAPHDEF \\\r\n>   --output_format=TFLITE \\\r\n>   --inference_type=QUANTIZED_UINT8 \\\r\n>   --input_shapes=1,300,300,3 \\\r\n>   --input_arrays=Preprocessor/sub \\\r\n>   --output_arrays=concat,concat_1 \\\r\n>   --std_values=128 \\\r\n>   --mean_values=127 \\\r\n>   --dump_graphviz=/tmp\r\n2018-04-24 18:51:51.645315: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 253 operators, 450 arrays (0 quantized)\r\n2018-04-24 18:51:51.686011: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 253 operators, 450 arrays (0 quantized)\r\n2018-04-24 18:51:51.774563: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 62 operators, 169 arrays (1 quantized)\r\n2018-04-24 18:51:51.775525: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 62 operators, 169 arrays (1 quantized)\r\n2018-04-24 18:51:51.776094: F tensorflow/contrib/lite/toco/tooling_util.cc:1464] Array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\nAborted (core dumped)\r\n```\r\nPlease help me to check!\r\n\r\nThanks!\r\n\r\n"}