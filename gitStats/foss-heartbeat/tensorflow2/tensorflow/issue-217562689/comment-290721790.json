{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290721790", "html_url": "https://github.com/tensorflow/tensorflow/issues/8775#issuecomment-290721790", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8775", "id": 290721790, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDcyMTc5MA==", "user": {"login": "mhnatiuk", "id": 2299492, "node_id": "MDQ6VXNlcjIyOTk0OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2299492?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mhnatiuk", "html_url": "https://github.com/mhnatiuk", "followers_url": "https://api.github.com/users/mhnatiuk/followers", "following_url": "https://api.github.com/users/mhnatiuk/following{/other_user}", "gists_url": "https://api.github.com/users/mhnatiuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/mhnatiuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mhnatiuk/subscriptions", "organizations_url": "https://api.github.com/users/mhnatiuk/orgs", "repos_url": "https://api.github.com/users/mhnatiuk/repos", "events_url": "https://api.github.com/users/mhnatiuk/events{/privacy}", "received_events_url": "https://api.github.com/users/mhnatiuk/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-31T14:07:52Z", "updated_at": "2017-03-31T14:47:43Z", "author_association": "NONE", "body_html": "<p>I switched back to using TrainingHelper instead of ScheduledEmbeddingHelper, and feeded embedded inputs by looking up embeddings using tf.nn.embedding_lookup. It works, now I run into other problem, the shape of decoder_outputs.rnn_output is (AFAIK) <em>dynamic</em> and it's not possible to feed it into tf.contrib.seq2seq.sequence_loss, since it expects TARGETS and LOGITS to have compatible shapes.<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> Do you have any solutions for feeding decoder_outputs.rnn_output as logits to sequence_loss?</p>\n<p>BTW Shouldn't \"weights\" argument in sequence to sequence loss become optional as if we don't use padding, we don't need weights == 0 for right-padding in decoding?</p>", "body_text": "I switched back to using TrainingHelper instead of ScheduledEmbeddingHelper, and feeded embedded inputs by looking up embeddings using tf.nn.embedding_lookup. It works, now I run into other problem, the shape of decoder_outputs.rnn_output is (AFAIK) dynamic and it's not possible to feed it into tf.contrib.seq2seq.sequence_loss, since it expects TARGETS and LOGITS to have compatible shapes.\n@ebrevdo Do you have any solutions for feeding decoder_outputs.rnn_output as logits to sequence_loss?\nBTW Shouldn't \"weights\" argument in sequence to sequence loss become optional as if we don't use padding, we don't need weights == 0 for right-padding in decoding?", "body": "I switched back to using TrainingHelper instead of ScheduledEmbeddingHelper, and feeded embedded inputs by looking up embeddings using tf.nn.embedding_lookup. It works, now I run into other problem, the shape of decoder_outputs.rnn_output is (AFAIK) *dynamic* and it's not possible to feed it into tf.contrib.seq2seq.sequence_loss, since it expects TARGETS and LOGITS to have compatible shapes.\r\n@ebrevdo Do you have any solutions for feeding decoder_outputs.rnn_output as logits to sequence_loss?\r\n\r\nBTW Shouldn't \"weights\" argument in sequence to sequence loss become optional as if we don't use padding, we don't need weights == 0 for right-padding in decoding?"}