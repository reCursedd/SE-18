{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/289816751", "html_url": "https://github.com/tensorflow/tensorflow/issues/8775#issuecomment-289816751", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8775", "id": 289816751, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTgxNjc1MQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-28T15:56:15Z", "updated_at": "2017-03-28T15:56:15Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">We need to update that video somehow.  It turns out it's cleaner to\nimplement attention as an RNNCell wrapper rather than decoder.  This way it\ncan be combined with other decoders easily.  See tensorflow master branch,\ntf.contrib.seq2seq.AttentionWrapper.  It's pretty feature complete, and can\nbe used with other RNNCells, wrappers, and the BasicDecoder.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Tue, Mar 28, 2017 at 6:38 AM, mhnatiuk ***@***.***&gt; wrote:\n Hi,\n <a class=\"user-mention\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> &lt;<a href=\"https://github.com/ebrevdo\">https://github.com/ebrevdo</a>&gt; Eugene speaks here\n <a href=\"https://www.youtube.com/watch?v=RIR_-Xlbp7s\">https://www.youtube.com/watch?v=RIR_-Xlbp7s</a> (29:50) about a class\n AttentionDecoder and says it's under development (as of Tensorflow Summit\n date), however I can't find this class anywhere in the master/r1.1/r1.0\n tensorflow code. Do you know when it will be added?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"217562689\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8775\" href=\"https://github.com/tensorflow/tensorflow/issues/8775\">#8775</a>&gt;, or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim5clNyjhcV_TYgzOpSy_HbQhRMTeks5rqQ1hgaJpZM4MrogY\">https://github.com/notifications/unsubscribe-auth/ABtim5clNyjhcV_TYgzOpSy_HbQhRMTeks5rqQ1hgaJpZM4MrogY</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "We need to update that video somehow.  It turns out it's cleaner to\nimplement attention as an RNNCell wrapper rather than decoder.  This way it\ncan be combined with other decoders easily.  See tensorflow master branch,\ntf.contrib.seq2seq.AttentionWrapper.  It's pretty feature complete, and can\nbe used with other RNNCells, wrappers, and the BasicDecoder.\n\u2026\nOn Tue, Mar 28, 2017 at 6:38 AM, mhnatiuk ***@***.***> wrote:\n Hi,\n @ebrevdo <https://github.com/ebrevdo> Eugene speaks here\n https://www.youtube.com/watch?v=RIR_-Xlbp7s (29:50) about a class\n AttentionDecoder and says it's under development (as of Tensorflow Summit\n date), however I can't find this class anywhere in the master/r1.1/r1.0\n tensorflow code. Do you know when it will be added?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#8775>, or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim5clNyjhcV_TYgzOpSy_HbQhRMTeks5rqQ1hgaJpZM4MrogY>\n .", "body": "We need to update that video somehow.  It turns out it's cleaner to\nimplement attention as an RNNCell wrapper rather than decoder.  This way it\ncan be combined with other decoders easily.  See tensorflow master branch,\ntf.contrib.seq2seq.AttentionWrapper.  It's pretty feature complete, and can\nbe used with other RNNCells, wrappers, and the BasicDecoder.\n\nOn Tue, Mar 28, 2017 at 6:38 AM, mhnatiuk <notifications@github.com> wrote:\n\n> Hi,\n> @ebrevdo <https://github.com/ebrevdo> Eugene speaks here\n> https://www.youtube.com/watch?v=RIR_-Xlbp7s (29:50) about a class\n> AttentionDecoder and says it's under development (as of Tensorflow Summit\n> date), however I can't find this class anywhere in the master/r1.1/r1.0\n> tensorflow code. Do you know when it will be added?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8775>, or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim5clNyjhcV_TYgzOpSy_HbQhRMTeks5rqQ1hgaJpZM4MrogY>\n> .\n>\n"}