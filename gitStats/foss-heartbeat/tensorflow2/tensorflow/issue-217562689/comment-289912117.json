{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/289912117", "html_url": "https://github.com/tensorflow/tensorflow/issues/8775#issuecomment-289912117", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8775", "id": 289912117, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTkxMjExNw==", "user": {"login": "mhnatiuk", "id": 2299492, "node_id": "MDQ6VXNlcjIyOTk0OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2299492?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mhnatiuk", "html_url": "https://github.com/mhnatiuk", "followers_url": "https://api.github.com/users/mhnatiuk/followers", "following_url": "https://api.github.com/users/mhnatiuk/following{/other_user}", "gists_url": "https://api.github.com/users/mhnatiuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/mhnatiuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mhnatiuk/subscriptions", "organizations_url": "https://api.github.com/users/mhnatiuk/orgs", "repos_url": "https://api.github.com/users/mhnatiuk/repos", "events_url": "https://api.github.com/users/mhnatiuk/events{/privacy}", "received_events_url": "https://api.github.com/users/mhnatiuk/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-28T21:35:27Z", "updated_at": "2017-03-29T11:07:15Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> Ok I tired with LSTMBasicCell and got \"state has no attribute attention\" exception.. looks like a bug. I will review and report back.<br>\nThanks for the talk, it was great to suddenly realize that to scale up training to 8 GPUS I only need to use DeviceWrapper. You saved my whole week dude.</p>\n<p>However,<br>\nI am trying to use BasicDecoder like you suggested and I get<br>\n<code>InvalidArgumentError (see above for traceback): assertion failed: [Expected shape for Tensor sequence_length:0 is ] [1] [ but saw shape: ] [64] [[Node: rnn/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn/All/_2029, rnn/Assert/Assert/data_0, rnn/stack/_2031, rnn/Assert/Assert/data_2, rnn/Shape_1/_2033)]] [[Node: rnn/while/Identity_12/_2727 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:5\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4293_rnn/while/Identity_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:5\"](^_clooprnn/while/multi_rnn_cell/cell_5/lstm_cell/zeros/_208)]] </code><br>\nI can't figure it out, sequence_length tensor should be batch-sized and it is and error messege suggests that it should be [1]. This would be a case when a list of Tensors would be used instead of one fat tensor [time, batch_size, 1]</p>\n<p>My target_vocab_size is 500K<br>\nsize of RNN = 64, for testing<br>\ndec_inp : &lt;tf.Tensor 'embedded_inputs_1:0' shape=(100, ?, 64) dtype=float32&gt;<br>\ndecoder seq len is batch-sized (64) &lt;tf.Tensor 'decoder_seq_len:0' shape=(?,) dtype=int32&gt;</p>\n<pre><code>W_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\n\nhalf = tf.constant(0.5)\ndec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\ndec_inp = tf.reshape(dec_inp,[encoder_max_size, -1, size], name = \"embedded_inputs\")\nif not forward_only:\n\t#helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\n\thelper = seq2seq.ScheduledEmbeddingTrainingHelper(inputs = dec_inp,\n\t\t\t\t\t\t\t\t\t\t\t\t\t  sequence_length = self.decoder_seq_len,\n\t\t\t\t\t\t\t\t\t\t\t\t\t embedding = W_target_emb,\n\t\t\t\t\t\t\t\t\t\t\t\t\t sampling_probability = half,\n\t\t\t\t\t\t\t\t\t\t\t\t\t time_major=True)\n\t\nelse:\n\thelper = seq2seq.GreedyEmbeddingHelper(dec_inp, \n\t\t\t\t\t\t\t\t\t\t   start_tokens=self.decoder_inputs[0],\n\t\t\t\t\t\t\t\t\t\t   end_token=data_utils.EOS_ID)\n\t\ndecoder_cell = LSTMBlockCell(num_units=size)\ndecoder_cell = MultiRNNCell([DeviceWrapper(ResidualWrapper(decoder_cell),device=\"/gpu:%d\" % i) for i in range(8) ])\n\nmy_decoder = seq2seq.BasicDecoder(\n\t\tcell=decoder_cell,\n\t\thelper=helper,\n\t\tinitial_state=encoder_final_state)\n\n\ndecoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\n\t\t\t   swap_memory = True)\n</code></pre>", "body_text": "@ebrevdo Ok I tired with LSTMBasicCell and got \"state has no attribute attention\" exception.. looks like a bug. I will review and report back.\nThanks for the talk, it was great to suddenly realize that to scale up training to 8 GPUS I only need to use DeviceWrapper. You saved my whole week dude.\nHowever,\nI am trying to use BasicDecoder like you suggested and I get\nInvalidArgumentError (see above for traceback): assertion failed: [Expected shape for Tensor sequence_length:0 is ] [1] [ but saw shape: ] [64] [[Node: rnn/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn/All/_2029, rnn/Assert/Assert/data_0, rnn/stack/_2031, rnn/Assert/Assert/data_2, rnn/Shape_1/_2033)]] [[Node: rnn/while/Identity_12/_2727 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:5\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4293_rnn/while/Identity_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:5\"](^_clooprnn/while/multi_rnn_cell/cell_5/lstm_cell/zeros/_208)]] \nI can't figure it out, sequence_length tensor should be batch-sized and it is and error messege suggests that it should be [1]. This would be a case when a list of Tensors would be used instead of one fat tensor [time, batch_size, 1]\nMy target_vocab_size is 500K\nsize of RNN = 64, for testing\ndec_inp : <tf.Tensor 'embedded_inputs_1:0' shape=(100, ?, 64) dtype=float32>\ndecoder seq len is batch-sized (64) <tf.Tensor 'decoder_seq_len:0' shape=(?,) dtype=int32>\nW_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\n\nhalf = tf.constant(0.5)\ndec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\ndec_inp = tf.reshape(dec_inp,[encoder_max_size, -1, size], name = \"embedded_inputs\")\nif not forward_only:\n\t#helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\n\thelper = seq2seq.ScheduledEmbeddingTrainingHelper(inputs = dec_inp,\n\t\t\t\t\t\t\t\t\t\t\t\t\t  sequence_length = self.decoder_seq_len,\n\t\t\t\t\t\t\t\t\t\t\t\t\t embedding = W_target_emb,\n\t\t\t\t\t\t\t\t\t\t\t\t\t sampling_probability = half,\n\t\t\t\t\t\t\t\t\t\t\t\t\t time_major=True)\n\t\nelse:\n\thelper = seq2seq.GreedyEmbeddingHelper(dec_inp, \n\t\t\t\t\t\t\t\t\t\t   start_tokens=self.decoder_inputs[0],\n\t\t\t\t\t\t\t\t\t\t   end_token=data_utils.EOS_ID)\n\t\ndecoder_cell = LSTMBlockCell(num_units=size)\ndecoder_cell = MultiRNNCell([DeviceWrapper(ResidualWrapper(decoder_cell),device=\"/gpu:%d\" % i) for i in range(8) ])\n\nmy_decoder = seq2seq.BasicDecoder(\n\t\tcell=decoder_cell,\n\t\thelper=helper,\n\t\tinitial_state=encoder_final_state)\n\n\ndecoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\n\t\t\t   swap_memory = True)", "body": "@ebrevdo Ok I tired with LSTMBasicCell and got \"state has no attribute attention\" exception.. looks like a bug. I will review and report back.\r\nThanks for the talk, it was great to suddenly realize that to scale up training to 8 GPUS I only need to use DeviceWrapper. You saved my whole week dude.\r\n\r\nHowever,\r\nI am trying to use BasicDecoder like you suggested and I get \r\n`InvalidArgumentError (see above for traceback): assertion failed: [Expected shape for Tensor sequence_length:0 is ] [1] [ but saw shape: ] [64]\r\n         [[Node: rnn/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn/All/_2029, rnn/Assert/Assert/data_0, rnn/stack/_2031, rnn/Assert/Assert/data_2, rnn/Shape_1/_2033)]]\r\n         [[Node: rnn/while/Identity_12/_2727 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:5\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4293_rnn/while/Identity_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:5\"](^_clooprnn/while/multi_rnn_cell/cell_5/lstm_cell/zeros/_208)]]\r\n`\r\nI can't figure it out, sequence_length tensor should be batch-sized and it is and error messege suggests that it should be [1]. This would be a case when a list of Tensors would be used instead of one fat tensor [time, batch_size, 1]\r\n\r\nMy target_vocab_size is 500K\r\nsize of RNN = 64, for testing\r\ndec_inp : <tf.Tensor 'embedded_inputs_1:0' shape=(100, ?, 64) dtype=float32>\r\ndecoder seq len is batch-sized (64) <tf.Tensor 'decoder_seq_len:0' shape=(?,) dtype=int32>\r\n\r\n\r\n```\r\nW_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\r\n\r\nhalf = tf.constant(0.5)\r\ndec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\r\ndec_inp = tf.reshape(dec_inp,[encoder_max_size, -1, size], name = \"embedded_inputs\")\r\nif not forward_only:\r\n\t#helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\r\n\thelper = seq2seq.ScheduledEmbeddingTrainingHelper(inputs = dec_inp,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t  sequence_length = self.decoder_seq_len,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t embedding = W_target_emb,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t sampling_probability = half,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t time_major=True)\r\n\t\r\nelse:\r\n\thelper = seq2seq.GreedyEmbeddingHelper(dec_inp, \r\n\t\t\t\t\t\t\t\t\t\t   start_tokens=self.decoder_inputs[0],\r\n\t\t\t\t\t\t\t\t\t\t   end_token=data_utils.EOS_ID)\r\n\t\r\ndecoder_cell = LSTMBlockCell(num_units=size)\r\ndecoder_cell = MultiRNNCell([DeviceWrapper(ResidualWrapper(decoder_cell),device=\"/gpu:%d\" % i) for i in range(8) ])\r\n\r\nmy_decoder = seq2seq.BasicDecoder(\r\n\t\tcell=decoder_cell,\r\n\t\thelper=helper,\r\n\t\tinitial_state=encoder_final_state)\r\n\r\n\r\ndecoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\r\n\t\t\t   swap_memory = True)\r\n```"}