{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/414107227", "html_url": "https://github.com/tensorflow/tensorflow/issues/21710#issuecomment-414107227", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21710", "id": 414107227, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNDEwNzIyNw==", "user": {"login": "OronG13", "id": 41447787, "node_id": "MDQ6VXNlcjQxNDQ3Nzg3", "avatar_url": "https://avatars3.githubusercontent.com/u/41447787?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OronG13", "html_url": "https://github.com/OronG13", "followers_url": "https://api.github.com/users/OronG13/followers", "following_url": "https://api.github.com/users/OronG13/following{/other_user}", "gists_url": "https://api.github.com/users/OronG13/gists{/gist_id}", "starred_url": "https://api.github.com/users/OronG13/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OronG13/subscriptions", "organizations_url": "https://api.github.com/users/OronG13/orgs", "repos_url": "https://api.github.com/users/OronG13/repos", "events_url": "https://api.github.com/users/OronG13/events{/privacy}", "received_events_url": "https://api.github.com/users/OronG13/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-19T06:37:02Z", "updated_at": "2018-08-19T08:17:27Z", "author_association": "NONE", "body_html": "<p><strong>System information</strong><br>\n\u2022Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No<br>\n\u2022OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 Professional SP 1<br>\n\u2022Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No<br>\n\u2022TensorFlow installed from (source or binary): source<br>\n\u2022TensorFlow version (use command below):1.9.0-rc0<br>\n\u2022Python version:3.6<br>\n\u2022Bazel version (if compiling from source):  No<br>\n\u2022GCC/Compiler version (if compiling from source): Visual C++ 14.0 (Visual Studio 2015 x64 Release)<br>\n\u2022CUDA/cuDNN version:  CUDA 9.0/cuDNN 7.2.1 for WIndows 7<br>\n\u2022GPU model and memory: NVIDIA Quadro K2100M<br>\n\u2022Exact command to reproduce:<br>\nI performed the following guide:<br>\n<a href=\"url\">https://medium.com/@shiweili/building-tensorflow-c-shared-library-on-windows-e79c90e23e6e</a><br>\nAlso, I worked according to what I succeeded to get from here:<br>\n<a href=\"url\">https://www.tensorflow.org/install/install_sources</a></p>\n<p><strong>Some of the guide steps was adapted:</strong></p>\n<ol>\n<li>Configuration was changed as described above</li>\n<li>CMake was invoked like this:<br>\nC:\\AAG\\HPC\\Apps\\build&gt;C:\\CMake\\bin\\cmake.exe ..\\tensorflow-master\\tensorflow\\con<br>\ntrib\\cmake -DCMAKE_BUILD_TYPE=Release -Dtensorflow_ENABLE_GPU=ON -Dtensorflow_BU<br>\nILD_PYTHON_BINDINGS=OFF -Dtensorflow_ENABLE_GRPC_SUPPORT=ON -Deigan_PATCH_FILE=O<br>\nN -Dtensorflow_BUILD_PYTHON_TESTS=OFF -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AV<br>\nX -Dtensorflow_BUILD_SHARED_LIB=ON -DCUDA_TOOLKIT_ROOT_DIR=\"C:/Program Files/NVI<br>\nDIA GPU Computing Toolkit/CUDA/v9.0\" -DCUDNN_HOME=\"C:/Program Files/NVIDIA GPU C<br>\nomputing Toolkit/CUDA/v9.0\" -G\"Visual Studio 14 2015 Win64\"</li>\n<li>Build was invoked like this:<br>\nC:\\AAG\\HPC\\Apps\\build&gt;\"C:\\Program Files (x86)\\MSBuild\\14.0\\Bin\\MSbuild.exe\" /m:1<br>\n/p:CL_MPCount=1 /p:Configuration=Release /p:Platform=x64 /p:PreferredToolArchit<br>\necture=x64 All_BUILD.vcxproj</li>\n</ol>\n<p><strong>Problem description:</strong><br>\nI made an application via Visual Studio 2015 which was linked with all Tensorflow libraries under the x64 platform and  Release configuration.</p>\n<p>I succeeded to load and run the lenet5_mnist_frozen.pb file while using the default device (CPU).<br>\nI got the expected results as described in the TensorRT-Developer-Guide document.</p>\n<p>This is the code for loading the pb file and Session creation:</p>\n<pre><code>boost::filesystem::path m_filePath;\ntensorflow::Session *m_session;\ntensorflow::GraphDef m_graphDef;\n\nReadBinaryProto(tensorflow::Env::Default(), m_filePath.string(), &amp;m_graphDef);\t\ntensorflow::SessionOptions options;\ntensorflow::NewSession(tensorflow::SessionOptions(options), &amp;m_session);\nm_session-&gt;Create(m_graphDef);\n\n</code></pre>\n<p><strong>Of course</strong>, tensor input and tensor output were declared according to the examples provided in the  stock example script provided in TensorFlow and according to the lenet5_mnist_frozen.pb definitions.</p>\n<p><strong>If the entire code will be required I will provide it.</strong></p>\n<p>After that, I wanted to change the device to the GPU without any further change.<br>\nSo, I tried to separately add a call to any one of these options:<br>\ntensorflow::graph::SetDefaultDevice(\"/gpu:0\", &amp;graph_def);<br>\ntensorflow::graph::SetDefaultDevice(\"/device:GPU:0\", &amp;graph_def);</p>\n<p>But then the Session run started to return <strong>an error that the key wasn't found</strong>.</p>\n<p>So I added the following:<br>\n`std::vectortensorflow::DeviceAttributes listDevices;<br>\nm_session-&gt;ListDevices(&amp;listDevices);</p>\n<p>std::cout &lt;&lt; \"TF identified devices list:\" &lt;&lt; std::endl;<br>\nfor (auto&amp; tVal : listDevices)<br>\n{<br>\nstd::cout &lt;&lt; tVal.DebugString() &lt;&lt; std::endl;<br>\n}`</p>\n<p>And I saw that the tensorflow::Session ListDevices function only returns this value:<br>\n\"/job:localhost/replica:0/task:0/device:CPU:0\"</p>\n<p>While activating this Python code with Tensorflow 1.10:<br>\n`import tensorflow as tf</p>\n<p>print(tf.<strong>version</strong>)</p>\n<h1>Creates a graph.</h1>\n<p>a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')<br>\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')<br>\nc = tf.matmul(a, b)</p>\n<h1>Creates a session with log_device_placement set to True.</h1>\n<p>sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</p>\n<h1>Runs the op.</h1>\n<p>print(sess.run(c))`</p>\n<p>I'm getting the following prints:<br>\n1.10.0<br>\n2018-08-19 10:26:06.096006: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2<br>\n2018-08-19 10:26:06.432040: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1405] Found device 0 with properties:<br>\n<strong>name: Quadro K2100M major: 3 minor: 0 memoryClockRate(GHz): 0.6665</strong><br>\npciBusID: 0000:01:00.0<br>\ntotalMemory: 2.00GiB freeMemory: 1.86GiB<br>\n2018-08-19 10:26:06.433040: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1484] Adding visible gpu devices: 0<br>\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:<br>\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971]      0<br>\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:984] 0:   N<br>\n2018-08-19 10:26:07.616158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1636 MB memory) -&gt; physical GPU (device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0)<br>\nDevice mapping:<br>\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0<br>\n2018-08-19 10:26:07.832180: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\direct_session.cc:288] Device mapping:<br>\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0</p>\n<p>2018-08-19 10:26:15.257922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] MatMul: (MatMul)/job:localhost/replica:0/task:0/device:GPU:0<br>\n2018-08-19 10:26:15.257922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] a: (Const)/job:localhost/replica:0/task:0/device:GPU:0<br>\n2018-08-19 10:26:15.258922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] b: (Const)/job:localhost/replica:0/task:0/device:GPU:0<br>\nMatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0<br>\na: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\nb: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\n[[22. 28.]<br>\n[49. 64.]]</p>\n<p><strong>Question:</strong><br>\nGiven that my GPU is active and is recognized by the Python script, what should I do in order for the tensorflow::Session in C++ to run on my GPU as well?</p>", "body_text": "System information\n\u2022Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\n\u2022OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 Professional SP 1\n\u2022Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\n\u2022TensorFlow installed from (source or binary): source\n\u2022TensorFlow version (use command below):1.9.0-rc0\n\u2022Python version:3.6\n\u2022Bazel version (if compiling from source):  No\n\u2022GCC/Compiler version (if compiling from source): Visual C++ 14.0 (Visual Studio 2015 x64 Release)\n\u2022CUDA/cuDNN version:  CUDA 9.0/cuDNN 7.2.1 for WIndows 7\n\u2022GPU model and memory: NVIDIA Quadro K2100M\n\u2022Exact command to reproduce:\nI performed the following guide:\nhttps://medium.com/@shiweili/building-tensorflow-c-shared-library-on-windows-e79c90e23e6e\nAlso, I worked according to what I succeeded to get from here:\nhttps://www.tensorflow.org/install/install_sources\nSome of the guide steps was adapted:\n\nConfiguration was changed as described above\nCMake was invoked like this:\nC:\\AAG\\HPC\\Apps\\build>C:\\CMake\\bin\\cmake.exe ..\\tensorflow-master\\tensorflow\\con\ntrib\\cmake -DCMAKE_BUILD_TYPE=Release -Dtensorflow_ENABLE_GPU=ON -Dtensorflow_BU\nILD_PYTHON_BINDINGS=OFF -Dtensorflow_ENABLE_GRPC_SUPPORT=ON -Deigan_PATCH_FILE=O\nN -Dtensorflow_BUILD_PYTHON_TESTS=OFF -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AV\nX -Dtensorflow_BUILD_SHARED_LIB=ON -DCUDA_TOOLKIT_ROOT_DIR=\"C:/Program Files/NVI\nDIA GPU Computing Toolkit/CUDA/v9.0\" -DCUDNN_HOME=\"C:/Program Files/NVIDIA GPU C\nomputing Toolkit/CUDA/v9.0\" -G\"Visual Studio 14 2015 Win64\"\nBuild was invoked like this:\nC:\\AAG\\HPC\\Apps\\build>\"C:\\Program Files (x86)\\MSBuild\\14.0\\Bin\\MSbuild.exe\" /m:1\n/p:CL_MPCount=1 /p:Configuration=Release /p:Platform=x64 /p:PreferredToolArchit\necture=x64 All_BUILD.vcxproj\n\nProblem description:\nI made an application via Visual Studio 2015 which was linked with all Tensorflow libraries under the x64 platform and  Release configuration.\nI succeeded to load and run the lenet5_mnist_frozen.pb file while using the default device (CPU).\nI got the expected results as described in the TensorRT-Developer-Guide document.\nThis is the code for loading the pb file and Session creation:\nboost::filesystem::path m_filePath;\ntensorflow::Session *m_session;\ntensorflow::GraphDef m_graphDef;\n\nReadBinaryProto(tensorflow::Env::Default(), m_filePath.string(), &m_graphDef);\t\ntensorflow::SessionOptions options;\ntensorflow::NewSession(tensorflow::SessionOptions(options), &m_session);\nm_session->Create(m_graphDef);\n\n\nOf course, tensor input and tensor output were declared according to the examples provided in the  stock example script provided in TensorFlow and according to the lenet5_mnist_frozen.pb definitions.\nIf the entire code will be required I will provide it.\nAfter that, I wanted to change the device to the GPU without any further change.\nSo, I tried to separately add a call to any one of these options:\ntensorflow::graph::SetDefaultDevice(\"/gpu:0\", &graph_def);\ntensorflow::graph::SetDefaultDevice(\"/device:GPU:0\", &graph_def);\nBut then the Session run started to return an error that the key wasn't found.\nSo I added the following:\n`std::vectortensorflow::DeviceAttributes listDevices;\nm_session->ListDevices(&listDevices);\nstd::cout << \"TF identified devices list:\" << std::endl;\nfor (auto& tVal : listDevices)\n{\nstd::cout << tVal.DebugString() << std::endl;\n}`\nAnd I saw that the tensorflow::Session ListDevices function only returns this value:\n\"/job:localhost/replica:0/task:0/device:CPU:0\"\nWhile activating this Python code with Tensorflow 1.10:\n`import tensorflow as tf\nprint(tf.version)\nCreates a graph.\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\nCreates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\nRuns the op.\nprint(sess.run(c))`\nI'm getting the following prints:\n1.10.0\n2018-08-19 10:26:06.096006: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2018-08-19 10:26:06.432040: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1405] Found device 0 with properties:\nname: Quadro K2100M major: 3 minor: 0 memoryClockRate(GHz): 0.6665\npciBusID: 0000:01:00.0\ntotalMemory: 2.00GiB freeMemory: 1.86GiB\n2018-08-19 10:26:06.433040: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971]      0\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:984] 0:   N\n2018-08-19 10:26:07.616158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1636 MB memory) -> physical GPU (device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0\n2018-08-19 10:26:07.832180: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\direct_session.cc:288] Device mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0\n2018-08-19 10:26:15.257922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] MatMul: (MatMul)/job:localhost/replica:0/task:0/device:GPU:0\n2018-08-19 10:26:15.257922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] a: (Const)/job:localhost/replica:0/task:0/device:GPU:0\n2018-08-19 10:26:15.258922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] b: (Const)/job:localhost/replica:0/task:0/device:GPU:0\nMatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\na: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nb: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n[[22. 28.]\n[49. 64.]]\nQuestion:\nGiven that my GPU is active and is recognized by the Python script, what should I do in order for the tensorflow::Session in C++ to run on my GPU as well?", "body": "**System information**\r\n\u2022Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\r\n\u2022OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 Professional SP 1\r\n\u2022Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\r\n\u2022TensorFlow installed from (source or binary): source\r\n\u2022TensorFlow version (use command below):1.9.0-rc0\r\n\u2022Python version:3.6\r\n\u2022Bazel version (if compiling from source):  No\r\n\u2022GCC/Compiler version (if compiling from source): Visual C++ 14.0 (Visual Studio 2015 x64 Release)\r\n\u2022CUDA/cuDNN version:  CUDA 9.0/cuDNN 7.2.1 for WIndows 7\r\n\u2022GPU model and memory: NVIDIA Quadro K2100M\r\n\u2022Exact command to reproduce:\r\nI performed the following guide:\r\n[https://medium.com/@shiweili/building-tensorflow-c-shared-library-on-windows-e79c90e23e6e](url)\r\nAlso, I worked according to what I succeeded to get from here:\r\n[https://www.tensorflow.org/install/install_sources](url)\r\n\r\n**Some of the guide steps was adapted:**\r\n1. Configuration was changed as described above\r\n2. CMake was invoked like this:\r\nC:\\AAG\\HPC\\Apps\\build>C:\\CMake\\bin\\cmake.exe ..\\tensorflow-master\\tensorflow\\con\r\ntrib\\cmake -DCMAKE_BUILD_TYPE=Release -Dtensorflow_ENABLE_GPU=ON -Dtensorflow_BU\r\nILD_PYTHON_BINDINGS=OFF -Dtensorflow_ENABLE_GRPC_SUPPORT=ON -Deigan_PATCH_FILE=O\r\nN -Dtensorflow_BUILD_PYTHON_TESTS=OFF -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AV\r\nX -Dtensorflow_BUILD_SHARED_LIB=ON -DCUDA_TOOLKIT_ROOT_DIR=\"C:/Program Files/NVI\r\nDIA GPU Computing Toolkit/CUDA/v9.0\" -DCUDNN_HOME=\"C:/Program Files/NVIDIA GPU C\r\nomputing Toolkit/CUDA/v9.0\" -G\"Visual Studio 14 2015 Win64\"\r\n3. Build was invoked like this:\r\nC:\\AAG\\HPC\\Apps\\build>\"C:\\Program Files (x86)\\MSBuild\\14.0\\Bin\\MSbuild.exe\" /m:1\r\n /p:CL_MPCount=1 /p:Configuration=Release /p:Platform=x64 /p:PreferredToolArchit\r\necture=x64 All_BUILD.vcxproj\r\n\r\n**Problem description:**\r\nI made an application via Visual Studio 2015 which was linked with all Tensorflow libraries under the x64 platform and  Release configuration.\r\n\r\nI succeeded to load and run the lenet5_mnist_frozen.pb file while using the default device (CPU).\r\nI got the expected results as described in the TensorRT-Developer-Guide document.\r\n\r\nThis is the code for loading the pb file and Session creation:\r\n```\r\nboost::filesystem::path m_filePath;\r\ntensorflow::Session *m_session;\r\ntensorflow::GraphDef m_graphDef;\r\n\r\nReadBinaryProto(tensorflow::Env::Default(), m_filePath.string(), &m_graphDef);\t\r\ntensorflow::SessionOptions options;\r\ntensorflow::NewSession(tensorflow::SessionOptions(options), &m_session);\r\nm_session->Create(m_graphDef);\r\n\r\n```\r\n**Of course**, tensor input and tensor output were declared according to the examples provided in the  stock example script provided in TensorFlow and according to the lenet5_mnist_frozen.pb definitions.\r\n\r\n**If the entire code will be required I will provide it.**\r\n\r\nAfter that, I wanted to change the device to the GPU without any further change.\r\n So, I tried to separately add a call to any one of these options:\r\ntensorflow::graph::SetDefaultDevice(\"/gpu:0\", &graph_def);\r\ntensorflow::graph::SetDefaultDevice(\"/device:GPU:0\", &graph_def);\r\n\r\nBut then the Session run started to return **an error that the key wasn't found**.\r\n\r\nSo I added the following:\r\n`std::vector<tensorflow::DeviceAttributes> listDevices;\r\nm_session->ListDevices(&listDevices);\r\n\r\nstd::cout << \"TF identified devices list:\" << std::endl;\r\nfor (auto& tVal : listDevices)\r\n{\r\n\tstd::cout << tVal.DebugString() << std::endl;\r\n}`\r\n\r\nAnd I saw that the tensorflow::Session ListDevices function only returns this value:\r\n\"/job:localhost/replica:0/task:0/device:CPU:0\"\r\n\r\nWhile activating this Python code with Tensorflow 1.10:\r\n`import tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\n# Creates a graph.\r\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\n# Creates a session with log_device_placement set to True.\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n# Runs the op.\r\nprint(sess.run(c))`\r\n\r\nI'm getting the following prints:\r\n1.10.0\r\n2018-08-19 10:26:06.096006: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-08-19 10:26:06.432040: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1405] Found device 0 with properties: \r\n**name: Quadro K2100M major: 3 minor: 0 memoryClockRate(GHz): 0.6665**\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 2.00GiB freeMemory: 1.86GiB\r\n2018-08-19 10:26:06.433040: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971]      0 \r\n2018-08-19 10:26:07.615158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:984] 0:   N \r\n2018-08-19 10:26:07.616158: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1636 MB memory) -> physical GPU (device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0\r\n2018-08-19 10:26:07.832180: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\direct_session.cc:288] Device mapping:\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro K2100M, pci bus id: 0000:01:00.0, compute capability: 3.0\r\n\r\n2018-08-19 10:26:15.257922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] MatMul: (MatMul)/job:localhost/replica:0/task:0/device:GPU:0\r\n2018-08-19 10:26:15.257922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] a: (Const)/job:localhost/replica:0/task:0/device:GPU:0\r\n2018-08-19 10:26:15.258922: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\placer.cc:935] b: (Const)/job:localhost/replica:0/task:0/device:GPU:0\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\r\na: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\nb: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\n[[22. 28.]\r\n [49. 64.]]\r\n\r\n**Question:**\r\nGiven that my GPU is active and is recognized by the Python script, what should I do in order for the tensorflow::Session in C++ to run on my GPU as well?\r\n"}