{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/217992066", "html_url": "https://github.com/tensorflow/tensorflow/issues/2296#issuecomment-217992066", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2296", "id": 217992066, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNzk5MjA2Ng==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-09T21:14:50Z", "updated_at": "2016-05-09T21:15:43Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If you had something like 1B images, then you could train for one epoch<br>\nsince another epoch would be 2x longer but a only small improvement in accuracy<br>\nBut for 600k you probably will need several passes to get convergence (a<br>\nfew dozen epochs at batch size 32 maybe?). I don't remember the details off<br>\nthe top of my head, but ImageNet papers should talk about how many epochs<br>\nthey used</p>\n<p>On Mon, May 9, 2016 at 2:06 PM, oren weingrod <a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\nwrote:</p>\n<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> <a href=\"https://github.com/yaroslavvb\">https://github.com/yaroslavvb</a> Interesting. Another<br>\nquestion\u2014albeit a stupid one\u2014should the number of training steps reflect<br>\nthe number of images 1-1? As in, 600k images, 600k training steps?</p>\n<p>\u2014<br>\nYou are receiving this because you were mentioned.<br>\nReply to this email directly or view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"153849607\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2296\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2296/hovercard?comment_id=217989795&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/2296#issuecomment-217989795\">#2296 (comment)</a></p>\n</blockquote>", "body_text": "If you had something like 1B images, then you could train for one epoch\nsince another epoch would be 2x longer but a only small improvement in accuracy\nBut for 600k you probably will need several passes to get convergence (a\nfew dozen epochs at batch size 32 maybe?). I don't remember the details off\nthe top of my head, but ImageNet papers should talk about how many epochs\nthey used\nOn Mon, May 9, 2016 at 2:06 PM, oren weingrod notifications@github.com\nwrote:\n\n@yaroslavvb https://github.com/yaroslavvb Interesting. Another\nquestion\u2014albeit a stupid one\u2014should the number of training steps reflect\nthe number of images 1-1? As in, 600k images, 600k training steps?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n#2296 (comment)", "body": "If you had something like 1B images, then you could train for one epoch\nsince another epoch would be 2x longer but a only small improvement in accuracy\nBut for 600k you probably will need several passes to get convergence (a\nfew dozen epochs at batch size 32 maybe?). I don't remember the details off\nthe top of my head, but ImageNet papers should talk about how many epochs\nthey used\n\nOn Mon, May 9, 2016 at 2:06 PM, oren weingrod notifications@github.com\nwrote:\n\n> @yaroslavvb https://github.com/yaroslavvb Interesting. Another\n> question\u2014albeit a stupid one\u2014should the number of training steps reflect\n> the number of images 1-1? As in, 600k images, 600k training steps?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2296#issuecomment-217989795\n"}