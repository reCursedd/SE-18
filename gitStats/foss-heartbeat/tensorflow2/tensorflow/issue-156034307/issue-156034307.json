{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2444", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2444/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2444/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2444/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2444", "id": 156034307, "node_id": "MDU6SXNzdWUxNTYwMzQzMDc=", "number": 2444, "title": "Reinforcement Learning can be really, really slow in tensorflow.", "user": {"login": "scroyston", "id": 620227, "node_id": "MDQ6VXNlcjYyMDIyNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/620227?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scroyston", "html_url": "https://github.com/scroyston", "followers_url": "https://api.github.com/users/scroyston/followers", "following_url": "https://api.github.com/users/scroyston/following{/other_user}", "gists_url": "https://api.github.com/users/scroyston/gists{/gist_id}", "starred_url": "https://api.github.com/users/scroyston/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scroyston/subscriptions", "organizations_url": "https://api.github.com/users/scroyston/orgs", "repos_url": "https://api.github.com/users/scroyston/repos", "events_url": "https://api.github.com/users/scroyston/events{/privacy}", "received_events_url": "https://api.github.com/users/scroyston/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2016-05-20T19:26:08Z", "updated_at": "2017-06-16T16:54:08Z", "closed_at": "2017-06-16T16:54:08Z", "author_association": "NONE", "body_html": "<p>I was looking at applying DeepMind's <a href=\"http://arxiv.org/pdf/1509.02971.pdf\" rel=\"nofollow\">DDPG algorithm</a> to the new OpenAI gym problem set, focusing on continuous control problems like: <a href=\"https://gym.openai.com/evaluations/eval_I3x3s4DuS7CmIbpaTCs51w\" rel=\"nofollow\">the pendulum</a></p>\n<p>I noticed that a TensorFlow version of the algorithm was running about 10-20x slower than a theano version of the same algorithm.</p>\n<p><a href=\"https://github.com/nivwusquorum/tensorflow-deepq/blob/continuous/tf_rl/controller/continuous_deepq.py\">Tensorflow implementation</a>  (but with a couple bugs fixed)<br>\n<a href=\"https://github.com/scroyston/rllab/blob/master/rllab/algos/ddpg.py\">Theano implementation</a></p>\n<p>When I started profiling both implementations in detail, I noticed there were huge performance difference even when just comparing the forward pass of the actor neural network.</p>\n<p>I built a quick script to just compare a forward pass of a layered net, varying the layer depth and layer breadth (code and results below), and using a \"mini batch\" size of 64.  (For reference, in Deepmind's DDPG paper, they used a network of 2 hidden layers, sized 400 and 300, mini batch size of 64).<br>\nUsing the handy tf.RunOptions.FULL_TRACE, it showed 99% of the cost was in running the ops themselves (vs op scheduling, startup time, etc).</p>\n<p>I then stumbled on a couple of settings that seemed to help:<br>\nconfig_proto.intra_op_parallelism_threads = 1<br>\nconfig_proto.inter_op_parallelism_threads = 1</p>\n<p>That seemed to improve things a bunch, to where tensorflow was as fast in a couple instances, or \"only\" 2-3x slower.</p>\n<p>Before finding the threading flags, I started looking at speeding up the individual ops. In MatMulOp I replaced the eigen matrix multiply call with a blas call.  That also seemed to help quite a bit.</p>\n<p>Below are some chart of the performance delta vs Theano.<br>\n\"EigenMultiThread\" is just vanilla tensorflow.<br>\n\"EigenSingleThread\" is tensorflow with intra/inter op_parallelism = 1.<br>\n\"BlasSingleThread is the same as \"EigenSingleThread\", with the eigen matrix multiply replaced by blas.<br>\nThe data that makes up these charts can be <a href=\"https://docs.google.com/a/rgmadvisors.com/spreadsheets/d/1EU9xPFUqELDpRnFUOJUKCDNjm977sUC7AAM29iCwfgc/pubhtml\" rel=\"nofollow\">found here</a>.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/620227/15438353/62156fc2-1e91-11e6-9b22-5c7cf04aef91.png\"><img src=\"https://cloud.githubusercontent.com/assets/620227/15438353/62156fc2-1e91-11e6-9b22-5c7cf04aef91.png\" alt=\"depth2\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/620227/15438368/795d2698-1e91-11e6-979e-ea341f5d6720.png\"><img src=\"https://cloud.githubusercontent.com/assets/620227/15438368/795d2698-1e91-11e6-979e-ea341f5d6720.png\" alt=\"depth4\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/620227/15438371/7d03b064-1e91-11e6-9589-33ccf83b926f.png\"><img src=\"https://cloud.githubusercontent.com/assets/620227/15438371/7d03b064-1e91-11e6-9589-33ccf83b926f.png\" alt=\"depth6\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/620227/15438374/80979718-1e91-11e6-8f88-ecdfeff44fef.png\"><img src=\"https://cloud.githubusercontent.com/assets/620227/15438374/80979718-1e91-11e6-8f88-ecdfeff44fef.png\" alt=\"depth8\" style=\"max-width:100%;\"></a></p>\n<p>I primarily ran these tests on a mac pro (with avx).  I did compile tensorflow with the avx flag.  I also spot checked these results on a linux box and got similar results.  Blas implementation was OpenBlas</p>\n<p>I guess my issue/question is: Is there any ongoing work to improve performance for Reinforcement Learning scenarios like these, especially on CPUs?</p>\n<p>I have heard DeepMind is moving completely to tensorflow, and they used/are using the new TPU chips. However, they also got a huge performance boost in runtime and error rate over GPUs by <a href=\"http://arxiv.org/pdf/1602.01783v1.pdf\" rel=\"nofollow\">using 16 normal cores asynchronously</a> (which btw, I don't think I can set the threading options to 1 and have an <a href=\"https://github.com/muupan/async-rl\">implementation</a> still work).</p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nOS X 10.11.4,  3.5 GHz 6-Core Intel Xeon E5<br>\nand<br>\nFedora 20, 12 physical cores, Xeon X5670  @ 2.93GHz</p>\n<p>Installed version of CUDA and cuDNN:<br>\nNone</p>\n<p>If installed from binary pip package, provide:<br>\nTried both a release version:<br>\npip install --upgrade <a href=\"https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl</a></p>\n<p>and from source, commit hash:<br>\n371d341c7ef22d38b80235bbcb5a6e230546781c<br>\ncompile command:<br>\nbazel build -c opt --copt=-mavx //tensorflow/tools/pip_package:build_pip_package<br>\n(for the Xeon E5 machine)</p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>I used the script below to generate the numbers<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/275280/tf_perf_test.py.zip\">tf_perf_test.py.zip</a></li>\n</ol>", "body_text": "I was looking at applying DeepMind's DDPG algorithm to the new OpenAI gym problem set, focusing on continuous control problems like: the pendulum\nI noticed that a TensorFlow version of the algorithm was running about 10-20x slower than a theano version of the same algorithm.\nTensorflow implementation  (but with a couple bugs fixed)\nTheano implementation\nWhen I started profiling both implementations in detail, I noticed there were huge performance difference even when just comparing the forward pass of the actor neural network.\nI built a quick script to just compare a forward pass of a layered net, varying the layer depth and layer breadth (code and results below), and using a \"mini batch\" size of 64.  (For reference, in Deepmind's DDPG paper, they used a network of 2 hidden layers, sized 400 and 300, mini batch size of 64).\nUsing the handy tf.RunOptions.FULL_TRACE, it showed 99% of the cost was in running the ops themselves (vs op scheduling, startup time, etc).\nI then stumbled on a couple of settings that seemed to help:\nconfig_proto.intra_op_parallelism_threads = 1\nconfig_proto.inter_op_parallelism_threads = 1\nThat seemed to improve things a bunch, to where tensorflow was as fast in a couple instances, or \"only\" 2-3x slower.\nBefore finding the threading flags, I started looking at speeding up the individual ops. In MatMulOp I replaced the eigen matrix multiply call with a blas call.  That also seemed to help quite a bit.\nBelow are some chart of the performance delta vs Theano.\n\"EigenMultiThread\" is just vanilla tensorflow.\n\"EigenSingleThread\" is tensorflow with intra/inter op_parallelism = 1.\n\"BlasSingleThread is the same as \"EigenSingleThread\", with the eigen matrix multiply replaced by blas.\nThe data that makes up these charts can be found here.\n\n\n\n\nI primarily ran these tests on a mac pro (with avx).  I did compile tensorflow with the avx flag.  I also spot checked these results on a linux box and got similar results.  Blas implementation was OpenBlas\nI guess my issue/question is: Is there any ongoing work to improve performance for Reinforcement Learning scenarios like these, especially on CPUs?\nI have heard DeepMind is moving completely to tensorflow, and they used/are using the new TPU chips. However, they also got a huge performance boost in runtime and error rate over GPUs by using 16 normal cores asynchronously (which btw, I don't think I can set the threading options to 1 and have an implementation still work).\nEnvironment info\nOperating System:\nOS X 10.11.4,  3.5 GHz 6-Core Intel Xeon E5\nand\nFedora 20, 12 physical cores, Xeon X5670  @ 2.93GHz\nInstalled version of CUDA and cuDNN:\nNone\nIf installed from binary pip package, provide:\nTried both a release version:\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl\nand from source, commit hash:\n371d341c7ef22d38b80235bbcb5a6e230546781c\ncompile command:\nbazel build -c opt --copt=-mavx //tensorflow/tools/pip_package:build_pip_package\n(for the Xeon E5 machine)\nSteps to reproduce\n\nI used the script below to generate the numbers\ntf_perf_test.py.zip", "body": "I was looking at applying DeepMind's [DDPG algorithm](http://arxiv.org/pdf/1509.02971.pdf) to the new OpenAI gym problem set, focusing on continuous control problems like: [the pendulum](https://gym.openai.com/evaluations/eval_I3x3s4DuS7CmIbpaTCs51w)\n\nI noticed that a TensorFlow version of the algorithm was running about 10-20x slower than a theano version of the same algorithm.\n\n[Tensorflow implementation](https://github.com/nivwusquorum/tensorflow-deepq/blob/continuous/tf_rl/controller/continuous_deepq.py)  (but with a couple bugs fixed)\n[Theano implementation](https://github.com/scroyston/rllab/blob/master/rllab/algos/ddpg.py)\n\nWhen I started profiling both implementations in detail, I noticed there were huge performance difference even when just comparing the forward pass of the actor neural network.\n\nI built a quick script to just compare a forward pass of a layered net, varying the layer depth and layer breadth (code and results below), and using a \"mini batch\" size of 64.  (For reference, in Deepmind's DDPG paper, they used a network of 2 hidden layers, sized 400 and 300, mini batch size of 64).\nUsing the handy tf.RunOptions.FULL_TRACE, it showed 99% of the cost was in running the ops themselves (vs op scheduling, startup time, etc).\n\nI then stumbled on a couple of settings that seemed to help:\n    config_proto.intra_op_parallelism_threads = 1\n    config_proto.inter_op_parallelism_threads = 1\n\nThat seemed to improve things a bunch, to where tensorflow was as fast in a couple instances, or \"only\" 2-3x slower.\n\nBefore finding the threading flags, I started looking at speeding up the individual ops. In MatMulOp I replaced the eigen matrix multiply call with a blas call.  That also seemed to help quite a bit.\n\nBelow are some chart of the performance delta vs Theano.\n\"EigenMultiThread\" is just vanilla tensorflow. \n\"EigenSingleThread\" is tensorflow with intra/inter op_parallelism = 1. \n\"BlasSingleThread is the same as \"EigenSingleThread\", with the eigen matrix multiply replaced by blas.\nThe data that makes up these charts can be [found here](https://docs.google.com/a/rgmadvisors.com/spreadsheets/d/1EU9xPFUqELDpRnFUOJUKCDNjm977sUC7AAM29iCwfgc/pubhtml).\n\n![depth2](https://cloud.githubusercontent.com/assets/620227/15438353/62156fc2-1e91-11e6-9b22-5c7cf04aef91.png)\n![depth4](https://cloud.githubusercontent.com/assets/620227/15438368/795d2698-1e91-11e6-979e-ea341f5d6720.png)\n![depth6](https://cloud.githubusercontent.com/assets/620227/15438371/7d03b064-1e91-11e6-9589-33ccf83b926f.png)\n![depth8](https://cloud.githubusercontent.com/assets/620227/15438374/80979718-1e91-11e6-8f88-ecdfeff44fef.png)\n\nI primarily ran these tests on a mac pro (with avx).  I did compile tensorflow with the avx flag.  I also spot checked these results on a linux box and got similar results.  Blas implementation was OpenBlas\n\nI guess my issue/question is: Is there any ongoing work to improve performance for Reinforcement Learning scenarios like these, especially on CPUs? \n\nI have heard DeepMind is moving completely to tensorflow, and they used/are using the new TPU chips. However, they also got a huge performance boost in runtime and error rate over GPUs by [using 16 normal cores asynchronously](http://arxiv.org/pdf/1602.01783v1.pdf) (which btw, I don't think I can set the threading options to 1 and have an [implementation](https://github.com/muupan/async-rl) still work).\n### Environment info\n\nOperating System: \nOS X 10.11.4,  3.5 GHz 6-Core Intel Xeon E5\nand\nFedora 20, 12 physical cores, Xeon X5670  @ 2.93GHz\n\nInstalled version of CUDA and cuDNN: \nNone\n\nIf installed from binary pip package, provide:\nTried both a release version:\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl\n\nand from source, commit hash:\n371d341c7ef22d38b80235bbcb5a6e230546781c\ncompile command:\nbazel build -c opt --copt=-mavx //tensorflow/tools/pip_package:build_pip_package\n(for the Xeon E5 machine)\n### Steps to reproduce\n1. I used the script below to generate the numbers\n   [tf_perf_test.py.zip](https://github.com/tensorflow/tensorflow/files/275280/tf_perf_test.py.zip)\n"}