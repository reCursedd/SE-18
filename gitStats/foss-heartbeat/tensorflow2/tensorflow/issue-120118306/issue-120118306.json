{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/398", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/398/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/398/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/398/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/398", "id": 120118306, "node_id": "MDU6SXNzdWUxMjAxMTgzMDY=", "number": 398, "title": "GPU ran-out-of-memory problem", "user": {"login": "zhangchen-qinyinghua", "id": 5279087, "node_id": "MDQ6VXNlcjUyNzkwODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5279087?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangchen-qinyinghua", "html_url": "https://github.com/zhangchen-qinyinghua", "followers_url": "https://api.github.com/users/zhangchen-qinyinghua/followers", "following_url": "https://api.github.com/users/zhangchen-qinyinghua/following{/other_user}", "gists_url": "https://api.github.com/users/zhangchen-qinyinghua/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangchen-qinyinghua/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangchen-qinyinghua/subscriptions", "organizations_url": "https://api.github.com/users/zhangchen-qinyinghua/orgs", "repos_url": "https://api.github.com/users/zhangchen-qinyinghua/repos", "events_url": "https://api.github.com/users/zhangchen-qinyinghua/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangchen-qinyinghua/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2015-12-03T08:36:48Z", "updated_at": "2018-03-06T07:53:56Z", "closed_at": "2015-12-15T01:00:14Z", "author_association": "NONE", "body_html": "<p>I've got a GPU ran-out-of-memory problem.</p>\n<p>My single GPU Card has about 11GB memory. As the nvidia-smi shows below:</p>\n<h2>N/A   48C    P0   129W / 235W |  10985MiB / 11519MiB |     99%      Default</h2>\n<p>I define a big CNN models, it is like this:</p>\n<h2>My CNN Models Start...</h2>\n<p>Layer 1.<br>\ninput: one batch 35 pics, with 1024x1024x3:<br>\n(35,1024,1024,3)</p>\n<p>Layer 2.<br>\n2D conv-layer and 2D max-pool layer:<br>\nconv-kernel (3,3,3), 16 feature maps, stride=1, and using \"SAME\" padding,<br>\nmax-pool-kernel (2,2), stride=2, so the output should be<br>\n(35,512,512,16)<br>\nand the parameters of the layer should be:<br>\nW: 3x3x3x16+b: 16=448</p>\n<p>Layer3, 4, 5, 6:<br>\nThe same as Layer2, 2D Conv and 2D Max Pool,<br>\nconv-kernel (3,3,16), 16 feature maps, stride=1, and using \"SAME\" padding,<br>\nmax-pool-kernel (2,2), strides=2,<br>\nthe output of the layers is:<br>\n(35,256,256,16)<br>\n(35,128,128,16)<br>\n(35,64,64,16)<br>\n(35,32,32,16)<br>\nThe total parameters is:<br>\n4x(3x3x16x16)+4x16=9280</p>\n<p>Layer7:<br>\ndense layer with 2048 hidden nodes,<br>\nthe parameters:<br>\n32x32x16x2048+2048=33556480</p>\n<p>Layer8:<br>\ndense layer with 600 hidden nodes,<br>\nthe parameters:<br>\n600x2048+600=1229400</p>\n<h2>END.</h2>\n<p>So all together, the model has 448+9280+33556480+1229400=34795608 float32 parameters, it is  34795608x4/1024/1024=132MB parameters.</p>\n<p>Maybe I should also add the memory cost by the outputs, so it is<br>\n(35x1024x1024x3)+(35x512x512x16)+(35x256x256x16)+(35x128x128x16)+(35x64x64x16)+(35x32x32x16)=305643520 float32<br>\n=305643520x4/1024/1024=1164MB</p>\n<h2>All together, no more than 2GB. Far from 11GB.</h2>\n<p>But I got the following:</p>\n<h2>Ran out of memory trying to allocate 512.00MiB.  See logs for memory state</h2>\n<p>However,  once I changed the number of output feature-maps for each layer from 16 to 8 (or less), the model just trained well.</p>\n<p>I use the latest tensor-flow codes (20151202), the following session configs:</p>\n<h2>Code start</h2>\n<pre><code>### start session\nconfig=tf.ConfigProto()\n# config.gpu_options.per_process_gpu_memory_fraction=0.98\nconfig.gpu_options.allocator_type=\"BFC\"\nconfig.log_device_placement=True\nsess=tf.Session(config=config)\n</code></pre>\n<h2>Code end</h2>\n<p>But it doesn't solve my problems.</p>\n<h2>So, help....</h2>", "body_text": "I've got a GPU ran-out-of-memory problem.\nMy single GPU Card has about 11GB memory. As the nvidia-smi shows below:\nN/A   48C    P0   129W / 235W |  10985MiB / 11519MiB |     99%      Default\nI define a big CNN models, it is like this:\nMy CNN Models Start...\nLayer 1.\ninput: one batch 35 pics, with 1024x1024x3:\n(35,1024,1024,3)\nLayer 2.\n2D conv-layer and 2D max-pool layer:\nconv-kernel (3,3,3), 16 feature maps, stride=1, and using \"SAME\" padding,\nmax-pool-kernel (2,2), stride=2, so the output should be\n(35,512,512,16)\nand the parameters of the layer should be:\nW: 3x3x3x16+b: 16=448\nLayer3, 4, 5, 6:\nThe same as Layer2, 2D Conv and 2D Max Pool,\nconv-kernel (3,3,16), 16 feature maps, stride=1, and using \"SAME\" padding,\nmax-pool-kernel (2,2), strides=2,\nthe output of the layers is:\n(35,256,256,16)\n(35,128,128,16)\n(35,64,64,16)\n(35,32,32,16)\nThe total parameters is:\n4x(3x3x16x16)+4x16=9280\nLayer7:\ndense layer with 2048 hidden nodes,\nthe parameters:\n32x32x16x2048+2048=33556480\nLayer8:\ndense layer with 600 hidden nodes,\nthe parameters:\n600x2048+600=1229400\nEND.\nSo all together, the model has 448+9280+33556480+1229400=34795608 float32 parameters, it is  34795608x4/1024/1024=132MB parameters.\nMaybe I should also add the memory cost by the outputs, so it is\n(35x1024x1024x3)+(35x512x512x16)+(35x256x256x16)+(35x128x128x16)+(35x64x64x16)+(35x32x32x16)=305643520 float32\n=305643520x4/1024/1024=1164MB\nAll together, no more than 2GB. Far from 11GB.\nBut I got the following:\nRan out of memory trying to allocate 512.00MiB.  See logs for memory state\nHowever,  once I changed the number of output feature-maps for each layer from 16 to 8 (or less), the model just trained well.\nI use the latest tensor-flow codes (20151202), the following session configs:\nCode start\n### start session\nconfig=tf.ConfigProto()\n# config.gpu_options.per_process_gpu_memory_fraction=0.98\nconfig.gpu_options.allocator_type=\"BFC\"\nconfig.log_device_placement=True\nsess=tf.Session(config=config)\n\nCode end\nBut it doesn't solve my problems.\nSo, help....", "body": "I've got a GPU ran-out-of-memory problem.\n\nMy single GPU Card has about 11GB memory. As the nvidia-smi shows below:\n## N/A   48C    P0   129W / 235W |  10985MiB / 11519MiB |     99%      Default\n\nI define a big CNN models, it is like this:\n## My CNN Models Start...\n\nLayer 1.\ninput: one batch 35 pics, with 1024x1024x3:\n(35,1024,1024,3)\n\nLayer 2.\n2D conv-layer and 2D max-pool layer:\nconv-kernel (3,3,3), 16 feature maps, stride=1, and using \"SAME\" padding,\nmax-pool-kernel (2,2), stride=2, so the output should be\n(35,512,512,16)\nand the parameters of the layer should be:\nW: 3x3x3x16+b: 16=448\n\nLayer3, 4, 5, 6:\nThe same as Layer2, 2D Conv and 2D Max Pool,\nconv-kernel (3,3,16), 16 feature maps, stride=1, and using \"SAME\" padding,\nmax-pool-kernel (2,2), strides=2, \nthe output of the layers is:\n(35,256,256,16)\n(35,128,128,16)\n(35,64,64,16)\n(35,32,32,16)\nThe total parameters is:\n4x(3x3x16x16)+4x16=9280\n\nLayer7:\ndense layer with 2048 hidden nodes,\nthe parameters:\n32x32x16x2048+2048=33556480\n\nLayer8:\ndense layer with 600 hidden nodes,\nthe parameters:\n600x2048+600=1229400\n## END.\n\nSo all together, the model has 448+9280+33556480+1229400=34795608 float32 parameters, it is  34795608x4/1024/1024=132MB parameters.\n\nMaybe I should also add the memory cost by the outputs, so it is\n(35x1024x1024x3)+(35x512x512x16)+(35x256x256x16)+(35x128x128x16)+(35x64x64x16)+(35x32x32x16)=305643520 float32\n=305643520x4/1024/1024=1164MB\n## All together, no more than 2GB. Far from 11GB.\n\nBut I got the following:\n## Ran out of memory trying to allocate 512.00MiB.  See logs for memory state\n\nHowever,  once I changed the number of output feature-maps for each layer from 16 to 8 (or less), the model just trained well.\n\nI use the latest tensor-flow codes (20151202), the following session configs:\n## Code start\n\n```\n### start session\nconfig=tf.ConfigProto()\n# config.gpu_options.per_process_gpu_memory_fraction=0.98\nconfig.gpu_options.allocator_type=\"BFC\"\nconfig.log_device_placement=True\nsess=tf.Session(config=config)\n```\n## Code end\n\nBut it doesn't solve my problems.\n## So, help....\n"}