{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/201095721", "html_url": "https://github.com/tensorflow/tensorflow/pull/1620#issuecomment-201095721", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1620", "id": 201095721, "node_id": "MDEyOklzc3VlQ29tbWVudDIwMTA5NTcyMQ==", "user": {"login": "fayeshine", "id": 11470826, "node_id": "MDQ6VXNlcjExNDcwODI2", "avatar_url": "https://avatars0.githubusercontent.com/u/11470826?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fayeshine", "html_url": "https://github.com/fayeshine", "followers_url": "https://api.github.com/users/fayeshine/followers", "following_url": "https://api.github.com/users/fayeshine/following{/other_user}", "gists_url": "https://api.github.com/users/fayeshine/gists{/gist_id}", "starred_url": "https://api.github.com/users/fayeshine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fayeshine/subscriptions", "organizations_url": "https://api.github.com/users/fayeshine/orgs", "repos_url": "https://api.github.com/users/fayeshine/repos", "events_url": "https://api.github.com/users/fayeshine/events{/privacy}", "received_events_url": "https://api.github.com/users/fayeshine/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-25T01:24:06Z", "updated_at": "2016-03-25T01:28:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11607205\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/samjabrahams\">@samjabrahams</a><br>\nI understand what you mean, truly dropout is very important and common for ML learners.<br>\nIt seems to be very necessary to teach users how to use dropout.</p>\n<p>However, the main point is not to reduce the training time, but dropout seems didn't useful or work at this MNIST tutorial. It may not be a good example here and may mislead users to use dropout all time without thinking the proper situation to use dropout.</p>\n<p>So I just wonder maybe it is not suitable to put a non-useful procedure here, but we should put dropout in later chapter of tutorial where it can truly work and in this case we can also teach the intuitive why it work: dropout can reduce the overfitting problem in complicated models with many parameters. In such manner, people can understand why dropout work and where dropout can work. <g-emoji class=\"g-emoji\" alias=\"smiley\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f603.png\">\ud83d\ude03</g-emoji></p>", "body_text": "@samjabrahams\nI understand what you mean, truly dropout is very important and common for ML learners.\nIt seems to be very necessary to teach users how to use dropout.\nHowever, the main point is not to reduce the training time, but dropout seems didn't useful or work at this MNIST tutorial. It may not be a good example here and may mislead users to use dropout all time without thinking the proper situation to use dropout.\nSo I just wonder maybe it is not suitable to put a non-useful procedure here, but we should put dropout in later chapter of tutorial where it can truly work and in this case we can also teach the intuitive why it work: dropout can reduce the overfitting problem in complicated models with many parameters. In such manner, people can understand why dropout work and where dropout can work. \ud83d\ude03", "body": "@samjabrahams \nI understand what you mean, truly dropout is very important and common for ML learners.\nIt seems to be very necessary to teach users how to use dropout.\n\nHowever, the main point is not to reduce the training time, but dropout seems didn't useful or work at this MNIST tutorial. It may not be a good example here and may mislead users to use dropout all time without thinking the proper situation to use dropout.\n\nSo I just wonder maybe it is not suitable to put a non-useful procedure here, but we should put dropout in later chapter of tutorial where it can truly work and in this case we can also teach the intuitive why it work: dropout can reduce the overfitting problem in complicated models with many parameters. In such manner, people can understand why dropout work and where dropout can work. :smiley: \n"}