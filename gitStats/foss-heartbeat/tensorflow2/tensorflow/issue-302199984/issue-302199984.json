{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17429", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17429/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17429/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17429/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17429", "id": 302199984, "node_id": "MDU6SXNzdWUzMDIxOTk5ODQ=", "number": 17429, "title": "How to get the predicted probabilities for image classification using tensor flow CNN", "user": {"login": "tianke0711", "id": 6407418, "node_id": "MDQ6VXNlcjY0MDc0MTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6407418?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tianke0711", "html_url": "https://github.com/tianke0711", "followers_url": "https://api.github.com/users/tianke0711/followers", "following_url": "https://api.github.com/users/tianke0711/following{/other_user}", "gists_url": "https://api.github.com/users/tianke0711/gists{/gist_id}", "starred_url": "https://api.github.com/users/tianke0711/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tianke0711/subscriptions", "organizations_url": "https://api.github.com/users/tianke0711/orgs", "repos_url": "https://api.github.com/users/tianke0711/repos", "events_url": "https://api.github.com/users/tianke0711/events{/privacy}", "received_events_url": "https://api.github.com/users/tianke0711/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-03-05T07:46:16Z", "updated_at": "2018-04-10T23:24:54Z", "closed_at": "2018-04-10T23:24:54Z", "author_association": "NONE", "body_html": "<p>I am studying the tensor flow for CNN image classification following the official document(<a href=\"https://www.tensorflow.org/tutorials/layers\" rel=\"nofollow\">https://www.tensorflow.org/tutorials/layers</a>) . The code in above link for image classification with tensorflow CNN, I want to get all the probabilities of each image labels in test data. I want to ask.</p>\n<p>How to get the probabilities of predicting result for each image.<br>\nHow to evaluate the result of predicted probabilities, in this example using accuracy for label classification. Thanks!</p>\n<pre><code>`import numpy as np\nimport tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n  # Input Layer\n  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n  # MNIST images are 28x28 pixels, and have one color channel\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer #1\n  # Computes 32 features using a 5x5 filter with ReLU activation.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 28, 28, 1]\n  # Output Tensor Shape: [batch_size, 28, 28, 32]\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=32,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #1\n  # First max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 28, 28, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 32]\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  # Convolutional Layer #2\n  # Computes 64 features using a 5x5 filter.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 14, 14, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 64]\n  conv2 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=64,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #2\n  # Second max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 14, 14, 64]\n  # Output Tensor Shape: [batch_size, 7, 7, 64]\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n  # Flatten tensor into a batch of vectors\n  # Input Tensor Shape: [batch_size, 7, 7, 64]\n  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\n  # Dense Layer\n  # Densely connected layer with 1024 neurons\n  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n  # Output Tensor Shape: [batch_size, 1024]\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n\n  # Add dropout operation; 0.6 probability that element will be kept\n  dropout = tf.layers.dropout(\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n  # Logits layer\n  # Input Tensor Shape: [batch_size, 1024]\n  # Output Tensor Shape: [batch_size, 10]\n  logits = tf.layers.dense(inputs=dropout, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef main(unused_argv):\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n  train_data = mnist.train.images  # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n  eval_data = mnist.test.images  # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  # Create the Estimator\n  mnist_classifier = tf.estimator.Estimator(\n      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n\n  # Set up logging for predictions\n  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n  logging_hook = tf.train.LoggingTensorHook(\n      tensors=tensors_to_log, every_n_iter=50)\n\n  # Train the model\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": train_data},\n      y=train_labels,\n      batch_size=100,\n      num_epochs=None,\n      shuffle=True)\n  mnist_classifier.train(\n      input_fn=train_input_fn,\n      steps=20000,\n      hooks=[logging_hook])\n\n  # Evaluate the model and print results\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": eval_data},\n      y=eval_labels,\n      num_epochs=1,\n      shuffle=False)\n  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n  print(eval_results)\n\n\nif __name__ == \"__main__\":\n  tf.app.run()`\n</code></pre>", "body_text": "I am studying the tensor flow for CNN image classification following the official document(https://www.tensorflow.org/tutorials/layers) . The code in above link for image classification with tensorflow CNN, I want to get all the probabilities of each image labels in test data. I want to ask.\nHow to get the probabilities of predicting result for each image.\nHow to evaluate the result of predicted probabilities, in this example using accuracy for label classification. Thanks!\n`import numpy as np\nimport tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n  # Input Layer\n  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n  # MNIST images are 28x28 pixels, and have one color channel\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer #1\n  # Computes 32 features using a 5x5 filter with ReLU activation.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 28, 28, 1]\n  # Output Tensor Shape: [batch_size, 28, 28, 32]\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=32,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #1\n  # First max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 28, 28, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 32]\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  # Convolutional Layer #2\n  # Computes 64 features using a 5x5 filter.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 14, 14, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 64]\n  conv2 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=64,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #2\n  # Second max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 14, 14, 64]\n  # Output Tensor Shape: [batch_size, 7, 7, 64]\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n  # Flatten tensor into a batch of vectors\n  # Input Tensor Shape: [batch_size, 7, 7, 64]\n  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\n  # Dense Layer\n  # Densely connected layer with 1024 neurons\n  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n  # Output Tensor Shape: [batch_size, 1024]\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n\n  # Add dropout operation; 0.6 probability that element will be kept\n  dropout = tf.layers.dropout(\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n  # Logits layer\n  # Input Tensor Shape: [batch_size, 1024]\n  # Output Tensor Shape: [batch_size, 10]\n  logits = tf.layers.dense(inputs=dropout, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef main(unused_argv):\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n  train_data = mnist.train.images  # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n  eval_data = mnist.test.images  # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  # Create the Estimator\n  mnist_classifier = tf.estimator.Estimator(\n      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n\n  # Set up logging for predictions\n  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n  logging_hook = tf.train.LoggingTensorHook(\n      tensors=tensors_to_log, every_n_iter=50)\n\n  # Train the model\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": train_data},\n      y=train_labels,\n      batch_size=100,\n      num_epochs=None,\n      shuffle=True)\n  mnist_classifier.train(\n      input_fn=train_input_fn,\n      steps=20000,\n      hooks=[logging_hook])\n\n  # Evaluate the model and print results\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": eval_data},\n      y=eval_labels,\n      num_epochs=1,\n      shuffle=False)\n  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n  print(eval_results)\n\n\nif __name__ == \"__main__\":\n  tf.app.run()`", "body": "I am studying the tensor flow for CNN image classification following the official document(https://www.tensorflow.org/tutorials/layers) . The code in above link for image classification with tensorflow CNN, I want to get all the probabilities of each image labels in test data. I want to ask.\r\n\r\nHow to get the probabilities of predicting result for each image.\r\nHow to evaluate the result of predicted probabilities, in this example using accuracy for label classification. Thanks!\r\n\r\n\r\n```\r\n`import numpy as np\r\nimport tensorflow as tf\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef cnn_model_fn(features, labels, mode):\r\n  \"\"\"Model function for CNN.\"\"\"\r\n  # Input Layer\r\n  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\r\n  # MNIST images are 28x28 pixels, and have one color channel\r\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\r\n\r\n  # Convolutional Layer #1\r\n  # Computes 32 features using a 5x5 filter with ReLU activation.\r\n  # Padding is added to preserve width and height.\r\n  # Input Tensor Shape: [batch_size, 28, 28, 1]\r\n  # Output Tensor Shape: [batch_size, 28, 28, 32]\r\n  conv1 = tf.layers.conv2d(\r\n      inputs=input_layer,\r\n      filters=32,\r\n      kernel_size=[5, 5],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n\r\n  # Pooling Layer #1\r\n  # First max pooling layer with a 2x2 filter and stride of 2\r\n  # Input Tensor Shape: [batch_size, 28, 28, 32]\r\n  # Output Tensor Shape: [batch_size, 14, 14, 32]\r\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\r\n\r\n  # Convolutional Layer #2\r\n  # Computes 64 features using a 5x5 filter.\r\n  # Padding is added to preserve width and height.\r\n  # Input Tensor Shape: [batch_size, 14, 14, 32]\r\n  # Output Tensor Shape: [batch_size, 14, 14, 64]\r\n  conv2 = tf.layers.conv2d(\r\n      inputs=pool1,\r\n      filters=64,\r\n      kernel_size=[5, 5],\r\n      padding=\"same\",\r\n      activation=tf.nn.relu)\r\n\r\n  # Pooling Layer #2\r\n  # Second max pooling layer with a 2x2 filter and stride of 2\r\n  # Input Tensor Shape: [batch_size, 14, 14, 64]\r\n  # Output Tensor Shape: [batch_size, 7, 7, 64]\r\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\r\n\r\n  # Flatten tensor into a batch of vectors\r\n  # Input Tensor Shape: [batch_size, 7, 7, 64]\r\n  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\r\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\r\n\r\n  # Dense Layer\r\n  # Densely connected layer with 1024 neurons\r\n  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\r\n  # Output Tensor Shape: [batch_size, 1024]\r\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\r\n\r\n  # Add dropout operation; 0.6 probability that element will be kept\r\n  dropout = tf.layers.dropout(\r\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\r\n\r\n  # Logits layer\r\n  # Input Tensor Shape: [batch_size, 1024]\r\n  # Output Tensor Shape: [batch_size, 10]\r\n  logits = tf.layers.dense(inputs=dropout, units=10)\r\n\r\n  predictions = {\r\n      # Generate predictions (for PREDICT and EVAL mode)\r\n      \"classes\": tf.argmax(input=logits, axis=1),\r\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\r\n      # `logging_hook`.\r\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\r\n  }\r\n  if mode == tf.estimator.ModeKeys.PREDICT:\r\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n  # Calculate Loss (for both TRAIN and EVAL modes)\r\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\r\n\r\n  # Configure the Training Op (for TRAIN mode)\r\n  if mode == tf.estimator.ModeKeys.TRAIN:\r\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\r\n    train_op = optimizer.minimize(\r\n        loss=loss,\r\n        global_step=tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\n  # Add evaluation metrics (for EVAL mode)\r\n  eval_metric_ops = {\r\n      \"accuracy\": tf.metrics.accuracy(\r\n          labels=labels, predictions=predictions[\"classes\"])}\r\n  return tf.estimator.EstimatorSpec(\r\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n\r\n\r\ndef main(unused_argv):\r\n  # Load training and eval data\r\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\r\n  train_data = mnist.train.images  # Returns np.array\r\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\r\n  eval_data = mnist.test.images  # Returns np.array\r\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\r\n\r\n  # Create the Estimator\r\n  mnist_classifier = tf.estimator.Estimator(\r\n      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\r\n\r\n  # Set up logging for predictions\r\n  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\r\n  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\r\n  logging_hook = tf.train.LoggingTensorHook(\r\n      tensors=tensors_to_log, every_n_iter=50)\r\n\r\n  # Train the model\r\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n      x={\"x\": train_data},\r\n      y=train_labels,\r\n      batch_size=100,\r\n      num_epochs=None,\r\n      shuffle=True)\r\n  mnist_classifier.train(\r\n      input_fn=train_input_fn,\r\n      steps=20000,\r\n      hooks=[logging_hook])\r\n\r\n  # Evaluate the model and print results\r\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n      x={\"x\": eval_data},\r\n      y=eval_labels,\r\n      num_epochs=1,\r\n      shuffle=False)\r\n  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\r\n  print(eval_results)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  tf.app.run()`\r\n```"}