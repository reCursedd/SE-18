{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11165", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11165/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11165/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11165/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11165", "id": 239679862, "node_id": "MDU6SXNzdWUyMzk2Nzk4NjI=", "number": 11165, "title": "[feature-request] Multi-arity elems in fold{l,r}", "user": {"login": "akssri", "id": 65960, "node_id": "MDQ6VXNlcjY1OTYw", "avatar_url": "https://avatars2.githubusercontent.com/u/65960?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akssri", "html_url": "https://github.com/akssri", "followers_url": "https://api.github.com/users/akssri/followers", "following_url": "https://api.github.com/users/akssri/following{/other_user}", "gists_url": "https://api.github.com/users/akssri/gists{/gist_id}", "starred_url": "https://api.github.com/users/akssri/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akssri/subscriptions", "organizations_url": "https://api.github.com/users/akssri/orgs", "repos_url": "https://api.github.com/users/akssri/repos", "events_url": "https://api.github.com/users/akssri/events{/privacy}", "received_events_url": "https://api.github.com/users/akssri/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-30T05:20:51Z", "updated_at": "2018-02-03T13:04:34Z", "closed_at": "2018-02-03T13:04:34Z", "author_association": "NONE", "body_html": "<p>The functions <code>fold{l,r}</code> that are part of <code>tensorflow.python.ops.functional_ops</code> currently only allow single-arity arguments for <code>elems</code>. This makes it inconvenient for writing operations that involve dynamic concatenation of tensors differing in the dimension along a particular axis without padding (this also means one can't use <code>tf.map_fn</code> for accomplishing this task).</p>\n<p>This scenario is present in cases like object detection where a different number of boxes are emitted for each image in the batch. Currently, the implementation in tensorflow/models (<code>tensorflow-models:object_detection/core/post_processing.py</code>) gets around this by fixing the batch size and using <code>tf.split</code> during graph compilation time. The requested op would make such scenarios dynamic; it would also be the way forward in making <code>tf.dynamic_partition</code> ..erm, more dynamic (without introducing a List into Tensorflow's semantics).</p>\n<p>I currently resort to something like the following,</p>\n<div class=\"highlight highlight-source-python\"><pre>zeroq <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0</span>) <span class=\"pl-k\">-</span> tf.constant(<span class=\"pl-c1\">0</span>)\nnkeeps_0 <span class=\"pl-k\">=</span> tf.zeros([zeroq], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32); keeps_0 <span class=\"pl-k\">=</span> tf.zeros([zeroq], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)  \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_compute</span>(<span class=\"pl-smi\">ii</span>, <span class=\"pl-smi\">nkeeps_r</span>, <span class=\"pl-smi\">keeps_r</span>):\n  keep_ii <span class=\"pl-k\">=</span> <span class=\"pl-k\">&lt;</span>function that spits a varying tensor of shape [M_ii]<span class=\"pl-k\">&gt;</span>\n  <span class=\"pl-k\">return</span> (ii <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, tf.concat([nkeeps_r, tf.stack([tf.shape(keep_ii)[<span class=\"pl-c1\">0</span>]])], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>), tf.concat([keeps_r, keep_ii], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>))\n_, <span class=\"pl-k\">*</span>ret <span class=\"pl-k\">=</span> control_flow_ops.while_loop(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">ii</span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">_</span>: ii <span class=\"pl-k\">&lt;</span> bsize, _compute, [tf.constant(<span class=\"pl-c1\">0</span>), nkeeps_0, keeps_0], <span class=\"pl-v\">back_prop</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)</pre></div>\n<p>I'm not sure how this will play with <code>back_prop=True</code>, or as to how this would fit in with the larger goals for the project.</p>", "body_text": "The functions fold{l,r} that are part of tensorflow.python.ops.functional_ops currently only allow single-arity arguments for elems. This makes it inconvenient for writing operations that involve dynamic concatenation of tensors differing in the dimension along a particular axis without padding (this also means one can't use tf.map_fn for accomplishing this task).\nThis scenario is present in cases like object detection where a different number of boxes are emitted for each image in the batch. Currently, the implementation in tensorflow/models (tensorflow-models:object_detection/core/post_processing.py) gets around this by fixing the batch size and using tf.split during graph compilation time. The requested op would make such scenarios dynamic; it would also be the way forward in making tf.dynamic_partition ..erm, more dynamic (without introducing a List into Tensorflow's semantics).\nI currently resort to something like the following,\nzeroq = tf.constant(0) - tf.constant(0)\nnkeeps_0 = tf.zeros([zeroq], dtype=tf.int32); keeps_0 = tf.zeros([zeroq], dtype=tf.int32)  \ndef _compute(ii, nkeeps_r, keeps_r):\n  keep_ii = <function that spits a varying tensor of shape [M_ii]>\n  return (ii + 1, tf.concat([nkeeps_r, tf.stack([tf.shape(keep_ii)[0]])], axis=0), tf.concat([keeps_r, keep_ii], axis=0))\n_, *ret = control_flow_ops.while_loop(lambda ii, *_: ii < bsize, _compute, [tf.constant(0), nkeeps_0, keeps_0], back_prop=False)\nI'm not sure how this will play with back_prop=True, or as to how this would fit in with the larger goals for the project.", "body": "The functions ```fold{l,r}``` that are part of ```tensorflow.python.ops.functional_ops``` currently only allow single-arity arguments for ```elems```. This makes it inconvenient for writing operations that involve dynamic concatenation of tensors differing in the dimension along a particular axis without padding (this also means one can't use ```tf.map_fn``` for accomplishing this task).\r\n\r\nThis scenario is present in cases like object detection where a different number of boxes are emitted for each image in the batch. Currently, the implementation in tensorflow/models (```tensorflow-models:object_detection/core/post_processing.py```) gets around this by fixing the batch size and using ```tf.split``` during graph compilation time. The requested op would make such scenarios dynamic; it would also be the way forward in making ```tf.dynamic_partition``` ..erm, more dynamic (without introducing a List into Tensorflow's semantics).\r\n\r\nI currently resort to something like the following,\r\n``` python\r\nzeroq = tf.constant(0) - tf.constant(0)\r\nnkeeps_0 = tf.zeros([zeroq], dtype=tf.int32); keeps_0 = tf.zeros([zeroq], dtype=tf.int32)  \r\ndef _compute(ii, nkeeps_r, keeps_r):\r\n  keep_ii = <function that spits a varying tensor of shape [M_ii]>\r\n  return (ii + 1, tf.concat([nkeeps_r, tf.stack([tf.shape(keep_ii)[0]])], axis=0), tf.concat([keeps_r, keep_ii], axis=0))\r\n_, *ret = control_flow_ops.while_loop(lambda ii, *_: ii < bsize, _compute, [tf.constant(0), nkeeps_0, keeps_0], back_prop=False)\r\n```\r\nI'm not sure how this will play with ```back_prop=True```, or as to how this would fit in with the larger goals for the project."}