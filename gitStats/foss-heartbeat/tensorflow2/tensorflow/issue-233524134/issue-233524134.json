{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10435", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10435/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10435/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10435/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10435", "id": 233524134, "node_id": "MDU6SXNzdWUyMzM1MjQxMzQ=", "number": 10435, "title": "build optimize_for_inference fail", "user": {"login": "JcmeLs", "id": 12932339, "node_id": "MDQ6VXNlcjEyOTMyMzM5", "avatar_url": "https://avatars2.githubusercontent.com/u/12932339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JcmeLs", "html_url": "https://github.com/JcmeLs", "followers_url": "https://api.github.com/users/JcmeLs/followers", "following_url": "https://api.github.com/users/JcmeLs/following{/other_user}", "gists_url": "https://api.github.com/users/JcmeLs/gists{/gist_id}", "starred_url": "https://api.github.com/users/JcmeLs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JcmeLs/subscriptions", "organizations_url": "https://api.github.com/users/JcmeLs/orgs", "repos_url": "https://api.github.com/users/JcmeLs/repos", "events_url": "https://api.github.com/users/JcmeLs/events{/privacy}", "received_events_url": "https://api.github.com/users/JcmeLs/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "meteorcloudy", "id": 4171702, "node_id": "MDQ6VXNlcjQxNzE3MDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/4171702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meteorcloudy", "html_url": "https://github.com/meteorcloudy", "followers_url": "https://api.github.com/users/meteorcloudy/followers", "following_url": "https://api.github.com/users/meteorcloudy/following{/other_user}", "gists_url": "https://api.github.com/users/meteorcloudy/gists{/gist_id}", "starred_url": "https://api.github.com/users/meteorcloudy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meteorcloudy/subscriptions", "organizations_url": "https://api.github.com/users/meteorcloudy/orgs", "repos_url": "https://api.github.com/users/meteorcloudy/repos", "events_url": "https://api.github.com/users/meteorcloudy/events{/privacy}", "received_events_url": "https://api.github.com/users/meteorcloudy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "meteorcloudy", "id": 4171702, "node_id": "MDQ6VXNlcjQxNzE3MDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/4171702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meteorcloudy", "html_url": "https://github.com/meteorcloudy", "followers_url": "https://api.github.com/users/meteorcloudy/followers", "following_url": "https://api.github.com/users/meteorcloudy/following{/other_user}", "gists_url": "https://api.github.com/users/meteorcloudy/gists{/gist_id}", "starred_url": "https://api.github.com/users/meteorcloudy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meteorcloudy/subscriptions", "organizations_url": "https://api.github.com/users/meteorcloudy/orgs", "repos_url": "https://api.github.com/users/meteorcloudy/repos", "events_url": "https://api.github.com/users/meteorcloudy/events{/privacy}", "received_events_url": "https://api.github.com/users/meteorcloudy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 36, "created_at": "2017-06-05T08:23:13Z", "updated_at": "2018-06-21T05:56:26Z", "closed_at": "2017-06-11T06:01:51Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nNo</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 7 x64</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\nbinary (pip3 install....)</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\ntensorflow 1.1.0 CPU only</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\nBuild label: 0.5.0<br>\nBuild target: bazel-out/msys_x64-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Fri May 26 12:12:09 2017 (1495800729)<br>\nBuild timestamp: 1495800729<br>\nBuild timestamp as int: 1495800729</p>\n<p>$ protoc --version<br>\nlibprotoc 3.2.0</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nCPU Only</p>\n</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I want to build optimize_for_inference and optimize and would like to optimize my graph by the optimizer.But when I run <code>bazel build tensorflow/python/tools:optimize_for_inference</code>.It will get me a problem--<code> Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//'</code>.The problem occurs when i try to build anything with tensorflow as dependancy,like:<code>convert_graphdef_memmapped_format</code>.<br>\nI've seen all the issues from github or stack overflow.And I tried all the fixes from issues or stackoverflow.But the problem still exists.</p>\n<h3>Source code / logs</h3>\n<p>Source code:</p>\n<pre><code>bazel build tensorflow/python/tools:optimize_for_inference &amp;&amp; bazel-bin/tensorflow/python/tools/optimize_for_inference --input=frozen_inception_graph.pb --output=optimized_inception_graph.pb --frozen_graph=True --input_names=Mul --output_names=softmax\n</code></pre>\n<p>logs:</p>\n<pre><code>D:\\tensorflow-r1.2&gt;bazel build tensorflow/python/tools:optimize_for_inference\n\ufffd[32mINFO: \ufffd[0mLoading complete.  Analyzing...\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 257,202 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 501,196 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 951,646 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 1,433,556 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 2,197,176 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 2,997,976 bytes\n\ufffd[1A\ufffd[K\ufffd[31m\ufffd[1mERROR: \ufffd[0mD:/tensorflow-r1.2/tensorflow/python/tools/BUILD:133:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such packa\nge '@protobuf//': Traceback (most recent call last):\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 117\n                _apply_patch(repo_ctx, repo_ctx.attr.patch_file)\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 108, in _apply_patch\n                _execute_and_check_ret_code(repo_ctx, cmd)\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 92, in _execute_and_check_ret_code\n                fail(\"Non-zero return code({1}) when ..., &lt;2 more arguments&gt;))\nNon-zero return code(3) when executing 'c:/tools/msys64/usr/bin/bash.exe -c patch -p1 -d C:/users/liba/appdata/local/temp/_bazel_liba/mffpt2ks/external/protobuf -i D:/tensorflow-r1.2/third_party/proto\nbuf/add_noinlines.patch':\nStdout: patching file src/google/protobuf/compiler/cpp/cpp_file.cc\n\nStderr: Assertion failed: hunk, file ../patch-2.5.9-src/patch.c, line 354\n\nThis application has requested the Runtime to terminate it in an unusual way.\nPlease contact the application's support team for more information.\n and referenced by '//tensorflow/python/tools:optimize_for_inference'.\n\ufffd[31m\ufffd[1mERROR: \ufffd[0mAnalysis of target '//tensorflow/python/tools:optimize_for_inference' failed; build aborted.\n\ufffd[32mINFO: \ufffd[0mElapsed time: 12.754s\n</code></pre>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nNo\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 7 x64\n\n\nTensorFlow installed from (source or binary):\nbinary (pip3 install....)\n\n\nTensorFlow version (use command below):\ntensorflow 1.1.0 CPU only\n\n\nBazel version (if compiling from source):\nBuild label: 0.5.0\nBuild target: bazel-out/msys_x64-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri May 26 12:12:09 2017 (1495800729)\nBuild timestamp: 1495800729\nBuild timestamp as int: 1495800729\n$ protoc --version\nlibprotoc 3.2.0\n\n\nCUDA/cuDNN version:\nCPU Only\n\n\nDescribe the problem\nI want to build optimize_for_inference and optimize and would like to optimize my graph by the optimizer.But when I run bazel build tensorflow/python/tools:optimize_for_inference.It will get me a problem-- Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//'.The problem occurs when i try to build anything with tensorflow as dependancy,like:convert_graphdef_memmapped_format.\nI've seen all the issues from github or stack overflow.And I tried all the fixes from issues or stackoverflow.But the problem still exists.\nSource code / logs\nSource code:\nbazel build tensorflow/python/tools:optimize_for_inference && bazel-bin/tensorflow/python/tools/optimize_for_inference --input=frozen_inception_graph.pb --output=optimized_inception_graph.pb --frozen_graph=True --input_names=Mul --output_names=softmax\n\nlogs:\nD:\\tensorflow-r1.2>bazel build tensorflow/python/tools:optimize_for_inference\n\ufffd[32mINFO: \ufffd[0mLoading complete.  Analyzing...\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 257,202 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 501,196 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 951,646 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 1,433,556 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 2,197,176 bytes\n\ufffd[1A\ufffd[K\ufffd[32mINFO: \ufffd[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 2,997,976 bytes\n\ufffd[1A\ufffd[K\ufffd[31m\ufffd[1mERROR: \ufffd[0mD:/tensorflow-r1.2/tensorflow/python/tools/BUILD:133:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such packa\nge '@protobuf//': Traceback (most recent call last):\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 117\n                _apply_patch(repo_ctx, repo_ctx.attr.patch_file)\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 108, in _apply_patch\n                _execute_and_check_ret_code(repo_ctx, cmd)\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 92, in _execute_and_check_ret_code\n                fail(\"Non-zero return code({1}) when ..., <2 more arguments>))\nNon-zero return code(3) when executing 'c:/tools/msys64/usr/bin/bash.exe -c patch -p1 -d C:/users/liba/appdata/local/temp/_bazel_liba/mffpt2ks/external/protobuf -i D:/tensorflow-r1.2/third_party/proto\nbuf/add_noinlines.patch':\nStdout: patching file src/google/protobuf/compiler/cpp/cpp_file.cc\n\nStderr: Assertion failed: hunk, file ../patch-2.5.9-src/patch.c, line 354\n\nThis application has requested the Runtime to terminate it in an unusual way.\nPlease contact the application's support team for more information.\n and referenced by '//tensorflow/python/tools:optimize_for_inference'.\n\ufffd[31m\ufffd[1mERROR: \ufffd[0mAnalysis of target '//tensorflow/python/tools:optimize_for_inference' failed; build aborted.\n\ufffd[32mINFO: \ufffd[0mElapsed time: 12.754s", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n    No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n    Windows 7 x64\r\n- **TensorFlow installed from (source or binary)**:\r\n    binary (pip3 install....)\r\n- **TensorFlow version (use command below)**:\r\n    tensorflow 1.1.0 CPU only\r\n- **Bazel version (if compiling from source)**:\r\n    Build label: 0.5.0\r\n    Build target: bazel-out/msys_x64-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\n    Build time: Fri May 26 12:12:09 2017 (1495800729)\r\n    Build timestamp: 1495800729\r\n    Build timestamp as int: 1495800729\r\n  \r\n    $ protoc --version\r\n    libprotoc 3.2.0\r\n- **CUDA/cuDNN version**:\r\n    CPU Only\r\n\r\n### Describe the problem\r\nI want to build optimize_for_inference and optimize and would like to optimize my graph by the optimizer.But when I run ` bazel build tensorflow/python/tools:optimize_for_inference `.It will get me a problem--` Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//'`.The problem occurs when i try to build anything with tensorflow as dependancy,like:`convert_graphdef_memmapped_format`.  \r\nI've seen all the issues from github or stack overflow.And I tried all the fixes from issues or stackoverflow.But the problem still exists.\r\n### Source code / logs\r\nSource code:\r\n``` \r\nbazel build tensorflow/python/tools:optimize_for_inference && bazel-bin/tensorflow/python/tools/optimize_for_inference --input=frozen_inception_graph.pb --output=optimized_inception_graph.pb --frozen_graph=True --input_names=Mul --output_names=softmax\r\n```\r\nlogs:\r\n``` \r\nD:\\tensorflow-r1.2>bazel build tensorflow/python/tools:optimize_for_inference\r\n\u001b[32mINFO: \u001b[0mLoading complete.  Analyzing...\r\n\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 257,202 bytes\r\n\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 501,196 bytes\r\n\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 951,646 bytes\r\n\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 1,433,556 bytes\r\n\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 2,197,176 bytes\r\n\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mDownloading http://mirror.bazel.build/github.com/google/protobuf/archive/2b7430d96aeff2bb624c8d52182ff5e4b9f7f18a.tar.gz: 2,997,976 bytes\r\n\u001b[1A\u001b[K\u001b[31m\u001b[1mERROR: \u001b[0mD:/tensorflow-r1.2/tensorflow/python/tools/BUILD:133:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such packa\r\nge '@protobuf//': Traceback (most recent call last):\r\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 117\r\n                _apply_patch(repo_ctx, repo_ctx.attr.patch_file)\r\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 108, in _apply_patch\r\n                _execute_and_check_ret_code(repo_ctx, cmd)\r\n        File \"D:/tensorflow-r1.2/tensorflow/workspace.bzl\", line 92, in _execute_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ..., <2 more arguments>))\r\nNon-zero return code(3) when executing 'c:/tools/msys64/usr/bin/bash.exe -c patch -p1 -d C:/users/liba/appdata/local/temp/_bazel_liba/mffpt2ks/external/protobuf -i D:/tensorflow-r1.2/third_party/proto\r\nbuf/add_noinlines.patch':\r\nStdout: patching file src/google/protobuf/compiler/cpp/cpp_file.cc\r\n\r\nStderr: Assertion failed: hunk, file ../patch-2.5.9-src/patch.c, line 354\r\n\r\nThis application has requested the Runtime to terminate it in an unusual way.\r\nPlease contact the application's support team for more information.\r\n and referenced by '//tensorflow/python/tools:optimize_for_inference'.\r\n\u001b[31m\u001b[1mERROR: \u001b[0mAnalysis of target '//tensorflow/python/tools:optimize_for_inference' failed; build aborted.\r\n\u001b[32mINFO: \u001b[0mElapsed time: 12.754s\r\n```\r\n"}