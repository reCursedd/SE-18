{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/381802682", "html_url": "https://github.com/tensorflow/tensorflow/issues/18548#issuecomment-381802682", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18548", "id": 381802682, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MTgwMjY4Mg==", "user": {"login": "oscarriddle", "id": 13745902, "node_id": "MDQ6VXNlcjEzNzQ1OTAy", "avatar_url": "https://avatars0.githubusercontent.com/u/13745902?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oscarriddle", "html_url": "https://github.com/oscarriddle", "followers_url": "https://api.github.com/users/oscarriddle/followers", "following_url": "https://api.github.com/users/oscarriddle/following{/other_user}", "gists_url": "https://api.github.com/users/oscarriddle/gists{/gist_id}", "starred_url": "https://api.github.com/users/oscarriddle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oscarriddle/subscriptions", "organizations_url": "https://api.github.com/users/oscarriddle/orgs", "repos_url": "https://api.github.com/users/oscarriddle/repos", "events_url": "https://api.github.com/users/oscarriddle/events{/privacy}", "received_events_url": "https://api.github.com/users/oscarriddle/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-17T01:42:20Z", "updated_at": "2018-04-17T01:42:20Z", "author_association": "NONE", "body_html": "<p>Hi tensorflowbutler,</p>\n<p>Sorry for ignoring the required information.</p>\n<ul>\n<li>Have I written custom code: No</li>\n<li>OS Platform and Distribution:  Red Hat 4.8.5-16, Linux version 3.10.0-693.5.2.el7.x86_64</li>\n<li>TensorFlow installed from: pip (python 2.7)</li>\n<li>TensorFlow version: tensorflow-gpu==1.7.0</li>\n<li>Bazel version: N/A</li>\n<li>CUDA/cuDNN version: CUDA9.0, cuDNN7.0.5</li>\n<li>GPU model and memory: Tesla P4, 8GB</li>\n<li>Exact command to reproduce:<br>\nMy own script is coded based on the official test \"tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\", so I think you can reproduce this problem with this test. The point is \"max_batch_size\" within trt.create_inference_graph().</li>\n</ul>\n<p>Thanks,</p>", "body_text": "Hi tensorflowbutler,\nSorry for ignoring the required information.\n\nHave I written custom code: No\nOS Platform and Distribution:  Red Hat 4.8.5-16, Linux version 3.10.0-693.5.2.el7.x86_64\nTensorFlow installed from: pip (python 2.7)\nTensorFlow version: tensorflow-gpu==1.7.0\nBazel version: N/A\nCUDA/cuDNN version: CUDA9.0, cuDNN7.0.5\nGPU model and memory: Tesla P4, 8GB\nExact command to reproduce:\nMy own script is coded based on the official test \"tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\", so I think you can reproduce this problem with this test. The point is \"max_batch_size\" within trt.create_inference_graph().\n\nThanks,", "body": "Hi tensorflowbutler,\r\n\r\nSorry for ignoring the required information.\r\n\r\n- Have I written custom code: No\r\n- OS Platform and Distribution:  Red Hat 4.8.5-16, Linux version 3.10.0-693.5.2.el7.x86_64\r\n- TensorFlow installed from: pip (python 2.7)\r\n- TensorFlow version: tensorflow-gpu==1.7.0\r\n- Bazel version: N/A\r\n- CUDA/cuDNN version: CUDA9.0, cuDNN7.0.5\r\n- GPU model and memory: Tesla P4, 8GB\r\n- Exact command to reproduce: \r\nMy own script is coded based on the official test \"tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\", so I think you can reproduce this problem with this test. The point is \"max_batch_size\" within trt.create_inference_graph().\r\n\r\nThanks,"}