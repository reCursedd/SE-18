{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/358876109", "html_url": "https://github.com/tensorflow/tensorflow/issues/15425#issuecomment-358876109", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15425", "id": 358876109, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODg3NjEwOQ==", "user": {"login": "anpark", "id": 12320255, "node_id": "MDQ6VXNlcjEyMzIwMjU1", "avatar_url": "https://avatars1.githubusercontent.com/u/12320255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anpark", "html_url": "https://github.com/anpark", "followers_url": "https://api.github.com/users/anpark/followers", "following_url": "https://api.github.com/users/anpark/following{/other_user}", "gists_url": "https://api.github.com/users/anpark/gists{/gist_id}", "starred_url": "https://api.github.com/users/anpark/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anpark/subscriptions", "organizations_url": "https://api.github.com/users/anpark/orgs", "repos_url": "https://api.github.com/users/anpark/repos", "events_url": "https://api.github.com/users/anpark/events{/privacy}", "received_events_url": "https://api.github.com/users/anpark/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-19T06:09:48Z", "updated_at": "2018-01-20T09:58:31Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15676913\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/poxvoculi\">@poxvoculi</a> thanks, i had already tried same fix with you before this issue.<br>\nyesterday i tried your code, but failed again at same error: (use tf_benchmark:<br>\nvariable_update: distributed_all_reduce<br>\nall_reduce_spec: nccl/xring)</p>\n<p>UnimplementedError (see above for traceback): This op should be replaced during graph optimization.<br>\ncaused by<br>\nFile python2.7/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py\", line 781, in build_nccl_then_ring<br>\nreturn _build_nccl_hybrid(input_tensors, red_op, upper_level_f)<br>\nFile \"python2.7/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py\", line 749, in _build_nccl_hybrid<br>\nbroadcast_src = nccl.broadcast(array_ops.identity(level_2_output[w]))<br>\nFile \"python2.7/site-packages/tensorflow/contrib/nccl/python/ops/nccl_ops.py\", line 187, in broadcast<br>\nreturn gen_nccl_ops.nccl_broadcast(input=tensor, shape=tensor.shape)<br>\nFile \"python2.7/site-packages/tensorflow/contrib/nccl/ops/gen_nccl_ops.py\", line 98, in nccl_broadcast<br>\n\"NcclBroadcast\", input=input, shape=shape, name=name)</p>\n<p><strong>which i guess rewrite graph maybe happen in nccl send/recv op.</strong></p>\n<p><strong>IndexedSlices are a sparse representation, right?</strong><br>\nYes,  excuse me for that i sayed that nccl in the issue above, actually it's contrib/all_reduce module, i fix the issue content error now, thanks.</p>", "body_text": "@poxvoculi thanks, i had already tried same fix with you before this issue.\nyesterday i tried your code, but failed again at same error: (use tf_benchmark:\nvariable_update: distributed_all_reduce\nall_reduce_spec: nccl/xring)\nUnimplementedError (see above for traceback): This op should be replaced during graph optimization.\ncaused by\nFile python2.7/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py\", line 781, in build_nccl_then_ring\nreturn _build_nccl_hybrid(input_tensors, red_op, upper_level_f)\nFile \"python2.7/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py\", line 749, in _build_nccl_hybrid\nbroadcast_src = nccl.broadcast(array_ops.identity(level_2_output[w]))\nFile \"python2.7/site-packages/tensorflow/contrib/nccl/python/ops/nccl_ops.py\", line 187, in broadcast\nreturn gen_nccl_ops.nccl_broadcast(input=tensor, shape=tensor.shape)\nFile \"python2.7/site-packages/tensorflow/contrib/nccl/ops/gen_nccl_ops.py\", line 98, in nccl_broadcast\n\"NcclBroadcast\", input=input, shape=shape, name=name)\nwhich i guess rewrite graph maybe happen in nccl send/recv op.\nIndexedSlices are a sparse representation, right?\nYes,  excuse me for that i sayed that nccl in the issue above, actually it's contrib/all_reduce module, i fix the issue content error now, thanks.", "body": "@poxvoculi thanks, i had already tried same fix with you before this issue. \r\nyesterday i tried your code, but failed again at same error: (use tf_benchmark: \r\nvariable_update: distributed_all_reduce\r\nall_reduce_spec: nccl/xring) \r\n\r\nUnimplementedError (see above for traceback): This op should be replaced during graph optimization. \r\ncaused by \r\nFile python2.7/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py\", line 781, in build_nccl_then_ring \r\nreturn _build_nccl_hybrid(input_tensors, red_op, upper_level_f) \r\nFile \"python2.7/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py\", line 749, in _build_nccl_hybrid \r\nbroadcast_src = nccl.broadcast(array_ops.identity(level_2_output[w])) \r\nFile \"python2.7/site-packages/tensorflow/contrib/nccl/python/ops/nccl_ops.py\", line 187, in broadcast \r\nreturn gen_nccl_ops.nccl_broadcast(input=tensor, shape=tensor.shape) \r\nFile \"python2.7/site-packages/tensorflow/contrib/nccl/ops/gen_nccl_ops.py\", line 98, in nccl_broadcast \r\n\"NcclBroadcast\", input=input, shape=shape, name=name) \r\n\r\n**which i guess rewrite graph maybe happen in nccl send/recv op.**\r\n\r\n**IndexedSlices are a sparse representation, right?**\r\nYes,  excuse me for that i sayed that nccl in the issue above, actually it's contrib/all_reduce module, i fix the issue content error now, thanks."}