{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/406728304", "html_url": "https://github.com/tensorflow/tensorflow/issues/18920#issuecomment-406728304", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18920", "id": 406728304, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNjcyODMwNA==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-20T21:12:39Z", "updated_at": "2018-07-20T21:12:39Z", "author_association": "MEMBER", "body_html": "<p>I think what you want is very reasonable, but you need different math than plain gradients. Once you do move beyond gradients the many known approaches to this are well-supported by TensorFlow.</p>\n<p>The problem lies in (hopefully) continuous functions which are not differentiable everywhere. Anytime you have control flow in a program you have a function which, though it might be continuous, is not guaranteed to have a derivative everywhere. For example, the function f(x) defined by f(x) = x^2 for x &lt; 0, f(x) = x otherwise is continuous, but has no derivative at the change point (0). What it can have is a directional derivative or a subgradient, which is what TensorFlow computes.</p>\n<p>If you think about it, by the definition of derivatives (epsilons and deltas, etc) if you make a small change to a number used in a predicate to decide the number of iterations in a loop the number of iterations will not change (for sufficiently small epsilon). There is only a set of measure zero of settings which will change the number of iterations.</p>\n<p>So if you want to optimize something which involves the number of iterations you need some other method. A popular one is to define auxiliary losses in your training problem (for example, make the probability of stopping at this loop iteration a function of some parameters, and then add a term to your loss function which maximizes this probability; this will encourage the model to stop earlier). A generalization of this is to write a differentiable upper bound on your number of iterations which you can then optimize. Work like <a href=\"https://arxiv.org/abs/1603.08983\" rel=\"nofollow\">adaptive computation time rnns</a> is based on this upper-bound approach.</p>\n<p>Another way of dealing with this non-differentiability is to simply pretend things are differentiable and not use a bound. For example, <a href=\"https://arxiv.org/abs/1308.3432\" rel=\"nofollow\">bengio</a> shows that in many cases you can approximate the \"gradient\" of a step function by pretending that the step function isn't there (the staight through estimator).</p>\n<p>Finally, approaches such as policy gradient and the REINFORCE algorithm (many sources on the internet; I like <a href=\"http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_4_policy_gradient.pdf\" rel=\"nofollow\">Sergey Levine's slides</a>) are a general (and so slow) way of optimizing these functions;  you can use them to approximate gradients to change your number of loop iterations.</p>\n<p>All of these approaches can be (and have been) implemented in TensorFlow, but none of them is just computing gradients. Because it requires some thought to decide what you should do we remain agnostic.</p>", "body_text": "I think what you want is very reasonable, but you need different math than plain gradients. Once you do move beyond gradients the many known approaches to this are well-supported by TensorFlow.\nThe problem lies in (hopefully) continuous functions which are not differentiable everywhere. Anytime you have control flow in a program you have a function which, though it might be continuous, is not guaranteed to have a derivative everywhere. For example, the function f(x) defined by f(x) = x^2 for x < 0, f(x) = x otherwise is continuous, but has no derivative at the change point (0). What it can have is a directional derivative or a subgradient, which is what TensorFlow computes.\nIf you think about it, by the definition of derivatives (epsilons and deltas, etc) if you make a small change to a number used in a predicate to decide the number of iterations in a loop the number of iterations will not change (for sufficiently small epsilon). There is only a set of measure zero of settings which will change the number of iterations.\nSo if you want to optimize something which involves the number of iterations you need some other method. A popular one is to define auxiliary losses in your training problem (for example, make the probability of stopping at this loop iteration a function of some parameters, and then add a term to your loss function which maximizes this probability; this will encourage the model to stop earlier). A generalization of this is to write a differentiable upper bound on your number of iterations which you can then optimize. Work like adaptive computation time rnns is based on this upper-bound approach.\nAnother way of dealing with this non-differentiability is to simply pretend things are differentiable and not use a bound. For example, bengio shows that in many cases you can approximate the \"gradient\" of a step function by pretending that the step function isn't there (the staight through estimator).\nFinally, approaches such as policy gradient and the REINFORCE algorithm (many sources on the internet; I like Sergey Levine's slides) are a general (and so slow) way of optimizing these functions;  you can use them to approximate gradients to change your number of loop iterations.\nAll of these approaches can be (and have been) implemented in TensorFlow, but none of them is just computing gradients. Because it requires some thought to decide what you should do we remain agnostic.", "body": "I think what you want is very reasonable, but you need different math than plain gradients. Once you do move beyond gradients the many known approaches to this are well-supported by TensorFlow.\r\n\r\nThe problem lies in (hopefully) continuous functions which are not differentiable everywhere. Anytime you have control flow in a program you have a function which, though it might be continuous, is not guaranteed to have a derivative everywhere. For example, the function f(x) defined by f(x) = x^2 for x < 0, f(x) = x otherwise is continuous, but has no derivative at the change point (0). What it can have is a directional derivative or a subgradient, which is what TensorFlow computes.\r\n\r\nIf you think about it, by the definition of derivatives (epsilons and deltas, etc) if you make a small change to a number used in a predicate to decide the number of iterations in a loop the number of iterations will not change (for sufficiently small epsilon). There is only a set of measure zero of settings which will change the number of iterations.\r\n\r\nSo if you want to optimize something which involves the number of iterations you need some other method. A popular one is to define auxiliary losses in your training problem (for example, make the probability of stopping at this loop iteration a function of some parameters, and then add a term to your loss function which maximizes this probability; this will encourage the model to stop earlier). A generalization of this is to write a differentiable upper bound on your number of iterations which you can then optimize. Work like [adaptive computation time rnns](https://arxiv.org/abs/1603.08983) is based on this upper-bound approach.\r\n\r\nAnother way of dealing with this non-differentiability is to simply pretend things are differentiable and not use a bound. For example, [bengio](https://arxiv.org/abs/1308.3432) shows that in many cases you can approximate the \"gradient\" of a step function by pretending that the step function isn't there (the staight through estimator).\r\n\r\nFinally, approaches such as policy gradient and the REINFORCE algorithm (many sources on the internet; I like [Sergey Levine's slides](http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_4_policy_gradient.pdf)) are a general (and so slow) way of optimizing these functions;  you can use them to approximate gradients to change your number of loop iterations.\r\n\r\nAll of these approaches can be (and have been) implemented in TensorFlow, but none of them is just computing gradients. Because it requires some thought to decide what you should do we remain agnostic."}