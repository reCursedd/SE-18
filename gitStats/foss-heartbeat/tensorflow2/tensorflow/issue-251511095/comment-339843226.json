{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/339843226", "html_url": "https://github.com/tensorflow/tensorflow/issues/12434#issuecomment-339843226", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12434", "id": 339843226, "node_id": "MDEyOklzc3VlQ29tbWVudDMzOTg0MzIyNg==", "user": {"login": "aakreidler", "id": 11166947, "node_id": "MDQ6VXNlcjExMTY2OTQ3", "avatar_url": "https://avatars1.githubusercontent.com/u/11166947?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aakreidler", "html_url": "https://github.com/aakreidler", "followers_url": "https://api.github.com/users/aakreidler/followers", "following_url": "https://api.github.com/users/aakreidler/following{/other_user}", "gists_url": "https://api.github.com/users/aakreidler/gists{/gist_id}", "starred_url": "https://api.github.com/users/aakreidler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aakreidler/subscriptions", "organizations_url": "https://api.github.com/users/aakreidler/orgs", "repos_url": "https://api.github.com/users/aakreidler/repos", "events_url": "https://api.github.com/users/aakreidler/events{/privacy}", "received_events_url": "https://api.github.com/users/aakreidler/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-27T01:03:23Z", "updated_at": "2017-10-27T01:03:23Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> Could OpenACC be used to optimize parallel tasks like matmuls and convolutions (IDK if you use a library) on a wider range of accelerators (like AMD GPUs), that the CUDA kernels and CPU-oriented code are not targeting? I think that this could complement the existing Tensorflow primitives for parallelization.</p>", "body_text": "@yaroslavvb Could OpenACC be used to optimize parallel tasks like matmuls and convolutions (IDK if you use a library) on a wider range of accelerators (like AMD GPUs), that the CUDA kernels and CPU-oriented code are not targeting? I think that this could complement the existing Tensorflow primitives for parallelization.", "body": "@yaroslavvb Could OpenACC be used to optimize parallel tasks like matmuls and convolutions (IDK if you use a library) on a wider range of accelerators (like AMD GPUs), that the CUDA kernels and CPU-oriented code are not targeting? I think that this could complement the existing Tensorflow primitives for parallelization."}