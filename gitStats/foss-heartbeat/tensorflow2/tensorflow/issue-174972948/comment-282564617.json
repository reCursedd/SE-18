{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/282564617", "html_url": "https://github.com/tensorflow/tensorflow/issues/4196#issuecomment-282564617", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4196", "id": 282564617, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MjU2NDYxNw==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-26T15:43:02Z", "updated_at": "2017-02-26T15:43:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p><code>CUBLAS_STATUS_NOT_INITIALIZED</code> can be thrown when you are out of memory, which can happen when you run two GPU TensorFlow processes in parallel. TensorFlow doesn't like sharing GPU memory with another process, the solution is to run only a single TensorFlow process per GPU (using <code>CUDA_VISIBLE_DEVICES=k</code> to restrict k'th process to k'th GPU)</p>", "body_text": "CUBLAS_STATUS_NOT_INITIALIZED can be thrown when you are out of memory, which can happen when you run two GPU TensorFlow processes in parallel. TensorFlow doesn't like sharing GPU memory with another process, the solution is to run only a single TensorFlow process per GPU (using CUDA_VISIBLE_DEVICES=k to restrict k'th process to k'th GPU)", "body": "`CUBLAS_STATUS_NOT_INITIALIZED` can be thrown when you are out of memory, which can happen when you run two GPU TensorFlow processes in parallel. TensorFlow doesn't like sharing GPU memory with another process, the solution is to run only a single TensorFlow process per GPU (using `CUDA_VISIBLE_DEVICES=k` to restrict k'th process to k'th GPU) "}