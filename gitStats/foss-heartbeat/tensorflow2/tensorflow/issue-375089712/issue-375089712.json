{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23352", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23352/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23352/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23352/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23352", "id": 375089712, "node_id": "MDU6SXNzdWUzNzUwODk3MTI=", "number": 23352, "title": "Wildly different quantization performance on different DenseNet169 models", "user": {"login": "wickstopher", "id": 1975810, "node_id": "MDQ6VXNlcjE5NzU4MTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1975810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wickstopher", "html_url": "https://github.com/wickstopher", "followers_url": "https://api.github.com/users/wickstopher/followers", "following_url": "https://api.github.com/users/wickstopher/following{/other_user}", "gists_url": "https://api.github.com/users/wickstopher/gists{/gist_id}", "starred_url": "https://api.github.com/users/wickstopher/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wickstopher/subscriptions", "organizations_url": "https://api.github.com/users/wickstopher/orgs", "repos_url": "https://api.github.com/users/wickstopher/repos", "events_url": "https://api.github.com/users/wickstopher/events{/privacy}", "received_events_url": "https://api.github.com/users/wickstopher/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-29T15:59:52Z", "updated_at": "2018-10-31T14:57:31Z", "closed_at": "2018-10-31T14:57:31Z", "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14 Mojave</li>\n<li>TensorFlow installed from (source or binary): binary (pip)</li>\n<li>TensorFlow version (use command below): 1.11.0</li>\n<li>Python version: 3.6.4</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nI have two models that I have trained using Keras. The two models use the same architecture (Keras' DenseNet169 implementation), however have a different number of target classes (80 in one case, 200 in the other case).</p>\n<ul>\n<li>\n<p>Converting both models to .pb format works just fine (identical performance in inference).</p>\n</li>\n<li>\n<p>Converting both models to .tflite format using TOCO works just fine (again, identical performance in inference).</p>\n</li>\n<li>\n<p>Converting the 80-class model to .tflite using quantization in TOCO works reasonably well (&lt;1% drop in top 3 accuracy).</p>\n</li>\n<li>\n<p>Converting the 200-class model to .tflite using quantization in TOCO goes off the rails (~30% drop in top 3 accuracy).</p>\n</li>\n</ul>\n<p>I'm using an identical conversion process for both models.</p>\n<p><code>toco --graph_def_file frozen_graph.pb --output_file quantized_graph.tflite --inference_type FLOAT --inference_input_type FLOAT --output_format TFLITE --input_arrays input_1 --output_arrays output_node0 --quantize True</code></p>\n<p><strong>Describe the expected behavior</strong></p>\n<p>I would expect that two models trained to similar accuracy on the same architecture should both quantize reasonably well, despite the number of prediction target classes in the fully-connected layers.</p>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14 Mojave\nTensorFlow installed from (source or binary): binary (pip)\nTensorFlow version (use command below): 1.11.0\nPython version: 3.6.4\n\nDescribe the current behavior\nI have two models that I have trained using Keras. The two models use the same architecture (Keras' DenseNet169 implementation), however have a different number of target classes (80 in one case, 200 in the other case).\n\n\nConverting both models to .pb format works just fine (identical performance in inference).\n\n\nConverting both models to .tflite format using TOCO works just fine (again, identical performance in inference).\n\n\nConverting the 80-class model to .tflite using quantization in TOCO works reasonably well (<1% drop in top 3 accuracy).\n\n\nConverting the 200-class model to .tflite using quantization in TOCO goes off the rails (~30% drop in top 3 accuracy).\n\n\nI'm using an identical conversion process for both models.\ntoco --graph_def_file frozen_graph.pb --output_file quantized_graph.tflite --inference_type FLOAT --inference_input_type FLOAT --output_format TFLITE --input_arrays input_1 --output_arrays output_node0 --quantize True\nDescribe the expected behavior\nI would expect that two models trained to similar accuracy on the same architecture should both quantize reasonably well, despite the number of prediction target classes in the fully-connected layers.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14 Mojave\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): 1.11.0\r\n- Python version: 3.6.4\r\n\r\n**Describe the current behavior**\r\nI have two models that I have trained using Keras. The two models use the same architecture (Keras' DenseNet169 implementation), however have a different number of target classes (80 in one case, 200 in the other case).\r\n\r\n* Converting both models to .pb format works just fine (identical performance in inference).\r\n\r\n* Converting both models to .tflite format using TOCO works just fine (again, identical performance in inference).\r\n\r\n* Converting the 80-class model to .tflite using quantization in TOCO works reasonably well (<1% drop in top 3 accuracy).\r\n\r\n* Converting the 200-class model to .tflite using quantization in TOCO goes off the rails (~30% drop in top 3 accuracy).\r\n\r\nI'm using an identical conversion process for both models.\r\n\r\n`toco --graph_def_file frozen_graph.pb --output_file quantized_graph.tflite --inference_type FLOAT --inference_input_type FLOAT --output_format TFLITE --input_arrays input_1 --output_arrays output_node0 --quantize True`\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect that two models trained to similar accuracy on the same architecture should both quantize reasonably well, despite the number of prediction target classes in the fully-connected layers.\r\n\r\n"}