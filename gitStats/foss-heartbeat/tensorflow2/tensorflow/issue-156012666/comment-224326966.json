{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/224326966", "html_url": "https://github.com/tensorflow/tensorflow/issues/2441#issuecomment-224326966", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2441", "id": 224326966, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNDMyNjk2Ng==", "user": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-07T15:58:09Z", "updated_at": "2016-06-07T15:58:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If you <code>tf.add_n</code> the losses together, you fuse the two different backward passes into a single backward pass which can no longer be parallelized across multiple GPUs (TensorFlow currently does not split single ops across multiple GPUs).  Thus, one of the GPUs is likely running idle during the backward pass.</p>", "body_text": "If you tf.add_n the losses together, you fuse the two different backward passes into a single backward pass which can no longer be parallelized across multiple GPUs (TensorFlow currently does not split single ops across multiple GPUs).  Thus, one of the GPUs is likely running idle during the backward pass.", "body": "If you `tf.add_n` the losses together, you fuse the two different backward passes into a single backward pass which can no longer be parallelized across multiple GPUs (TensorFlow currently does not split single ops across multiple GPUs).  Thus, one of the GPUs is likely running idle during the backward pass.\n"}