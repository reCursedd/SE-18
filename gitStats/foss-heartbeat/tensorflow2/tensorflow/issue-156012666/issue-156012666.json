{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2441", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2441/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2441/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2441/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2441", "id": 156012666, "node_id": "MDU6SXNzdWUxNTYwMTI2NjY=", "number": 2441, "title": "Understanding cause of bad performance", "user": {"login": "cgel", "id": 11093686, "node_id": "MDQ6VXNlcjExMDkzNjg2", "avatar_url": "https://avatars0.githubusercontent.com/u/11093686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgel", "html_url": "https://github.com/cgel", "followers_url": "https://api.github.com/users/cgel/followers", "following_url": "https://api.github.com/users/cgel/following{/other_user}", "gists_url": "https://api.github.com/users/cgel/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgel/subscriptions", "organizations_url": "https://api.github.com/users/cgel/orgs", "repos_url": "https://api.github.com/users/cgel/repos", "events_url": "https://api.github.com/users/cgel/events{/privacy}", "received_events_url": "https://api.github.com/users/cgel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2016-05-20T17:28:22Z", "updated_at": "2018-09-11T06:24:43Z", "closed_at": "2016-07-11T21:51:59Z", "author_association": "NONE", "body_html": "<p>I am training a convnet with multilple gpus and was using the cifar10 model as an example. It computes the gradients in every tower, stitches them and averages them. But that is mathematically equivalent to defining <code>total_loss = tf.add_n(tower_loss_list)</code> so I thought I would just do that.<br>\nBut this implementation with 2 gpus runs at 1/2 the speed of the single gpu implementation. I am guessing the reason is that the gradient ops placement is very bad, and forces a lot data to be moved around.<br>\nDo you also think that is the reason?<br>\nIf so, what could be done to improve the automatic device assignment?</p>", "body_text": "I am training a convnet with multilple gpus and was using the cifar10 model as an example. It computes the gradients in every tower, stitches them and averages them. But that is mathematically equivalent to defining total_loss = tf.add_n(tower_loss_list) so I thought I would just do that.\nBut this implementation with 2 gpus runs at 1/2 the speed of the single gpu implementation. I am guessing the reason is that the gradient ops placement is very bad, and forces a lot data to be moved around.\nDo you also think that is the reason?\nIf so, what could be done to improve the automatic device assignment?", "body": "I am training a convnet with multilple gpus and was using the cifar10 model as an example. It computes the gradients in every tower, stitches them and averages them. But that is mathematically equivalent to defining `total_loss = tf.add_n(tower_loss_list)` so I thought I would just do that.\nBut this implementation with 2 gpus runs at 1/2 the speed of the single gpu implementation. I am guessing the reason is that the gradient ops placement is very bad, and forces a lot data to be moved around.\nDo you also think that is the reason?\nIf so, what could be done to improve the automatic device assignment?\n"}