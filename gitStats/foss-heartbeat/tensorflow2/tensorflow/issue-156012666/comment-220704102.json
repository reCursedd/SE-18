{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/220704102", "html_url": "https://github.com/tensorflow/tensorflow/issues/2441#issuecomment-220704102", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2441", "id": 220704102, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDcwNDEwMg==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-20T19:58:37Z", "updated_at": "2016-05-20T19:58:37Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Did you change from having one <code>Optimizer</code> per tower to a single <code>Optimizer</code>? In that case, it's possible that all of the gradients are being computed on a single GPU (most likely <code>/gpu:0</code>), because the <code>colocate_gradients_with_ops</code> argument to <code>Optimizer.minimize()</code>/<code>Optimizer.compute_gradients()</code> defaults to <code>False</code>, and so the gradient ops will default to running on a single device.  You could try switching that option to <code>True</code> to see if it makes a difference.</p>", "body_text": "Did you change from having one Optimizer per tower to a single Optimizer? In that case, it's possible that all of the gradients are being computed on a single GPU (most likely /gpu:0), because the colocate_gradients_with_ops argument to Optimizer.minimize()/Optimizer.compute_gradients() defaults to False, and so the gradient ops will default to running on a single device.  You could try switching that option to True to see if it makes a difference.", "body": "Did you change from having one `Optimizer` per tower to a single `Optimizer`? In that case, it's possible that all of the gradients are being computed on a single GPU (most likely `/gpu:0`), because the `colocate_gradients_with_ops` argument to `Optimizer.minimize()`/`Optimizer.compute_gradients()` defaults to `False`, and so the gradient ops will default to running on a single device.  You could try switching that option to `True` to see if it makes a difference.\n"}