{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227229182", "html_url": "https://github.com/tensorflow/tensorflow/issues/600#issuecomment-227229182", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/600", "id": 227229182, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzIyOTE4Mg==", "user": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-20T18:33:33Z", "updated_at": "2016-06-20T18:33:33Z", "author_association": "MEMBER", "body_html": "<p>It will, but the automatic placement currently might not be optimal. You can place manually with tf.device and that could make it faster (esp. if you place different LSTM layers on separate GPUs, as they can often work in parallel). I think this is a good question, but this bug is not the best place for it, as it's mostly unrelated and will be hard to find. If you want to ask about speeding up training, maybe open a stack overflow thread?</p>", "body_text": "It will, but the automatic placement currently might not be optimal. You can place manually with tf.device and that could make it faster (esp. if you place different LSTM layers on separate GPUs, as they can often work in parallel). I think this is a good question, but this bug is not the best place for it, as it's mostly unrelated and will be hard to find. If you want to ask about speeding up training, maybe open a stack overflow thread?", "body": "It will, but the automatic placement currently might not be optimal. You can place manually with tf.device and that could make it faster (esp. if you place different LSTM layers on separate GPUs, as they can often work in parallel). I think this is a good question, but this bug is not the best place for it, as it's mostly unrelated and will be hard to find. If you want to ask about speeding up training, maybe open a stack overflow thread?\n"}