{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/295779638", "html_url": "https://github.com/tensorflow/tensorflow/issues/9322#issuecomment-295779638", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9322", "id": 295779638, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NTc3OTYzOA==", "user": {"login": "taion", "id": 3112159, "node_id": "MDQ6VXNlcjMxMTIxNTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/3112159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taion", "html_url": "https://github.com/taion", "followers_url": "https://api.github.com/users/taion/followers", "following_url": "https://api.github.com/users/taion/following{/other_user}", "gists_url": "https://api.github.com/users/taion/gists{/gist_id}", "starred_url": "https://api.github.com/users/taion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taion/subscriptions", "organizations_url": "https://api.github.com/users/taion/orgs", "repos_url": "https://api.github.com/users/taion/repos", "events_url": "https://api.github.com/users/taion/events{/privacy}", "received_events_url": "https://api.github.com/users/taion/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-20T15:28:58Z", "updated_at": "2017-04-20T15:28:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Turns out I don't need to re-build TF after all. In fact it looks like all I need to do is to set <code>TF_ENABLE_WINOGRAD_NONFUSED=1</code>.</p>\n<p>I get comparable numbers to what you report above when using the 1.0.1 Docker image, and when installing 1.1.0rc2 from pip.</p>\n<p>Against <a href=\"https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue\">https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue</a> as above:</p>\n<pre><code>[2017-04-20 15:25:47,770] INFO in train: epoch 0, batch 200: 0.162s\n[2017-04-20 15:25:47,934] INFO in train: epoch 0, batch 201: 0.164s\n[2017-04-20 15:25:48,100] INFO in train: epoch 0, batch 202: 0.165s\n[2017-04-20 15:25:48,266] INFO in train: epoch 0, batch 203: 0.166s\n[2017-04-20 15:25:48,431] INFO in train: epoch 0, batch 204: 0.164s\n[2017-04-20 15:25:48,594] INFO in train: epoch 0, batch 205: 0.164s\n[2017-04-20 15:25:48,761] INFO in train: epoch 0, batch 206: 0.167s\n[2017-04-20 15:25:48,926] INFO in train: epoch 0, batch 207: 0.164s\n[2017-04-20 15:25:49,089] INFO in train: epoch 0, batch 208: 0.163s\n[2017-04-20 15:25:49,254] INFO in train: epoch 0, batch 209: 0.165s\n</code></pre>\n<p>I can see the comment in the source code regarding testing, but this seems to make a significant difference in performance when using common model types that heavily use 3x3 convolutions.</p>\n<p>How can we get this added to the TF documentation?</p>", "body_text": "Turns out I don't need to re-build TF after all. In fact it looks like all I need to do is to set TF_ENABLE_WINOGRAD_NONFUSED=1.\nI get comparable numbers to what you report above when using the 1.0.1 Docker image, and when installing 1.1.0rc2 from pip.\nAgainst https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue as above:\n[2017-04-20 15:25:47,770] INFO in train: epoch 0, batch 200: 0.162s\n[2017-04-20 15:25:47,934] INFO in train: epoch 0, batch 201: 0.164s\n[2017-04-20 15:25:48,100] INFO in train: epoch 0, batch 202: 0.165s\n[2017-04-20 15:25:48,266] INFO in train: epoch 0, batch 203: 0.166s\n[2017-04-20 15:25:48,431] INFO in train: epoch 0, batch 204: 0.164s\n[2017-04-20 15:25:48,594] INFO in train: epoch 0, batch 205: 0.164s\n[2017-04-20 15:25:48,761] INFO in train: epoch 0, batch 206: 0.167s\n[2017-04-20 15:25:48,926] INFO in train: epoch 0, batch 207: 0.164s\n[2017-04-20 15:25:49,089] INFO in train: epoch 0, batch 208: 0.163s\n[2017-04-20 15:25:49,254] INFO in train: epoch 0, batch 209: 0.165s\n\nI can see the comment in the source code regarding testing, but this seems to make a significant difference in performance when using common model types that heavily use 3x3 convolutions.\nHow can we get this added to the TF documentation?", "body": "Turns out I don't need to re-build TF after all. In fact it looks like all I need to do is to set `TF_ENABLE_WINOGRAD_NONFUSED=1`.\r\n\r\nI get comparable numbers to what you report above when using the 1.0.1 Docker image, and when installing 1.1.0rc2 from pip.\r\n\r\nAgainst https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue as above:\r\n\r\n```\r\n[2017-04-20 15:25:47,770] INFO in train: epoch 0, batch 200: 0.162s\r\n[2017-04-20 15:25:47,934] INFO in train: epoch 0, batch 201: 0.164s\r\n[2017-04-20 15:25:48,100] INFO in train: epoch 0, batch 202: 0.165s\r\n[2017-04-20 15:25:48,266] INFO in train: epoch 0, batch 203: 0.166s\r\n[2017-04-20 15:25:48,431] INFO in train: epoch 0, batch 204: 0.164s\r\n[2017-04-20 15:25:48,594] INFO in train: epoch 0, batch 205: 0.164s\r\n[2017-04-20 15:25:48,761] INFO in train: epoch 0, batch 206: 0.167s\r\n[2017-04-20 15:25:48,926] INFO in train: epoch 0, batch 207: 0.164s\r\n[2017-04-20 15:25:49,089] INFO in train: epoch 0, batch 208: 0.163s\r\n[2017-04-20 15:25:49,254] INFO in train: epoch 0, batch 209: 0.165s\r\n```\r\n\r\nI can see the comment in the source code regarding testing, but this seems to make a significant difference in performance when using common model types that heavily use 3x3 convolutions.\r\n\r\nHow can we get this added to the TF documentation?"}