{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/295578845", "html_url": "https://github.com/tensorflow/tensorflow/issues/9322#issuecomment-295578845", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9322", "id": 295578845, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NTU3ODg0NQ==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-20T04:44:04Z", "updated_at": "2017-04-20T04:47:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Since it's slow even with a constant fake input and 100% GPU util, it's probably not a problem with feed_dict or input, right?</p>\n<p>Also I'm able to reproduce the 60% performance difference with my own TF code written fully independently from the above TF code. So it's unlikely to be a problem of model definition, unless both of us interpret the pytorch code in the wrong way.</p>\n<p>Slow speed at high GPU util may be a result of using inefficient kernels. For example by setting <code>cudnn.benchmark=False</code> (disable autotuner) I can make the above pytorch code 2x slower, while still taking 100% GPU utilization -- maybe that's something to look at.</p>", "body_text": "Since it's slow even with a constant fake input and 100% GPU util, it's probably not a problem with feed_dict or input, right?\nAlso I'm able to reproduce the 60% performance difference with my own TF code written fully independently from the above TF code. So it's unlikely to be a problem of model definition, unless both of us interpret the pytorch code in the wrong way.\nSlow speed at high GPU util may be a result of using inefficient kernels. For example by setting cudnn.benchmark=False (disable autotuner) I can make the above pytorch code 2x slower, while still taking 100% GPU utilization -- maybe that's something to look at.", "body": "Since it's slow even with a constant fake input and 100% GPU util, it's probably not a problem with feed_dict or input, right? \r\n\r\nAlso I'm able to reproduce the 60% performance difference with my own TF code written fully independently from the above TF code. So it's unlikely to be a problem of model definition, unless both of us interpret the pytorch code in the wrong way.\r\n\r\nSlow speed at high GPU util may be a result of using inefficient kernels. For example by setting `cudnn.benchmark=False` (disable autotuner) I can make the above pytorch code 2x slower, while still taking 100% GPU utilization -- maybe that's something to look at."}