{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/295773467", "html_url": "https://github.com/tensorflow/tensorflow/issues/9322#issuecomment-295773467", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9322", "id": 295773467, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NTc3MzQ2Nw==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-20T15:13:36Z", "updated_at": "2017-04-20T15:13:36Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3112159\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/taion\">@taion</a>   I thought your progress bars were cool, they are kind of fun when logging that often.  It was  1am when I ran it and my terminal was like a black and white explosion of moving stuff.  My first thought was that my scripts need to be much cooler.</p>\n<p>Yeah that TensorBoard thing got me as well.  I don't want to talk about it.  :-)</p>\n<p>Apologies again.  When I said apples-to-apples, I meant in the first post I was running TF with a constant and PyTorch with real data.  Turns out the results were similar.  I honestly do not know if the queues will help over <code>feed_dict</code> with the GPU at 100%.  I do know that every time I see it I assume it is a problem and it is good practice to just not use the <code>feed_dict</code> approach.  I hope I am being clear that I don't know in this instance.  I would do it just so I knew it was not a problem.  If I was faster with TF, I would \"hack\" it in and try it.</p>\n<p>Thank you for all the feedback Jimmy, you are a nice person.  It is really hard to work through this stuff with \"strangers\" and trying to get on the same page.  You likely know way more than I do but I have access to some code and happen to be connected to recent changes.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=51059\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cancan101\">@cancan101</a> Yup.  Once we are sure WINOGRAD is working in all instances it will just be the default.  The AUTOTUNE is not really needed but you could play with it.  TF_CUDNN_WORKSPACE_LIMIT_IN_MB is not something I have used.  I will include them in the perf guide update next week and the ones we use in the benchmark is embedded in the code.  I shared them with this group because all of you were curious and I felt knowledgeable enough (more than me in many ways) to turn them on or off if you have issues, e.g. things don't converge or things \"explode\".</p>\n<p>This is great feedback.  Yes, I type too much.</p>", "body_text": "@taion   I thought your progress bars were cool, they are kind of fun when logging that often.  It was  1am when I ran it and my terminal was like a black and white explosion of moving stuff.  My first thought was that my scripts need to be much cooler.\nYeah that TensorBoard thing got me as well.  I don't want to talk about it.  :-)\nApologies again.  When I said apples-to-apples, I meant in the first post I was running TF with a constant and PyTorch with real data.  Turns out the results were similar.  I honestly do not know if the queues will help over feed_dict with the GPU at 100%.  I do know that every time I see it I assume it is a problem and it is good practice to just not use the feed_dict approach.  I hope I am being clear that I don't know in this instance.  I would do it just so I knew it was not a problem.  If I was faster with TF, I would \"hack\" it in and try it.\nThank you for all the feedback Jimmy, you are a nice person.  It is really hard to work through this stuff with \"strangers\" and trying to get on the same page.  You likely know way more than I do but I have access to some code and happen to be connected to recent changes.\n@cancan101 Yup.  Once we are sure WINOGRAD is working in all instances it will just be the default.  The AUTOTUNE is not really needed but you could play with it.  TF_CUDNN_WORKSPACE_LIMIT_IN_MB is not something I have used.  I will include them in the perf guide update next week and the ones we use in the benchmark is embedded in the code.  I shared them with this group because all of you were curious and I felt knowledgeable enough (more than me in many ways) to turn them on or off if you have issues, e.g. things don't converge or things \"explode\".\nThis is great feedback.  Yes, I type too much.", "body": "@taion   I thought your progress bars were cool, they are kind of fun when logging that often.  It was  1am when I ran it and my terminal was like a black and white explosion of moving stuff.  My first thought was that my scripts need to be much cooler.  \r\n\r\nYeah that TensorBoard thing got me as well.  I don't want to talk about it.  :-)  \r\n\r\nApologies again.  When I said apples-to-apples, I meant in the first post I was running TF with a constant and PyTorch with real data.  Turns out the results were similar.  I honestly do not know if the queues will help over `feed_dict` with the GPU at 100%.  I do know that every time I see it I assume it is a problem and it is good practice to just not use the `feed_dict` approach.  I hope I am being clear that I don't know in this instance.  I would do it just so I knew it was not a problem.  If I was faster with TF, I would \"hack\" it in and try it.  \r\n\r\nThank you for all the feedback Jimmy, you are a nice person.  It is really hard to work through this stuff with \"strangers\" and trying to get on the same page.  You likely know way more than I do but I have access to some code and happen to be connected to recent changes.\r\n\r\n@cancan101 Yup.  Once we are sure WINOGRAD is working in all instances it will just be the default.  The AUTOTUNE is not really needed but you could play with it.  TF_CUDNN_WORKSPACE_LIMIT_IN_MB is not something I have used.  I will include them in the perf guide update next week and the ones we use in the benchmark is embedded in the code.  I shared them with this group because all of you were curious and I felt knowledgeable enough (more than me in many ways) to turn them on or off if you have issues, e.g. things don't converge or things \"explode\".  \r\n\r\nThis is great feedback.  Yes, I type too much.  "}