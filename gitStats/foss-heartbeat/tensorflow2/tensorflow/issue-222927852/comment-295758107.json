{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/295758107", "html_url": "https://github.com/tensorflow/tensorflow/issues/9322#issuecomment-295758107", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9322", "id": 295758107, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NTc1ODEwNw==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-20T14:28:57Z", "updated_at": "2017-04-20T14:28:57Z", "author_association": "MEMBER", "body_html": "<p>If you are doing actual research, I would increase the batch-size (PyTorch as well) unless you think it will harm accuracy.  I did not check memory usage but if you want to train as fast as possible that is sometimes overlooked.</p>\n<p>Here are also some other flags we use in the benchmarks.  They did not seem to have an impact on K80 but I did not extensively.</p>\n<p>config = tf.ConfigProto()<br>\nconfig.allow_soft_placement = True<br>\nconfig.intra_op_parallelism_threads = 1<br>\nconfig.inter_op_parallelism_threads = 0  &lt;-- let the system figure it out<br>\nconfig.gpu_options.force_gpu_compatible = True  &lt;-- requires master head from the past few days</p>\n<p>This env variable might be of interest.<br>\nos.environ['TF_AUTOTUNE_THRESHOLD']<br>\nIt defaults to 1 if I understand the underlying code so there is likely no need to set it but it might be interesting.</p>", "body_text": "If you are doing actual research, I would increase the batch-size (PyTorch as well) unless you think it will harm accuracy.  I did not check memory usage but if you want to train as fast as possible that is sometimes overlooked.\nHere are also some other flags we use in the benchmarks.  They did not seem to have an impact on K80 but I did not extensively.\nconfig = tf.ConfigProto()\nconfig.allow_soft_placement = True\nconfig.intra_op_parallelism_threads = 1\nconfig.inter_op_parallelism_threads = 0  <-- let the system figure it out\nconfig.gpu_options.force_gpu_compatible = True  <-- requires master head from the past few days\nThis env variable might be of interest.\nos.environ['TF_AUTOTUNE_THRESHOLD']\nIt defaults to 1 if I understand the underlying code so there is likely no need to set it but it might be interesting.", "body": "If you are doing actual research, I would increase the batch-size (PyTorch as well) unless you think it will harm accuracy.  I did not check memory usage but if you want to train as fast as possible that is sometimes overlooked.  \r\n\r\nHere are also some other flags we use in the benchmarks.  They did not seem to have an impact on K80 but I did not extensively.  \r\n\r\n  config = tf.ConfigProto()\r\n  config.allow_soft_placement = True\r\n  config.intra_op_parallelism_threads = 1\r\n  config.inter_op_parallelism_threads = 0  <-- let the system figure it out\r\n  config.gpu_options.force_gpu_compatible = True  <-- requires master head from the past few days\r\n\r\nThis env variable might be of interest.\r\nos.environ['TF_AUTOTUNE_THRESHOLD'] \r\nIt defaults to 1 if I understand the underlying code so there is likely no need to set it but it might be interesting.  \r\n\r\n\r\n\r\n\r\n"}