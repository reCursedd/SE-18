{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/295775991", "html_url": "https://github.com/tensorflow/tensorflow/issues/9322#issuecomment-295775991", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9322", "id": 295775991, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NTc3NTk5MQ==", "user": {"login": "taion", "id": 3112159, "node_id": "MDQ6VXNlcjMxMTIxNTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/3112159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taion", "html_url": "https://github.com/taion", "followers_url": "https://api.github.com/users/taion/followers", "following_url": "https://api.github.com/users/taion/following{/other_user}", "gists_url": "https://api.github.com/users/taion/gists{/gist_id}", "starred_url": "https://api.github.com/users/taion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taion/subscriptions", "organizations_url": "https://api.github.com/users/taion/orgs", "repos_url": "https://api.github.com/users/taion/repos", "events_url": "https://api.github.com/users/taion/events{/privacy}", "received_events_url": "https://api.github.com/users/taion/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-20T15:20:16Z", "updated_at": "2017-04-20T15:20:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The queue-based data loading from the tutorial appears to be comparable to what I had before with <code>feed_dict</code>.</p>\n<p>Using the same setup as above (TF 1.0.1 from the Docker image on a p2.xlarge).</p>\n<p>Queue (<a href=\"https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue\">https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue</a>):</p>\n<pre><code>[2017-04-20 15:16:30,871] INFO in train: epoch 0, batch 200: 0.268s\n[2017-04-20 15:16:31,141] INFO in train: epoch 0, batch 201: 0.269s\n[2017-04-20 15:16:31,416] INFO in train: epoch 0, batch 202: 0.275s\n[2017-04-20 15:16:31,691] INFO in train: epoch 0, batch 203: 0.274s\n[2017-04-20 15:16:31,966] INFO in train: epoch 0, batch 204: 0.275s\n[2017-04-20 15:16:32,239] INFO in train: epoch 0, batch 205: 0.273s\n[2017-04-20 15:16:32,513] INFO in train: epoch 0, batch 206: 0.274s\n[2017-04-20 15:16:32,791] INFO in train: epoch 0, batch 207: 0.277s\n[2017-04-20 15:16:33,066] INFO in train: epoch 0, batch 208: 0.275s\n[2017-04-20 15:16:33,335] INFO in train: epoch 0, batch 209: 0.269s\n</code></pre>\n<p><code>feed_dict</code> (<a href=\"https://github.com/4Catalyzer/dl-papers/tree/benchmark-feed-data-only\">https://github.com/4Catalyzer/dl-papers/tree/benchmark-feed-data-only</a>):</p>\n<pre><code>[2017-04-20 15:18:00,192] INFO in train: epoch 0, batch 200: 0.275s\n[2017-04-20 15:18:00,470] INFO in train: epoch 0, batch 201: 0.278s\n[2017-04-20 15:18:00,751] INFO in train: epoch 0, batch 202: 0.281s\n[2017-04-20 15:18:01,029] INFO in train: epoch 0, batch 203: 0.277s\n[2017-04-20 15:18:01,309] INFO in train: epoch 0, batch 204: 0.280s\n[2017-04-20 15:18:01,583] INFO in train: epoch 0, batch 205: 0.274s\n[2017-04-20 15:18:01,859] INFO in train: epoch 0, batch 206: 0.276s\n[2017-04-20 15:18:02,138] INFO in train: epoch 0, batch 207: 0.279s\n[2017-04-20 15:18:02,414] INFO in train: epoch 0, batch 208: 0.275s\n[2017-04-20 15:18:02,690] INFO in train: epoch 0, batch 209: 0.276s\n</code></pre>\n<p>This doesn't say anything on TF v PyTorch, but it's consistent with what we saw earlier in there not being a huge performance gap between <code>feed_dict</code> and queues.</p>", "body_text": "The queue-based data loading from the tutorial appears to be comparable to what I had before with feed_dict.\nUsing the same setup as above (TF 1.0.1 from the Docker image on a p2.xlarge).\nQueue (https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue):\n[2017-04-20 15:16:30,871] INFO in train: epoch 0, batch 200: 0.268s\n[2017-04-20 15:16:31,141] INFO in train: epoch 0, batch 201: 0.269s\n[2017-04-20 15:16:31,416] INFO in train: epoch 0, batch 202: 0.275s\n[2017-04-20 15:16:31,691] INFO in train: epoch 0, batch 203: 0.274s\n[2017-04-20 15:16:31,966] INFO in train: epoch 0, batch 204: 0.275s\n[2017-04-20 15:16:32,239] INFO in train: epoch 0, batch 205: 0.273s\n[2017-04-20 15:16:32,513] INFO in train: epoch 0, batch 206: 0.274s\n[2017-04-20 15:16:32,791] INFO in train: epoch 0, batch 207: 0.277s\n[2017-04-20 15:16:33,066] INFO in train: epoch 0, batch 208: 0.275s\n[2017-04-20 15:16:33,335] INFO in train: epoch 0, batch 209: 0.269s\n\nfeed_dict (https://github.com/4Catalyzer/dl-papers/tree/benchmark-feed-data-only):\n[2017-04-20 15:18:00,192] INFO in train: epoch 0, batch 200: 0.275s\n[2017-04-20 15:18:00,470] INFO in train: epoch 0, batch 201: 0.278s\n[2017-04-20 15:18:00,751] INFO in train: epoch 0, batch 202: 0.281s\n[2017-04-20 15:18:01,029] INFO in train: epoch 0, batch 203: 0.277s\n[2017-04-20 15:18:01,309] INFO in train: epoch 0, batch 204: 0.280s\n[2017-04-20 15:18:01,583] INFO in train: epoch 0, batch 205: 0.274s\n[2017-04-20 15:18:01,859] INFO in train: epoch 0, batch 206: 0.276s\n[2017-04-20 15:18:02,138] INFO in train: epoch 0, batch 207: 0.279s\n[2017-04-20 15:18:02,414] INFO in train: epoch 0, batch 208: 0.275s\n[2017-04-20 15:18:02,690] INFO in train: epoch 0, batch 209: 0.276s\n\nThis doesn't say anything on TF v PyTorch, but it's consistent with what we saw earlier in there not being a huge performance gap between feed_dict and queues.", "body": "The queue-based data loading from the tutorial appears to be comparable to what I had before with `feed_dict`.\r\n\r\nUsing the same setup as above (TF 1.0.1 from the Docker image on a p2.xlarge).\r\n\r\nQueue (https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue):\r\n```\r\n[2017-04-20 15:16:30,871] INFO in train: epoch 0, batch 200: 0.268s\r\n[2017-04-20 15:16:31,141] INFO in train: epoch 0, batch 201: 0.269s\r\n[2017-04-20 15:16:31,416] INFO in train: epoch 0, batch 202: 0.275s\r\n[2017-04-20 15:16:31,691] INFO in train: epoch 0, batch 203: 0.274s\r\n[2017-04-20 15:16:31,966] INFO in train: epoch 0, batch 204: 0.275s\r\n[2017-04-20 15:16:32,239] INFO in train: epoch 0, batch 205: 0.273s\r\n[2017-04-20 15:16:32,513] INFO in train: epoch 0, batch 206: 0.274s\r\n[2017-04-20 15:16:32,791] INFO in train: epoch 0, batch 207: 0.277s\r\n[2017-04-20 15:16:33,066] INFO in train: epoch 0, batch 208: 0.275s\r\n[2017-04-20 15:16:33,335] INFO in train: epoch 0, batch 209: 0.269s\r\n```\r\n\r\n`feed_dict` (https://github.com/4Catalyzer/dl-papers/tree/benchmark-feed-data-only):\r\n```\r\n[2017-04-20 15:18:00,192] INFO in train: epoch 0, batch 200: 0.275s\r\n[2017-04-20 15:18:00,470] INFO in train: epoch 0, batch 201: 0.278s\r\n[2017-04-20 15:18:00,751] INFO in train: epoch 0, batch 202: 0.281s\r\n[2017-04-20 15:18:01,029] INFO in train: epoch 0, batch 203: 0.277s\r\n[2017-04-20 15:18:01,309] INFO in train: epoch 0, batch 204: 0.280s\r\n[2017-04-20 15:18:01,583] INFO in train: epoch 0, batch 205: 0.274s\r\n[2017-04-20 15:18:01,859] INFO in train: epoch 0, batch 206: 0.276s\r\n[2017-04-20 15:18:02,138] INFO in train: epoch 0, batch 207: 0.279s\r\n[2017-04-20 15:18:02,414] INFO in train: epoch 0, batch 208: 0.275s\r\n[2017-04-20 15:18:02,690] INFO in train: epoch 0, batch 209: 0.276s\r\n```\r\n\r\nThis doesn't say anything on TF v PyTorch, but it's consistent with what we saw earlier in there not being a huge performance gap between `feed_dict` and queues."}