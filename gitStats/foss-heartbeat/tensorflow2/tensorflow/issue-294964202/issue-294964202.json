{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16813", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16813/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16813/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16813/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16813", "id": 294964202, "node_id": "MDU6SXNzdWUyOTQ5NjQyMDI=", "number": 16813, "title": "TensorFlow Lite for Inception v3 - Squeeze operator isn't supported", "user": {"login": "Johnson145", "id": 6339078, "node_id": "MDQ6VXNlcjYzMzkwNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6339078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Johnson145", "html_url": "https://github.com/Johnson145", "followers_url": "https://api.github.com/users/Johnson145/followers", "following_url": "https://api.github.com/users/Johnson145/following{/other_user}", "gists_url": "https://api.github.com/users/Johnson145/gists{/gist_id}", "starred_url": "https://api.github.com/users/Johnson145/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Johnson145/subscriptions", "organizations_url": "https://api.github.com/users/Johnson145/orgs", "repos_url": "https://api.github.com/users/Johnson145/repos", "events_url": "https://api.github.com/users/Johnson145/events{/privacy}", "received_events_url": "https://api.github.com/users/Johnson145/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2018-02-07T00:35:33Z", "updated_at": "2018-07-12T22:46:04Z", "closed_at": "2018-07-12T22:46:04Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nNo, I haven't used any custom code for this.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nr1.5 (<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/6c5063a3f099c302412fcefa17edb2efa9921f01/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/6c5063a3f099c302412fcefa17edb2efa9921f01\"><tt>6c5063a</tt></a>)</li>\n<li><strong>Python version</strong>:<br>\n3</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.9.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\ngcc4.4</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n9.0/7.0</li>\n<li><strong>GPU model and memory</strong>:<br>\nGTX 1080 8GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>bazel-bin/tensorflow/contrib/lite/toco/toco \\\n  --input_file=inception-retrained-graph_freezed.pb \\\n  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\n  --output_file=inception-retrained-graph.tflite --inference_type=FLOAT \\\n  --input_type=FLOAT --input_arrays=input \\\n  --output_arrays=InceptionV3/Predictions/Reshape_1 --input_shapes=1,299,299,3\n</code></pre>\n<h3>Describe the problem</h3>\n<p>I tried to use the above command to convert a retrained inception v3 model into the new tflite format. The input graph has already been freezed. The general process is described in <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite#freeze-graph\">this tutorial</a>. However, I'm not able to finish the conversion as the tool complains that the Squeeze operator isn't supported. <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md\">According to this guide</a> the script should be able to remove the squeeze operation. <a href=\"https://github.com/tensorflow/tensorflow/issues/16001#issuecomment-356635651\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/16001/hovercard\">This comment</a> suggests that it may not always be possible to remove it. <a href=\"https://www.tensorflow.org/mobile/tflite/\" rel=\"nofollow\">The inception v3 architecture is guaranteed to work though</a>. Am I safe using the <code>--allow_custom_ops</code> flag?</p>\n<p>Some final note:<br>\nI retrained the inception net using the <a href=\"https://github.com/tensorflow/models/tree/master/research/inception/inception/slim\">slim model</a> rather than just retraining the last layer using the freezed graph version. May this be the cause of the additional squeeze problem?</p>\n<h3>Source code / logs</h3>\n<p>This is the complete log as returned by the toco script:</p>\n<pre><code>W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\n2018-02-07 01:23:50.754337: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1074 operators, 1657 arrays (0 quantized)\n2018-02-07 01:23:50.826283: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 126 operators, 317 arrays (0 quantized)\n2018-02-07 01:23:50.827683: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 126 operators, 317 arrays (0 quantized)\n2018-02-07 01:23:50.828908: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 11139584 bytes, theoretical optimal value: 8297856 bytes.\n2018-02-07 01:23:50.829206: I tensorflow/contrib/lite/toco/toco_tooling.cc:269] Estimated count of arithmetic ops: 11.4574 billion (note that a multiply-add is counted as 2 ops).\n2018-02-07 01:23:50.829493: F tensorflow/contrib/lite/toco/tflite/export.cc:303] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: Squeeze.\n[1]    16187 abort (core dumped)  bazel-bin/tensorflow/contrib/lite/toco/toco   --output_format=TFLITE\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nNo, I haven't used any custom code for this.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\nTensorFlow installed from (source or binary):\nsource\nTensorFlow version (use command below):\nr1.5 (6c5063a)\nPython version:\n3\nBazel version (if compiling from source):\n0.9.0\nGCC/Compiler version (if compiling from source):\ngcc4.4\nCUDA/cuDNN version:\n9.0/7.0\nGPU model and memory:\nGTX 1080 8GB\nExact command to reproduce:\n\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\n  --input_file=inception-retrained-graph_freezed.pb \\\n  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\n  --output_file=inception-retrained-graph.tflite --inference_type=FLOAT \\\n  --input_type=FLOAT --input_arrays=input \\\n  --output_arrays=InceptionV3/Predictions/Reshape_1 --input_shapes=1,299,299,3\n\nDescribe the problem\nI tried to use the above command to convert a retrained inception v3 model into the new tflite format. The input graph has already been freezed. The general process is described in this tutorial. However, I'm not able to finish the conversion as the tool complains that the Squeeze operator isn't supported. According to this guide the script should be able to remove the squeeze operation. This comment suggests that it may not always be possible to remove it. The inception v3 architecture is guaranteed to work though. Am I safe using the --allow_custom_ops flag?\nSome final note:\nI retrained the inception net using the slim model rather than just retraining the last layer using the freezed graph version. May this be the cause of the additional squeeze problem?\nSource code / logs\nThis is the complete log as returned by the toco script:\nW tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\n2018-02-07 01:23:50.754337: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1074 operators, 1657 arrays (0 quantized)\n2018-02-07 01:23:50.826283: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 126 operators, 317 arrays (0 quantized)\n2018-02-07 01:23:50.827683: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 126 operators, 317 arrays (0 quantized)\n2018-02-07 01:23:50.828908: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 11139584 bytes, theoretical optimal value: 8297856 bytes.\n2018-02-07 01:23:50.829206: I tensorflow/contrib/lite/toco/toco_tooling.cc:269] Estimated count of arithmetic ops: 11.4574 billion (note that a multiply-add is counted as 2 ops).\n2018-02-07 01:23:50.829493: F tensorflow/contrib/lite/toco/tflite/export.cc:303] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: Squeeze.\n[1]    16187 abort (core dumped)  bazel-bin/tensorflow/contrib/lite/toco/toco   --output_format=TFLITE", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo, I haven't used any custom code for this.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\nr1.5 (6c5063a3f099c302412fcefa17edb2efa9921f01)\r\n- **Python version**: \r\n3\r\n- **Bazel version (if compiling from source)**:\r\n0.9.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc4.4\r\n- **CUDA/cuDNN version**:\r\n9.0/7.0\r\n- **GPU model and memory**:\r\nGTX 1080 8GB\r\n- **Exact command to reproduce**:\r\n```\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n  --input_file=inception-retrained-graph_freezed.pb \\\r\n  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\r\n  --output_file=inception-retrained-graph.tflite --inference_type=FLOAT \\\r\n  --input_type=FLOAT --input_arrays=input \\\r\n  --output_arrays=InceptionV3/Predictions/Reshape_1 --input_shapes=1,299,299,3\r\n```\r\n\r\n### Describe the problem\r\nI tried to use the above command to convert a retrained inception v3 model into the new tflite format. The input graph has already been freezed. The general process is described in [this tutorial](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite#freeze-graph). However, I'm not able to finish the conversion as the tool complains that the Squeeze operator isn't supported. [According to this guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md) the script should be able to remove the squeeze operation. [This comment](https://github.com/tensorflow/tensorflow/issues/16001#issuecomment-356635651) suggests that it may not always be possible to remove it. [The inception v3 architecture is guaranteed to work though](https://www.tensorflow.org/mobile/tflite/). Am I safe using the `--allow_custom_ops` flag?\r\n\r\nSome final note:\r\nI retrained the inception net using the [slim model](https://github.com/tensorflow/models/tree/master/research/inception/inception/slim) rather than just retraining the last layer using the freezed graph version. May this be the cause of the additional squeeze problem?\r\n\r\n### Source code / logs\r\nThis is the complete log as returned by the toco script:\r\n```\r\nW tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\r\n2018-02-07 01:23:50.754337: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1074 operators, 1657 arrays (0 quantized)\r\n2018-02-07 01:23:50.826283: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 126 operators, 317 arrays (0 quantized)\r\n2018-02-07 01:23:50.827683: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 126 operators, 317 arrays (0 quantized)\r\n2018-02-07 01:23:50.828908: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 11139584 bytes, theoretical optimal value: 8297856 bytes.\r\n2018-02-07 01:23:50.829206: I tensorflow/contrib/lite/toco/toco_tooling.cc:269] Estimated count of arithmetic ops: 11.4574 billion (note that a multiply-add is counted as 2 ops).\r\n2018-02-07 01:23:50.829493: F tensorflow/contrib/lite/toco/tflite/export.cc:303] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: Squeeze.\r\n[1]    16187 abort (core dumped)  bazel-bin/tensorflow/contrib/lite/toco/toco   --output_format=TFLITE\r\n```\r\n"}