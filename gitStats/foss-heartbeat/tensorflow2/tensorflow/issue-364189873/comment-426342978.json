{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/426342978", "html_url": "https://github.com/tensorflow/tensorflow/issues/22546#issuecomment-426342978", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22546", "id": 426342978, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNjM0Mjk3OA==", "user": {"login": "priyankjain", "id": 4019056, "node_id": "MDQ6VXNlcjQwMTkwNTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/4019056?v=4", "gravatar_id": "", "url": "https://api.github.com/users/priyankjain", "html_url": "https://github.com/priyankjain", "followers_url": "https://api.github.com/users/priyankjain/followers", "following_url": "https://api.github.com/users/priyankjain/following{/other_user}", "gists_url": "https://api.github.com/users/priyankjain/gists{/gist_id}", "starred_url": "https://api.github.com/users/priyankjain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/priyankjain/subscriptions", "organizations_url": "https://api.github.com/users/priyankjain/orgs", "repos_url": "https://api.github.com/users/priyankjain/repos", "events_url": "https://api.github.com/users/priyankjain/events{/privacy}", "received_events_url": "https://api.github.com/users/priyankjain/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-02T16:36:09Z", "updated_at": "2018-10-02T17:11:01Z", "author_association": "NONE", "body_html": "<p>Here is the C++ OP code</p>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/op.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/shape_inference.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/op_kernel.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/common_shape_fns.h<span class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">using</span> <span class=\"pl-k\">namespace</span> <span class=\"pl-en\">tensorflow</span><span class=\"pl-k\">;</span>\n\n<span class=\"pl-en\">REGISTER_OP</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>NumIntraOpThreads<span class=\"pl-pds\">\"</span></span>)\n.Output(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num_intra_op_threads: int32<span class=\"pl-pds\">\"</span></span>)\n.SetShapeFn(tensorflow::shape_inference::ScalarShape)\n.Doc(<span class=\"pl-s\"><span class=\"pl-pds\">R\"doc(</span></span>\n<span class=\"pl-s\">A tensorflow OP that returns the number of threads in the intra_op_parallelism pool</span>\n<span class=\"pl-s\"><span class=\"pl-pds\">)doc\"</span></span>);\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">NumIntraOpThreads</span> : <span class=\"pl-k\">public</span> <span class=\"pl-en\">OpKernel</span> {\n <span class=\"pl-k\">public:</span>\n  <span class=\"pl-k\">explicit</span> <span class=\"pl-en\">NumIntraOpThreads</span>(OpKernelConstruction* context)\n      : OpKernel(context) {}\n\n  <span class=\"pl-k\">void</span> <span class=\"pl-en\">Compute</span>(OpKernelContext* context) <span class=\"pl-k\">override</span> {\n    <span class=\"pl-k\">int</span> num_intra_op_threads = context-&gt;<span class=\"pl-c1\">device</span>()-&gt;<span class=\"pl-c1\">tensorflow_cpu_worker_threads</span>()-&gt;<span class=\"pl-smi\">num_threads</span>;\n    Tensor* output_tensor = <span class=\"pl-c1\">NULL</span>;\n    <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_output</span>(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">TensorShape</span>({}), &amp;output_tensor));\n    <span class=\"pl-k\">auto</span> output_flat = output_tensor-&gt;<span class=\"pl-smi\">flat</span>&lt;int32&gt;();\n    <span class=\"pl-c1\">output_flat</span>(<span class=\"pl-c1\">0</span>) = num_intra_op_threads;\n    }\n};\n\n<span class=\"pl-en\">REGISTER_KERNEL_BUILDER</span>(Name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>NumIntraOpThreads<span class=\"pl-pds\">\"</span></span>).Device(DEVICE_CPU), NumIntraOpThreads);</pre></div>\n<p>Here are the flags I am using to compile the OP</p>\n<div class=\"highlight highlight-source-shell\"><pre>TF_CFLAGS=( <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>python -c <span class=\"pl-s\"><span class=\"pl-pds\">'</span>import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))<span class=\"pl-pds\">'</span></span><span class=\"pl-pds\">)</span></span> )\nTF_LFLAGS=( <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>python -c <span class=\"pl-s\"><span class=\"pl-pds\">'</span>import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))<span class=\"pl-pds\">'</span></span><span class=\"pl-pds\">)</span></span> )\ng++ -std=c++11 -shared -undefined dynamic_lookup num_intra_op_threads.cc -o num_intra_op_threads.so -fPIC <span class=\"pl-smi\">${TF_CFLAGS[@]}</span> <span class=\"pl-smi\">${TF_LFLAGS[@]}</span> -O2</pre></div>\n<p>The python code to test the output of the OP:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Tensorflow version is <span class=\"pl-pds\">'</span></span>, tf.<span class=\"pl-c1\">__version__</span>)\nn_module <span class=\"pl-k\">=</span> tf.load_op_library(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>./num_intra_op_threads.so<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(tf.<span class=\"pl-c1\">__version__</span>)\n<span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>tf.ConfigProto(<span class=\"pl-v\">intra_op_parallelism_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>, <span class=\"pl-v\">inter_op_parallelism_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)):\n  <span class=\"pl-c1\">print</span>(n_module.num_intra_op_threads().eval())</pre></div>\n<p>Output of the above python script with TF 1.7:</p>\n<div class=\"highlight highlight-source-shell\"><pre>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Tensorflow version is <span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1.7.0<span class=\"pl-pds\">'</span></span>)\n1.7.0\n2018-10-02 12:25:36.949725: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n10</pre></div>\n<p>Output with TF 1.8:</p>\n<div class=\"highlight highlight-source-shell\"><pre>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Tensorflow version is <span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1.8.0<span class=\"pl-pds\">'</span></span>)\n1.8.0\n2018-10-02 13:05:41.198519: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n1</pre></div>\n<p>Output with TF 1.9:</p>\n<div class=\"highlight highlight-source-shell\"><pre>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Tensorflow version is <span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1.9.0<span class=\"pl-pds\">'</span></span>)\n1.9.0\n2018-10-02 13:04:50.161943: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n1</pre></div>\n<p>Output with TF 1.10:</p>\n<div class=\"highlight highlight-source-shell\"><pre>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Tensorflow version is <span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1.10.0<span class=\"pl-pds\">'</span></span>)\n1.10.0\n2018-10-02 12:24:26.858385: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n1</pre></div>\n<p>Output with TF 1.11:</p>\n<div class=\"highlight highlight-source-shell\"><pre>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Tensorflow version is <span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1.11.0<span class=\"pl-pds\">'</span></span>)\n1.11.0\n2018-10-02 12:27:45.802153: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n1</pre></div>\n<p>I am recompiling the OP with different TF versions, before running the python script. Looks like the bug was introduced in TF 1.8.</p>", "body_text": "Here is the C++ OP code\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"NumIntraOpThreads\")\n.Output(\"num_intra_op_threads: int32\")\n.SetShapeFn(tensorflow::shape_inference::ScalarShape)\n.Doc(R\"doc(\nA tensorflow OP that returns the number of threads in the intra_op_parallelism pool\n)doc\");\n\nclass NumIntraOpThreads : public OpKernel {\n public:\n  explicit NumIntraOpThreads(OpKernelConstruction* context)\n      : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    int num_intra_op_threads = context->device()->tensorflow_cpu_worker_threads()->num_threads;\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}), &output_tensor));\n    auto output_flat = output_tensor->flat<int32>();\n    output_flat(0) = num_intra_op_threads;\n    }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"NumIntraOpThreads\").Device(DEVICE_CPU), NumIntraOpThreads);\nHere are the flags I am using to compile the OP\nTF_CFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))') )\nTF_LFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))') )\ng++ -std=c++11 -shared -undefined dynamic_lookup num_intra_op_threads.cc -o num_intra_op_threads.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2\nThe python code to test the output of the OP:\nimport tensorflow as tf\nprint('Tensorflow version is ', tf.__version__)\nn_module = tf.load_op_library('./num_intra_op_threads.so')\nprint(tf.__version__)\nwith tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=10, inter_op_parallelism_threads=10)):\n  print(n_module.num_intra_op_threads().eval())\nOutput of the above python script with TF 1.7:\n('Tensorflow version is ', '1.7.0')\n1.7.0\n2018-10-02 12:25:36.949725: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n10\nOutput with TF 1.8:\n('Tensorflow version is ', '1.8.0')\n1.8.0\n2018-10-02 13:05:41.198519: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n1\nOutput with TF 1.9:\n('Tensorflow version is ', '1.9.0')\n1.9.0\n2018-10-02 13:04:50.161943: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n1\nOutput with TF 1.10:\n('Tensorflow version is ', '1.10.0')\n1.10.0\n2018-10-02 12:24:26.858385: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n1\nOutput with TF 1.11:\n('Tensorflow version is ', '1.11.0')\n1.11.0\n2018-10-02 12:27:45.802153: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n1\nI am recompiling the OP with different TF versions, before running the python script. Looks like the bug was introduced in TF 1.8.", "body": "Here is the C++ OP code\r\n```cpp\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include \"tensorflow/core/framework/common_shape_fns.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\nREGISTER_OP(\"NumIntraOpThreads\")\r\n.Output(\"num_intra_op_threads: int32\")\r\n.SetShapeFn(tensorflow::shape_inference::ScalarShape)\r\n.Doc(R\"doc(\r\nA tensorflow OP that returns the number of threads in the intra_op_parallelism pool\r\n)doc\");\r\n\r\nclass NumIntraOpThreads : public OpKernel {\r\n public:\r\n  explicit NumIntraOpThreads(OpKernelConstruction* context)\r\n      : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n    int num_intra_op_threads = context->device()->tensorflow_cpu_worker_threads()->num_threads;\r\n    Tensor* output_tensor = NULL;\r\n    OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}), &output_tensor));\r\n    auto output_flat = output_tensor->flat<int32>();\r\n    output_flat(0) = num_intra_op_threads;\r\n    }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"NumIntraOpThreads\").Device(DEVICE_CPU), NumIntraOpThreads);\r\n```\r\n\r\nHere are the flags I am using to compile the OP\r\n```bash\r\nTF_CFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))') )\r\nTF_LFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))') )\r\ng++ -std=c++11 -shared -undefined dynamic_lookup num_intra_op_threads.cc -o num_intra_op_threads.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2\r\n```\r\n\r\nThe python code to test the output of the OP:\r\n```python\r\nimport tensorflow as tf\r\nprint('Tensorflow version is ', tf.__version__)\r\nn_module = tf.load_op_library('./num_intra_op_threads.so')\r\nprint(tf.__version__)\r\nwith tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=10, inter_op_parallelism_threads=10)):\r\n  print(n_module.num_intra_op_threads().eval())\r\n```\r\n\r\nOutput of the above python script with TF 1.7:\r\n```bash\r\n('Tensorflow version is ', '1.7.0')\r\n1.7.0\r\n2018-10-02 12:25:36.949725: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n10\r\n```\r\nOutput with TF 1.8:\r\n```bash\r\n('Tensorflow version is ', '1.8.0')\r\n1.8.0\r\n2018-10-02 13:05:41.198519: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n1\r\n```\r\n\r\nOutput with TF 1.9:\r\n```bash\r\n('Tensorflow version is ', '1.9.0')\r\n1.9.0\r\n2018-10-02 13:04:50.161943: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n1\r\n```\r\n\r\nOutput with TF 1.10:\r\n```bash\r\n('Tensorflow version is ', '1.10.0')\r\n1.10.0\r\n2018-10-02 12:24:26.858385: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n1\r\n```\r\n\r\nOutput with TF 1.11:\r\n```bash\r\n('Tensorflow version is ', '1.11.0')\r\n1.11.0\r\n2018-10-02 12:27:45.802153: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n1\r\n```\r\n\r\nI am recompiling the OP with different TF versions, before running the python script. Looks like the bug was introduced in TF 1.8."}