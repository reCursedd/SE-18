{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/189339517", "html_url": "https://github.com/tensorflow/tensorflow/issues/435#issuecomment-189339517", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/435", "id": 189339517, "node_id": "MDEyOklzc3VlQ29tbWVudDE4OTMzOTUxNw==", "user": {"login": "sesse", "id": 238700, "node_id": "MDQ6VXNlcjIzODcwMA==", "avatar_url": "https://avatars0.githubusercontent.com/u/238700?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sesse", "html_url": "https://github.com/sesse", "followers_url": "https://api.github.com/users/sesse/followers", "following_url": "https://api.github.com/users/sesse/following{/other_user}", "gists_url": "https://api.github.com/users/sesse/gists{/gist_id}", "starred_url": "https://api.github.com/users/sesse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sesse/subscriptions", "organizations_url": "https://api.github.com/users/sesse/orgs", "repos_url": "https://api.github.com/users/sesse/repos", "events_url": "https://api.github.com/users/sesse/events{/privacy}", "received_events_url": "https://api.github.com/users/sesse/received_events", "type": "User", "site_admin": false}, "created_at": "2016-02-26T16:00:28Z", "updated_at": "2016-02-26T16:00:28Z", "author_association": "NONE", "body_html": "<p>There's a fair amount of per-op overhead, so for small data sets, you could be seeing contention on the thread pool. You could try going the other way, of course; splitting the tf.cross input in four, one for each CPU, and seeing if it matches your expectations.</p>\n<p>The cross op right now has the unfortunate effect of starting three CUDA kernels (since it does three operator= statement on device); it should really have been one for better GPU efficiency, but I didn't think of it at the time.</p>", "body_text": "There's a fair amount of per-op overhead, so for small data sets, you could be seeing contention on the thread pool. You could try going the other way, of course; splitting the tf.cross input in four, one for each CPU, and seeing if it matches your expectations.\nThe cross op right now has the unfortunate effect of starting three CUDA kernels (since it does three operator= statement on device); it should really have been one for better GPU efficiency, but I didn't think of it at the time.", "body": "There's a fair amount of per-op overhead, so for small data sets, you could be seeing contention on the thread pool. You could try going the other way, of course; splitting the tf.cross input in four, one for each CPU, and seeing if it matches your expectations.\n\nThe cross op right now has the unfortunate effect of starting three CUDA kernels (since it does three operator= statement on device); it should really have been one for better GPU efficiency, but I didn't think of it at the time.\n"}