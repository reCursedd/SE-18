{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/171088781", "html_url": "https://github.com/tensorflow/tensorflow/issues/435#issuecomment-171088781", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/435", "id": 171088781, "node_id": "MDEyOklzc3VlQ29tbWVudDE3MTA4ODc4MQ==", "user": {"login": "fxsuper", "id": 16196995, "node_id": "MDQ6VXNlcjE2MTk2OTk1", "avatar_url": "https://avatars1.githubusercontent.com/u/16196995?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fxsuper", "html_url": "https://github.com/fxsuper", "followers_url": "https://api.github.com/users/fxsuper/followers", "following_url": "https://api.github.com/users/fxsuper/following{/other_user}", "gists_url": "https://api.github.com/users/fxsuper/gists{/gist_id}", "starred_url": "https://api.github.com/users/fxsuper/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fxsuper/subscriptions", "organizations_url": "https://api.github.com/users/fxsuper/orgs", "repos_url": "https://api.github.com/users/fxsuper/repos", "events_url": "https://api.github.com/users/fxsuper/events{/privacy}", "received_events_url": "https://api.github.com/users/fxsuper/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-12T22:55:22Z", "updated_at": "2016-01-12T22:55:22Z", "author_association": "NONE", "body_html": "<p>Do you have a sense of the likely performance improvement if I were to implement it as a native op in C++ vs. just python TF code? I already have a python implementation that's very simple, basically just this:</p>\n<pre><code>def cross(u, v, name=None):\n    with tf.op_scope([u, v], name, 'cross') as scope:\n        u = tf.convert_to_tensor(u, name='u')\n        v = tf.convert_to_tensor(v, name='v')\n\n        u1, u2, u3 = tf.split(1, 3, u)\n        v1, v2, v3 = tf.split(1, 3, v)\n\n        return tf.concat(1, [(u2 * v3) - (u3 * v2),\n                             (u3 * v1) - (u1 * v3),\n                             (u1 * v2) - (u2 * v1)], name=scope)\n</code></pre>\n<p>And I'm wondering if it would be worth the extra investment. A speed up of 30% wouldn't be for me, but something like &gt;3x would. Interestingly the above implementation is about 5x faster on CPUs than GPUs (Titan X).</p>", "body_text": "Do you have a sense of the likely performance improvement if I were to implement it as a native op in C++ vs. just python TF code? I already have a python implementation that's very simple, basically just this:\ndef cross(u, v, name=None):\n    with tf.op_scope([u, v], name, 'cross') as scope:\n        u = tf.convert_to_tensor(u, name='u')\n        v = tf.convert_to_tensor(v, name='v')\n\n        u1, u2, u3 = tf.split(1, 3, u)\n        v1, v2, v3 = tf.split(1, 3, v)\n\n        return tf.concat(1, [(u2 * v3) - (u3 * v2),\n                             (u3 * v1) - (u1 * v3),\n                             (u1 * v2) - (u2 * v1)], name=scope)\n\nAnd I'm wondering if it would be worth the extra investment. A speed up of 30% wouldn't be for me, but something like >3x would. Interestingly the above implementation is about 5x faster on CPUs than GPUs (Titan X).", "body": "Do you have a sense of the likely performance improvement if I were to implement it as a native op in C++ vs. just python TF code? I already have a python implementation that's very simple, basically just this:\n\n```\ndef cross(u, v, name=None):\n    with tf.op_scope([u, v], name, 'cross') as scope:\n        u = tf.convert_to_tensor(u, name='u')\n        v = tf.convert_to_tensor(v, name='v')\n\n        u1, u2, u3 = tf.split(1, 3, u)\n        v1, v2, v3 = tf.split(1, 3, v)\n\n        return tf.concat(1, [(u2 * v3) - (u3 * v2),\n                             (u3 * v1) - (u1 * v3),\n                             (u1 * v2) - (u2 * v1)], name=scope)\n```\n\nAnd I'm wondering if it would be worth the extra investment. A speed up of 30% wouldn't be for me, but something like >3x would. Interestingly the above implementation is about 5x faster on CPUs than GPUs (Titan X).\n"}