{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/165174257", "pull_request_review_id": 93067849, "id": 165174257, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NTE3NDI1Nw==", "diff_hunk": "@@ -46,59 +47,73 @@ struct SegmentSumFunctor {\n                   const Index data_size, const T* data,\n                   typename TTypes<T, 2>::Tensor output);\n };\n-#endif\n \n-// BaseFunctor for definition of UnsorteSegmentReductionOp\n-// for usage without templates.\n-template <typename Device, typename T, typename Index>\n-struct UnsortedSegmentBaseFunctor {\n-  virtual ~UnsortedSegmentBaseFunctor() {}\n-  virtual void operator()(OpKernelContext* ctx, const Device& d,\n-                          const Index output_rows,\n-                          const TensorShape& segment_ids_shape,\n-                          typename TTypes<Index>::ConstFlat segment_ids,\n-                          const Index data_size, const T* data,\n-                          typename TTypes<T, 2>::Tensor output){};\n-};\n+#endif\n \n-// Functor for UnsortedSegmentSumOp.\n-// output_rows: the number of output segments (unique segment ids in\n-//                'segment_ids').\n-// segment_ids_shape: shape of 'segment_ids' tensor.\n-// segment_ids: unsorted map from input to output segment ids at which to\n-//                perform segment sum operation.\n-// data_size: size of input data tensor.\n-// data: input data tensor.\n-// output: output reshaped to {output_rows, output.size/output_rows}\n-template <typename Device, typename T, typename Index>\n-struct UnsortedSegmentSumFunctor\n-    : public UnsortedSegmentBaseFunctor<Device, T, Index> {\n-  void operator()(OpKernelContext* ctx, const Device& d,\n-                  const Index output_rows, const TensorShape& segment_ids_shape,\n+template <typename Device, typename T, typename Index, typename InitialValueF,\n+          typename ReductionF>\n+struct UnsortedSegmentFunctor {\n+  void operator()(OpKernelContext* ctx, const Index num_segments,\n+                  const TensorShape& segment_ids_shape,\n                   typename TTypes<Index>::ConstFlat segment_ids,\n                   const Index data_size, const T* data,\n                   typename TTypes<T, 2>::Tensor output);\n };\n \n-// Functor for UnsortedSegmentMaxOp.\n-// output_rows: the number of output segments (unique segment ids in\n-//                'segment_ids').\n-// segment_ids_shape: shape of 'segment_ids' tensor.\n-// segment_ids: unsorted map from input to output segment ids at which to\n-//                perform segment sum operation.\n-// data_size: size of input data tensor.\n-// data: input data tensor.\n-// output: output reshaped to {output_rows, output.size/output_rows}\n-template <typename Device, typename T, typename Index>\n-struct UnsortedSegmentMaxFunctor\n-    : public UnsortedSegmentBaseFunctor<Device, T, Index> {\n-  void operator()(OpKernelContext* ctx, const Device& d,\n-                  const Index output_rows, const TensorShape& segment_ids_shape,\n-                  typename TTypes<Index>::ConstFlat segment_ids,\n-                  const Index data_size, const T* data,\n-                  typename TTypes<T, 2>::Tensor output);\n+#ifdef GOOGLE_CUDA\n+// reduction functors for the gpu\n+template <typename T>\n+struct SumOpGpu {\n+  __device__ __forceinline__ void operator()(T* dest, const T& value) {\n+    CudaAtomicAdd(dest, value);\n+  }\n+};\n+\n+template <typename T>\n+struct ProdOpGpu {\n+  __device__ __forceinline__ void operator()(T* dest, const T& value) {\n+    CudaAtomicMul(dest, value);\n+  }\n+};\n+\n+template <typename T>\n+struct MaxOpGpu {\n+  __device__ __forceinline__ void operator()(T* dest, const T& value) {\n+    CudaAtomicMax(dest, value);\n+  }\n+};\n+\n+template <typename T>\n+struct MinOpGpu {\n+  __device__ __forceinline__ void operator()(T* dest, const T& value) {\n+    CudaAtomicMin(dest, value);\n+  }\n };\n+\n+#endif  // GOOGLE_CUDA\n+\n+// initial value functors\n+template <typename T>\n+struct Zero {\n+  inline T operator()() const { return T(0); }\n+};\n+\n+template <typename T>\n+struct One {\n+  inline T operator()() const { return T(1); }\n+};\n+\n+template <typename T>\n+struct Lowest {\n+  inline T operator()() const { return std::numeric_limits<T>::lowest(); }", "path": "tensorflow/core/kernels/segment_reduction_ops.h", "position": null, "original_position": 124, "commit_id": "328288aa723d351ed4675592bcb1330025fa51cf", "original_commit_id": "00407e7e7fe60ba18c7567c3eb390fc8b974bfbe", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "If instead of using numeric_limits here, you used the equivalent functions from Eigen\r\n```Eigen::NumTraits<T>::highest()``` and ```Eigen::NumTraits<T>::lowest()``` \r\n the code would handle DT_HALF and DT_BFLOAT16 correctly.  See, e.g.,  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/quantization_utils.h#L74", "created_at": "2018-01-31T20:16:28Z", "updated_at": "2018-02-06T11:33:33Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/15858#discussion_r165174257", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15858", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/165174257"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/15858#discussion_r165174257"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15858"}}, "body_html": "<p>If instead of using numeric_limits here, you used the equivalent functions from Eigen<br>\n<code>Eigen::NumTraits&lt;T&gt;::highest()</code> and <code>Eigen::NumTraits&lt;T&gt;::lowest()</code><br>\nthe code would handle DT_HALF and DT_BFLOAT16 correctly.  See, e.g.,  <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/quantization_utils.h#L74\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/quantization_utils.h#L74</a></p>", "body_text": "If instead of using numeric_limits here, you used the equivalent functions from Eigen\nEigen::NumTraits<T>::highest() and Eigen::NumTraits<T>::lowest()\nthe code would handle DT_HALF and DT_BFLOAT16 correctly.  See, e.g.,  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/quantization_utils.h#L74"}