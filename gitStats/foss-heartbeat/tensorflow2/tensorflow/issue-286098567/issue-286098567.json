{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15858", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15858/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15858/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15858/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/15858", "id": 286098567, "node_id": "MDExOlB1bGxSZXF1ZXN0MTYxMjA2MDM5", "number": 15858, "title": "Add unsortedsegment(prod/min/max/sqrt_n/mean).", "user": {"login": "PhilJd", "id": 16101605, "node_id": "MDQ6VXNlcjE2MTAxNjA1", "avatar_url": "https://avatars2.githubusercontent.com/u/16101605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PhilJd", "html_url": "https://github.com/PhilJd", "followers_url": "https://api.github.com/users/PhilJd/followers", "following_url": "https://api.github.com/users/PhilJd/following{/other_user}", "gists_url": "https://api.github.com/users/PhilJd/gists{/gist_id}", "starred_url": "https://api.github.com/users/PhilJd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PhilJd/subscriptions", "organizations_url": "https://api.github.com/users/PhilJd/orgs", "repos_url": "https://api.github.com/users/PhilJd/repos", "events_url": "https://api.github.com/users/PhilJd/events{/privacy}", "received_events_url": "https://api.github.com/users/PhilJd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 390482148, "node_id": "MDU6TGFiZWwzOTA0ODIxNDg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20review", "name": "awaiting review", "color": "fef2c0", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 21, "created_at": "2018-01-04T20:05:30Z", "updated_at": "2018-02-08T10:22:58Z", "closed_at": "2018-02-07T19:00:00Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15858", "html_url": "https://github.com/tensorflow/tensorflow/pull/15858", "diff_url": "https://github.com/tensorflow/tensorflow/pull/15858.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/15858.patch"}, "body_html": "<p>This pull request</p>\n<ul>\n<li>adds CPU/GPU implementations of\n<ul>\n<li><code>tf.unsorted_segment_min</code>,</li>\n<li><code>tf.unsorted_segment_prod</code> and a</li>\n<li>GPU implementation for <code>tf.unsorted_segment_max</code>.</li>\n</ul>\n</li>\n<li>adds python implementations of:\n<ul>\n<li><code>tf.unsorted_segment_mean</code></li>\n<li><code>tf.unsorted_segment_sqrt_n</code></li>\n</ul>\n</li>\n<li>fixes the gradient calculation for unsorted_segment_sum/max.<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"257925181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13055\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/13055/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/13055\">#13055</a> introduced silent dropping of negative values on the cpu.<br>\nHowever, the gradient of e.g. unsorted_segment_sum used tf.gather<br>\nand therefore failed for negative indices on cpu.</li>\n</ul>\n<p>I tried to simplify the code and to remove code duplication,<br>\naddressing this <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L362\">todo</a>.<br>\n(Also I once filed an  <a href=\"https://github.com/tensorflow/tensorflow/issues/7389\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7389/hovercard\">issue</a>  to add these ops but only now had time to finish it ;).)</p>\n<p>Some notes on this pull request:</p>\n<ul>\n<li>\n<p>tf.gather returns zero on GPU for negative indices and raises an exception on<br>\nCPU. To overcome this, the current implementation masks negative indices and<br>\nsets them to zero later. This is of course not as efficient as the original gather.<br>\nWould it make sense to use something like <code>if \"gpu\" in op.device.lower():</code> to run<br>\ndifferent functions, depending on the device?</p>\n</li>\n<li>\n<p>Instead of having a native op for mean/sqrt_n I added them in python.<br>\nMaking them native would require two additional template arguments<br>\n(a functor to process the counter), resulting in more complicated code with<br>\nprobably only minor performance improvement, if at all. In my quick<br>\nbenchmarks, the python ops are nearly as fast as unsorted_segment_sum. However,<br>\nthey use more memory than a native op would, due to creating a tensor of ones.<br>\n(bincount doesn't work here as it doesn't support negative indices)</p>\n</li>\n<li>\n<p>I simply copy-pasted some atomicOp code in <code>cuda_kernel_helper.h</code> instead of<br>\nwriting this more nicely as for a short period there was a completely different<br>\nversion of this file online and I wanted to check back with you before<br>\ndoing something more sophisticated. What's the status of this?</p>\n<p>Additionally, I guess the function <code>AccumulateInto</code> in <code>segment_reduction_ops_gpu.cu.cc</code><br>\ncould be removed? CudaAtomicAdd has specializations for complex types in<br>\ncuda_kernel_helper.h</p>\n</li>\n</ul>\n<p>Cheers,<br>\nPhil</p>", "body_text": "This pull request\n\nadds CPU/GPU implementations of\n\ntf.unsorted_segment_min,\ntf.unsorted_segment_prod and a\nGPU implementation for tf.unsorted_segment_max.\n\n\nadds python implementations of:\n\ntf.unsorted_segment_mean\ntf.unsorted_segment_sqrt_n\n\n\nfixes the gradient calculation for unsorted_segment_sum/max.\n#13055 introduced silent dropping of negative values on the cpu.\nHowever, the gradient of e.g. unsorted_segment_sum used tf.gather\nand therefore failed for negative indices on cpu.\n\nI tried to simplify the code and to remove code duplication,\naddressing this todo.\n(Also I once filed an  issue  to add these ops but only now had time to finish it ;).)\nSome notes on this pull request:\n\n\ntf.gather returns zero on GPU for negative indices and raises an exception on\nCPU. To overcome this, the current implementation masks negative indices and\nsets them to zero later. This is of course not as efficient as the original gather.\nWould it make sense to use something like if \"gpu\" in op.device.lower(): to run\ndifferent functions, depending on the device?\n\n\nInstead of having a native op for mean/sqrt_n I added them in python.\nMaking them native would require two additional template arguments\n(a functor to process the counter), resulting in more complicated code with\nprobably only minor performance improvement, if at all. In my quick\nbenchmarks, the python ops are nearly as fast as unsorted_segment_sum. However,\nthey use more memory than a native op would, due to creating a tensor of ones.\n(bincount doesn't work here as it doesn't support negative indices)\n\n\nI simply copy-pasted some atomicOp code in cuda_kernel_helper.h instead of\nwriting this more nicely as for a short period there was a completely different\nversion of this file online and I wanted to check back with you before\ndoing something more sophisticated. What's the status of this?\nAdditionally, I guess the function AccumulateInto in segment_reduction_ops_gpu.cu.cc\ncould be removed? CudaAtomicAdd has specializations for complex types in\ncuda_kernel_helper.h\n\n\nCheers,\nPhil", "body": "\r\nThis pull request\r\n- adds CPU/GPU implementations of\r\n  - `tf.unsorted_segment_min`,\r\n  - `tf.unsorted_segment_prod` and a\r\n  - GPU implementation for `tf.unsorted_segment_max`.\r\n- adds python implementations of:\r\n  - `tf.unsorted_segment_mean`\r\n  - `tf.unsorted_segment_sqrt_n`\r\n- fixes the gradient calculation for unsorted_segment_sum/max.\r\n  #13055 introduced silent dropping of negative values on the cpu.\r\n  However, the gradient of e.g. unsorted_segment_sum used tf.gather\r\n  and therefore failed for negative indices on cpu.\r\n  \r\nI tried to simplify the code and to remove code duplication,\r\naddressing this [todo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L362).\r\n(Also I once filed an  [issue](https://github.com/tensorflow/tensorflow/issues/7389)  to add these ops but only now had time to finish it ;).)\r\n\r\n\r\nSome notes on this pull request:\r\n\r\n- tf.gather returns zero on GPU for negative indices and raises an exception on\r\n  CPU. To overcome this, the current implementation masks negative indices and\r\n  sets them to zero later. This is of course not as efficient as the original gather.\r\n  Would it make sense to use something like `if \"gpu\" in op.device.lower():` to run\r\n  different functions, depending on the device?\r\n- Instead of having a native op for mean/sqrt_n I added them in python.\r\n  Making them native would require two additional template arguments\r\n  (a functor to process the counter), resulting in more complicated code with\r\n  probably only minor performance improvement, if at all. In my quick\r\n  benchmarks, the python ops are nearly as fast as unsorted_segment_sum. However,\r\n  they use more memory than a native op would, due to creating a tensor of ones.\r\n  (bincount doesn't work here as it doesn't support negative indices)\r\n- I simply copy-pasted some atomicOp code in `cuda_kernel_helper.h` instead of\r\n  writing this more nicely as for a short period there was a completely different\r\n  version of this file online and I wanted to check back with you before\r\n  doing something more sophisticated. What's the status of this?\r\n\r\n  Additionally, I guess the function `AccumulateInto` in `segment_reduction_ops_gpu.cu.cc`\r\n  could be removed? CudaAtomicAdd has specializations for complex types in\r\n  cuda_kernel_helper.h\r\n\r\nCheers,\r\nPhil"}