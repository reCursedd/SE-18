{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/166057041", "pull_request_review_id": 94084555, "id": 166057041, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjA1NzA0MQ==", "diff_hunk": "@@ -228,56 +228,142 @@ def _SparseSegmentSqrtNWithNumSegmentsGrad(op, grad):\n                                               dim0), None, None, None)\n \n \n-def _SegmentMinOrMaxGrad(op, grad, is_sorted):\n-  \"\"\"Gradient for SegmentMin and (unsorted) SegmentMax.\n-\n-  They share similar code.\n-  \"\"\"\n-  zeros = array_ops.zeros(\n-      array_ops.shape(op.inputs[0]), dtype=op.inputs[0].dtype)\n-\n+def _SegmentMinOrMaxGrad(op, grad):\n+  \"\"\" Gradient for SegmentMin and SegmentMax. \"\"\"\n+  zeros = array_ops.zeros_like(op.inputs[0], dtype=op.inputs[0].dtype)\n   # Get the number of selected (minimum or maximum) elements in each segment.\n   gathered_outputs = array_ops.gather(op.outputs[0], op.inputs[1])\n   is_selected = math_ops.equal(op.inputs[0], gathered_outputs)\n-  if is_sorted:\n-    num_selected = math_ops.segment_sum(\n-        math_ops.cast(is_selected, grad.dtype), op.inputs[1])\n-  else:\n-    num_selected = math_ops.unsorted_segment_sum(\n-        math_ops.cast(is_selected, grad.dtype), op.inputs[1], op.inputs[2])\n-\n+  num_selected = math_ops.segment_sum(math_ops.cast(is_selected, grad.dtype),\n+                                      op.inputs[1])\n   # Compute the gradient for each segment. The gradient for the ith segment is\n   # divided evenly among the selected elements in that segment.\n   weighted_grads = math_ops.div(grad, num_selected)\n   gathered_grads = array_ops.gather(weighted_grads, op.inputs[1])\n-\n-  if is_sorted:\n-    return array_ops.where(is_selected, gathered_grads, zeros), None\n-  else:\n-    return array_ops.where(is_selected, gathered_grads, zeros), None, None\n+  return array_ops.where(is_selected, gathered_grads, zeros), None\n \n \n @ops.RegisterGradient(\"SegmentMin\")\n def _SegmentMinGrad(op, grad):\n   \"\"\"Gradient for SegmentMin.\"\"\"\n-  return _SegmentMinOrMaxGrad(op, grad, True)\n+  return _SegmentMinOrMaxGrad(op, grad)\n \n \n @ops.RegisterGradient(\"SegmentMax\")\n def _SegmentMaxGrad(op, grad):\n   \"\"\"Gradient for SegmentMax.\"\"\"\n-  return _SegmentMinOrMaxGrad(op, grad, True)\n+  return _SegmentMinOrMaxGrad(op, grad)\n+\n+\n+def _GatherDropNegatives(params, ids, zero_clipped_indices=None,\n+                         is_positive=None):\n+  \"\"\" Helper function for unsorted segment ops. Gathers params for\n+      positive segment ids and gathers 0 for inputs with negative segment id.\n+      Also returns the clipped indices and a boolean mask with the same shape\n+      as ids where a positive id is masked as true. With this, the latter two\n+      can be passed as arguments to this function to reuse them.\n+  \"\"\"\n+  if zero_clipped_indices is None:\n+    zero_clipped_indices = math_ops.maximum(ids, array_ops.zeros_like(ids))\n+  gathered = array_ops.gather(params, zero_clipped_indices)\n+  if is_positive is None:\n+    is_positive = math_ops.greater_equal(ids, 0)\n+    # tf.where(condition, x, y) requires condition to have the same shape as x\n+    # and y.\n+    # todo(philjd): remove this if tf.where supports broadcasting (#9284)\n+    for _ in range(gathered.shape.ndims - is_positive.shape.ndims):\n+      is_positive = array_ops.expand_dims(is_positive, -1)\n+    is_positive = (is_positive &\n+                   array_ops.ones_like(gathered, dtype=dtypes.bool))\n+  # replace gathered params of negative indices with 0\n+  zero_slice = array_ops.zeros_like(gathered)\n+  return (array_ops.where(is_positive, gathered, zero_slice),\n+          zero_clipped_indices, is_positive)\n+\n+\n+def _UnsortedSegmentMinOrMaxGrad(op, grad):\n+  \"\"\" Gradient for UnsortedSegmentMin and UnsortedSegmentMax. \"\"\"\n+  # Get the number of selected (minimum or maximum) elements in each segment.\n+  gathered_outputs, zero_clipped_indices, is_positive = \\\n+      _GatherDropNegatives(op.outputs[0], op.inputs[1])\n+  is_selected = math_ops.equal(op.inputs[0], gathered_outputs)\n+  is_selected = math_ops.logical_and(is_selected, is_positive)\n+  num_selected = math_ops.unsorted_segment_sum(\n+      math_ops.cast(is_selected, grad.dtype), op.inputs[1], op.inputs[2])\n+  # Compute the gradient for each segment. The gradient for the ith segment is\n+  # divided evenly among the selected elements in that segment.\n+  weighted_grads = math_ops.div(grad, num_selected)\n+  gathered_grads, _, _ = _GatherDropNegatives(weighted_grads, None,\n+                                              zero_clipped_indices,\n+                                              is_positive)\n+  zeros = array_ops.zeros_like(gathered_grads)\n+  return array_ops.where(is_selected, gathered_grads, zeros), None, None\n \n \n @ops.RegisterGradient(\"UnsortedSegmentSum\")\n def _UnsortedSegmentSumGrad(op, grad):\n-  \"\"\"Gradient for SegmentSum.\"\"\"\n-  return array_ops.gather(grad, op.inputs[1]), None, None\n+  \"\"\"Gradient for UnsortedSegmentSum.\"\"\"\n+  return _GatherDropNegatives(grad, op.inputs[1])[0], None, None\n \n \n @ops.RegisterGradient(\"UnsortedSegmentMax\")\n def _UnsortedSegmentMaxGrad(op, grad):\n-  return _SegmentMinOrMaxGrad(op, grad, False)\n+  \"\"\" Gradient for UnsortedSegmentMax. \"\"\"\n+  return _UnsortedSegmentMinOrMaxGrad(op, grad)\n+\n+\n+@ops.RegisterGradient(\"UnsortedSegmentMin\")\n+def _UnsortedSegmentMinGrad(op, grad):\n+  \"\"\" Gradient for UnsortedSegmentMin. \"\"\"\n+  return _UnsortedSegmentMinOrMaxGrad(op, grad)\n+\n+\n+@ops.RegisterGradient(\"UnsortedSegmentProd\")\n+def _UnsortedSegmentProdGrad(op, grad):\n+  \"\"\" Gradient for UnsortedSegmentProd.\n+  The gradient can be expressed for each segment by dividing the segment's\n+  product by each element of the segment input tensor, but this approach can't\n+  deal with zeros in the input.\n+  Unlike reduce_prod we can't use cumsum here as individual segments may have\n+  a different number of elements. Therefore we consider three cases:\n+  1) A segment input contains no zeros and we can safely divide by the input\n+     tensor.\n+  2) A segment contains exactly on zero. Then the gradient of each input of\n+     the segment is zero except for the 0-input, there the gradient is\n+     the product of the remaining segment entries.\n+  3) A segment contains at least two zeros. The gradient is zero for all", "path": "tensorflow/python/ops/math_grad.py", "position": null, "original_position": 132, "commit_id": "328288aa723d351ed4675592bcb1330025fa51cf", "original_commit_id": "e9dd60f4d45105a4f014867f17dcd8740526d949", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "Very nice. Thanks for documenting the algorithm carefully.", "created_at": "2018-02-05T18:04:10Z", "updated_at": "2018-02-06T11:33:33Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/15858#discussion_r166057041", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15858", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/166057041"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/15858#discussion_r166057041"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15858"}}, "body_html": "<p>Very nice. Thanks for documenting the algorithm carefully.</p>", "body_text": "Very nice. Thanks for documenting the algorithm carefully."}