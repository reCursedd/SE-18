{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7963", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7963/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7963/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7963/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/7963", "id": 210997116, "node_id": "MDExOlB1bGxSZXF1ZXN0MTA4NDc5NDQ1", "number": 7963, "title": "Fix TensorFlow compilation errors with KNL optimization flags (-mavx512f)", "user": {"login": "vamsi-sripathi", "id": 18724658, "node_id": "MDQ6VXNlcjE4NzI0NjU4", "avatar_url": "https://avatars3.githubusercontent.com/u/18724658?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vamsi-sripathi", "html_url": "https://github.com/vamsi-sripathi", "followers_url": "https://api.github.com/users/vamsi-sripathi/followers", "following_url": "https://api.github.com/users/vamsi-sripathi/following{/other_user}", "gists_url": "https://api.github.com/users/vamsi-sripathi/gists{/gist_id}", "starred_url": "https://api.github.com/users/vamsi-sripathi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vamsi-sripathi/subscriptions", "organizations_url": "https://api.github.com/users/vamsi-sripathi/orgs", "repos_url": "https://api.github.com/users/vamsi-sripathi/repos", "events_url": "https://api.github.com/users/vamsi-sripathi/events{/privacy}", "received_events_url": "https://api.github.com/users/vamsi-sripathi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}, {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-03-01T07:06:19Z", "updated_at": "2017-03-02T22:09:54Z", "closed_at": "2017-03-02T00:05:48Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7963", "html_url": "https://github.com/tensorflow/tensorflow/pull/7963", "diff_url": "https://github.com/tensorflow/tensorflow/pull/7963.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/7963.patch"}, "body_html": "<p>This fixes the compilation errors (listed below) encountered when building TensorFlow with -mavx512f flag. -mavx512f enables generation of AVX-512 Foundational instructions in TF/Eigen and are needed for optimal performance on Knights Landing (Intel Xeon Phi x200) architecture.</p>\n<p>./tensorflow/core/kernels/sparse_matmul_op.h:258:46: error: cannot convert 'const Packet8d {aka const __vector(8) double}' to '__m512 {aka __vector(16) float}' for argument '1' to '__m128 _mm512_extractf32x4_ps(__m512, int)'<br>\n./tensorflow/core/kernels/sparse_matmul_op.h:263:61: error: cannot convert 'const Packet8d {aka const __vector(8) double}' to '__m512 {aka __vector(16) float}' for argument '1' to '__m128 _mm512_extractf32x4_ps(__m512, int)'<br>\n./tensorflow/core/kernels/sparse_matmul_op.h:420:77: error: cannot convert 'const Packet16f {aka const __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'<br>\n./tensorflow/core/kernels/sparse_matmul_op.h:427:59: error: cannot convert 'const Packet16f {aka const __vector(16) float}' to '__m512d {aka __vector(8) double}' for argument '1' to '__m256d _mm512_extractf64x4_pd(__m512d, int)'<br>\n./tensorflow/core/kernels/eigen_pooling.h:334:67: error: cannot convert '__m512i {aka __vector(8) long long int}' to '__vector(16) float' in initialization<br>\n./tensorflow/core/kernels/eigen_pooling.h:335:57: error: cannot convert '__vector(16) float' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_ternarylogic_epi64(__m512i, __m512i, __m512i, int)'<br>\n./tensorflow/core/kernels/eigen_pooling.h:335:57: error: cannot convert '__vector(16) float' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_ternarylogic_epi64(__m512i, __m512i, __m512i, int)'</p>", "body_text": "This fixes the compilation errors (listed below) encountered when building TensorFlow with -mavx512f flag. -mavx512f enables generation of AVX-512 Foundational instructions in TF/Eigen and are needed for optimal performance on Knights Landing (Intel Xeon Phi x200) architecture.\n./tensorflow/core/kernels/sparse_matmul_op.h:258:46: error: cannot convert 'const Packet8d {aka const __vector(8) double}' to '__m512 {aka __vector(16) float}' for argument '1' to '__m128 _mm512_extractf32x4_ps(__m512, int)'\n./tensorflow/core/kernels/sparse_matmul_op.h:263:61: error: cannot convert 'const Packet8d {aka const __vector(8) double}' to '__m512 {aka __vector(16) float}' for argument '1' to '__m128 _mm512_extractf32x4_ps(__m512, int)'\n./tensorflow/core/kernels/sparse_matmul_op.h:420:77: error: cannot convert 'const Packet16f {aka const __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\n./tensorflow/core/kernels/sparse_matmul_op.h:427:59: error: cannot convert 'const Packet16f {aka const __vector(16) float}' to '__m512d {aka __vector(8) double}' for argument '1' to '__m256d _mm512_extractf64x4_pd(__m512d, int)'\n./tensorflow/core/kernels/eigen_pooling.h:334:67: error: cannot convert '__m512i {aka __vector(8) long long int}' to '__vector(16) float' in initialization\n./tensorflow/core/kernels/eigen_pooling.h:335:57: error: cannot convert '__vector(16) float' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_ternarylogic_epi64(__m512i, __m512i, __m512i, int)'\n./tensorflow/core/kernels/eigen_pooling.h:335:57: error: cannot convert '__vector(16) float' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_ternarylogic_epi64(__m512i, __m512i, __m512i, int)'", "body": "This fixes the compilation errors (listed below) encountered when building TensorFlow with -mavx512f flag. -mavx512f enables generation of AVX-512 Foundational instructions in TF/Eigen and are needed for optimal performance on Knights Landing (Intel Xeon Phi x200) architecture.\r\n\r\n./tensorflow/core/kernels/sparse_matmul_op.h:258:46: error: cannot convert 'const Packet8d {aka const __vector(8) double}' to '__m512 {aka __vector(16) float}' for argument '1' to '__m128 _mm512_extractf32x4_ps(__m512, int)'\r\n./tensorflow/core/kernels/sparse_matmul_op.h:263:61: error: cannot convert 'const Packet8d {aka const __vector(8) double}' to '__m512 {aka __vector(16) float}' for argument '1' to '__m128 _mm512_extractf32x4_ps(__m512, int)'\r\n./tensorflow/core/kernels/sparse_matmul_op.h:420:77: error: cannot convert 'const Packet16f {aka const __vector(16) float}' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m256i _mm512_castsi512_si256(__m512i)'\r\n./tensorflow/core/kernels/sparse_matmul_op.h:427:59: error: cannot convert 'const Packet16f {aka const __vector(16) float}' to '__m512d {aka __vector(8) double}' for argument '1' to '__m256d _mm512_extractf64x4_pd(__m512d, int)'\r\n./tensorflow/core/kernels/eigen_pooling.h:334:67: error: cannot convert '__m512i {aka __vector(8) long long int}' to '__vector(16) float' in initialization\r\n./tensorflow/core/kernels/eigen_pooling.h:335:57: error: cannot convert '__vector(16) float' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_ternarylogic_epi64(__m512i, __m512i, __m512i, int)'\r\n./tensorflow/core/kernels/eigen_pooling.h:335:57: error: cannot convert '__vector(16) float' to '__m512i {aka __vector(8) long long int}' for argument '1' to '__m512i _mm512_ternarylogic_epi64(__m512i, __m512i, __m512i, int)'\r\n"}