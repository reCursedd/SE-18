{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/273919317", "html_url": "https://github.com/tensorflow/tensorflow/issues/6961#issuecomment-273919317", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6961", "id": 273919317, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MzkxOTMxNw==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-19T22:29:35Z", "updated_at": "2017-01-20T20:38:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>a way to break the loop while capturing backprop graph in a function is to call <code>symbolic_gradient</code> on a copy of <code>A</code> instead of <code>A</code> directly.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/23068/22128144/156da6fc-de54-11e6-8c90-7259b4587343.png\"><img width=\"307\" height=\"202\" src=\"https://cloud.githubusercontent.com/assets/23068/22128144/156da6fc-de54-11e6-8c90-7259b4587343.png\" style=\"max-width:100%;\"></a></p>\n<p>Not sure how easy it is to detect this kind of computation loops, but a warning from TF runtime would help debugging.</p>", "body_text": "a way to break the loop while capturing backprop graph in a function is to call symbolic_gradient on a copy of A instead of A directly.\n\nNot sure how easy it is to detect this kind of computation loops, but a warning from TF runtime would help debugging.", "body": "a way to break the loop while capturing backprop graph in a function is to call `symbolic_gradient` on a copy of `A` instead of `A` directly. \r\n\r\n<img width=307 height=202\r\nsrc=https://cloud.githubusercontent.com/assets/23068/22128144/156da6fc-de54-11e6-8c90-7259b4587343.png>\r\n\r\nNot sure how easy it is to detect this kind of computation loops, but a warning from TF runtime would help debugging."}