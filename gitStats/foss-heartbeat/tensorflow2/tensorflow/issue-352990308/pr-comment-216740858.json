{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/216740858", "pull_request_review_id": 154277870, "id": 216740858, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNjc0MDg1OA==", "diff_hunk": "@@ -0,0 +1,257 @@\n+# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Estimator classes for TensorForest.\"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import collections\n+import math\n+\n+from tensorflow.python.estimator import estimator\n+from tensorflow.python.estimator.canned import head as head_lib\n+from tensorflow.python.ops.losses import losses\n+from tensorflow.python.summary import summary\n+from tensorflow.python.feature_column import feature_column as feature_column_lib\n+from tensorflow.python.ops import gen_tensor_forest_ops\n+from tensorflow.python.ops import tensor_forest_ops, math_ops, array_ops\n+\n+# from tensorflow.python.util.tf_export import estimator_export\n+\n+_ForestHParams = collections.namedtuple('TreeHParams', [\n+    'logits_dimension',\n+    'n_trees', 'max_nodes', 'num_splits_to_consider',\n+    'split_node_after_samples', 'is_regression',\n+])\n+\n+VARIANCE_PREDICTION_KEY = 'prediction_variance'\n+\n+\n+class RandomForestGraphs(object):\n+  \"\"\"Builds TF graphs for random forest training and inference.\"\"\"\n+\n+  def __init__(self,\n+               params,\n+               configs,\n+               tree_configs=None):\n+    self._params = params\n+    self._configs = configs\n+    self._variables = tensor_forest_ops.ForestVariables(\n+        self._params,\n+        tree_configs=tree_configs)\n+\n+  def inference_graph(self, dense_features):\n+    \"\"\" Builds inference graphs\"\"\"\n+\n+    logits = [\n+        gen_tensor_forest_ops.tensor_forest_tree_predict(\n+            tree_variable,\n+            dense_features,\n+            self._params.logits_dimension)\n+        for tree_variable in self._variables\n+    ]\n+\n+    # shape of all_predict should be [batch_size, n_trees, logits_dimension]\n+    all_predict = array_ops.stack(logits, axis=1)\n+    average_values = math_ops.div(\n+        math_ops.reduce_sum(all_predict, 1),\n+        self._params.n_trees,\n+        name='probabilities')\n+\n+    expected_squares = math_ops.div(\n+        math_ops.reduce_sum(all_predict * all_predict, 1),\n+        self._params.n_trees)\n+    regression_variance = math_ops.maximum(\n+        0., expected_squares - average_values * average_values)\n+\n+    return average_values, regression_variance\n+\n+  def average_size(self):\n+    sizes = [gen_tensor_forest_ops.tensor_forest_tree_size(tree_variable)\n+             for tree_variable in self._variables]\n+    return math_ops.reduce_mean(math_ops.to_float(array_ops.stack(sizes)))\n+\n+\n+def _tensor_forest_model_fn(features,\n+                            labels,\n+                            mode,\n+                            head,\n+                            sorted_feature_columns,\n+                            forest_hparams,\n+                            config,\n+                            name='tensor_forest'):\n+  \"\"\"tensor forest model function\"\"\"\n+  with ops.name_scope(name):\n+    graph_builder = RandomForestGraphs(\n+        forest_hparams, config)\n+    # pylint: disable=protected-access\n+    transformed_features = feature_column_lib._transform_features(\n+        features, sorted_feature_columns)\n+\n+    dense_features = array_ops.concat(transformed_features.values(), axis=1)\n+\n+    logits, regression_variance = graph_builder.inference_graph(\n+        dense_features)\n+\n+    summary.scalar('average_tree_size', graph_builder.average_size())\n+\n+  training_graph = None\n+\n+  def _train_op_fn(unused_loss):\n+    del unused_loss\n+    return training_graph\n+\n+  estimator_spec = head.create_estimator_spec(\n+      features=features,\n+      mode=mode,\n+      labels=labels,\n+      train_op_fn=_train_op_fn,\n+      logits=logits)\n+\n+  extra_predictions = {\n+      VARIANCE_PREDICTION_KEY: regression_variance\n+  }\n+\n+  estimator_spec = estimator_spec._replace(\n+      predictions=estimator_spec.predictions.update(extra_predictions))\n+\n+  return estimator_spec\n+\n+\n+# @estimator_export('estimator.TensorForestClassifier')\n+class TensorForestClassifier(estimator.Estimator):\n+  \"\"\" TensorForest Classifier \"\"\"\n+\n+  def __init__(self,\n+               feature_columns,\n+               model_dir=None,\n+               n_classes=2,\n+               label_vocabulary=None,\n+               head=None,\n+               n_trees=100,\n+               max_nodes=1000,\n+               num_splits_to_consider=None,\n+               split_node_after_samples=250,\n+               config=None):\n+    \"\"\"Initializes a `TensorForestClassifier` instance.\n+\n+    Example:\n+\n+    ```python\n+    feature_1 = numeric_column('feature_1')\n+    feature_2 = numeric_column('feature_2')\n+\n+    classifier = estimator.TensorForestClassifier(feature_columns=[feature_1,\n+                                                feature_2],\n+\t\t\t\t\t\tmodel_dir=None,\n+\t\t\t\t\t\tn_classes=2,\n+\t\t\t\t\t\tlabel_vocabulary=None,\n+\t\t\t\t\t\thead=None,\n+\t\t\t\t\t\tn_trees=100,\n+\t\t\t\t\t\tmax_nodes=1000,\n+\t\t\t\t\t\tnum_splits_to_consider=10,\n+\t\t\t\t\t\tsplit_after_samples=250,\n+\t\t\t\t\t\tconfig=None)\n+\n+\n+    def input_fn_train():\n+        ...\n+        return dataset\n+\n+    classifier.train(input_fn=input_fn_train)\n+\n+    def input_fn_predict():\n+        ...\n+        return dataset\n+\n+    classifier.predict(input_fn=input_fn_predict)\n+\n+    def input_fn_eval():\n+        ...\n+        return dataset\n+\n+    metrics = classifier.evaluate(input_fn=input_fn_eval)\n+    ```\n+\n+    Args:\n+      feature_columns: An iterable containing all the feature columns used\n+        by the model.All items in the set should be instances of classes\n+        derived from FeatureColumn.\n+      n_classes: Defaults to 2. The number of classes in a classification\n+        problem.\n+      model_dir: Directory to save model parameters, graph and etc. This can\n+        also be used to load checkpoints from the directory into an estimator\n+        to continue training a previously saved model.\n+      label_vocabulary: A list of strings representing all possible label\n+        values. If provided, labels must be of string type and their values\n+        must be present in label_vocabulary list. If label_vocabulary is\n+        omitted, it is assumed that the labels are already encoded as integer\n+        values within {0, 1} for `n_classes=2`, or encoded as integer values\n+        in {0, 1,..., n_classes-1} for `n_classes>2`. If vocabulary is not\n+        provided and labels are of string, an error will be generated.\n+      head: A `canned.Head` instance, the loss would be calculated for\n+        metrics purpose and not being used for training. If not provided,\n+        one will be automatically created based on `n_classes`.\n+      n_trees: The number of trees to create. Defaults to 100. There usually\n+        isn't any accuracy gain from using higher values (assuming deep\n+        enough trees are built).\n+      max_nodes: Default to 10k. No tree is allowed to grow beyond max_nodes\n+        nodes, and training stops when all trees in the forest are this large.\n+      num_splits_to_consider: Defaults to sqrt(num_features). In the extremely\n+        randomized tree training algorithm, only this many potential splits\n+        are evaluated for each tree node.\n+      split_node_after_samples: Defaults to 250. In our online version of\n+        extremely randomized tree training, we pick a split for a node after\n+        it has accumulated this many training samples.\n+      config: RunConfig object to configure the runtime settings.\n+\n+    Returns:\n+      A `TensorForestClassifier` instance.\n+    \"\"\"\n+\n+    if head is None:\n+      # pylint: disable=protected-access\n+      head = head_lib._binary_logistic_or_multi_class_head(\n+          n_classes=n_classes,\n+          weight_column=None,\n+          label_vocabulary=label_vocabulary,\n+          loss_reduction=losses.Reduction.SUM_OVER_BATCH_SIZE)\n+\n+    assert all(isinstance(fc, feature_column_lib.DenseColumn)\n+               for fc in feature_columns), 'Only Dense Column supported'", "path": "tensorflow/python/estimator/canned/tensor_forest.py", "position": null, "original_position": 233, "commit_id": "8e85fe418aa40e5e4d4d4700dd491f4cbef4b30e", "original_commit_id": "bde776ab80be61a02b3714459acf4076b671456b", "user": {"login": "nataliaponomareva", "id": 4313109, "node_id": "MDQ6VXNlcjQzMTMxMDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/4313109?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nataliaponomareva", "html_url": "https://github.com/nataliaponomareva", "followers_url": "https://api.github.com/users/nataliaponomareva/followers", "following_url": "https://api.github.com/users/nataliaponomareva/following{/other_user}", "gists_url": "https://api.github.com/users/nataliaponomareva/gists{/gist_id}", "starred_url": "https://api.github.com/users/nataliaponomareva/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nataliaponomareva/subscriptions", "organizations_url": "https://api.github.com/users/nataliaponomareva/orgs", "repos_url": "https://api.github.com/users/nataliaponomareva/repos", "events_url": "https://api.github.com/users/nataliaponomareva/events{/privacy}", "received_events_url": "https://api.github.com/users/nataliaponomareva/received_events", "type": "User", "site_admin": false}, "body": "columns are supported for now", "created_at": "2018-09-11T16:49:03Z", "updated_at": "2018-11-13T17:25:40Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21803#discussion_r216740858", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21803", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/216740858"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21803#discussion_r216740858"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21803"}}, "body_html": "<p>columns are supported for now</p>", "body_text": "columns are supported for now"}