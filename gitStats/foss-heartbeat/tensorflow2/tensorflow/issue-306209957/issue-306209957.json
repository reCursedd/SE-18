{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17802", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17802/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17802/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17802/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17802", "id": 306209957, "node_id": "MDU6SXNzdWUzMDYyMDk5NTc=", "number": 17802, "title": "Importing a meta graph which contains a SummaryWriter doesn't work", "user": {"login": "darthdeus", "id": 123374, "node_id": "MDQ6VXNlcjEyMzM3NA==", "avatar_url": "https://avatars1.githubusercontent.com/u/123374?v=4", "gravatar_id": "", "url": "https://api.github.com/users/darthdeus", "html_url": "https://github.com/darthdeus", "followers_url": "https://api.github.com/users/darthdeus/followers", "following_url": "https://api.github.com/users/darthdeus/following{/other_user}", "gists_url": "https://api.github.com/users/darthdeus/gists{/gist_id}", "starred_url": "https://api.github.com/users/darthdeus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/darthdeus/subscriptions", "organizations_url": "https://api.github.com/users/darthdeus/orgs", "repos_url": "https://api.github.com/users/darthdeus/repos", "events_url": "https://api.github.com/users/darthdeus/events{/privacy}", "received_events_url": "https://api.github.com/users/darthdeus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-03-18T03:24:59Z", "updated_at": "2018-03-20T22:20:23Z", "closed_at": "2018-03-20T22:20:23Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 17.10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary via pip</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.6.0-0-gd2e24b6039 1.6.0</li>\n<li><strong>Python version</strong>: 3.6.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7.0</li>\n<li><strong>GPU model and memory</strong>: GTX 1080ti 11G</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>First run this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\nv1 <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>v1<span class=\"pl-pds\">\"</span></span>)\nv2 <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>v2<span class=\"pl-pds\">\"</span></span>)\nv3 <span class=\"pl-k\">=</span> v1 <span class=\"pl-k\">*</span> v2\nvx <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">10.0</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>vx<span class=\"pl-pds\">\"</span></span>)\nv4 <span class=\"pl-k\">=</span> v3 <span class=\"pl-k\">*</span> vx\nwriter <span class=\"pl-k\">=</span> tf.contrib.summary.create_file_writer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>foo<span class=\"pl-pds\">\"</span></span>)\nsaver <span class=\"pl-k\">=</span> tf.train.Saver([vx])\nsess <span class=\"pl-k\">=</span> tf.Session()\nsess.run(tf.initialize_all_variables())\nsess.run(vx.assign(tf.add(vx, vx)))\nresult <span class=\"pl-k\">=</span> sess.run(v4, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{v1:<span class=\"pl-c1\">12.0</span>, v2:<span class=\"pl-c1\">3.3</span>})\n<span class=\"pl-c1\">print</span>(result)\nsaver.save(sess, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>./model_ex1<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p><strong>Then in a different Python instance</strong> (it works if done right after the first snippet within the same instance)</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\nsaver <span class=\"pl-k\">=</span> tf.train.import_meta_graph(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>./model_ex1.meta<span class=\"pl-pds\">\"</span></span>)\nsess <span class=\"pl-k\">=</span> tf.Session()\nsaver.restore(sess, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>./model_ex1<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<h3>Describe the problem</h3>\n<p>Trying to restore the meta graph via <code>import_meta_graph</code> does not work if the graph contains a SummaryWriter as shown in the example above. The example works if <code>import_meta_graph</code> is called within the same instance of Python, or if the <code>tf.contrib.summary.create_file_writer(\"foo\")</code> call is removed from the graph.</p>\n<h3>Source code / logs</h3>\n<pre><code>---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n&lt;ipython-input-1-1661c33bc0e5&gt; in &lt;module&gt;()\n      1 import tensorflow as tf\n----&gt; 2 saver = tf.train.import_meta_graph(\"./model_ex1.meta\")\n      3 sess = tf.Session()\n      4 saver.restore(sess, \"./model_ex1\")\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)\n   1907                                       clear_devices=clear_devices,\n   1908                                       import_scope=import_scope,\n-&gt; 1909                                       **kwargs)\n   1910   if meta_graph_def.HasField(\"saver_def\"):\n   1911     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)\n    735     importer.import_graph_def(\n    736         input_graph_def, name=(import_scope or \"\"), input_map=input_map,\n--&gt; 737         producer_op_list=producer_op_list)\n    738\n    739     # Restores all the other collections.\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\n    430                 'in a future version' if date is None else ('after %s' % date),\n    431                 instructions)\n--&gt; 432       return func(*args, **kwargs)\n    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n    434                                        _add_deprecated_arg_notice_to_docstring(\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\n    429   if producer_op_list is not None:\n    430     # TODO(skyewm): make a copy of graph_def so we're not mutating the argument?\n--&gt; 431     _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\n    432\n    433   graph = ops.get_default_graph()\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\n    209     # Remove any default attr values that aren't in op_def.\n    210     if node.op in producer_op_dict:\n--&gt; 211       op_def = op_dict[node.op]\n    212       producer_op_def = producer_op_dict[node.op]\n    213       # We make a copy of node.attr to iterate through since we may modify\n\nKeyError: 'SummaryWriter'\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 17.10\nTensorFlow installed from (source or binary): binary via pip\nTensorFlow version (use command below): v1.6.0-0-gd2e24b6039 1.6.0\nPython version: 3.6.4\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 9.0/7.0\nGPU model and memory: GTX 1080ti 11G\nExact command to reproduce:\n\nFirst run this:\nimport tensorflow as tf\nv1 = tf.placeholder(tf.float32, name=\"v1\")\nv2 = tf.placeholder(tf.float32, name=\"v2\")\nv3 = v1 * v2\nvx = tf.Variable(10.0, name=\"vx\")\nv4 = v3 * vx\nwriter = tf.contrib.summary.create_file_writer(\"foo\")\nsaver = tf.train.Saver([vx])\nsess = tf.Session()\nsess.run(tf.initialize_all_variables())\nsess.run(vx.assign(tf.add(vx, vx)))\nresult = sess.run(v4, feed_dict={v1:12.0, v2:3.3})\nprint(result)\nsaver.save(sess, \"./model_ex1\")\nThen in a different Python instance (it works if done right after the first snippet within the same instance)\nimport tensorflow as tf\nsaver = tf.train.import_meta_graph(\"./model_ex1.meta\")\nsess = tf.Session()\nsaver.restore(sess, \"./model_ex1\")\nDescribe the problem\nTrying to restore the meta graph via import_meta_graph does not work if the graph contains a SummaryWriter as shown in the example above. The example works if import_meta_graph is called within the same instance of Python, or if the tf.contrib.summary.create_file_writer(\"foo\") call is removed from the graph.\nSource code / logs\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n<ipython-input-1-1661c33bc0e5> in <module>()\n      1 import tensorflow as tf\n----> 2 saver = tf.train.import_meta_graph(\"./model_ex1.meta\")\n      3 sess = tf.Session()\n      4 saver.restore(sess, \"./model_ex1\")\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)\n   1907                                       clear_devices=clear_devices,\n   1908                                       import_scope=import_scope,\n-> 1909                                       **kwargs)\n   1910   if meta_graph_def.HasField(\"saver_def\"):\n   1911     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)\n    735     importer.import_graph_def(\n    736         input_graph_def, name=(import_scope or \"\"), input_map=input_map,\n--> 737         producer_op_list=producer_op_list)\n    738\n    739     # Restores all the other collections.\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\n    430                 'in a future version' if date is None else ('after %s' % date),\n    431                 instructions)\n--> 432       return func(*args, **kwargs)\n    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n    434                                        _add_deprecated_arg_notice_to_docstring(\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\n    429   if producer_op_list is not None:\n    430     # TODO(skyewm): make a copy of graph_def so we're not mutating the argument?\n--> 431     _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\n    432\n    433   graph = ops.get_default_graph()\n\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\n    209     # Remove any default attr values that aren't in op_def.\n    210     if node.op in producer_op_dict:\n--> 211       op_def = op_dict[node.op]\n    212       producer_op_def = producer_op_dict[node.op]\n    213       # We make a copy of node.attr to iterate through since we may modify\n\nKeyError: 'SummaryWriter'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: binary via pip\r\n- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039 1.6.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: GTX 1080ti 11G\r\n- **Exact command to reproduce**:\r\n\r\nFirst run this:\r\n\r\n```python\r\nimport tensorflow as tf\r\nv1 = tf.placeholder(tf.float32, name=\"v1\")\r\nv2 = tf.placeholder(tf.float32, name=\"v2\")\r\nv3 = v1 * v2\r\nvx = tf.Variable(10.0, name=\"vx\")\r\nv4 = v3 * vx\r\nwriter = tf.contrib.summary.create_file_writer(\"foo\")\r\nsaver = tf.train.Saver([vx])\r\nsess = tf.Session()\r\nsess.run(tf.initialize_all_variables())\r\nsess.run(vx.assign(tf.add(vx, vx)))\r\nresult = sess.run(v4, feed_dict={v1:12.0, v2:3.3})\r\nprint(result)\r\nsaver.save(sess, \"./model_ex1\")\r\n```\r\n\r\n**Then in a different Python instance** (it works if done right after the first snippet within the same instance)\r\n\r\n```python\r\nimport tensorflow as tf\r\nsaver = tf.train.import_meta_graph(\"./model_ex1.meta\")\r\nsess = tf.Session()\r\nsaver.restore(sess, \"./model_ex1\")\r\n```\r\n\r\n\r\n### Describe the problem\r\n\r\nTrying to restore the meta graph via `import_meta_graph` does not work if the graph contains a SummaryWriter as shown in the example above. The example works if `import_meta_graph` is called within the same instance of Python, or if the `tf.contrib.summary.create_file_writer(\"foo\")` call is removed from the graph.\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-1-1661c33bc0e5> in <module>()\r\n      1 import tensorflow as tf\r\n----> 2 saver = tf.train.import_meta_graph(\"./model_ex1.meta\")\r\n      3 sess = tf.Session()\r\n      4 saver.restore(sess, \"./model_ex1\")\r\n\r\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)\r\n   1907                                       clear_devices=clear_devices,\r\n   1908                                       import_scope=import_scope,\r\n-> 1909                                       **kwargs)\r\n   1910   if meta_graph_def.HasField(\"saver_def\"):\r\n   1911     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)\r\n\r\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)\r\n    735     importer.import_graph_def(\r\n    736         input_graph_def, name=(import_scope or \"\"), input_map=input_map,\r\n--> 737         producer_op_list=producer_op_list)\r\n    738\r\n    739     # Restores all the other collections.\r\n\r\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    430                 'in a future version' if date is None else ('after %s' % date),\r\n    431                 instructions)\r\n--> 432       return func(*args, **kwargs)\r\n    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    434                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\r\n    429   if producer_op_list is not None:\r\n    430     # TODO(skyewm): make a copy of graph_def so we're not mutating the argument?\r\n--> 431     _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\r\n    432\r\n    433   graph = ops.get_default_graph()\r\n\r\n~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\r\n    209     # Remove any default attr values that aren't in op_def.\r\n    210     if node.op in producer_op_dict:\r\n--> 211       op_def = op_dict[node.op]\r\n    212       producer_op_def = producer_op_dict[node.op]\r\n    213       # We make a copy of node.attr to iterate through since we may modify\r\n\r\nKeyError: 'SummaryWriter'\r\n```"}