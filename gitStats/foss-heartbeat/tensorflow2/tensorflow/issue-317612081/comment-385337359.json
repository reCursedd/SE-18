{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385337359", "html_url": "https://github.com/tensorflow/tensorflow/issues/18861#issuecomment-385337359", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18861", "id": 385337359, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTMzNzM1OQ==", "user": {"login": "kerolos", "id": 3300016, "node_id": "MDQ6VXNlcjMzMDAwMTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/3300016?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kerolos", "html_url": "https://github.com/kerolos", "followers_url": "https://api.github.com/users/kerolos/followers", "following_url": "https://api.github.com/users/kerolos/following{/other_user}", "gists_url": "https://api.github.com/users/kerolos/gists{/gist_id}", "starred_url": "https://api.github.com/users/kerolos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kerolos/subscriptions", "organizations_url": "https://api.github.com/users/kerolos/orgs", "repos_url": "https://api.github.com/users/kerolos/repos", "events_url": "https://api.github.com/users/kerolos/events{/privacy}", "received_events_url": "https://api.github.com/users/kerolos/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-30T08:21:55Z", "updated_at": "2018-04-30T08:57:23Z", "author_association": "NONE", "body_html": "<p>Running multiple models in parallel with different GPUs in Tensorflow for Prediction:</p>\n<h3>Describe the problem</h3>\n<p>I would like to run two models for prediction in two different GPUs to speed up the running time (by creating two instance of sessions in two GPUs).<br>\nthe first model is computing to the first GPU and the second is computing in the second GPU by executing each session for a specific device, something like that in python \"with tf.device('/gpu:0') \"</p>\n<h3>Source code / logs</h3>\n<pre><code>int GPUID = std::stoi(params-&gt;getGpuDeviceStr());\nsetenv(\"CUDA_VISIBLE_DEVICES\", \"\", GPUID);\n\nstd::cout &lt;&lt; \"Initial  visible_device_list : \"&lt;&lt;session_options.config.gpu_options().visible_device_list() &lt;&lt; std::endl;\nsession_options.config.mutable_gpu_options()-&gt;set_allow_growth(true);\nsession_options.config.mutable_gpu_options()-&gt;set_per_process_gpu_memory_fraction(\n        params-&gt;getGpuMemoryRatio());\n</code></pre>\n<h3>output:</h3>\n<p>2018-04-30 10:18:56.625199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 0 with properties:<br>\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683<br>\npciBusID: 0000:09:00.0<br>\ntotalMemory: 10,91GiB freeMemory: 10,75GiB<br>\n2018-04-30 10:18:56.750435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 1 with properties:<br>\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683<br>\npciBusID: 0000:42:00.0<br>\ntotalMemory: 10,91GiB freeMemory: 10,42GiB<br>\n2018-04-30 10:18:56.751296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1223] Device peer to peer matrix<br>\n2018-04-30 10:18:56.751324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1229] DMA: 0 1<br>\n2018-04-30 10:18:56.751332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1239] 0:   Y Y<br>\n2018-04-30 10:18:56.751337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1239] 1:   Y Y<br>\n2018-04-30 10:18:56.751345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1308] Adding visible gpu devices: 0, 1<br>\n2018-04-30 10:18:57.110046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10055 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)<br>\n2018-04-30 10:18:57.110819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10050 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)<br>\nRunning tensorflow in Version 1.5.0</p>\n<h3>Discussion:</h3>\n<p>i cannot see any improvement in time-consuming by running two model simultaneously by creating two threads to run two models in two GPUs. the time consuming by running two model in two GPUs is approximately the same as running by using only one GPU.</p>", "body_text": "Running multiple models in parallel with different GPUs in Tensorflow for Prediction:\nDescribe the problem\nI would like to run two models for prediction in two different GPUs to speed up the running time (by creating two instance of sessions in two GPUs).\nthe first model is computing to the first GPU and the second is computing in the second GPU by executing each session for a specific device, something like that in python \"with tf.device('/gpu:0') \"\nSource code / logs\nint GPUID = std::stoi(params->getGpuDeviceStr());\nsetenv(\"CUDA_VISIBLE_DEVICES\", \"\", GPUID);\n\nstd::cout << \"Initial  visible_device_list : \"<<session_options.config.gpu_options().visible_device_list() << std::endl;\nsession_options.config.mutable_gpu_options()->set_allow_growth(true);\nsession_options.config.mutable_gpu_options()->set_per_process_gpu_memory_fraction(\n        params->getGpuMemoryRatio());\n\noutput:\n2018-04-30 10:18:56.625199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 0 with properties:\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\npciBusID: 0000:09:00.0\ntotalMemory: 10,91GiB freeMemory: 10,75GiB\n2018-04-30 10:18:56.750435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 1 with properties:\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\npciBusID: 0000:42:00.0\ntotalMemory: 10,91GiB freeMemory: 10,42GiB\n2018-04-30 10:18:56.751296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1223] Device peer to peer matrix\n2018-04-30 10:18:56.751324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1229] DMA: 0 1\n2018-04-30 10:18:56.751332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1239] 0:   Y Y\n2018-04-30 10:18:56.751337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1239] 1:   Y Y\n2018-04-30 10:18:56.751345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1308] Adding visible gpu devices: 0, 1\n2018-04-30 10:18:57.110046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10055 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n2018-04-30 10:18:57.110819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10050 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\nRunning tensorflow in Version 1.5.0\nDiscussion:\ni cannot see any improvement in time-consuming by running two model simultaneously by creating two threads to run two models in two GPUs. the time consuming by running two model in two GPUs is approximately the same as running by using only one GPU.", "body": "Running multiple models in parallel with different GPUs in Tensorflow for Prediction:\r\n\r\n### Describe the problem\r\nI would like to run two models for prediction in two different GPUs to speed up the running time (by creating two instance of sessions in two GPUs).\r\nthe first model is computing to the first GPU and the second is computing in the second GPU by executing each session for a specific device, something like that in python \"with tf.device('/gpu:0') \"\r\n\r\n### Source code / logs\r\n\r\n    int GPUID = std::stoi(params->getGpuDeviceStr());\r\n    setenv(\"CUDA_VISIBLE_DEVICES\", \"\", GPUID);\r\n\r\n    std::cout << \"Initial  visible_device_list : \"<<session_options.config.gpu_options().visible_device_list() << std::endl;\r\n    session_options.config.mutable_gpu_options()->set_allow_growth(true);\r\n    session_options.config.mutable_gpu_options()->set_per_process_gpu_memory_fraction(\r\n            params->getGpuMemoryRatio());\r\n\r\n### output:\r\n2018-04-30 10:18:56.625199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:09:00.0\r\ntotalMemory: 10,91GiB freeMemory: 10,75GiB\r\n2018-04-30 10:18:56.750435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:42:00.0\r\ntotalMemory: 10,91GiB freeMemory: 10,42GiB\r\n2018-04-30 10:18:56.751296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1223] Device peer to peer matrix\r\n2018-04-30 10:18:56.751324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1229] DMA: 0 1 \r\n2018-04-30 10:18:56.751332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1239] 0:   Y Y \r\n2018-04-30 10:18:56.751337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1239] 1:   Y Y \r\n2018-04-30 10:18:56.751345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1308] Adding visible gpu devices: 0, 1\r\n2018-04-30 10:18:57.110046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10055 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\r\n2018-04-30 10:18:57.110819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10050 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\r\nRunning tensorflow in Version 1.5.0\r\n\r\n### Discussion:\r\ni cannot see any improvement in time-consuming by running two model simultaneously by creating two threads to run two models in two GPUs. the time consuming by running two model in two GPUs is approximately the same as running by using only one GPU. \r\n\r\n"}