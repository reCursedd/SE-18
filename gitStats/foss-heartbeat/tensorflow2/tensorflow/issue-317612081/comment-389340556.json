{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/389340556", "html_url": "https://github.com/tensorflow/tensorflow/issues/18861#issuecomment-389340556", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18861", "id": 389340556, "node_id": "MDEyOklzc3VlQ29tbWVudDM4OTM0MDU1Ng==", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-15T23:00:07Z", "updated_at": "2018-05-15T23:00:07Z", "author_association": "MEMBER", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7693798\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rundembear\">@rundembear</a>,</p>\n<p>Sorry for the confusion, let me clarify:</p>\n<ol>\n<li>it's totally fine to use different configs in different process, there is no restriction on that. For example, you may set CUDA_VISIBLE_DEVICES=1 in one process and 2 in another, you may also set visible_gpu_device or any other ConfigProto options differently.</li>\n<li>in the same process, if possible, we should use same <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L16\">GPUOptions</a> for all sessions, as most of the options inside GPUOptions are process-wide (AFAIK, per_process_gpu_memory_fraction, allocator_type, allow_growth, visible_device_list, experimental are all process-wide options). If we use different GPUOptions for different sessions, unexpected behavior may/would occur, depending on which options you set differently.</li>\n</ol>\n<p>In your case, specifically for the code:</p>\n<pre><code>G =tf.Graph()\nsess1 = tf.Session(graph=G, config=tf.ConfigProto(log_device_placement=False,gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list='0')))\nsess2 = tf.Session(graph=G, config=tf.ConfigProto(log_device_placement=False,gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list='1')))\n</code></pre>\n<p><code>sess1</code> and <code>sess2</code> are in same process and using same graph but different GPUOptions options (visible_device_list is different).</p>\n<ul>\n<li>For <code>sess1</code>, a <code>BaseGPUDevice</code> will be created with name '/gpu:0' and pointing to <strong>physical gpu 0</strong></li>\n<li>For <code>sess2</code>, a <code>BaseGPUDevice</code> will be created with name '/gpu:0' but pointing to <strong>physical gpu 1</strong>.</li>\n</ul>\n<p>Note that both device have same name '/gpu:0', so any code that use only the device name (not the BaseGPUDevice object itself) to access the physical gpu will be directed to physical gpu 0, this is what I called 'unexpected behavior'. For example, assume that <code>G</code> has a node placed in '/gpu:0', grappler will use the information from physical gpu 0 to optimize your graph in <code>sess2</code> which is not what we want.</p>\n<p>In order to apply the same graph to different gpu, we can use <code>with tf.device()</code> with different device name when building/importing the graph.</p>\n<p>Thanks.</p>", "body_text": "Hi @rundembear,\nSorry for the confusion, let me clarify:\n\nit's totally fine to use different configs in different process, there is no restriction on that. For example, you may set CUDA_VISIBLE_DEVICES=1 in one process and 2 in another, you may also set visible_gpu_device or any other ConfigProto options differently.\nin the same process, if possible, we should use same GPUOptions for all sessions, as most of the options inside GPUOptions are process-wide (AFAIK, per_process_gpu_memory_fraction, allocator_type, allow_growth, visible_device_list, experimental are all process-wide options). If we use different GPUOptions for different sessions, unexpected behavior may/would occur, depending on which options you set differently.\n\nIn your case, specifically for the code:\nG =tf.Graph()\nsess1 = tf.Session(graph=G, config=tf.ConfigProto(log_device_placement=False,gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list='0')))\nsess2 = tf.Session(graph=G, config=tf.ConfigProto(log_device_placement=False,gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list='1')))\n\nsess1 and sess2 are in same process and using same graph but different GPUOptions options (visible_device_list is different).\n\nFor sess1, a BaseGPUDevice will be created with name '/gpu:0' and pointing to physical gpu 0\nFor sess2, a BaseGPUDevice will be created with name '/gpu:0' but pointing to physical gpu 1.\n\nNote that both device have same name '/gpu:0', so any code that use only the device name (not the BaseGPUDevice object itself) to access the physical gpu will be directed to physical gpu 0, this is what I called 'unexpected behavior'. For example, assume that G has a node placed in '/gpu:0', grappler will use the information from physical gpu 0 to optimize your graph in sess2 which is not what we want.\nIn order to apply the same graph to different gpu, we can use with tf.device() with different device name when building/importing the graph.\nThanks.", "body": "Hi @rundembear,\r\n\r\nSorry for the confusion, let me clarify:\r\n1. it's totally fine to use different configs in different process, there is no restriction on that. For example, you may set CUDA_VISIBLE_DEVICES=1 in one process and 2 in another, you may also set visible_gpu_device or any other ConfigProto options differently.\r\n1. in the same process, if possible, we should use same [GPUOptions](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L16) for all sessions, as most of the options inside GPUOptions are process-wide (AFAIK, per_process_gpu_memory_fraction, allocator_type, allow_growth, visible_device_list, experimental are all process-wide options). If we use different GPUOptions for different sessions, unexpected behavior may/would occur, depending on which options you set differently.\r\n\r\nIn your case, specifically for the code:\r\n```\r\nG =tf.Graph()\r\nsess1 = tf.Session(graph=G, config=tf.ConfigProto(log_device_placement=False,gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list='0')))\r\nsess2 = tf.Session(graph=G, config=tf.ConfigProto(log_device_placement=False,gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list='1')))\r\n```\r\n\r\n`sess1` and `sess2` are in same process and using same graph but different GPUOptions options (visible_device_list is different).\r\n\r\n- For `sess1`, a `BaseGPUDevice` will be created with name '/gpu:0' and pointing to **physical gpu 0**\r\n- For `sess2`, a `BaseGPUDevice` will be created with name '/gpu:0' but pointing to **physical gpu 1**.\r\n\r\nNote that both device have same name '/gpu:0', so any code that use only the device name (not the BaseGPUDevice object itself) to access the physical gpu will be directed to physical gpu 0, this is what I called 'unexpected behavior'. For example, assume that `G` has a node placed in '/gpu:0', grappler will use the information from physical gpu 0 to optimize your graph in `sess2` which is not what we want.\r\n\r\nIn order to apply the same graph to different gpu, we can use `with tf.device()` with different device name when building/importing the graph.\r\n\r\nThanks."}