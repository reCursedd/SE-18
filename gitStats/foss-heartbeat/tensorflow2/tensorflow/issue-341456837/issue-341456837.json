{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20834", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20834/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20834/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20834/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20834", "id": 341456837, "node_id": "MDU6SXNzdWUzNDE0NTY4Mzc=", "number": 20834, "title": "SyncReplicasOptimizer + MonitoredTrainingSession go through network many times with one session.run", "user": {"login": "muye5", "id": 1658029, "node_id": "MDQ6VXNlcjE2NTgwMjk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1658029?v=4", "gravatar_id": "", "url": "https://api.github.com/users/muye5", "html_url": "https://github.com/muye5", "followers_url": "https://api.github.com/users/muye5/followers", "following_url": "https://api.github.com/users/muye5/following{/other_user}", "gists_url": "https://api.github.com/users/muye5/gists{/gist_id}", "starred_url": "https://api.github.com/users/muye5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/muye5/subscriptions", "organizations_url": "https://api.github.com/users/muye5/orgs", "repos_url": "https://api.github.com/users/muye5/repos", "events_url": "https://api.github.com/users/muye5/events{/privacy}", "received_events_url": "https://api.github.com/users/muye5/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-07-16T10:01:52Z", "updated_at": "2018-09-15T18:48:33Z", "closed_at": "2018-09-15T18:30:17Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 7.0</li>\n<li><strong>GPU model and memory</strong>: 16G</li>\n<li><strong>Exact command to reproduce</strong>: None</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>training model by <code>tf.train.MonitoredTrainingSession</code> combined with <code>tf.train.SyncReplicasOptimizer</code>,<br>\nI find the model network will be run twice with only once <code>session.run</code> calling, and many NaN values will be raised. More, this will update the batch normalization parameters.<br>\nI do the initialization by <code>tf.train.SyncReplicasOptimizer.make_session_run_hook</code>. By the way, code will be right without <code>tf.train.SyncReplicasOptimizer</code>.</p>\n<h3>Source code / logs</h3>\n<pre><code># 1. model define\ninput = tf.placeholder_with_default()\nphase = tf.placeholder_with_default(True, shape=(), name='phase')\n... network define ...\nself.loss = xxx\n\n# 2. optimizer define\nself.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\nself.optimizer = tf.train.SyncReplicasOptimizer(self.optimizer, replicas_to_aggregate=worker_num, total_num_replicas=worker_num\uff09\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nwith tf.control_dependencies(update_ops):\n     self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)\n\n# 3. hook define\nsync_replicas_hook = self.optimizer.make_session_run_hook((flags.task_index == 0), num_tokens=0)\n\n# 4. train\nwith tf.train.MonitoredTrainingSession(master=server.target, hooks=[sync_replicas_hook], is_chief=is_chief):\n    outpus = sess.run([self.train_op, global_step], feed_dict={'phase:0':True, ...})\n</code></pre>\n<p>Problem A:<br>\nI add <code>tf.Print</code> line when define in network, I find this line executing twice with once sess.run calling.</p>\n<p>Problem B:<br>\nwhen <code>phase = True</code>, the BatchNorm Parameter update right, but when <code>phase = False</code>, <code>moving_mean</code> and <code>moving_variance</code> turn to NaN, so does the loss.</p>\n<p>Everything is OK when training with async optimizer.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.9\nPython version: 2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 7.0\nGPU model and memory: 16G\nExact command to reproduce: None\n\nDescribe the problem\ntraining model by tf.train.MonitoredTrainingSession combined with tf.train.SyncReplicasOptimizer,\nI find the model network will be run twice with only once session.run calling, and many NaN values will be raised. More, this will update the batch normalization parameters.\nI do the initialization by tf.train.SyncReplicasOptimizer.make_session_run_hook. By the way, code will be right without tf.train.SyncReplicasOptimizer.\nSource code / logs\n# 1. model define\ninput = tf.placeholder_with_default()\nphase = tf.placeholder_with_default(True, shape=(), name='phase')\n... network define ...\nself.loss = xxx\n\n# 2. optimizer define\nself.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\nself.optimizer = tf.train.SyncReplicasOptimizer(self.optimizer, replicas_to_aggregate=worker_num, total_num_replicas=worker_num\uff09\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nwith tf.control_dependencies(update_ops):\n     self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)\n\n# 3. hook define\nsync_replicas_hook = self.optimizer.make_session_run_hook((flags.task_index == 0), num_tokens=0)\n\n# 4. train\nwith tf.train.MonitoredTrainingSession(master=server.target, hooks=[sync_replicas_hook], is_chief=is_chief):\n    outpus = sess.run([self.train_op, global_step], feed_dict={'phase:0':True, ...})\n\nProblem A:\nI add tf.Print line when define in network, I find this line executing twice with once sess.run calling.\nProblem B:\nwhen phase = True, the BatchNorm Parameter update right, but when phase = False, moving_mean and moving_variance turn to NaN, so does the loss.\nEverything is OK when training with async optimizer.", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 7.0\r\n- **GPU model and memory**: 16G\r\n- **Exact command to reproduce**: None\r\n\r\n### Describe the problem\r\ntraining model by `tf.train.MonitoredTrainingSession` combined with `tf.train.SyncReplicasOptimizer`,\r\nI find the model network will be run twice with only once `session.run` calling, and many NaN values will be raised. More, this will update the batch normalization parameters.\r\nI do the initialization by `tf.train.SyncReplicasOptimizer.make_session_run_hook`. By the way, code will be right without `tf.train.SyncReplicasOptimizer`.\r\n\r\n\r\n### Source code / logs\r\n```\r\n# 1. model define\r\ninput = tf.placeholder_with_default()\r\nphase = tf.placeholder_with_default(True, shape=(), name='phase')\r\n... network define ...\r\nself.loss = xxx\r\n\r\n# 2. optimizer define\r\nself.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\r\nself.optimizer = tf.train.SyncReplicasOptimizer(self.optimizer, replicas_to_aggregate=worker_num, total_num_replicas=worker_num\uff09\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n     self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)\r\n\r\n# 3. hook define\r\nsync_replicas_hook = self.optimizer.make_session_run_hook((flags.task_index == 0), num_tokens=0)\r\n\r\n# 4. train\r\nwith tf.train.MonitoredTrainingSession(master=server.target, hooks=[sync_replicas_hook], is_chief=is_chief):\r\n    outpus = sess.run([self.train_op, global_step], feed_dict={'phase:0':True, ...})\r\n```\r\n\r\nProblem A:\r\nI add `tf.Print` line when define in network, I find this line executing twice with once sess.run calling.\r\n\r\nProblem B: \r\nwhen `phase = True`, the BatchNorm Parameter update right, but when `phase = False`, `moving_mean` and `moving_variance` turn to NaN, so does the loss.\r\n\r\nEverything is OK when training with async optimizer."}