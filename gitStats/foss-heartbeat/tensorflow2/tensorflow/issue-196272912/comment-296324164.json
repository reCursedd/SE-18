{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/296324164", "html_url": "https://github.com/tensorflow/tensorflow/issues/6385#issuecomment-296324164", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6385", "id": 296324164, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NjMyNDE2NA==", "user": {"login": "andrewharp", "id": 3376817, "node_id": "MDQ6VXNlcjMzNzY4MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3376817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewharp", "html_url": "https://github.com/andrewharp", "followers_url": "https://api.github.com/users/andrewharp/followers", "following_url": "https://api.github.com/users/andrewharp/following{/other_user}", "gists_url": "https://api.github.com/users/andrewharp/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewharp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewharp/subscriptions", "organizations_url": "https://api.github.com/users/andrewharp/orgs", "repos_url": "https://api.github.com/users/andrewharp/repos", "events_url": "https://api.github.com/users/andrewharp/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewharp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-21T23:00:17Z", "updated_at": "2017-04-21T23:00:28Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=14006062\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vyse8\">@vyse8</a> My guess is that you're running on an arm64 device, and since the app finds an arm64 variant of libtensorflow_inference.so (provided by tensorflow.aar) it expects to find the same for libtensorflow_demo.so. In this case you can fix this by changing  cpuType from \"armeabi-v7a\" to \"arm64-v8a\".</p>\n<p>Also note that you appear to now be manually building libtensorflow_inference.so in addition to grabbing it from the aar -- so you might want to go back and comment out those references or remove the dependency on the aar. Otherwise the behavior might get confusing.</p>", "body_text": "@vyse8 My guess is that you're running on an arm64 device, and since the app finds an arm64 variant of libtensorflow_inference.so (provided by tensorflow.aar) it expects to find the same for libtensorflow_demo.so. In this case you can fix this by changing  cpuType from \"armeabi-v7a\" to \"arm64-v8a\".\nAlso note that you appear to now be manually building libtensorflow_inference.so in addition to grabbing it from the aar -- so you might want to go back and comment out those references or remove the dependency on the aar. Otherwise the behavior might get confusing.", "body": "@vyse8 My guess is that you're running on an arm64 device, and since the app finds an arm64 variant of libtensorflow_inference.so (provided by tensorflow.aar) it expects to find the same for libtensorflow_demo.so. In this case you can fix this by changing  cpuType from \"armeabi-v7a\" to \"arm64-v8a\".\r\n\r\nAlso note that you appear to now be manually building libtensorflow_inference.so in addition to grabbing it from the aar -- so you might want to go back and comment out those references or remove the dependency on the aar. Otherwise the behavior might get confusing."}