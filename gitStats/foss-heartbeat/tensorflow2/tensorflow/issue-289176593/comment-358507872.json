{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/358507872", "html_url": "https://github.com/tensorflow/tensorflow/issues/16184#issuecomment-358507872", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16184", "id": 358507872, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODUwNzg3Mg==", "user": {"login": "dominiclai", "id": 28782718, "node_id": "MDQ6VXNlcjI4NzgyNzE4", "avatar_url": "https://avatars0.githubusercontent.com/u/28782718?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dominiclai", "html_url": "https://github.com/dominiclai", "followers_url": "https://api.github.com/users/dominiclai/followers", "following_url": "https://api.github.com/users/dominiclai/following{/other_user}", "gists_url": "https://api.github.com/users/dominiclai/gists{/gist_id}", "starred_url": "https://api.github.com/users/dominiclai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dominiclai/subscriptions", "organizations_url": "https://api.github.com/users/dominiclai/orgs", "repos_url": "https://api.github.com/users/dominiclai/repos", "events_url": "https://api.github.com/users/dominiclai/events{/privacy}", "received_events_url": "https://api.github.com/users/dominiclai/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-18T01:32:07Z", "updated_at": "2018-01-18T01:32:07Z", "author_association": "NONE", "body_html": "<p>OS:  CentOS 6 x86_64<br>\n(we have our compiled gcc 4.9.2 installed under /usr/local, and making use of this<br>\ncustomized toolchain for building bazel and tensorflow)<br>\nTensorflow version:  1.4.1, grabbed from github.<br>\nBazel: 0.9.0<br>\nCUDA: 9.0<br>\nCUDNN: 7.0.3<br>\nGPU:  K20m, 4GB<br>\ncommand to build:<br>\nbazel build --config=opt --config=cuda <br>\n--incompatible_load_argument_is_label=false <br>\n//tensorflow/tools/pip_package:build_pip_package</p>\n<p>In fact, if we compile the package under the host with CUDA installed, we could have a workable<br>\ntensorflow package.  However, this package has a dynamic link to /usr/lib64/libcuda.so.1.<br>\n(eg.  libtensorflow_framework.so).  This arrangement works under computational server with<br>\nGPU installed.  But it fails when running under a server without GPU (ie. no CUDA library) installed.</p>\n<p>In the past (tensorflow 1.0.0), tensorflow loads up cuda libraries by means of dso_loader<br>\n(./tensorflow/stream_executor/dso_loader.cc), but it is no longer the case under<br>\ntensorflow 1.4.1.  As a result, in the past (1.0.0), the same binary works for servers with or without CUDA library installed (ie. both GPU and non-GPU servers).  But under 1.4.1, due to the dynamic link to libcuda.so.1, the binary does not work with non-GPU servers that are without CUDA installed.  Of course, we can install cuda under those non-GPU servers to make it run.  But hey, what is the point when installing the CUDA toolkit to a non-GPU server??!!!</p>", "body_text": "OS:  CentOS 6 x86_64\n(we have our compiled gcc 4.9.2 installed under /usr/local, and making use of this\ncustomized toolchain for building bazel and tensorflow)\nTensorflow version:  1.4.1, grabbed from github.\nBazel: 0.9.0\nCUDA: 9.0\nCUDNN: 7.0.3\nGPU:  K20m, 4GB\ncommand to build:\nbazel build --config=opt --config=cuda \n--incompatible_load_argument_is_label=false \n//tensorflow/tools/pip_package:build_pip_package\nIn fact, if we compile the package under the host with CUDA installed, we could have a workable\ntensorflow package.  However, this package has a dynamic link to /usr/lib64/libcuda.so.1.\n(eg.  libtensorflow_framework.so).  This arrangement works under computational server with\nGPU installed.  But it fails when running under a server without GPU (ie. no CUDA library) installed.\nIn the past (tensorflow 1.0.0), tensorflow loads up cuda libraries by means of dso_loader\n(./tensorflow/stream_executor/dso_loader.cc), but it is no longer the case under\ntensorflow 1.4.1.  As a result, in the past (1.0.0), the same binary works for servers with or without CUDA library installed (ie. both GPU and non-GPU servers).  But under 1.4.1, due to the dynamic link to libcuda.so.1, the binary does not work with non-GPU servers that are without CUDA installed.  Of course, we can install cuda under those non-GPU servers to make it run.  But hey, what is the point when installing the CUDA toolkit to a non-GPU server??!!!", "body": "OS:  CentOS 6 x86_64\r\n(we have our compiled gcc 4.9.2 installed under /usr/local, and making use of this\r\ncustomized toolchain for building bazel and tensorflow)\r\nTensorflow version:  1.4.1, grabbed from github.\r\nBazel: 0.9.0\r\nCUDA: 9.0\r\nCUDNN: 7.0.3\r\nGPU:  K20m, 4GB\r\ncommand to build:\r\nbazel build --config=opt --config=cuda \\\r\n        --incompatible_load_argument_is_label=false \\\r\n         //tensorflow/tools/pip_package:build_pip_package\r\n\r\nIn fact, if we compile the package under the host with CUDA installed, we could have a workable\r\ntensorflow package.  However, this package has a dynamic link to /usr/lib64/libcuda.so.1.\r\n(eg.  libtensorflow_framework.so).  This arrangement works under computational server with\r\nGPU installed.  But it fails when running under a server without GPU (ie. no CUDA library) installed.\r\n\r\nIn the past (tensorflow 1.0.0), tensorflow loads up cuda libraries by means of dso_loader \r\n(./tensorflow/stream_executor/dso_loader.cc), but it is no longer the case under \r\ntensorflow 1.4.1.  As a result, in the past (1.0.0), the same binary works for servers with or without CUDA library installed (ie. both GPU and non-GPU servers).  But under 1.4.1, due to the dynamic link to libcuda.so.1, the binary does not work with non-GPU servers that are without CUDA installed.  Of course, we can install cuda under those non-GPU servers to make it run.  But hey, what is the point when installing the CUDA toolkit to a non-GPU server??!!!\r\n"}