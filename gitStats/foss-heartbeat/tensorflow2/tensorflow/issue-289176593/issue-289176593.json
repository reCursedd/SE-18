{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16184", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16184/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16184/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16184/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16184", "id": 289176593, "node_id": "MDU6SXNzdWUyODkxNzY1OTM=", "number": 16184, "title": "Tensorflow and libcuda.so.1", "user": {"login": "dominiclai", "id": 28782718, "node_id": "MDQ6VXNlcjI4NzgyNzE4", "avatar_url": "https://avatars0.githubusercontent.com/u/28782718?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dominiclai", "html_url": "https://github.com/dominiclai", "followers_url": "https://api.github.com/users/dominiclai/followers", "following_url": "https://api.github.com/users/dominiclai/following{/other_user}", "gists_url": "https://api.github.com/users/dominiclai/gists{/gist_id}", "starred_url": "https://api.github.com/users/dominiclai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dominiclai/subscriptions", "organizations_url": "https://api.github.com/users/dominiclai/orgs", "repos_url": "https://api.github.com/users/dominiclai/repos", "events_url": "https://api.github.com/users/dominiclai/events{/privacy}", "received_events_url": "https://api.github.com/users/dominiclai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "gunan", "id": 7946809, "node_id": "MDQ6VXNlcjc5NDY4MDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7946809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gunan", "html_url": "https://github.com/gunan", "followers_url": "https://api.github.com/users/gunan/followers", "following_url": "https://api.github.com/users/gunan/following{/other_user}", "gists_url": "https://api.github.com/users/gunan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gunan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gunan/subscriptions", "organizations_url": "https://api.github.com/users/gunan/orgs", "repos_url": "https://api.github.com/users/gunan/repos", "events_url": "https://api.github.com/users/gunan/events{/privacy}", "received_events_url": "https://api.github.com/users/gunan/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gunan", "id": 7946809, "node_id": "MDQ6VXNlcjc5NDY4MDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7946809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gunan", "html_url": "https://github.com/gunan", "followers_url": "https://api.github.com/users/gunan/followers", "following_url": "https://api.github.com/users/gunan/following{/other_user}", "gists_url": "https://api.github.com/users/gunan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gunan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gunan/subscriptions", "organizations_url": "https://api.github.com/users/gunan/orgs", "repos_url": "https://api.github.com/users/gunan/repos", "events_url": "https://api.github.com/users/gunan/events{/privacy}", "received_events_url": "https://api.github.com/users/gunan/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2018-01-17T08:15:06Z", "updated_at": "2018-11-10T18:48:37Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Tensorflow 1.4.1<br>\nOS:  CentOS 6/7  (we use customized gcc 4.9.2 build for CentOS 6)</p>\n<p>We have a number of computational servers.  Some are with GPU but some are not.  For the ease of maintenance, we build tensorflow from source code (bazel build) and install the modules under<br>\n/usr/local/... that all computational servers mount to the same /usr/local by means of NFS.</p>\n<p>In the past (Tensorflow 1.0.0), the module could be built without linking with libcuda.so.1.  When a computational server without GPU runs tensorflow, it could run as CPU mode without problems.  When the computational server with GPU runs tensorflow, it could detect the GPU and load up libcuda.so.1 (and libcudart.so and libcudnn.so) by using dso_loader.  This works great for supporting both GPU and non-GPU servers while sharing the same module.</p>\n<p>But I think that since 1.2.1 (at least, still 1.4.1), it seems that linking libcuda.so.1 is mandatory.  This is bad when non-GPU server would fail loading the module (missing libcuda.so.1), unless we explicitly putting libcuda.so.1 under /usr/lib64 (but this is a non-GPU server...!).</p>\n<p>Wonder if it is possible to make use of the old method of dso_loader instead of linking libcuda.so.1 for bazel building.  Thanks.</p>", "body_text": "Tensorflow 1.4.1\nOS:  CentOS 6/7  (we use customized gcc 4.9.2 build for CentOS 6)\nWe have a number of computational servers.  Some are with GPU but some are not.  For the ease of maintenance, we build tensorflow from source code (bazel build) and install the modules under\n/usr/local/... that all computational servers mount to the same /usr/local by means of NFS.\nIn the past (Tensorflow 1.0.0), the module could be built without linking with libcuda.so.1.  When a computational server without GPU runs tensorflow, it could run as CPU mode without problems.  When the computational server with GPU runs tensorflow, it could detect the GPU and load up libcuda.so.1 (and libcudart.so and libcudnn.so) by using dso_loader.  This works great for supporting both GPU and non-GPU servers while sharing the same module.\nBut I think that since 1.2.1 (at least, still 1.4.1), it seems that linking libcuda.so.1 is mandatory.  This is bad when non-GPU server would fail loading the module (missing libcuda.so.1), unless we explicitly putting libcuda.so.1 under /usr/lib64 (but this is a non-GPU server...!).\nWonder if it is possible to make use of the old method of dso_loader instead of linking libcuda.so.1 for bazel building.  Thanks.", "body": "Tensorflow 1.4.1\r\nOS:  CentOS 6/7  (we use customized gcc 4.9.2 build for CentOS 6)\r\n\r\nWe have a number of computational servers.  Some are with GPU but some are not.  For the ease of maintenance, we build tensorflow from source code (bazel build) and install the modules under\r\n/usr/local/... that all computational servers mount to the same /usr/local by means of NFS.\r\n\r\nIn the past (Tensorflow 1.0.0), the module could be built without linking with libcuda.so.1.  When a computational server without GPU runs tensorflow, it could run as CPU mode without problems.  When the computational server with GPU runs tensorflow, it could detect the GPU and load up libcuda.so.1 (and libcudart.so and libcudnn.so) by using dso_loader.  This works great for supporting both GPU and non-GPU servers while sharing the same module.\r\n\r\nBut I think that since 1.2.1 (at least, still 1.4.1), it seems that linking libcuda.so.1 is mandatory.  This is bad when non-GPU server would fail loading the module (missing libcuda.so.1), unless we explicitly putting libcuda.so.1 under /usr/lib64 (but this is a non-GPU server...!).  \r\n\r\nWonder if it is possible to make use of the old method of dso_loader instead of linking libcuda.so.1 for bazel building.  Thanks.\r\n"}