{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3724", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3724/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3724/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3724/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3724", "id": 170355832, "node_id": "MDU6SXNzdWUxNzAzNTU4MzI=", "number": 3724, "title": "Source-compiled .whl package is much slower in training", "user": {"login": "gclouding", "id": 13829403, "node_id": "MDQ6VXNlcjEzODI5NDAz", "avatar_url": "https://avatars0.githubusercontent.com/u/13829403?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gclouding", "html_url": "https://github.com/gclouding", "followers_url": "https://api.github.com/users/gclouding/followers", "following_url": "https://api.github.com/users/gclouding/following{/other_user}", "gists_url": "https://api.github.com/users/gclouding/gists{/gist_id}", "starred_url": "https://api.github.com/users/gclouding/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gclouding/subscriptions", "organizations_url": "https://api.github.com/users/gclouding/orgs", "repos_url": "https://api.github.com/users/gclouding/repos", "events_url": "https://api.github.com/users/gclouding/events{/privacy}", "received_events_url": "https://api.github.com/users/gclouding/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-08-10T08:03:34Z", "updated_at": "2016-08-11T11:06:28Z", "closed_at": "2016-08-10T16:31:27Z", "author_association": "NONE", "body_html": "<p>Recently, from my experiment, I found that running inception model using the .whl file generated by myself is much slower than using .whl file downloaded directly from the $TF_BINARY_URL.</p>\n<h3>Environment info</h3>\n<p>Operating System: ubuntu14.04<br>\nCUDA: cuda7.5<br>\nCUDNN: cudnn 5</p>\n<p>I followed the instructions<br>\n./configure<br>\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package<br>\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg<br>\nAnd I got tensorflow-0.9.0-py2-none-any.whl to install using:<br>\npip install /home/dl/bxl/tensorflow/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl<br>\n(the name of this .whl file is automatically generated )</p>\n<p>Then I downloaded the inception model related files to train following the instructions:<br>\ncd ~/models/inception<br>\nbazel build inception/imagenet_train<br>\nbazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=64 --train_dir=/tmp/imagenet_train --data_dir=/data1/ImageNet</p>\n<p>From the information printed out, I found that the speed is 8.5 samples/sec. (In the first several lines printed out, it says\uff1a<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally,<br>\nfrom which I guess CUDA/CuDNN are automatically loaded)</p>\n<p>However, if I replace the .whl file by that directly downloaded from the $TF_BINARY_URL provided in <a href=\"http://www.tensorflow.org\" rel=\"nofollow\">www.tensorflow.org</a> ( tensorflow-0.9.0-cp27-none-linux_x86_64.whl, which uses CuDNN4 and cuda7.5), and reinstall it using pip, and restart a new process to train the inception model using the same code.</p>\n<p>I got that the training speed was 20.2 samples/sec, which is nearly 2.5x faster than my first training using the .whl package generated by myself.</p>\n<p>So it is very difficult to explain. Because I use CUDNN5, I expect my version is faster, but in fact, it is 2.5x slower....</p>\n<p>Does anyone know why??</p>\n<p>Thanks in advance.</p>", "body_text": "Recently, from my experiment, I found that running inception model using the .whl file generated by myself is much slower than using .whl file downloaded directly from the $TF_BINARY_URL.\nEnvironment info\nOperating System: ubuntu14.04\nCUDA: cuda7.5\nCUDNN: cudnn 5\nI followed the instructions\n./configure\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\nAnd I got tensorflow-0.9.0-py2-none-any.whl to install using:\npip install /home/dl/bxl/tensorflow/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl\n(the name of this .whl file is automatically generated )\nThen I downloaded the inception model related files to train following the instructions:\ncd ~/models/inception\nbazel build inception/imagenet_train\nbazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=64 --train_dir=/tmp/imagenet_train --data_dir=/data1/ImageNet\nFrom the information printed out, I found that the speed is 8.5 samples/sec. (In the first several lines printed out, it says\uff1a\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally,\nfrom which I guess CUDA/CuDNN are automatically loaded)\nHowever, if I replace the .whl file by that directly downloaded from the $TF_BINARY_URL provided in www.tensorflow.org ( tensorflow-0.9.0-cp27-none-linux_x86_64.whl, which uses CuDNN4 and cuda7.5), and reinstall it using pip, and restart a new process to train the inception model using the same code.\nI got that the training speed was 20.2 samples/sec, which is nearly 2.5x faster than my first training using the .whl package generated by myself.\nSo it is very difficult to explain. Because I use CUDNN5, I expect my version is faster, but in fact, it is 2.5x slower....\nDoes anyone know why??\nThanks in advance.", "body": "Recently, from my experiment, I found that running inception model using the .whl file generated by myself is much slower than using .whl file downloaded directly from the $TF_BINARY_URL.\n### Environment info\n\nOperating System: ubuntu14.04\nCUDA: cuda7.5\nCUDNN: cudnn 5\n\nI followed the instructions\n./configure\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\nAnd I got tensorflow-0.9.0-py2-none-any.whl to install using:\npip install /home/dl/bxl/tensorflow/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl\n (the name of this .whl file is automatically generated )\n\nThen I downloaded the inception model related files to train following the instructions:\ncd ~/models/inception\nbazel build inception/imagenet_train\nbazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=64 --train_dir=/tmp/imagenet_train --data_dir=/data1/ImageNet\n\nFrom the information printed out, I found that the speed is 8.5 samples/sec. (In the first several lines printed out, it says\uff1a\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally,\nfrom which I guess CUDA/CuDNN are automatically loaded)\n\nHowever, if I replace the .whl file by that directly downloaded from the $TF_BINARY_URL provided in www.tensorflow.org ( tensorflow-0.9.0-cp27-none-linux_x86_64.whl, which uses CuDNN4 and cuda7.5), and reinstall it using pip, and restart a new process to train the inception model using the same code. \n\nI got that the training speed was 20.2 samples/sec, which is nearly 2.5x faster than my first training using the .whl package generated by myself. \n\nSo it is very difficult to explain. Because I use CUDNN5, I expect my version is faster, but in fact, it is 2.5x slower....\n\nDoes anyone know why??\n\nThanks in advance.\n"}