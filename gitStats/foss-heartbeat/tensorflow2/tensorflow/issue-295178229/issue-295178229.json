{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16835", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16835/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16835/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16835/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16835", "id": 295178229, "node_id": "MDU6SXNzdWUyOTUxNzgyMjk=", "number": 16835, "title": "Optimized einsum", "user": {"login": "Bonnevie", "id": 5861991, "node_id": "MDQ6VXNlcjU4NjE5OTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/5861991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Bonnevie", "html_url": "https://github.com/Bonnevie", "followers_url": "https://api.github.com/users/Bonnevie/followers", "following_url": "https://api.github.com/users/Bonnevie/following{/other_user}", "gists_url": "https://api.github.com/users/Bonnevie/gists{/gist_id}", "starred_url": "https://api.github.com/users/Bonnevie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Bonnevie/subscriptions", "organizations_url": "https://api.github.com/users/Bonnevie/orgs", "repos_url": "https://api.github.com/users/Bonnevie/repos", "events_url": "https://api.github.com/users/Bonnevie/events{/privacy}", "received_events_url": "https://api.github.com/users/Bonnevie/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-02-07T15:24:03Z", "updated_at": "2018-04-14T16:07:40Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>In Numpy, it's my understanding that the np.einsum function has been extended with the functionality of<br>\n<a href=\"https://github.com/dgasmith/opt_einsum\">opt_einsum</a>,<br>\nwhich computes an optimal (or near-optimal) way to perform the tensor contractions.<br>\nAs far as I've heard, the Tensorflow einsum is a lot more basic (but extremely convenient), and cannot be relied upon for performance. Also, even though <code>opt_einsum</code> can give allegedly perfect decomposition paths, these optimizations appear to not always work well in Tensorflow - which might be down to memory order, available numerical routines, views vs reshapes, etc.</p>\n<p>As a feature request, I think it would be hugely beneficial to have a high-performing version of <code>tf.einsum</code> in Tensorflow, as it makes it easy to handle many complicated linear algebra tasks compactly.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04 LTS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>", "body_text": "In Numpy, it's my understanding that the np.einsum function has been extended with the functionality of\nopt_einsum,\nwhich computes an optimal (or near-optimal) way to perform the tensor contractions.\nAs far as I've heard, the Tensorflow einsum is a lot more basic (but extremely convenient), and cannot be relied upon for performance. Also, even though opt_einsum can give allegedly perfect decomposition paths, these optimizations appear to not always work well in Tensorflow - which might be down to memory order, available numerical routines, views vs reshapes, etc.\nAs a feature request, I think it would be hugely beneficial to have a high-performing version of tf.einsum in Tensorflow, as it makes it easy to handle many complicated linear algebra tasks compactly.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 LTS\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.5\nPython version: 3.6\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A", "body": "In Numpy, it's my understanding that the np.einsum function has been extended with the functionality of\r\n[opt_einsum](https://github.com/dgasmith/opt_einsum), \r\nwhich computes an optimal (or near-optimal) way to perform the tensor contractions.\r\nAs far as I've heard, the Tensorflow einsum is a lot more basic (but extremely convenient), and cannot be relied upon for performance. Also, even though `opt_einsum` can give allegedly perfect decomposition paths, these optimizations appear to not always work well in Tensorflow - which might be down to memory order, available numerical routines, views vs reshapes, etc. \r\n\r\nAs a feature request, I think it would be hugely beneficial to have a high-performing version of `tf.einsum` in Tensorflow, as it makes it easy to handle many complicated linear algebra tasks compactly.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 LTS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n"}