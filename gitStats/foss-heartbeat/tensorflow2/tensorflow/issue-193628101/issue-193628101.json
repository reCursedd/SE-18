{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6100", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6100/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6100/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6100/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6100", "id": 193628101, "node_id": "MDU6SXNzdWUxOTM2MjgxMDE=", "number": 6100, "title": "Error on compiling model using Keras", "user": {"login": "oxrider", "id": 4476557, "node_id": "MDQ6VXNlcjQ0NzY1NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4476557?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oxrider", "html_url": "https://github.com/oxrider", "followers_url": "https://api.github.com/users/oxrider/followers", "following_url": "https://api.github.com/users/oxrider/following{/other_user}", "gists_url": "https://api.github.com/users/oxrider/gists{/gist_id}", "starred_url": "https://api.github.com/users/oxrider/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oxrider/subscriptions", "organizations_url": "https://api.github.com/users/oxrider/orgs", "repos_url": "https://api.github.com/users/oxrider/repos", "events_url": "https://api.github.com/users/oxrider/events{/privacy}", "received_events_url": "https://api.github.com/users/oxrider/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-12-05T22:26:39Z", "updated_at": "2016-12-06T17:23:46Z", "closed_at": "2016-12-06T17:23:46Z", "author_association": "NONE", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>I don't know where to begin looking for this problem. It seems like an internal bug but I am not entirely sure if it is something I did wrong. I am fairly new to tensorflow, please help!</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 16.04</p>\n<p>Installed version of CUDA and cuDNN:<br>\nCUDA 8.0, cuDNN 5.1</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed: <a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl</a></li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.<br>\n0.12.0-rc0</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<pre><code>import tensorflow as tf\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.layers.convolutional import Convolution1D\nfrom keras.layers.pooling import MaxPooling1D\nfrom keras.layers.core import Flatten\nfrom keras.engine.topology import Merge\nfrom keras import backend as K\nfrom keras.optimizers import SGD\nfrom keras.objectives import *\nfrom keras.utils.layer_utils import layer_from_config\nfrom keras.regularizers import l1, l2\nfrom keras.callbacks import *\nfrom keras.metrics import *\n\nsgd = SGD(lr=10 ** (-lr), momentum=0.9, decay=0, nesterov=True)\n\n# model1: ConvNet\nmodel = Sequential()\nmodel.add(Convolution1D(128, 6, border_mode='same', input_shape=(256,2)))\nmodel.add(MaxPooling1D())\nmodel.add(Convolution1D(64, 6, border_mode='same'))\nmodel.add(MaxPooling1D())\nmodel.add(Convolution1D(32, 6, border_mode='same'))\nmodel.add(MaxPooling1D())\nmodel.add(Convolution1D(16, 6, border_mode='same'))\nmodel.add(MaxPooling1D())\nmodel.add(Flatten())\n\n# merge model:\nmodel.add(Dense(128, name='d1'))\nmodel.add(Activation('relu'))\nmodel.add(Dense(128, name='d2'))\nmodel.add(Activation('relu'))\nmodel.add(Dense(128, name='d3'))\nmodel.add(Activation('tanh'))\nmodel.add(Dense(3))\nmodel.add(Activation('softmax'))\n\n# My y contains three columns, which can be understood as '-1', '0' and '+1'. I want to maximize the correct labeling of '+1' and '-1', don't care how many 0's that I label, and minimize the number of mis-labeling of '+1' or '-1'. \ndef func_loss(y_true, y_pred):\n\treturn -K.mean(K.prod(K.cast(K.argmax(y_pred, axis=1), K.floatx()) - 1.0), (K.cast(K.argmax(y_true, axis=1), K.floatx()) - 1.0))\n\nmodel.compile(loss=func_loss, optimizer='sgd', metrics=[categorical_accuracy])\n</code></pre>\n<h3>What other attempted solutions have you tried?</h3>\n<p>I tried numerous tweaking on the loss function but they all end up with some problems.</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>\n<blockquote>\n<p>Traceback (most recent call last):<br>\nFile \"\", line 1, in <br>\nFile \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 547, in compile<br>\n**kwargs)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 622, in compile<br>\nsample_weight, mask)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 324, in weighted<br>\nscore_array = fn(y_true, y_pred)<br>\nFile \"\", line 2, in func_loss<br>\nFile \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 490, in mean<br>\naxis = _normalize_axis(axis, ndim(x))<br>\nFile \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 435, in _normalize_axis<br>\nif axis is not None and axis &lt; 0:<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 547, in <strong>nonzero</strong><br>\nraise TypeError(\"Using a <code>tf.Tensor</code> as a Python <code>bool</code> is not allowed. \"<br>\nTypeError: Using a <code>tf.Tensor</code> as a Python <code>bool</code> is not allowed. Use <code>if t is not None:</code> instead of <code>if t:</code> to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.</p>\n</blockquote>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nI don't know where to begin looking for this problem. It seems like an internal bug but I am not entirely sure if it is something I did wrong. I am fairly new to tensorflow, please help!\nEnvironment info\nOperating System: Ubuntu 16.04\nInstalled version of CUDA and cuDNN:\nCUDA 8.0, cuDNN 5.1\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n0.12.0-rc0\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nimport tensorflow as tf\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.layers.convolutional import Convolution1D\nfrom keras.layers.pooling import MaxPooling1D\nfrom keras.layers.core import Flatten\nfrom keras.engine.topology import Merge\nfrom keras import backend as K\nfrom keras.optimizers import SGD\nfrom keras.objectives import *\nfrom keras.utils.layer_utils import layer_from_config\nfrom keras.regularizers import l1, l2\nfrom keras.callbacks import *\nfrom keras.metrics import *\n\nsgd = SGD(lr=10 ** (-lr), momentum=0.9, decay=0, nesterov=True)\n\n# model1: ConvNet\nmodel = Sequential()\nmodel.add(Convolution1D(128, 6, border_mode='same', input_shape=(256,2)))\nmodel.add(MaxPooling1D())\nmodel.add(Convolution1D(64, 6, border_mode='same'))\nmodel.add(MaxPooling1D())\nmodel.add(Convolution1D(32, 6, border_mode='same'))\nmodel.add(MaxPooling1D())\nmodel.add(Convolution1D(16, 6, border_mode='same'))\nmodel.add(MaxPooling1D())\nmodel.add(Flatten())\n\n# merge model:\nmodel.add(Dense(128, name='d1'))\nmodel.add(Activation('relu'))\nmodel.add(Dense(128, name='d2'))\nmodel.add(Activation('relu'))\nmodel.add(Dense(128, name='d3'))\nmodel.add(Activation('tanh'))\nmodel.add(Dense(3))\nmodel.add(Activation('softmax'))\n\n# My y contains three columns, which can be understood as '-1', '0' and '+1'. I want to maximize the correct labeling of '+1' and '-1', don't care how many 0's that I label, and minimize the number of mis-labeling of '+1' or '-1'. \ndef func_loss(y_true, y_pred):\n\treturn -K.mean(K.prod(K.cast(K.argmax(y_pred, axis=1), K.floatx()) - 1.0), (K.cast(K.argmax(y_true, axis=1), K.floatx()) - 1.0))\n\nmodel.compile(loss=func_loss, optimizer='sgd', metrics=[categorical_accuracy])\n\nWhat other attempted solutions have you tried?\nI tried numerous tweaking on the loss function but they all end up with some problems.\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\n\nTraceback (most recent call last):\nFile \"\", line 1, in \nFile \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 547, in compile\n**kwargs)\nFile \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 622, in compile\nsample_weight, mask)\nFile \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 324, in weighted\nscore_array = fn(y_true, y_pred)\nFile \"\", line 2, in func_loss\nFile \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 490, in mean\naxis = _normalize_axis(axis, ndim(x))\nFile \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 435, in _normalize_axis\nif axis is not None and axis < 0:\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 547, in nonzero\nraise TypeError(\"Using a tf.Tensor as a Python bool is not allowed. \"\nTypeError: Using a tf.Tensor as a Python bool is not allowed. Use if t is not None: instead of if t: to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nI don't know where to begin looking for this problem. It seems like an internal bug but I am not entirely sure if it is something I did wrong. I am fairly new to tensorflow, please help!\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN:\r\nCUDA 8.0, cuDNN 5.1\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n0.12.0-rc0\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Activation, Dropout\r\nfrom keras.layers.convolutional import Convolution1D\r\nfrom keras.layers.pooling import MaxPooling1D\r\nfrom keras.layers.core import Flatten\r\nfrom keras.engine.topology import Merge\r\nfrom keras import backend as K\r\nfrom keras.optimizers import SGD\r\nfrom keras.objectives import *\r\nfrom keras.utils.layer_utils import layer_from_config\r\nfrom keras.regularizers import l1, l2\r\nfrom keras.callbacks import *\r\nfrom keras.metrics import *\r\n\r\nsgd = SGD(lr=10 ** (-lr), momentum=0.9, decay=0, nesterov=True)\r\n\r\n# model1: ConvNet\r\nmodel = Sequential()\r\nmodel.add(Convolution1D(128, 6, border_mode='same', input_shape=(256,2)))\r\nmodel.add(MaxPooling1D())\r\nmodel.add(Convolution1D(64, 6, border_mode='same'))\r\nmodel.add(MaxPooling1D())\r\nmodel.add(Convolution1D(32, 6, border_mode='same'))\r\nmodel.add(MaxPooling1D())\r\nmodel.add(Convolution1D(16, 6, border_mode='same'))\r\nmodel.add(MaxPooling1D())\r\nmodel.add(Flatten())\r\n\r\n# merge model:\r\nmodel.add(Dense(128, name='d1'))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dense(128, name='d2'))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dense(128, name='d3'))\r\nmodel.add(Activation('tanh'))\r\nmodel.add(Dense(3))\r\nmodel.add(Activation('softmax'))\r\n\r\n# My y contains three columns, which can be understood as '-1', '0' and '+1'. I want to maximize the correct labeling of '+1' and '-1', don't care how many 0's that I label, and minimize the number of mis-labeling of '+1' or '-1'. \r\ndef func_loss(y_true, y_pred):\r\n\treturn -K.mean(K.prod(K.cast(K.argmax(y_pred, axis=1), K.floatx()) - 1.0), (K.cast(K.argmax(y_true, axis=1), K.floatx()) - 1.0))\r\n\r\nmodel.compile(loss=func_loss, optimizer='sgd', metrics=[categorical_accuracy])\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\nI tried numerous tweaking on the loss function but they all end up with some problems. \r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 547, in compile\r\n>     **kwargs)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 622, in compile\r\n>     sample_weight, mask)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 324, in weighted\r\n>     score_array = fn(y_true, y_pred)\r\n>   File \"<stdin>\", line 2, in func_loss\r\n>   File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 490, in mean\r\n>     axis = _normalize_axis(axis, ndim(x))\r\n>   File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 435, in _normalize_axis\r\n>     if axis is not None and axis < 0:\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 547, in __nonzero__\r\n>     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\r\n> TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.\r\n> "}