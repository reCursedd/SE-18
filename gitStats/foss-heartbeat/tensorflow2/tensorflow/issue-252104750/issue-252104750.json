{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12502", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12502/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12502/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12502/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/12502", "id": 252104750, "node_id": "MDExOlB1bGxSZXF1ZXN0MTM3MDkxNDM2", "number": 12502, "title": "Support for CUDA 9.0", "user": {"login": "nluehr", "id": 1873655, "node_id": "MDQ6VXNlcjE4NzM2NTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1873655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nluehr", "html_url": "https://github.com/nluehr", "followers_url": "https://api.github.com/users/nluehr/followers", "following_url": "https://api.github.com/users/nluehr/following{/other_user}", "gists_url": "https://api.github.com/users/nluehr/gists{/gist_id}", "starred_url": "https://api.github.com/users/nluehr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nluehr/subscriptions", "organizations_url": "https://api.github.com/users/nluehr/orgs", "repos_url": "https://api.github.com/users/nluehr/repos", "events_url": "https://api.github.com/users/nluehr/events{/privacy}", "received_events_url": "https://api.github.com/users/nluehr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2017-08-22T22:12:59Z", "updated_at": "2017-10-03T13:16:43Z", "closed_at": "2017-09-12T01:22:33Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12502", "html_url": "https://github.com/tensorflow/tensorflow/pull/12502", "diff_url": "https://github.com/tensorflow/tensorflow/pull/12502.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/12502.patch"}, "body_html": "<p>For review by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a>.</p>\n<p>Add explicit __syncwarp to bias_op</p>\n<ul>\n<li>Makes warp-synchronous code safe on Volta<br>\nAdd sync mask to __shfl intrinsics<br>\nAdd libdevice bytecode paths for CUDA 9</li>\n<li>In CUDA 9, all supported architectures are merged into a single file<br>\nUpdate code gating for CUDA 9<br>\nAdd sm_70 to the lookup table used by XLA<br>\nChange the default sm arch from 20 to 30.<br>\nFix for NVPTX not yet supporting sm_70<br>\nRemove unnecessary cuda decorators from defaulted constructors<br>\nUse updated NCCL for CUDA 9 fp16 support</li>\n</ul>", "body_text": "For review by @zheng-xq.\nAdd explicit __syncwarp to bias_op\n\nMakes warp-synchronous code safe on Volta\nAdd sync mask to __shfl intrinsics\nAdd libdevice bytecode paths for CUDA 9\nIn CUDA 9, all supported architectures are merged into a single file\nUpdate code gating for CUDA 9\nAdd sm_70 to the lookup table used by XLA\nChange the default sm arch from 20 to 30.\nFix for NVPTX not yet supporting sm_70\nRemove unnecessary cuda decorators from defaulted constructors\nUse updated NCCL for CUDA 9 fp16 support", "body": "For review by @zheng-xq.\r\n\r\nAdd explicit __syncwarp to bias_op\r\n - Makes warp-synchronous code safe on Volta\r\nAdd sync mask to __shfl intrinsics\r\nAdd libdevice bytecode paths for CUDA 9\r\n - In CUDA 9, all supported architectures are merged into a single file\r\nUpdate code gating for CUDA 9\r\nAdd sm_70 to the lookup table used by XLA\r\nChange the default sm arch from 20 to 30.\r\nFix for NVPTX not yet supporting sm_70\r\nRemove unnecessary cuda decorators from defaulted constructors\r\nUse updated NCCL for CUDA 9 fp16 support"}