{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23842", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23842/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23842/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23842/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23842", "id": 382070496, "node_id": "MDU6SXNzdWUzODIwNzA0OTY=", "number": 23842, "title": "Run time GPU resources allocation in Tensorflow", "user": {"login": "Akhtar303nu", "id": 41958819, "node_id": "MDQ6VXNlcjQxOTU4ODE5", "avatar_url": "https://avatars0.githubusercontent.com/u/41958819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Akhtar303nu", "html_url": "https://github.com/Akhtar303nu", "followers_url": "https://api.github.com/users/Akhtar303nu/followers", "following_url": "https://api.github.com/users/Akhtar303nu/following{/other_user}", "gists_url": "https://api.github.com/users/Akhtar303nu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Akhtar303nu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Akhtar303nu/subscriptions", "organizations_url": "https://api.github.com/users/Akhtar303nu/orgs", "repos_url": "https://api.github.com/users/Akhtar303nu/repos", "events_url": "https://api.github.com/users/Akhtar303nu/events{/privacy}", "received_events_url": "https://api.github.com/users/Akhtar303nu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-19T06:10:38Z", "updated_at": "2018-11-20T13:00:23Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hi<br>\nI have developed a model which is  Real time vehicle and person detection using tensor flow as back end in python and have  ten jobs (ten video feed from different cctv camera ) or more than that at run time some time jobs are more than ten or less than ten  jobs ,I want to run ten  jobs at a same time on one  gpu(GT X 1080 memory 8118MiB) using tensor flow  but if i have ten jobs then GPU resources equally distribute to every jobs and if jobs are five then resource equally distributed to five jobs i.e run time GPU resources allocation on the basis of number of available jobs(may be more than ten jobs or less than ten jobs) like cpu use its intelligence when one job/process complete then it release resources and cpu assign these resources to other process so  I want to utilize my whole resources of my GPU at every time<br>\nsuggest me any approach<br>\nThanks</p>", "body_text": "Hi\nI have developed a model which is  Real time vehicle and person detection using tensor flow as back end in python and have  ten jobs (ten video feed from different cctv camera ) or more than that at run time some time jobs are more than ten or less than ten  jobs ,I want to run ten  jobs at a same time on one  gpu(GT X 1080 memory 8118MiB) using tensor flow  but if i have ten jobs then GPU resources equally distribute to every jobs and if jobs are five then resource equally distributed to five jobs i.e run time GPU resources allocation on the basis of number of available jobs(may be more than ten jobs or less than ten jobs) like cpu use its intelligence when one job/process complete then it release resources and cpu assign these resources to other process so  I want to utilize my whole resources of my GPU at every time\nsuggest me any approach\nThanks", "body": "Hi\r\nI have developed a model which is  Real time vehicle and person detection using tensor flow as back end in python and have  ten jobs (ten video feed from different cctv camera ) or more than that at run time some time jobs are more than ten or less than ten  jobs ,I want to run ten  jobs at a same time on one  gpu(GT X 1080 memory 8118MiB) using tensor flow  but if i have ten jobs then GPU resources equally distribute to every jobs and if jobs are five then resource equally distributed to five jobs i.e run time GPU resources allocation on the basis of number of available jobs(may be more than ten jobs or less than ten jobs) like cpu use its intelligence when one job/process complete then it release resources and cpu assign these resources to other process so  I want to utilize my whole resources of my GPU at every time\r\nsuggest me any approach\r\nThanks"}