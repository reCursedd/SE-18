{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/415881852", "html_url": "https://github.com/tensorflow/tensorflow/issues/21832#issuecomment-415881852", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21832", "id": 415881852, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTg4MTg1Mg==", "user": {"login": "mforde84", "id": 20908622, "node_id": "MDQ6VXNlcjIwOTA4NjIy", "avatar_url": "https://avatars1.githubusercontent.com/u/20908622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mforde84", "html_url": "https://github.com/mforde84", "followers_url": "https://api.github.com/users/mforde84/followers", "following_url": "https://api.github.com/users/mforde84/following{/other_user}", "gists_url": "https://api.github.com/users/mforde84/gists{/gist_id}", "starred_url": "https://api.github.com/users/mforde84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mforde84/subscriptions", "organizations_url": "https://api.github.com/users/mforde84/orgs", "repos_url": "https://api.github.com/users/mforde84/repos", "events_url": "https://api.github.com/users/mforde84/events{/privacy}", "received_events_url": "https://api.github.com/users/mforde84/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-24T21:03:11Z", "updated_at": "2018-08-24T21:07:04Z", "author_association": "NONE", "body_html": "<p>Sure. But the question is more on how to integrate compatible drivers into a tensorflow container. The adage about containerization is: build once, run anywhere; and not: build once, run anywhere with Nvidia drivers v485 and above plus a kernel supporting experimental filesystem overlays. Even experimental / unofficial documentation on this scenario would be extremely helpful for most HPC environments that are still running epel6. \u00af_(\u30c4)_/\u00af</p>", "body_text": "Sure. But the question is more on how to integrate compatible drivers into a tensorflow container. The adage about containerization is: build once, run anywhere; and not: build once, run anywhere with Nvidia drivers v485 and above plus a kernel supporting experimental filesystem overlays. Even experimental / unofficial documentation on this scenario would be extremely helpful for most HPC environments that are still running epel6. \u00af_(\u30c4)_/\u00af", "body": "Sure. But the question is more on how to integrate compatible drivers into a tensorflow container. The adage about containerization is: build once, run anywhere; and not: build once, run anywhere with Nvidia drivers v485 and above plus a kernel supporting experimental filesystem overlays. Even experimental / unofficial documentation on this scenario would be extremely helpful for most HPC environments that are still running epel6. \u00af\\_(\u30c4)_/\u00af"}