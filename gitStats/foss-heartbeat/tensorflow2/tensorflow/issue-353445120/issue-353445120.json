{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21832", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21832/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21832/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21832/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21832", "id": 353445120, "node_id": "MDU6SXNzdWUzNTM0NDUxMjA=", "number": 21832, "title": "Status: CUDA driver version is insufficient for CUDA runtime version", "user": {"login": "mforde84", "id": 20908622, "node_id": "MDQ6VXNlcjIwOTA4NjIy", "avatar_url": "https://avatars1.githubusercontent.com/u/20908622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mforde84", "html_url": "https://github.com/mforde84", "followers_url": "https://api.github.com/users/mforde84/followers", "following_url": "https://api.github.com/users/mforde84/following{/other_user}", "gists_url": "https://api.github.com/users/mforde84/gists{/gist_id}", "starred_url": "https://api.github.com/users/mforde84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mforde84/subscriptions", "organizations_url": "https://api.github.com/users/mforde84/orgs", "repos_url": "https://api.github.com/users/mforde84/repos", "events_url": "https://api.github.com/users/mforde84/events{/privacy}", "received_events_url": "https://api.github.com/users/mforde84/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473173351, "node_id": "MDU6TGFiZWw0NzMxNzMzNTE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "azaks2", "id": 40365382, "node_id": "MDQ6VXNlcjQwMzY1Mzgy", "avatar_url": "https://avatars2.githubusercontent.com/u/40365382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/azaks2", "html_url": "https://github.com/azaks2", "followers_url": "https://api.github.com/users/azaks2/followers", "following_url": "https://api.github.com/users/azaks2/following{/other_user}", "gists_url": "https://api.github.com/users/azaks2/gists{/gist_id}", "starred_url": "https://api.github.com/users/azaks2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/azaks2/subscriptions", "organizations_url": "https://api.github.com/users/azaks2/orgs", "repos_url": "https://api.github.com/users/azaks2/repos", "events_url": "https://api.github.com/users/azaks2/events{/privacy}", "received_events_url": "https://api.github.com/users/azaks2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "azaks2", "id": 40365382, "node_id": "MDQ6VXNlcjQwMzY1Mzgy", "avatar_url": "https://avatars2.githubusercontent.com/u/40365382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/azaks2", "html_url": "https://github.com/azaks2", "followers_url": "https://api.github.com/users/azaks2/followers", "following_url": "https://api.github.com/users/azaks2/following{/other_user}", "gists_url": "https://api.github.com/users/azaks2/gists{/gist_id}", "starred_url": "https://api.github.com/users/azaks2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/azaks2/subscriptions", "organizations_url": "https://api.github.com/users/azaks2/orgs", "repos_url": "https://api.github.com/users/azaks2/repos", "events_url": "https://api.github.com/users/azaks2/events{/privacy}", "received_events_url": "https://api.github.com/users/azaks2/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 17, "created_at": "2018-08-23T15:52:15Z", "updated_at": "2018-10-19T09:30:07Z", "closed_at": "2018-08-24T23:25:58Z", "author_association": "NONE", "body_html": "<ul>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nKernel: 2.6.32-573.12.1.el6.x86_64<br>\nHost: RHEL 6.7<br>\nContainer: Ubuntu 16.04.5 LTS</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\nSingularity</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\nTensorflow:1.10.0-devel-gpu-py3</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\nPython 3.5.2</p>\n</li>\n<li>\n<p><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\nGCC 5.4.0</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\n9</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:<br>\nSingularity tensorflow:1.10.0-devel-gpu-py3:~&gt; nvidia-smi<br>\nThu Aug 23 00:24:41 2018<br>\n+------------------------------------------------------+<br>\n| NVIDIA-SMI 352.39 Driver Version: 352.39 |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |<br>\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |<br>\n|===============================+======================+======================|<br>\n| 0 Tesla K80 Off | 0000:84:00.0 Off | 0 |<br>\n| N/A 39C P0 58W / 149W | 22MiB / 11519MiB | 0% E. Process |<br>\n+-------------------------------+----------------------+----------------------+</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\n$ # install nvidia driver v352.39<br>\n$ sudo singularity build --sandbox /path/to/sandbox docker://tensorflow/tensorflow/1.10.0-devel-gpu-py3<br>\n$ singularity shell -nv /path/to/sandbox<br>\nSingularity tensorflow:1.10.0-devel-gpu-py3:~&gt; nvidia-smi<br>\nThu Aug 23 00:24:41 2018<br>\n+------------------------------------------------------+<br>\n| NVIDIA-SMI 352.39 Driver Version: 352.39 |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |<br>\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |<br>\n|===============================+======================+======================|<br>\n| 0 Tesla K80 Off | 0000:84:00.0 Off | 0 |<br>\n| N/A 39C P0 58W / 149W | 22MiB / 11519MiB | 0% E. Process |<br>\n+-------------------------------+----------------------+----------------------+</p>\n</li>\n</ul>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes: GPU Memory |<br>\n| GPU PID Type Process name Usage |<br>\n|=============================================================================|<br>\n| No running processes found |<br>\n+-----------------------------------------------------------------------------+<br>\nSingularity tensorflow:1.10.0-devel-gpu-py3:~&gt; python3<br>\nPython 3.5.2 (default, Nov 23 2017, 16:37:01)<br>\n[GCC 5.4.0 20160609] on linux<br>\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.</p>\n<pre><code>        from tensorflow.python.client import device_lib\n        print(device_lib.list_local_devices())\n        2018-08-23 00:26:35.424225: I\n        tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports\n        instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n        2018-08-23 00:26:38.208490: I\n        tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with\n        properties:\n        name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n        pciBusID: 0000:84:00.0\n        totalMemory: 11.25GiB freeMemory: 11.16GiB\n        2018-08-23 00:26:38.208576: I\n        tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu\n        devices: 0\n        Traceback (most recent call last):\n        File \"\", line 1, in\n        File\n        \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/device_lib.py\",\n        line 41, in list_local_devices\n        for s in pywrap_tensorflow.list_devices(session_config=session_config)\n        File\n        \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\",\n        line 1679, in list_devices\n        return ListDevices(status)\n        File\n        \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\",\n        line 519, in exit\n        c_api.TF_GetCode(self.status.status))\n        tensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed.\n        Status: CUDA driver version is insufficient for CUDA runtime version\n</code></pre>\n<h3>Describe the problem</h3>\n<p>I built a tensorflow container with singularity. I think there might be a mismatch between the some of the card drivers and cuda libraries between the host and container. I have the container built as a sandbox so I'm able to make modifications quiet easily, I was curious if there's a way I can install appropriate cuda driver and runtimes to the container, and have the container run off those instead of pulling libraries from the host which are incompatible with the container? Is this the right way to do it? Or should I be updating the cuda drivers / libraries on the host to match the container?</p>", "body_text": "OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nKernel: 2.6.32-573.12.1.el6.x86_64\nHost: RHEL 6.7\nContainer: Ubuntu 16.04.5 LTS\n\n\nTensorFlow installed from (source or binary):\nSingularity\n\n\nTensorFlow version (use command below):\nTensorflow:1.10.0-devel-gpu-py3\n\n\nPython version:\nPython 3.5.2\n\n\nGCC/Compiler version (if compiling from source):\nGCC 5.4.0\n\n\nCUDA/cuDNN version:\n9\n\n\nGPU model and memory:\nSingularity tensorflow:1.10.0-devel-gpu-py3:~> nvidia-smi\nThu Aug 23 00:24:41 2018\n+------------------------------------------------------+\n| NVIDIA-SMI 352.39 Driver Version: 352.39 |\n|-------------------------------+----------------------+----------------------+\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\n|===============================+======================+======================|\n| 0 Tesla K80 Off | 0000:84:00.0 Off | 0 |\n| N/A 39C P0 58W / 149W | 22MiB / 11519MiB | 0% E. Process |\n+-------------------------------+----------------------+----------------------+\n\n\nExact command to reproduce:\n$ # install nvidia driver v352.39\n$ sudo singularity build --sandbox /path/to/sandbox docker://tensorflow/tensorflow/1.10.0-devel-gpu-py3\n$ singularity shell -nv /path/to/sandbox\nSingularity tensorflow:1.10.0-devel-gpu-py3:~> nvidia-smi\nThu Aug 23 00:24:41 2018\n+------------------------------------------------------+\n| NVIDIA-SMI 352.39 Driver Version: 352.39 |\n|-------------------------------+----------------------+----------------------+\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\n|===============================+======================+======================|\n| 0 Tesla K80 Off | 0000:84:00.0 Off | 0 |\n| N/A 39C P0 58W / 149W | 22MiB / 11519MiB | 0% E. Process |\n+-------------------------------+----------------------+----------------------+\n\n\n+-----------------------------------------------------------------------------+\n| Processes: GPU Memory |\n| GPU PID Type Process name Usage |\n|=============================================================================|\n| No running processes found |\n+-----------------------------------------------------------------------------+\nSingularity tensorflow:1.10.0-devel-gpu-py3:~> python3\nPython 3.5.2 (default, Nov 23 2017, 16:37:01)\n[GCC 5.4.0 20160609] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n        from tensorflow.python.client import device_lib\n        print(device_lib.list_local_devices())\n        2018-08-23 00:26:35.424225: I\n        tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports\n        instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n        2018-08-23 00:26:38.208490: I\n        tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with\n        properties:\n        name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n        pciBusID: 0000:84:00.0\n        totalMemory: 11.25GiB freeMemory: 11.16GiB\n        2018-08-23 00:26:38.208576: I\n        tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu\n        devices: 0\n        Traceback (most recent call last):\n        File \"\", line 1, in\n        File\n        \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/device_lib.py\",\n        line 41, in list_local_devices\n        for s in pywrap_tensorflow.list_devices(session_config=session_config)\n        File\n        \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\",\n        line 1679, in list_devices\n        return ListDevices(status)\n        File\n        \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\",\n        line 519, in exit\n        c_api.TF_GetCode(self.status.status))\n        tensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed.\n        Status: CUDA driver version is insufficient for CUDA runtime version\n\nDescribe the problem\nI built a tensorflow container with singularity. I think there might be a mismatch between the some of the card drivers and cuda libraries between the host and container. I have the container built as a sandbox so I'm able to make modifications quiet easily, I was curious if there's a way I can install appropriate cuda driver and runtimes to the container, and have the container run off those instead of pulling libraries from the host which are incompatible with the container? Is this the right way to do it? Or should I be updating the cuda drivers / libraries on the host to match the container?", "body": "- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\nKernel: 2.6.32-573.12.1.el6.x86_64 \r\nHost: RHEL 6.7\r\n Container: Ubuntu 16.04.5 LTS \r\n\r\n- **TensorFlow installed from (source or binary)**: \r\nSingularity \r\n\r\n- **TensorFlow version (use command below)**:\r\nTensorflow:1.10.0-devel-gpu-py3\r\n\r\n- **Python version**:\r\nPython 3.5.2\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nGCC 5.4.0\r\n\r\n- **CUDA/cuDNN version**:\r\n9\r\n\r\n- **GPU model and memory**:\r\nSingularity tensorflow:1.10.0-devel-gpu-py3:~> nvidia-smi\r\nThu Aug 23 00:24:41 2018\r\n+------------------------------------------------------+\r\n| NVIDIA-SMI 352.39 Driver Version: 352.39 |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\r\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\r\n|===============================+======================+======================|\r\n| 0 Tesla K80 Off | 0000:84:00.0 Off | 0 |\r\n| N/A 39C P0 58W / 149W | 22MiB / 11519MiB | 0% E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n- **Exact command to reproduce**:\r\n$ # install nvidia driver v352.39\r\n$ sudo singularity build --sandbox /path/to/sandbox docker://tensorflow/tensorflow/1.10.0-devel-gpu-py3\r\n$ singularity shell -nv /path/to/sandbox\r\nSingularity tensorflow:1.10.0-devel-gpu-py3:~> nvidia-smi\r\nThu Aug 23 00:24:41 2018\r\n+------------------------------------------------------+\r\n| NVIDIA-SMI 352.39 Driver Version: 352.39 |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\r\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\r\n|===============================+======================+======================|\r\n| 0 Tesla K80 Off | 0000:84:00.0 Off | 0 |\r\n| N/A 39C P0 58W / 149W | 22MiB / 11519MiB | 0% E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes: GPU Memory |\r\n| GPU PID Type Process name Usage |\r\n|=============================================================================|\r\n| No running processes found |\r\n+-----------------------------------------------------------------------------+\r\nSingularity tensorflow:1.10.0-devel-gpu-py3:~> python3\r\nPython 3.5.2 (default, Nov 23 2017, 16:37:01)\r\n[GCC 5.4.0 20160609] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n            from tensorflow.python.client import device_lib\r\n            print(device_lib.list_local_devices())\r\n            2018-08-23 00:26:35.424225: I\r\n            tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports\r\n            instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n            2018-08-23 00:26:38.208490: I\r\n            tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with\r\n            properties:\r\n            name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\n            pciBusID: 0000:84:00.0\r\n            totalMemory: 11.25GiB freeMemory: 11.16GiB\r\n            2018-08-23 00:26:38.208576: I\r\n            tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu\r\n            devices: 0\r\n            Traceback (most recent call last):\r\n            File \"\", line 1, in\r\n            File\r\n            \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/device_lib.py\",\r\n            line 41, in list_local_devices\r\n            for s in pywrap_tensorflow.list_devices(session_config=session_config)\r\n            File\r\n            \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\",\r\n            line 1679, in list_devices\r\n            return ListDevices(status)\r\n            File\r\n            \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\",\r\n            line 519, in exit\r\n            c_api.TF_GetCode(self.status.status))\r\n            tensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed.\r\n            Status: CUDA driver version is insufficient for CUDA runtime version\r\n\r\n\r\n### Describe the problem\r\nI built a tensorflow container with singularity. I think there might be a mismatch between the some of the card drivers and cuda libraries between the host and container. I have the container built as a sandbox so I'm able to make modifications quiet easily, I was curious if there's a way I can install appropriate cuda driver and runtimes to the container, and have the container run off those instead of pulling libraries from the host which are incompatible with the container? Is this the right way to do it? Or should I be updating the cuda drivers / libraries on the host to match the container? \r\n"}