{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/297358522", "html_url": "https://github.com/tensorflow/tensorflow/issues/2916#issuecomment-297358522", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2916", "id": 297358522, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NzM1ODUyMg==", "user": {"login": "shamoya", "id": 22274255, "node_id": "MDQ6VXNlcjIyMjc0MjU1", "avatar_url": "https://avatars2.githubusercontent.com/u/22274255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shamoya", "html_url": "https://github.com/shamoya", "followers_url": "https://api.github.com/users/shamoya/followers", "following_url": "https://api.github.com/users/shamoya/following{/other_user}", "gists_url": "https://api.github.com/users/shamoya/gists{/gist_id}", "starred_url": "https://api.github.com/users/shamoya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shamoya/subscriptions", "organizations_url": "https://api.github.com/users/shamoya/orgs", "repos_url": "https://api.github.com/users/shamoya/repos", "events_url": "https://api.github.com/users/shamoya/events{/privacy}", "received_events_url": "https://api.github.com/users/shamoya/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-26T11:03:03Z", "updated_at": "2017-04-26T11:03:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>@avader906 - In general I agree with the impact of RoCE added latency and number of connections, but I don't think it matters at all in our specific use case.<br>\nWe care about large messages (Tensors) so latency ~ throughput,<br>\nand number of connections is not in large scale (dozens of nodes at max) so I don't expect any penalties in HW caches, and all of them are established beforehand.<br>\nDo you agree or I misunderstood your point ?</p>", "body_text": "@avader906 - In general I agree with the impact of RoCE added latency and number of connections, but I don't think it matters at all in our specific use case.\nWe care about large messages (Tensors) so latency ~ throughput,\nand number of connections is not in large scale (dozens of nodes at max) so I don't expect any penalties in HW caches, and all of them are established beforehand.\nDo you agree or I misunderstood your point ?", "body": "@avader906 - In general I agree with the impact of RoCE added latency and number of connections, but I don't think it matters at all in our specific use case.\r\nWe care about large messages (Tensors) so latency ~ throughput,\r\nand number of connections is not in large scale (dozens of nodes at max) so I don't expect any penalties in HW caches, and all of them are established beforehand.\r\nDo you agree or I misunderstood your point ? "}