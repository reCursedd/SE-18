{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/276810077", "html_url": "https://github.com/tensorflow/tensorflow/issues/2916#issuecomment-276810077", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2916", "id": 276810077, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NjgxMDA3Nw==", "user": {"login": "junshi15", "id": 12075848, "node_id": "MDQ6VXNlcjEyMDc1ODQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/12075848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/junshi15", "html_url": "https://github.com/junshi15", "followers_url": "https://api.github.com/users/junshi15/followers", "following_url": "https://api.github.com/users/junshi15/following{/other_user}", "gists_url": "https://api.github.com/users/junshi15/gists{/gist_id}", "starred_url": "https://api.github.com/users/junshi15/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/junshi15/subscriptions", "organizations_url": "https://api.github.com/users/junshi15/orgs", "repos_url": "https://api.github.com/users/junshi15/repos", "events_url": "https://api.github.com/users/junshi15/events{/privacy}", "received_events_url": "https://api.github.com/users/junshi15/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-01T22:55:18Z", "updated_at": "2017-02-01T22:55:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>@avader906 Thanks for your informative reply.</p>\n<p>I have no doubt that high-speed interconnection helps in a multi-node setting. We see it with Caffe, more precisely CaffeOnSpark since Caffe does not go beyond single node. I however have yet to see it with Tensorflow.</p>\n<p>The chart you provided \"PerformanceChart.png\" does not scale to more than 1-node for tensorflow. The Alexey-Kamenev tensorflow benchmark  shows only 1-node-4-gpu case. I do not see multi-node-multi(or single)-gpu settings in dlbench web page either (or maybe I missed it).</p>\n<p>I was not expecting speed-up in the 1-worker-1ps case, instead I was hoping to see slow-down compared to training the same VGG on a single GPU. But to my supprise, I see more or less the same speed.</p>", "body_text": "@avader906 Thanks for your informative reply.\nI have no doubt that high-speed interconnection helps in a multi-node setting. We see it with Caffe, more precisely CaffeOnSpark since Caffe does not go beyond single node. I however have yet to see it with Tensorflow.\nThe chart you provided \"PerformanceChart.png\" does not scale to more than 1-node for tensorflow. The Alexey-Kamenev tensorflow benchmark  shows only 1-node-4-gpu case. I do not see multi-node-multi(or single)-gpu settings in dlbench web page either (or maybe I missed it).\nI was not expecting speed-up in the 1-worker-1ps case, instead I was hoping to see slow-down compared to training the same VGG on a single GPU. But to my supprise, I see more or less the same speed.", "body": "@avader906 Thanks for your informative reply.\r\n\r\nI have no doubt that high-speed interconnection helps in a multi-node setting. We see it with Caffe, more precisely CaffeOnSpark since Caffe does not go beyond single node. I however have yet to see it with Tensorflow.\r\n\r\nThe chart you provided \"PerformanceChart.png\" does not scale to more than 1-node for tensorflow. The Alexey-Kamenev tensorflow benchmark  shows only 1-node-4-gpu case. I do not see multi-node-multi(or single)-gpu settings in dlbench web page either (or maybe I missed it).\r\n\r\nI was not expecting speed-up in the 1-worker-1ps case, instead I was hoping to see slow-down compared to training the same VGG on a single GPU. But to my supprise, I see more or less the same speed. "}