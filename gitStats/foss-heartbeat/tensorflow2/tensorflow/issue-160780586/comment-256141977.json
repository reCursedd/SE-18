{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256141977", "html_url": "https://github.com/tensorflow/tensorflow/issues/2916#issuecomment-256141977", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2916", "id": 256141977, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NjE0MTk3Nw==", "user": {"login": "abhinavvishnu", "id": 6489071, "node_id": "MDQ6VXNlcjY0ODkwNzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/6489071?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhinavvishnu", "html_url": "https://github.com/abhinavvishnu", "followers_url": "https://api.github.com/users/abhinavvishnu/followers", "following_url": "https://api.github.com/users/abhinavvishnu/following{/other_user}", "gists_url": "https://api.github.com/users/abhinavvishnu/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhinavvishnu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhinavvishnu/subscriptions", "organizations_url": "https://api.github.com/users/abhinavvishnu/orgs", "repos_url": "https://api.github.com/users/abhinavvishnu/repos", "events_url": "https://api.github.com/users/abhinavvishnu/events{/privacy}", "received_events_url": "https://api.github.com/users/abhinavvishnu/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-25T19:00:08Z", "updated_at": "2016-10-25T19:00:08Z", "author_association": "NONE", "body_html": "<p>OK. Actually mpi-python will provide better performance than gRPC because<br>\nMPI can use high speed interconnect. Can you be more specific as to how it<br>\nis different than the TF paper? Does gRPC support collective operations?<br>\nsend/recv with parameter server will not work for more than a few compute<br>\nnodes.</p>\n<p>On Tue, Oct 18, 2016 at 8:13 AM, Bairen Yi <a href=\"mailto:notifications@github.com\">notifications@github.com</a> wrote:</p>\n<blockquote>\n<p>I've only had a quick look but it seems rather ad-hoc (implemented in<br>\nMPI-Python and run single-node TF in it). Plus it is certainly not the same<br>\nas what appears in the TF paper. I believe what we are talking about would<br>\nbe a truly remote API that support sync/async communication and send/recv<br>\ngraph partitioning, or pretty much everything in the current gRPC runtime.</p>\n<p>\u2014<br>\nYou are receiving this because you commented.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"160780586\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2916\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2916/hovercard?comment_id=254538689&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/2916#issuecomment-254538689\">#2916 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/AGMD7zysqQZuOkq8epf83zCmmiRsiQw8ks5q1OItgaJpZM4I35Qd\">https://github.com/notifications/unsubscribe-auth/AGMD7zysqQZuOkq8epf83zCmmiRsiQw8ks5q1OItgaJpZM4I35Qd</a><br>\n.</p>\n</blockquote>\n<h2></h2>\n<p>Abhinav Vishnu<br>\nResearch Scientist<br>\nPacific Northwest National Lab<br>\nRichland, WA 99352</p>", "body_text": "OK. Actually mpi-python will provide better performance than gRPC because\nMPI can use high speed interconnect. Can you be more specific as to how it\nis different than the TF paper? Does gRPC support collective operations?\nsend/recv with parameter server will not work for more than a few compute\nnodes.\nOn Tue, Oct 18, 2016 at 8:13 AM, Bairen Yi notifications@github.com wrote:\n\nI've only had a quick look but it seems rather ad-hoc (implemented in\nMPI-Python and run single-node TF in it). Plus it is certainly not the same\nas what appears in the TF paper. I believe what we are talking about would\nbe a truly remote API that support sync/async communication and send/recv\ngraph partitioning, or pretty much everything in the current gRPC runtime.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\n#2916 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGMD7zysqQZuOkq8epf83zCmmiRsiQw8ks5q1OItgaJpZM4I35Qd\n.\n\n\nAbhinav Vishnu\nResearch Scientist\nPacific Northwest National Lab\nRichland, WA 99352", "body": "OK. Actually mpi-python will provide better performance than gRPC because\nMPI can use high speed interconnect. Can you be more specific as to how it\nis different than the TF paper? Does gRPC support collective operations?\nsend/recv with parameter server will not work for more than a few compute\nnodes.\n\nOn Tue, Oct 18, 2016 at 8:13 AM, Bairen Yi notifications@github.com wrote:\n\n> I've only had a quick look but it seems rather ad-hoc (implemented in\n> MPI-Python and run single-node TF in it). Plus it is certainly not the same\n> as what appears in the TF paper. I believe what we are talking about would\n> be a truly remote API that support sync/async communication and send/recv\n> graph partitioning, or pretty much everything in the current gRPC runtime.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2916#issuecomment-254538689,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AGMD7zysqQZuOkq8epf83zCmmiRsiQw8ks5q1OItgaJpZM4I35Qd\n> .\n\n## \n\nAbhinav Vishnu\nResearch Scientist\nPacific Northwest National Lab\nRichland, WA 99352\n"}