{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/278761308", "html_url": "https://github.com/tensorflow/tensorflow/issues/2916#issuecomment-278761308", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2916", "id": 278761308, "node_id": "MDEyOklzc3VlQ29tbWVudDI3ODc2MTMwOA==", "user": {"login": "abhinavvishnu", "id": 6489071, "node_id": "MDQ6VXNlcjY0ODkwNzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/6489071?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhinavvishnu", "html_url": "https://github.com/abhinavvishnu", "followers_url": "https://api.github.com/users/abhinavvishnu/followers", "following_url": "https://api.github.com/users/abhinavvishnu/following{/other_user}", "gists_url": "https://api.github.com/users/abhinavvishnu/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhinavvishnu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhinavvishnu/subscriptions", "organizations_url": "https://api.github.com/users/abhinavvishnu/orgs", "repos_url": "https://api.github.com/users/abhinavvishnu/repos", "events_url": "https://api.github.com/users/abhinavvishnu/events{/privacy}", "received_events_url": "https://api.github.com/users/abhinavvishnu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-09T20:21:32Z", "updated_at": "2017-02-09T20:21:32Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">Chainer is showing results for ResNet-50, which is much easier to scale the\nAlexNet/GoogleNet. They are using MPI based implementation as well. So it\nis pretty good, but I am not sure, if they are doing any other\noptimizations such as asynchronous communication, layer-wise etc.\n\n:- Abhinav</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Thu, Feb 9, 2017 at 6:10 AM, Yaroslav Goncharov ***@***.*** &gt; wrote:\n Chainer folks claim that they are 5.5 times faster than TF in the\n distributed environment (128 GPUs, Resnet-50):\n <a href=\"http://chainer.org/general/2017/02/08/Performance-of-\">http://chainer.org/general/2017/02/08/Performance-of-</a>\n Distributed-Deep-Learning-Using-ChainerMN.html\n\n I think it is mostly because of RDMA/InfiniBand (MXNet and CNTK are doing\n much better than TF most likely because of it).\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"160780586\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2916\" href=\"https://github.com/tensorflow/tensorflow/issues/2916#issuecomment-278612491\">#2916 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AGMD7ydCkSmF_Y25cG7eo53dms3EHP94ks5ravQxgaJpZM4I35Qd\">https://github.com/notifications/unsubscribe-auth/AGMD7ydCkSmF_Y25cG7eo53dms3EHP94ks5ravQxgaJpZM4I35Qd</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \nAbhinav Vishnu\nResearch Scientist\nPacific Northwest National Lab\nRichland, WA 99352</div>\n</div>", "body_text": "Chainer is showing results for ResNet-50, which is much easier to scale the\nAlexNet/GoogleNet. They are using MPI based implementation as well. So it\nis pretty good, but I am not sure, if they are doing any other\noptimizations such as asynchronous communication, layer-wise etc.\n\n:- Abhinav\n\u2026\nOn Thu, Feb 9, 2017 at 6:10 AM, Yaroslav Goncharov ***@***.*** > wrote:\n Chainer folks claim that they are 5.5 times faster than TF in the\n distributed environment (128 GPUs, Resnet-50):\n http://chainer.org/general/2017/02/08/Performance-of-\n Distributed-Deep-Learning-Using-ChainerMN.html\n\n I think it is mostly because of RDMA/InfiniBand (MXNet and CNTK are doing\n much better than TF most likely because of it).\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#2916 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AGMD7ydCkSmF_Y25cG7eo53dms3EHP94ks5ravQxgaJpZM4I35Qd>\n .\n\n\n-- \nAbhinav Vishnu\nResearch Scientist\nPacific Northwest National Lab\nRichland, WA 99352", "body": "Chainer is showing results for ResNet-50, which is much easier to scale the\nAlexNet/GoogleNet. They are using MPI based implementation as well. So it\nis pretty good, but I am not sure, if they are doing any other\noptimizations such as asynchronous communication, layer-wise etc.\n\n:- Abhinav\n\nOn Thu, Feb 9, 2017 at 6:10 AM, Yaroslav Goncharov <notifications@github.com\n> wrote:\n\n> Chainer folks claim that they are 5.5 times faster than TF in the\n> distributed environment (128 GPUs, Resnet-50):\n> http://chainer.org/general/2017/02/08/Performance-of-\n> Distributed-Deep-Learning-Using-ChainerMN.html\n>\n> I think it is mostly because of RDMA/InfiniBand (MXNet and CNTK are doing\n> much better than TF most likely because of it).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/2916#issuecomment-278612491>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AGMD7ydCkSmF_Y25cG7eo53dms3EHP94ks5ravQxgaJpZM4I35Qd>\n> .\n>\n\n\n\n-- \nAbhinav Vishnu\nResearch Scientist\nPacific Northwest National Lab\nRichland, WA 99352\n"}