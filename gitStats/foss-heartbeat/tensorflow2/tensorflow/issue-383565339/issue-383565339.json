{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23924", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23924/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23924/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23924/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23924", "id": 383565339, "node_id": "MDU6SXNzdWUzODM1NjUzMzk=", "number": 23924, "title": "Memory leak when using tf.contrib.data.unbatch()", "user": {"login": "w4-sjcho", "id": 8187891, "node_id": "MDQ6VXNlcjgxODc4OTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8187891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/w4-sjcho", "html_url": "https://github.com/w4-sjcho", "followers_url": "https://api.github.com/users/w4-sjcho/followers", "following_url": "https://api.github.com/users/w4-sjcho/following{/other_user}", "gists_url": "https://api.github.com/users/w4-sjcho/gists{/gist_id}", "starred_url": "https://api.github.com/users/w4-sjcho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/w4-sjcho/subscriptions", "organizations_url": "https://api.github.com/users/w4-sjcho/orgs", "repos_url": "https://api.github.com/users/w4-sjcho/repos", "events_url": "https://api.github.com/users/w4-sjcho/events{/privacy}", "received_events_url": "https://api.github.com/users/w4-sjcho/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-22T14:45:32Z", "updated_at": "2018-11-22T16:13:45Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0</li>\n<li>Python version: Python 3.6.7 :: Anaconda, Inc.</li>\n<li>Bazel version (if compiling from source):</li>\n<li>GCC/Compiler version (if compiling from source):</li>\n<li>CUDA/cuDNN version: 9.0</li>\n<li>GPU model and memory: 1080ti</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nMemory usage continuously increase when using <code>tf.contrib.data.unbatch()</code>.</p>\n<p><strong>Describe the expected behavior</strong><br>\nMemory usage should not increase.</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<pre><code>from absl import app\nfrom absl import flags\nfrom absl import logging\nimport tensorflow as tf\n\n\nFLAGS = flags.FLAGS\nflags.DEFINE_integer('epochs', 1000, '')\nflags.DEFINE_boolean('use_unbatch', False, '')\n\n\ndef create_dataset(input_holder):\n    dataset = tf.data.Dataset.from_tensor_slices((input_holder,))\n\n    def generate_random_tensor(size):\n        return tf.random_uniform([5, size, size], dtype=tf.float32)\n\n    dataset = dataset.map(generate_random_tensor)\n    if FLAGS.use_unbatch:\n        dataset = dataset.apply(tf.contrib.data.unbatch())\n    else:\n        dataset = dataset.flat_map(\n            lambda x: tf.data.Dataset.from_tensor_slices((x,)))\n        # The output of the dataset becomes a single-element tuple w/o this.\n        dataset = dataset.map(lambda x: x)\n    return dataset\n\n\ndef main(_):\n    with tf.Session() as sess:\n        size_holder = tf.placeholder(tf.int32, shape=[None])\n        dataset = create_dataset(size_holder)\n\n        iterator = dataset.make_initializable_iterator()\n        get_next = iterator.get_next()\n\n        for i in range(FLAGS.epochs):\n            logging.info('Epoch #%d', i)\n            sess.run(iterator.initializer, feed_dict={\n                size_holder: [1000 + (i % 100)],\n            })\n            try:\n                while True:\n                    array = sess.run(get_next)\n                    logging.info('  Generated: %s', array.shape)\n            except tf.errors.OutOfRangeError:\n                pass\n\n\nif __name__ == '__main__':\n    app.run(main)\n</code></pre>\n<p>Memory usage will increase with <code>--use_unbatch</code>, while with <code>--nouse_unbatch</code>, memory usage does not increase.</p>\n<p><strong>Other info / logs</strong></p>\n<p>It seems like <code>input_-&gt;Unref()</code> call is missing in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/unbatch_dataset_op.cc#L42\"><code>UnbatchDatasetOp</code></a>.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\nPython version: Python 3.6.7 :: Anaconda, Inc.\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0\nGPU model and memory: 1080ti\n\nDescribe the current behavior\nMemory usage continuously increase when using tf.contrib.data.unbatch().\nDescribe the expected behavior\nMemory usage should not increase.\nCode to reproduce the issue\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport tensorflow as tf\n\n\nFLAGS = flags.FLAGS\nflags.DEFINE_integer('epochs', 1000, '')\nflags.DEFINE_boolean('use_unbatch', False, '')\n\n\ndef create_dataset(input_holder):\n    dataset = tf.data.Dataset.from_tensor_slices((input_holder,))\n\n    def generate_random_tensor(size):\n        return tf.random_uniform([5, size, size], dtype=tf.float32)\n\n    dataset = dataset.map(generate_random_tensor)\n    if FLAGS.use_unbatch:\n        dataset = dataset.apply(tf.contrib.data.unbatch())\n    else:\n        dataset = dataset.flat_map(\n            lambda x: tf.data.Dataset.from_tensor_slices((x,)))\n        # The output of the dataset becomes a single-element tuple w/o this.\n        dataset = dataset.map(lambda x: x)\n    return dataset\n\n\ndef main(_):\n    with tf.Session() as sess:\n        size_holder = tf.placeholder(tf.int32, shape=[None])\n        dataset = create_dataset(size_holder)\n\n        iterator = dataset.make_initializable_iterator()\n        get_next = iterator.get_next()\n\n        for i in range(FLAGS.epochs):\n            logging.info('Epoch #%d', i)\n            sess.run(iterator.initializer, feed_dict={\n                size_holder: [1000 + (i % 100)],\n            })\n            try:\n                while True:\n                    array = sess.run(get_next)\n                    logging.info('  Generated: %s', array.shape)\n            except tf.errors.OutOfRangeError:\n                pass\n\n\nif __name__ == '__main__':\n    app.run(main)\n\nMemory usage will increase with --use_unbatch, while with --nouse_unbatch, memory usage does not increase.\nOther info / logs\nIt seems like input_->Unref() call is missing in UnbatchDatasetOp.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: Python 3.6.7 :: Anaconda, Inc.\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.0\r\n- GPU model and memory: 1080ti\r\n\r\n**Describe the current behavior**\r\nMemory usage continuously increase when using `tf.contrib.data.unbatch()`.\r\n\r\n**Describe the expected behavior**\r\nMemory usage should not increase.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nfrom absl import app\r\nfrom absl import flags\r\nfrom absl import logging\r\nimport tensorflow as tf\r\n\r\n\r\nFLAGS = flags.FLAGS\r\nflags.DEFINE_integer('epochs', 1000, '')\r\nflags.DEFINE_boolean('use_unbatch', False, '')\r\n\r\n\r\ndef create_dataset(input_holder):\r\n    dataset = tf.data.Dataset.from_tensor_slices((input_holder,))\r\n\r\n    def generate_random_tensor(size):\r\n        return tf.random_uniform([5, size, size], dtype=tf.float32)\r\n\r\n    dataset = dataset.map(generate_random_tensor)\r\n    if FLAGS.use_unbatch:\r\n        dataset = dataset.apply(tf.contrib.data.unbatch())\r\n    else:\r\n        dataset = dataset.flat_map(\r\n            lambda x: tf.data.Dataset.from_tensor_slices((x,)))\r\n        # The output of the dataset becomes a single-element tuple w/o this.\r\n        dataset = dataset.map(lambda x: x)\r\n    return dataset\r\n\r\n\r\ndef main(_):\r\n    with tf.Session() as sess:\r\n        size_holder = tf.placeholder(tf.int32, shape=[None])\r\n        dataset = create_dataset(size_holder)\r\n\r\n        iterator = dataset.make_initializable_iterator()\r\n        get_next = iterator.get_next()\r\n\r\n        for i in range(FLAGS.epochs):\r\n            logging.info('Epoch #%d', i)\r\n            sess.run(iterator.initializer, feed_dict={\r\n                size_holder: [1000 + (i % 100)],\r\n            })\r\n            try:\r\n                while True:\r\n                    array = sess.run(get_next)\r\n                    logging.info('  Generated: %s', array.shape)\r\n            except tf.errors.OutOfRangeError:\r\n                pass\r\n\r\n\r\nif __name__ == '__main__':\r\n    app.run(main)\r\n```\r\n\r\nMemory usage will increase with `--use_unbatch`, while with `--nouse_unbatch`, memory usage does not increase.\r\n\r\n**Other info / logs**\r\n\r\nIt seems like `input_->Unref()` call is missing in [`UnbatchDatasetOp`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/unbatch_dataset_op.cc#L42)."}