{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/388132259", "html_url": "https://github.com/tensorflow/tensorflow/issues/19193#issuecomment-388132259", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19193", "id": 388132259, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODEzMjI1OQ==", "user": {"login": "tokotchd", "id": 8561315, "node_id": "MDQ6VXNlcjg1NjEzMTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/8561315?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tokotchd", "html_url": "https://github.com/tokotchd", "followers_url": "https://api.github.com/users/tokotchd/followers", "following_url": "https://api.github.com/users/tokotchd/following{/other_user}", "gists_url": "https://api.github.com/users/tokotchd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tokotchd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tokotchd/subscriptions", "organizations_url": "https://api.github.com/users/tokotchd/orgs", "repos_url": "https://api.github.com/users/tokotchd/repos", "events_url": "https://api.github.com/users/tokotchd/events{/privacy}", "received_events_url": "https://api.github.com/users/tokotchd/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-10T17:53:59Z", "updated_at": "2018-05-15T15:32:38Z", "author_association": "NONE", "body_html": "<p>You can do this with three separate padding operations and a concat.</p>\n<p>I.E. if an example \"yourTensor\" has 4 dimensions (batch,width,height,channels)</p>\n<pre><code>paddedR = tf.pad(tensor = yourTensor[:,:,:,0:1], #the R channel of tensor\n    paddings=[[0,0],[2,2],[2,2],[0,0]],  #don't pad it in batch or channel dimensions\n    mode='Constant',\n    name='padAverageRed',\n    constant_values=123.68)\npaddedG = tf.pad(tensor = yourTensor[:,:,:,1:2], #the G channel of tensor\n    paddings=[[0,0],[2,2],[2,2],[0,0]],  #don't pad it in batch or channel dimensions\n    mode='Constant',\n    name='padAverageGreen',\n    constant_values=116.779)\npaddedB = tf.pad(tensor = yourTensor[:,:,:,2:3], #the B channel of tensor\n    paddings=[[0,0],[2,2],[2,2],[0,0]], #don't pad it in batch or channel dimensions\n    mode='Constant',\n    name='padAverageBlue',\n    constant_values=103.939)\nfinalTensor=tf.concat([paddedR, paddedG, paddedB], 3)\n</code></pre>\n<p>You can replace the slices on the final dimension with 0,1,and 2 respectively and use stack instead of concat and you will be able to just use a constant padding of \"2\" across every dimension which neatens the code up a decent bit but it also makes it less understandable.  Either will be sufficient, however.</p>", "body_text": "You can do this with three separate padding operations and a concat.\nI.E. if an example \"yourTensor\" has 4 dimensions (batch,width,height,channels)\npaddedR = tf.pad(tensor = yourTensor[:,:,:,0:1], #the R channel of tensor\n    paddings=[[0,0],[2,2],[2,2],[0,0]],  #don't pad it in batch or channel dimensions\n    mode='Constant',\n    name='padAverageRed',\n    constant_values=123.68)\npaddedG = tf.pad(tensor = yourTensor[:,:,:,1:2], #the G channel of tensor\n    paddings=[[0,0],[2,2],[2,2],[0,0]],  #don't pad it in batch or channel dimensions\n    mode='Constant',\n    name='padAverageGreen',\n    constant_values=116.779)\npaddedB = tf.pad(tensor = yourTensor[:,:,:,2:3], #the B channel of tensor\n    paddings=[[0,0],[2,2],[2,2],[0,0]], #don't pad it in batch or channel dimensions\n    mode='Constant',\n    name='padAverageBlue',\n    constant_values=103.939)\nfinalTensor=tf.concat([paddedR, paddedG, paddedB], 3)\n\nYou can replace the slices on the final dimension with 0,1,and 2 respectively and use stack instead of concat and you will be able to just use a constant padding of \"2\" across every dimension which neatens the code up a decent bit but it also makes it less understandable.  Either will be sufficient, however.", "body": "You can do this with three separate padding operations and a concat.\r\n\r\nI.E. if an example \"yourTensor\" has 4 dimensions (batch,width,height,channels)\r\n\r\n```\r\npaddedR = tf.pad(tensor = yourTensor[:,:,:,0:1], #the R channel of tensor\r\n    paddings=[[0,0],[2,2],[2,2],[0,0]],  #don't pad it in batch or channel dimensions\r\n    mode='Constant',\r\n    name='padAverageRed',\r\n    constant_values=123.68)\r\npaddedG = tf.pad(tensor = yourTensor[:,:,:,1:2], #the G channel of tensor\r\n    paddings=[[0,0],[2,2],[2,2],[0,0]],  #don't pad it in batch or channel dimensions\r\n    mode='Constant',\r\n    name='padAverageGreen',\r\n    constant_values=116.779)\r\npaddedB = tf.pad(tensor = yourTensor[:,:,:,2:3], #the B channel of tensor\r\n    paddings=[[0,0],[2,2],[2,2],[0,0]], #don't pad it in batch or channel dimensions\r\n    mode='Constant',\r\n    name='padAverageBlue',\r\n    constant_values=103.939)\r\nfinalTensor=tf.concat([paddedR, paddedG, paddedB], 3)\r\n```\r\nYou can replace the slices on the final dimension with 0,1,and 2 respectively and use stack instead of concat and you will be able to just use a constant padding of \"2\" across every dimension which neatens the code up a decent bit but it also makes it less understandable.  Either will be sufficient, however."}