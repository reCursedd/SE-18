{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235433645", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235433645", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235433645, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTQzMzY0NQ==", "user": {"login": "papadopav", "id": 20671213, "node_id": "MDQ6VXNlcjIwNjcxMjEz", "avatar_url": "https://avatars3.githubusercontent.com/u/20671213?v=4", "gravatar_id": "", "url": "https://api.github.com/users/papadopav", "html_url": "https://github.com/papadopav", "followers_url": "https://api.github.com/users/papadopav/followers", "following_url": "https://api.github.com/users/papadopav/following{/other_user}", "gists_url": "https://api.github.com/users/papadopav/gists{/gist_id}", "starred_url": "https://api.github.com/users/papadopav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/papadopav/subscriptions", "organizations_url": "https://api.github.com/users/papadopav/orgs", "repos_url": "https://api.github.com/users/papadopav/repos", "events_url": "https://api.github.com/users/papadopav/events{/privacy}", "received_events_url": "https://api.github.com/users/papadopav/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-26T23:08:51Z", "updated_at": "2016-07-26T23:08:51Z", "author_association": "NONE", "body_html": "<p>I am also confused regarding is_training and reuse flags. I have created a program following the CIFAR example, where my code is structured as in CIFAR:</p>\n<ul>\n<li>Inference</li>\n<li>Loss</li>\n<li>Train</li>\n</ul>\n<p>And I am running it in a multi-gpu fashion (for training).<br>\nSo I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py).<br>\nSo</p>\n<pre><code>for ii in xrange(2):  # Num of GPU\n  with tf.device('/gpu:%d' % ii):\n    with tf.name_scope('device_%d' % ii) as scope:\n\n      data_batch, label_batch = factory.GetShuffleBatch(batch_size)\n\n      unnormalized_logits = factory.MyModel(dataBatch=data_batch, numClasses=numClasses,\n                                                 isTraining=True)\n\n      More stuff happening\n      tf.get_variable_scope().reuse_variables()\n</code></pre>\n<p>The inference happens with the function MyModel. (below is an example of the function, in reality i use more layers and neurons).</p>\n<pre><code>def MyModel(data_batch, num_classes, feature_dim):\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n\n  # Hidden Layer 2\n  with tf.variable_scope('hidden2') as scope:\n    weights = variable_on_cpu('weights',[256, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases, name=scope.name)\n\n  # output, unnormalized softmax\n  with tf.variable_scope('softmax_unnorm') as scope:\n\n    weights = variable_on_cpu('weights', [256, num_classes], tf.truncated_normal_initializer(stddev=1/num_classes))\n    biases = variable_on_cpu('biases', [num_classes], tf.constant_initializer(0.0))\n    softmax_un = tf.add(tf.matmul(hidden2, weights), biases, name=scope.name)\n\n  return softmax_un\n</code></pre>\n<p>I want to perform batch nomalization. So when I did:</p>\n<pre><code>def MyModel(data_batch, num_classes, feature_dim, isTraining):\n\n  with tf.variable_scope('bnormalization') as scope:\n    norm_data_batch = tcl.batch_norm(inputs=dataBatch, epsilon=0.0001, is_training=isTraining, \n                                      reuse=True, scope=scope)\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n</code></pre>\n<p>I got the following error in the training phase:<br>\nVariable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?</p>\n<p>From what I 've been reading in this thread in the training phase I should be using reuse=None. Have I got this part correct? If this is true, then since I am using two GPUS, should I do reuse=None in the first GPU and reuse=True in the second? Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?</p>\n<p>Finally, in the testing phase, should I have is_training=False and reuse=True?</p>\n<p>Any help is greatly appreciated.</p>", "body_text": "I am also confused regarding is_training and reuse flags. I have created a program following the CIFAR example, where my code is structured as in CIFAR:\n\nInference\nLoss\nTrain\n\nAnd I am running it in a multi-gpu fashion (for training).\nSo I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py).\nSo\nfor ii in xrange(2):  # Num of GPU\n  with tf.device('/gpu:%d' % ii):\n    with tf.name_scope('device_%d' % ii) as scope:\n\n      data_batch, label_batch = factory.GetShuffleBatch(batch_size)\n\n      unnormalized_logits = factory.MyModel(dataBatch=data_batch, numClasses=numClasses,\n                                                 isTraining=True)\n\n      More stuff happening\n      tf.get_variable_scope().reuse_variables()\n\nThe inference happens with the function MyModel. (below is an example of the function, in reality i use more layers and neurons).\ndef MyModel(data_batch, num_classes, feature_dim):\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n\n  # Hidden Layer 2\n  with tf.variable_scope('hidden2') as scope:\n    weights = variable_on_cpu('weights',[256, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases, name=scope.name)\n\n  # output, unnormalized softmax\n  with tf.variable_scope('softmax_unnorm') as scope:\n\n    weights = variable_on_cpu('weights', [256, num_classes], tf.truncated_normal_initializer(stddev=1/num_classes))\n    biases = variable_on_cpu('biases', [num_classes], tf.constant_initializer(0.0))\n    softmax_un = tf.add(tf.matmul(hidden2, weights), biases, name=scope.name)\n\n  return softmax_un\n\nI want to perform batch nomalization. So when I did:\ndef MyModel(data_batch, num_classes, feature_dim, isTraining):\n\n  with tf.variable_scope('bnormalization') as scope:\n    norm_data_batch = tcl.batch_norm(inputs=dataBatch, epsilon=0.0001, is_training=isTraining, \n                                      reuse=True, scope=scope)\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n\nI got the following error in the training phase:\nVariable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?\nFrom what I 've been reading in this thread in the training phase I should be using reuse=None. Have I got this part correct? If this is true, then since I am using two GPUS, should I do reuse=None in the first GPU and reuse=True in the second? Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?\nFinally, in the testing phase, should I have is_training=False and reuse=True?\nAny help is greatly appreciated.", "body": "I am also confused regarding is_training and reuse flags. I have created a program following the CIFAR example, where my code is structured as in CIFAR:\n- Inference\n- Loss\n- Train\n\nAnd I am running it in a multi-gpu fashion (for training).\nSo I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py). \nSo \n\n```\nfor ii in xrange(2):  # Num of GPU\n  with tf.device('/gpu:%d' % ii):\n    with tf.name_scope('device_%d' % ii) as scope:\n\n      data_batch, label_batch = factory.GetShuffleBatch(batch_size)\n\n      unnormalized_logits = factory.MyModel(dataBatch=data_batch, numClasses=numClasses,\n                                                 isTraining=True)\n\n      More stuff happening\n      tf.get_variable_scope().reuse_variables()\n```\n\nThe inference happens with the function MyModel. (below is an example of the function, in reality i use more layers and neurons). \n\n```\ndef MyModel(data_batch, num_classes, feature_dim):\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n\n  # Hidden Layer 2\n  with tf.variable_scope('hidden2') as scope:\n    weights = variable_on_cpu('weights',[256, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases, name=scope.name)\n\n  # output, unnormalized softmax\n  with tf.variable_scope('softmax_unnorm') as scope:\n\n    weights = variable_on_cpu('weights', [256, num_classes], tf.truncated_normal_initializer(stddev=1/num_classes))\n    biases = variable_on_cpu('biases', [num_classes], tf.constant_initializer(0.0))\n    softmax_un = tf.add(tf.matmul(hidden2, weights), biases, name=scope.name)\n\n  return softmax_un\n```\n\nI want to perform batch nomalization. So when I did:\n\n```\ndef MyModel(data_batch, num_classes, feature_dim, isTraining):\n\n  with tf.variable_scope('bnormalization') as scope:\n    norm_data_batch = tcl.batch_norm(inputs=dataBatch, epsilon=0.0001, is_training=isTraining, \n                                      reuse=True, scope=scope)\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n```\n\nI got the following error in the training phase:\nVariable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?\n\nFrom what I 've been reading in this thread in the training phase I should be using reuse=None. Have I got this part correct? If this is true, then since I am using two GPUS, should I do reuse=None in the first GPU and reuse=True in the second? Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?\n\nFinally, in the testing phase, should I have is_training=False and reuse=True?\n\nAny help is greatly appreciated. \n"}