{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/226928192", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-226928192", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 226928192, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjkyODE5Mg==", "user": {"login": "Mahdizade", "id": 5513062, "node_id": "MDQ6VXNlcjU1MTMwNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5513062?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mahdizade", "html_url": "https://github.com/Mahdizade", "followers_url": "https://api.github.com/users/Mahdizade/followers", "following_url": "https://api.github.com/users/Mahdizade/following{/other_user}", "gists_url": "https://api.github.com/users/Mahdizade/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mahdizade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mahdizade/subscriptions", "organizations_url": "https://api.github.com/users/Mahdizade/orgs", "repos_url": "https://api.github.com/users/Mahdizade/repos", "events_url": "https://api.github.com/users/Mahdizade/events{/privacy}", "received_events_url": "https://api.github.com/users/Mahdizade/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-18T07:55:49Z", "updated_at": "2016-06-18T11:55:25Z", "author_association": "NONE", "body_html": "<p>I think some thing wrong with this layer. in training every thing is OK and loss decrease very good. but in testing I get zero accuracy.<br>\nBy the way in testing when I use is_training=False, I get zero acc.<br>\nI know batch normalization behave different in train and test phase, as describe in <a href=\"https://www.quora.com/How-does-batch-normalization-behave-differently-at-training-time-and-test-time\" rel=\"nofollow\">How does batch normalization behave differently at training time and test time? - Quora</a>. I think this implementation is unclear</p>", "body_text": "I think some thing wrong with this layer. in training every thing is OK and loss decrease very good. but in testing I get zero accuracy.\nBy the way in testing when I use is_training=False, I get zero acc.\nI know batch normalization behave different in train and test phase, as describe in How does batch normalization behave differently at training time and test time? - Quora. I think this implementation is unclear", "body": "I think some thing wrong with this layer. in training every thing is OK and loss decrease very good. but in testing I get zero accuracy.\nBy the way in testing when I use is_training=False, I get zero acc.\nI know batch normalization behave different in train and test phase, as describe in [How does batch normalization behave differently at training time and test time? - Quora](https://www.quora.com/How-does-batch-normalization-behave-differently-at-training-time-and-test-time). I think this implementation is unclear\n"}