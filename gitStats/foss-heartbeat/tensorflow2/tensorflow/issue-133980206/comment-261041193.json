{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261041193", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-261041193", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 261041193, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA0MTE5Mw==", "user": {"login": "zhongyuk", "id": 6901075, "node_id": "MDQ6VXNlcjY5MDEwNzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6901075?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhongyuk", "html_url": "https://github.com/zhongyuk", "followers_url": "https://api.github.com/users/zhongyuk/followers", "following_url": "https://api.github.com/users/zhongyuk/following{/other_user}", "gists_url": "https://api.github.com/users/zhongyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhongyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhongyuk/subscriptions", "organizations_url": "https://api.github.com/users/zhongyuk/orgs", "repos_url": "https://api.github.com/users/zhongyuk/repos", "events_url": "https://api.github.com/users/zhongyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/zhongyuk/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-16T19:09:16Z", "updated_at": "2016-11-16T19:11:23Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2166977\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmduc\">@nmduc</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=172688\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/davek44\">@davek44</a>  I wrote some code to track the moving mean and moving variance computed in <code>tf.contrib.layers.batch_norm</code> during training and testing. I found out that the value of <code>decay</code> matters a lot (they use exponential decay to compute moving average and moving variance), with a <code>decay</code> setting closer to 1.0 (i.e. <code>decay=.999</code>), moving mean drops to a value closer to 0. I did 2 test runs with the exact same code but different <code>decay</code> settings in the <code>tf.contrib.layers.batch_norm</code>, and my validation/test accuracies seemed more reasonable.</p>\n<p>The test run results with <code>decay=0.9</code><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/6901075/20361517/dd5dbbd8-ac05-11e6-85ac-5a9e2dec3a2b.png\"><img width=\"784\" alt=\"screen shot 2016-11-16 at 1 51 51 pm\" src=\"https://cloud.githubusercontent.com/assets/6901075/20361517/dd5dbbd8-ac05-11e6-85ac-5a9e2dec3a2b.png\" style=\"max-width:100%;\"></a></p>\n<p>The test run results with <code>decay=0.999</code> (<code>decay=0.999</code> is the default setting in <code>tf.contrib.layers.batch_norm</code>)<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/6901075/20361605/31729f5e-ac06-11e6-9736-eb9ad2f15de1.png\"><img width=\"784\" alt=\"screen shot 2016-11-16 at 2 03 58 pm\" src=\"https://cloud.githubusercontent.com/assets/6901075/20361605/31729f5e-ac06-11e6-9736-eb9ad2f15de1.png\" style=\"max-width:100%;\"></a></p>\n<p>(also seems like larger decay value would require the model to train longer to see validation accuracy change )</p>", "body_text": "@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in tf.contrib.layers.batch_norm during training and testing. I found out that the value of decay matters a lot (they use exponential decay to compute moving average and moving variance), with a decay setting closer to 1.0 (i.e. decay=.999), moving mean drops to a value closer to 0. I did 2 test runs with the exact same code but different decay settings in the tf.contrib.layers.batch_norm, and my validation/test accuracies seemed more reasonable.\nThe test run results with decay=0.9\n\nThe test run results with decay=0.999 (decay=0.999 is the default setting in tf.contrib.layers.batch_norm)\n\n(also seems like larger decay value would require the model to train longer to see validation accuracy change )", "body": "@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in `tf.contrib.layers.batch_norm` during training and testing. I found out that the value of `decay` matters a lot (they use exponential decay to compute moving average and moving variance), with a `decay` setting closer to 1.0 (i.e. `decay=.999`), moving mean drops to a value closer to 0. I did 2 test runs with the exact same code but different `decay` settings in the `tf.contrib.layers.batch_norm`, and my validation/test accuracies seemed more reasonable.\n\nThe test run results with `decay=0.9`\n<img width=\"784\" alt=\"screen shot 2016-11-16 at 1 51 51 pm\" src=\"https://cloud.githubusercontent.com/assets/6901075/20361517/dd5dbbd8-ac05-11e6-85ac-5a9e2dec3a2b.png\">\n\nThe test run results with `decay=0.999` (`decay=0.999` is the default setting in `tf.contrib.layers.batch_norm`)\n<img width=\"784\" alt=\"screen shot 2016-11-16 at 2 03 58 pm\" src=\"https://cloud.githubusercontent.com/assets/6901075/20361605/31729f5e-ac06-11e6-9736-eb9ad2f15de1.png\">\n\n(also seems like larger decay value would require the model to train longer to see validation accuracy change )\n"}