{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259834510", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-259834510", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 259834510, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTgzNDUxMA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-10T23:05:26Z", "updated_at": "2016-11-10T23:05:26Z", "author_association": "MEMBER", "body_html": "<p>tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.</p>\n<pre><code>is_training_ph = tf.placeholder(tf.bool)\n\noutputs = tf.contrib.layers.batch_norm(layer_input, is_training=is_training_ph, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope='batch_norm'),\n</code></pre>", "body_text": "tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.\nis_training_ph = tf.placeholder(tf.bool)\n\noutputs = tf.contrib.layers.batch_norm(layer_input, is_training=is_training_ph, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope='batch_norm'),", "body": "tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.\n\n```\nis_training_ph = tf.placeholder(tf.bool)\n\noutputs = tf.contrib.layers.batch_norm(layer_input, is_training=is_training_ph, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope='batch_norm'),\n```\n"}