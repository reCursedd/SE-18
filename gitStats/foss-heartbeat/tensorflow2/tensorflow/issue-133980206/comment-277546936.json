{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277546936", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-277546936", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 277546936, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NzU0NjkzNg==", "user": {"login": "mshunshin", "id": 1478710, "node_id": "MDQ6VXNlcjE0Nzg3MTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1478710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mshunshin", "html_url": "https://github.com/mshunshin", "followers_url": "https://api.github.com/users/mshunshin/followers", "following_url": "https://api.github.com/users/mshunshin/following{/other_user}", "gists_url": "https://api.github.com/users/mshunshin/gists{/gist_id}", "starred_url": "https://api.github.com/users/mshunshin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mshunshin/subscriptions", "organizations_url": "https://api.github.com/users/mshunshin/orgs", "repos_url": "https://api.github.com/users/mshunshin/repos", "events_url": "https://api.github.com/users/mshunshin/events{/privacy}", "received_events_url": "https://api.github.com/users/mshunshin/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-05T20:33:27Z", "updated_at": "2017-02-05T20:33:27Z", "author_association": "NONE", "body_html": "<p>I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.</p>\n<p>When saving and restoring using:<br>\nsaver = tf.train.Saver()<br>\nit works,</p>\n<p>but when saving using:<br>\nsaver = tf.train.Saver(tf.trainable_variables() + [global_step])<br>\nso that I can save storage space (by not saving the gradients etc)<br>\non restore there is an error:<br>\n\"uninitialized value unpool4/convc/bn/moving_mean\"</p>\n<p>Obviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers. As I have lots of them (nested in many layers) - what is the most efficient way of adding them to the list of values to be saved? Also, given that these are trainable variables, why are they not addded to the trainable_variables collection?</p>", "body_text": "I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.\nWhen saving and restoring using:\nsaver = tf.train.Saver()\nit works,\nbut when saving using:\nsaver = tf.train.Saver(tf.trainable_variables() + [global_step])\nso that I can save storage space (by not saving the gradients etc)\non restore there is an error:\n\"uninitialized value unpool4/convc/bn/moving_mean\"\nObviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers. As I have lots of them (nested in many layers) - what is the most efficient way of adding them to the list of values to be saved? Also, given that these are trainable variables, why are they not addded to the trainable_variables collection?", "body": "I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.\r\n\r\nWhen saving and restoring using:\r\nsaver = tf.train.Saver()\r\nit works,\r\n\r\nbut when saving using:\r\nsaver = tf.train.Saver(tf.trainable_variables() + [global_step])\r\nso that I can save storage space (by not saving the gradients etc)\r\non restore there is an error:\r\n\"uninitialized value unpool4/convc/bn/moving_mean\"\r\n\r\nObviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers. As I have lots of them (nested in many layers) - what is the most efficient way of adding them to the list of values to be saved? Also, given that these are trainable variables, why are they not addded to the trainable_variables collection?\r\n"}