{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/280652741", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-280652741", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 280652741, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MDY1Mjc0MQ==", "user": {"login": "pavelbulanov", "id": 14073667, "node_id": "MDQ6VXNlcjE0MDczNjY3", "avatar_url": "https://avatars0.githubusercontent.com/u/14073667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavelbulanov", "html_url": "https://github.com/pavelbulanov", "followers_url": "https://api.github.com/users/pavelbulanov/followers", "following_url": "https://api.github.com/users/pavelbulanov/following{/other_user}", "gists_url": "https://api.github.com/users/pavelbulanov/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavelbulanov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavelbulanov/subscriptions", "organizations_url": "https://api.github.com/users/pavelbulanov/orgs", "repos_url": "https://api.github.com/users/pavelbulanov/repos", "events_url": "https://api.github.com/users/pavelbulanov/events{/privacy}", "received_events_url": "https://api.github.com/users/pavelbulanov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-17T13:44:05Z", "updated_at": "2017-02-17T13:49:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8534653\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soloice\">@soloice</a> , notice, how in about <a href=\"https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1122/hovercard\">comment</a> the following parameter is passed inside to the layer for calling batch_norm:</p>\n<blockquote>\n<p>batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}</p>\n</blockquote>\n<p>Without <code>updates_collections </code>set to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.</p>\n<p>Or you may try to run UPDATE_OPS yourself explicitly as one <a href=\"https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7469/hovercard\">here</a></p>\n<pre><code>    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n    if update_ops:\n        updates = tf.group(*update_ops)\n        cross_entropy = control_flow_ops.with_dependencies([updates], cross_entropy)\n</code></pre>\n<p>Update - I found that I quoted exactly your code and you do use UPDATE_OPS.</p>\n<p>As for \"cold start\", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up</p>", "body_text": "@soloice , notice, how in about comment the following parameter is passed inside to the layer for calling batch_norm:\n\nbatch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\n\nWithout updates_collections set to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.\nOr you may try to run UPDATE_OPS yourself explicitly as one here\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n    if update_ops:\n        updates = tf.group(*update_ops)\n        cross_entropy = control_flow_ops.with_dependencies([updates], cross_entropy)\n\nUpdate - I found that I quoted exactly your code and you do use UPDATE_OPS.\nAs for \"cold start\", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up", "body": "@soloice , notice, how in about [comment](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564) the following parameter is passed inside to the layer for calling batch_norm:\r\n\r\n>  batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\r\n\r\nWithout `updates_collections `set to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.\r\n\r\nOr you may try to run UPDATE_OPS yourself explicitly as one [here](https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674)\r\n```\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    if update_ops:\r\n        updates = tf.group(*update_ops)\r\n        cross_entropy = control_flow_ops.with_dependencies([updates], cross_entropy)\r\n```\r\n\r\nUpdate - I found that I quoted exactly your code and you do use UPDATE_OPS. \r\n\r\nAs for \"cold start\", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up"}