{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262093844", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-262093844", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 262093844, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjA5Mzg0NA==", "user": {"login": "dominikandreas", "id": 13525040, "node_id": "MDQ6VXNlcjEzNTI1MDQw", "avatar_url": "https://avatars2.githubusercontent.com/u/13525040?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dominikandreas", "html_url": "https://github.com/dominikandreas", "followers_url": "https://api.github.com/users/dominikandreas/followers", "following_url": "https://api.github.com/users/dominikandreas/following{/other_user}", "gists_url": "https://api.github.com/users/dominikandreas/gists{/gist_id}", "starred_url": "https://api.github.com/users/dominikandreas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dominikandreas/subscriptions", "organizations_url": "https://api.github.com/users/dominikandreas/orgs", "repos_url": "https://api.github.com/users/dominikandreas/repos", "events_url": "https://api.github.com/users/dominikandreas/events{/privacy}", "received_events_url": "https://api.github.com/users/dominikandreas/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-21T22:55:00Z", "updated_at": "2016-11-21T22:55:00Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1766524\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/sguada\">@sguada</a> thanks, does that also mean the output is actually independent of the batch size? because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change). To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size. Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6901075\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zhongyuk\">@zhongyuk</a> thanks, I've run about 5k updates with <code>decay=0.9</code>, so it should've converged and testing performance using large batch sizes is fine. But even if it didn't, would it result in a difference between training a testing? I'd be seeing bad performance during training <em>and</em> testing if it hadn't converged, right?</p>\n<p>I will investigate some more and see if I can reproduce the issue on another task. Thanks for the quick feed back so far!</p>", "body_text": "@sguada thanks, does that also mean the output is actually independent of the batch size? because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change). To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size. Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces.\n@zhongyuk thanks, I've run about 5k updates with decay=0.9, so it should've converged and testing performance using large batch sizes is fine. But even if it didn't, would it result in a difference between training a testing? I'd be seeing bad performance during training and testing if it hadn't converged, right?\nI will investigate some more and see if I can reproduce the issue on another task. Thanks for the quick feed back so far!", "body": "@sguada thanks, does that also mean the output is actually independent of the batch size? because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change). To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size. Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces. \r\n\r\n@zhongyuk thanks, I've run about 5k updates with `decay=0.9`, so it should've converged and testing performance using large batch sizes is fine. But even if it didn't, would it result in a difference between training a testing? I'd be seeing bad performance during training *and* testing if it hadn't converged, right?\r\n\r\nI will investigate some more and see if I can reproduce the issue on another task. Thanks for the quick feed back so far!"}