{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/232535426", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-232535426", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 232535426, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMjUzNTQyNg==", "user": {"login": "nmhkahn", "id": 16869368, "node_id": "MDQ6VXNlcjE2ODY5MzY4", "avatar_url": "https://avatars0.githubusercontent.com/u/16869368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nmhkahn", "html_url": "https://github.com/nmhkahn", "followers_url": "https://api.github.com/users/nmhkahn/followers", "following_url": "https://api.github.com/users/nmhkahn/following{/other_user}", "gists_url": "https://api.github.com/users/nmhkahn/gists{/gist_id}", "starred_url": "https://api.github.com/users/nmhkahn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nmhkahn/subscriptions", "organizations_url": "https://api.github.com/users/nmhkahn/orgs", "repos_url": "https://api.github.com/users/nmhkahn/repos", "events_url": "https://api.github.com/users/nmhkahn/events{/privacy}", "received_events_url": "https://api.github.com/users/nmhkahn/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-14T01:49:35Z", "updated_at": "2016-07-14T01:51:05Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1855278\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/brando90\">@brando90</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2412413\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pawni\">@pawni</a> he's code works good, but have to change like below</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">BatchNorm</span>(<span class=\"pl-smi\">inputT</span>, <span class=\"pl-smi\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-smi\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Note: is_training is tf.placeholder(tf.bool) type</span>\n    <span class=\"pl-k\">return</span> tf.cond(is_training,  \n                <span class=\"pl-k\">lambda</span>: batch_norm(inputT, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,  \n                                   <span class=\"pl-v\">center</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">updates_collections</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span>scope),  \n                <span class=\"pl-k\">lambda</span>: batch_norm(inputT, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,  \n                                   <span class=\"pl-v\">updates_collections</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">center</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span>scope, <span class=\"pl-v\">reuse</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>))  </pre></div>\n<p>And when run in training or test time,</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> when training </span>\nsess.run([opt, loss], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x: bx, y: by, is_training=<span class=\"pl-c1\">True</span>})  \n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> when test </span>\nsess.run([opt, loss], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x: bx, y: by, is_training=<span class=\"pl-c1\">False</span>})  </pre></div>\n<p>This code works, but like <a href=\"https://github.com/tensorflow/tensorflow/issues/3265\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3265/hovercard\">#3265</a> says it will be great if <code>tf.contrib.layers.batch_norm</code> get <code>is_training</code> variable as a <code>tf.plcaeholer</code>.</p>", "body_text": "@brando90 @pawni he's code works good, but have to change like below\ndef BatchNorm(inputT, is_training=True, scope=None):\n    # Note: is_training is tf.placeholder(tf.bool) type\n    return tf.cond(is_training,  \n                lambda: batch_norm(inputT, is_training=True,  \n                                   center=False, updates_collections=None, scope=scope),  \n                lambda: batch_norm(inputT, is_training=False,  \n                                   updates_collections=None, center=False, scope=scope, reuse = True))  \nAnd when run in training or test time,\n# when training \nsess.run([opt, loss], feed_dict={x: bx, y: by, is_training=True})  \n\n# when test \nsess.run([opt, loss], feed_dict={x: bx, y: by, is_training=False})  \nThis code works, but like #3265 says it will be great if tf.contrib.layers.batch_norm get is_training variable as a tf.plcaeholer.", "body": "@brando90 @pawni he's code works good, but have to change like below\n\n``` python\ndef BatchNorm(inputT, is_training=True, scope=None):\n    # Note: is_training is tf.placeholder(tf.bool) type\n    return tf.cond(is_training,  \n                lambda: batch_norm(inputT, is_training=True,  \n                                   center=False, updates_collections=None, scope=scope),  \n                lambda: batch_norm(inputT, is_training=False,  \n                                   updates_collections=None, center=False, scope=scope, reuse = True))  \n```\n\nAnd when run in training or test time,\n\n``` python\n# when training \nsess.run([opt, loss], feed_dict={x: bx, y: by, is_training=True})  \n\n# when test \nsess.run([opt, loss], feed_dict={x: bx, y: by, is_training=False})  \n```\n\nThis code works, but like [#3265](https://github.com/tensorflow/tensorflow/issues/3265) says it will be great if `tf.contrib.layers.batch_norm` get `is_training` variable as a `tf.plcaeholer`.\n"}