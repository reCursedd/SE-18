{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8168", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8168/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8168/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8168/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8168", "id": 212435463, "node_id": "MDU6SXNzdWUyMTI0MzU0NjM=", "number": 8168, "title": "tf.case evaluating all outputs when using batches (?)", "user": {"login": "MicaelCarvalho", "id": 17184992, "node_id": "MDQ6VXNlcjE3MTg0OTky", "avatar_url": "https://avatars3.githubusercontent.com/u/17184992?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MicaelCarvalho", "html_url": "https://github.com/MicaelCarvalho", "followers_url": "https://api.github.com/users/MicaelCarvalho/followers", "following_url": "https://api.github.com/users/MicaelCarvalho/following{/other_user}", "gists_url": "https://api.github.com/users/MicaelCarvalho/gists{/gist_id}", "starred_url": "https://api.github.com/users/MicaelCarvalho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MicaelCarvalho/subscriptions", "organizations_url": "https://api.github.com/users/MicaelCarvalho/orgs", "repos_url": "https://api.github.com/users/MicaelCarvalho/repos", "events_url": "https://api.github.com/users/MicaelCarvalho/events{/privacy}", "received_events_url": "https://api.github.com/users/MicaelCarvalho/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-03-07T13:41:05Z", "updated_at": "2017-12-22T17:51:28Z", "closed_at": "2017-12-22T17:51:28Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello,</p>\n<p>I may be missing something here, but I couldn't find any useful information on the documentation, so I'm posting this behavior as a bug, hoping someone can clarify what's going on. Questions at the end of this issue</p>\n<p><strong>Operating System:</strong> Debian 4.8.15-2<br>\n<strong>Installed version of CUDA and cuDNN:</strong> CUDA 8, cuDNN 5<br>\n<strong>python3 -c \"import tensorflow; print(tensorflow.<strong>version</strong>)\"</strong>: 1.0.0</p>\n<h3>Reproducible example</h3>\n<pre><code>import tensorflow as tf\n\na = ([tf.constant(i) for i in range(2)],[tf.constant(i) for i in range(2)])\nb = ([tf.constant(i) for i in range(2)],[tf.constant(i) for i in range(2)])\n\nq1 = tf.train.slice_input_producer(a, num_epochs=3, shuffle=True, capacity=4)\nq2 = tf.train.batch(q1, batch_size=2, num_threads=1, enqueue_many=False, capacity=4, allow_smaller_final_batch=True)\n\nq3 = tf.train.slice_input_producer(b, num_epochs=1, shuffle=True, capacity=4)\nq4 = tf.train.batch(q3, batch_size=2, num_threads=1, enqueue_many=False, capacity=4, allow_smaller_final_batch=True)\n\nq4p = [tf.Print(q4[0], ['q4a']), tf.Print(q4[1], ['q4b'])]\nq2p = [tf.Print(q2[0], ['q2a']), tf.Print(q2[1], ['q2b'])]\n\ndef get_op1():\n\tprint('call1')\n\treturn tf.Print(q2p, ['op1'])\n\ndef get_op2():\n\tprint('call2')\n\treturn tf.Print(q4p, ['op2'])\n\nswitcher = tf.placeholder(tf.bool)\ntest = tf.case([(switcher, get_op1)], default=get_op2, exclusive=True)\n\ninit = [tf.global_variables_initializer(), tf.local_variables_initializer()]\nsess = tf.Session()\ncoord = tf.train.Coordinator()\nsess.run(init)\nthreads = tf.train.start_queue_runners(coord=coord, sess=sess)\n\nignore = sess.run(test, feed_dict={switcher: True})\n\nwait = input(\"So far, so good. We're evaluating q1/q2, but now q3/q4 will run out of examples. Press enter to continue.\")\n\nignore = sess.run(test, feed_dict={switcher: True})\n</code></pre>\n<h3>Output</h3>\n<pre><code>call2\ncall2\ncall1\n[None, None]\nI tensorflow/core/kernels/logging_ops.cc:79] [q4b]\nI tensorflow/core/kernels/logging_ops.cc:79] [q2a]\nI tensorflow/core/kernels/logging_ops.cc:79] [q4a]\nI tensorflow/core/kernels/logging_ops.cc:79] [q2b]\nI tensorflow/core/kernels/logging_ops.cc:79] [op1]\n(some warnings/errors)\nSo far, so good. We're evaluating q1/q2, but now q3/q4 will run out of examples. Press enter to continue. (enter pressed)\n(big errors, queue is empty)\n</code></pre>\n<h3>Questions</h3>\n<ol>\n<li>Why is <code>get_op2()</code> called 2 times before init?</li>\n<li>Why are there so many messages after the first <code>sess.run(test...)</code>? And why do they say <code>OutOfRange</code>, when I have enough examples in the queue? (I can only imagine it's because the threads feeding the queue are dying, but weird nevertheless)</li>\n<li>Although <code>op2</code> is not printed, <code>q4a</code> and <code>q4b</code> are, and they shouldn't, since we're evaluating <code>q2</code>. This led me to believe examples are being pulled from <code>q4</code> even though I didn't ask for them, and that is why the second <code>sess.run(test...)</code> crashes : no more examples in <code>q4</code>.</li>\n</ol>\n<p>It seems tf.case is evaluating everything (weirdly, without printing <code>op2</code>), because <code>q4</code> goes to exhaustion without being used at all. I am using this system to switch between train/validation sets, but I'm being restricted by the amount of images in validation, which doesn't make any sense. So far I can only imagine either there is a bizarre bug on <code>tf.case</code> or I misunderstood something. Could you clarify this please?</p>\n<p>Thanks in advance.</p>", "body_text": "Hello,\nI may be missing something here, but I couldn't find any useful information on the documentation, so I'm posting this behavior as a bug, hoping someone can clarify what's going on. Questions at the end of this issue\nOperating System: Debian 4.8.15-2\nInstalled version of CUDA and cuDNN: CUDA 8, cuDNN 5\npython3 -c \"import tensorflow; print(tensorflow.version)\": 1.0.0\nReproducible example\nimport tensorflow as tf\n\na = ([tf.constant(i) for i in range(2)],[tf.constant(i) for i in range(2)])\nb = ([tf.constant(i) for i in range(2)],[tf.constant(i) for i in range(2)])\n\nq1 = tf.train.slice_input_producer(a, num_epochs=3, shuffle=True, capacity=4)\nq2 = tf.train.batch(q1, batch_size=2, num_threads=1, enqueue_many=False, capacity=4, allow_smaller_final_batch=True)\n\nq3 = tf.train.slice_input_producer(b, num_epochs=1, shuffle=True, capacity=4)\nq4 = tf.train.batch(q3, batch_size=2, num_threads=1, enqueue_many=False, capacity=4, allow_smaller_final_batch=True)\n\nq4p = [tf.Print(q4[0], ['q4a']), tf.Print(q4[1], ['q4b'])]\nq2p = [tf.Print(q2[0], ['q2a']), tf.Print(q2[1], ['q2b'])]\n\ndef get_op1():\n\tprint('call1')\n\treturn tf.Print(q2p, ['op1'])\n\ndef get_op2():\n\tprint('call2')\n\treturn tf.Print(q4p, ['op2'])\n\nswitcher = tf.placeholder(tf.bool)\ntest = tf.case([(switcher, get_op1)], default=get_op2, exclusive=True)\n\ninit = [tf.global_variables_initializer(), tf.local_variables_initializer()]\nsess = tf.Session()\ncoord = tf.train.Coordinator()\nsess.run(init)\nthreads = tf.train.start_queue_runners(coord=coord, sess=sess)\n\nignore = sess.run(test, feed_dict={switcher: True})\n\nwait = input(\"So far, so good. We're evaluating q1/q2, but now q3/q4 will run out of examples. Press enter to continue.\")\n\nignore = sess.run(test, feed_dict={switcher: True})\n\nOutput\ncall2\ncall2\ncall1\n[None, None]\nI tensorflow/core/kernels/logging_ops.cc:79] [q4b]\nI tensorflow/core/kernels/logging_ops.cc:79] [q2a]\nI tensorflow/core/kernels/logging_ops.cc:79] [q4a]\nI tensorflow/core/kernels/logging_ops.cc:79] [q2b]\nI tensorflow/core/kernels/logging_ops.cc:79] [op1]\n(some warnings/errors)\nSo far, so good. We're evaluating q1/q2, but now q3/q4 will run out of examples. Press enter to continue. (enter pressed)\n(big errors, queue is empty)\n\nQuestions\n\nWhy is get_op2() called 2 times before init?\nWhy are there so many messages after the first sess.run(test...)? And why do they say OutOfRange, when I have enough examples in the queue? (I can only imagine it's because the threads feeding the queue are dying, but weird nevertheless)\nAlthough op2 is not printed, q4a and q4b are, and they shouldn't, since we're evaluating q2. This led me to believe examples are being pulled from q4 even though I didn't ask for them, and that is why the second sess.run(test...) crashes : no more examples in q4.\n\nIt seems tf.case is evaluating everything (weirdly, without printing op2), because q4 goes to exhaustion without being used at all. I am using this system to switch between train/validation sets, but I'm being restricted by the amount of images in validation, which doesn't make any sense. So far I can only imagine either there is a bizarre bug on tf.case or I misunderstood something. Could you clarify this please?\nThanks in advance.", "body": "Hello,\r\n\r\nI may be missing something here, but I couldn't find any useful information on the documentation, so I'm posting this behavior as a bug, hoping someone can clarify what's going on. Questions at the end of this issue\r\n\r\n**Operating System:** Debian 4.8.15-2\r\n**Installed version of CUDA and cuDNN:** CUDA 8, cuDNN 5\r\n**python3 -c \"import tensorflow; print(tensorflow.__version__)\"**: 1.0.0\r\n\r\n### Reproducible example\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\na = ([tf.constant(i) for i in range(2)],[tf.constant(i) for i in range(2)])\r\nb = ([tf.constant(i) for i in range(2)],[tf.constant(i) for i in range(2)])\r\n\r\nq1 = tf.train.slice_input_producer(a, num_epochs=3, shuffle=True, capacity=4)\r\nq2 = tf.train.batch(q1, batch_size=2, num_threads=1, enqueue_many=False, capacity=4, allow_smaller_final_batch=True)\r\n\r\nq3 = tf.train.slice_input_producer(b, num_epochs=1, shuffle=True, capacity=4)\r\nq4 = tf.train.batch(q3, batch_size=2, num_threads=1, enqueue_many=False, capacity=4, allow_smaller_final_batch=True)\r\n\r\nq4p = [tf.Print(q4[0], ['q4a']), tf.Print(q4[1], ['q4b'])]\r\nq2p = [tf.Print(q2[0], ['q2a']), tf.Print(q2[1], ['q2b'])]\r\n\r\ndef get_op1():\r\n\tprint('call1')\r\n\treturn tf.Print(q2p, ['op1'])\r\n\r\ndef get_op2():\r\n\tprint('call2')\r\n\treturn tf.Print(q4p, ['op2'])\r\n\r\nswitcher = tf.placeholder(tf.bool)\r\ntest = tf.case([(switcher, get_op1)], default=get_op2, exclusive=True)\r\n\r\ninit = [tf.global_variables_initializer(), tf.local_variables_initializer()]\r\nsess = tf.Session()\r\ncoord = tf.train.Coordinator()\r\nsess.run(init)\r\nthreads = tf.train.start_queue_runners(coord=coord, sess=sess)\r\n\r\nignore = sess.run(test, feed_dict={switcher: True})\r\n\r\nwait = input(\"So far, so good. We're evaluating q1/q2, but now q3/q4 will run out of examples. Press enter to continue.\")\r\n\r\nignore = sess.run(test, feed_dict={switcher: True})\r\n```\r\n\r\n### Output\r\n\r\n```\r\ncall2\r\ncall2\r\ncall1\r\n[None, None]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [q4b]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [q2a]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [q4a]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [q2b]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [op1]\r\n(some warnings/errors)\r\nSo far, so good. We're evaluating q1/q2, but now q3/q4 will run out of examples. Press enter to continue. (enter pressed)\r\n(big errors, queue is empty)\r\n```\r\n\r\n### Questions\r\n\r\n1) Why is `get_op2()` called 2 times before init?\r\n2) Why are there so many messages after the first `sess.run(test...)`? And why do they say `OutOfRange`, when I have enough examples in the queue? (I can only imagine it's because the threads feeding the queue are dying, but weird nevertheless)\r\n3) Although `op2` is not printed, `q4a` and `q4b` are, and they shouldn't, since we're evaluating `q2`. This led me to believe examples are being pulled from `q4` even though I didn't ask for them, and that is why the second `sess.run(test...)` crashes : no more examples in `q4`.\r\n\r\nIt seems tf.case is evaluating everything (weirdly, without printing `op2`), because `q4` goes to exhaustion without being used at all. I am using this system to switch between train/validation sets, but I'm being restricted by the amount of images in validation, which doesn't make any sense. So far I can only imagine either there is a bizarre bug on `tf.case` or I misunderstood something. Could you clarify this please?\r\n\r\nThanks in advance."}