{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/306101610", "html_url": "https://github.com/tensorflow/tensorflow/issues/8168#issuecomment-306101610", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8168", "id": 306101610, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNjEwMTYxMA==", "user": {"login": "ed-alertedh", "id": 24605895, "node_id": "MDQ6VXNlcjI0NjA1ODk1", "avatar_url": "https://avatars1.githubusercontent.com/u/24605895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ed-alertedh", "html_url": "https://github.com/ed-alertedh", "followers_url": "https://api.github.com/users/ed-alertedh/followers", "following_url": "https://api.github.com/users/ed-alertedh/following{/other_user}", "gists_url": "https://api.github.com/users/ed-alertedh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ed-alertedh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ed-alertedh/subscriptions", "organizations_url": "https://api.github.com/users/ed-alertedh/orgs", "repos_url": "https://api.github.com/users/ed-alertedh/repos", "events_url": "https://api.github.com/users/ed-alertedh/events{/privacy}", "received_events_url": "https://api.github.com/users/ed-alertedh/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-05T04:39:12Z", "updated_at": "2017-06-05T04:44:27Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17184992\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/MicaelCarvalho\">@MicaelCarvalho</a> I seem to have implemented the hack you described. Fairly dirty, but if anybody wants a stopgap...</p>\n<pre><code>batch_train=tf.train.shuffle_batch(...)\nbatch_test=tf.train.shuffle_batch(...)\nqueue_selector = tf.placeholder(tf.int32, name='queue_selector')\ntrain_q = tf.QueueBase(queue_ref=batch_train.op.inputs[0], dtypes=[tf.string], shapes=None, names=None)\ntest_q = tf.QueueBase(queue_ref=batch_test.op.inputs[0], dtypes=[tf.string], shapes=None, names=None)\nselected_batch = tf.QueueBase.from_list(queue_selector, [train_q, test_q])\nselected_batch_size = tf.stack([train_batch_size, test_batch_size], axis=0)[queue_selector]\ndequeue_op = selected_batch.dequeue_many(selected_batch_size)\nfeatures = tf.parse_example(dequeue_op, ....)\n</code></pre>\n<p>edit: if it's not entirely clear, batch_train and batch_test are dequeue ops and take the queue reference as their first input. We then use those to construct new QueueBase objects, feed them through a selector  and create our own dequeue op which only runs on the selected queue.</p>", "body_text": "@MicaelCarvalho I seem to have implemented the hack you described. Fairly dirty, but if anybody wants a stopgap...\nbatch_train=tf.train.shuffle_batch(...)\nbatch_test=tf.train.shuffle_batch(...)\nqueue_selector = tf.placeholder(tf.int32, name='queue_selector')\ntrain_q = tf.QueueBase(queue_ref=batch_train.op.inputs[0], dtypes=[tf.string], shapes=None, names=None)\ntest_q = tf.QueueBase(queue_ref=batch_test.op.inputs[0], dtypes=[tf.string], shapes=None, names=None)\nselected_batch = tf.QueueBase.from_list(queue_selector, [train_q, test_q])\nselected_batch_size = tf.stack([train_batch_size, test_batch_size], axis=0)[queue_selector]\ndequeue_op = selected_batch.dequeue_many(selected_batch_size)\nfeatures = tf.parse_example(dequeue_op, ....)\n\nedit: if it's not entirely clear, batch_train and batch_test are dequeue ops and take the queue reference as their first input. We then use those to construct new QueueBase objects, feed them through a selector  and create our own dequeue op which only runs on the selected queue.", "body": "@MicaelCarvalho I seem to have implemented the hack you described. Fairly dirty, but if anybody wants a stopgap...\r\n\r\n```\r\nbatch_train=tf.train.shuffle_batch(...)\r\nbatch_test=tf.train.shuffle_batch(...)\r\nqueue_selector = tf.placeholder(tf.int32, name='queue_selector')\r\ntrain_q = tf.QueueBase(queue_ref=batch_train.op.inputs[0], dtypes=[tf.string], shapes=None, names=None)\r\ntest_q = tf.QueueBase(queue_ref=batch_test.op.inputs[0], dtypes=[tf.string], shapes=None, names=None)\r\nselected_batch = tf.QueueBase.from_list(queue_selector, [train_q, test_q])\r\nselected_batch_size = tf.stack([train_batch_size, test_batch_size], axis=0)[queue_selector]\r\ndequeue_op = selected_batch.dequeue_many(selected_batch_size)\r\nfeatures = tf.parse_example(dequeue_op, ....)\r\n```\r\nedit: if it's not entirely clear, batch_train and batch_test are dequeue ops and take the queue reference as their first input. We then use those to construct new QueueBase objects, feed them through a selector  and create our own dequeue op which only runs on the selected queue."}