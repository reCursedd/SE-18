{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14023", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14023/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14023/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14023/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14023", "id": 269010864, "node_id": "MDU6SXNzdWUyNjkwMTA4NjQ=", "number": 14023, "title": "TFRecords and Inference issues", "user": {"login": "abviv", "id": 19665838, "node_id": "MDQ6VXNlcjE5NjY1ODM4", "avatar_url": "https://avatars3.githubusercontent.com/u/19665838?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abviv", "html_url": "https://github.com/abviv", "followers_url": "https://api.github.com/users/abviv/followers", "following_url": "https://api.github.com/users/abviv/following{/other_user}", "gists_url": "https://api.github.com/users/abviv/gists{/gist_id}", "starred_url": "https://api.github.com/users/abviv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abviv/subscriptions", "organizations_url": "https://api.github.com/users/abviv/orgs", "repos_url": "https://api.github.com/users/abviv/repos", "events_url": "https://api.github.com/users/abviv/events{/privacy}", "received_events_url": "https://api.github.com/users/abviv/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-10-27T07:20:20Z", "updated_at": "2017-10-27T12:12:00Z", "closed_at": "2017-10-27T12:12:00Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: conda</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/6.0</li>\n<li><strong>GPU model and memory</strong>: Nvidia quadro M6000</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>I converted my dataset into TFrecords and trained my model using a custom Network. Everything was quite fine until i tried to use the trained model by running an inference with the checkpoint files and the problems started there.Without using the _ = tf.contib.data.Dataset line it produces the following error</p>\n<pre><code>def create_graph():\n    with gfile.FastGFile(os.path.join(model_dir, 'frozen_net.pb'), 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        #_ = tf.contrib.data.Dataset   ---------------------------&gt;issue with this line \n        _ = tf.import_graph_def(graph_def, name='')\n\n\ndef load_graph(frozen_graph_filename):\n    # We load the protobuf file from the disk and parse it to retrieve the \n    # unserialized graph_def\n    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n\n    with tf.Graph().as_default() as graph:\n                    tf.import_graph_def(\n                        graph_def, \n                        input_map=None, \n                        return_elements=None, \n                        name=\"\", \n                        op_dict=None, \n                        producer_op_list=None\n                    )\n                    return graph\n\n</code></pre>\n<p>Traceback (most recent call last):<br>\nFile \"/home/sysgen/files/TENSOR_FROZEN/UNFREEZING_NET.py\", line 159, in <br>\ncreate_graph()<br>\nFile \"/home/sysgen/files/TENSOR_FROZEN/UNFREEZING_NET.py\", line 28, in create_graph<br>\n_ = tf.import_graph_def(graph_def, name='')<br>\nFile \"/home/sysgen/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 285, in import_graph_def<br>\nraise ValueError('No op named %s in defined operations.' % node.op)<br>\nValueError: No op named Iterator in defined operations.</p>\n<p>This was also the same issue which i faced even for freezing the whole graph ,without importing the Dataset module I'm not able to move forward. Even a normal restoring operation with saver.restore fails.</p>\n<p>FYI: I know how to solve the issue but my actual question is why it occurs and why was it not happening when i pickled the dataset and fed in the data?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): conda\nTensorFlow version (use command below): 1.3\nPython version: 2.7\nBazel version (if compiling from source):\nCUDA/cuDNN version: 8.0/6.0\nGPU model and memory: Nvidia quadro M6000\nExact command to reproduce:\n\nI converted my dataset into TFrecords and trained my model using a custom Network. Everything was quite fine until i tried to use the trained model by running an inference with the checkpoint files and the problems started there.Without using the _ = tf.contib.data.Dataset line it produces the following error\ndef create_graph():\n    with gfile.FastGFile(os.path.join(model_dir, 'frozen_net.pb'), 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        #_ = tf.contrib.data.Dataset   --------------------------->issue with this line \n        _ = tf.import_graph_def(graph_def, name='')\n\n\ndef load_graph(frozen_graph_filename):\n    # We load the protobuf file from the disk and parse it to retrieve the \n    # unserialized graph_def\n    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n\n    with tf.Graph().as_default() as graph:\n                    tf.import_graph_def(\n                        graph_def, \n                        input_map=None, \n                        return_elements=None, \n                        name=\"\", \n                        op_dict=None, \n                        producer_op_list=None\n                    )\n                    return graph\n\n\nTraceback (most recent call last):\nFile \"/home/sysgen/files/TENSOR_FROZEN/UNFREEZING_NET.py\", line 159, in \ncreate_graph()\nFile \"/home/sysgen/files/TENSOR_FROZEN/UNFREEZING_NET.py\", line 28, in create_graph\n_ = tf.import_graph_def(graph_def, name='')\nFile \"/home/sysgen/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 285, in import_graph_def\nraise ValueError('No op named %s in defined operations.' % node.op)\nValueError: No op named Iterator in defined operations.\nThis was also the same issue which i faced even for freezing the whole graph ,without importing the Dataset module I'm not able to move forward. Even a normal restoring operation with saver.restore fails.\nFYI: I know how to solve the issue but my actual question is why it occurs and why was it not happening when i pickled the dataset and fed in the data?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: conda\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: Nvidia quadro M6000\r\n- **Exact command to reproduce**:\r\n\r\nI converted my dataset into TFrecords and trained my model using a custom Network. Everything was quite fine until i tried to use the trained model by running an inference with the checkpoint files and the problems started there.Without using the _ = tf.contib.data.Dataset line it produces the following error\r\n\r\n ```\r\ndef create_graph():\r\n     with gfile.FastGFile(os.path.join(model_dir, 'frozen_net.pb'), 'rb') as f:\r\n         graph_def = tf.GraphDef()\r\n         graph_def.ParseFromString(f.read())\r\n         #_ = tf.contrib.data.Dataset   --------------------------->issue with this line \r\n         _ = tf.import_graph_def(graph_def, name='')\r\n\r\n\r\n def load_graph(frozen_graph_filename):\r\n     # We load the protobuf file from the disk and parse it to retrieve the \r\n     # unserialized graph_def\r\n     with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\r\n         graph_def = tf.GraphDef()\r\n         graph_def.ParseFromString(f.read())\r\n\r\n     with tf.Graph().as_default() as graph:\r\n                     tf.import_graph_def(\r\n                         graph_def, \r\n                         input_map=None, \r\n                         return_elements=None, \r\n                         name=\"\", \r\n                         op_dict=None, \r\n                         producer_op_list=None\r\n                     )\r\n                     return graph\r\n\r\n```\r\n Traceback (most recent call last):\r\n  File \"/home/sysgen/files/TENSOR_FROZEN/UNFREEZING_NET.py\", line 159, in <module>\r\n    create_graph()\r\n  File \"/home/sysgen/files/TENSOR_FROZEN/UNFREEZING_NET.py\", line 28, in create_graph\r\n    _ = tf.import_graph_def(graph_def, name='')\r\n  File \"/home/sysgen/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 285, in import_graph_def\r\n    raise ValueError('No op named %s in defined operations.' % node.op)\r\nValueError: No op named Iterator in defined operations.\r\n\r\nThis was also the same issue which i faced even for freezing the whole graph ,without importing the Dataset module I'm not able to move forward. Even a normal restoring operation with saver.restore fails.\r\n\r\nFYI: I know how to solve the issue but my actual question is why it occurs and why was it not happening when i pickled the dataset and fed in the data? "}