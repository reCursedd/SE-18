{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2919", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2919/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2919/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2919/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2919", "id": 160794964, "node_id": "MDU6SXNzdWUxNjA3OTQ5NjQ=", "number": 2919, "title": "feed_dict performance", "user": {"login": "nanddalal", "id": 2473609, "node_id": "MDQ6VXNlcjI0NzM2MDk=", "avatar_url": "https://avatars1.githubusercontent.com/u/2473609?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nanddalal", "html_url": "https://github.com/nanddalal", "followers_url": "https://api.github.com/users/nanddalal/followers", "following_url": "https://api.github.com/users/nanddalal/following{/other_user}", "gists_url": "https://api.github.com/users/nanddalal/gists{/gist_id}", "starred_url": "https://api.github.com/users/nanddalal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nanddalal/subscriptions", "organizations_url": "https://api.github.com/users/nanddalal/orgs", "repos_url": "https://api.github.com/users/nanddalal/repos", "events_url": "https://api.github.com/users/nanddalal/events{/privacy}", "received_events_url": "https://api.github.com/users/nanddalal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2016-06-17T01:27:27Z", "updated_at": "2016-10-03T15:44:52Z", "closed_at": "2016-08-08T16:25:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have been experimenting with different way of reading data in tensorflow, namely:</p>\n<ul>\n<li>input ops / queues</li>\n<li>feed_dict / placeholders</li>\n</ul>\n<p>I am finding that feed_dict is much slower on my alexnet benchmark. I have adapted the alexnet benchmark code from the <a href=\"https://github.com/soumith/convnet-benchmarks/blob/master/tensorflow/benchmark_alexnet.py\">convnet-benchmarks</a>. You can find my benchmarking code <a href=\"https://gist.github.com/nanddalal/a0fdd6798ea52afaaeb6e1a78aaeb6db\">here</a>. The main diff is the addition of a <code>feed_dict</code> flag which switches between using tf.Variable and tf.Placeholder for the inputs/labels.</p>\n<p>In all my tests, I only run the fprop.<br>\nMy first test was running the benchmark on a GPU using NCHW:</p>\n<pre><code>feed_dict=True: 102 ms/minibatch\nfeed_dict=False 28 ms/minibatch\n</code></pre>\n<p>As you can see, with <code>feed_dict=False</code>, it matches the benchmark, but with <code>feed_dict=True</code>, it is 4-5x slower. You can find the full output for <code>feed_dict=True</code> <a href=\"https://github.com/tensorflow/tensorflow/files/319610/benchmark_with_feed_dict.txt\">here</a><br>\nand <code>feed_dict=False</code> <a href=\"https://github.com/tensorflow/tensorflow/files/319611/benchmark_without_feed_dict.txt\">here</a>. These contain yappi profiling output which shows that the bottleneck does not seem to be in the python code. I have also attached the tf timeline output and would appreciate if you can tell me how to interpret it in chrome://tracing.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/319613/timeline_with_feed_dict.json.txt\">timeline_with_feed_dict.json.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/319614/timeline_without_feed_dict.json.txt\">timeline_without_feed_dict.json.txt</a></p>\n<p>I also ran the same test on CPU using NHWC:</p>\n<pre><code>feed_dict=True: 727 ms/minibatch\nfeed_dict=False: 664 ms/minibatch\n</code></pre>\n<p>So using <code>feed_dict</code> appears to have a constant/one time cost.</p>\n<p>I was able to gain almost 2x speedup by changing this <a href=\"https://github.com/tensorflow/tensorflow/blob/9425f822d8a5dc657022eed5c5142b4bf7b1087a/tensorflow/python/client/session.py#L619\">line</a> from <code>np.array</code> to <code>np.asarray</code>, but feed_dict is still quite slow.</p>\n<p>Please let me know what your thoughts are about this and whether feed_dict is supposed to be this much slower than a pipeline using tfrecords/queues.</p>", "body_text": "I have been experimenting with different way of reading data in tensorflow, namely:\n\ninput ops / queues\nfeed_dict / placeholders\n\nI am finding that feed_dict is much slower on my alexnet benchmark. I have adapted the alexnet benchmark code from the convnet-benchmarks. You can find my benchmarking code here. The main diff is the addition of a feed_dict flag which switches between using tf.Variable and tf.Placeholder for the inputs/labels.\nIn all my tests, I only run the fprop.\nMy first test was running the benchmark on a GPU using NCHW:\nfeed_dict=True: 102 ms/minibatch\nfeed_dict=False 28 ms/minibatch\n\nAs you can see, with feed_dict=False, it matches the benchmark, but with feed_dict=True, it is 4-5x slower. You can find the full output for feed_dict=True here\nand feed_dict=False here. These contain yappi profiling output which shows that the bottleneck does not seem to be in the python code. I have also attached the tf timeline output and would appreciate if you can tell me how to interpret it in chrome://tracing.\ntimeline_with_feed_dict.json.txt\ntimeline_without_feed_dict.json.txt\nI also ran the same test on CPU using NHWC:\nfeed_dict=True: 727 ms/minibatch\nfeed_dict=False: 664 ms/minibatch\n\nSo using feed_dict appears to have a constant/one time cost.\nI was able to gain almost 2x speedup by changing this line from np.array to np.asarray, but feed_dict is still quite slow.\nPlease let me know what your thoughts are about this and whether feed_dict is supposed to be this much slower than a pipeline using tfrecords/queues.", "body": "I have been experimenting with different way of reading data in tensorflow, namely:\n- input ops / queues\n- feed_dict / placeholders\n\nI am finding that feed_dict is much slower on my alexnet benchmark. I have adapted the alexnet benchmark code from the [convnet-benchmarks](https://github.com/soumith/convnet-benchmarks/blob/master/tensorflow/benchmark_alexnet.py). You can find my benchmarking code [here](https://gist.github.com/nanddalal/a0fdd6798ea52afaaeb6e1a78aaeb6db). The main diff is the addition of a `feed_dict` flag which switches between using tf.Variable and tf.Placeholder for the inputs/labels.\n\nIn all my tests, I only run the fprop.\nMy first test was running the benchmark on a GPU using NCHW:\n\n```\nfeed_dict=True: 102 ms/minibatch\nfeed_dict=False 28 ms/minibatch\n```\n\nAs you can see, with `feed_dict=False`, it matches the benchmark, but with `feed_dict=True`, it is 4-5x slower. You can find the full output for `feed_dict=True` [here](https://github.com/tensorflow/tensorflow/files/319610/benchmark_with_feed_dict.txt)\n and `feed_dict=False` [here](https://github.com/tensorflow/tensorflow/files/319611/benchmark_without_feed_dict.txt). These contain yappi profiling output which shows that the bottleneck does not seem to be in the python code. I have also attached the tf timeline output and would appreciate if you can tell me how to interpret it in chrome://tracing. \n[timeline_with_feed_dict.json.txt](https://github.com/tensorflow/tensorflow/files/319613/timeline_with_feed_dict.json.txt)\n[timeline_without_feed_dict.json.txt](https://github.com/tensorflow/tensorflow/files/319614/timeline_without_feed_dict.json.txt)\n\nI also ran the same test on CPU using NHWC:\n\n```\nfeed_dict=True: 727 ms/minibatch\nfeed_dict=False: 664 ms/minibatch\n```\n\nSo using `feed_dict` appears to have a constant/one time cost.\n\nI was able to gain almost 2x speedup by changing this [line](https://github.com/tensorflow/tensorflow/blob/9425f822d8a5dc657022eed5c5142b4bf7b1087a/tensorflow/python/client/session.py#L619) from `np.array` to `np.asarray`, but feed_dict is still quite slow.\n\nPlease let me know what your thoughts are about this and whether feed_dict is supposed to be this much slower than a pipeline using tfrecords/queues.\n"}