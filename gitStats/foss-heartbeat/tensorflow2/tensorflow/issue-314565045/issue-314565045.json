{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18550", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18550/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18550/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18550/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18550", "id": 314565045, "node_id": "MDU6SXNzdWUzMTQ1NjUwNDU=", "number": 18550, "title": "compile tensorflow r1.8 occured error", "user": {"login": "sirius-ai", "id": 32933617, "node_id": "MDQ6VXNlcjMyOTMzNjE3", "avatar_url": "https://avatars2.githubusercontent.com/u/32933617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sirius-ai", "html_url": "https://github.com/sirius-ai", "followers_url": "https://api.github.com/users/sirius-ai/followers", "following_url": "https://api.github.com/users/sirius-ai/following{/other_user}", "gists_url": "https://api.github.com/users/sirius-ai/gists{/gist_id}", "starred_url": "https://api.github.com/users/sirius-ai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sirius-ai/subscriptions", "organizations_url": "https://api.github.com/users/sirius-ai/orgs", "repos_url": "https://api.github.com/users/sirius-ai/repos", "events_url": "https://api.github.com/users/sirius-ai/events{/privacy}", "received_events_url": "https://api.github.com/users/sirius-ai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-04-16T09:18:02Z", "updated_at": "2018-09-01T10:10:01Z", "closed_at": "2018-05-03T00:51:59Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: N</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 17.10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: r1.8</li>\n<li><strong>Python version</strong>:  python 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: GCC-6\uff0cG++-6</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.1\uff08include patch1/2/3\uff09\uff0ccuDNN 7.1</li>\n<li><strong>GPU model and memory</strong>: gtx 1060ti\uff0c6GB\uff1b gtx 1080ti\uff0c11GB</li>\n<li><strong>Exact command to reproduce</strong>:<br>\nbazel build --config=opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>lately\uff0cI had try install tensorflow r1.8 from source but unsuccessful\uff0cthen I tryed to compile tf r1.6 it is normal, and my friend also try to install tensorflow r1.8 from source was successful, which difference enviroment between us are CUDA/cuDNN and gcc/g++, he use CUDA 8.0/cuDNN 5.0 and gcc-5/g++5.</p>\n<p>compile tf r1.8 occured error log as below\uff1a</p>\n<pre><code>/usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC&lt;&lt;anonymous&gt;, _Elements&gt;::_MoveConstructibleTuple() [with _UElements = {std::tuple&lt;int, int, int&gt;}; bool &lt;anonymous&gt; = true; _Elements = {int, int, int}]' not a return-statement\n     }\n ^\n/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC&lt;&lt;anonymous&gt;, _Elements&gt;::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple&lt;int, int, int&gt;}; bool &lt;anonymous&gt; = true; _Elements = {int, int, int}]':\n/usr/include/c++/6/tuple:626:362:   required by substitution of 'template&lt;class ... _UElements, typename std::enable_if&lt;(((std::_TC&lt;(sizeof... (_UElements) == 1), int, int, int&gt;::_NotSameTuple&lt;_UElements ...&gt;() &amp;&amp; std::_TC&lt;(1ul == sizeof... (_UElements)), int, int, int&gt;::_MoveConstructibleTuple&lt;_UElements ...&gt;()) &amp;&amp; std::_TC&lt;(1ul == sizeof... (_UElements)), int, int, int&gt;::_ImplicitlyMoveConvertibleTuple&lt;_UElements ...&gt;()) &amp;&amp; (3ul &gt;= 1)), bool&gt;::type &lt;anonymous&gt; &gt; constexpr std::tuple&lt; &lt;template-parameter-1-1&gt; &gt;::tuple(_UElements&amp;&amp; ...) [with _UElements = {std::tuple&lt;int, int, int&gt;}; typename std::enable_if&lt;(((std::_TC&lt;(sizeof... (_UElements) == 1), int, int, int&gt;::_NotSameTuple&lt;_UElements ...&gt;() &amp;&amp; std::_TC&lt;(1ul == sizeof... (_UElements)), int, int, int&gt;::_MoveConstructibleTuple&lt;_UElements ...&gt;()) &amp;&amp; std::_TC&lt;(1ul == sizeof... (_UElements)), int, int, int&gt;::_ImplicitlyMoveConvertibleTuple&lt;_UElements ...&gt;()) &amp;&amp; (3ul &gt;= 1)), bool&gt;::type &lt;anonymous&gt; = &lt;missing&gt;]'\n./tensorflow/stream_executor/dnn.h:891:91:   required from here\n/usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible&lt;_UElements&amp;&amp;, _Elements&gt;'\n       return __and_&lt;is_convertible&lt;_UElements&amp;&amp;, _Elements&gt;...&gt;::value;\n                                                                 ^~~~~\n/usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC&lt;&lt;anonymous&gt;, _Elements&gt;::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple&lt;int, int, int&gt;}; bool &lt;anonymous&gt; = true; _Elements = {int, int, int}]' not a return-statement\n     }\n ^\n/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC&lt;&lt;anonymous&gt;, _Elements&gt;::_NonNestedTuple() [with _SrcTuple = std::tuple&lt;int, int, int&gt;&amp;&amp;; bool &lt;anonymous&gt; = true; _Elements = {int, int, int}]':\n/usr/include/c++/6/tuple:686:422:   required by substitution of 'template&lt;class ... _UElements, class _Dummy, typename std::enable_if&lt;((std::_TC&lt;(1ul == sizeof... (_UElements)), int, int, int&gt;::_MoveConstructibleTuple&lt;_UElements ...&gt;() &amp;&amp; std::_TC&lt;(1ul == sizeof... (_UElements)), int, int, int&gt;::_ImplicitlyMoveConvertibleTuple&lt;_UElements ...&gt;()) &amp;&amp; std::_TC&lt;(std::is_same&lt;_Dummy, void&gt;::value &amp;&amp; (1ul == 1)), int, int, int&gt;::_NonNestedTuple&lt;tuple&lt;_Elements ...&gt;&amp;&amp;&gt;()), bool&gt;::type &lt;anonymous&gt; &gt; constexpr std::tuple&lt; &lt;template-parameter-1-1&gt; &gt;::tuple(std::tuple&lt;_Args1 ...&gt;&amp;&amp;) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if&lt;((std::_TC&lt;(1ul == sizeof... (_UElements)), int, int, int&gt;::_MoveConstructibleTuple&lt;_UElements ...&gt;() &amp;&amp; std::_TC&lt;(1ul == sizeof... (_UElements)), int, int, int&gt;::_ImplicitlyMoveConvertibleTuple&lt;_UElements ...&gt;()) &amp;&amp; std::_TC&lt;(std::is_same&lt;_Dummy, void&gt;::value &amp;&amp; (1ul == 1)), int, int, int&gt;::_NonNestedTuple&lt;tuple&lt;_Elements ...&gt;&amp;&amp;&gt;()), bool&gt;::type &lt;anonymous&gt; = &lt;missing&gt;]'\n./tensorflow/stream_executor/dnn.h:891:91:   required from here\n/usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)\n       return  __and_&lt;__not_&lt;is_same&lt;tuple&lt;_Elements...&gt;,\n                                                                                                                                                                                                                                                    ^    \n/usr/include/c++/6/type_traits:1558:8: note: provided for 'template&lt;class _From, class _To&gt; struct std::is_convertible'\n     struct is_convertible\n        ^~~~~~~~~~~~~~\n/usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC&lt;&lt;anonymous&gt;, _Elements&gt;::_NonNestedTuple() [with _SrcTuple = std::tuple&lt;int, int, int&gt;&amp;&amp;; bool &lt;anonymous&gt; = true; _Elements = {int, int, int}]' not a return-statement\n     }\n ^\nERROR: /home/andy/TF/tensorflow/tensorflow/contrib/nccl/BUILD:23:1: output 'tensorflow/contrib/nccl/_objs/python/ops/_nccl_ops_gpu/tensorflow/contrib/nccl/kernels/nccl_ops.pic.o' was not created\nERROR: /home/andy/TF/tensorflow/tensorflow/contrib/nccl/BUILD:23:1: not all outputs were created or valid\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 1037.698s, Critical Path: 28.30s\nFAILED: Build did NOT complete successfully\n</code></pre>\n<p>my configure of r1.7 and r1.8 is below:</p>\n<pre><code>(python3) andy@andy:~/TF/tensorflow$ ./configure \nWARNING: Running Bazel server needs to be killed, because the startup options are different.\nYou have bazel 0.11.1 installed.\nPlease specify the location of python. [Default is /home/andy/python3/bin/python]: \n\n\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nAttributeError: module 'site' has no attribute 'getsitepackages'\nFound possible Python library paths:\n  /home/andy/python3/lib/python3.6/site-packages\nPlease input the desired Python library path to use.  Default is [/home/andy/python3/lib/python3.6/site-packages]\n\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\nNo Hadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\nNo Amazon S3 File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n\nNo Apache Kafka Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \nNo XLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with GDR support? [y/N]: \nNo GDR support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]: \nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \nNo OpenCL SYCL support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1\n\n\nPlease specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \n\n\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7\n\n\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\n\n\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \nNo TensorRT support will be enabled for TensorFlow.\n\nPlease specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]: \n\n\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\n\n\nDo you want to use clang as CUDA compiler? [y/N]: \nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/x86_64-linux-gnu-gcc-6]: \n\n\nDo you wish to build TensorFlow with MPI support? [y/N]: \nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \n\n\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \nNot configuring the WORKSPACE for Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=&lt;&gt;\" to your build command. See tools/bazel.rc for more details.\n\t--config=mkl         \t# Build with MKL support.\n\t--config=monolithic  \t# Config for mostly static monolithic build.\nConfiguration finished\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 17.10\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): r1.8\nPython version:  python 3.6\nBazel version (if compiling from source): 0.11.1\nGCC/Compiler version (if compiling from source): GCC-6\uff0cG++-6\nCUDA/cuDNN version: CUDA 9.1\uff08include patch1/2/3\uff09\uff0ccuDNN 7.1\nGPU model and memory: gtx 1060ti\uff0c6GB\uff1b gtx 1080ti\uff0c11GB\nExact command to reproduce:\nbazel build --config=opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\n\nDescribe the problem\nlately\uff0cI had try install tensorflow r1.8 from source but unsuccessful\uff0cthen I tryed to compile tf r1.6 it is normal, and my friend also try to install tensorflow r1.8 from source was successful, which difference enviroment between us are CUDA/cuDNN and gcc/g++, he use CUDA 8.0/cuDNN 5.0 and gcc-5/g++5.\ncompile tf r1.8 occured error log as below\uff1a\n/usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\n     }\n ^\n/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':\n/usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'\n./tensorflow/stream_executor/dnn.h:891:91:   required from here\n/usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'\n       return __and_<is_convertible<_UElements&&, _Elements>...>::value;\n                                                                 ^~~~~\n/usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\n     }\n ^\n/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]':\n/usr/include/c++/6/tuple:686:422:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(std::tuple<_Args1 ...>&&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> = <missing>]'\n./tensorflow/stream_executor/dnn.h:891:91:   required from here\n/usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)\n       return  __and_<__not_<is_same<tuple<_Elements...>,\n                                                                                                                                                                                                                                                    ^    \n/usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'\n     struct is_convertible\n        ^~~~~~~~~~~~~~\n/usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\n     }\n ^\nERROR: /home/andy/TF/tensorflow/tensorflow/contrib/nccl/BUILD:23:1: output 'tensorflow/contrib/nccl/_objs/python/ops/_nccl_ops_gpu/tensorflow/contrib/nccl/kernels/nccl_ops.pic.o' was not created\nERROR: /home/andy/TF/tensorflow/tensorflow/contrib/nccl/BUILD:23:1: not all outputs were created or valid\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 1037.698s, Critical Path: 28.30s\nFAILED: Build did NOT complete successfully\n\nmy configure of r1.7 and r1.8 is below:\n(python3) andy@andy:~/TF/tensorflow$ ./configure \nWARNING: Running Bazel server needs to be killed, because the startup options are different.\nYou have bazel 0.11.1 installed.\nPlease specify the location of python. [Default is /home/andy/python3/bin/python]: \n\n\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nAttributeError: module 'site' has no attribute 'getsitepackages'\nFound possible Python library paths:\n  /home/andy/python3/lib/python3.6/site-packages\nPlease input the desired Python library path to use.  Default is [/home/andy/python3/lib/python3.6/site-packages]\n\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\nNo Hadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\nNo Amazon S3 File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n\nNo Apache Kafka Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \nNo XLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with GDR support? [y/N]: \nNo GDR support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]: \nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \nNo OpenCL SYCL support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1\n\n\nPlease specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \n\n\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7\n\n\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\n\n\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \nNo TensorRT support will be enabled for TensorFlow.\n\nPlease specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]: \n\n\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\n\n\nDo you want to use clang as CUDA compiler? [y/N]: \nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/x86_64-linux-gnu-gcc-6]: \n\n\nDo you wish to build TensorFlow with MPI support? [y/N]: \nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \n\n\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \nNot configuring the WORKSPACE for Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\n\t--config=mkl         \t# Build with MKL support.\n\t--config=monolithic  \t# Config for mostly static monolithic build.\nConfiguration finished", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.8\r\n- **Python version**:  python 3.6\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: GCC-6\uff0cG++-6\r\n- **CUDA/cuDNN version**: CUDA 9.1\uff08include patch1/2/3\uff09\uff0ccuDNN 7.1\r\n- **GPU model and memory**: gtx 1060ti\uff0c6GB\uff1b gtx 1080ti\uff0c11GB\r\n- **Exact command to reproduce**: \r\nbazel build --config=opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\nlately\uff0cI had try install tensorflow r1.8 from source but unsuccessful\uff0cthen I tryed to compile tf r1.6 it is normal, and my friend also try to install tensorflow r1.8 from source was successful, which difference enviroment between us are CUDA/cuDNN and gcc/g++, he use CUDA 8.0/cuDNN 5.0 and gcc-5/g++5.\r\n\r\ncompile tf r1.8 occured error log as below\uff1a\r\n```\r\n/usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n     }\r\n ^\r\n/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':\r\n/usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'\r\n./tensorflow/stream_executor/dnn.h:891:91:   required from here\r\n/usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'\r\n       return __and_<is_convertible<_UElements&&, _Elements>...>::value;\r\n                                                                 ^~~~~\r\n/usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n     }\r\n ^\r\n/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]':\r\n/usr/include/c++/6/tuple:686:422:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(std::tuple<_Args1 ...>&&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> = <missing>]'\r\n./tensorflow/stream_executor/dnn.h:891:91:   required from here\r\n/usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)\r\n       return  __and_<__not_<is_same<tuple<_Elements...>,\r\n                                                                                                                                                                                                                                                    ^    \r\n/usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'\r\n     struct is_convertible\r\n        ^~~~~~~~~~~~~~\r\n/usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement\r\n     }\r\n ^\r\nERROR: /home/andy/TF/tensorflow/tensorflow/contrib/nccl/BUILD:23:1: output 'tensorflow/contrib/nccl/_objs/python/ops/_nccl_ops_gpu/tensorflow/contrib/nccl/kernels/nccl_ops.pic.o' was not created\r\nERROR: /home/andy/TF/tensorflow/tensorflow/contrib/nccl/BUILD:23:1: not all outputs were created or valid\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1037.698s, Critical Path: 28.30s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nmy configure of r1.7 and r1.8 is below:\r\n```\r\n(python3) andy@andy:~/TF/tensorflow$ ./configure \r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nYou have bazel 0.11.1 installed.\r\nPlease specify the location of python. [Default is /home/andy/python3/bin/python]: \r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: module 'site' has no attribute 'getsitepackages'\r\nFound possible Python library paths:\r\n  /home/andy/python3/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/andy/python3/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\r\nNo Hadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\r\nNo Amazon S3 File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n\r\nNo Apache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: \r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: \r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1\r\n\r\n\r\nPlease specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7\r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]: \r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/x86_64-linux-gnu-gcc-6]: \r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: \r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\nConfiguration finished\r\n```\r\n\r\n"}