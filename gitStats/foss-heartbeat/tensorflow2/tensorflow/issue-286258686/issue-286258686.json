{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15876", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15876/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15876/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15876/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15876", "id": 286258686, "node_id": "MDU6SXNzdWUyODYyNTg2ODY=", "number": 15876, "title": "tfcompile with --config=monolithic and -fvisibility=hidden results in undefined reference __xla_cpu_runtime_EigenMatMulF32", "user": {"login": "lissyx", "id": 1645737, "node_id": "MDQ6VXNlcjE2NDU3Mzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1645737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lissyx", "html_url": "https://github.com/lissyx", "followers_url": "https://api.github.com/users/lissyx/followers", "following_url": "https://api.github.com/users/lissyx/following{/other_user}", "gists_url": "https://api.github.com/users/lissyx/gists{/gist_id}", "starred_url": "https://api.github.com/users/lissyx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lissyx/subscriptions", "organizations_url": "https://api.github.com/users/lissyx/orgs", "repos_url": "https://api.github.com/users/lissyx/repos", "events_url": "https://api.github.com/users/lissyx/events{/privacy}", "received_events_url": "https://api.github.com/users/lissyx/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2018-01-05T11:07:28Z", "updated_at": "2018-02-08T22:56:52Z", "closed_at": "2018-01-16T18:03:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Some background first. For DeepSpeech, I have been experimenting simplification of our set of dependencies, trying to do a <code>--config=monolithic</code> build. The root cause for that was being able to run a <code>SYCL</code>-enabled build on my system (Ubuntu 17.10). Using <code>OpenCL</code> on this would trigger dependency load-chain that in the end loads <code>libmirprotobuf</code>. This would clash with the <code>protobuf</code> symbols already built in our <code>libtensorflow_framework</code> / <code>libtensorflow_cc</code>. To avoid this, monolithic build and forcing <code>visibility=hidden</code> seemed to be the best solution.</p>\n<p>This allows us to move from those libraries (non tfcompile build, tfcompile adds <code>libdeepspeech_model.so</code> and all the <code>XLA</code> dependencies):</p>\n<ul>\n<li><code>libdeepspeech.so</code></li>\n<li><code>libdeepspeech_utils.so</code></li>\n<li><code>libtensorflow_cc.so</code></li>\n<li><code>libtensorflow_framework.so</code></li>\n</ul>\n<p>To just:</p>\n<ul>\n<li><code>libdeepspeech.so</code></li>\n<li><code>libdeepspeech_utils.so</code></li>\n</ul>\n<p>This way, we have all needed TensorFlow bits within <code>libdeepspeech.so</code>, and those symbols are not re-exported thus avoiding any unwanted interaction. I could get <code>SYCL</code> build nearly working on Intel GPU.</p>\n<p>Adding <code>tfcompile</code> in the equation, however, lead to linking issues. Symptom would be that build completes, but when one links binary against the model's <code>.so</code>, then it fails with:</p>\n<pre><code>undefined reference __xla_cpu_runtime_EigenMatMulF32\n</code></pre>\n<p>Checking with <code>objdump -t bazel-bin/tensorflow/compiler/xla/service/cpu/_objs/runtime_matmul/tensorflow/compiler/xla/service/cpu/runtime_matmul*.o | grep EigenMatMul</code> would show that the symbol is properly built into <code>runtime_matmul</code>, but that it is hidden.</p>\n<p>I would be able to solve that by exposing <code>__xla_cpu_runtime_EigenMatMulF32</code> and <code>__xla_cpu_runtime_EigenMatMulF64</code> through <code>TF_EXPORT</code>.</p>", "body_text": "Some background first. For DeepSpeech, I have been experimenting simplification of our set of dependencies, trying to do a --config=monolithic build. The root cause for that was being able to run a SYCL-enabled build on my system (Ubuntu 17.10). Using OpenCL on this would trigger dependency load-chain that in the end loads libmirprotobuf. This would clash with the protobuf symbols already built in our libtensorflow_framework / libtensorflow_cc. To avoid this, monolithic build and forcing visibility=hidden seemed to be the best solution.\nThis allows us to move from those libraries (non tfcompile build, tfcompile adds libdeepspeech_model.so and all the XLA dependencies):\n\nlibdeepspeech.so\nlibdeepspeech_utils.so\nlibtensorflow_cc.so\nlibtensorflow_framework.so\n\nTo just:\n\nlibdeepspeech.so\nlibdeepspeech_utils.so\n\nThis way, we have all needed TensorFlow bits within libdeepspeech.so, and those symbols are not re-exported thus avoiding any unwanted interaction. I could get SYCL build nearly working on Intel GPU.\nAdding tfcompile in the equation, however, lead to linking issues. Symptom would be that build completes, but when one links binary against the model's .so, then it fails with:\nundefined reference __xla_cpu_runtime_EigenMatMulF32\n\nChecking with objdump -t bazel-bin/tensorflow/compiler/xla/service/cpu/_objs/runtime_matmul/tensorflow/compiler/xla/service/cpu/runtime_matmul*.o | grep EigenMatMul would show that the symbol is properly built into runtime_matmul, but that it is hidden.\nI would be able to solve that by exposing __xla_cpu_runtime_EigenMatMulF32 and __xla_cpu_runtime_EigenMatMulF64 through TF_EXPORT.", "body": "Some background first. For DeepSpeech, I have been experimenting simplification of our set of dependencies, trying to do a `--config=monolithic` build. The root cause for that was being able to run a `SYCL`-enabled build on my system (Ubuntu 17.10). Using `OpenCL` on this would trigger dependency load-chain that in the end loads `libmirprotobuf`. This would clash with the `protobuf` symbols already built in our `libtensorflow_framework` / `libtensorflow_cc`. To avoid this, monolithic build and forcing `visibility=hidden` seemed to be the best solution.\r\n\r\nThis allows us to move from those libraries (non tfcompile build, tfcompile adds `libdeepspeech_model.so` and all the `XLA` dependencies):\r\n - `libdeepspeech.so`\r\n - `libdeepspeech_utils.so`\r\n - `libtensorflow_cc.so`\r\n - `libtensorflow_framework.so`\r\n\r\nTo just:\r\n - `libdeepspeech.so`\r\n - `libdeepspeech_utils.so`\r\n\r\nThis way, we have all needed TensorFlow bits within `libdeepspeech.so`, and those symbols are not re-exported thus avoiding any unwanted interaction. I could get `SYCL` build nearly working on Intel GPU.\r\n\r\nAdding `tfcompile` in the equation, however, lead to linking issues. Symptom would be that build completes, but when one links binary against the model's `.so`, then it fails with:\r\n```\r\nundefined reference __xla_cpu_runtime_EigenMatMulF32\r\n```\r\n\r\nChecking with `objdump -t bazel-bin/tensorflow/compiler/xla/service/cpu/_objs/runtime_matmul/tensorflow/compiler/xla/service/cpu/runtime_matmul*.o | grep EigenMatMul` would show that the symbol is properly built into `runtime_matmul`, but that it is hidden.\r\n\r\nI would be able to solve that by exposing `__xla_cpu_runtime_EigenMatMulF32` and `__xla_cpu_runtime_EigenMatMulF64` through `TF_EXPORT`."}