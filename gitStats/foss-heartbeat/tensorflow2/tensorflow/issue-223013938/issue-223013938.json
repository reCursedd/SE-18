{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9332", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9332/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9332/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9332/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9332", "id": 223013938, "node_id": "MDU6SXNzdWUyMjMwMTM5Mzg=", "number": 9332, "title": "Cannot get Conv1D layer to work", "user": {"login": "ddegraw", "id": 27475048, "node_id": "MDQ6VXNlcjI3NDc1MDQ4", "avatar_url": "https://avatars0.githubusercontent.com/u/27475048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ddegraw", "html_url": "https://github.com/ddegraw", "followers_url": "https://api.github.com/users/ddegraw/followers", "following_url": "https://api.github.com/users/ddegraw/following{/other_user}", "gists_url": "https://api.github.com/users/ddegraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/ddegraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ddegraw/subscriptions", "organizations_url": "https://api.github.com/users/ddegraw/orgs", "repos_url": "https://api.github.com/users/ddegraw/repos", "events_url": "https://api.github.com/users/ddegraw/events{/privacy}", "received_events_url": "https://api.github.com/users/ddegraw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-20T10:03:27Z", "updated_at": "2017-04-20T15:42:53Z", "closed_at": "2017-04-20T15:42:53Z", "author_association": "NONE", "body_html": "<p>For the life of me, I cannot get Conv1D layer to work.  I am on windoze7 with theano backend and using MKL multithreading.  No issues with other layer types whatsoever.</p>\n<p>The error I get is: convx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(embedded_sequences_1)<br>\nTypeError: <strong>init</strong>() takes at least 3 arguments (2 given)</p>\n<p>Model code as below:<br>\nembedding_layer = Embedding(nb_words,<br>\nEMBEDDING_DIM,<br>\nweights=[embedding_matrix],<br>\ninput_length=MAX_SEQUENCE_LENGTH,<br>\ntrainable=False)<br>\nsequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')<br>\nembedded_sequences_1 = embedding_layer(sequence_1_input)</p>\n<p>sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')<br>\nembedded_sequences_2 = embedding_layer(sequence_2_input)</p>\n<p>convx =[]<br>\nfor sz in filter_sizes:<br>\nconvx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(embedded_sequences_1)<br>\nconvx1 = GlobalMaxPooling1D(pool_size=2)(convx1)<br>\nconvx1 = Flatten()(convx1)<br>\nconvx.append(convx1)<br>\nx1 = merge(convx, mode='concat')</p>\n<p>convy =[]<br>\nfor sz in filter_sizes:<br>\nconvy1 = Conv1D(filters=num_filters,kernel_size=sz,padding=\"valid\",activation=\"relu\",strides=1)(embedded_sequences_2)<br>\nconvy1 = GlobalMaxPooling1D(pool_size=2)(convy1)<br>\nconvy1 = Flatten()(convy1)<br>\nconvy.append(convy1)<br>\ny1 = merge(convy, mode='concat')</p>\n<p>merged = merge([x1,y1], mode='concat')<br>\nmerged = Dropout(0.5)(merged)<br>\nmerged = BatchNormalization()(merged)<br>\nmerged = Dense(num_dense, activation='relu')(merged)<br>\nmerged = Dropout(0.15)(merged)<br>\nmerged = BatchNormalization()(merged)<br>\npreds = Dense(1, activation='sigmoid')(merged)<br>\nmodel = Model(input=[sequence_1_input,sequence_2_input], output=preds)<br>\nmodel.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])</p>", "body_text": "For the life of me, I cannot get Conv1D layer to work.  I am on windoze7 with theano backend and using MKL multithreading.  No issues with other layer types whatsoever.\nThe error I get is: convx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(embedded_sequences_1)\nTypeError: init() takes at least 3 arguments (2 given)\nModel code as below:\nembedding_layer = Embedding(nb_words,\nEMBEDDING_DIM,\nweights=[embedding_matrix],\ninput_length=MAX_SEQUENCE_LENGTH,\ntrainable=False)\nsequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')\nembedded_sequences_1 = embedding_layer(sequence_1_input)\nsequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')\nembedded_sequences_2 = embedding_layer(sequence_2_input)\nconvx =[]\nfor sz in filter_sizes:\nconvx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(embedded_sequences_1)\nconvx1 = GlobalMaxPooling1D(pool_size=2)(convx1)\nconvx1 = Flatten()(convx1)\nconvx.append(convx1)\nx1 = merge(convx, mode='concat')\nconvy =[]\nfor sz in filter_sizes:\nconvy1 = Conv1D(filters=num_filters,kernel_size=sz,padding=\"valid\",activation=\"relu\",strides=1)(embedded_sequences_2)\nconvy1 = GlobalMaxPooling1D(pool_size=2)(convy1)\nconvy1 = Flatten()(convy1)\nconvy.append(convy1)\ny1 = merge(convy, mode='concat')\nmerged = merge([x1,y1], mode='concat')\nmerged = Dropout(0.5)(merged)\nmerged = BatchNormalization()(merged)\nmerged = Dense(num_dense, activation='relu')(merged)\nmerged = Dropout(0.15)(merged)\nmerged = BatchNormalization()(merged)\npreds = Dense(1, activation='sigmoid')(merged)\nmodel = Model(input=[sequence_1_input,sequence_2_input], output=preds)\nmodel.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])", "body": "For the life of me, I cannot get Conv1D layer to work.  I am on windoze7 with theano backend and using MKL multithreading.  No issues with other layer types whatsoever.\r\n\r\nThe error I get is: convx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(embedded_sequences_1)\r\nTypeError: __init__() takes at least 3 arguments (2 given)\r\n\r\nModel code as below:\r\nembedding_layer = Embedding(nb_words,\r\n                            EMBEDDING_DIM,\r\n                            weights=[embedding_matrix],\r\n                            input_length=MAX_SEQUENCE_LENGTH,\r\n                            trainable=False)\r\nsequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')\r\nembedded_sequences_1 = embedding_layer(sequence_1_input)\r\n\r\nsequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')\r\nembedded_sequences_2 = embedding_layer(sequence_2_input)\r\n\r\nconvx =[]\r\nfor sz in filter_sizes:\r\n    convx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(embedded_sequences_1)\r\n    convx1 = GlobalMaxPooling1D(pool_size=2)(convx1)\r\n    convx1 = Flatten()(convx1)\r\n    convx.append(convx1)   \r\nx1 = merge(convx, mode='concat')\r\n\r\nconvy =[]\r\nfor sz in filter_sizes:\r\n    convy1 = Conv1D(filters=num_filters,kernel_size=sz,padding=\"valid\",activation=\"relu\",strides=1)(embedded_sequences_2)\r\n    convy1 = GlobalMaxPooling1D(pool_size=2)(convy1)\r\n    convy1 = Flatten()(convy1)\r\n    convy.append(convy1)   \r\ny1 = merge(convy, mode='concat')                   \r\n\r\nmerged = merge([x1,y1], mode='concat')\r\nmerged = Dropout(0.5)(merged)\r\nmerged = BatchNormalization()(merged)\r\nmerged = Dense(num_dense, activation='relu')(merged)\r\nmerged = Dropout(0.15)(merged)\r\nmerged = BatchNormalization()(merged)\r\npreds = Dense(1, activation='sigmoid')(merged)\r\nmodel = Model(input=[sequence_1_input,sequence_2_input], output=preds)\r\nmodel.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])"}