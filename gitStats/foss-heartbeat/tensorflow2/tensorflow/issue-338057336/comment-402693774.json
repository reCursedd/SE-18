{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/402693774", "html_url": "https://github.com/tensorflow/tensorflow/issues/20532#issuecomment-402693774", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20532", "id": 402693774, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjY5Mzc3NA==", "user": {"login": "Tauranis", "id": 9088856, "node_id": "MDQ6VXNlcjkwODg4NTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9088856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tauranis", "html_url": "https://github.com/Tauranis", "followers_url": "https://api.github.com/users/Tauranis/followers", "following_url": "https://api.github.com/users/Tauranis/following{/other_user}", "gists_url": "https://api.github.com/users/Tauranis/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tauranis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tauranis/subscriptions", "organizations_url": "https://api.github.com/users/Tauranis/orgs", "repos_url": "https://api.github.com/users/Tauranis/repos", "events_url": "https://api.github.com/users/Tauranis/events{/privacy}", "received_events_url": "https://api.github.com/users/Tauranis/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-05T11:34:49Z", "updated_at": "2018-07-05T11:34:49Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4759327\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dhingratul\">@dhingratul</a> I would recommend you to use the Estimator API if possible and export a saved model. It generates a frozen model (.pb file) and it can be easily deployed.</p>\n<p>If you do need to freeze the model in an old fashion way take a look on the script below I have been using until TensorFlow 1.6. It is a little different from what is provided by TF official repo</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> argparse\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">freeze_graph</span>(<span class=\"pl-smi\">model_dir</span>, <span class=\"pl-smi\">output_tensors</span>, <span class=\"pl-smi\">output_pb</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Freeze graph model into **.pb** file</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Extract the sub graph defined by the output nodes and convert all its variables to constants</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Args:    </span>\n<span class=\"pl-s\">        ``model_dir`` (str): directory that contains all checkpoint files (.ckpt, .meta, .info)</span>\n<span class=\"pl-s\">        </span>\n<span class=\"pl-s\">        ``output_tensors`` (str):  comma separated list of all the output node's names</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">        ``output_pb`` (str): output **.pb** frozen graph file      </span>\n<span class=\"pl-s\">        </span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> tf.gfile.Exists(model_dir):\n        <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">AssertionError</span>(\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Export directory doesn't exists. Please specify an export <span class=\"pl-pds\">\"</span></span>\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>directory: <span class=\"pl-c1\">%s</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> model_dir)\n\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> output_tensors:\n        tf.loogin.error(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>You need to supply the name of a node to --output_tensors.<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-k\">return</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Retrieve checkpoint fullpath</span>\n    checkpoint <span class=\"pl-k\">=</span> tf.train.get_checkpoint_state(model_dir)\n    input_checkpoint <span class=\"pl-k\">=</span> checkpoint.model_checkpoint_path\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Clear original devices from graph</span>\n    clear_devices <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>tf.Graph()) <span class=\"pl-k\">as</span> sess:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Import graph from .meta file</span>\n        saver <span class=\"pl-k\">=</span> tf.train.import_meta_graph(\n            input_checkpoint <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>.meta<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">clear_devices</span><span class=\"pl-k\">=</span>clear_devices)\n\n        input_graph_def <span class=\"pl-k\">=</span> tf.get_default_graph().as_graph_def()\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> and restore weights</span>\n        saver.restore(sess, input_checkpoint)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Convert variables to constants</span>\n        output_graph_def <span class=\"pl-k\">=</span> tf.graph_util.convert_variables_to_constants(\n            sess,\n            input_graph_def,            \n            output_tensors.split(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>,<span class=\"pl-pds\">\"</span></span>),\n            <span class=\"pl-v\">variable_names_blacklist</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>global_step<span class=\"pl-pds\">'</span></span>]\n        )\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Dump frozen model</span>\n        <span class=\"pl-k\">with</span> tf.gfile.GFile(output_pb, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wb<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> f:\n            f.write(output_graph_def.SerializeToString())\n        tf.logging.info(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-c1\">%d</span> ops in the final graph.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> <span class=\"pl-c1\">len</span>(output_graph_def.node))\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>return output_graph_def</span>\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    parser <span class=\"pl-k\">=</span> argparse.ArgumentParser()\n    parser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--model_dir<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n                        <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Model folder to export<span class=\"pl-pds\">\"</span></span>)\n    parser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--output_tensors<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n                        <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>The name of the output nodes, comma separated.<span class=\"pl-pds\">\"</span></span>)\n    parser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--output_pb<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n                        <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>frozen_model.pb<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Output pb file<span class=\"pl-pds\">\"</span></span>)\n    args <span class=\"pl-k\">=</span> parser.parse_args()\n\n    freeze_graph(args.model_dir, args.output_tensors, args.output_pb)</pre></div>", "body_text": "@dhingratul I would recommend you to use the Estimator API if possible and export a saved model. It generates a frozen model (.pb file) and it can be easily deployed.\nIf you do need to freeze the model in an old fashion way take a look on the script below I have been using until TensorFlow 1.6. It is a little different from what is provided by TF official repo\nimport os\nimport argparse\nimport tensorflow as tf\n\n\ndef freeze_graph(model_dir, output_tensors, output_pb):\n    \"\"\" Freeze graph model into **.pb** file\n    \n    Extract the sub graph defined by the output nodes and convert all its variables to constants\n\n    Args:    \n        ``model_dir`` (str): directory that contains all checkpoint files (.ckpt, .meta, .info)\n        \n        ``output_tensors`` (str):  comma separated list of all the output node's names\n\n        ``output_pb`` (str): output **.pb** frozen graph file      \n        \n    \"\"\"\n    if not tf.gfile.Exists(model_dir):\n        raise AssertionError(\n            \"Export directory doesn't exists. Please specify an export \"\n            \"directory: %s\" % model_dir)\n\n    if not output_tensors:\n        tf.loogin.error(\"You need to supply the name of a node to --output_tensors.\")\n        return -1\n\n    # Retrieve checkpoint fullpath\n    checkpoint = tf.train.get_checkpoint_state(model_dir)\n    input_checkpoint = checkpoint.model_checkpoint_path\n    \n    # Clear original devices from graph\n    clear_devices = True\n\n    with tf.Session(graph=tf.Graph()) as sess:\n        # Import graph from .meta file\n        saver = tf.train.import_meta_graph(\n            input_checkpoint + '.meta', clear_devices=clear_devices)\n\n        input_graph_def = tf.get_default_graph().as_graph_def()\n\n        # and restore weights\n        saver.restore(sess, input_checkpoint)\n\n        # Convert variables to constants\n        output_graph_def = tf.graph_util.convert_variables_to_constants(\n            sess,\n            input_graph_def,            \n            output_tensors.split(\",\"),\n            variable_names_blacklist=['global_step']\n        )\n\n        # Dump frozen model\n        with tf.gfile.GFile(output_pb, \"wb\") as f:\n            f.write(output_graph_def.SerializeToString())\n        tf.logging.info(\"%d ops in the final graph.\" % len(output_graph_def.node))\n\n    #return output_graph_def\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model_dir\", type=str, default=\"\",\n                        help=\"Model folder to export\")\n    parser.add_argument(\"--output_tensors\", type=str, default=\"\",\n                        help=\"The name of the output nodes, comma separated.\")\n    parser.add_argument(\"--output_pb\", type=str,\n                        default=\"frozen_model.pb\", help=\"Output pb file\")\n    args = parser.parse_args()\n\n    freeze_graph(args.model_dir, args.output_tensors, args.output_pb)", "body": "@dhingratul I would recommend you to use the Estimator API if possible and export a saved model. It generates a frozen model (.pb file) and it can be easily deployed.\r\n\r\nIf you do need to freeze the model in an old fashion way take a look on the script below I have been using until TensorFlow 1.6. It is a little different from what is provided by TF official repo\r\n\r\n\r\n```python\r\n\r\nimport os\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\n\r\ndef freeze_graph(model_dir, output_tensors, output_pb):\r\n    \"\"\" Freeze graph model into **.pb** file\r\n    \r\n    Extract the sub graph defined by the output nodes and convert all its variables to constants\r\n\r\n    Args:    \r\n        ``model_dir`` (str): directory that contains all checkpoint files (.ckpt, .meta, .info)\r\n        \r\n        ``output_tensors`` (str):  comma separated list of all the output node's names\r\n\r\n        ``output_pb`` (str): output **.pb** frozen graph file      \r\n        \r\n    \"\"\"\r\n    if not tf.gfile.Exists(model_dir):\r\n        raise AssertionError(\r\n            \"Export directory doesn't exists. Please specify an export \"\r\n            \"directory: %s\" % model_dir)\r\n\r\n    if not output_tensors:\r\n        tf.loogin.error(\"You need to supply the name of a node to --output_tensors.\")\r\n        return -1\r\n\r\n    # Retrieve checkpoint fullpath\r\n    checkpoint = tf.train.get_checkpoint_state(model_dir)\r\n    input_checkpoint = checkpoint.model_checkpoint_path\r\n    \r\n    # Clear original devices from graph\r\n    clear_devices = True\r\n\r\n    with tf.Session(graph=tf.Graph()) as sess:\r\n        # Import graph from .meta file\r\n        saver = tf.train.import_meta_graph(\r\n            input_checkpoint + '.meta', clear_devices=clear_devices)\r\n\r\n        input_graph_def = tf.get_default_graph().as_graph_def()\r\n\r\n        # and restore weights\r\n        saver.restore(sess, input_checkpoint)\r\n\r\n        # Convert variables to constants\r\n        output_graph_def = tf.graph_util.convert_variables_to_constants(\r\n            sess,\r\n            input_graph_def,            \r\n            output_tensors.split(\",\"),\r\n            variable_names_blacklist=['global_step']\r\n        )\r\n\r\n        # Dump frozen model\r\n        with tf.gfile.GFile(output_pb, \"wb\") as f:\r\n            f.write(output_graph_def.SerializeToString())\r\n        tf.logging.info(\"%d ops in the final graph.\" % len(output_graph_def.node))\r\n\r\n    #return output_graph_def\r\n\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--model_dir\", type=str, default=\"\",\r\n                        help=\"Model folder to export\")\r\n    parser.add_argument(\"--output_tensors\", type=str, default=\"\",\r\n                        help=\"The name of the output nodes, comma separated.\")\r\n    parser.add_argument(\"--output_pb\", type=str,\r\n                        default=\"frozen_model.pb\", help=\"Output pb file\")\r\n    args = parser.parse_args()\r\n\r\n    freeze_graph(args.model_dir, args.output_tensors, args.output_pb)\r\n```"}