{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/402781503", "html_url": "https://github.com/tensorflow/tensorflow/issues/20564#issuecomment-402781503", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20564", "id": 402781503, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjc4MTUwMw==", "user": {"login": "monk1337", "id": 17107749, "node_id": "MDQ6VXNlcjE3MTA3NzQ5", "avatar_url": "https://avatars2.githubusercontent.com/u/17107749?v=4", "gravatar_id": "", "url": "https://api.github.com/users/monk1337", "html_url": "https://github.com/monk1337", "followers_url": "https://api.github.com/users/monk1337/followers", "following_url": "https://api.github.com/users/monk1337/following{/other_user}", "gists_url": "https://api.github.com/users/monk1337/gists{/gist_id}", "starred_url": "https://api.github.com/users/monk1337/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/monk1337/subscriptions", "organizations_url": "https://api.github.com/users/monk1337/orgs", "repos_url": "https://api.github.com/users/monk1337/repos", "events_url": "https://api.github.com/users/monk1337/events{/privacy}", "received_events_url": "https://api.github.com/users/monk1337/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-05T16:35:23Z", "updated_at": "2018-07-05T16:40:13Z", "author_association": "NONE", "body_html": "<p>After some research i found how it is working</p>\n<p>if hyperparameters are</p>\n<pre><code># num_units =6 (lstm hidden_units )\n# batch_size = 4 \n# max_time = 90 \n# num_dim = 12  (input_size or embedding dim )\n</code></pre>\n<p>Now  input will be</p>\n<p><code>input_size = . Batch_size x max_time x num_dim   #4x90x12 </code><br>\nit will pass through dynamic_rnn  :</p>\n<p><code>lstm_output =dynamic_rnn_function ( input_size )   </code></p>\n<pre><code>which will return  [Batch_size x  max_time x rnn_dim ] and last state [Batch_size x rnn_dim ] \n#4x90x6 and 4x 6\n</code></pre>\n<p>Now what attention is doing , it's creating two matrix<br>\n<code>rnn_output is 4x6  </code><br>\nIn first matrix it is adding rnn_dim three times  so  matrix will be . [4,(6x3) ]</p>\n<p>second matrix it is adding num_dim + num_units and then reduce_max across rnn_dim<br>\n`num_dim + num_units ==&gt;6+12 = 18</p>\n<p>``reduce_max across rnn_dim ==&gt; (num_units x batch_size ) ==&gt; ((6+12) x (6x4) ) . ==&gt; [18,24]<br>\n<code></code>now matmul ( [4,18] , [18,24] ) . ==&gt; [4,24]<br>\n`<br>\nMy confusion is why it is adding rnn_dim three times every time , From where three is coming ?</p>\n<p>working code is here  <a href=\"https://colab.research.google.com/drive/1Ifb3Tg--xxI17CoqtaMEAMpDpWVgiv5A\" rel=\"nofollow\">https://colab.research.google.com/drive/1Ifb3Tg--xxI17CoqtaMEAMpDpWVgiv5A</a></p>", "body_text": "After some research i found how it is working\nif hyperparameters are\n# num_units =6 (lstm hidden_units )\n# batch_size = 4 \n# max_time = 90 \n# num_dim = 12  (input_size or embedding dim )\n\nNow  input will be\ninput_size = . Batch_size x max_time x num_dim   #4x90x12 \nit will pass through dynamic_rnn  :\nlstm_output =dynamic_rnn_function ( input_size )   \nwhich will return  [Batch_size x  max_time x rnn_dim ] and last state [Batch_size x rnn_dim ] \n#4x90x6 and 4x 6\n\nNow what attention is doing , it's creating two matrix\nrnn_output is 4x6  \nIn first matrix it is adding rnn_dim three times  so  matrix will be . [4,(6x3) ]\nsecond matrix it is adding num_dim + num_units and then reduce_max across rnn_dim\n`num_dim + num_units ==>6+12 = 18\n``reduce_max across rnn_dim ==> (num_units x batch_size ) ==> ((6+12) x (6x4) ) . ==> [18,24]\nnow matmul ( [4,18] , [18,24] ) . ==> [4,24]\n`\nMy confusion is why it is adding rnn_dim three times every time , From where three is coming ?\nworking code is here  https://colab.research.google.com/drive/1Ifb3Tg--xxI17CoqtaMEAMpDpWVgiv5A", "body": "After some research i found how it is working \r\n\r\nif hyperparameters are \r\n\r\n```\r\n# num_units =6 (lstm hidden_units )\r\n# batch_size = 4 \r\n# max_time = 90 \r\n# num_dim = 12  (input_size or embedding dim )\r\n```\r\n\r\nNow  input will be \r\n\r\n`input_size = . Batch_size x max_time x num_dim   #4x90x12\r\n`\r\nit will pass through dynamic_rnn  : \r\n\r\n`lstm_output =dynamic_rnn_function ( input_size )  \r\n`\r\n```\r\nwhich will return  [Batch_size x  max_time x rnn_dim ] and last state [Batch_size x rnn_dim ] \r\n#4x90x6 and 4x 6\r\n```\r\n\r\n\r\nNow what attention is doing , it's creating two matrix \r\n`rnn_output is 4x6 \r\n`\r\nIn first matrix it is adding rnn_dim three times  so  matrix will be . [4,(6x3) ]\r\n\r\nsecond matrix it is adding num_dim + num_units and then reduce_max across rnn_dim\r\n`num_dim + num_units ==>6+12 = 18\r\n\r\n\r\n``reduce_max across rnn_dim ==> (num_units x batch_size ) ==> ((6+12) x (6x4) ) . ==> [18,24]\r\n`\r\n`now matmul ( [4,18] , [18,24] ) . ==> [4,24]\r\n`\r\nMy confusion is why it is adding rnn_dim three times every time , From where three is coming ?\r\n\r\nworking code is here  https://colab.research.google.com/drive/1Ifb3Tg--xxI17CoqtaMEAMpDpWVgiv5A\r\n\r\n"}