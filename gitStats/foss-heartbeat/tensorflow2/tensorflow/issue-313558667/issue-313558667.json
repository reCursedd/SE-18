{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18441", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18441/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18441/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18441/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18441", "id": 313558667, "node_id": "MDU6SXNzdWUzMTM1NTg2Njc=", "number": 18441, "title": "Something seems like a bug in r1.8 when building from source code?", "user": {"login": "encore-zhou", "id": 10919711, "node_id": "MDQ6VXNlcjEwOTE5NzEx", "avatar_url": "https://avatars2.githubusercontent.com/u/10919711?v=4", "gravatar_id": "", "url": "https://api.github.com/users/encore-zhou", "html_url": "https://github.com/encore-zhou", "followers_url": "https://api.github.com/users/encore-zhou/followers", "following_url": "https://api.github.com/users/encore-zhou/following{/other_user}", "gists_url": "https://api.github.com/users/encore-zhou/gists{/gist_id}", "starred_url": "https://api.github.com/users/encore-zhou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/encore-zhou/subscriptions", "organizations_url": "https://api.github.com/users/encore-zhou/orgs", "repos_url": "https://api.github.com/users/encore-zhou/repos", "events_url": "https://api.github.com/users/encore-zhou/events{/privacy}", "received_events_url": "https://api.github.com/users/encore-zhou/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2018-04-12T02:53:56Z", "updated_at": "2018-07-25T00:39:13Z", "closed_at": "2018-06-09T03:32:33Z", "author_association": "NONE", "body_html": "<p>I try to build tensorflow with gpu support from source.</p>\n<h1><strong>Basic information:</strong></h1>\n<ul>\n<li>OS Platform and Distribution : ubuntu 14.04</li>\n<li>TensorFlow installed from : source code, branch r1.7</li>\n<li>TensorFlow version : r1.7</li>\n<li>Bazel version : 0.11.1</li>\n<li>CUDA/cuDNN version: 8.0/6.0</li>\n<li>GPU model and memory : Titan X</li>\n<li>Exact command to reproduce:<br>\n<code>bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package </code></li>\n</ul>\n<h1><strong>My configuration:</strong></h1>\n<pre><code>Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]:\njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\nNo Hadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\nNo Amazon S3 File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n\nNo Apache Kafka Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\nNo XLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with GDR support? [y/N]:\nNo GDR support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]:\nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:\nNo OpenCL SYCL support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 8.0\n\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default\n is /usr/local/cuda]:\n\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 6.0\n\nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default\nis /usr/local/cuda]:/home/chongyang/RemoteSensingImage/cuda\n\nDo you wish to build TensorFlow with TensorRT support? [y/N]:\nNo TensorRT support will be enabled for TensorFlow.\n\nPlease specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]:\n\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1,6.1,6.1,6.1]\n\nDo you want to use clang as CUDA compiler? [y/N]:\nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\n\nDo you wish to build TensorFlow with MPI support? [y/N]:\nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\n\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\nNot configuring the WORKSPACE for Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=&lt;&gt;\" to your build command. See tools/bazel.rc for more details.\n        --config=mkl            # Build with MKL support.\n        --config=monolithic     # Config for mostly static monolithic build.\nConfiguration finished\n</code></pre>\n<h1><strong>The error I encountered:</strong></h1>\n<pre><code>ERROR: /home/chongyang/RemoteSensingImage/tensorflow/tensorflow/stream_executor/BUILD:52:1: C++ compilation of\n rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1)\nIn file included from ./tensorflow/stream_executor/platform/port.h:21:0,\n                 from ./tensorflow/stream_executor/device_memory.h:30,\n                 from ./tensorflow/stream_executor/dnn.h:30,\n                 from ./tensorflow/stream_executor/cuda/cuda_dnn.h:22,\n                 from tensorflow/stream_executor/cuda/cuda_dnn.cc:16:\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In constructor 'perftools::gputools::cuda::CudnnRnnDescriptor::Cu\ndnnRnnDescriptor(perftools::gputools::cuda::CUDAExecutor*, cudnnHandle_t, int, int, int, cudnnRNNInputMode_t,\ncudnnDirectionMode_t, cudnnRNNMode_t, cudnnDataType_t, cudnnDataType_t, const perftools::gputools::dnn::Algori\nthmConfig&amp;, float, tensorflow::uint64, perftools::gputools::ScratchAllocator*)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1188:29: error: 'class perftools::gputools::dnn::AlgorithmConfig' has no member named 'is_default'\n     CHECK(algorithm_config_.is_default())\n</code></pre>\n<h1><strong>Something seems like a bug in r1.7?</strong></h1>\n<p>As the error message show, 'class perftools::gputools::dnn::AlgorithmConfig' has no member named 'is_default'. Then I check the code in <code> tensorflow/stream_executor/cuda/cuda_dnn.cc</code> and <code>tensorflow/stream_executor/dnn.h</code></p>\n<pre><code>//tensorflow/stream_executor/dnn.h\nclass AlgorithmConfig {\n public:\n  AlgorithmConfig() {}\n  explicit AlgorithmConfig(AlgorithmDesc algorithm) : algorithm_(algorithm) {}\n  AlgorithmConfig(AlgorithmDesc algorithm, AlgorithmDesc algorithm_no_scratch)\n      : algorithm_(algorithm), algorithm_no_scratch_(algorithm_no_scratch) {}\n  AlgorithmDesc algorithm() const { return algorithm_; }\n  void set_algorithm(AlgorithmDesc val) { algorithm_ = val; }\n  AlgorithmDesc algorithm_no_scratch() const { return algorithm_no_scratch_; }\n  void set_algorithm_no_scratch(AlgorithmDesc val) {\n    algorithm_no_scratch_ = val;\n  }\n  bool operator==(const AlgorithmConfig&amp; other) const {\n    return this-&gt;algorithm_ == other.algorithm_ &amp;&amp;\n           this-&gt;algorithm_no_scratch_ == other.algorithm_no_scratch_;\n  }\n  bool operator!=(const AlgorithmConfig&amp; other) const {\n    return !(*this == other);\n  }\n  string ToString() const;\n\n private:\n  AlgorithmDesc algorithm_;\n  AlgorithmDesc algorithm_no_scratch_;\n};\n</code></pre>\n<pre><code>//tensorflow/stream_executor/cuda/cuda_dnn.cc\nCudnnRnnDescriptor(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,\n                     int num_layers, int hidden_size, int input_size,\n                     cudnnRNNInputMode_t input_mode,\n                     cudnnDirectionMode_t direction_mode,\n                     cudnnRNNMode_t rnn_mode, cudnnDataType_t data_type,\n                     cudnnDataType_t compute_type,\n                     const dnn::AlgorithmConfig&amp; algorithm_config,\n                     float dropout, uint64 seed,\n                     ScratchAllocator* state_allocator)\n      : parent_(parent),\n        rnn_desc_(nullptr),\n        num_layers_(num_layers),\n        hidden_size_(hidden_size),\n        input_size_(input_size),\n        input_mode_(input_mode),\n        direction_mode_(direction_mode),\n        rnn_mode_(rnn_mode),\n        data_type_(data_type),\n        compute_type_(compute_type),\n       ///////////////////////////////////////////////////\n       ///// //algorithm_config_ is defined here!/////\n       ///////////////////////////////////////////////////\n        algorithm_config_(algorithm_config) {\n....\n       /////////////////////////////////////////////////////////////////////////////\n       //algorithm_config_ call function is_default(), which occurs the bug//\n        ////////////////////////////////////////////////////////////////////////////\n       CHECK(algorithm_config_.is_default())\n            &lt;&lt; \"Non-default algorithm not supported for CUDA version &lt; 6.0\";\n</code></pre>\n<p><strong>Actually, algorithm_config_ has no member named <code>is_default()</code>. Only <code>class AlgorithmDesc</code> has this function.</strong></p>\n<p>Thanks for helping me to solve this problem and correct me!</p>", "body_text": "I try to build tensorflow with gpu support from source.\nBasic information:\n\nOS Platform and Distribution : ubuntu 14.04\nTensorFlow installed from : source code, branch r1.7\nTensorFlow version : r1.7\nBazel version : 0.11.1\nCUDA/cuDNN version: 8.0/6.0\nGPU model and memory : Titan X\nExact command to reproduce:\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package \n\nMy configuration:\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]:\njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\nNo Hadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\nNo Amazon S3 File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n\nNo Apache Kafka Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\nNo XLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with GDR support? [y/N]:\nNo GDR support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]:\nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:\nNo OpenCL SYCL support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 8.0\n\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default\n is /usr/local/cuda]:\n\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 6.0\n\nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default\nis /usr/local/cuda]:/home/chongyang/RemoteSensingImage/cuda\n\nDo you wish to build TensorFlow with TensorRT support? [y/N]:\nNo TensorRT support will be enabled for TensorFlow.\n\nPlease specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]:\n\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1,6.1,6.1,6.1]\n\nDo you want to use clang as CUDA compiler? [y/N]:\nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\n\nDo you wish to build TensorFlow with MPI support? [y/N]:\nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\n\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\nNot configuring the WORKSPACE for Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\n        --config=mkl            # Build with MKL support.\n        --config=monolithic     # Config for mostly static monolithic build.\nConfiguration finished\n\nThe error I encountered:\nERROR: /home/chongyang/RemoteSensingImage/tensorflow/tensorflow/stream_executor/BUILD:52:1: C++ compilation of\n rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1)\nIn file included from ./tensorflow/stream_executor/platform/port.h:21:0,\n                 from ./tensorflow/stream_executor/device_memory.h:30,\n                 from ./tensorflow/stream_executor/dnn.h:30,\n                 from ./tensorflow/stream_executor/cuda/cuda_dnn.h:22,\n                 from tensorflow/stream_executor/cuda/cuda_dnn.cc:16:\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In constructor 'perftools::gputools::cuda::CudnnRnnDescriptor::Cu\ndnnRnnDescriptor(perftools::gputools::cuda::CUDAExecutor*, cudnnHandle_t, int, int, int, cudnnRNNInputMode_t,\ncudnnDirectionMode_t, cudnnRNNMode_t, cudnnDataType_t, cudnnDataType_t, const perftools::gputools::dnn::Algori\nthmConfig&, float, tensorflow::uint64, perftools::gputools::ScratchAllocator*)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1188:29: error: 'class perftools::gputools::dnn::AlgorithmConfig' has no member named 'is_default'\n     CHECK(algorithm_config_.is_default())\n\nSomething seems like a bug in r1.7?\nAs the error message show, 'class perftools::gputools::dnn::AlgorithmConfig' has no member named 'is_default'. Then I check the code in  tensorflow/stream_executor/cuda/cuda_dnn.cc and tensorflow/stream_executor/dnn.h\n//tensorflow/stream_executor/dnn.h\nclass AlgorithmConfig {\n public:\n  AlgorithmConfig() {}\n  explicit AlgorithmConfig(AlgorithmDesc algorithm) : algorithm_(algorithm) {}\n  AlgorithmConfig(AlgorithmDesc algorithm, AlgorithmDesc algorithm_no_scratch)\n      : algorithm_(algorithm), algorithm_no_scratch_(algorithm_no_scratch) {}\n  AlgorithmDesc algorithm() const { return algorithm_; }\n  void set_algorithm(AlgorithmDesc val) { algorithm_ = val; }\n  AlgorithmDesc algorithm_no_scratch() const { return algorithm_no_scratch_; }\n  void set_algorithm_no_scratch(AlgorithmDesc val) {\n    algorithm_no_scratch_ = val;\n  }\n  bool operator==(const AlgorithmConfig& other) const {\n    return this->algorithm_ == other.algorithm_ &&\n           this->algorithm_no_scratch_ == other.algorithm_no_scratch_;\n  }\n  bool operator!=(const AlgorithmConfig& other) const {\n    return !(*this == other);\n  }\n  string ToString() const;\n\n private:\n  AlgorithmDesc algorithm_;\n  AlgorithmDesc algorithm_no_scratch_;\n};\n\n//tensorflow/stream_executor/cuda/cuda_dnn.cc\nCudnnRnnDescriptor(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,\n                     int num_layers, int hidden_size, int input_size,\n                     cudnnRNNInputMode_t input_mode,\n                     cudnnDirectionMode_t direction_mode,\n                     cudnnRNNMode_t rnn_mode, cudnnDataType_t data_type,\n                     cudnnDataType_t compute_type,\n                     const dnn::AlgorithmConfig& algorithm_config,\n                     float dropout, uint64 seed,\n                     ScratchAllocator* state_allocator)\n      : parent_(parent),\n        rnn_desc_(nullptr),\n        num_layers_(num_layers),\n        hidden_size_(hidden_size),\n        input_size_(input_size),\n        input_mode_(input_mode),\n        direction_mode_(direction_mode),\n        rnn_mode_(rnn_mode),\n        data_type_(data_type),\n        compute_type_(compute_type),\n       ///////////////////////////////////////////////////\n       ///// //algorithm_config_ is defined here!/////\n       ///////////////////////////////////////////////////\n        algorithm_config_(algorithm_config) {\n....\n       /////////////////////////////////////////////////////////////////////////////\n       //algorithm_config_ call function is_default(), which occurs the bug//\n        ////////////////////////////////////////////////////////////////////////////\n       CHECK(algorithm_config_.is_default())\n            << \"Non-default algorithm not supported for CUDA version < 6.0\";\n\nActually, algorithm_config_ has no member named is_default(). Only class AlgorithmDesc has this function.\nThanks for helping me to solve this problem and correct me!", "body": "I try to build tensorflow with gpu support from source.\r\n\r\n# **Basic information:**\r\n\r\n- OS Platform and Distribution : ubuntu 14.04\r\n- TensorFlow installed from : source code, branch r1.7\r\n- TensorFlow version : r1.7\r\n- Bazel version : 0.11.1\r\n- CUDA/cuDNN version: 8.0/6.0\r\n- GPU model and memory : Titan X\r\n- Exact command to reproduce:\r\n    `bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package `\r\n\r\n# **My configuration:**\r\n```\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]:\r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\r\nNo Hadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\r\nNo Amazon S3 File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n\r\nNo Apache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]:\r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]:\r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 8.0\r\n\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default\r\n is /usr/local/cuda]:\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 6.0\r\n\r\nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default\r\nis /usr/local/cuda]:/home/chongyang/RemoteSensingImage/cuda\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]:\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]:\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1,6.1,6.1,6.1]\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]:\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]:\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\nConfiguration finished\r\n```\r\n# **The error I encountered:**\r\n```\r\nERROR: /home/chongyang/RemoteSensingImage/tensorflow/tensorflow/stream_executor/BUILD:52:1: C++ compilation of\r\n rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1)\r\nIn file included from ./tensorflow/stream_executor/platform/port.h:21:0,\r\n                 from ./tensorflow/stream_executor/device_memory.h:30,\r\n                 from ./tensorflow/stream_executor/dnn.h:30,\r\n                 from ./tensorflow/stream_executor/cuda/cuda_dnn.h:22,\r\n                 from tensorflow/stream_executor/cuda/cuda_dnn.cc:16:\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In constructor 'perftools::gputools::cuda::CudnnRnnDescriptor::Cu\r\ndnnRnnDescriptor(perftools::gputools::cuda::CUDAExecutor*, cudnnHandle_t, int, int, int, cudnnRNNInputMode_t,\r\ncudnnDirectionMode_t, cudnnRNNMode_t, cudnnDataType_t, cudnnDataType_t, const perftools::gputools::dnn::Algori\r\nthmConfig&, float, tensorflow::uint64, perftools::gputools::ScratchAllocator*)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1188:29: error: 'class perftools::gputools::dnn::AlgorithmConfig' has no member named 'is_default'\r\n     CHECK(algorithm_config_.is_default())\r\n```\r\n\r\n# **Something seems like a bug in r1.7?**\r\nAs the error message show, 'class perftools::gputools::dnn::AlgorithmConfig' has no member named 'is_default'. Then I check the code in ` tensorflow/stream_executor/cuda/cuda_dnn.cc` and `tensorflow/stream_executor/dnn.h`\r\n\r\n```\r\n//tensorflow/stream_executor/dnn.h\r\nclass AlgorithmConfig {\r\n public:\r\n  AlgorithmConfig() {}\r\n  explicit AlgorithmConfig(AlgorithmDesc algorithm) : algorithm_(algorithm) {}\r\n  AlgorithmConfig(AlgorithmDesc algorithm, AlgorithmDesc algorithm_no_scratch)\r\n      : algorithm_(algorithm), algorithm_no_scratch_(algorithm_no_scratch) {}\r\n  AlgorithmDesc algorithm() const { return algorithm_; }\r\n  void set_algorithm(AlgorithmDesc val) { algorithm_ = val; }\r\n  AlgorithmDesc algorithm_no_scratch() const { return algorithm_no_scratch_; }\r\n  void set_algorithm_no_scratch(AlgorithmDesc val) {\r\n    algorithm_no_scratch_ = val;\r\n  }\r\n  bool operator==(const AlgorithmConfig& other) const {\r\n    return this->algorithm_ == other.algorithm_ &&\r\n           this->algorithm_no_scratch_ == other.algorithm_no_scratch_;\r\n  }\r\n  bool operator!=(const AlgorithmConfig& other) const {\r\n    return !(*this == other);\r\n  }\r\n  string ToString() const;\r\n\r\n private:\r\n  AlgorithmDesc algorithm_;\r\n  AlgorithmDesc algorithm_no_scratch_;\r\n};\r\n```\r\n```\r\n//tensorflow/stream_executor/cuda/cuda_dnn.cc\r\nCudnnRnnDescriptor(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,\r\n                     int num_layers, int hidden_size, int input_size,\r\n                     cudnnRNNInputMode_t input_mode,\r\n                     cudnnDirectionMode_t direction_mode,\r\n                     cudnnRNNMode_t rnn_mode, cudnnDataType_t data_type,\r\n                     cudnnDataType_t compute_type,\r\n                     const dnn::AlgorithmConfig& algorithm_config,\r\n                     float dropout, uint64 seed,\r\n                     ScratchAllocator* state_allocator)\r\n      : parent_(parent),\r\n        rnn_desc_(nullptr),\r\n        num_layers_(num_layers),\r\n        hidden_size_(hidden_size),\r\n        input_size_(input_size),\r\n        input_mode_(input_mode),\r\n        direction_mode_(direction_mode),\r\n        rnn_mode_(rnn_mode),\r\n        data_type_(data_type),\r\n        compute_type_(compute_type),\r\n       ///////////////////////////////////////////////////\r\n       ///// //algorithm_config_ is defined here!/////\r\n       ///////////////////////////////////////////////////\r\n        algorithm_config_(algorithm_config) {\r\n....\r\n       /////////////////////////////////////////////////////////////////////////////\r\n       //algorithm_config_ call function is_default(), which occurs the bug//\r\n        ////////////////////////////////////////////////////////////////////////////\r\n       CHECK(algorithm_config_.is_default())\r\n            << \"Non-default algorithm not supported for CUDA version < 6.0\";\r\n```\r\n\r\n**Actually, algorithm_config_ has no member named `is_default()`. Only `class AlgorithmDesc` has this function.**\r\n\r\nThanks for helping me to solve this problem and correct me!"}