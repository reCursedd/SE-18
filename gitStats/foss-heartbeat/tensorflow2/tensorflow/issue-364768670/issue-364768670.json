{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22589", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22589/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22589/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22589/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22589", "id": 364768670, "node_id": "MDU6SXNzdWUzNjQ3Njg2NzA=", "number": 22589, "title": "Error when re-initializing the model", "user": {"login": "twolodzko", "id": 3750140, "node_id": "MDQ6VXNlcjM3NTAxNDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/3750140?v=4", "gravatar_id": "", "url": "https://api.github.com/users/twolodzko", "html_url": "https://github.com/twolodzko", "followers_url": "https://api.github.com/users/twolodzko/followers", "following_url": "https://api.github.com/users/twolodzko/following{/other_user}", "gists_url": "https://api.github.com/users/twolodzko/gists{/gist_id}", "starred_url": "https://api.github.com/users/twolodzko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/twolodzko/subscriptions", "organizations_url": "https://api.github.com/users/twolodzko/orgs", "repos_url": "https://api.github.com/users/twolodzko/repos", "events_url": "https://api.github.com/users/twolodzko/events{/privacy}", "received_events_url": "https://api.github.com/users/twolodzko/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1105108936, "node_id": "MDU6TGFiZWwxMTA1MTA4OTM2", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:model", "name": "comp:model", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-09-28T07:14:48Z", "updated_at": "2018-11-02T01:02:30Z", "closed_at": "2018-11-01T18:41:19Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: No</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: N/A</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.11.0-rc2</li>\n<li><strong>Python version</strong>: 3</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<p>Used Google Colab.</p>\n<h3>Describe the problem</h3>\n<p>I defined a model in terms of CuDNNLSTM, then re-defined it again in terms of LSTM. The model crushed with error message suggesting that it was looking for the CUDA optimized function no matter that the second model used standard LSTM.</p>\n<p>Below I post a reproducible code and a <del><a href=\"https://colab.research.google.com/drive/1fhsUfxAdtG2lTTYndhcr8Y9924IPYkiJ\" rel=\"nofollow\">Colab link</a></del> <a href=\"https://colab.research.google.com/drive/1fhsUfxAdtG2lTTYndhcr8Y9924IPYkiJ\" rel=\"nofollow\">Colab link</a>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n\n<span class=\"pl-k\">from</span> keras.preprocessing <span class=\"pl-k\">import</span> sequence\n<span class=\"pl-k\">from</span> keras.models <span class=\"pl-k\">import</span> Sequential\n<span class=\"pl-k\">from</span> keras.layers <span class=\"pl-k\">import</span> Dense, Embedding\n<span class=\"pl-k\">from</span> keras.layers <span class=\"pl-k\">import</span> <span class=\"pl-c1\">LSTM</span>, CuDNNLSTM\n<span class=\"pl-k\">from</span> keras.datasets <span class=\"pl-k\">import</span> imdb\n\nmax_features <span class=\"pl-k\">=</span> <span class=\"pl-c1\">20000</span>\nmaxlen <span class=\"pl-k\">=</span> <span class=\"pl-c1\">80</span>\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">32</span>\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Loading data...<span class=\"pl-pds\">'</span></span>)\n(x_train, y_train), (x_test, y_test) <span class=\"pl-k\">=</span> imdb.load_data(<span class=\"pl-v\">num_words</span><span class=\"pl-k\">=</span>max_features)\nx_train <span class=\"pl-k\">=</span> sequence.pad_sequences(x_train, <span class=\"pl-v\">maxlen</span><span class=\"pl-k\">=</span>maxlen)\nx_test <span class=\"pl-k\">=</span> sequence.pad_sequences(x_test, <span class=\"pl-v\">maxlen</span><span class=\"pl-k\">=</span>maxlen)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>## ========== IMPORTANT STUFF STARTS HERE ================</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> define the model</span>\n\nmodel <span class=\"pl-k\">=</span> Sequential()\nmodel.add(Embedding(max_features, <span class=\"pl-c1\">128</span>))\nmodel.add(CuDNNLSTM(<span class=\"pl-c1\">128</span>))\nmodel.add(Dense(<span class=\"pl-c1\">1</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>sigmoid<span class=\"pl-pds\">'</span></span>))\nmodel.compile(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>binary_crossentropy<span class=\"pl-pds\">'</span></span>,\n              <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>adam<span class=\"pl-pds\">'</span></span>,\n              <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>])\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> it will crush because not using GPUs, so re-define it in terms of standard LSTM:</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ===============================================================</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>          The below part starts in a DIFFERENT notebook cell</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ===============================================================</span>\n\nmodel <span class=\"pl-k\">=</span> Sequential()\nmodel.add(Embedding(max_features, <span class=\"pl-c1\">128</span>))\nmodel.add(LSTM(<span class=\"pl-c1\">128</span>))\nmodel.add(Dense(<span class=\"pl-c1\">1</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>sigmoid<span class=\"pl-pds\">'</span></span>))\nmodel.compile(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>binary_crossentropy<span class=\"pl-pds\">'</span></span>,\n              <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>adam<span class=\"pl-pds\">'</span></span>,\n              <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>])\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> it crushes again, with the same error</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>## ================ END HERE ======================</span>\n\nmodel.fit(x_train, y_train,\n          <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size,\n          <span class=\"pl-v\">epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">15</span>,\n          <span class=\"pl-v\">validation_data</span><span class=\"pl-k\">=</span>(x_test, y_test))\nscore, acc <span class=\"pl-k\">=</span> model.evaluate(x_test, y_test,\n                            <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size)</pre></div>\n<h3>Source code / logs</h3>\n<p>I get the following error on the very first iteration:</p>\n<pre><code>---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1291     try:\n-&gt; 1292       return fn(*args)\n   1293     except errors.OpError as e:\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\n   1274       # Ensure any changes to the graph are reflected in the runtime.\n-&gt; 1275       self._extend_graph()\n   1276       return self._call_tf_sessionrun(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _extend_graph(self)\n   1311     with self._graph._session_run_lock():  # pylint: disable=protected-access\n-&gt; 1312       tf_session.ExtendSession(self._session)\n   1313 \n\nInvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  &lt;no registered kernels&gt;\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n&lt;ipython-input-1-60cbd0c8ff19&gt; in &lt;module&gt;()\n     53           batch_size=batch_size,\n     54           epochs=15,\n---&gt; 55           validation_data=(x_test, y_test))\n     56 score, acc = model.evaluate(x_test, y_test,\n     57                             batch_size=batch_size)\n\n/usr/local/lib/python3.6/dist-packages/keras/models.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1000                               initial_epoch=initial_epoch,\n   1001                               steps_per_epoch=steps_per_epoch,\n-&gt; 1002                               validation_steps=validation_steps)\n   1003 \n   1004     def evaluate(self, x=None, y=None,\n\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1703                               initial_epoch=initial_epoch,\n   1704                               steps_per_epoch=steps_per_epoch,\n-&gt; 1705                               validation_steps=validation_steps)\n   1706 \n   1707     def evaluate(self, x=None, y=None,\n\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n   1234                         ins_batch[i] = ins_batch[i].toarray()\n   1235 \n-&gt; 1236                     outs = f(ins_batch)\n   1237                     if not isinstance(outs, list):\n   1238                         outs = [outs]\n\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in __call__(self, inputs)\n   2478             feed_dict[tensor] = value\n   2479         fetches = self.outputs + [self.updates_op] + self.fetches\n-&gt; 2480         session = get_session()\n   2481         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n   2482                               **self.session_kwargs)\n\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in get_session()\n    191                 # not already marked as initialized.\n    192                 is_initialized = session.run(\n--&gt; 193                     [tf.is_variable_initialized(v) for v in candidate_vars])\n    194                 uninitialized_vars = []\n    195                 for flag, v in zip(is_initialized, candidate_vars):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    885     try:\n    886       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 887                          run_metadata_ptr)\n    888       if run_metadata:\n    889         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1108     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1109       results = self._do_run(handle, final_targets, final_fetches,\n-&gt; 1110                              feed_dict_tensor, options, run_metadata)\n   1111     else:\n   1112       results = []\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1284     if handle is None:\n   1285       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-&gt; 1286                            run_metadata)\n   1287     else:\n   1288       return self._do_call(_prun_fn, handle, feeds, fetches)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1306           self._config.experimental.client_handles_error_formatting):\n   1307         message = error_interpolation.interpolate(message, self._graph)\n-&gt; 1308       raise type(e)(node_def, op, message)\n   1309 \n   1310   def _extend_graph(self):\n\nInvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  &lt;no registered kernels&gt;\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]\n\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in &lt;module&gt;\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;ipython-input-1-60cbd0c8ff19&gt;\", line 32, in &lt;module&gt;\n    model.add(CuDNNLSTM(128))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 522, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 500, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py\", line 510, in _process_batch\n    is_training=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1544, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1435, in __call__\n    seed=self._seed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 922, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 116, in cudnn_rnn\n    is_training=is_training, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  &lt;no registered kernels&gt;\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): N/A\nTensorFlow version (use command below): 1.11.0-rc2\nPython version: 3\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A\n\nUsed Google Colab.\nDescribe the problem\nI defined a model in terms of CuDNNLSTM, then re-defined it again in terms of LSTM. The model crushed with error message suggesting that it was looking for the CUDA optimized function no matter that the second model used standard LSTM.\nBelow I post a reproducible code and a Colab link Colab link:\nfrom __future__ import print_function\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding\nfrom keras.layers import LSTM, CuDNNLSTM\nfrom keras.datasets import imdb\n\nmax_features = 20000\nmaxlen = 80\nbatch_size = 32\n\nprint('Loading data...')\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n\n### ========== IMPORTANT STUFF STARTS HERE ================\n\n# define the model\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128))\nmodel.add(CuDNNLSTM(128))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# it will crush because not using GPUs, so re-define it in terms of standard LSTM:\n\n# ===============================================================\n#          The below part starts in a DIFFERENT notebook cell\n# ===============================================================\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128))\nmodel.add(LSTM(128))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# it crushes again, with the same error\n\n### ================ END HERE ======================\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=15,\n          validation_data=(x_test, y_test))\nscore, acc = model.evaluate(x_test, y_test,\n                            batch_size=batch_size)\nSource code / logs\nI get the following error on the very first iteration:\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1291     try:\n-> 1292       return fn(*args)\n   1293     except errors.OpError as e:\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\n   1274       # Ensure any changes to the graph are reflected in the runtime.\n-> 1275       self._extend_graph()\n   1276       return self._call_tf_sessionrun(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _extend_graph(self)\n   1311     with self._graph._session_run_lock():  # pylint: disable=protected-access\n-> 1312       tf_session.ExtendSession(self._session)\n   1313 \n\nInvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-1-60cbd0c8ff19> in <module>()\n     53           batch_size=batch_size,\n     54           epochs=15,\n---> 55           validation_data=(x_test, y_test))\n     56 score, acc = model.evaluate(x_test, y_test,\n     57                             batch_size=batch_size)\n\n/usr/local/lib/python3.6/dist-packages/keras/models.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1000                               initial_epoch=initial_epoch,\n   1001                               steps_per_epoch=steps_per_epoch,\n-> 1002                               validation_steps=validation_steps)\n   1003 \n   1004     def evaluate(self, x=None, y=None,\n\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1703                               initial_epoch=initial_epoch,\n   1704                               steps_per_epoch=steps_per_epoch,\n-> 1705                               validation_steps=validation_steps)\n   1706 \n   1707     def evaluate(self, x=None, y=None,\n\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n   1234                         ins_batch[i] = ins_batch[i].toarray()\n   1235 \n-> 1236                     outs = f(ins_batch)\n   1237                     if not isinstance(outs, list):\n   1238                         outs = [outs]\n\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in __call__(self, inputs)\n   2478             feed_dict[tensor] = value\n   2479         fetches = self.outputs + [self.updates_op] + self.fetches\n-> 2480         session = get_session()\n   2481         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n   2482                               **self.session_kwargs)\n\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in get_session()\n    191                 # not already marked as initialized.\n    192                 is_initialized = session.run(\n--> 193                     [tf.is_variable_initialized(v) for v in candidate_vars])\n    194                 uninitialized_vars = []\n    195                 for flag, v in zip(is_initialized, candidate_vars):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    885     try:\n    886       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 887                          run_metadata_ptr)\n    888       if run_metadata:\n    889         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1108     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1109       results = self._do_run(handle, final_targets, final_fetches,\n-> 1110                              feed_dict_tensor, options, run_metadata)\n   1111     else:\n   1112       results = []\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1284     if handle is None:\n   1285       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-> 1286                            run_metadata)\n   1287     else:\n   1288       return self._do_call(_prun_fn, handle, feeds, fetches)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1306           self._config.experimental.client_handles_error_formatting):\n   1307         message = error_interpolation.interpolate(message, self._graph)\n-> 1308       raise type(e)(node_def, op, message)\n   1309 \n   1310   def _extend_graph(self):\n\nInvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]\n\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-60cbd0c8ff19>\", line 32, in <module>\n    model.add(CuDNNLSTM(128))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 522, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 500, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py\", line 510, in _process_batch\n    is_training=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1544, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1435, in __call__\n    seed=self._seed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 922, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 116, in cudnn_rnn\n    is_training=is_training, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: 1.11.0-rc2\r\n- **Python version**: 3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\nUsed Google Colab.\r\n\r\n### Describe the problem\r\nI defined a model in terms of CuDNNLSTM, then re-defined it again in terms of LSTM. The model crushed with error message suggesting that it was looking for the CUDA optimized function no matter that the second model used standard LSTM.\r\n\r\nBelow I post a reproducible code and a ~~[Colab link](https://colab.research.google.com/drive/1fhsUfxAdtG2lTTYndhcr8Y9924IPYkiJ)~~ [Colab link](https://colab.research.google.com/drive/1fhsUfxAdtG2lTTYndhcr8Y9924IPYkiJ):\r\n\r\n```python\r\nfrom __future__ import print_function\r\n\r\nfrom keras.preprocessing import sequence\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Embedding\r\nfrom keras.layers import LSTM, CuDNNLSTM\r\nfrom keras.datasets import imdb\r\n\r\nmax_features = 20000\r\nmaxlen = 80\r\nbatch_size = 32\r\n\r\nprint('Loading data...')\r\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\r\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\r\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\r\n\r\n### ========== IMPORTANT STUFF STARTS HERE ================\r\n\r\n# define the model\r\n\r\nmodel = Sequential()\r\nmodel.add(Embedding(max_features, 128))\r\nmodel.add(CuDNNLSTM(128))\r\nmodel.add(Dense(1, activation='sigmoid'))\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n\r\n# it will crush because not using GPUs, so re-define it in terms of standard LSTM:\r\n\r\n# ===============================================================\r\n#          The below part starts in a DIFFERENT notebook cell\r\n# ===============================================================\r\n\r\nmodel = Sequential()\r\nmodel.add(Embedding(max_features, 128))\r\nmodel.add(LSTM(128))\r\nmodel.add(Dense(1, activation='sigmoid'))\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n\r\n# it crushes again, with the same error\r\n\r\n### ================ END HERE ======================\r\n\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          epochs=15,\r\n          validation_data=(x_test, y_test))\r\nscore, acc = model.evaluate(x_test, y_test,\r\n                            batch_size=batch_size)\r\n```\r\n\r\n### Source code / logs\r\n\r\nI get the following error on the very first iteration:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1291     try:\r\n-> 1292       return fn(*args)\r\n   1293     except errors.OpError as e:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1274       # Ensure any changes to the graph are reflected in the runtime.\r\n-> 1275       self._extend_graph()\r\n   1276       return self._call_tf_sessionrun(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _extend_graph(self)\r\n   1311     with self._graph._session_run_lock():  # pylint: disable=protected-access\r\n-> 1312       tf_session.ExtendSession(self._session)\r\n   1313 \r\n\r\nInvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-1-60cbd0c8ff19> in <module>()\r\n     53           batch_size=batch_size,\r\n     54           epochs=15,\r\n---> 55           validation_data=(x_test, y_test))\r\n     56 score, acc = model.evaluate(x_test, y_test,\r\n     57                             batch_size=batch_size)\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/models.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1000                               initial_epoch=initial_epoch,\r\n   1001                               steps_per_epoch=steps_per_epoch,\r\n-> 1002                               validation_steps=validation_steps)\r\n   1003 \r\n   1004     def evaluate(self, x=None, y=None,\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1703                               initial_epoch=initial_epoch,\r\n   1704                               steps_per_epoch=steps_per_epoch,\r\n-> 1705                               validation_steps=validation_steps)\r\n   1706 \r\n   1707     def evaluate(self, x=None, y=None,\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\r\n   1234                         ins_batch[i] = ins_batch[i].toarray()\r\n   1235 \r\n-> 1236                     outs = f(ins_batch)\r\n   1237                     if not isinstance(outs, list):\r\n   1238                         outs = [outs]\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in __call__(self, inputs)\r\n   2478             feed_dict[tensor] = value\r\n   2479         fetches = self.outputs + [self.updates_op] + self.fetches\r\n-> 2480         session = get_session()\r\n   2481         updated = session.run(fetches=fetches, feed_dict=feed_dict,\r\n   2482                               **self.session_kwargs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in get_session()\r\n    191                 # not already marked as initialized.\r\n    192                 is_initialized = session.run(\r\n--> 193                     [tf.is_variable_initialized(v) for v in candidate_vars])\r\n    194                 uninitialized_vars = []\r\n    195                 for flag, v in zip(is_initialized, candidate_vars):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    885     try:\r\n    886       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 887                          run_metadata_ptr)\r\n    888       if run_metadata:\r\n    889         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1108     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1109       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1110                              feed_dict_tensor, options, run_metadata)\r\n   1111     else:\r\n   1112       results = []\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1284     if handle is None:\r\n   1285       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1286                            run_metadata)\r\n   1287     else:\r\n   1288       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1306           self._config.experimental.client_handles_error_formatting):\r\n   1307         message = error_interpolation.interpolate(message, self._graph)\r\n-> 1308       raise type(e)(node_def, op, message)\r\n   1309 \r\n   1310   def _extend_graph(self):\r\n\r\nInvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]\r\n\r\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-60cbd0c8ff19>\", line 32, in <module>\r\n    model.add(CuDNNLSTM(128))\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 522, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 500, in __call__\r\n    return super(RNN, self).__call__(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\r\n    output = self.call(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\r\n    output, states = self._process_batch(inputs, initial_state)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py\", line 510, in _process_batch\r\n    is_training=True)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1544, in __call__\r\n    input_data, input_h, input_c, params, is_training=is_training)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1435, in __call__\r\n    seed=self._seed)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 922, in _cudnn_rnn\r\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 116, in cudnn_rnn\r\n    is_training=is_training, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[{{node cu_dnnlstm_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](cu_dnnlstm_1/transpose, cu_dnnlstm_1/ExpandDims_1, cu_dnnlstm_1/ExpandDims_2, cu_dnnlstm_1/concat_1)]]\r\n```\r\n"}