{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21491", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21491/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21491/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21491/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21491", "id": 348904395, "node_id": "MDU6SXNzdWUzNDg5MDQzOTU=", "number": 21491, "title": "Consider automatic casting rules for promoting dtypes", "user": {"login": "shoyer", "id": 1217238, "node_id": "MDQ6VXNlcjEyMTcyMzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoyer", "html_url": "https://github.com/shoyer", "followers_url": "https://api.github.com/users/shoyer/followers", "following_url": "https://api.github.com/users/shoyer/following{/other_user}", "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions", "organizations_url": "https://api.github.com/users/shoyer/orgs", "repos_url": "https://api.github.com/users/shoyer/repos", "events_url": "https://api.github.com/users/shoyer/events{/privacy}", "received_events_url": "https://api.github.com/users/shoyer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-08-08T21:48:22Z", "updated_at": "2018-11-15T19:03:40Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: NA</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: NA</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: NA</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: NA</li>\n<li><strong>TensorFlow version (use command below)</strong>: unknown 1.10.0-rc1</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>: NA</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>Arithmetic between objects with different dtypes only works with Python scalars, not Tensors:</p>\n<pre><code># this works\n&gt;&gt;&gt; tf.constant(1.0) * 2\n&lt;tf.Tensor: id=4, shape=(), dtype=float32, numpy=2.0&gt;\n\n# this doesn't\n&gt;&gt;&gt; tf.constant(1.0) * tf.constant(2)\nInvalidArgumentError: cannot compute Mul as input #0 was expected to be a int32 tensor but is a float tensor [Op:Mul] name: mul/\n</code></pre>\n<h3>Describe the problem</h3>\n<p>NumPy has well defined <a href=\"https://docs.scipy.org/doc/numpy/reference/ufuncs.html#casting-rules\" rel=\"nofollow\">casting rules</a> for converting between dtypes. If an operation cannot be performed natively on the given dtypes (e.g., <code>np.add</code> between float32 and float64), then one or more of the inputs will be promoted to a higher data-type, e.g., float32 -&gt; float64.</p>\n<p>This is highly convenient, and remains one of the major annoyances when porting NumPy code to TensorFlow. TensorFlow code ends up littered with calls to <code>tf.cast()</code>. It's particularly annoying for any use-cases that require types other than float32, e.g., models that use complex numbers, because you can't simply cast every argument to float32.</p>\n<p>An argument for not implementing this would be that TensorFlow strives to be more explicit than NumPy, and this could lead to unintended performance degradation. But I'm struggling to imagine cases where this would actually be the case. It's also easy to avoid by using explicit casting on everything, which could still be utilized by users who concerned about it. There are lots of areas where NumPy got things wrong by being undisciplined (e.g., indexing rules) but I have not heard any complaints about this one.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NA\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): NA\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\nTensorFlow installed from (source or binary): NA\nTensorFlow version (use command below): unknown 1.10.0-rc1\nPython version: 3.6\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source): NA\nCUDA/cuDNN version: NA\nGPU model and memory: NA\nExact command to reproduce:\n\nArithmetic between objects with different dtypes only works with Python scalars, not Tensors:\n# this works\n>>> tf.constant(1.0) * 2\n<tf.Tensor: id=4, shape=(), dtype=float32, numpy=2.0>\n\n# this doesn't\n>>> tf.constant(1.0) * tf.constant(2)\nInvalidArgumentError: cannot compute Mul as input #0 was expected to be a int32 tensor but is a float tensor [Op:Mul] name: mul/\n\nDescribe the problem\nNumPy has well defined casting rules for converting between dtypes. If an operation cannot be performed natively on the given dtypes (e.g., np.add between float32 and float64), then one or more of the inputs will be promoted to a higher data-type, e.g., float32 -> float64.\nThis is highly convenient, and remains one of the major annoyances when porting NumPy code to TensorFlow. TensorFlow code ends up littered with calls to tf.cast(). It's particularly annoying for any use-cases that require types other than float32, e.g., models that use complex numbers, because you can't simply cast every argument to float32.\nAn argument for not implementing this would be that TensorFlow strives to be more explicit than NumPy, and this could lead to unintended performance degradation. But I'm struggling to imagine cases where this would actually be the case. It's also easy to avoid by using explicit casting on everything, which could still be utilized by users who concerned about it. There are lots of areas where NumPy got things wrong by being undisciplined (e.g., indexing rules) but I have not heard any complaints about this one.", "body": "### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NA\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: NA\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: NA\r\n- **TensorFlow version (use command below)**: unknown 1.10.0-rc1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**:\r\n\r\nArithmetic between objects with different dtypes only works with Python scalars, not Tensors:\r\n```\r\n# this works\r\n>>> tf.constant(1.0) * 2\r\n<tf.Tensor: id=4, shape=(), dtype=float32, numpy=2.0>\r\n\r\n# this doesn't\r\n>>> tf.constant(1.0) * tf.constant(2)\r\nInvalidArgumentError: cannot compute Mul as input #0 was expected to be a int32 tensor but is a float tensor [Op:Mul] name: mul/\r\n```\r\n\r\n### Describe the problem\r\n\r\nNumPy has well defined [casting rules](https://docs.scipy.org/doc/numpy/reference/ufuncs.html#casting-rules) for converting between dtypes. If an operation cannot be performed natively on the given dtypes (e.g., `np.add` between float32 and float64), then one or more of the inputs will be promoted to a higher data-type, e.g., float32 -> float64.\r\n\r\nThis is highly convenient, and remains one of the major annoyances when porting NumPy code to TensorFlow. TensorFlow code ends up littered with calls to `tf.cast()`. It's particularly annoying for any use-cases that require types other than float32, e.g., models that use complex numbers, because you can't simply cast every argument to float32.\r\n\r\nAn argument for not implementing this would be that TensorFlow strives to be more explicit than NumPy, and this could lead to unintended performance degradation. But I'm struggling to imagine cases where this would actually be the case. It's also easy to avoid by using explicit casting on everything, which could still be utilized by users who concerned about it. There are lots of areas where NumPy got things wrong by being undisciplined (e.g., indexing rules) but I have not heard any complaints about this one."}