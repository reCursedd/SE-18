{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/417819957", "html_url": "https://github.com/tensorflow/tensorflow/issues/21491#issuecomment-417819957", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21491", "id": 417819957, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNzgxOTk1Nw==", "user": {"login": "shoyer", "id": 1217238, "node_id": "MDQ6VXNlcjEyMTcyMzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoyer", "html_url": "https://github.com/shoyer", "followers_url": "https://api.github.com/users/shoyer/followers", "following_url": "https://api.github.com/users/shoyer/following{/other_user}", "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions", "organizations_url": "https://api.github.com/users/shoyer/orgs", "repos_url": "https://api.github.com/users/shoyer/repos", "events_url": "https://api.github.com/users/shoyer/events{/privacy}", "received_events_url": "https://api.github.com/users/shoyer/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-01T00:35:48Z", "updated_at": "2018-09-01T00:35:48Z", "author_association": "MEMBER", "body_html": "<p>Thinking about this a little more, the biggest reason why this might not work as well for TensorFlow as it does for NumPy is our preference for small data types (e.g., float32/int32 over float64/int64). NumPy's dtype promotion rules end up promoting even int32 + float32 into float64. This is rarely what a TensorFlow user would want, but conversely it's dangerous to assume that every int32 would fit in float32.</p>", "body_text": "Thinking about this a little more, the biggest reason why this might not work as well for TensorFlow as it does for NumPy is our preference for small data types (e.g., float32/int32 over float64/int64). NumPy's dtype promotion rules end up promoting even int32 + float32 into float64. This is rarely what a TensorFlow user would want, but conversely it's dangerous to assume that every int32 would fit in float32.", "body": "Thinking about this a little more, the biggest reason why this might not work as well for TensorFlow as it does for NumPy is our preference for small data types (e.g., float32/int32 over float64/int64). NumPy's dtype promotion rules end up promoting even int32 + float32 into float64. This is rarely what a TensorFlow user would want, but conversely it's dangerous to assume that every int32 would fit in float32."}