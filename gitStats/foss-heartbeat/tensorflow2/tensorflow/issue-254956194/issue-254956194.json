{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12789", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12789/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12789/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12789/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12789", "id": 254956194, "node_id": "MDU6SXNzdWUyNTQ5NTYxOTQ=", "number": 12789, "title": "Zero accuracy if shuffle is False in TF Keras ImageDataGenerator", "user": {"login": "DiplEng", "id": 20629486, "node_id": "MDQ6VXNlcjIwNjI5NDg2", "avatar_url": "https://avatars3.githubusercontent.com/u/20629486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DiplEng", "html_url": "https://github.com/DiplEng", "followers_url": "https://api.github.com/users/DiplEng/followers", "following_url": "https://api.github.com/users/DiplEng/following{/other_user}", "gists_url": "https://api.github.com/users/DiplEng/gists{/gist_id}", "starred_url": "https://api.github.com/users/DiplEng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DiplEng/subscriptions", "organizations_url": "https://api.github.com/users/DiplEng/orgs", "repos_url": "https://api.github.com/users/DiplEng/repos", "events_url": "https://api.github.com/users/DiplEng/events{/privacy}", "received_events_url": "https://api.github.com/users/DiplEng/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-04T07:26:01Z", "updated_at": "2017-09-06T20:49:21Z", "closed_at": "2017-09-06T20:49:21Z", "author_association": "NONE", "body_html": "<p>If I use the TF Keras reimplementation (tensorflow.contrib.keras) and set the ImageDataGenerator's shuffle param to False, I get zero accuracy every time. Also this:</p>\n<p>I've just used for the first time the ModelCheckpoint from function to save the best model (best_model = True) and wanted to test its performance. When the model was saved it said that the \"val_acc\" was at 83.3% before saving. I loaded the model and used the evaluate_generator on validation_generator but the result for \"val_acc\" was 0.639. I got confused and used it again and got 0.654 and then 0.647, 0.744 and so on. Questions are:</p>\n<ol>\n<li>Am I loading the model correctly, and if not what did I miss? Why is the result so much different?</li>\n<li>Why are the results between different evaluate_generator executions different (no retraining is happening, just shear execution of predict_generator multiple times in a row)?<br>\nimportant part of the code (ResNet50 fine-tuning):</li>\n</ol>\n<pre><code>model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', monitor = \"val_acc\", verbose=1, save_best_only=True)\n# prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(\n    rescale = 1./ 255,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True)\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size = (img_height, img_width),\n    batch_size = batch_size)\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size = (img_height, img_width),\n    batch_size = batch_size)\n# fine-tune the model\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch = math.ceil(train_samples/batch_size),\n    epochs=100,\n    workers = 120,\n    validation_data=validation_generator,\n    validation_steps=math.ceil(val_samples/batch_size),\n    callbacks=[checkpointer])\nmodel.load_weights(filepath='/tmp/weights.hdf5')\nmodel.predict_generator(validation_generator, steps = math.ceil(val_samples/batch_size) )\n&gt;&gt; 0.62\nmodel.predict_generator(validation_generator, steps = math.ceil(val_samples/batch_size) )\n&gt;&gt; 0.587\n</code></pre>", "body_text": "If I use the TF Keras reimplementation (tensorflow.contrib.keras) and set the ImageDataGenerator's shuffle param to False, I get zero accuracy every time. Also this:\nI've just used for the first time the ModelCheckpoint from function to save the best model (best_model = True) and wanted to test its performance. When the model was saved it said that the \"val_acc\" was at 83.3% before saving. I loaded the model and used the evaluate_generator on validation_generator but the result for \"val_acc\" was 0.639. I got confused and used it again and got 0.654 and then 0.647, 0.744 and so on. Questions are:\n\nAm I loading the model correctly, and if not what did I miss? Why is the result so much different?\nWhy are the results between different evaluate_generator executions different (no retraining is happening, just shear execution of predict_generator multiple times in a row)?\nimportant part of the code (ResNet50 fine-tuning):\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', monitor = \"val_acc\", verbose=1, save_best_only=True)\n# prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(\n    rescale = 1./ 255,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True)\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size = (img_height, img_width),\n    batch_size = batch_size)\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size = (img_height, img_width),\n    batch_size = batch_size)\n# fine-tune the model\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch = math.ceil(train_samples/batch_size),\n    epochs=100,\n    workers = 120,\n    validation_data=validation_generator,\n    validation_steps=math.ceil(val_samples/batch_size),\n    callbacks=[checkpointer])\nmodel.load_weights(filepath='/tmp/weights.hdf5')\nmodel.predict_generator(validation_generator, steps = math.ceil(val_samples/batch_size) )\n>> 0.62\nmodel.predict_generator(validation_generator, steps = math.ceil(val_samples/batch_size) )\n>> 0.587", "body": "If I use the TF Keras reimplementation (tensorflow.contrib.keras) and set the ImageDataGenerator's shuffle param to False, I get zero accuracy every time. Also this:\r\n\r\nI've just used for the first time the ModelCheckpoint from function to save the best model (best_model = True) and wanted to test its performance. When the model was saved it said that the \"val_acc\" was at 83.3% before saving. I loaded the model and used the evaluate_generator on validation_generator but the result for \"val_acc\" was 0.639. I got confused and used it again and got 0.654 and then 0.647, 0.744 and so on. Questions are:\r\n\r\n1. Am I loading the model correctly, and if not what did I miss? Why is the result so much different?\r\n2. Why are the results between different evaluate_generator executions different (no retraining is happening, just shear execution of predict_generator multiple times in a row)?\r\nimportant part of the code (ResNet50 fine-tuning):\r\n\r\n```\r\nmodel.compile(loss='categorical_crossentropy',\r\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\r\n              metrics=['accuracy'])\r\ncheckpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', monitor = \"val_acc\", verbose=1, save_best_only=True)\r\n# prepare data augmentation configuration\r\ntrain_datagen = ImageDataGenerator(\r\n    rescale = 1./ 255,\r\n    shear_range = 0.2,\r\n    zoom_range = 0.2,\r\n    horizontal_flip = True)\r\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\r\ntrain_generator = train_datagen.flow_from_directory(\r\n    train_data_dir,\r\n    target_size = (img_height, img_width),\r\n    batch_size = batch_size)\r\nvalidation_generator = test_datagen.flow_from_directory(\r\n    validation_data_dir,\r\n    target_size = (img_height, img_width),\r\n    batch_size = batch_size)\r\n# fine-tune the model\r\nmodel.fit_generator(\r\n    train_generator,\r\n    steps_per_epoch = math.ceil(train_samples/batch_size),\r\n    epochs=100,\r\n    workers = 120,\r\n    validation_data=validation_generator,\r\n    validation_steps=math.ceil(val_samples/batch_size),\r\n    callbacks=[checkpointer])\r\nmodel.load_weights(filepath='/tmp/weights.hdf5')\r\nmodel.predict_generator(validation_generator, steps = math.ceil(val_samples/batch_size) )\r\n>> 0.62\r\nmodel.predict_generator(validation_generator, steps = math.ceil(val_samples/batch_size) )\r\n>> 0.587\r\n```\r\n"}