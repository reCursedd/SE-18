{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11859", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11859/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11859/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11859/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11859", "id": 246472575, "node_id": "MDU6SXNzdWUyNDY0NzI1NzU=", "number": 11859, "title": "no such package '@local_config_cuda//cuda'", "user": {"login": "alex-taffe", "id": 6820226, "node_id": "MDQ6VXNlcjY4MjAyMjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6820226?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alex-taffe", "html_url": "https://github.com/alex-taffe", "followers_url": "https://api.github.com/users/alex-taffe/followers", "following_url": "https://api.github.com/users/alex-taffe/following{/other_user}", "gists_url": "https://api.github.com/users/alex-taffe/gists{/gist_id}", "starred_url": "https://api.github.com/users/alex-taffe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alex-taffe/subscriptions", "organizations_url": "https://api.github.com/users/alex-taffe/orgs", "repos_url": "https://api.github.com/users/alex-taffe/repos", "events_url": "https://api.github.com/users/alex-taffe/events{/privacy}", "received_events_url": "https://api.github.com/users/alex-taffe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 29, "created_at": "2017-07-28T22:21:58Z", "updated_at": "2018-09-20T17:23:12Z", "closed_at": "2017-10-02T19:24:27Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n</ul>\n<p>No</p>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n</ul>\n<p>Linux \u2014 Ubuntu Server 16.04 LTS</p>\n<p>Linux PowerEdge-R810 4.4.0-87-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116236573\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/110\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/110/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/110\">#110</a>-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>\n<ul>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n</ul>\n<p>Source</p>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n</ul>\n<p>master, r1.3, r1.2.1</p>\n<ul>\n<li><strong>Python version</strong>:</li>\n</ul>\n<p>2.7</p>\n<ul>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n</ul>\n<p>Build label: 0.5.3<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Fri Jul 28 08:34:59 2017 (1501230899)<br>\nBuild timestamp: 1501230899<br>\nBuild timestamp as int: 1501230899</p>\n<ul>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n</ul>\n<p>CUDA 8, cuDNN 6</p>\n<ul>\n<li><strong>GPU model and memory</strong>:</li>\n</ul>\n<p>GTX 1080, 8gb</p>\n<ul>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p><code>./configure;bazel build -c opt \u2014config=cuda //tensorflow/tools/pip_package:build_pip_package</code></p>\n<p>-<strong>Premade script</strong>:</p>\n<pre><code>alex@PowerEdge-R810:~$ sh tf_env_collect.sh \nCollecting system information...\ntf_env_collect.sh: 39: [: Linux: unexpected operator\ntf_env_collect.sh: 41: [: Linux: unexpected operator\nTraceback (most recent call last):\n  File \"/tmp/check_tf.py\", line 1, in &lt;module&gt;\n    import tensorflow as tf;\nImportError: No module named tensorflow\nWrote environment to tf_env.txt. You can review the contents of that file.\nand use it to populate the fields in the github issue template.\n\ncat tf_env.txt\n\nalex@PowerEdge-R810:~$ cat tf_env.txt\n\n== cat /etc/issue ===============================================\nLinux PowerEdge-R810 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux PowerEdge-R810 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.11.0)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nImportError: No module named tensorflow\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nFri Jul 28 18:12:37 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 00000000:0E:00.0 Off |                  N/A |\n| 37%   32C    P0    32W / 180W |      0MiB /  8105MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n</code></pre>\n<h3>Describe the problem</h3>\n<p>I am trying to compile tensorflow from source. When I run the above command, the bazel build fails. This is the configuration I used as well as the error. It seems like some other people had this issue but the threads were for much older versions and none of the solutions fixed it:</p>\n<pre><code>Please specify the location of python. [Default is /usr/bin/python]: \nFound possible Python library paths:\n/usr/local/lib/python2.7/dist-packages\n/usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is /usr/local/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]: y\nGoogle Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]: \nNo Hadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \nNo XLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]: \nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL support? [y/N]: y\nOpenCL support will be enabled for TensorFlow.\n\nPlease specify which C++ compiler should be used as the host C++ compiler. [Default is /usr/bin/g++]: \nPlease specify which C compiler should be used as the host C compiler. [Default is /usr/bin/gcc]: \nPlease specify the location where ComputeCpp for SYCL 1.2 is installed. [Default is /usr/local/computecpp]: \nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: \nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\nDo you want to use clang as CUDA compiler? [y/N]: \nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nDo you wish to build TensorFlow with MPI support? [y/N]: \nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nAdd \"--config=mkl\" to your bazel command to build with MKL support.\nPlease note that MKL on MacOS or windows is still not supported.\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\nConfiguration finished\n...............\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\n\t\t_create_local_cuda_repository(repository_ctx)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\n\t\t_host_compiler_includes(repository_ctx, cc)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\n\t\tget_cxx_inc_directories(repository_ctx, cc)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\n\t\tset(includes_cpp)\ndepsets cannot contain mutable items\nWARNING: Target pattern parsing failed.\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\n\t\t_create_local_cuda_repository(repository_ctx)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\n\t\t_host_compiler_includes(repository_ctx, cc)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\n\t\tget_cxx_inc_directories(repository_ctx, cc)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\n\t\tset(includes_cpp)\ndepsets cannot contain mutable items\nINFO: Elapsed time: 13.663s\nFAILED: Build did NOT complete successfully (0 packages loaded)\n    currently loading: tensorflow/tools/pip_package\n</code></pre>", "body_text": "Please go to Stack Overflow for help and support:\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nNo\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n\nLinux \u2014 Ubuntu Server 16.04 LTS\nLinux PowerEdge-R810 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\nTensorFlow installed from (source or binary):\n\nSource\n\nTensorFlow version (use command below):\n\nmaster, r1.3, r1.2.1\n\nPython version:\n\n2.7\n\nBazel version (if compiling from source):\n\nBuild label: 0.5.3\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 28 08:34:59 2017 (1501230899)\nBuild timestamp: 1501230899\nBuild timestamp as int: 1501230899\n\nCUDA/cuDNN version:\n\nCUDA 8, cuDNN 6\n\nGPU model and memory:\n\nGTX 1080, 8gb\n\nExact command to reproduce:\n\n./configure;bazel build -c opt \u2014config=cuda //tensorflow/tools/pip_package:build_pip_package\n-Premade script:\nalex@PowerEdge-R810:~$ sh tf_env_collect.sh \nCollecting system information...\ntf_env_collect.sh: 39: [: Linux: unexpected operator\ntf_env_collect.sh: 41: [: Linux: unexpected operator\nTraceback (most recent call last):\n  File \"/tmp/check_tf.py\", line 1, in <module>\n    import tensorflow as tf;\nImportError: No module named tensorflow\nWrote environment to tf_env.txt. You can review the contents of that file.\nand use it to populate the fields in the github issue template.\n\ncat tf_env.txt\n\nalex@PowerEdge-R810:~$ cat tf_env.txt\n\n== cat /etc/issue ===============================================\nLinux PowerEdge-R810 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux PowerEdge-R810 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.11.0)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nImportError: No module named tensorflow\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nFri Jul 28 18:12:37 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 00000000:0E:00.0 Off |                  N/A |\n| 37%   32C    P0    32W / 180W |      0MiB /  8105MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n\nDescribe the problem\nI am trying to compile tensorflow from source. When I run the above command, the bazel build fails. This is the configuration I used as well as the error. It seems like some other people had this issue but the threads were for much older versions and none of the solutions fixed it:\nPlease specify the location of python. [Default is /usr/bin/python]: \nFound possible Python library paths:\n/usr/local/lib/python2.7/dist-packages\n/usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is /usr/local/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]: y\nGoogle Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]: \nNo Hadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \nNo XLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]: \nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL support? [y/N]: y\nOpenCL support will be enabled for TensorFlow.\n\nPlease specify which C++ compiler should be used as the host C++ compiler. [Default is /usr/bin/g++]: \nPlease specify which C compiler should be used as the host C compiler. [Default is /usr/bin/gcc]: \nPlease specify the location where ComputeCpp for SYCL 1.2 is installed. [Default is /usr/local/computecpp]: \nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: \nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\nDo you want to use clang as CUDA compiler? [y/N]: \nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nDo you wish to build TensorFlow with MPI support? [y/N]: \nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nAdd \"--config=mkl\" to your bazel command to build with MKL support.\nPlease note that MKL on MacOS or windows is still not supported.\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\nConfiguration finished\n...............\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\n\t\t_create_local_cuda_repository(repository_ctx)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\n\t\t_host_compiler_includes(repository_ctx, cc)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\n\t\tget_cxx_inc_directories(repository_ctx, cc)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\n\t\tset(includes_cpp)\ndepsets cannot contain mutable items\nWARNING: Target pattern parsing failed.\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\n\t\t_create_local_cuda_repository(repository_ctx)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\n\t\t_host_compiler_includes(repository_ctx, cc)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\n\t\tget_cxx_inc_directories(repository_ctx, cc)\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\n\t\tset(includes_cpp)\ndepsets cannot contain mutable items\nINFO: Elapsed time: 13.663s\nFAILED: Build did NOT complete successfully (0 packages loaded)\n    currently loading: tensorflow/tools/pip_package", "body": "Please go to Stack Overflow for help and support:\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nNo\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nLinux \u2014 Ubuntu Server 16.04 LTS\r\n\r\nLinux PowerEdge-R810 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nSource\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\nmaster, r1.3, r1.2.1\r\n\r\n- **Python version**: \r\n\r\n2.7\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\nBuild label: 0.5.3\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Jul 28 08:34:59 2017 (1501230899)\r\nBuild timestamp: 1501230899\r\nBuild timestamp as int: 1501230899\r\n\r\n\r\n- **CUDA/cuDNN version**:\r\n\r\nCUDA 8, cuDNN 6\r\n\r\n- **GPU model and memory**:\r\n\r\nGTX 1080, 8gb\r\n\r\n- **Exact command to reproduce**:\r\n\r\n`./configure;bazel build -c opt \u2014config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n\r\n\r\n-**Premade script**:\r\n```\r\nalex@PowerEdge-R810:~$ sh tf_env_collect.sh \r\nCollecting system information...\r\ntf_env_collect.sh: 39: [: Linux: unexpected operator\r\ntf_env_collect.sh: 41: [: Linux: unexpected operator\r\nTraceback (most recent call last):\r\n  File \"/tmp/check_tf.py\", line 1, in <module>\r\n    import tensorflow as tf;\r\nImportError: No module named tensorflow\r\nWrote environment to tf_env.txt. You can review the contents of that file.\r\nand use it to populate the fields in the github issue template.\r\n\r\ncat tf_env.txt\r\n\r\nalex@PowerEdge-R810:~$ cat tf_env.txt\r\n\r\n== cat /etc/issue ===============================================\r\nLinux PowerEdge-R810 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux PowerEdge-R810 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.11.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: No module named tensorflow\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nFri Jul 28 18:12:37 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1080    Off  | 00000000:0E:00.0 Off |                  N/A |\r\n| 37%   32C    P0    32W / 180W |      0MiB /  8105MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n```\r\n\r\n### Describe the problem\r\n\r\nI am trying to compile tensorflow from source. When I run the above command, the bazel build fails. This is the configuration I used as well as the error. It seems like some other people had this issue but the threads were for much older versions and none of the solutions fixed it: \r\n\r\n\r\n```\r\nPlease specify the location of python. [Default is /usr/bin/python]: \r\nFound possible Python library paths:\r\n/usr/local/lib/python2.7/dist-packages\r\n/usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is /usr/local/lib/python2.7/dist-packages\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]: y\r\nGoogle Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]: \r\nNo Hadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: \r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]: y\r\nOpenCL support will be enabled for TensorFlow.\r\n\r\nPlease specify which C++ compiler should be used as the host C++ compiler. [Default is /usr/bin/g++]: \r\nPlease specify which C compiler should be used as the host C compiler. [Default is /usr/bin/gcc]: \r\nPlease specify the location where ComputeCpp for SYCL 1.2 is installed. [Default is /usr/local/computecpp]: \r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: \r\nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nDo you wish to build TensorFlow with MPI support? [y/N]: \r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\nAdd \"--config=mkl\" to your bazel command to build with MKL support.\r\nPlease note that MKL on MacOS or windows is still not supported.\r\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\r\nConfiguration finished\r\n...............\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\r\n\t\t_create_local_cuda_repository(repository_ctx)\r\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\r\n\t\t_host_compiler_includes(repository_ctx, cc)\r\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\r\n\t\tget_cxx_inc_directories(repository_ctx, cc)\r\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\r\n\t\tset(includes_cpp)\r\ndepsets cannot contain mutable items\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1039\r\n\t\t_create_local_cuda_repository(repository_ctx)\r\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\r\n\t\t_host_compiler_includes(repository_ctx, cc)\r\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\r\n\t\tget_cxx_inc_directories(repository_ctx, cc)\r\n\tFile \"/home/alex/tensorflow/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\r\n\t\tset(includes_cpp)\r\ndepsets cannot contain mutable items\r\nINFO: Elapsed time: 13.663s\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n```\r\n\r\n"}