{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261911768", "html_url": "https://github.com/tensorflow/tensorflow/pull/5546#issuecomment-261911768", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5546", "id": 261911768, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTkxMTc2OA==", "user": {"login": "abhitopia", "id": 12864026, "node_id": "MDQ6VXNlcjEyODY0MDI2", "avatar_url": "https://avatars1.githubusercontent.com/u/12864026?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhitopia", "html_url": "https://github.com/abhitopia", "followers_url": "https://api.github.com/users/abhitopia/followers", "following_url": "https://api.github.com/users/abhitopia/following{/other_user}", "gists_url": "https://api.github.com/users/abhitopia/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhitopia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhitopia/subscriptions", "organizations_url": "https://api.github.com/users/abhitopia/orgs", "repos_url": "https://api.github.com/users/abhitopia/repos", "events_url": "https://api.github.com/users/abhitopia/events{/privacy}", "received_events_url": "https://api.github.com/users/abhitopia/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-21T11:24:30Z", "updated_at": "2016-11-21T11:24:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=577277\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/martinwicke\">@martinwicke</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=175486\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ilblackdragon\">@ilblackdragon</a>  - I can give you at least one real life example where this is required.<br>\nConsider the case of Response Selection in conversation.  ( See <a href=\"http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\" rel=\"nofollow\">http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/</a>)</p>\n<p><strong>During training:</strong><br>\nX: context<br>\ny: response</p>\n<p><strong>During evaluation:</strong><br>\nX: context<br>\ny: k responses which are ranked against X to give k@recall metric.</p>\n<p>Also, I don't understand how having different signature makes it fragile. If for instance, the tensor signature in ModeKeys.EVAL is not compatible with computation graph, the error will be generated any how. Similarly, for ModeKeys.INFER the code first tries to match it up against signatures for ModeKeys.TRAIN/EVAL. If it doesn't match, warning is generated. But if the user doesn't pay heed to the warning and continues, that error should automatically get generated down the line if signature of ModeKeys.INFER is incompatible with computation graph.</p>", "body_text": "@martinwicke, @ilblackdragon  - I can give you at least one real life example where this is required.\nConsider the case of Response Selection in conversation.  ( See http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/)\nDuring training:\nX: context\ny: response\nDuring evaluation:\nX: context\ny: k responses which are ranked against X to give k@recall metric.\nAlso, I don't understand how having different signature makes it fragile. If for instance, the tensor signature in ModeKeys.EVAL is not compatible with computation graph, the error will be generated any how. Similarly, for ModeKeys.INFER the code first tries to match it up against signatures for ModeKeys.TRAIN/EVAL. If it doesn't match, warning is generated. But if the user doesn't pay heed to the warning and continues, that error should automatically get generated down the line if signature of ModeKeys.INFER is incompatible with computation graph.", "body": "@martinwicke, @ilblackdragon  - I can give you at least one real life example where this is required. \r\nConsider the case of Response Selection in conversation.  ( See http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/)\r\n\r\n**During training:**\r\nX: context\r\ny: response\r\n\r\n**During evaluation:**\r\nX: context\r\ny: k responses which are ranked against X to give k@recall metric.\r\n\r\nAlso, I don't understand how having different signature makes it fragile. If for instance, the tensor signature in ModeKeys.EVAL is not compatible with computation graph, the error will be generated any how. Similarly, for ModeKeys.INFER the code first tries to match it up against signatures for ModeKeys.TRAIN/EVAL. If it doesn't match, warning is generated. But if the user doesn't pay heed to the warning and continues, that error should automatically get generated down the line if signature of ModeKeys.INFER is incompatible with computation graph.\r\n\r\n"}