{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17487", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17487/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17487/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17487/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17487", "id": 302768866, "node_id": "MDU6SXNzdWUzMDI3Njg4NjY=", "number": 17487, "title": "SparseTensor", "user": {"login": "sami93", "id": 19590686, "node_id": "MDQ6VXNlcjE5NTkwNjg2", "avatar_url": "https://avatars2.githubusercontent.com/u/19590686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sami93", "html_url": "https://github.com/sami93", "followers_url": "https://api.github.com/users/sami93/followers", "following_url": "https://api.github.com/users/sami93/following{/other_user}", "gists_url": "https://api.github.com/users/sami93/gists{/gist_id}", "starred_url": "https://api.github.com/users/sami93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sami93/subscriptions", "organizations_url": "https://api.github.com/users/sami93/orgs", "repos_url": "https://api.github.com/users/sami93/repos", "events_url": "https://api.github.com/users/sami93/events{/privacy}", "received_events_url": "https://api.github.com/users/sami93/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-03-06T16:23:41Z", "updated_at": "2018-04-10T15:56:36Z", "closed_at": "2018-04-10T15:56:36Z", "author_association": "NONE", "body_html": "<p>Hi, i want to have a prediction with continuous and categorial features.<br>\ni faced a problem with the last line with SparseTensor</p>\n<p>i used Tensorflow version : 1.5.0 installed with anaconda<br>\nos : windows 7<br>\nconda version : 4.4.10<br>\nconda-build version : 3.0.27<br>\npython version : 3.6.3.final.0</p>\n<p>there is my code :</p>\n<p>from <strong>future</strong> import absolute_import<br>\nfrom <strong>future</strong> import division<br>\nfrom <strong>future</strong> import print_function<br>\nimport tensorflow as tf</p>\n<p>import itertools<br>\nimport pandas as pd<br>\nimport numpy as np</p>\n<p>from sklearn.model_selection import train_test_split<br>\nfrom sklearn.preprocessing import MinMaxScaler<br>\nimport warnings<br>\nfrom sklearn.ensemble import IsolationForest<br>\nwarnings.filterwarnings('ignore')</p>\n<h1>categorial with continuous</h1>\n<p>train = pd.read_csv('Dataset3.csv', delimiter=';')<br>\ntrain.drop('Matricule',axis = 1, inplace = True)<br>\ntrain_numerical = train.select_dtypes(exclude=['object'])<br>\ntrain_numerical.fillna(0,inplace = True)<br>\ntrain_categoric = train.select_dtypes(include=['object'])<br>\ntrain_categoric.fillna('NONE',inplace = True)<br>\ntrain = train_numerical.merge(train_categoric, left_index = True, right_index = True)</p>\n<p>test = pd.read_csv('Dataset3_test.csv', delimiter=';')<br>\nMatricule = test.Matricule<br>\ntest.drop('Matricule',axis = 1, inplace = True)<br>\ntest_numerical = test.select_dtypes(exclude=['object'])<br>\ntest_numerical.fillna(0,inplace = True)<br>\ntest_categoric = test.select_dtypes(include=['object'])<br>\ntest_categoric.fillna('NONE',inplace = True)<br>\ntest = test_numerical.merge(test_categoric, left_index = True, right_index = True)</p>\n<p>clf = IsolationForest( random_state = 42)<br>\nclf.fit(train_numerical)<br>\ny_noano = clf.predict(train_numerical)<br>\ny_noano = pd.DataFrame(y_noano, columns = ['Top'])<br>\ny_noano[y_noano['Top'] == 1].index.values</p>\n<p>train_numerical = train_numerical.iloc[y_noano[y_noano['Top'] == 1].index.values]<br>\ntrain_numerical.reset_index(drop = True, inplace = True)</p>\n<p>train_categoric = train_categoric.iloc[y_noano[y_noano['Top'] == 1].index.values]<br>\ntrain_categoric.reset_index(drop = True, inplace = True)</p>\n<p>train = train.iloc[y_noano[y_noano['Top'] == 1].index.values]<br>\ntrain.reset_index(drop = True, inplace = True)</p>\n<p>col_train = list(train_numerical.columns)<br>\ncol_train_bis = list(train_numerical.columns)</p>\n<p>col_train_cat = list(train_categoric.columns)</p>\n<p>col_train_bis.remove('DEM')</p>\n<p>mat_train = np.matrix(train_numerical)<br>\nmat_test  = np.matrix(test_numerical)<br>\nmat_new = np.matrix(train_numerical.drop('DEM',axis = 1))<br>\nmat_y = np.array(train.DEM)</p>\n<p>prepro_y = MinMaxScaler()<br>\nprepro_y.fit(mat_y.reshape(len(mat_y),1))</p>\n<p>prepro = MinMaxScaler()<br>\nprepro.fit(mat_train)</p>\n<p>prepro_test = MinMaxScaler()<br>\nprepro_test.fit(mat_new)</p>\n<p>train_num_scale = pd.DataFrame(prepro.transform(mat_train),columns = col_train)<br>\ntest_num_scale  = pd.DataFrame(prepro_test.transform(mat_test),columns = col_train_bis)</p>\n<p>train[col_train] = pd.DataFrame(prepro.transform(mat_train),columns = col_train)<br>\ntest[col_train_bis]  = test_num_scale</p>\n<h1>List of features</h1>\n<p>COLUMNS = col_train<br>\nFEATURES = col_train_bis<br>\nLABEL = \"SalePrice\"</p>\n<p>FEATURES_CAT = col_train_cat<br>\nprint (FEATURES_CAT)</p>\n<p>engineered_features = []</p>\n<p>for continuous_feature in FEATURES:<br>\nengineered_features.append(<br>\ntf.contrib.layers.real_valued_column(continuous_feature))</p>\n<p>for categorical_feature in FEATURES_CAT:<br>\nsparse_column = tf.contrib.layers.sparse_column_with_hash_bucket(<br>\ncategorical_feature, hash_bucket_size=1000)<br>\nengineered_features.append(<br>\ntf.contrib.layers.embedding_column(sparse_id_column=sparse_column, dimension=16, combiner=\"sum\"))<br>\nprint (engineered_features)</p>\n<h1>Training set and Prediction set with the features to predict</h1>\n<p>training_set = train[FEATURES + FEATURES_CAT]<br>\nprediction_set = train.DEM<br>\nprint (training_set)</p>\n<h1>Train and Test</h1>\n<p>x_train, x_test, y_train, y_test = train_test_split(training_set[FEATURES + FEATURES_CAT] ,<br>\nprediction_set, test_size=0.33, random_state=42)<br>\ny_train = pd.DataFrame(y_train, columns = [LABEL])<br>\ntraining_set = pd.DataFrame(x_train, columns = FEATURES + FEATURES_CAT).merge(y_train, left_index = True, right_index = True)</p>\n<h1>Training for submission</h1>\n<p>training_sub = training_set[FEATURES + FEATURES_CAT]<br>\ntesting_sub = test[FEATURES + FEATURES_CAT]</p>\n<h1>Same thing but for the test set</h1>\n<p>y_test = pd.DataFrame(y_test, columns = [LABEL])<br>\ntesting_set = pd.DataFrame(x_test, columns = FEATURES + FEATURES_CAT).merge(y_test, left_index = True, right_index = True)</p>\n<p>testing_set[FEATURES_CAT] = testing_set[FEATURES_CAT].applymap(str)</p>\n<p>print (training_set[FEATURES_CAT])</p>\n<p>def input_fn_new(data_set, training=True):<br>\ncontinuous_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}</p>\n<pre><code>categorical_cols = {k: tf.SparseTensor(\n    indices=[[i, 0] for i in range(data_set[k].size)], values=data_set[k].values, dense_shape=[data_set[k].size, 1])\nfor k in FEATURES_CAT}\n\n# Merges the two dictionaries into one.\nfeature_cols = dict(list(continuous_cols.items()) + list(categorical_cols.items()))\nprint(feature_cols)\nif training == True:\n    # Converts the label column into a constant Tensor.\n    label = tf.constant(data_set[LABEL].values)\n\n    # Returns the feature columns and the label.\n    return feature_cols, label\n\nreturn feature_cols\n</code></pre>\n<h1>Model</h1>\n<p>regressor = tf.contrib.learn.DNNRegressor(feature_columns = engineered_features,<br>\nactivation_fn = tf.nn.relu, hidden_units=[200, 100, 50, 25, 12])</p>\n<p>training_set[FEATURES_CAT] = training_set[FEATURES_CAT].applymap(str)<br>\ncategorical_cols = {k: tf.SparseTensor(<br>\nindices=[[i, 0] for i in range(training_set[k].size)],<br>\nvalues=training_set[k].values,<br>\ndense_shape=[training_set[k].size, 1])<br>\nfor k in FEATURES_CAT}</p>\n<h1>Error:</h1>\n<p>WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\S9E55~1.GHO\\AppData\\Local\\Temp\\tmpl279_r04<br>\nTraceback (most recent call last):<br>\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 576, in merge_with<br>\nself.assert_same_rank(other)<br>\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 621, in assert_same_rank<br>\nother))<br>\nValueError: Shapes (0,) and (?, ?) must have the same rank</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 651, in with_rank<br>\nreturn self.merge_with(unknown_shape(ndims=rank))<br>\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 582, in merge_with<br>\nraise ValueError(\"Shapes %s and %s are not compatible\" % (self, other))<br>\nValueError: Shapes (0,) and (?, ?) are not compatible</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"prediction.py\", line 156, in <br>\nfor k in FEATURES_CAT}<br>\nFile \"prediction.py\", line 156, in <br>\nfor k in FEATURES_CAT}<br>\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\", line 131, in <strong>init</strong><br>\nindices_shape = indices.get_shape().with_rank(2)<br>\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 653, in with_rank<br>\nraise ValueError(\"Shape %s must have rank %d\" % (self, rank))<br>\nValueError: Shape (0,) must have rank 2</p>", "body_text": "Hi, i want to have a prediction with continuous and categorial features.\ni faced a problem with the last line with SparseTensor\ni used Tensorflow version : 1.5.0 installed with anaconda\nos : windows 7\nconda version : 4.4.10\nconda-build version : 3.0.27\npython version : 3.6.3.final.0\nthere is my code :\nfrom future import absolute_import\nfrom future import division\nfrom future import print_function\nimport tensorflow as tf\nimport itertools\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nfrom sklearn.ensemble import IsolationForest\nwarnings.filterwarnings('ignore')\ncategorial with continuous\ntrain = pd.read_csv('Dataset3.csv', delimiter=';')\ntrain.drop('Matricule',axis = 1, inplace = True)\ntrain_numerical = train.select_dtypes(exclude=['object'])\ntrain_numerical.fillna(0,inplace = True)\ntrain_categoric = train.select_dtypes(include=['object'])\ntrain_categoric.fillna('NONE',inplace = True)\ntrain = train_numerical.merge(train_categoric, left_index = True, right_index = True)\ntest = pd.read_csv('Dataset3_test.csv', delimiter=';')\nMatricule = test.Matricule\ntest.drop('Matricule',axis = 1, inplace = True)\ntest_numerical = test.select_dtypes(exclude=['object'])\ntest_numerical.fillna(0,inplace = True)\ntest_categoric = test.select_dtypes(include=['object'])\ntest_categoric.fillna('NONE',inplace = True)\ntest = test_numerical.merge(test_categoric, left_index = True, right_index = True)\nclf = IsolationForest( random_state = 42)\nclf.fit(train_numerical)\ny_noano = clf.predict(train_numerical)\ny_noano = pd.DataFrame(y_noano, columns = ['Top'])\ny_noano[y_noano['Top'] == 1].index.values\ntrain_numerical = train_numerical.iloc[y_noano[y_noano['Top'] == 1].index.values]\ntrain_numerical.reset_index(drop = True, inplace = True)\ntrain_categoric = train_categoric.iloc[y_noano[y_noano['Top'] == 1].index.values]\ntrain_categoric.reset_index(drop = True, inplace = True)\ntrain = train.iloc[y_noano[y_noano['Top'] == 1].index.values]\ntrain.reset_index(drop = True, inplace = True)\ncol_train = list(train_numerical.columns)\ncol_train_bis = list(train_numerical.columns)\ncol_train_cat = list(train_categoric.columns)\ncol_train_bis.remove('DEM')\nmat_train = np.matrix(train_numerical)\nmat_test  = np.matrix(test_numerical)\nmat_new = np.matrix(train_numerical.drop('DEM',axis = 1))\nmat_y = np.array(train.DEM)\nprepro_y = MinMaxScaler()\nprepro_y.fit(mat_y.reshape(len(mat_y),1))\nprepro = MinMaxScaler()\nprepro.fit(mat_train)\nprepro_test = MinMaxScaler()\nprepro_test.fit(mat_new)\ntrain_num_scale = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\ntest_num_scale  = pd.DataFrame(prepro_test.transform(mat_test),columns = col_train_bis)\ntrain[col_train] = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\ntest[col_train_bis]  = test_num_scale\nList of features\nCOLUMNS = col_train\nFEATURES = col_train_bis\nLABEL = \"SalePrice\"\nFEATURES_CAT = col_train_cat\nprint (FEATURES_CAT)\nengineered_features = []\nfor continuous_feature in FEATURES:\nengineered_features.append(\ntf.contrib.layers.real_valued_column(continuous_feature))\nfor categorical_feature in FEATURES_CAT:\nsparse_column = tf.contrib.layers.sparse_column_with_hash_bucket(\ncategorical_feature, hash_bucket_size=1000)\nengineered_features.append(\ntf.contrib.layers.embedding_column(sparse_id_column=sparse_column, dimension=16, combiner=\"sum\"))\nprint (engineered_features)\nTraining set and Prediction set with the features to predict\ntraining_set = train[FEATURES + FEATURES_CAT]\nprediction_set = train.DEM\nprint (training_set)\nTrain and Test\nx_train, x_test, y_train, y_test = train_test_split(training_set[FEATURES + FEATURES_CAT] ,\nprediction_set, test_size=0.33, random_state=42)\ny_train = pd.DataFrame(y_train, columns = [LABEL])\ntraining_set = pd.DataFrame(x_train, columns = FEATURES + FEATURES_CAT).merge(y_train, left_index = True, right_index = True)\nTraining for submission\ntraining_sub = training_set[FEATURES + FEATURES_CAT]\ntesting_sub = test[FEATURES + FEATURES_CAT]\nSame thing but for the test set\ny_test = pd.DataFrame(y_test, columns = [LABEL])\ntesting_set = pd.DataFrame(x_test, columns = FEATURES + FEATURES_CAT).merge(y_test, left_index = True, right_index = True)\ntesting_set[FEATURES_CAT] = testing_set[FEATURES_CAT].applymap(str)\nprint (training_set[FEATURES_CAT])\ndef input_fn_new(data_set, training=True):\ncontinuous_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\ncategorical_cols = {k: tf.SparseTensor(\n    indices=[[i, 0] for i in range(data_set[k].size)], values=data_set[k].values, dense_shape=[data_set[k].size, 1])\nfor k in FEATURES_CAT}\n\n# Merges the two dictionaries into one.\nfeature_cols = dict(list(continuous_cols.items()) + list(categorical_cols.items()))\nprint(feature_cols)\nif training == True:\n    # Converts the label column into a constant Tensor.\n    label = tf.constant(data_set[LABEL].values)\n\n    # Returns the feature columns and the label.\n    return feature_cols, label\n\nreturn feature_cols\n\nModel\nregressor = tf.contrib.learn.DNNRegressor(feature_columns = engineered_features,\nactivation_fn = tf.nn.relu, hidden_units=[200, 100, 50, 25, 12])\ntraining_set[FEATURES_CAT] = training_set[FEATURES_CAT].applymap(str)\ncategorical_cols = {k: tf.SparseTensor(\nindices=[[i, 0] for i in range(training_set[k].size)],\nvalues=training_set[k].values,\ndense_shape=[training_set[k].size, 1])\nfor k in FEATURES_CAT}\nError:\nWARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\S9E55~1.GHO\\AppData\\Local\\Temp\\tmpl279_r04\nTraceback (most recent call last):\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 576, in merge_with\nself.assert_same_rank(other)\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 621, in assert_same_rank\nother))\nValueError: Shapes (0,) and (?, ?) must have the same rank\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 651, in with_rank\nreturn self.merge_with(unknown_shape(ndims=rank))\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 582, in merge_with\nraise ValueError(\"Shapes %s and %s are not compatible\" % (self, other))\nValueError: Shapes (0,) and (?, ?) are not compatible\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"prediction.py\", line 156, in \nfor k in FEATURES_CAT}\nFile \"prediction.py\", line 156, in \nfor k in FEATURES_CAT}\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\", line 131, in init\nindices_shape = indices.get_shape().with_rank(2)\nFile \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 653, in with_rank\nraise ValueError(\"Shape %s must have rank %d\" % (self, rank))\nValueError: Shape (0,) must have rank 2", "body": "Hi, i want to have a prediction with continuous and categorial features.\r\ni faced a problem with the last line with SparseTensor\r\n\r\ni used Tensorflow version : 1.5.0 installed with anaconda\r\nos : windows 7\r\nconda version : 4.4.10\r\nconda-build version : 3.0.27\r\npython version : 3.6.3.final.0\r\n \r\n\r\nthere is my code : \r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nimport tensorflow as tf\r\n\r\nimport itertools\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nimport warnings\r\nfrom sklearn.ensemble import IsolationForest\r\nwarnings.filterwarnings('ignore')\r\n\r\n\r\n\r\n# categorial with continuous\r\ntrain = pd.read_csv('Dataset3.csv', delimiter=';')\r\ntrain.drop('Matricule',axis = 1, inplace = True)\r\ntrain_numerical = train.select_dtypes(exclude=['object'])\r\ntrain_numerical.fillna(0,inplace = True)\r\ntrain_categoric = train.select_dtypes(include=['object'])\r\ntrain_categoric.fillna('NONE',inplace = True)\r\ntrain = train_numerical.merge(train_categoric, left_index = True, right_index = True)\r\n\r\n\r\ntest = pd.read_csv('Dataset3_test.csv', delimiter=';')\r\nMatricule = test.Matricule\r\ntest.drop('Matricule',axis = 1, inplace = True)\r\ntest_numerical = test.select_dtypes(exclude=['object'])\r\ntest_numerical.fillna(0,inplace = True)\r\ntest_categoric = test.select_dtypes(include=['object'])\r\ntest_categoric.fillna('NONE',inplace = True)\r\ntest = test_numerical.merge(test_categoric, left_index = True, right_index = True)\r\n\r\n\r\nclf = IsolationForest( random_state = 42)\r\nclf.fit(train_numerical)\r\ny_noano = clf.predict(train_numerical)\r\ny_noano = pd.DataFrame(y_noano, columns = ['Top'])\r\ny_noano[y_noano['Top'] == 1].index.values\r\n\r\ntrain_numerical = train_numerical.iloc[y_noano[y_noano['Top'] == 1].index.values]\r\ntrain_numerical.reset_index(drop = True, inplace = True)\r\n\r\ntrain_categoric = train_categoric.iloc[y_noano[y_noano['Top'] == 1].index.values]\r\ntrain_categoric.reset_index(drop = True, inplace = True)\r\n\r\ntrain = train.iloc[y_noano[y_noano['Top'] == 1].index.values]\r\ntrain.reset_index(drop = True, inplace = True)\r\n\r\ncol_train = list(train_numerical.columns)\r\ncol_train_bis = list(train_numerical.columns)\r\n\r\ncol_train_cat = list(train_categoric.columns)\r\n\r\ncol_train_bis.remove('DEM')\r\n\r\nmat_train = np.matrix(train_numerical)\r\nmat_test  = np.matrix(test_numerical)\r\nmat_new = np.matrix(train_numerical.drop('DEM',axis = 1))\r\nmat_y = np.array(train.DEM)\r\n\r\nprepro_y = MinMaxScaler()\r\nprepro_y.fit(mat_y.reshape(len(mat_y),1))\r\n\r\nprepro = MinMaxScaler()\r\nprepro.fit(mat_train)\r\n\r\nprepro_test = MinMaxScaler()\r\nprepro_test.fit(mat_new)\r\n\r\ntrain_num_scale = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\r\ntest_num_scale  = pd.DataFrame(prepro_test.transform(mat_test),columns = col_train_bis)\r\n\r\ntrain[col_train] = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\r\ntest[col_train_bis]  = test_num_scale\r\n\r\n# List of features\r\nCOLUMNS = col_train\r\nFEATURES = col_train_bis\r\nLABEL = \"SalePrice\"\r\n\r\nFEATURES_CAT = col_train_cat\r\nprint (FEATURES_CAT)\r\n\r\nengineered_features = []\r\n\r\n\r\nfor continuous_feature in FEATURES:\r\n    engineered_features.append(\r\n        tf.contrib.layers.real_valued_column(continuous_feature))\r\n\r\nfor categorical_feature in FEATURES_CAT:\r\n    sparse_column = tf.contrib.layers.sparse_column_with_hash_bucket(\r\n        categorical_feature, hash_bucket_size=1000)\r\n    engineered_features.append(\r\n        tf.contrib.layers.embedding_column(sparse_id_column=sparse_column, dimension=16, combiner=\"sum\"))\r\nprint (engineered_features)\r\n\r\n# Training set and Prediction set with the features to predict\r\ntraining_set = train[FEATURES + FEATURES_CAT]\r\nprediction_set = train.DEM\r\nprint (training_set)\r\n\r\n# Train and Test\r\nx_train, x_test, y_train, y_test = train_test_split(training_set[FEATURES + FEATURES_CAT] ,\r\n                                                    prediction_set, test_size=0.33, random_state=42)\r\ny_train = pd.DataFrame(y_train, columns = [LABEL])\r\ntraining_set = pd.DataFrame(x_train, columns = FEATURES + FEATURES_CAT).merge(y_train, left_index = True, right_index = True)\r\n\r\n# Training for submission\r\ntraining_sub = training_set[FEATURES + FEATURES_CAT]\r\ntesting_sub = test[FEATURES + FEATURES_CAT]\r\n\r\n# Same thing but for the test set\r\ny_test = pd.DataFrame(y_test, columns = [LABEL])\r\ntesting_set = pd.DataFrame(x_test, columns = FEATURES + FEATURES_CAT).merge(y_test, left_index = True, right_index = True)\r\n\r\n\r\ntesting_set[FEATURES_CAT] = testing_set[FEATURES_CAT].applymap(str)\r\n\r\nprint (training_set[FEATURES_CAT])\r\n\r\n\r\ndef input_fn_new(data_set, training=True):\r\n    continuous_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\r\n\r\n    categorical_cols = {k: tf.SparseTensor(\r\n        indices=[[i, 0] for i in range(data_set[k].size)], values=data_set[k].values, dense_shape=[data_set[k].size, 1])\r\n    for k in FEATURES_CAT}\r\n\r\n    # Merges the two dictionaries into one.\r\n    feature_cols = dict(list(continuous_cols.items()) + list(categorical_cols.items()))\r\n    print(feature_cols)\r\n    if training == True:\r\n        # Converts the label column into a constant Tensor.\r\n        label = tf.constant(data_set[LABEL].values)\r\n\r\n        # Returns the feature columns and the label.\r\n        return feature_cols, label\r\n\r\n    return feature_cols\r\n\r\n# Model\r\nregressor = tf.contrib.learn.DNNRegressor(feature_columns = engineered_features,\r\n                                          activation_fn = tf.nn.relu, hidden_units=[200, 100, 50, 25, 12])\r\n\r\n\r\ntraining_set[FEATURES_CAT] = training_set[FEATURES_CAT].applymap(str)\r\ncategorical_cols = {k: tf.SparseTensor(\r\n      indices=[[i, 0] for i in range(training_set[k].size)],\r\n      values=training_set[k].values,\r\n    dense_shape=[training_set[k].size, 1])\r\n                      for k in FEATURES_CAT}\r\n\r\n# Error: \r\n\r\nWARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\S9E55~1.GHO\\AppData\\Local\\Temp\\tmpl279_r04\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 576, in merge_with\r\n    self.assert_same_rank(other)\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 621, in assert_same_rank\r\n    other))\r\nValueError: Shapes (0,) and (?, ?) must have the same rank\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 651, in with_rank\r\n    return self.merge_with(unknown_shape(ndims=rank))\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 582, in merge_with\r\n    raise ValueError(\"Shapes %s and %s are not compatible\" % (self, other))\r\nValueError: Shapes (0,) and (?, ?) are not compatible\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"prediction.py\", line 156, in <module>\r\n    for k in FEATURES_CAT}\r\n  File \"prediction.py\", line 156, in <dictcomp>\r\n    for k in FEATURES_CAT}\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\", line 131, in __init__\r\n    indices_shape = indices.get_shape().with_rank(2)\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 653, in with_rank\r\n    raise ValueError(\"Shape %s must have rank %d\" % (self, rank))\r\nValueError: Shape (0,) must have rank 2\r\n\r\n\r\n\r\n"}