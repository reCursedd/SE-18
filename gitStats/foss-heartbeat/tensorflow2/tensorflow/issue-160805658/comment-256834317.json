{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256834317", "html_url": "https://github.com/tensorflow/tensorflow/issues/2922#issuecomment-256834317", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2922", "id": 256834317, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NjgzNDMxNw==", "user": {"login": "ilblackdragon", "id": 175486, "node_id": "MDQ6VXNlcjE3NTQ4Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/175486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilblackdragon", "html_url": "https://github.com/ilblackdragon", "followers_url": "https://api.github.com/users/ilblackdragon/followers", "following_url": "https://api.github.com/users/ilblackdragon/following{/other_user}", "gists_url": "https://api.github.com/users/ilblackdragon/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilblackdragon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilblackdragon/subscriptions", "organizations_url": "https://api.github.com/users/ilblackdragon/orgs", "repos_url": "https://api.github.com/users/ilblackdragon/repos", "events_url": "https://api.github.com/users/ilblackdragon/events{/privacy}", "received_events_url": "https://api.github.com/users/ilblackdragon/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-28T04:35:32Z", "updated_at": "2016-10-28T04:35:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The way to pass anything to optimizer is by passing a <code>callable</code> function as optimizer, like this:</p>\n<pre><code>def get_optimizer():\n  def exp_decay(global_step):\n      return tf.train.exponential_decay(\n          learning_rate=0.1, global_step=global_step,\n          decay_steps=100, decay_rate=0.001)\n\n  # use customized decay function in learning_rate\n  return tf.train.AdagradOptimizer(learning_rate=exp_decay)\n\nclassifier = tf.contrib.learn.DNNClassifier(\n    hidden_units=[10, 20, 10], optimizer=get_optimizer, ...)\n</code></pre>", "body_text": "The way to pass anything to optimizer is by passing a callable function as optimizer, like this:\ndef get_optimizer():\n  def exp_decay(global_step):\n      return tf.train.exponential_decay(\n          learning_rate=0.1, global_step=global_step,\n          decay_steps=100, decay_rate=0.001)\n\n  # use customized decay function in learning_rate\n  return tf.train.AdagradOptimizer(learning_rate=exp_decay)\n\nclassifier = tf.contrib.learn.DNNClassifier(\n    hidden_units=[10, 20, 10], optimizer=get_optimizer, ...)", "body": "The way to pass anything to optimizer is by passing a `callable` function as optimizer, like this:\n\n```\ndef get_optimizer():\n  def exp_decay(global_step):\n      return tf.train.exponential_decay(\n          learning_rate=0.1, global_step=global_step,\n          decay_steps=100, decay_rate=0.001)\n\n  # use customized decay function in learning_rate\n  return tf.train.AdagradOptimizer(learning_rate=exp_decay)\n\nclassifier = tf.contrib.learn.DNNClassifier(\n    hidden_units=[10, 20, 10], optimizer=get_optimizer, ...)\n```\n"}