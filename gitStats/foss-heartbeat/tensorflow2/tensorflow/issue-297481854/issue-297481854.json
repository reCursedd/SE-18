{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17045", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17045/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17045/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17045/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17045", "id": 297481854, "node_id": "MDU6SXNzdWUyOTc0ODE4NTQ=", "number": 17045, "title": "Tensorflow 1.5.0 breaking previously built models", "user": {"login": "nikita68", "id": 15629332, "node_id": "MDQ6VXNlcjE1NjI5MzMy", "avatar_url": "https://avatars0.githubusercontent.com/u/15629332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikita68", "html_url": "https://github.com/nikita68", "followers_url": "https://api.github.com/users/nikita68/followers", "following_url": "https://api.github.com/users/nikita68/following{/other_user}", "gists_url": "https://api.github.com/users/nikita68/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikita68/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikita68/subscriptions", "organizations_url": "https://api.github.com/users/nikita68/orgs", "repos_url": "https://api.github.com/users/nikita68/repos", "events_url": "https://api.github.com/users/nikita68/events{/privacy}", "received_events_url": "https://api.github.com/users/nikita68/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-15T15:15:05Z", "updated_at": "2018-02-27T18:11:22Z", "closed_at": "2018-02-27T18:11:22Z", "author_association": "NONE", "body_html": "<p>Hello!</p>\n<p>I've recently updated to tensorflow version 1.5.0, and suddenly receive an error, that I can't decipher, for code that worked before (in version 1.4.1): <code>Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop</code></p>\n<p>I've also tried using the softmax_cross_entropy_with_logits function, but that still produced the same error. Here's the <a href=\"https://stackoverflow.com/questions/48713335/tensorflow-strided-slice-slicing-error-with-while-loop\" rel=\"nofollow\">stackoverflow</a> post, in case its a coding mistake on my part.<br>\nThe model is a seq2seq variation.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5.0 (previous 1.4.1)</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: Copy, paste and run the code</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib.rnn <span class=\"pl-k\">import</span> LSTMCell, LSTMStateTuple\n<span class=\"pl-k\">from</span> tensorflow.python.layers <span class=\"pl-k\">import</span> core <span class=\"pl-k\">as</span> layers_core\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">NOTE</span>: Time major</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---------------- Constants Manager ----------------------------</span>\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ConstantsManager</span>(<span class=\"pl-c1\">object</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input_dimensions</span>, <span class=\"pl-smi\">input_embedding_size</span>, <span class=\"pl-smi\">inputs_embedded</span>, <span class=\"pl-smi\">encoder_hidden_units</span>,\n                 <span class=\"pl-smi\">transducer_hidden_units</span>, <span class=\"pl-smi\">vocab_ids</span>, <span class=\"pl-smi\">input_block_size</span>, <span class=\"pl-smi\">beam_width</span>):\n        <span class=\"pl-k\">assert</span> transducer_hidden_units <span class=\"pl-k\">==</span> encoder_hidden_units, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Encoder and transducer have to have the same amount<span class=\"pl-pds\">'</span></span> \\\n                                                                <span class=\"pl-s\"><span class=\"pl-pds\">'</span>of hidden units<span class=\"pl-pds\">'</span></span>\n        <span class=\"pl-c1\">self</span>.input_dimensions <span class=\"pl-k\">=</span> input_dimensions\n        <span class=\"pl-c1\">self</span>.vocab_ids <span class=\"pl-k\">=</span> vocab_ids\n        <span class=\"pl-c1\">self</span>.<span class=\"pl-c1\">E_SYMBOL</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(<span class=\"pl-c1\">self</span>.vocab_ids)\n        <span class=\"pl-c1\">self</span>.vocab_ids.append(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>E_SYMBOL<span class=\"pl-pds\">'</span></span>)\n        <span class=\"pl-c1\">self</span>.<span class=\"pl-c1\">GO_SYMBOL</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(<span class=\"pl-c1\">self</span>.vocab_ids)\n        <span class=\"pl-c1\">self</span>.vocab_ids.append(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>GO_SYMBOL<span class=\"pl-pds\">'</span></span>)\n        <span class=\"pl-c1\">self</span>.vocab_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(<span class=\"pl-c1\">self</span>.vocab_ids)\n        <span class=\"pl-c1\">self</span>.input_embedding_size <span class=\"pl-k\">=</span> input_embedding_size\n        <span class=\"pl-c1\">self</span>.inputs_embedded <span class=\"pl-k\">=</span> inputs_embedded\n        <span class=\"pl-c1\">self</span>.encoder_hidden_units <span class=\"pl-k\">=</span> encoder_hidden_units\n        <span class=\"pl-c1\">self</span>.transducer_hidden_units <span class=\"pl-k\">=</span> transducer_hidden_units\n        <span class=\"pl-c1\">self</span>.input_block_size <span class=\"pl-k\">=</span> input_block_size\n        <span class=\"pl-c1\">self</span>.beam_width <span class=\"pl-k\">=</span> beam_width\n        <span class=\"pl-c1\">self</span>.batch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Cannot be increased, see paper</span>\n        <span class=\"pl-c1\">self</span>.log_prob_init_value <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ----------------- Model ---------------------------------------</span>\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Model</span>(<span class=\"pl-c1\">object</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">cons_manager</span>):\n        <span class=\"pl-c1\">self</span>.var_list <span class=\"pl-k\">=</span> []\n        <span class=\"pl-c1\">self</span>.cons_manager <span class=\"pl-k\">=</span> cons_manager\n        <span class=\"pl-c1\">self</span>.max_blocks, <span class=\"pl-c1\">self</span>.inputs_full_raw, <span class=\"pl-c1\">self</span>.transducer_list_outputs, <span class=\"pl-c1\">self</span>.start_block, <span class=\"pl-c1\">self</span>.encoder_hidden_init,\\\n            <span class=\"pl-c1\">self</span>.trans_hidden_init, <span class=\"pl-c1\">self</span>.logits, <span class=\"pl-c1\">self</span>.encoder_hidden_state_new, \\\n            <span class=\"pl-c1\">self</span>.transducer_hidden_state_new, <span class=\"pl-c1\">self</span>.train_saver <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.build_full_transducer()\n\n        <span class=\"pl-c1\">self</span>.targets, <span class=\"pl-c1\">self</span>.train_op, <span class=\"pl-c1\">self</span>.loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.build_training_step()\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">build_full_transducer</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>transducer_training<span class=\"pl-pds\">'</span></span>):\n\n            embeddings <span class=\"pl-k\">=</span> tf.Variable(tf.random_uniform([<span class=\"pl-c1\">self</span>.cons_manager.vocab_size,\n                                                        <span class=\"pl-c1\">self</span>.cons_manager.input_embedding_size], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>),\n                                     <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                     <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>embedding<span class=\"pl-pds\">'</span></span>)\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Inputs</span>\n            max_blocks <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>max_blocks<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> total amount of blocks to go through</span>\n            <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.cons_manager.inputs_embedded <span class=\"pl-k\">is</span> <span class=\"pl-c1\">True</span>:\n                input_type <span class=\"pl-k\">=</span> tf.float32\n            <span class=\"pl-k\">else</span>:\n                input_type <span class=\"pl-k\">=</span> tf.int32\n            inputs_full_raw <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">self</span>.cons_manager.batch_size,\n                                                    <span class=\"pl-c1\">self</span>.cons_manager.input_dimensions), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>input_type,\n                                             <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>inputs_full_raw<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> shape [max_time, 1, input_dims]</span>\n            transducer_list_outputs <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>,), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32,\n                                                     <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>transducer_list_outputs<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> amount to output per block</span>\n            start_block <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>transducer_start_block<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> where to start the input</span>\n\n            encoder_hidden_init <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.encoder_hidden_units), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                                 <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_hidden_init<span class=\"pl-pds\">'</span></span>)\n            trans_hidden_init <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.transducer_hidden_units), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                               <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>trans_hidden_init<span class=\"pl-pds\">'</span></span>)\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Temporary constants, maybe changed during inference</span>\n            end_symbol <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>end_symbol<span class=\"pl-pds\">'</span></span>,\n                                         <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-c1\">self</span>.cons_manager.vocab_size),\n                                         <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Turn inputs into tensor which is easily readable#</span>\n\n            inputs_full <span class=\"pl-k\">=</span> tf.reshape(inputs_full_raw, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.input_block_size,\n                                                             <span class=\"pl-c1\">self</span>.cons_manager.batch_size,\n                                                             <span class=\"pl-c1\">self</span>.cons_manager.input_dimensions])\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Outputs</span>\n            outputs_ta <span class=\"pl-k\">=</span> tf.TensorArray(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>max_blocks)\n\n            init_state <span class=\"pl-k\">=</span> (start_block, outputs_ta, encoder_hidden_init, trans_hidden_init)\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Initiate cells, <span class=\"pl-k\">NOTE</span>: if there is a future error, put these back inside the body function</span>\n            encoder_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.LSTMCell(<span class=\"pl-v\">num_units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.cons_manager.encoder_hidden_units)\n            transducer_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.LSTMCell(<span class=\"pl-c1\">self</span>.cons_manager.transducer_hidden_units)\n\n            <span class=\"pl-k\">def</span> <span class=\"pl-en\">cond</span>(<span class=\"pl-smi\">current_block</span>, <span class=\"pl-smi\">outputs_int</span>, <span class=\"pl-smi\">encoder_hidden</span>, <span class=\"pl-smi\">trans_hidden</span>):\n                <span class=\"pl-k\">return</span> current_block <span class=\"pl-k\">&lt;</span> start_block <span class=\"pl-k\">+</span> max_blocks\n\n            <span class=\"pl-k\">def</span> <span class=\"pl-en\">body</span>(<span class=\"pl-smi\">current_block</span>, <span class=\"pl-smi\">outputs_int</span>, <span class=\"pl-smi\">encoder_hidden</span>, <span class=\"pl-smi\">trans_hidden</span>):\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> --------------------- ENCODER ----------------------------------------------------------------------</span>\n                encoder_inputs <span class=\"pl-k\">=</span> inputs_full[current_block]\n                encoder_inputs_length <span class=\"pl-k\">=</span> [tf.shape(encoder_inputs)[<span class=\"pl-c1\">0</span>]]\n                encoder_hidden_state <span class=\"pl-k\">=</span> encoder_hidden\n\n                <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.cons_manager.inputs_embedded <span class=\"pl-k\">is</span> <span class=\"pl-c1\">True</span>:\n                    encoder_inputs_embedded <span class=\"pl-k\">=</span> encoder_inputs\n                <span class=\"pl-k\">else</span>:\n                    encoder_inputs <span class=\"pl-k\">=</span> tf.reshape(encoder_inputs, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.batch_size])\n                    encoder_inputs_embedded <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(embeddings, encoder_inputs)\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build model</span>\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build previous state</span>\n                encoder_hidden_c, encoder_hidden_h <span class=\"pl-k\">=</span> tf.split(encoder_hidden_state, <span class=\"pl-v\">num_or_size_splits</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n                encoder_hidden_c <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_c, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.encoder_hidden_units])\n                encoder_hidden_h <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_h, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.encoder_hidden_units])\n                encoder_hidden_state_t <span class=\"pl-k\">=</span> LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span>   encoder_outputs: [max_time, batch_size, num_units]</span>\n                encoder_outputs, encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(\n                    encoder_cell, encoder_inputs_embedded,\n                    <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>encoder_inputs_length, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                    <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>encoder_hidden_state_t)\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.</span>\n                encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n                encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_state_new,\n                                                      <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.encoder_hidden_units])\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> --------------------- TRANSDUCER --------------------------------------------------------------------</span>\n                encoder_raw_outputs <span class=\"pl-k\">=</span> encoder_outputs\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Save/load the state as one tensor, use encoder state as init if this is the first block</span>\n                trans_hidden_state <span class=\"pl-k\">=</span> tf.cond(current_block <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">0</span>, <span class=\"pl-k\">lambda</span>: trans_hidden, <span class=\"pl-k\">lambda</span>: encoder_hidden_state_new)\n                transducer_amount_outputs <span class=\"pl-k\">=</span> transducer_list_outputs[current_block <span class=\"pl-k\">-</span> start_block]\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Model building</span>\n                helper <span class=\"pl-k\">=</span> tf.contrib.seq2seq.GreedyEmbeddingHelper(\n                    <span class=\"pl-v\">embedding</span><span class=\"pl-k\">=</span>embeddings,\n                    <span class=\"pl-v\">start_tokens</span><span class=\"pl-k\">=</span>tf.tile([<span class=\"pl-c1\">self</span>.cons_manager.<span class=\"pl-c1\">GO_SYMBOL</span>],\n                                         [<span class=\"pl-c1\">self</span>.cons_manager.batch_size]),  <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">TODO</span>: check if this looks good</span>\n                    <span class=\"pl-v\">end_token</span><span class=\"pl-k\">=</span>end_symbol)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> vocab size, so that it doesn't prematurely end the decoding</span>\n\n                attention_states <span class=\"pl-k\">=</span> tf.transpose(encoder_raw_outputs,\n                                                [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> attention_states: [batch_size, max_time, num_units]</span>\n\n                attention_mechanism <span class=\"pl-k\">=</span> tf.contrib.seq2seq.LuongAttention(\n                    <span class=\"pl-c1\">self</span>.cons_manager.encoder_hidden_units, attention_states)\n\n                decoder_cell <span class=\"pl-k\">=</span> tf.contrib.seq2seq.AttentionWrapper(\n                    transducer_cell,\n                    attention_mechanism,\n                    <span class=\"pl-v\">attention_layer_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.cons_manager.transducer_hidden_units)\n\n                projection_layer <span class=\"pl-k\">=</span> layers_core.Dense(<span class=\"pl-c1\">self</span>.cons_manager.vocab_size, <span class=\"pl-v\">use_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build previous state</span>\n                trans_hidden_c, trans_hidden_h <span class=\"pl-k\">=</span> tf.split(trans_hidden_state, <span class=\"pl-v\">num_or_size_splits</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n                trans_hidden_c <span class=\"pl-k\">=</span> tf.reshape(trans_hidden_c, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.transducer_hidden_units])\n                trans_hidden_h <span class=\"pl-k\">=</span> tf.reshape(trans_hidden_h, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.transducer_hidden_units])\n                trans_hidden_state_t <span class=\"pl-k\">=</span> LSTMStateTuple(trans_hidden_c, trans_hidden_h)\n\n                decoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BasicDecoder(\n                    decoder_cell, helper,\n                    decoder_cell.zero_state(<span class=\"pl-c1\">1</span>, tf.float32).clone(<span class=\"pl-v\">cell_state</span><span class=\"pl-k\">=</span>trans_hidden_state_t),\n                    <span class=\"pl-v\">output_layer</span><span class=\"pl-k\">=</span>projection_layer)\n\n                outputs, transducer_hidden_state_new, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(decoder,\n                                                                                            <span class=\"pl-v\">output_time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                                                                                            <span class=\"pl-v\">maximum_iterations</span><span class=\"pl-k\">=</span>transducer_amount_outputs)\n                logits <span class=\"pl-k\">=</span> outputs.rnn_output  <span class=\"pl-c\"><span class=\"pl-c\">#</span> logits of shape [max_time,batch_size,vocab_size]</span>\n                decoder_prediction <span class=\"pl-k\">=</span> outputs.sample_id  <span class=\"pl-c\"><span class=\"pl-c\">#</span> For debugging</span>\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.</span>\n                transducer_hidden_state_new <span class=\"pl-k\">=</span> tf.concat(\n                    [transducer_hidden_state_new[<span class=\"pl-c1\">0</span>].c, transducer_hidden_state_new[<span class=\"pl-c1\">0</span>].h],\n                    <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n                transducer_hidden_state_new <span class=\"pl-k\">=</span> tf.reshape(transducer_hidden_state_new,\n                                                         <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.transducer_hidden_units])\n\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Note the outputs</span>\n                outputs_int <span class=\"pl-k\">=</span> outputs_int.write(current_block <span class=\"pl-k\">-</span> start_block, logits)\n\n                <span class=\"pl-k\">return</span> current_block <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, outputs_int, encoder_hidden_state_new, transducer_hidden_state_new\n\n            _, outputs_final, encoder_hidden_state_new, transducer_hidden_state_new <span class=\"pl-k\">=</span> \\\n                tf.while_loop(cond, body, init_state, <span class=\"pl-v\">parallel_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Process outputs</span>\n            outputs <span class=\"pl-k\">=</span> outputs_final.concat()\n            logits <span class=\"pl-k\">=</span> tf.reshape(\n                outputs,\n                <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.cons_manager.vocab_size))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> And now its [max_output_time, batch_size, vocab]</span>\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> For loading the model later on</span>\n            logits <span class=\"pl-k\">=</span> tf.identity(logits, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>logits<span class=\"pl-pds\">'</span></span>)\n            encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.identity(encoder_hidden_state_new, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_hidden_state_new<span class=\"pl-pds\">'</span></span>)\n            transducer_hidden_state_new <span class=\"pl-k\">=</span> tf.identity(transducer_hidden_state_new, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>transducer_hidden_state_new<span class=\"pl-pds\">'</span></span>)\n\n        train_saver <span class=\"pl-k\">=</span> tf.train.Saver()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> For now save everything</span>\n\n        <span class=\"pl-k\">return</span> max_blocks, inputs_full_raw, transducer_list_outputs, start_block, encoder_hidden_init,\\\n            trans_hidden_init, logits, encoder_hidden_state_new, transducer_hidden_state_new, train_saver\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">build_training_step</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        targets <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>,), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>targets<span class=\"pl-pds\">'</span></span>)\n        targets_one_hot <span class=\"pl-k\">=</span> tf.one_hot(targets, <span class=\"pl-v\">depth</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.cons_manager.vocab_size, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n        targets_one_hot <span class=\"pl-k\">=</span> tf.Print(targets_one_hot, [targets], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Targets: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">summarize</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)\n        targets_one_hot <span class=\"pl-k\">=</span> tf.Print(targets_one_hot, [tf.argmax(<span class=\"pl-c1\">self</span>.logits, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Argmax: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">summarize</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)\n\n        stepwise_cross_entropy <span class=\"pl-k\">=</span> tf.nn.softmax_cross_entropy_with_logits(<span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>targets_one_hot,\n                                                                         <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.logits)\n        loss <span class=\"pl-k\">=</span> tf.reduce_mean(stepwise_cross_entropy)\n        train_op <span class=\"pl-k\">=</span> tf.train.AdamOptimizer().minimize(loss)\n        <span class=\"pl-k\">return</span> targets, train_op, loss\n\n\nconstants_manager <span class=\"pl-k\">=</span> ConstantsManager(<span class=\"pl-v\">input_dimensions</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">input_embedding_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">11</span>, <span class=\"pl-v\">inputs_embedded</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                                     <span class=\"pl-v\">encoder_hidden_units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>, <span class=\"pl-v\">transducer_hidden_units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>, <span class=\"pl-v\">vocab_ids</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>],\n                                     <span class=\"pl-v\">input_block_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">beam_width</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>)\nmodel <span class=\"pl-k\">=</span> Model(<span class=\"pl-v\">cons_manager</span><span class=\"pl-k\">=</span>constants_manager)</pre></div>\n<p>I can try and make a smaller fail case if needed.</p>\n<p>Thanks!<br>\nNikita</p>", "body_text": "Hello!\nI've recently updated to tensorflow version 1.5.0, and suddenly receive an error, that I can't decipher, for code that worked before (in version 1.4.1): Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop\nI've also tried using the softmax_cross_entropy_with_logits function, but that still produced the same error. Here's the stackoverflow post, in case its a coding mistake on my part.\nThe model is a seq2seq variation.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): 1.5.0 (previous 1.4.1)\nPython version: 2.7\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: Copy, paste and run the code\n\nimport tensorflow as tf\nfrom tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\nfrom tensorflow.python.layers import core as layers_core\n\n# NOTE: Time major\n\n# ---------------- Constants Manager ----------------------------\nclass ConstantsManager(object):\n    def __init__(self, input_dimensions, input_embedding_size, inputs_embedded, encoder_hidden_units,\n                 transducer_hidden_units, vocab_ids, input_block_size, beam_width):\n        assert transducer_hidden_units == encoder_hidden_units, 'Encoder and transducer have to have the same amount' \\\n                                                                'of hidden units'\n        self.input_dimensions = input_dimensions\n        self.vocab_ids = vocab_ids\n        self.E_SYMBOL = len(self.vocab_ids)\n        self.vocab_ids.append('E_SYMBOL')\n        self.GO_SYMBOL = len(self.vocab_ids)\n        self.vocab_ids.append('GO_SYMBOL')\n        self.vocab_size = len(self.vocab_ids)\n        self.input_embedding_size = input_embedding_size\n        self.inputs_embedded = inputs_embedded\n        self.encoder_hidden_units = encoder_hidden_units\n        self.transducer_hidden_units = transducer_hidden_units\n        self.input_block_size = input_block_size\n        self.beam_width = beam_width\n        self.batch_size = 1  # Cannot be increased, see paper\n        self.log_prob_init_value = 0\n\n# ----------------- Model ---------------------------------------\n\n\nclass Model(object):\n    def __init__(self, cons_manager):\n        self.var_list = []\n        self.cons_manager = cons_manager\n        self.max_blocks, self.inputs_full_raw, self.transducer_list_outputs, self.start_block, self.encoder_hidden_init,\\\n            self.trans_hidden_init, self.logits, self.encoder_hidden_state_new, \\\n            self.transducer_hidden_state_new, self.train_saver = self.build_full_transducer()\n\n        self.targets, self.train_op, self.loss = self.build_training_step()\n\n    def build_full_transducer(self):\n        with tf.variable_scope('transducer_training'):\n\n            embeddings = tf.Variable(tf.random_uniform([self.cons_manager.vocab_size,\n                                                        self.cons_manager.input_embedding_size], -1.0, 1.0),\n                                     dtype=tf.float32,\n                                     name='embedding')\n            # Inputs\n            max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')  # total amount of blocks to go through\n            if self.cons_manager.inputs_embedded is True:\n                input_type = tf.float32\n            else:\n                input_type = tf.int32\n            inputs_full_raw = tf.placeholder(shape=(None, self.cons_manager.batch_size,\n                                                    self.cons_manager.input_dimensions), dtype=input_type,\n                                             name='inputs_full_raw')  # shape [max_time, 1, input_dims]\n            transducer_list_outputs = tf.placeholder(shape=(None,), dtype=tf.int32,\n                                                     name='transducer_list_outputs')  # amount to output per block\n            start_block = tf.placeholder(dtype=tf.int32, name='transducer_start_block')  # where to start the input\n\n            encoder_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.encoder_hidden_units), dtype=tf.float32,\n                                                 name='encoder_hidden_init')\n            trans_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.transducer_hidden_units), dtype=tf.float32,\n                                               name='trans_hidden_init')\n\n            # Temporary constants, maybe changed during inference\n            end_symbol = tf.get_variable(name='end_symbol',\n                                         initializer=tf.constant_initializer(self.cons_manager.vocab_size),\n                                         shape=(), dtype=tf.int32)\n\n            # Turn inputs into tensor which is easily readable#\n\n            inputs_full = tf.reshape(inputs_full_raw, shape=[-1, self.cons_manager.input_block_size,\n                                                             self.cons_manager.batch_size,\n                                                             self.cons_manager.input_dimensions])\n\n            # Outputs\n            outputs_ta = tf.TensorArray(dtype=tf.float32, size=max_blocks)\n\n            init_state = (start_block, outputs_ta, encoder_hidden_init, trans_hidden_init)\n\n            # Initiate cells, NOTE: if there is a future error, put these back inside the body function\n            encoder_cell = tf.contrib.rnn.LSTMCell(num_units=self.cons_manager.encoder_hidden_units)\n            transducer_cell = tf.contrib.rnn.LSTMCell(self.cons_manager.transducer_hidden_units)\n\n            def cond(current_block, outputs_int, encoder_hidden, trans_hidden):\n                return current_block < start_block + max_blocks\n\n            def body(current_block, outputs_int, encoder_hidden, trans_hidden):\n\n                # --------------------- ENCODER ----------------------------------------------------------------------\n                encoder_inputs = inputs_full[current_block]\n                encoder_inputs_length = [tf.shape(encoder_inputs)[0]]\n                encoder_hidden_state = encoder_hidden\n\n                if self.cons_manager.inputs_embedded is True:\n                    encoder_inputs_embedded = encoder_inputs\n                else:\n                    encoder_inputs = tf.reshape(encoder_inputs, shape=[-1, self.cons_manager.batch_size])\n                    encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n\n                # Build model\n\n                # Build previous state\n                encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\n                encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, self.cons_manager.encoder_hidden_units])\n                encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, self.cons_manager.encoder_hidden_units])\n                encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\n\n                #   encoder_outputs: [max_time, batch_size, num_units]\n                encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\n                    encoder_cell, encoder_inputs_embedded,\n                    sequence_length=encoder_inputs_length, time_major=True,\n                    dtype=tf.float32, initial_state=encoder_hidden_state_t)\n\n                # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\n                encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\n                encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new,\n                                                      shape=[2, -1, self.cons_manager.encoder_hidden_units])\n\n                # --------------------- TRANSDUCER --------------------------------------------------------------------\n                encoder_raw_outputs = encoder_outputs\n                # Save/load the state as one tensor, use encoder state as init if this is the first block\n                trans_hidden_state = tf.cond(current_block > 0, lambda: trans_hidden, lambda: encoder_hidden_state_new)\n                transducer_amount_outputs = transducer_list_outputs[current_block - start_block]\n\n                # Model building\n                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n                    embedding=embeddings,\n                    start_tokens=tf.tile([self.cons_manager.GO_SYMBOL],\n                                         [self.cons_manager.batch_size]),  # TODO: check if this looks good\n                    end_token=end_symbol)  # vocab size, so that it doesn't prematurely end the decoding\n\n                attention_states = tf.transpose(encoder_raw_outputs,\n                                                [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\n\n                attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n                    self.cons_manager.encoder_hidden_units, attention_states)\n\n                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n                    transducer_cell,\n                    attention_mechanism,\n                    attention_layer_size=self.cons_manager.transducer_hidden_units)\n\n                projection_layer = layers_core.Dense(self.cons_manager.vocab_size, use_bias=False)\n\n                # Build previous state\n                trans_hidden_c, trans_hidden_h = tf.split(trans_hidden_state, num_or_size_splits=2, axis=0)\n                trans_hidden_c = tf.reshape(trans_hidden_c, shape=[-1, self.cons_manager.transducer_hidden_units])\n                trans_hidden_h = tf.reshape(trans_hidden_h, shape=[-1, self.cons_manager.transducer_hidden_units])\n                trans_hidden_state_t = LSTMStateTuple(trans_hidden_c, trans_hidden_h)\n\n                decoder = tf.contrib.seq2seq.BasicDecoder(\n                    decoder_cell, helper,\n                    decoder_cell.zero_state(1, tf.float32).clone(cell_state=trans_hidden_state_t),\n                    output_layer=projection_layer)\n\n                outputs, transducer_hidden_state_new, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\n                                                                                            output_time_major=True,\n                                                                                            maximum_iterations=transducer_amount_outputs)\n                logits = outputs.rnn_output  # logits of shape [max_time,batch_size,vocab_size]\n                decoder_prediction = outputs.sample_id  # For debugging\n\n                # Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.\n                transducer_hidden_state_new = tf.concat(\n                    [transducer_hidden_state_new[0].c, transducer_hidden_state_new[0].h],\n                    axis=0)\n                transducer_hidden_state_new = tf.reshape(transducer_hidden_state_new,\n                                                         shape=[2, -1, self.cons_manager.transducer_hidden_units])\n\n\n                # Note the outputs\n                outputs_int = outputs_int.write(current_block - start_block, logits)\n\n                return current_block + 1, outputs_int, encoder_hidden_state_new, transducer_hidden_state_new\n\n            _, outputs_final, encoder_hidden_state_new, transducer_hidden_state_new = \\\n                tf.while_loop(cond, body, init_state, parallel_iterations=1)\n\n            # Process outputs\n            outputs = outputs_final.concat()\n            logits = tf.reshape(\n                outputs,\n                shape=(-1, 1, self.cons_manager.vocab_size))  # And now its [max_output_time, batch_size, vocab]\n\n            # For loading the model later on\n            logits = tf.identity(logits, name='logits')\n            encoder_hidden_state_new = tf.identity(encoder_hidden_state_new, name='encoder_hidden_state_new')\n            transducer_hidden_state_new = tf.identity(transducer_hidden_state_new, name='transducer_hidden_state_new')\n\n        train_saver = tf.train.Saver()  # For now save everything\n\n        return max_blocks, inputs_full_raw, transducer_list_outputs, start_block, encoder_hidden_init,\\\n            trans_hidden_init, logits, encoder_hidden_state_new, transducer_hidden_state_new, train_saver\n\n    def build_training_step(self):\n        targets = tf.placeholder(shape=(None,), dtype=tf.int32, name='targets')\n        targets_one_hot = tf.one_hot(targets, depth=self.cons_manager.vocab_size, dtype=tf.float32)\n\n        targets_one_hot = tf.Print(targets_one_hot, [targets], message='Targets: ', summarize=10)\n        targets_one_hot = tf.Print(targets_one_hot, [tf.argmax(self.logits, axis=2)], message='Argmax: ', summarize=10)\n\n        stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot,\n                                                                         logits=self.logits)\n        loss = tf.reduce_mean(stepwise_cross_entropy)\n        train_op = tf.train.AdamOptimizer().minimize(loss)\n        return targets, train_op, loss\n\n\nconstants_manager = ConstantsManager(input_dimensions=1, input_embedding_size=11, inputs_embedded=False,\n                                     encoder_hidden_units=100, transducer_hidden_units=100, vocab_ids=[0, 1, 2],\n                                     input_block_size=1, beam_width=5)\nmodel = Model(cons_manager=constants_manager)\nI can try and make a smaller fail case if needed.\nThanks!\nNikita", "body": "Hello!\r\n\r\nI've recently updated to tensorflow version 1.5.0, and suddenly receive an error, that I can't decipher, for code that worked before (in version 1.4.1): `Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop`\r\n\r\nI've also tried using the softmax_cross_entropy_with_logits function, but that still produced the same error. Here's the [stackoverflow](https://stackoverflow.com/questions/48713335/tensorflow-strided-slice-slicing-error-with-while-loop) post, in case its a coding mistake on my part.\r\nThe model is a seq2seq variation.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.5.0 (previous 1.4.1)\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Copy, paste and run the code\r\n\r\n\r\n``` python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\r\nfrom tensorflow.python.layers import core as layers_core\r\n\r\n# NOTE: Time major\r\n\r\n# ---------------- Constants Manager ----------------------------\r\nclass ConstantsManager(object):\r\n    def __init__(self, input_dimensions, input_embedding_size, inputs_embedded, encoder_hidden_units,\r\n                 transducer_hidden_units, vocab_ids, input_block_size, beam_width):\r\n        assert transducer_hidden_units == encoder_hidden_units, 'Encoder and transducer have to have the same amount' \\\r\n                                                                'of hidden units'\r\n        self.input_dimensions = input_dimensions\r\n        self.vocab_ids = vocab_ids\r\n        self.E_SYMBOL = len(self.vocab_ids)\r\n        self.vocab_ids.append('E_SYMBOL')\r\n        self.GO_SYMBOL = len(self.vocab_ids)\r\n        self.vocab_ids.append('GO_SYMBOL')\r\n        self.vocab_size = len(self.vocab_ids)\r\n        self.input_embedding_size = input_embedding_size\r\n        self.inputs_embedded = inputs_embedded\r\n        self.encoder_hidden_units = encoder_hidden_units\r\n        self.transducer_hidden_units = transducer_hidden_units\r\n        self.input_block_size = input_block_size\r\n        self.beam_width = beam_width\r\n        self.batch_size = 1  # Cannot be increased, see paper\r\n        self.log_prob_init_value = 0\r\n\r\n# ----------------- Model ---------------------------------------\r\n\r\n\r\nclass Model(object):\r\n    def __init__(self, cons_manager):\r\n        self.var_list = []\r\n        self.cons_manager = cons_manager\r\n        self.max_blocks, self.inputs_full_raw, self.transducer_list_outputs, self.start_block, self.encoder_hidden_init,\\\r\n            self.trans_hidden_init, self.logits, self.encoder_hidden_state_new, \\\r\n            self.transducer_hidden_state_new, self.train_saver = self.build_full_transducer()\r\n\r\n        self.targets, self.train_op, self.loss = self.build_training_step()\r\n\r\n    def build_full_transducer(self):\r\n        with tf.variable_scope('transducer_training'):\r\n\r\n            embeddings = tf.Variable(tf.random_uniform([self.cons_manager.vocab_size,\r\n                                                        self.cons_manager.input_embedding_size], -1.0, 1.0),\r\n                                     dtype=tf.float32,\r\n                                     name='embedding')\r\n            # Inputs\r\n            max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')  # total amount of blocks to go through\r\n            if self.cons_manager.inputs_embedded is True:\r\n                input_type = tf.float32\r\n            else:\r\n                input_type = tf.int32\r\n            inputs_full_raw = tf.placeholder(shape=(None, self.cons_manager.batch_size,\r\n                                                    self.cons_manager.input_dimensions), dtype=input_type,\r\n                                             name='inputs_full_raw')  # shape [max_time, 1, input_dims]\r\n            transducer_list_outputs = tf.placeholder(shape=(None,), dtype=tf.int32,\r\n                                                     name='transducer_list_outputs')  # amount to output per block\r\n            start_block = tf.placeholder(dtype=tf.int32, name='transducer_start_block')  # where to start the input\r\n\r\n            encoder_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.encoder_hidden_units), dtype=tf.float32,\r\n                                                 name='encoder_hidden_init')\r\n            trans_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.transducer_hidden_units), dtype=tf.float32,\r\n                                               name='trans_hidden_init')\r\n\r\n            # Temporary constants, maybe changed during inference\r\n            end_symbol = tf.get_variable(name='end_symbol',\r\n                                         initializer=tf.constant_initializer(self.cons_manager.vocab_size),\r\n                                         shape=(), dtype=tf.int32)\r\n\r\n            # Turn inputs into tensor which is easily readable#\r\n\r\n            inputs_full = tf.reshape(inputs_full_raw, shape=[-1, self.cons_manager.input_block_size,\r\n                                                             self.cons_manager.batch_size,\r\n                                                             self.cons_manager.input_dimensions])\r\n\r\n            # Outputs\r\n            outputs_ta = tf.TensorArray(dtype=tf.float32, size=max_blocks)\r\n\r\n            init_state = (start_block, outputs_ta, encoder_hidden_init, trans_hidden_init)\r\n\r\n            # Initiate cells, NOTE: if there is a future error, put these back inside the body function\r\n            encoder_cell = tf.contrib.rnn.LSTMCell(num_units=self.cons_manager.encoder_hidden_units)\r\n            transducer_cell = tf.contrib.rnn.LSTMCell(self.cons_manager.transducer_hidden_units)\r\n\r\n            def cond(current_block, outputs_int, encoder_hidden, trans_hidden):\r\n                return current_block < start_block + max_blocks\r\n\r\n            def body(current_block, outputs_int, encoder_hidden, trans_hidden):\r\n\r\n                # --------------------- ENCODER ----------------------------------------------------------------------\r\n                encoder_inputs = inputs_full[current_block]\r\n                encoder_inputs_length = [tf.shape(encoder_inputs)[0]]\r\n                encoder_hidden_state = encoder_hidden\r\n\r\n                if self.cons_manager.inputs_embedded is True:\r\n                    encoder_inputs_embedded = encoder_inputs\r\n                else:\r\n                    encoder_inputs = tf.reshape(encoder_inputs, shape=[-1, self.cons_manager.batch_size])\r\n                    encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\r\n\r\n                # Build model\r\n\r\n                # Build previous state\r\n                encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\r\n                encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, self.cons_manager.encoder_hidden_units])\r\n                encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, self.cons_manager.encoder_hidden_units])\r\n                encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\r\n\r\n                #   encoder_outputs: [max_time, batch_size, num_units]\r\n                encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\r\n                    encoder_cell, encoder_inputs_embedded,\r\n                    sequence_length=encoder_inputs_length, time_major=True,\r\n                    dtype=tf.float32, initial_state=encoder_hidden_state_t)\r\n\r\n                # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\r\n                encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\r\n                encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new,\r\n                                                      shape=[2, -1, self.cons_manager.encoder_hidden_units])\r\n\r\n                # --------------------- TRANSDUCER --------------------------------------------------------------------\r\n                encoder_raw_outputs = encoder_outputs\r\n                # Save/load the state as one tensor, use encoder state as init if this is the first block\r\n                trans_hidden_state = tf.cond(current_block > 0, lambda: trans_hidden, lambda: encoder_hidden_state_new)\r\n                transducer_amount_outputs = transducer_list_outputs[current_block - start_block]\r\n\r\n                # Model building\r\n                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\r\n                    embedding=embeddings,\r\n                    start_tokens=tf.tile([self.cons_manager.GO_SYMBOL],\r\n                                         [self.cons_manager.batch_size]),  # TODO: check if this looks good\r\n                    end_token=end_symbol)  # vocab size, so that it doesn't prematurely end the decoding\r\n\r\n                attention_states = tf.transpose(encoder_raw_outputs,\r\n                                                [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\r\n\r\n                attention_mechanism = tf.contrib.seq2seq.LuongAttention(\r\n                    self.cons_manager.encoder_hidden_units, attention_states)\r\n\r\n                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n                    transducer_cell,\r\n                    attention_mechanism,\r\n                    attention_layer_size=self.cons_manager.transducer_hidden_units)\r\n\r\n                projection_layer = layers_core.Dense(self.cons_manager.vocab_size, use_bias=False)\r\n\r\n                # Build previous state\r\n                trans_hidden_c, trans_hidden_h = tf.split(trans_hidden_state, num_or_size_splits=2, axis=0)\r\n                trans_hidden_c = tf.reshape(trans_hidden_c, shape=[-1, self.cons_manager.transducer_hidden_units])\r\n                trans_hidden_h = tf.reshape(trans_hidden_h, shape=[-1, self.cons_manager.transducer_hidden_units])\r\n                trans_hidden_state_t = LSTMStateTuple(trans_hidden_c, trans_hidden_h)\r\n\r\n                decoder = tf.contrib.seq2seq.BasicDecoder(\r\n                    decoder_cell, helper,\r\n                    decoder_cell.zero_state(1, tf.float32).clone(cell_state=trans_hidden_state_t),\r\n                    output_layer=projection_layer)\r\n\r\n                outputs, transducer_hidden_state_new, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\r\n                                                                                            output_time_major=True,\r\n                                                                                            maximum_iterations=transducer_amount_outputs)\r\n                logits = outputs.rnn_output  # logits of shape [max_time,batch_size,vocab_size]\r\n                decoder_prediction = outputs.sample_id  # For debugging\r\n\r\n                # Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.\r\n                transducer_hidden_state_new = tf.concat(\r\n                    [transducer_hidden_state_new[0].c, transducer_hidden_state_new[0].h],\r\n                    axis=0)\r\n                transducer_hidden_state_new = tf.reshape(transducer_hidden_state_new,\r\n                                                         shape=[2, -1, self.cons_manager.transducer_hidden_units])\r\n\r\n\r\n                # Note the outputs\r\n                outputs_int = outputs_int.write(current_block - start_block, logits)\r\n\r\n                return current_block + 1, outputs_int, encoder_hidden_state_new, transducer_hidden_state_new\r\n\r\n            _, outputs_final, encoder_hidden_state_new, transducer_hidden_state_new = \\\r\n                tf.while_loop(cond, body, init_state, parallel_iterations=1)\r\n\r\n            # Process outputs\r\n            outputs = outputs_final.concat()\r\n            logits = tf.reshape(\r\n                outputs,\r\n                shape=(-1, 1, self.cons_manager.vocab_size))  # And now its [max_output_time, batch_size, vocab]\r\n\r\n            # For loading the model later on\r\n            logits = tf.identity(logits, name='logits')\r\n            encoder_hidden_state_new = tf.identity(encoder_hidden_state_new, name='encoder_hidden_state_new')\r\n            transducer_hidden_state_new = tf.identity(transducer_hidden_state_new, name='transducer_hidden_state_new')\r\n\r\n        train_saver = tf.train.Saver()  # For now save everything\r\n\r\n        return max_blocks, inputs_full_raw, transducer_list_outputs, start_block, encoder_hidden_init,\\\r\n            trans_hidden_init, logits, encoder_hidden_state_new, transducer_hidden_state_new, train_saver\r\n\r\n    def build_training_step(self):\r\n        targets = tf.placeholder(shape=(None,), dtype=tf.int32, name='targets')\r\n        targets_one_hot = tf.one_hot(targets, depth=self.cons_manager.vocab_size, dtype=tf.float32)\r\n\r\n        targets_one_hot = tf.Print(targets_one_hot, [targets], message='Targets: ', summarize=10)\r\n        targets_one_hot = tf.Print(targets_one_hot, [tf.argmax(self.logits, axis=2)], message='Argmax: ', summarize=10)\r\n\r\n        stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot,\r\n                                                                         logits=self.logits)\r\n        loss = tf.reduce_mean(stepwise_cross_entropy)\r\n        train_op = tf.train.AdamOptimizer().minimize(loss)\r\n        return targets, train_op, loss\r\n\r\n\r\nconstants_manager = ConstantsManager(input_dimensions=1, input_embedding_size=11, inputs_embedded=False,\r\n                                     encoder_hidden_units=100, transducer_hidden_units=100, vocab_ids=[0, 1, 2],\r\n                                     input_block_size=1, beam_width=5)\r\nmodel = Model(cons_manager=constants_manager)\r\n```\r\nI can try and make a smaller fail case if needed.\r\n\r\nThanks!\r\nNikita"}