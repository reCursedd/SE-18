{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9545", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9545/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9545/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9545/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9545", "id": 225287288, "node_id": "MDU6SXNzdWUyMjUyODcyODg=", "number": 9545, "title": "Duplicate variable shown in Tensorboard expected?", "user": {"login": "ethanluoyc", "id": 6040760, "node_id": "MDQ6VXNlcjYwNDA3NjA=", "avatar_url": "https://avatars3.githubusercontent.com/u/6040760?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ethanluoyc", "html_url": "https://github.com/ethanluoyc", "followers_url": "https://api.github.com/users/ethanluoyc/followers", "following_url": "https://api.github.com/users/ethanluoyc/following{/other_user}", "gists_url": "https://api.github.com/users/ethanluoyc/gists{/gist_id}", "starred_url": "https://api.github.com/users/ethanluoyc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ethanluoyc/subscriptions", "organizations_url": "https://api.github.com/users/ethanluoyc/orgs", "repos_url": "https://api.github.com/users/ethanluoyc/repos", "events_url": "https://api.github.com/users/ethanluoyc/events{/privacy}", "received_events_url": "https://api.github.com/users/ethanluoyc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284285184, "node_id": "MDU6TGFiZWwyODQyODUxODQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:tensorboard", "name": "comp:tensorboard", "color": "0052cc", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "chihuahua", "id": 4221553, "node_id": "MDQ6VXNlcjQyMjE1NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/4221553?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chihuahua", "html_url": "https://github.com/chihuahua", "followers_url": "https://api.github.com/users/chihuahua/followers", "following_url": "https://api.github.com/users/chihuahua/following{/other_user}", "gists_url": "https://api.github.com/users/chihuahua/gists{/gist_id}", "starred_url": "https://api.github.com/users/chihuahua/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chihuahua/subscriptions", "organizations_url": "https://api.github.com/users/chihuahua/orgs", "repos_url": "https://api.github.com/users/chihuahua/repos", "events_url": "https://api.github.com/users/chihuahua/events{/privacy}", "received_events_url": "https://api.github.com/users/chihuahua/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "chihuahua", "id": 4221553, "node_id": "MDQ6VXNlcjQyMjE1NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/4221553?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chihuahua", "html_url": "https://github.com/chihuahua", "followers_url": "https://api.github.com/users/chihuahua/followers", "following_url": "https://api.github.com/users/chihuahua/following{/other_user}", "gists_url": "https://api.github.com/users/chihuahua/gists{/gist_id}", "starred_url": "https://api.github.com/users/chihuahua/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chihuahua/subscriptions", "organizations_url": "https://api.github.com/users/chihuahua/orgs", "repos_url": "https://api.github.com/users/chihuahua/repos", "events_url": "https://api.github.com/users/chihuahua/events{/privacy}", "received_events_url": "https://api.github.com/users/chihuahua/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 31, "created_at": "2017-04-29T21:43:08Z", "updated_at": "2018-11-22T15:50:25Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nMacOS Sierra 12.12.4</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\npip</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.1.0 (CPU)</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am trying to implement E2C (available from <a href=\"https://arxiv.org/pdf/1506.07365.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1506.07365.pdf</a>). Basically it is a neural network that is used for learning a transition model using neural networks. In the training set I have data of the form (X_t, X_t+1) where both X_t and X_t+1 needs to be transformed by an encoding network (e.g. a variational autoencoder). I use the following snippet for creating the encoding network (adapted from <a href=\"https://github.com/ericjang/e2c\">https://github.com/ericjang/e2c</a>):</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">encode</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">share</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n        fc <span class=\"pl-k\">=</span> tf.contrib.layers.fully_connected\n        <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Encoder<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>share):\n            l1 <span class=\"pl-k\">=</span> fc(x, <span class=\"pl-c1\">400</span>, <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>tf.orthogonal_initializer(),\n                    <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.relu)\n            l2 <span class=\"pl-k\">=</span> fc(l1, <span class=\"pl-c1\">100</span>, <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>tf.orthogonal_initializer(),\n                    <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.relu)\n            <span class=\"pl-k\">return</span> l2\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">decode</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">z</span>, <span class=\"pl-smi\">share</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n        fc <span class=\"pl-k\">=</span> tf.contrib.layers.fully_connected\n        <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Decoder<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>share):\n            l1 <span class=\"pl-k\">=</span> fc(z, <span class=\"pl-c1\">100</span>, <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>tf.orthogonal_initializer(<span class=\"pl-c1\">1.1</span>),\n                    <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.relu)\n            l2 <span class=\"pl-k\">=</span> fc(l1, <span class=\"pl-c1\">400</span>, <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>tf.orthogonal_initializer(<span class=\"pl-c1\">1.1</span>),\n                    <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.relu)\n\n            <span class=\"pl-k\">return</span> fc(l2, <span class=\"pl-c1\">self</span>.x_dim,\n                      <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>tf.orthogonal_initializer(<span class=\"pl-c1\">1.1</span>),\n                      <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.sigmoid)</pre></div>\n<p>Then I would use something like</p>\n<div class=\"highlight highlight-source-python\"><pre>h_enc_t <span class=\"pl-k\">=</span> encoder(X_t)\nh_enc_t_next <span class=\"pl-k\">=</span> encoder(X_{t<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>}, <span class=\"pl-v\">share</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<p>to create the encoded output for the model.</p>\n<p>The problem is that when visualizing this on Tensorboard, while it is sharing the variables by setting <code>share=True</code> for the variable scope, on the graph visulisation you will have <code>Encoder</code> and <code>Encoder_1</code> instead of just a <code>Decoder</code> scope. Of course they took different input since we need to transform X_t and X_t+1, but shouldn't the network be wrapped in the same scope since underneath we are reusing the same weights? I wonder if it is a feature to have <code>Encoder_1</code> and <code>Encoder</code> separately or it is a limitation of the variable scoping. The problem is illustrated in the screenshot below, you will see duplicates for 'Encoder' 'SampleQPhi\" etc:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/6040760/25559064/98fecc5a-2d2b-11e7-8669-00b1227abf17.png\"><img src=\"https://cloud.githubusercontent.com/assets/6040760/25559064/98fecc5a-2d2b-11e7-8669-00b1227abf17.png\" alt=\"graph-run\" style=\"max-width:100%;\"></a></p>\n<p>However, I would expect something like this (as appeared in the paper) to be a more reasonable visualization (h_enc) with input x_t and x_t+1 are the same network:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/6040760/25565322/fc04ab8a-2dbc-11e7-9876-5e823a3bf47b.png\"><img width=\"546\" alt=\"screenshot 2017-04-30 15 51 01\" src=\"https://cloud.githubusercontent.com/assets/6040760/25565322/fc04ab8a-2dbc-11e7-9876-5e823a3bf47b.png\" style=\"max-width:100%;\"></a></p>\n<p>Many thanks in advance!</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nMacOS Sierra 12.12.4\nTensorFlow installed from (source or binary):\npip\nTensorFlow version (use command below):\n1.1.0 (CPU)\n\nDescribe the problem\nI am trying to implement E2C (available from https://arxiv.org/pdf/1506.07365.pdf). Basically it is a neural network that is used for learning a transition model using neural networks. In the training set I have data of the form (X_t, X_t+1) where both X_t and X_t+1 needs to be transformed by an encoding network (e.g. a variational autoencoder). I use the following snippet for creating the encoding network (adapted from https://github.com/ericjang/e2c):\n    def encode(self, x, share=None):\n        fc = tf.contrib.layers.fully_connected\n        with tf.variable_scope('Encoder', reuse=share):\n            l1 = fc(x, 400, weights_initializer=tf.orthogonal_initializer(),\n                    activation_fn=tf.nn.relu)\n            l2 = fc(l1, 100, weights_initializer=tf.orthogonal_initializer(),\n                    activation_fn=tf.nn.relu)\n            return l2\n\n    def decode(self, z, share=None):\n        fc = tf.contrib.layers.fully_connected\n        with tf.variable_scope(\"Decoder\", reuse=share):\n            l1 = fc(z, 100, weights_initializer=tf.orthogonal_initializer(1.1),\n                    activation_fn=tf.nn.relu)\n            l2 = fc(l1, 400, weights_initializer=tf.orthogonal_initializer(1.1),\n                    activation_fn=tf.nn.relu)\n\n            return fc(l2, self.x_dim,\n                      weights_initializer=tf.orthogonal_initializer(1.1),\n                      activation_fn=tf.nn.sigmoid)\nThen I would use something like\nh_enc_t = encoder(X_t)\nh_enc_t_next = encoder(X_{t+1}, share=True)\nto create the encoded output for the model.\nThe problem is that when visualizing this on Tensorboard, while it is sharing the variables by setting share=True for the variable scope, on the graph visulisation you will have Encoder and Encoder_1 instead of just a Decoder scope. Of course they took different input since we need to transform X_t and X_t+1, but shouldn't the network be wrapped in the same scope since underneath we are reusing the same weights? I wonder if it is a feature to have Encoder_1 and Encoder separately or it is a limitation of the variable scoping. The problem is illustrated in the screenshot below, you will see duplicates for 'Encoder' 'SampleQPhi\" etc:\n\nHowever, I would expect something like this (as appeared in the paper) to be a more reasonable visualization (h_enc) with input x_t and x_t+1 are the same network:\n\nMany thanks in advance!", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMacOS Sierra 12.12.4\r\n- **TensorFlow installed from (source or binary)**:\r\npip\r\n- **TensorFlow version (use command below)**:\r\n1.1.0 (CPU)\r\n### Describe the problem\r\nI am trying to implement E2C (available from https://arxiv.org/pdf/1506.07365.pdf). Basically it is a neural network that is used for learning a transition model using neural networks. In the training set I have data of the form (X_t, X_t+1) where both X_t and X_t+1 needs to be transformed by an encoding network (e.g. a variational autoencoder). I use the following snippet for creating the encoding network (adapted from https://github.com/ericjang/e2c):\r\n\r\n```python\r\n    def encode(self, x, share=None):\r\n        fc = tf.contrib.layers.fully_connected\r\n        with tf.variable_scope('Encoder', reuse=share):\r\n            l1 = fc(x, 400, weights_initializer=tf.orthogonal_initializer(),\r\n                    activation_fn=tf.nn.relu)\r\n            l2 = fc(l1, 100, weights_initializer=tf.orthogonal_initializer(),\r\n                    activation_fn=tf.nn.relu)\r\n            return l2\r\n\r\n    def decode(self, z, share=None):\r\n        fc = tf.contrib.layers.fully_connected\r\n        with tf.variable_scope(\"Decoder\", reuse=share):\r\n            l1 = fc(z, 100, weights_initializer=tf.orthogonal_initializer(1.1),\r\n                    activation_fn=tf.nn.relu)\r\n            l2 = fc(l1, 400, weights_initializer=tf.orthogonal_initializer(1.1),\r\n                    activation_fn=tf.nn.relu)\r\n\r\n            return fc(l2, self.x_dim,\r\n                      weights_initializer=tf.orthogonal_initializer(1.1),\r\n                      activation_fn=tf.nn.sigmoid)\r\n```\r\nThen I would use something like\r\n\r\n```python\r\nh_enc_t = encoder(X_t)\r\nh_enc_t_next = encoder(X_{t+1}, share=True)\r\n```\r\nto create the encoded output for the model.\r\n\r\nThe problem is that when visualizing this on Tensorboard, while it is sharing the variables by setting `share=True` for the variable scope, on the graph visulisation you will have `Encoder` and `Encoder_1` instead of just a `Decoder` scope. Of course they took different input since we need to transform X_t and X_t+1, but shouldn't the network be wrapped in the same scope since underneath we are reusing the same weights? I wonder if it is a feature to have `Encoder_1` and `Encoder` separately or it is a limitation of the variable scoping. The problem is illustrated in the screenshot below, you will see duplicates for 'Encoder' 'SampleQPhi\" etc:\r\n\r\n![graph-run](https://cloud.githubusercontent.com/assets/6040760/25559064/98fecc5a-2d2b-11e7-8669-00b1227abf17.png)\r\n\r\nHowever, I would expect something like this (as appeared in the paper) to be a more reasonable visualization (h_enc) with input x_t and x_t+1 are the same network:\r\n\r\n<img width=\"546\" alt=\"screenshot 2017-04-30 15 51 01\" src=\"https://cloud.githubusercontent.com/assets/6040760/25565322/fc04ab8a-2dbc-11e7-9876-5e823a3bf47b.png\">\r\n\r\n\r\nMany thanks in advance!"}