{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5187", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5187/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5187/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5187/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5187", "id": 185019016, "node_id": "MDU6SXNzdWUxODUwMTkwMTY=", "number": 5187, "title": "Reading data from tfrecords error", "user": {"login": "soccergame", "id": 23046251, "node_id": "MDQ6VXNlcjIzMDQ2MjUx", "avatar_url": "https://avatars3.githubusercontent.com/u/23046251?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soccergame", "html_url": "https://github.com/soccergame", "followers_url": "https://api.github.com/users/soccergame/followers", "following_url": "https://api.github.com/users/soccergame/following{/other_user}", "gists_url": "https://api.github.com/users/soccergame/gists{/gist_id}", "starred_url": "https://api.github.com/users/soccergame/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soccergame/subscriptions", "organizations_url": "https://api.github.com/users/soccergame/orgs", "repos_url": "https://api.github.com/users/soccergame/repos", "events_url": "https://api.github.com/users/soccergame/events{/privacy}", "received_events_url": "https://api.github.com/users/soccergame/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-10-25T04:57:17Z", "updated_at": "2016-11-11T17:44:56Z", "closed_at": "2016-11-11T17:44:56Z", "author_association": "NONE", "body_html": "<p>When I use tf to read traing and testing data from tfrecords, it runed for a while, then stoped with errors like this (this is testing net error, traing net is the same problem):<br>\nINFO:tensorflow:Executing eval_op 8133/15916<br>\nINFO:tensorflow:Executing eval_op 8134/15916<br>\nINFO:tensorflow:Executing eval_op 8135/15916<br>\nINFO:tensorflow:Executing eval_op 8136/15916<br>\nINFO:tensorflow:Executing eval_op 8137/15916<br>\nINFO:tensorflow:Executing eval_op 8138/15916<br>\nINFO:tensorflow:Executing eval_op 8139/15916<br>\nINFO:tensorflow:Executing eval_op 8140/15916<br>\nINFO:tensorflow:Executing eval_op 8141/15916<br>\nINFO:tensorflow:Executing eval_op 8142/15916<br>\nINFO:tensorflow:Executing eval_op 8143/15916<br>\nINFO:tensorflow:Executing eval_op 8144/15916<br>\nINFO:tensorflow:Executing eval_op 8145/15916<br>\nINFO:tensorflow:Executing eval_op 8146/15916<br>\nINFO:tensorflow:Executing eval_op 8147/15916<br>\nINFO:tensorflow:Executing eval_op 8148/15916<br>\nINFO:tensorflow:Executing eval_op 8149/15916<br>\nINFO:tensorflow:Executing eval_op 8150/15916<br>\nINFO:tensorflow:Executing eval_op 8151/15916<br>\nINFO:tensorflow:Executing eval_op 8152/15916<br>\nINFO:tensorflow:Executing eval_op 8153/15916<br>\nINFO:tensorflow:Executing eval_op 8154/15916<br>\nINFO:tensorflow:Executing eval_op 8155/15916<br>\nINFO:tensorflow:Executing eval_op 8156/15916<br>\nINFO:tensorflow:Error reported to Coordinator: &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt;, Input to reshape is a tensor with 836310 values, but the requested shape has 65712<br>\n[[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](case_1/If_2/Merge, Reshape_14/shape)]]<br>\n[[Node: eval_image/Mul/_3773 = _Recv<a href=\"\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_eval_image/Mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"</a>]]<br>\nCaused by op u'Reshape_14', defined at:<br>\nFile \"eval_image_classifier.py\", line 210, in <br>\ntf.app.run()<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run<br>\nsys.exit(main(sys.argv[:1] + flags_passthrough))<br>\nFile \"eval_image_classifier.py\", line 130, in main<br>\ncommon_queue_min=FLAGS.batch_size)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in <strong>init</strong><br>\ntensors = dataset.decoder.decode(data, items)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode<br>\noutputs.append(handler.tensors_to_item(keys_to_tensors))<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item<br>\nimage = self._decode(image_buffer, image_format)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 328, in _decode<br>\nimage = array_ops.reshape(image, self._shape)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py\", line 1758, in reshape<br>\nname=name)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2333, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1252, in <strong>init</strong><br>\nself._traceback = _extract_stack()</p>\n<p>Traceback (most recent call last):<br>\nFile \"eval_image_classifier.py\", line 210, in <br>\ntf.app.run()<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run<br>\nsys.exit(main(sys.argv[:1] + flags_passthrough))<br>\nFile \"eval_image_classifier.py\", line 206, in main<br>\nvariables_to_restore=variables_to_restore)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/evaluation.py\", line 323, in evaluate_once<br>\nglobal_step=global_step)<br>\nFile \"/usr/lib/python2.7/contextlib.py\", line 35, in <strong>exit</strong><br>\nself.gen.throw(type, value, traceback)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py\", line 969, in managed_session<br>\nself.stop(close_summary_writer=close_summary_writer)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py\", line 797, in stop<br>\nstop_grace_period_secs=self._stop_grace_secs)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/training/coordinator.py\", line 386, in join<br>\nsix.reraise(*self._exc_info_to_raise)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/training/queue_runner.py\", line 225, in _run<br>\nsess.run(enqueue_op)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 717, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 915, in _run<br>\nfeed_dict_string, options, run_metadata)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 965, in _do_run<br>\ntarget_list, options, run_metadata)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 985, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 836310 values, but the requested shape has 65712<br>\n[[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](case_1/If_2/Merge, Reshape_14/shape)]]<br>\n[[Node: eval_image/Mul/_3773 = _Recv<a href=\"\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_eval_image/Mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"</a>]]<br>\nCaused by op u'Reshape_14', defined at:<br>\nFile \"eval_image_classifier.py\", line 210, in <br>\ntf.app.run()<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run<br>\nsys.exit(main(sys.argv[:1] + flags_passthrough))<br>\nFile \"eval_image_classifier.py\", line 130, in main<br>\ncommon_queue_min=FLAGS.batch_size)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in <strong>init</strong><br>\ntensors = dataset.decoder.decode(data, items)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode<br>\noutputs.append(handler.tensors_to_item(keys_to_tensors))<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item<br>\nimage = self._decode(image_buffer, image_format)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 328, in _decode<br>\nimage = array_ops.reshape(image, self._shape)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py\", line 1758, in reshape<br>\nname=name)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2333, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1252, in <strong>init</strong><br>\nself._traceback = _extract_stack()</p>\n<h6></h6>\n<p>while I wrote the tfrecords like this:</p>\n<p>def _process_image(file_path, label, coder, logfile=None):<br>\n\"\"\"Process a single image file.</p>\n<pre><code>Args:\n    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\nReturns:\n    image_buffer: string, JPEG encoding of RGB image.\n    height: integer, image height in pixels.\n    width: integer, image width in pixels.\n\"\"\"\n# Clean the dirty data.\nif _is_not_jpg(file_path):\n    print('Image %s is not a JPEG image, and its label is %d' % (file_path, label))\n    if logfile:\n        logfile.write('Image %s is not a JPEG image, and its label is %d\\n' % (file_path, label))\n    return -1, None\n\nif not tf.gfile.Exists(file_path):\n    print('Image %s is not exist, and its label is %d' % (file_path, label))\n    if logfile:\n        logfile.write('Image %s is not exist, and its label is %d\\n' % (file_path, label))\n    return -1, None\n\n# Read the image file.\nimage_data = tf.gfile.FastGFile(file_path, 'r').read()\n\n# Decode the RGB JPEG.\nheight, width, channels = coder.read_image_dims(image_data)\n\n# Check that image converted right\nif height != 148 and width != 148 and channels != 3:\n    print('The size of image %s is wrong, which is h[%d] w[%d] c[%d], but requested h[148] w[148] c[148]\\n' % (file_path, height, width, channels))\n    if logfile:\n        logfile.write('The size of image %s is wrong, which is h[%d] w[%d], but requested h[148] w[148] c[148]\\n' % (file_path, height, width, channels))\n    return -1, None\n\nreturn 0, _convert_to_example(image_data, height, width, channels, 'jpg', label)\n</code></pre>\n<p>def _process_image_files_batch(coder, thread_index, ranges, name, filenames, labels, num_shards, logfile=None):</p>\n<pre><code>num_threads = len(ranges)\nassert not num_shards % num_threads\nnum_shards_per_batch = int(num_shards / num_threads)\n\nshard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], num_shards_per_batch + 1).astype(int)\nnum_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n\ncounter = 0\nfor s in xrange(num_shards_per_batch):\n    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n    shard = thread_index * num_shards_per_batch + s\n    output_file = '%s-%.5d-of-%.5d.tfrecord' % (name, shard, num_shards)\n    writer = tf.python_io.TFRecordWriter(output_file)\n\n    shard_counter = 0\n    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n    for i in files_in_shard:\n        file_path = filenames[i]\n        label = labels[i]\n\n        errCode, example = _process_image(file_path, label, coder, logfile)\n        if -1 == errCode:\n            continue\n\n        writer.write(example.SerializeToString())\n        shard_counter += 1\n        counter += 1\n\n        if not counter % 1000:\n            print('%s [thread %d]: Processed %d of %d images in thread batch.' % (datetime.now(), thread_index, counter, num_files_in_thread))\n            sys.stdout.flush()\n\n    print('%s [thread %d]: Wrote %d images to %s' % (datetime.now(), thread_index, shard_counter, output_file))\n    sys.stdout.flush()\n    shard_counter = 0\nprint('%s [thread %d]: Wrote %d images to %d shards.' % (datetime.now(), thread_index, counter, num_files_in_thread))\nsys.stdout.flush()\n</code></pre>\n<h6></h6>\n<p>So I checked all the images as the same shape and same size of 65712, and write them by jpg format, Ibut I don't know where the problem is.</p>", "body_text": "When I use tf to read traing and testing data from tfrecords, it runed for a while, then stoped with errors like this (this is testing net error, traing net is the same problem):\nINFO:tensorflow:Executing eval_op 8133/15916\nINFO:tensorflow:Executing eval_op 8134/15916\nINFO:tensorflow:Executing eval_op 8135/15916\nINFO:tensorflow:Executing eval_op 8136/15916\nINFO:tensorflow:Executing eval_op 8137/15916\nINFO:tensorflow:Executing eval_op 8138/15916\nINFO:tensorflow:Executing eval_op 8139/15916\nINFO:tensorflow:Executing eval_op 8140/15916\nINFO:tensorflow:Executing eval_op 8141/15916\nINFO:tensorflow:Executing eval_op 8142/15916\nINFO:tensorflow:Executing eval_op 8143/15916\nINFO:tensorflow:Executing eval_op 8144/15916\nINFO:tensorflow:Executing eval_op 8145/15916\nINFO:tensorflow:Executing eval_op 8146/15916\nINFO:tensorflow:Executing eval_op 8147/15916\nINFO:tensorflow:Executing eval_op 8148/15916\nINFO:tensorflow:Executing eval_op 8149/15916\nINFO:tensorflow:Executing eval_op 8150/15916\nINFO:tensorflow:Executing eval_op 8151/15916\nINFO:tensorflow:Executing eval_op 8152/15916\nINFO:tensorflow:Executing eval_op 8153/15916\nINFO:tensorflow:Executing eval_op 8154/15916\nINFO:tensorflow:Executing eval_op 8155/15916\nINFO:tensorflow:Executing eval_op 8156/15916\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.InvalidArgumentError'>, Input to reshape is a tensor with 836310 values, but the requested shape has 65712\n[[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](case_1/If_2/Merge, Reshape_14/shape)]]\n[[Node: eval_image/Mul/_3773 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_eval_image/Mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nCaused by op u'Reshape_14', defined at:\nFile \"eval_image_classifier.py\", line 210, in \ntf.app.run()\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\nsys.exit(main(sys.argv[:1] + flags_passthrough))\nFile \"eval_image_classifier.py\", line 130, in main\ncommon_queue_min=FLAGS.batch_size)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in init\ntensors = dataset.decoder.decode(data, items)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\noutputs.append(handler.tensors_to_item(keys_to_tensors))\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\nimage = self._decode(image_buffer, image_format)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 328, in _decode\nimage = array_ops.reshape(image, self._shape)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py\", line 1758, in reshape\nname=name)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\nop_def=op_def)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2333, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1252, in init\nself._traceback = _extract_stack()\nTraceback (most recent call last):\nFile \"eval_image_classifier.py\", line 210, in \ntf.app.run()\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\nsys.exit(main(sys.argv[:1] + flags_passthrough))\nFile \"eval_image_classifier.py\", line 206, in main\nvariables_to_restore=variables_to_restore)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/evaluation.py\", line 323, in evaluate_once\nglobal_step=global_step)\nFile \"/usr/lib/python2.7/contextlib.py\", line 35, in exit\nself.gen.throw(type, value, traceback)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py\", line 969, in managed_session\nself.stop(close_summary_writer=close_summary_writer)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py\", line 797, in stop\nstop_grace_period_secs=self._stop_grace_secs)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/training/coordinator.py\", line 386, in join\nsix.reraise(*self._exc_info_to_raise)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/training/queue_runner.py\", line 225, in _run\nsess.run(enqueue_op)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 717, in run\nrun_metadata_ptr)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 915, in _run\nfeed_dict_string, options, run_metadata)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 965, in _do_run\ntarget_list, options, run_metadata)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 985, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 836310 values, but the requested shape has 65712\n[[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](case_1/If_2/Merge, Reshape_14/shape)]]\n[[Node: eval_image/Mul/_3773 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_eval_image/Mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nCaused by op u'Reshape_14', defined at:\nFile \"eval_image_classifier.py\", line 210, in \ntf.app.run()\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\nsys.exit(main(sys.argv[:1] + flags_passthrough))\nFile \"eval_image_classifier.py\", line 130, in main\ncommon_queue_min=FLAGS.batch_size)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in init\ntensors = dataset.decoder.decode(data, items)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\noutputs.append(handler.tensors_to_item(keys_to_tensors))\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\nimage = self._decode(image_buffer, image_format)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 328, in _decode\nimage = array_ops.reshape(image, self._shape)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py\", line 1758, in reshape\nname=name)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\nop_def=op_def)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2333, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1252, in init\nself._traceback = _extract_stack()\n\nwhile I wrote the tfrecords like this:\ndef _process_image(file_path, label, coder, logfile=None):\n\"\"\"Process a single image file.\nArgs:\n    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\nReturns:\n    image_buffer: string, JPEG encoding of RGB image.\n    height: integer, image height in pixels.\n    width: integer, image width in pixels.\n\"\"\"\n# Clean the dirty data.\nif _is_not_jpg(file_path):\n    print('Image %s is not a JPEG image, and its label is %d' % (file_path, label))\n    if logfile:\n        logfile.write('Image %s is not a JPEG image, and its label is %d\\n' % (file_path, label))\n    return -1, None\n\nif not tf.gfile.Exists(file_path):\n    print('Image %s is not exist, and its label is %d' % (file_path, label))\n    if logfile:\n        logfile.write('Image %s is not exist, and its label is %d\\n' % (file_path, label))\n    return -1, None\n\n# Read the image file.\nimage_data = tf.gfile.FastGFile(file_path, 'r').read()\n\n# Decode the RGB JPEG.\nheight, width, channels = coder.read_image_dims(image_data)\n\n# Check that image converted right\nif height != 148 and width != 148 and channels != 3:\n    print('The size of image %s is wrong, which is h[%d] w[%d] c[%d], but requested h[148] w[148] c[148]\\n' % (file_path, height, width, channels))\n    if logfile:\n        logfile.write('The size of image %s is wrong, which is h[%d] w[%d], but requested h[148] w[148] c[148]\\n' % (file_path, height, width, channels))\n    return -1, None\n\nreturn 0, _convert_to_example(image_data, height, width, channels, 'jpg', label)\n\ndef _process_image_files_batch(coder, thread_index, ranges, name, filenames, labels, num_shards, logfile=None):\nnum_threads = len(ranges)\nassert not num_shards % num_threads\nnum_shards_per_batch = int(num_shards / num_threads)\n\nshard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], num_shards_per_batch + 1).astype(int)\nnum_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n\ncounter = 0\nfor s in xrange(num_shards_per_batch):\n    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n    shard = thread_index * num_shards_per_batch + s\n    output_file = '%s-%.5d-of-%.5d.tfrecord' % (name, shard, num_shards)\n    writer = tf.python_io.TFRecordWriter(output_file)\n\n    shard_counter = 0\n    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n    for i in files_in_shard:\n        file_path = filenames[i]\n        label = labels[i]\n\n        errCode, example = _process_image(file_path, label, coder, logfile)\n        if -1 == errCode:\n            continue\n\n        writer.write(example.SerializeToString())\n        shard_counter += 1\n        counter += 1\n\n        if not counter % 1000:\n            print('%s [thread %d]: Processed %d of %d images in thread batch.' % (datetime.now(), thread_index, counter, num_files_in_thread))\n            sys.stdout.flush()\n\n    print('%s [thread %d]: Wrote %d images to %s' % (datetime.now(), thread_index, shard_counter, output_file))\n    sys.stdout.flush()\n    shard_counter = 0\nprint('%s [thread %d]: Wrote %d images to %d shards.' % (datetime.now(), thread_index, counter, num_files_in_thread))\nsys.stdout.flush()\n\n\nSo I checked all the images as the same shape and same size of 65712, and write them by jpg format, Ibut I don't know where the problem is.", "body": "When I use tf to read traing and testing data from tfrecords, it runed for a while, then stoped with errors like this (this is testing net error, traing net is the same problem):\nINFO:tensorflow:Executing eval_op 8133/15916\nINFO:tensorflow:Executing eval_op 8134/15916\nINFO:tensorflow:Executing eval_op 8135/15916\nINFO:tensorflow:Executing eval_op 8136/15916\nINFO:tensorflow:Executing eval_op 8137/15916\nINFO:tensorflow:Executing eval_op 8138/15916\nINFO:tensorflow:Executing eval_op 8139/15916\nINFO:tensorflow:Executing eval_op 8140/15916\nINFO:tensorflow:Executing eval_op 8141/15916\nINFO:tensorflow:Executing eval_op 8142/15916\nINFO:tensorflow:Executing eval_op 8143/15916\nINFO:tensorflow:Executing eval_op 8144/15916\nINFO:tensorflow:Executing eval_op 8145/15916\nINFO:tensorflow:Executing eval_op 8146/15916\nINFO:tensorflow:Executing eval_op 8147/15916\nINFO:tensorflow:Executing eval_op 8148/15916\nINFO:tensorflow:Executing eval_op 8149/15916\nINFO:tensorflow:Executing eval_op 8150/15916\nINFO:tensorflow:Executing eval_op 8151/15916\nINFO:tensorflow:Executing eval_op 8152/15916\nINFO:tensorflow:Executing eval_op 8153/15916\nINFO:tensorflow:Executing eval_op 8154/15916\nINFO:tensorflow:Executing eval_op 8155/15916\nINFO:tensorflow:Executing eval_op 8156/15916\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.InvalidArgumentError'>, Input to reshape is a tensor with 836310 values, but the requested shape has 65712\n         [[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](case_1/If_2/Merge, Reshape_14/shape)]]\n         [[Node: eval_image/Mul/_3773 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_eval_image/Mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Reshape_14', defined at:\n  File \"eval_image_classifier.py\", line 210, in <module>\n    tf.app.run()\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"eval_image_classifier.py\", line 130, in main\n    common_queue_min=FLAGS.batch_size)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\n    tensors = dataset.decoder.decode(data, items)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\n    image = self._decode(image_buffer, image_format)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 328, in _decode\n    image = array_ops.reshape(image, self._shape)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py\", line 1758, in reshape\n    name=name)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2333, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1252, in __init__\n    self._traceback = _extract_stack()\n\nTraceback (most recent call last):\n  File \"eval_image_classifier.py\", line 210, in <module>\n    tf.app.run()\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"eval_image_classifier.py\", line 206, in main\n    variables_to_restore=variables_to_restore)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/evaluation.py\", line 323, in evaluate_once\n    global_step=global_step)\n  File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py\", line 969, in managed_session\n    self.stop(close_summary_writer=close_summary_writer)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py\", line 797, in stop\n    stop_grace_period_secs=self._stop_grace_secs)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/training/coordinator.py\", line 386, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/training/queue_runner.py\", line 225, in _run\n    sess.run(enqueue_op)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 836310 values, but the requested shape has 65712\n         [[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](case_1/If_2/Merge, Reshape_14/shape)]]\n         [[Node: eval_image/Mul/_3773 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_eval_image/Mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Reshape_14', defined at:\n  File \"eval_image_classifier.py\", line 210, in <module>\n    tf.app.run()\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"eval_image_classifier.py\", line 130, in main\n    common_queue_min=FLAGS.batch_size)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\n    tensors = dataset.decoder.decode(data, items)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\n    image = self._decode(image_buffer, image_format)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 328, in _decode\n    image = array_ops.reshape(image, self._shape)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py\", line 1758, in reshape\n    name=name)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2333, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1252, in __init__\n    self._traceback = _extract_stack()\n###### \n\nwhile I wrote the tfrecords like this:\n\ndef _process_image(file_path, label, coder, logfile=None):\n    \"\"\"Process a single image file.\n\n```\nArgs:\n    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\nReturns:\n    image_buffer: string, JPEG encoding of RGB image.\n    height: integer, image height in pixels.\n    width: integer, image width in pixels.\n\"\"\"\n# Clean the dirty data.\nif _is_not_jpg(file_path):\n    print('Image %s is not a JPEG image, and its label is %d' % (file_path, label))\n    if logfile:\n        logfile.write('Image %s is not a JPEG image, and its label is %d\\n' % (file_path, label))\n    return -1, None\n\nif not tf.gfile.Exists(file_path):\n    print('Image %s is not exist, and its label is %d' % (file_path, label))\n    if logfile:\n        logfile.write('Image %s is not exist, and its label is %d\\n' % (file_path, label))\n    return -1, None\n\n# Read the image file.\nimage_data = tf.gfile.FastGFile(file_path, 'r').read()\n\n# Decode the RGB JPEG.\nheight, width, channels = coder.read_image_dims(image_data)\n\n# Check that image converted right\nif height != 148 and width != 148 and channels != 3:\n    print('The size of image %s is wrong, which is h[%d] w[%d] c[%d], but requested h[148] w[148] c[148]\\n' % (file_path, height, width, channels))\n    if logfile:\n        logfile.write('The size of image %s is wrong, which is h[%d] w[%d], but requested h[148] w[148] c[148]\\n' % (file_path, height, width, channels))\n    return -1, None\n\nreturn 0, _convert_to_example(image_data, height, width, channels, 'jpg', label)\n```\n\ndef _process_image_files_batch(coder, thread_index, ranges, name, filenames, labels, num_shards, logfile=None):\n\n```\nnum_threads = len(ranges)\nassert not num_shards % num_threads\nnum_shards_per_batch = int(num_shards / num_threads)\n\nshard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], num_shards_per_batch + 1).astype(int)\nnum_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n\ncounter = 0\nfor s in xrange(num_shards_per_batch):\n    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n    shard = thread_index * num_shards_per_batch + s\n    output_file = '%s-%.5d-of-%.5d.tfrecord' % (name, shard, num_shards)\n    writer = tf.python_io.TFRecordWriter(output_file)\n\n    shard_counter = 0\n    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n    for i in files_in_shard:\n        file_path = filenames[i]\n        label = labels[i]\n\n        errCode, example = _process_image(file_path, label, coder, logfile)\n        if -1 == errCode:\n            continue\n\n        writer.write(example.SerializeToString())\n        shard_counter += 1\n        counter += 1\n\n        if not counter % 1000:\n            print('%s [thread %d]: Processed %d of %d images in thread batch.' % (datetime.now(), thread_index, counter, num_files_in_thread))\n            sys.stdout.flush()\n\n    print('%s [thread %d]: Wrote %d images to %s' % (datetime.now(), thread_index, shard_counter, output_file))\n    sys.stdout.flush()\n    shard_counter = 0\nprint('%s [thread %d]: Wrote %d images to %d shards.' % (datetime.now(), thread_index, counter, num_files_in_thread))\nsys.stdout.flush()\n```\n###### \n\nSo I checked all the images as the same shape and same size of 65712, and write them by jpg format, Ibut I don't know where the problem is.\n"}