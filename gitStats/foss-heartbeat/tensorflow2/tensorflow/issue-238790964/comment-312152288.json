{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/312152288", "html_url": "https://github.com/tensorflow/tensorflow/issues/11081#issuecomment-312152288", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11081", "id": 312152288, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjE1MjI4OA==", "user": {"login": "saeta", "id": 1284535, "node_id": "MDQ6VXNlcjEyODQ1MzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1284535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saeta", "html_url": "https://github.com/saeta", "followers_url": "https://api.github.com/users/saeta/followers", "following_url": "https://api.github.com/users/saeta/following{/other_user}", "gists_url": "https://api.github.com/users/saeta/gists{/gist_id}", "starred_url": "https://api.github.com/users/saeta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saeta/subscriptions", "organizations_url": "https://api.github.com/users/saeta/orgs", "repos_url": "https://api.github.com/users/saeta/repos", "events_url": "https://api.github.com/users/saeta/events{/privacy}", "received_events_url": "https://api.github.com/users/saeta/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-30T01:42:04Z", "updated_at": "2017-06-30T01:42:04Z", "author_association": "MEMBER", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1291583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nfergu\">@nfergu</a>,</p>\n<p>You're exactly on the right track with regards to what the issue is. The GrpcChannelCache needs the actual ports of the TF servers in order to correctly connect. The way to do this is by using <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session_clusterspec_prop_test.py#L56\">ClusterSpec propagation</a> a new feature in TF 1.2.</p>\n<p>Your script would look like the following:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.core.protobuf <span class=\"pl-k\">import</span> cluster_pb2 <span class=\"pl-k\">as</span> cluster\n\ntmp_cluster <span class=\"pl-k\">=</span> tf.train.ClusterSpec({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tmp<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:0<span class=\"pl-pds\">\"</span></span>]})\n\nps <span class=\"pl-k\">=</span> tf.train.Server(tmp_cluster, <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tmp<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\nworker <span class=\"pl-k\">=</span> tf.train.Server(tmp_cluster, <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tmp<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>PS: <span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(ps.target))\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Worker: <span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(worker.target))\n\ncluster_def <span class=\"pl-k\">=</span> cluster.ClusterDef()\nps_job <span class=\"pl-k\">=</span> cluster_def.job.add()\nps_job.name <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>ps<span class=\"pl-pds\">'</span></span>\nps_job.tasks[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> ps.target[<span class=\"pl-c1\">len</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>grpc://<span class=\"pl-pds\">'</span></span>):]  <span class=\"pl-c\"><span class=\"pl-c\">#</span> strip off `grpc://` prefix</span>\n\nworker_job <span class=\"pl-k\">=</span> cluster_def.job.add()\nworker_job.name <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>\nworker_job.tasks[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> worker.target[<span class=\"pl-c1\">len</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>grpc://<span class=\"pl-pds\">'</span></span>):]\n\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">cluster_def</span><span class=\"pl-k\">=</span>cluster_def)\n\n<span class=\"pl-k\">with</span> tf.Session(worker.target, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n\n  <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:ps/task:0<span class=\"pl-pds\">\"</span></span>):\n    W <span class=\"pl-k\">=</span> tf.Variable(tf.zeros([<span class=\"pl-c1\">784</span>, <span class=\"pl-c1\">10</span>]))\n    b <span class=\"pl-k\">=</span> tf.Variable(tf.zeros([<span class=\"pl-c1\">10</span>]))\n\n    init <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>RUNNING SESSION<span class=\"pl-pds\">\"</span></span>)\n    sess.run(init)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>SESSION FINISHED<span class=\"pl-pds\">\"</span></span>)\n</pre></div>\n<p>The output of this on my machine is:</p>\n<pre><code>2017-06-29 18:38:45.168720: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.168744: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.168750: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.168754: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.168758: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.197904: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job tmp -&gt; {0 -&gt; localhost:35403}\n2017-06-29 18:38:45.208088: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:35403\n2017-06-29 18:38:45.241186: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job tmp -&gt; {0 -&gt; localhost:38776}\n2017-06-29 18:38:45.243309: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:38776\nPS: grpc://localhost:35403\nWorker: grpc://localhost:38776\nRUNNING SESSION\n2017-06-29 18:38:45.268510: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:35403}\n2017-06-29 18:38:45.268564: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:38776}\n2017-06-29 18:38:45.280314: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 928a851d8c8eae3d with config: \ncluster_def {\n  job {\n    name: \"ps\"\n    tasks {\n      key: 0\n      value: \"localhost:35403\"\n    }\n  }\n  job {\n    name: \"worker\"\n    tasks {\n      key: 0\n      value: \"localhost:38776\"\n    }\n  }\n}\n\n2017-06-29 18:38:45.280573: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:35403}\n2017-06-29 18:38:45.280599: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:38776}\n2017-06-29 18:38:45.280790: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:35403}\n2017-06-29 18:38:45.280829: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:38776}\nSESSION FINISHED\n</code></pre>\n<p>Note: ClusterSpec propagation is a new feature I added in the latest TF release. We haven't yet updated the documentation as we have some ongoing work to make it much easier to construct the ClusterDef's. (Hence the awkward import.) Hope this helps!</p>", "body_text": "Hi @nfergu,\nYou're exactly on the right track with regards to what the issue is. The GrpcChannelCache needs the actual ports of the TF servers in order to correctly connect. The way to do this is by using ClusterSpec propagation a new feature in TF 1.2.\nYour script would look like the following:\nimport tensorflow as tf\nfrom tensorflow.core.protobuf import cluster_pb2 as cluster\n\ntmp_cluster = tf.train.ClusterSpec({\"tmp\": [\"localhost:0\"]})\n\nps = tf.train.Server(tmp_cluster, job_name=\"tmp\", task_index=0)\nworker = tf.train.Server(tmp_cluster, job_name=\"tmp\", task_index=0)\n\nprint(\"PS: {0}\".format(ps.target))\nprint(\"Worker: {0}\".format(worker.target))\n\ncluster_def = cluster.ClusterDef()\nps_job = cluster_def.job.add()\nps_job.name = 'ps'\nps_job.tasks[0] = ps.target[len('grpc://'):]  # strip off `grpc://` prefix\n\nworker_job = cluster_def.job.add()\nworker_job.name = 'worker'\nworker_job.tasks[0] = worker.target[len('grpc://'):]\n\nconfig = tf.ConfigProto(cluster_def=cluster_def)\n\nwith tf.Session(worker.target, config=config) as sess:\n\n  with tf.device(\"/job:ps/task:0\"):\n    W = tf.Variable(tf.zeros([784, 10]))\n    b = tf.Variable(tf.zeros([10]))\n\n    init = tf.global_variables_initializer()\n\n    print(\"RUNNING SESSION\")\n    sess.run(init)\n    print(\"SESSION FINISHED\")\n\nThe output of this on my machine is:\n2017-06-29 18:38:45.168720: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.168744: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.168750: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.168754: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.168758: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2017-06-29 18:38:45.197904: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job tmp -> {0 -> localhost:35403}\n2017-06-29 18:38:45.208088: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:35403\n2017-06-29 18:38:45.241186: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job tmp -> {0 -> localhost:38776}\n2017-06-29 18:38:45.243309: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:38776\nPS: grpc://localhost:35403\nWorker: grpc://localhost:38776\nRUNNING SESSION\n2017-06-29 18:38:45.268510: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:35403}\n2017-06-29 18:38:45.268564: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:38776}\n2017-06-29 18:38:45.280314: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 928a851d8c8eae3d with config: \ncluster_def {\n  job {\n    name: \"ps\"\n    tasks {\n      key: 0\n      value: \"localhost:35403\"\n    }\n  }\n  job {\n    name: \"worker\"\n    tasks {\n      key: 0\n      value: \"localhost:38776\"\n    }\n  }\n}\n\n2017-06-29 18:38:45.280573: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:35403}\n2017-06-29 18:38:45.280599: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:38776}\n2017-06-29 18:38:45.280790: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:35403}\n2017-06-29 18:38:45.280829: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:38776}\nSESSION FINISHED\n\nNote: ClusterSpec propagation is a new feature I added in the latest TF release. We haven't yet updated the documentation as we have some ongoing work to make it much easier to construct the ClusterDef's. (Hence the awkward import.) Hope this helps!", "body": "Hi @nfergu,\r\n\r\nYou're exactly on the right track with regards to what the issue is. The GrpcChannelCache needs the actual ports of the TF servers in order to correctly connect. The way to do this is by using [ClusterSpec propagation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session_clusterspec_prop_test.py#L56) a new feature in TF 1.2.\r\n\r\nYour script would look like the following:\r\n\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.core.protobuf import cluster_pb2 as cluster\r\n\r\ntmp_cluster = tf.train.ClusterSpec({\"tmp\": [\"localhost:0\"]})\r\n\r\nps = tf.train.Server(tmp_cluster, job_name=\"tmp\", task_index=0)\r\nworker = tf.train.Server(tmp_cluster, job_name=\"tmp\", task_index=0)\r\n\r\nprint(\"PS: {0}\".format(ps.target))\r\nprint(\"Worker: {0}\".format(worker.target))\r\n\r\ncluster_def = cluster.ClusterDef()\r\nps_job = cluster_def.job.add()\r\nps_job.name = 'ps'\r\nps_job.tasks[0] = ps.target[len('grpc://'):]  # strip off `grpc://` prefix\r\n\r\nworker_job = cluster_def.job.add()\r\nworker_job.name = 'worker'\r\nworker_job.tasks[0] = worker.target[len('grpc://'):]\r\n\r\nconfig = tf.ConfigProto(cluster_def=cluster_def)\r\n\r\nwith tf.Session(worker.target, config=config) as sess:\r\n\r\n  with tf.device(\"/job:ps/task:0\"):\r\n    W = tf.Variable(tf.zeros([784, 10]))\r\n    b = tf.Variable(tf.zeros([10]))\r\n\r\n    init = tf.global_variables_initializer()\r\n\r\n    print(\"RUNNING SESSION\")\r\n    sess.run(init)\r\n    print(\"SESSION FINISHED\")\r\n\r\n```\r\n\r\nThe output of this on my machine is:\r\n\r\n```\r\n2017-06-29 18:38:45.168720: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 18:38:45.168744: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 18:38:45.168750: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 18:38:45.168754: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 18:38:45.168758: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-06-29 18:38:45.197904: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job tmp -> {0 -> localhost:35403}\r\n2017-06-29 18:38:45.208088: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:35403\r\n2017-06-29 18:38:45.241186: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job tmp -> {0 -> localhost:38776}\r\n2017-06-29 18:38:45.243309: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:38776\r\nPS: grpc://localhost:35403\r\nWorker: grpc://localhost:38776\r\nRUNNING SESSION\r\n2017-06-29 18:38:45.268510: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:35403}\r\n2017-06-29 18:38:45.268564: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:38776}\r\n2017-06-29 18:38:45.280314: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 928a851d8c8eae3d with config: \r\ncluster_def {\r\n  job {\r\n    name: \"ps\"\r\n    tasks {\r\n      key: 0\r\n      value: \"localhost:35403\"\r\n    }\r\n  }\r\n  job {\r\n    name: \"worker\"\r\n    tasks {\r\n      key: 0\r\n      value: \"localhost:38776\"\r\n    }\r\n  }\r\n}\r\n\r\n2017-06-29 18:38:45.280573: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:35403}\r\n2017-06-29 18:38:45.280599: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:38776}\r\n2017-06-29 18:38:45.280790: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:35403}\r\n2017-06-29 18:38:45.280829: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:38776}\r\nSESSION FINISHED\r\n```\r\n\r\nNote: ClusterSpec propagation is a new feature I added in the latest TF release. We haven't yet updated the documentation as we have some ongoing work to make it much easier to construct the ClusterDef's. (Hence the awkward import.) Hope this helps!"}