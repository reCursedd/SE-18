{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11081", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11081/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11081/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11081/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11081", "id": 238790964, "node_id": "MDU6SXNzdWUyMzg3OTA5NjQ=", "number": 11081, "title": "Problem with operating system allocated ports in distributed Tensorflow", "user": {"login": "nfergu", "id": 1291583, "node_id": "MDQ6VXNlcjEyOTE1ODM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1291583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nfergu", "html_url": "https://github.com/nfergu", "followers_url": "https://api.github.com/users/nfergu/followers", "following_url": "https://api.github.com/users/nfergu/following{/other_user}", "gists_url": "https://api.github.com/users/nfergu/gists{/gist_id}", "starred_url": "https://api.github.com/users/nfergu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nfergu/subscriptions", "organizations_url": "https://api.github.com/users/nfergu/orgs", "repos_url": "https://api.github.com/users/nfergu/repos", "events_url": "https://api.github.com/users/nfergu/events{/privacy}", "received_events_url": "https://api.github.com/users/nfergu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-06-27T09:33:12Z", "updated_at": "2017-10-06T19:09:03Z", "closed_at": "2017-06-30T01:42:04Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes (simple test case to reproduce)</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Reproduced on Ubuntu 16.04.1 and MacOS Sierra (10.12.5).</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.2.0-rc2-21-g12f033d 1.2.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: See source code below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When using operating system allocated ports (specifying port zero in the cluster spec), distributed Tensorflow seems to wait forever with the message \"CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\" when initializing variables on the parameter server.</p>\n<p>The same code works fine with explicitly allocated ports.</p>\n<p>See below for code to reproduce the issue.</p>\n<h3>Source code / logs</h3>\n<p>This code works fine:</p>\n<pre><code>import tensorflow as tf\n\ncluster = tf.train.ClusterSpec({\"ps\": [\"localhost:65062\"], \"worker\": [\"localhost:65063\"]})\n\nps = tf.train.Server(cluster, job_name=\"ps\", task_index=0)\nworker = tf.train.Server(cluster, job_name=\"worker\", task_index=0)\n\nprint(\"PS: {0}\".format(ps.target))\nprint(\"Worker: {0}\".format(worker.target))\n\nwith tf.Session(worker.target) as sess:\n\n    with tf.device(\"/job:ps/task:0\"):\n        W = tf.Variable(tf.zeros([784, 10]))\n        b = tf.Variable(tf.zeros([10]))\n\n    init = tf.global_variables_initializer()\n\n    print(\"RUNNING SESSION\")\n    sess.run(init)\n    print(\"SESSION FINISHED\")\n</code></pre>\n<p>It gets to the end and prints \"SESSION FINISHED\", producing the following output:</p>\n<pre><code>2017-06-27 10:12:58.482841: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:65062}\n2017-06-27 10:12:58.482857: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:65063}\n2017-06-27 10:12:58.483156: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65062\n2017-06-27 10:12:58.493057: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:65062}\n2017-06-27 10:12:58.493077: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:65063}\n2017-06-27 10:12:58.493263: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65063\nPS: b'grpc://localhost:65062'\nWorker: b'grpc://localhost:65063'\nRUNNING SESSION\n2017-06-27 10:12:58.525303: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 78091edd7d24288b with config: \n\nSESSION FINISHED\n</code></pre>\n<p>However, this code does not work:</p>\n<pre><code>import tensorflow as tf\n\ncluster = tf.train.ClusterSpec({\"ps\": [\"localhost:0\"], \"worker\": [\"localhost:0\"]})\n\nps = tf.train.Server(cluster, job_name=\"ps\", task_index=0)\nworker = tf.train.Server(cluster, job_name=\"worker\", task_index=0)\n\nprint(\"PS: {0}\".format(ps.target))\nprint(\"Worker: {0}\".format(worker.target))\n\nwith tf.Session(worker.target) as sess:\n\n    with tf.device(\"/job:ps/task:0\"):\n        W = tf.Variable(tf.zeros([784, 10]))\n        b = tf.Variable(tf.zeros([10]))\n\n    init = tf.global_variables_initializer()\n\n    print(\"RUNNING SESSION\")\n    sess.run(init)\n    print(\"SESSION FINISHED\")\n</code></pre>\n<p>The only difference in the above code is that we let the operating system allocate ports by specifying zero as the port number, rather than explicitly allocating them.</p>\n<p>This code does not reach the end, but instead prints the message \"CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\" repeatedly. The following output is produced:</p>\n<pre><code>2017-06-27 10:11:31.238753: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:65062}\n2017-06-27 10:11:31.238770: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:0}\n2017-06-27 10:11:31.239114: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65062\n2017-06-27 10:11:31.247859: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:0}\n2017-06-27 10:11:31.247877: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:65063}\n2017-06-27 10:11:31.248059: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65063\nPS: b'grpc://localhost:65062'\nWorker: b'grpc://localhost:65063'\nRUNNING SESSION\n2017-06-27 10:11:41.283559: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2017-06-27 10:11:51.287739: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2017-06-27 10:12:01.290028: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2017-06-27 10:12:11.290560: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2017-06-27 10:12:21.292900: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n</code></pre>\n<p>Note the messages <code>Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:0}</code> above, which may indicate the source of the problem.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (simple test case to reproduce)\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Reproduced on Ubuntu 16.04.1 and MacOS Sierra (10.12.5).\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): v1.2.0-rc2-21-g12f033d 1.2.0\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: See source code below\n\nDescribe the problem\nWhen using operating system allocated ports (specifying port zero in the cluster spec), distributed Tensorflow seems to wait forever with the message \"CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\" when initializing variables on the parameter server.\nThe same code works fine with explicitly allocated ports.\nSee below for code to reproduce the issue.\nSource code / logs\nThis code works fine:\nimport tensorflow as tf\n\ncluster = tf.train.ClusterSpec({\"ps\": [\"localhost:65062\"], \"worker\": [\"localhost:65063\"]})\n\nps = tf.train.Server(cluster, job_name=\"ps\", task_index=0)\nworker = tf.train.Server(cluster, job_name=\"worker\", task_index=0)\n\nprint(\"PS: {0}\".format(ps.target))\nprint(\"Worker: {0}\".format(worker.target))\n\nwith tf.Session(worker.target) as sess:\n\n    with tf.device(\"/job:ps/task:0\"):\n        W = tf.Variable(tf.zeros([784, 10]))\n        b = tf.Variable(tf.zeros([10]))\n\n    init = tf.global_variables_initializer()\n\n    print(\"RUNNING SESSION\")\n    sess.run(init)\n    print(\"SESSION FINISHED\")\n\nIt gets to the end and prints \"SESSION FINISHED\", producing the following output:\n2017-06-27 10:12:58.482841: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}\n2017-06-27 10:12:58.482857: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}\n2017-06-27 10:12:58.483156: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65062\n2017-06-27 10:12:58.493057: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}\n2017-06-27 10:12:58.493077: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}\n2017-06-27 10:12:58.493263: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65063\nPS: b'grpc://localhost:65062'\nWorker: b'grpc://localhost:65063'\nRUNNING SESSION\n2017-06-27 10:12:58.525303: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 78091edd7d24288b with config: \n\nSESSION FINISHED\n\nHowever, this code does not work:\nimport tensorflow as tf\n\ncluster = tf.train.ClusterSpec({\"ps\": [\"localhost:0\"], \"worker\": [\"localhost:0\"]})\n\nps = tf.train.Server(cluster, job_name=\"ps\", task_index=0)\nworker = tf.train.Server(cluster, job_name=\"worker\", task_index=0)\n\nprint(\"PS: {0}\".format(ps.target))\nprint(\"Worker: {0}\".format(worker.target))\n\nwith tf.Session(worker.target) as sess:\n\n    with tf.device(\"/job:ps/task:0\"):\n        W = tf.Variable(tf.zeros([784, 10]))\n        b = tf.Variable(tf.zeros([10]))\n\n    init = tf.global_variables_initializer()\n\n    print(\"RUNNING SESSION\")\n    sess.run(init)\n    print(\"SESSION FINISHED\")\n\nThe only difference in the above code is that we let the operating system allocate ports by specifying zero as the port number, rather than explicitly allocating them.\nThis code does not reach the end, but instead prints the message \"CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\" repeatedly. The following output is produced:\n2017-06-27 10:11:31.238753: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}\n2017-06-27 10:11:31.238770: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:0}\n2017-06-27 10:11:31.239114: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65062\n2017-06-27 10:11:31.247859: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:0}\n2017-06-27 10:11:31.247877: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}\n2017-06-27 10:11:31.248059: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65063\nPS: b'grpc://localhost:65062'\nWorker: b'grpc://localhost:65063'\nRUNNING SESSION\n2017-06-27 10:11:41.283559: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2017-06-27 10:11:51.287739: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2017-06-27 10:12:01.290028: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2017-06-27 10:12:11.290560: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2017-06-27 10:12:21.292900: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n\nNote the messages Initialize GrpcChannelCache for job worker -> {0 -> localhost:0} above, which may indicate the source of the problem.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (simple test case to reproduce)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Reproduced on Ubuntu 16.04.1 and MacOS Sierra (10.12.5).\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See source code below\r\n\r\n### Describe the problem\r\n\r\nWhen using operating system allocated ports (specifying port zero in the cluster spec), distributed Tensorflow seems to wait forever with the message \"CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\" when initializing variables on the parameter server.\r\n\r\nThe same code works fine with explicitly allocated ports.  \r\n\r\nSee below for code to reproduce the issue.\r\n\r\n### Source code / logs\r\n\r\nThis code works fine:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ncluster = tf.train.ClusterSpec({\"ps\": [\"localhost:65062\"], \"worker\": [\"localhost:65063\"]})\r\n\r\nps = tf.train.Server(cluster, job_name=\"ps\", task_index=0)\r\nworker = tf.train.Server(cluster, job_name=\"worker\", task_index=0)\r\n\r\nprint(\"PS: {0}\".format(ps.target))\r\nprint(\"Worker: {0}\".format(worker.target))\r\n\r\nwith tf.Session(worker.target) as sess:\r\n\r\n    with tf.device(\"/job:ps/task:0\"):\r\n        W = tf.Variable(tf.zeros([784, 10]))\r\n        b = tf.Variable(tf.zeros([10]))\r\n\r\n    init = tf.global_variables_initializer()\r\n\r\n    print(\"RUNNING SESSION\")\r\n    sess.run(init)\r\n    print(\"SESSION FINISHED\")\r\n```\r\n\r\nIt gets to the end and prints \"SESSION FINISHED\", producing the following output:\r\n\r\n```\r\n2017-06-27 10:12:58.482841: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}\r\n2017-06-27 10:12:58.482857: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}\r\n2017-06-27 10:12:58.483156: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65062\r\n2017-06-27 10:12:58.493057: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}\r\n2017-06-27 10:12:58.493077: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}\r\n2017-06-27 10:12:58.493263: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65063\r\nPS: b'grpc://localhost:65062'\r\nWorker: b'grpc://localhost:65063'\r\nRUNNING SESSION\r\n2017-06-27 10:12:58.525303: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 78091edd7d24288b with config: \r\n\r\nSESSION FINISHED\r\n```\r\n\r\nHowever, this code does not work:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ncluster = tf.train.ClusterSpec({\"ps\": [\"localhost:0\"], \"worker\": [\"localhost:0\"]})\r\n\r\nps = tf.train.Server(cluster, job_name=\"ps\", task_index=0)\r\nworker = tf.train.Server(cluster, job_name=\"worker\", task_index=0)\r\n\r\nprint(\"PS: {0}\".format(ps.target))\r\nprint(\"Worker: {0}\".format(worker.target))\r\n\r\nwith tf.Session(worker.target) as sess:\r\n\r\n    with tf.device(\"/job:ps/task:0\"):\r\n        W = tf.Variable(tf.zeros([784, 10]))\r\n        b = tf.Variable(tf.zeros([10]))\r\n\r\n    init = tf.global_variables_initializer()\r\n\r\n    print(\"RUNNING SESSION\")\r\n    sess.run(init)\r\n    print(\"SESSION FINISHED\")\r\n```\r\n\r\nThe only difference in the above code is that we let the operating system allocate ports by specifying zero as the port number, rather than explicitly allocating them.\r\n\r\nThis code does not reach the end, but instead prints the message \"CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\" repeatedly. The following output is produced:\r\n\r\n```\r\n2017-06-27 10:11:31.238753: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:65062}\r\n2017-06-27 10:11:31.238770: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:0}\r\n2017-06-27 10:11:31.239114: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65062\r\n2017-06-27 10:11:31.247859: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:0}\r\n2017-06-27 10:11:31.247877: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65063}\r\n2017-06-27 10:11:31.248059: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:65063\r\nPS: b'grpc://localhost:65062'\r\nWorker: b'grpc://localhost:65063'\r\nRUNNING SESSION\r\n2017-06-27 10:11:41.283559: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n2017-06-27 10:11:51.287739: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n2017-06-27 10:12:01.290028: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n2017-06-27 10:12:11.290560: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n2017-06-27 10:12:21.292900: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n``` \r\n\r\nNote the messages ```Initialize GrpcChannelCache for job worker -> {0 -> localhost:0}``` above, which may indicate the source of the problem."}