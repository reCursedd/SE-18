{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4526", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4526/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4526/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4526/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4526", "id": 178499435, "node_id": "MDU6SXNzdWUxNzg0OTk0MzU=", "number": 4526, "title": "GPU-resident queue for prefetching over PCIe", "user": {"login": "benbarsdell", "id": 3979096, "node_id": "MDQ6VXNlcjM5NzkwOTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/3979096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benbarsdell", "html_url": "https://github.com/benbarsdell", "followers_url": "https://api.github.com/users/benbarsdell/followers", "following_url": "https://api.github.com/users/benbarsdell/following{/other_user}", "gists_url": "https://api.github.com/users/benbarsdell/gists{/gist_id}", "starred_url": "https://api.github.com/users/benbarsdell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benbarsdell/subscriptions", "organizations_url": "https://api.github.com/users/benbarsdell/orgs", "repos_url": "https://api.github.com/users/benbarsdell/repos", "events_url": "https://api.github.com/users/benbarsdell/events{/privacy}", "received_events_url": "https://api.github.com/users/benbarsdell/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2016-09-22T01:19:57Z", "updated_at": "2018-04-25T16:54:56Z", "closed_at": "2016-09-22T05:10:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>It would improve performance in some cases to be able to asynchronously prefetch data over the PCIe bus while GPU computation is taking place. A GPU-resident queue seems like the natural way to achieve this.</p>\n<p>In the SO thread below, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> mentions using Variables pinned to the GPU to achieve the same effect, but I was unable to find a way to get this to work.</p>\n<h3>Related threads:</h3>\n<p><a href=\"https://stackoverflow.com/questions/38751736/understanding-tensorflow-queues-and-cpu-gpu-transfer\" rel=\"nofollow\">https://stackoverflow.com/questions/38751736/understanding-tensorflow-queues-and-cpu-gpu-transfer</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"161912688\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3009\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3009/hovercard?comment_id=242235654&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/3009#issuecomment-242235654\">#3009 (comment)</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"166212411\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3377\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3377/hovercard?comment_id=239966932&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/3377#issuecomment-239966932\">#3377 (comment)</a></p>", "body_text": "It would improve performance in some cases to be able to asynchronously prefetch data over the PCIe bus while GPU computation is taking place. A GPU-resident queue seems like the natural way to achieve this.\nIn the SO thread below, @yaroslavvb mentions using Variables pinned to the GPU to achieve the same effect, but I was unable to find a way to get this to work.\nRelated threads:\nhttps://stackoverflow.com/questions/38751736/understanding-tensorflow-queues-and-cpu-gpu-transfer\n#3009 (comment)\n#3377 (comment)", "body": "It would improve performance in some cases to be able to asynchronously prefetch data over the PCIe bus while GPU computation is taking place. A GPU-resident queue seems like the natural way to achieve this.\n\nIn the SO thread below, @yaroslavvb mentions using Variables pinned to the GPU to achieve the same effect, but I was unable to find a way to get this to work.\n### Related threads:\n\nhttps://stackoverflow.com/questions/38751736/understanding-tensorflow-queues-and-cpu-gpu-transfer\nhttps://github.com/tensorflow/tensorflow/issues/3009#issuecomment-242235654\nhttps://github.com/tensorflow/tensorflow/issues/3377#issuecomment-239966932\n"}