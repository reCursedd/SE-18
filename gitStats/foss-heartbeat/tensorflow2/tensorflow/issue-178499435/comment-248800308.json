{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/248800308", "html_url": "https://github.com/tensorflow/tensorflow/issues/4526#issuecomment-248800308", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4526", "id": 248800308, "node_id": "MDEyOklzc3VlQ29tbWVudDI0ODgwMDMwOA==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-22T03:16:44Z", "updated_at": "2016-09-22T03:16:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>tf.assign itself doesn't do the copy. The send/recv pair after the graph partition does that. And it runs in parallel with the computation.</p>\n<p>The data transfer between TF and Python through feed_dict is often hidden through input queues. A GPU-resident queue could save the additional overhead from CPU to GPU once the data is in TF.</p>\n<p>However, we had discussed the possibility of a GPU-resident queue, or GPU-cached queue in this context in the past few days. However, a naive implementation might be problematic since it might consume too much GPU memory, which is often much less than its CPU counterpart. If we go with a GPU-cached queue, we have to be very careful, since there are a number of tricky issues to iron out so it doesn't interfere with the rest of the system.</p>", "body_text": "tf.assign itself doesn't do the copy. The send/recv pair after the graph partition does that. And it runs in parallel with the computation.\nThe data transfer between TF and Python through feed_dict is often hidden through input queues. A GPU-resident queue could save the additional overhead from CPU to GPU once the data is in TF.\nHowever, we had discussed the possibility of a GPU-resident queue, or GPU-cached queue in this context in the past few days. However, a naive implementation might be problematic since it might consume too much GPU memory, which is often much less than its CPU counterpart. If we go with a GPU-cached queue, we have to be very careful, since there are a number of tricky issues to iron out so it doesn't interfere with the rest of the system.", "body": "tf.assign itself doesn't do the copy. The send/recv pair after the graph partition does that. And it runs in parallel with the computation. \n\nThe data transfer between TF and Python through feed_dict is often hidden through input queues. A GPU-resident queue could save the additional overhead from CPU to GPU once the data is in TF. \n\nHowever, we had discussed the possibility of a GPU-resident queue, or GPU-cached queue in this context in the past few days. However, a naive implementation might be problematic since it might consume too much GPU memory, which is often much less than its CPU counterpart. If we go with a GPU-cached queue, we have to be very careful, since there are a number of tricky issues to iron out so it doesn't interfere with the rest of the system. \n"}