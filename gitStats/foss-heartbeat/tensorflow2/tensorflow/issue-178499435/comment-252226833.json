{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/252226833", "html_url": "https://github.com/tensorflow/tensorflow/issues/4526#issuecomment-252226833", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4526", "id": 252226833, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MjIyNjgzMw==", "user": {"login": "sjperkins", "id": 3530212, "node_id": "MDQ6VXNlcjM1MzAyMTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/3530212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sjperkins", "html_url": "https://github.com/sjperkins", "followers_url": "https://api.github.com/users/sjperkins/followers", "following_url": "https://api.github.com/users/sjperkins/following{/other_user}", "gists_url": "https://api.github.com/users/sjperkins/gists{/gist_id}", "starred_url": "https://api.github.com/users/sjperkins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sjperkins/subscriptions", "organizations_url": "https://api.github.com/users/sjperkins/orgs", "repos_url": "https://api.github.com/users/sjperkins/repos", "events_url": "https://api.github.com/users/sjperkins/events{/privacy}", "received_events_url": "https://api.github.com/users/sjperkins/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-07T11:30:03Z", "updated_at": "2016-10-07T15:26:10Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I also agree with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=476135\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mkolod\">@mkolod</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3979096\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/benbarsdell\">@benbarsdell</a>  that the H2D (and D2H) transfers can be problematic. Related to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"160137156\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2848\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2848/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2848\">#2848</a> where there is further discussion on tensorflow's GPU transfer scheduling. Part of the problem is that the Send/Recv ops are scheduled immediately and not necessarily in the order of their dependent operations. One suggested solution is to use <code>tf.identity</code> to order transfer to the GPU.</p>\n<p>Thinking on this some more, would multiple <code>towers</code> (in the cifar10 example terminology) per GPU be a solution? Is the scheduler intelligent enough to interleave the GPU transfers and compute for both towers in parallel? I'm trying to come up with something</p>", "body_text": "I also agree with @mkolod and @benbarsdell  that the H2D (and D2H) transfers can be problematic. Related to #2848 where there is further discussion on tensorflow's GPU transfer scheduling. Part of the problem is that the Send/Recv ops are scheduled immediately and not necessarily in the order of their dependent operations. One suggested solution is to use tf.identity to order transfer to the GPU.\nThinking on this some more, would multiple towers (in the cifar10 example terminology) per GPU be a solution? Is the scheduler intelligent enough to interleave the GPU transfers and compute for both towers in parallel? I'm trying to come up with something", "body": "I also agree with @mkolod and @benbarsdell  that the H2D (and D2H) transfers can be problematic. Related to #2848 where there is further discussion on tensorflow's GPU transfer scheduling. Part of the problem is that the Send/Recv ops are scheduled immediately and not necessarily in the order of their dependent operations. One suggested solution is to use `tf.identity` to order transfer to the GPU.\n\nThinking on this some more, would multiple `towers` (in the cifar10 example terminology) per GPU be a solution? Is the scheduler intelligent enough to interleave the GPU transfers and compute for both towers in parallel? I'm trying to come up with something \n"}