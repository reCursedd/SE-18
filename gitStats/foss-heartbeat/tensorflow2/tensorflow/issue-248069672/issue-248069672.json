{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12043", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12043/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12043/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12043/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12043", "id": 248069672, "node_id": "MDU6SXNzdWUyNDgwNjk2NzI=", "number": 12043, "title": "tf.contrib.util.make_ndarray is slow the first time it is run", "user": {"login": "chrisranderson", "id": 5461398, "node_id": "MDQ6VXNlcjU0NjEzOTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/5461398?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chrisranderson", "html_url": "https://github.com/chrisranderson", "followers_url": "https://api.github.com/users/chrisranderson/followers", "following_url": "https://api.github.com/users/chrisranderson/following{/other_user}", "gists_url": "https://api.github.com/users/chrisranderson/gists{/gist_id}", "starred_url": "https://api.github.com/users/chrisranderson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chrisranderson/subscriptions", "organizations_url": "https://api.github.com/users/chrisranderson/orgs", "repos_url": "https://api.github.com/users/chrisranderson/repos", "events_url": "https://api.github.com/users/chrisranderson/events{/privacy}", "received_events_url": "https://api.github.com/users/chrisranderson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-08-04T17:32:07Z", "updated_at": "2017-08-04T22:25:53Z", "closed_at": "2017-08-04T22:25:53Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<p><strong>Output of tf_env_collect.sh:</strong> <a href=\"https://github.com/tensorflow/tensorflow/files/1201133/tf_env.txt\">tf_env.txt</a></p>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>: binary</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>: v1.3.0-rc1-479-g82456f9 1.2.1-rc1</p>\n</li>\n<li>\n<p><strong>Python version</strong>: Python 3.5.2</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>: n/a</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\n== cuda libs  ===================================================<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61<br>\n/usr/local/cuda-8.0/lib64/libcudart_static.a<br>\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart.so.8.0<br>\n/usr/local/cuda-7.5/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-7.5/lib/libcudart.so.7.5.18<br>\n/usr/local/cuda-7.5/lib/libcudart_static.a<br>\n/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18<br>\n/usr/local/cuda-7.5/lib64/libcudart_static.a</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:</p>\n</li>\n</ul>\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 381.22                 Driver Version: 381.22                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1060    Off  | 0000:01:00.0      On |                  N/A |\n| N/A   48C    P0    28W /  N/A |    591MiB /  6064MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n</code></pre>\n<ul>\n<li><strong>Exact command to reproduce</strong>:<br>\nDownload  <a href=\"https://github.com/tensorflow/tensorflow/files/1201101/frame.summary.zip\">frame.summary.zip</a> and extract it to <code>frame.summary</code>. Some info about it:</li>\n</ul>\n<pre><code>tensor_proto dtype: DT_UINT8\ntensor_shape {\n  dim {\n    size: 1059\n  }\n  dim {\n    size: 768\n  }\n}\n</code></pre>\n<p>Run the following:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">from</span> google.protobuf <span class=\"pl-k\">import</span> message\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">2</span>):\n  path <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>frame.summary<span class=\"pl-pds\">'</span></span>\n  <span class=\"pl-k\">with</span> <span class=\"pl-c1\">open</span>(path, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> summary_file:\n    summary_string <span class=\"pl-k\">=</span> summary_file.read()\n\n  summary_proto <span class=\"pl-k\">=</span> tf.Summary()\n  summary_proto.ParseFromString(summary_string)\n  tensor_proto <span class=\"pl-k\">=</span> summary_proto.value[<span class=\"pl-c1\">0</span>].tensor\n  a <span class=\"pl-k\">=</span> time.time()\n  array <span class=\"pl-k\">=</span> tf.contrib.util.make_ndarray(tensor_proto)\n  b <span class=\"pl-k\">=</span> time.time()\n  <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>b-a<span class=\"pl-pds\">'</span></span>, b<span class=\"pl-k\">-</span>a)</pre></div>\n<h3>Describe the problem</h3>\n<p>The first time <code>make_ndarray</code> is run, it takes a long time. For this isolated example, the output is this on my machine:</p>\n<pre><code>b-a 2.810185194015503\nb-a 0.00030040740966796875\n</code></pre>\n<p>In my project, it took 105.96585726737976 for the first run, and 0.0005743503570556641 the second time (and closer to 0.0003 afterwards).</p>\n<h3>Source code / logs</h3>\n<p>Here is the branch I was using : <a href=\"https://github.com/chrisranderson/beholder/tree/bug-report\">https://github.com/chrisranderson/beholder/tree/bug-report</a><br>\nAnd the line that took ~105 seconds: <a href=\"https://github.com/chrisranderson/beholder/blob/b54d4203d803492af9852b7c8453e8a1e5342f46/beholder/file_system_tools.py#L34\">https://github.com/chrisranderson/beholder/blob/b54d4203d803492af9852b7c8453e8a1e5342f46/beholder/file_system_tools.py#L34</a></p>", "body_text": "System information\nOutput of tf_env_collect.sh: tf_env.txt\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\n\n\nTensorFlow installed from (source or binary): binary\n\n\nTensorFlow version (use command below): v1.3.0-rc1-479-g82456f9 1.2.1-rc1\n\n\nPython version: Python 3.5.2\n\n\nBazel version (if compiling from source): n/a\n\n\nCUDA/cuDNN version:\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart.so.8.0\n/usr/local/cuda-7.5/doc/man/man7/libcudart.7\n/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7\n/usr/local/cuda-7.5/lib/libcudart.so.7.5.18\n/usr/local/cuda-7.5/lib/libcudart_static.a\n/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\n/usr/local/cuda-7.5/lib64/libcudart_static.a\n\n\nGPU model and memory:\n\n\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 381.22                 Driver Version: 381.22                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1060    Off  | 0000:01:00.0      On |                  N/A |\n| N/A   48C    P0    28W /  N/A |    591MiB /  6064MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n\n\nExact command to reproduce:\nDownload  frame.summary.zip and extract it to frame.summary. Some info about it:\n\ntensor_proto dtype: DT_UINT8\ntensor_shape {\n  dim {\n    size: 1059\n  }\n  dim {\n    size: 768\n  }\n}\n\nRun the following:\nimport time\nfrom google.protobuf import message\nimport tensorflow as tf\n\nfor i in range(2):\n  path = 'frame.summary'\n  with open(path, 'rb') as summary_file:\n    summary_string = summary_file.read()\n\n  summary_proto = tf.Summary()\n  summary_proto.ParseFromString(summary_string)\n  tensor_proto = summary_proto.value[0].tensor\n  a = time.time()\n  array = tf.contrib.util.make_ndarray(tensor_proto)\n  b = time.time()\n  print('b-a', b-a)\nDescribe the problem\nThe first time make_ndarray is run, it takes a long time. For this isolated example, the output is this on my machine:\nb-a 2.810185194015503\nb-a 0.00030040740966796875\n\nIn my project, it took 105.96585726737976 for the first run, and 0.0005743503570556641 the second time (and closer to 0.0003 afterwards).\nSource code / logs\nHere is the branch I was using : https://github.com/chrisranderson/beholder/tree/bug-report\nAnd the line that took ~105 seconds: https://github.com/chrisranderson/beholder/blob/b54d4203d803492af9852b7c8453e8a1e5342f46/beholder/file_system_tools.py#L34", "body": "### System information\r\n\r\n**Output of tf_env_collect.sh:** [tf_env.txt](https://github.com/tensorflow/tensorflow/files/1201133/tf_env.txt)\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.3.0-rc1-479-g82456f9 1.2.1-rc1\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**:\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart.so.8.0\r\n/usr/local/cuda-7.5/doc/man/man7/libcudart.7\r\n/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-7.5/lib/libcudart.so.7.5.18\r\n/usr/local/cuda-7.5/lib/libcudart_static.a\r\n/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\r\n/usr/local/cuda-7.5/lib64/libcudart_static.a\r\n\r\n- **GPU model and memory**:\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 381.22                 Driver Version: 381.22                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1060    Off  | 0000:01:00.0      On |                  N/A |\r\n| N/A   48C    P0    28W /  N/A |    591MiB /  6064MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n```\r\n- **Exact command to reproduce**:\r\nDownload  [frame.summary.zip](https://github.com/tensorflow/tensorflow/files/1201101/frame.summary.zip) and extract it to `frame.summary`. Some info about it:\r\n\r\n```\r\ntensor_proto dtype: DT_UINT8\r\ntensor_shape {\r\n  dim {\r\n    size: 1059\r\n  }\r\n  dim {\r\n    size: 768\r\n  }\r\n}\r\n```\r\n\r\nRun the following:\r\n\r\n```python\r\nimport time\r\nfrom google.protobuf import message\r\nimport tensorflow as tf\r\n\r\nfor i in range(2):\r\n  path = 'frame.summary'\r\n  with open(path, 'rb') as summary_file:\r\n    summary_string = summary_file.read()\r\n\r\n  summary_proto = tf.Summary()\r\n  summary_proto.ParseFromString(summary_string)\r\n  tensor_proto = summary_proto.value[0].tensor\r\n  a = time.time()\r\n  array = tf.contrib.util.make_ndarray(tensor_proto)\r\n  b = time.time()\r\n  print('b-a', b-a)\r\n```\r\n\r\n### Describe the problem\r\nThe first time `make_ndarray` is run, it takes a long time. For this isolated example, the output is this on my machine:\r\n```\r\nb-a 2.810185194015503\r\nb-a 0.00030040740966796875\r\n```\r\nIn my project, it took 105.96585726737976 for the first run, and 0.0005743503570556641 the second time (and closer to 0.0003 afterwards).\r\n\r\n### Source code / logs\r\nHere is the branch I was using : https://github.com/chrisranderson/beholder/tree/bug-report\r\nAnd the line that took ~105 seconds: https://github.com/chrisranderson/beholder/blob/b54d4203d803492af9852b7c8453e8a1e5342f46/beholder/file_system_tools.py#L34\r\n\r\n\r\n"}