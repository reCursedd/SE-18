{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/266548668", "html_url": "https://github.com/tensorflow/tensorflow/issues/6224#issuecomment-266548668", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6224", "id": 266548668, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NjU0ODY2OA==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-12T20:50:41Z", "updated_at": "2016-12-12T20:50:41Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">The events are used to queue the freeing of memory that must stay live\nuntil completion.  If memory is not freed promptly it can cause the max\nmemory in use to exceed that available.  In that circumstance either the\nprogram fails or it slows down to wait for memory to be freed.\n\nYou could try varying the polling to see what happens.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Mon, Dec 12, 2016 at 12:38 PM, Zheng ***@***.***&gt; wrote:\n Can you please briefly explain why the lower polling frequency would slow\n down the overall program execution?\n\n From your reply, looks like it may affect any computation that is waiting\n on completion of event. But looks to me the polling would only lead to the\n destroy of events once these events are completed.\n\n If in any case the computation would wait on polling of events to proceed,\n then the execution model is not efficient. Events should automatically\n unblock computation with CUDA API like cuStreamWaitEvent, which I believe\n is in fact used by tensorflow in this regard.\n\n So it only makes sense to me that polling of events is used to release\n event resources once the events are complete. Then polling frequency is a\n matter that you want to have as lower frequency as possible but still make\n sure the GPUs are not out of resources for event allocation.\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"194694729\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/6224\" href=\"https://github.com/tensorflow/tensorflow/issues/6224#issuecomment-266545533\">#6224 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AO818Rgi848mm3NfnyIDsWR70ivzpyJtks5rHbDFgaJpZM4LJWUJ\">https://github.com/notifications/unsubscribe-auth/AO818Rgi848mm3NfnyIDsWR70ivzpyJtks5rHbDFgaJpZM4LJWUJ</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "The events are used to queue the freeing of memory that must stay live\nuntil completion.  If memory is not freed promptly it can cause the max\nmemory in use to exceed that available.  In that circumstance either the\nprogram fails or it slows down to wait for memory to be freed.\n\nYou could try varying the polling to see what happens.\n\u2026\nOn Mon, Dec 12, 2016 at 12:38 PM, Zheng ***@***.***> wrote:\n Can you please briefly explain why the lower polling frequency would slow\n down the overall program execution?\n\n From your reply, looks like it may affect any computation that is waiting\n on completion of event. But looks to me the polling would only lead to the\n destroy of events once these events are completed.\n\n If in any case the computation would wait on polling of events to proceed,\n then the execution model is not efficient. Events should automatically\n unblock computation with CUDA API like cuStreamWaitEvent, which I believe\n is in fact used by tensorflow in this regard.\n\n So it only makes sense to me that polling of events is used to release\n event resources once the events are complete. Then polling frequency is a\n matter that you want to have as lower frequency as possible but still make\n sure the GPUs are not out of resources for event allocation.\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n <#6224 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AO818Rgi848mm3NfnyIDsWR70ivzpyJtks5rHbDFgaJpZM4LJWUJ>\n .", "body": "The events are used to queue the freeing of memory that must stay live\nuntil completion.  If memory is not freed promptly it can cause the max\nmemory in use to exceed that available.  In that circumstance either the\nprogram fails or it slows down to wait for memory to be freed.\n\nYou could try varying the polling to see what happens.\n\n\nOn Mon, Dec 12, 2016 at 12:38 PM, Zheng <notifications@github.com> wrote:\n\n> Can you please briefly explain why the lower polling frequency would slow\n> down the overall program execution?\n>\n> From your reply, looks like it may affect any computation that is waiting\n> on completion of event. But looks to me the polling would only lead to the\n> destroy of events once these events are completed.\n>\n> If in any case the computation would wait on polling of events to proceed,\n> then the execution model is not efficient. Events should automatically\n> unblock computation with CUDA API like cuStreamWaitEvent, which I believe\n> is in fact used by tensorflow in this regard.\n>\n> So it only makes sense to me that polling of events is used to release\n> event resources once the events are complete. Then polling frequency is a\n> matter that you want to have as lower frequency as possible but still make\n> sure the GPUs are not out of resources for event allocation.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6224#issuecomment-266545533>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AO818Rgi848mm3NfnyIDsWR70ivzpyJtks5rHbDFgaJpZM4LJWUJ>\n> .\n>\n"}