{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/266508377", "html_url": "https://github.com/tensorflow/tensorflow/issues/6224#issuecomment-266508377", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6224", "id": 266508377, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NjUwODM3Nw==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-12T18:20:00Z", "updated_at": "2016-12-12T18:20:00Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13840805\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ZhengBitFusion\">@ZhengBitFusion</a>: I don't think your implied measure of efficiency is most useful in this case.</p>\n<p>If your measure is to poll the minimum number of times per queued event, then the optimal strategy would be to poll at an extremely long interval, say once per second or slower.  However, that would result in extremely slow overall program execution.</p>\n<p>The kind of efficiency most people care more about is getting the program to execute as quickly as possible, which is most easily accomplished by polling much more frequently, so that any potential computation waiting on completion of an event can begin as soon as possible.</p>\n<p>More generally, there is some conflict between increased polling frequency and overall computation speed, but only to the extent that use of one thread for polling blocks other necessary work that might otherwise use that thread.  And the extra gain provided by the part of that one thread not used for polling must be greater than the loss from polling less frequently.  If your TF program is mostly executing on GPUs, and you're using a modern CPU with many cores and hyperthreading, this seems unlikely.</p>\n<p>If you look at the polling logic source code in<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc#L123\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc#L123</a><br>\nyou can see the tradeoff explained, and that we try to achieve a good balance by polling at two different frequencies, depending on whether the last poll found the event queue empty.</p>\n<p>At the slower polling frequency,  it should poll about 1000/sec, which should consume only a small fraction of one core.  At the higher frequency it should poll about 100k/sec, which still probably doesn't consume a full core on a good processor.  You didn't say how long your 100 iterations takes, but it sounds like your program always had events queued, and hence always polled at full speed.</p>\n<p>We arrived at this polling strategy by experimentation with some test programs.  It's possible that a different strategy would result in slightly faster execution for your program.  Somewhat more likely, it's possible that a different strategy could yield equivalent performance but poll a little less often, if that matters to you.</p>\n<p>In any case, if you devise an alternative polling strategy that consistently yields better performance in practice, that would make a nice contribution.</p>", "body_text": "@ZhengBitFusion: I don't think your implied measure of efficiency is most useful in this case.\nIf your measure is to poll the minimum number of times per queued event, then the optimal strategy would be to poll at an extremely long interval, say once per second or slower.  However, that would result in extremely slow overall program execution.\nThe kind of efficiency most people care more about is getting the program to execute as quickly as possible, which is most easily accomplished by polling much more frequently, so that any potential computation waiting on completion of an event can begin as soon as possible.\nMore generally, there is some conflict between increased polling frequency and overall computation speed, but only to the extent that use of one thread for polling blocks other necessary work that might otherwise use that thread.  And the extra gain provided by the part of that one thread not used for polling must be greater than the loss from polling less frequently.  If your TF program is mostly executing on GPUs, and you're using a modern CPU with many cores and hyperthreading, this seems unlikely.\nIf you look at the polling logic source code in\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc#L123\nyou can see the tradeoff explained, and that we try to achieve a good balance by polling at two different frequencies, depending on whether the last poll found the event queue empty.\nAt the slower polling frequency,  it should poll about 1000/sec, which should consume only a small fraction of one core.  At the higher frequency it should poll about 100k/sec, which still probably doesn't consume a full core on a good processor.  You didn't say how long your 100 iterations takes, but it sounds like your program always had events queued, and hence always polled at full speed.\nWe arrived at this polling strategy by experimentation with some test programs.  It's possible that a different strategy would result in slightly faster execution for your program.  Somewhat more likely, it's possible that a different strategy could yield equivalent performance but poll a little less often, if that matters to you.\nIn any case, if you devise an alternative polling strategy that consistently yields better performance in practice, that would make a nice contribution.", "body": "@ZhengBitFusion: I don't think your implied measure of efficiency is most useful in this case.  \r\n\r\nIf your measure is to poll the minimum number of times per queued event, then the optimal strategy would be to poll at an extremely long interval, say once per second or slower.  However, that would result in extremely slow overall program execution.\r\n\r\nThe kind of efficiency most people care more about is getting the program to execute as quickly as possible, which is most easily accomplished by polling much more frequently, so that any potential computation waiting on completion of an event can begin as soon as possible.\r\n\r\nMore generally, there is some conflict between increased polling frequency and overall computation speed, but only to the extent that use of one thread for polling blocks other necessary work that might otherwise use that thread.  And the extra gain provided by the part of that one thread not used for polling must be greater than the loss from polling less frequently.  If your TF program is mostly executing on GPUs, and you're using a modern CPU with many cores and hyperthreading, this seems unlikely.  \r\n\r\nIf you look at the polling logic source code in\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc#L123\r\nyou can see the tradeoff explained, and that we try to achieve a good balance by polling at two different frequencies, depending on whether the last poll found the event queue empty.\r\n\r\nAt the slower polling frequency,  it should poll about 1000/sec, which should consume only a small fraction of one core.  At the higher frequency it should poll about 100k/sec, which still probably doesn't consume a full core on a good processor.  You didn't say how long your 100 iterations takes, but it sounds like your program always had events queued, and hence always polled at full speed.\r\n\r\nWe arrived at this polling strategy by experimentation with some test programs.  It's possible that a different strategy would result in slightly faster execution for your program.  Somewhat more likely, it's possible that a different strategy could yield equivalent performance but poll a little less often, if that matters to you.  \r\n\r\nIn any case, if you devise an alternative polling strategy that consistently yields better performance in practice, that would make a nice contribution."}