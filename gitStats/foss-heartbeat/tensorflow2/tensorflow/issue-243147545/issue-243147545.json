{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11512", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11512/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11512/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11512/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11512", "id": 243147545, "node_id": "MDU6SXNzdWUyNDMxNDc1NDU=", "number": 11512, "title": "Error in table.lookup from tf.contrib.lookup when using dataset api", "user": {"login": "Arvinds-ds", "id": 25126304, "node_id": "MDQ6VXNlcjI1MTI2MzA0", "avatar_url": "https://avatars3.githubusercontent.com/u/25126304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Arvinds-ds", "html_url": "https://github.com/Arvinds-ds", "followers_url": "https://api.github.com/users/Arvinds-ds/followers", "following_url": "https://api.github.com/users/Arvinds-ds/following{/other_user}", "gists_url": "https://api.github.com/users/Arvinds-ds/gists{/gist_id}", "starred_url": "https://api.github.com/users/Arvinds-ds/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Arvinds-ds/subscriptions", "organizations_url": "https://api.github.com/users/Arvinds-ds/orgs", "repos_url": "https://api.github.com/users/Arvinds-ds/repos", "events_url": "https://api.github.com/users/Arvinds-ds/events{/privacy}", "received_events_url": "https://api.github.com/users/Arvinds-ds/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-07-15T02:28:46Z", "updated_at": "2017-10-17T01:34:04Z", "closed_at": "2017-10-17T01:33:41Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: All platforms</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.2.1</li>\n<li><strong>Python version</strong>: 3.6, 2.7</li>\n</ul>\n<p>I try the following code:</p>\n<pre><code>vocab =tf.contrib.lookup.index_table_from_file('./vocab.txt', num_oov_buckets=1)\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(['./test1.txt']))\ndataset = dataset.flat_map(lambda filename: tf.contrib.data.TextLineDataset(filename))\ndataset = dataset.map(lambda line: tf.string_split([line]).values)\ndataset = dataset.map(lambda words: table.lookup(words))\n</code></pre>\n<p>gives me the following errors. This is different from the stack overflow issue:<br>\n<a href=\"https://stackoverflow.com/questions/44519045/new-dataset-map-transformation-and-lookup-table-incompatible-string-type\" rel=\"nofollow\">https://stackoverflow.com/questions/44519045/new-dataset-map-transformation-and-lookup-table-incompatible-string-type</a> and appears before referencing the iterator</p>\n<pre><code>----&gt; 1 dataset.map(lambda x: table.lookup(x))\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/lookup/lookup_ops.pyc in lookup(self, keys, name)\n    803             name=\"hash_bucket\")\n    804         if self._table:\n--&gt; 805           ids = self._table.lookup(values)\n    806           buckets = math_ops.add(buckets, self._table.size())\n    807           is_id_non_default = math_ops.not_equal(ids, self._table.default_value)\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/lookup/lookup_ops.pyc in lookup(self, keys, name)\n    184       # pylint: disable=protected-access\n    185       values = gen_lookup_ops._lookup_table_find(\n--&gt; 186           self._table_ref, key_tensor, self._default_value, name=scope)\n    187       # pylint: enable=protected-access\n    188 \n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_lookup_ops.pyc in _lookup_table_find(table_handle, keys, default_value, name)\n    286   result = _op_def_lib.apply_op(\"LookupTableFind\", table_handle=table_handle,\n    287                                 keys=keys, default_value=default_value,\n--&gt; 288                                 name=name)\n    289   return result\n    290 \n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)\n    765         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    766                          input_types=input_types, attrs=attr_protos,\n--&gt; 767                          op_def=op_def)\n    768         if output_structure:\n    769           outputs = op.outputs\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/data/python/framework/function.pyc in create_op(self, op_type, inputs, data_types, **kwargs)\n     79           self.extra_args.append(ph)\n     80     return super(_ExperimentalFuncGraph, self).create_op(op_type, inputs,\n---&gt; 81                                                          data_types, **kwargs)\n     82 \n     83   def _add_tensor_and_parents(self, tensor):\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/function.pyc in create_op(self, op_type, inputs, data_types, **kwargs)\n    359           self.extra_args.append(ph)\n    360     return super(_FuncGraph, self).create_op(op_type, inputs, data_types,\n--&gt; 361                                              **kwargs)\n    362 \n    363 \n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\n   2504     ret = Operation(node_def, self, inputs=inputs, output_types=dtypes,\n   2505                     control_inputs=control_inputs, input_types=input_types,\n-&gt; 2506                     original_op=self._default_original_op, op_def=op_def)\n   2507     if compute_shapes:\n   2508       set_shapes_for_outputs(ret)\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\n   1248                             self.node_def.name,\n   1249                             [i.dtype for i in self._inputs],\n-&gt; 1250                             input_types))\n   1251     self._input_types = input_types\n   1252 \n\nTypeError: In op 'string_to_index_Lookup/hash_table_Lookup', \ninput types ([tf.string, tf.string, tf.int64]) are not compatible with expected types\n ([tf.string_ref, tf.string, tf.int64])\n</code></pre>\n<p>However if I use the following referencing python_lookup_ops as outline in NMT, there is no issue..<br>\nWhy is this?</p>\n<pre><code>from tensorflow.python.ops import lookup_ops\ntable = lookup_ops.index_table_from_file('./vocab.txt', num_oov_buckets=1)\n</code></pre>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): All platforms\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.2.1\nPython version: 3.6, 2.7\n\nI try the following code:\nvocab =tf.contrib.lookup.index_table_from_file('./vocab.txt', num_oov_buckets=1)\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(['./test1.txt']))\ndataset = dataset.flat_map(lambda filename: tf.contrib.data.TextLineDataset(filename))\ndataset = dataset.map(lambda line: tf.string_split([line]).values)\ndataset = dataset.map(lambda words: table.lookup(words))\n\ngives me the following errors. This is different from the stack overflow issue:\nhttps://stackoverflow.com/questions/44519045/new-dataset-map-transformation-and-lookup-table-incompatible-string-type and appears before referencing the iterator\n----> 1 dataset.map(lambda x: table.lookup(x))\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/lookup/lookup_ops.pyc in lookup(self, keys, name)\n    803             name=\"hash_bucket\")\n    804         if self._table:\n--> 805           ids = self._table.lookup(values)\n    806           buckets = math_ops.add(buckets, self._table.size())\n    807           is_id_non_default = math_ops.not_equal(ids, self._table.default_value)\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/lookup/lookup_ops.pyc in lookup(self, keys, name)\n    184       # pylint: disable=protected-access\n    185       values = gen_lookup_ops._lookup_table_find(\n--> 186           self._table_ref, key_tensor, self._default_value, name=scope)\n    187       # pylint: enable=protected-access\n    188 \n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_lookup_ops.pyc in _lookup_table_find(table_handle, keys, default_value, name)\n    286   result = _op_def_lib.apply_op(\"LookupTableFind\", table_handle=table_handle,\n    287                                 keys=keys, default_value=default_value,\n--> 288                                 name=name)\n    289   return result\n    290 \n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)\n    765         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    766                          input_types=input_types, attrs=attr_protos,\n--> 767                          op_def=op_def)\n    768         if output_structure:\n    769           outputs = op.outputs\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/data/python/framework/function.pyc in create_op(self, op_type, inputs, data_types, **kwargs)\n     79           self.extra_args.append(ph)\n     80     return super(_ExperimentalFuncGraph, self).create_op(op_type, inputs,\n---> 81                                                          data_types, **kwargs)\n     82 \n     83   def _add_tensor_and_parents(self, tensor):\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/function.pyc in create_op(self, op_type, inputs, data_types, **kwargs)\n    359           self.extra_args.append(ph)\n    360     return super(_FuncGraph, self).create_op(op_type, inputs, data_types,\n--> 361                                              **kwargs)\n    362 \n    363 \n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\n   2504     ret = Operation(node_def, self, inputs=inputs, output_types=dtypes,\n   2505                     control_inputs=control_inputs, input_types=input_types,\n-> 2506                     original_op=self._default_original_op, op_def=op_def)\n   2507     if compute_shapes:\n   2508       set_shapes_for_outputs(ret)\n\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\n   1248                             self.node_def.name,\n   1249                             [i.dtype for i in self._inputs],\n-> 1250                             input_types))\n   1251     self._input_types = input_types\n   1252 \n\nTypeError: In op 'string_to_index_Lookup/hash_table_Lookup', \ninput types ([tf.string, tf.string, tf.int64]) are not compatible with expected types\n ([tf.string_ref, tf.string, tf.int64])\n\nHowever if I use the following referencing python_lookup_ops as outline in NMT, there is no issue..\nWhy is this?\nfrom tensorflow.python.ops import lookup_ops\ntable = lookup_ops.index_table_from_file('./vocab.txt', num_oov_buckets=1)", "body": "\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: All platforms\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.2.1\r\n- **Python version**: 3.6, 2.7\r\n\r\nI try the following code:\r\n\r\n```\r\nvocab =tf.contrib.lookup.index_table_from_file('./vocab.txt', num_oov_buckets=1)\r\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(['./test1.txt']))\r\ndataset = dataset.flat_map(lambda filename: tf.contrib.data.TextLineDataset(filename))\r\ndataset = dataset.map(lambda line: tf.string_split([line]).values)\r\ndataset = dataset.map(lambda words: table.lookup(words))\r\n```\r\ngives me the following errors. This is different from the stack overflow issue:\r\nhttps://stackoverflow.com/questions/44519045/new-dataset-map-transformation-and-lookup-table-incompatible-string-type and appears before referencing the iterator\r\n\r\n\r\n```\r\n----> 1 dataset.map(lambda x: table.lookup(x))\r\n\r\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/lookup/lookup_ops.pyc in lookup(self, keys, name)\r\n    803             name=\"hash_bucket\")\r\n    804         if self._table:\r\n--> 805           ids = self._table.lookup(values)\r\n    806           buckets = math_ops.add(buckets, self._table.size())\r\n    807           is_id_non_default = math_ops.not_equal(ids, self._table.default_value)\r\n\r\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/lookup/lookup_ops.pyc in lookup(self, keys, name)\r\n    184       # pylint: disable=protected-access\r\n    185       values = gen_lookup_ops._lookup_table_find(\r\n--> 186           self._table_ref, key_tensor, self._default_value, name=scope)\r\n    187       # pylint: enable=protected-access\r\n    188 \r\n\r\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_lookup_ops.pyc in _lookup_table_find(table_handle, keys, default_value, name)\r\n    286   result = _op_def_lib.apply_op(\"LookupTableFind\", table_handle=table_handle,\r\n    287                                 keys=keys, default_value=default_value,\r\n--> 288                                 name=name)\r\n    289   return result\r\n    290 \r\n\r\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)\r\n    765         op = g.create_op(op_type_name, inputs, output_types, name=scope,\r\n    766                          input_types=input_types, attrs=attr_protos,\r\n--> 767                          op_def=op_def)\r\n    768         if output_structure:\r\n    769           outputs = op.outputs\r\n\r\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/data/python/framework/function.pyc in create_op(self, op_type, inputs, data_types, **kwargs)\r\n     79           self.extra_args.append(ph)\r\n     80     return super(_ExperimentalFuncGraph, self).create_op(op_type, inputs,\r\n---> 81                                                          data_types, **kwargs)\r\n     82 \r\n     83   def _add_tensor_and_parents(self, tensor):\r\n\r\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/function.pyc in create_op(self, op_type, inputs, data_types, **kwargs)\r\n    359           self.extra_args.append(ph)\r\n    360     return super(_FuncGraph, self).create_op(op_type, inputs, data_types,\r\n--> 361                                              **kwargs)\r\n    362 \r\n    363 \r\n\r\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\r\n   2504     ret = Operation(node_def, self, inputs=inputs, output_types=dtypes,\r\n   2505                     control_inputs=control_inputs, input_types=input_types,\r\n-> 2506                     original_op=self._default_original_op, op_def=op_def)\r\n   2507     if compute_shapes:\r\n   2508       set_shapes_for_outputs(ret)\r\n\r\n/Users/xxx/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\r\n   1248                             self.node_def.name,\r\n   1249                             [i.dtype for i in self._inputs],\r\n-> 1250                             input_types))\r\n   1251     self._input_types = input_types\r\n   1252 \r\n\r\nTypeError: In op 'string_to_index_Lookup/hash_table_Lookup', \r\ninput types ([tf.string, tf.string, tf.int64]) are not compatible with expected types\r\n ([tf.string_ref, tf.string, tf.int64])\r\n```\r\nHowever if I use the following referencing python_lookup_ops as outline in NMT, there is no issue..\r\nWhy is this?\r\n\r\n```\r\nfrom tensorflow.python.ops import lookup_ops\r\ntable = lookup_ops.index_table_from_file('./vocab.txt', num_oov_buckets=1)\r\n```"}