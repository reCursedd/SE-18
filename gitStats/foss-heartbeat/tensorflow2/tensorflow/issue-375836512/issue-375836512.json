{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23397", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23397/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23397/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23397/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23397", "id": 375836512, "node_id": "MDU6SXNzdWUzNzU4MzY1MTI=", "number": 23397, "title": "parallel_for: No converter defined for MaxPoolGradGrad", "user": {"login": "jonasrauber", "id": 5837385, "node_id": "MDQ6VXNlcjU4MzczODU=", "avatar_url": "https://avatars1.githubusercontent.com/u/5837385?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonasrauber", "html_url": "https://github.com/jonasrauber", "followers_url": "https://api.github.com/users/jonasrauber/followers", "following_url": "https://api.github.com/users/jonasrauber/following{/other_user}", "gists_url": "https://api.github.com/users/jonasrauber/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonasrauber/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonasrauber/subscriptions", "organizations_url": "https://api.github.com/users/jonasrauber/orgs", "repos_url": "https://api.github.com/users/jonasrauber/repos", "events_url": "https://api.github.com/users/jonasrauber/events{/privacy}", "received_events_url": "https://api.github.com/users/jonasrauber/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097547147, "node_id": "MDU6TGFiZWwxMDk3NTQ3MTQ3", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:ops", "name": "comp:ops", "color": "0052cc", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "agarwal-ashish", "id": 19335798, "node_id": "MDQ6VXNlcjE5MzM1Nzk4", "avatar_url": "https://avatars3.githubusercontent.com/u/19335798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agarwal-ashish", "html_url": "https://github.com/agarwal-ashish", "followers_url": "https://api.github.com/users/agarwal-ashish/followers", "following_url": "https://api.github.com/users/agarwal-ashish/following{/other_user}", "gists_url": "https://api.github.com/users/agarwal-ashish/gists{/gist_id}", "starred_url": "https://api.github.com/users/agarwal-ashish/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agarwal-ashish/subscriptions", "organizations_url": "https://api.github.com/users/agarwal-ashish/orgs", "repos_url": "https://api.github.com/users/agarwal-ashish/repos", "events_url": "https://api.github.com/users/agarwal-ashish/events{/privacy}", "received_events_url": "https://api.github.com/users/agarwal-ashish/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "agarwal-ashish", "id": 19335798, "node_id": "MDQ6VXNlcjE5MzM1Nzk4", "avatar_url": "https://avatars3.githubusercontent.com/u/19335798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agarwal-ashish", "html_url": "https://github.com/agarwal-ashish", "followers_url": "https://api.github.com/users/agarwal-ashish/followers", "following_url": "https://api.github.com/users/agarwal-ashish/following{/other_user}", "gists_url": "https://api.github.com/users/agarwal-ashish/gists{/gist_id}", "starred_url": "https://api.github.com/users/agarwal-ashish/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agarwal-ashish/subscriptions", "organizations_url": "https://api.github.com/users/agarwal-ashish/orgs", "repos_url": "https://api.github.com/users/agarwal-ashish/repos", "events_url": "https://api.github.com/users/agarwal-ashish/events{/privacy}", "received_events_url": "https://api.github.com/users/agarwal-ashish/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-10-31T07:44:09Z", "updated_at": "2018-11-11T20:44:48Z", "closed_at": "2018-11-07T20:59:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have written a <code>fwd_gradients</code>-based implementation of <code>batch_jacobian</code> (comparable to the <code>tf.gradients</code>-based <code>tensorflow.python.ops.parallel_for.batch_jacobian</code>). To efficiently implement <code>batch_jacobian</code>, TensorFlow added support <code>parallel_for</code>: unfortunately, <code>pfor</code> does not support the <code>MaxPoolGradGrad</code> op, requiring a fallback to a slow while loop. For performance reasons, it would be great to add a converter for <code>MaxPoolGradGrad</code> to <code>parallel_for</code>.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nThe following code is a minimal example to reproduce the issue and can be run as is.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>!/usr/bin/env python3</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.ops.parallel_for <span class=\"pl-k\">import</span> control_flow_ops\n<span class=\"pl-k\">from</span> tensorflow.contrib.nn.python.ops.fwd_gradients <span class=\"pl-k\">import</span> fwd_gradients\n<span class=\"pl-k\">from</span> tensorflow.python.platform <span class=\"pl-k\">import</span> flags\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n    sess <span class=\"pl-k\">=</span> tf.InteractiveSession()\n\n    <span class=\"pl-c1\">print</span>(tf.<span class=\"pl-c1\">__version__</span>)\n\n    flags.FLAGS(sys.argv)\n\n    x <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, (<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>))\n    y <span class=\"pl-k\">=</span> tf.nn.max_pool(x, (<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>)\n\n    input_shape <span class=\"pl-k\">=</span> tf.shape(x)\n    batch_size <span class=\"pl-k\">=</span> input_shape[<span class=\"pl-c1\">0</span>]\n\n    input_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4</span>\n    one_hot_vectors <span class=\"pl-k\">=</span> tf.eye(input_size)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">loop_fn</span>(<span class=\"pl-smi\">i</span>):\n        one_hot <span class=\"pl-k\">=</span> tf.gather(one_hot_vectors, i)\n        one_hot <span class=\"pl-k\">=</span> one_hot[tf.newaxis]\n        grad_inputs <span class=\"pl-k\">=</span> tf.tile(one_hot, (batch_size, <span class=\"pl-c1\">1</span>))\n        grad_inputs <span class=\"pl-k\">=</span> tf.reshape(grad_inputs, input_shape)\n        g <span class=\"pl-k\">=</span> fwd_gradients([y], [x], [grad_inputs])\n        <span class=\"pl-k\">assert</span> <span class=\"pl-c1\">len</span>(g) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">1</span>\n        <span class=\"pl-c1\">print</span>(g[<span class=\"pl-c1\">0</span>])\n        <span class=\"pl-k\">return</span> g[<span class=\"pl-c1\">0</span>]\n\n    J <span class=\"pl-k\">=</span> control_flow_ops.pfor(loop_fn, <span class=\"pl-c1\">4</span>)\n\n    x_ <span class=\"pl-k\">=</span> np.array([<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>]).reshape(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>)\n    y_, J_ <span class=\"pl-k\">=</span> sess.run([y, J], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x: x_})\n    <span class=\"pl-c1\">print</span>(x_.squeeze())\n    <span class=\"pl-c1\">print</span>(y_.squeeze())\n    <span class=\"pl-c1\">print</span>(J_.squeeze())\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    main()</pre></div>\n<p><strong>Describe the current behavior</strong></p>\n<pre><code>1.11.0\nTensor(\"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad:0\", shape=(?, 2, 2, 1), dtype=float32)\nTraceback (most recent call last):\n  File \"./minimal_example.py\", line 46, in &lt;module&gt;\n    main()\n  File \"./minimal_example.py\", line 36, in main\n    J = control_flow_ops.pfor(loop_fn, 4)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 129, in pfor\n    outputs.append(converter.convert(loop_fn_output))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py\", line 1077, in convert\n    output = self._convert_helper(y)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py\", line 1223, in _convert_helper\n    \"which may run slower\" % (y_op.type, y_op, converted_inputs))\nValueError: No converter defined for MaxPoolGradGrad\nname: \"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad\"\nop: \"MaxPoolGradGrad\"\ninput: \"Placeholder\"\ninput: \"MaxPool\"\ninput: \"loop_body/gradients_1/grad_ys_0\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"data_format\"\n  value {\n    s: \"NHWC\"\n  }\n}\nattr {\n  key: \"ksize\"\n  value {\n    list {\n      i: 1\n      i: 2\n      i: 2\n      i: 1\n    }\n  }\n}\nattr {\n  key: \"padding\"\n  value {\n    s: \"SAME\"\n  }\n}\nattr {\n  key: \"strides\"\n  value {\n    list {\n      i: 1\n      i: 1\n      i: 1\n      i: 1\n    }\n  }\n}\n\ninputs: [WrappedTensor(t=&lt;tf.Tensor 'Placeholder:0' shape=(?, 2, 2, 1) dtype=float32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'MaxPool:0' shape=(?, 2, 2, 1) dtype=float32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'loop_body/gradients_1/grad_ys_0/pfor/Identity:0' shape=(4, ?, 2, 2, 1) dtype=float32&gt;, is_stacked=True, is_sparse_stacked=False)]. \nEither add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower\n</code></pre>\n<p><strong>Describe the expected behavior</strong><br>\n(produced by running the above script with <code>--op_conversion_fallback_to_while_loop</code>)</p>\n<pre><code>1.11.0\nTensor(\"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad:0\", shape=(?, 2, 2, 1), dtype=float32)\nWARNING:tensorflow:Using a while_loop for converting MaxPoolGradGrad\n[[4 1]\n [2 3]]\n[[4. 3.]\n [3. 3.]]\n[[[1. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]]\n\n [[0. 1.]\n  [1. 1.]]]\n</code></pre>\n<p>P.S. If you are interested, I'd be happy to contribute my <code>fwd_gradients</code>-based <code>batch_jacobian</code> to TensorFlow once this performance issue with MaxPool ops is fixed and I've cleaned up my code.</p>", "body_text": "I have written a fwd_gradients-based implementation of batch_jacobian (comparable to the tf.gradients-based tensorflow.python.ops.parallel_for.batch_jacobian). To efficiently implement batch_jacobian, TensorFlow added support parallel_for: unfortunately, pfor does not support the MaxPoolGradGrad op, requiring a fallback to a slow while loop. For performance reasons, it would be great to add a converter for MaxPoolGradGrad to parallel_for.\nCode to reproduce the issue\nThe following code is a minimal example to reproduce the issue and can be run as is.\n#!/usr/bin/env python3\nimport tensorflow as tf\nfrom tensorflow.python.ops.parallel_for import control_flow_ops\nfrom tensorflow.contrib.nn.python.ops.fwd_gradients import fwd_gradients\nfrom tensorflow.python.platform import flags\nimport sys\nimport numpy as np\n\n\ndef main():\n    sess = tf.InteractiveSession()\n\n    print(tf.__version__)\n\n    flags.FLAGS(sys.argv)\n\n    x = tf.placeholder(tf.float32, (None, 2, 2, 1))\n    y = tf.nn.max_pool(x, (1, 2, 2, 1), strides=(1, 1, 1, 1), padding='SAME')\n\n    input_shape = tf.shape(x)\n    batch_size = input_shape[0]\n\n    input_size = 4\n    one_hot_vectors = tf.eye(input_size)\n\n    def loop_fn(i):\n        one_hot = tf.gather(one_hot_vectors, i)\n        one_hot = one_hot[tf.newaxis]\n        grad_inputs = tf.tile(one_hot, (batch_size, 1))\n        grad_inputs = tf.reshape(grad_inputs, input_shape)\n        g = fwd_gradients([y], [x], [grad_inputs])\n        assert len(g) == 1\n        print(g[0])\n        return g[0]\n\n    J = control_flow_ops.pfor(loop_fn, 4)\n\n    x_ = np.array([4, 1, 2, 3]).reshape(1, 2, 2, 1)\n    y_, J_ = sess.run([y, J], feed_dict={x: x_})\n    print(x_.squeeze())\n    print(y_.squeeze())\n    print(J_.squeeze())\n\n\nif __name__ == '__main__':\n    main()\nDescribe the current behavior\n1.11.0\nTensor(\"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad:0\", shape=(?, 2, 2, 1), dtype=float32)\nTraceback (most recent call last):\n  File \"./minimal_example.py\", line 46, in <module>\n    main()\n  File \"./minimal_example.py\", line 36, in main\n    J = control_flow_ops.pfor(loop_fn, 4)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 129, in pfor\n    outputs.append(converter.convert(loop_fn_output))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py\", line 1077, in convert\n    output = self._convert_helper(y)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py\", line 1223, in _convert_helper\n    \"which may run slower\" % (y_op.type, y_op, converted_inputs))\nValueError: No converter defined for MaxPoolGradGrad\nname: \"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad\"\nop: \"MaxPoolGradGrad\"\ninput: \"Placeholder\"\ninput: \"MaxPool\"\ninput: \"loop_body/gradients_1/grad_ys_0\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"data_format\"\n  value {\n    s: \"NHWC\"\n  }\n}\nattr {\n  key: \"ksize\"\n  value {\n    list {\n      i: 1\n      i: 2\n      i: 2\n      i: 1\n    }\n  }\n}\nattr {\n  key: \"padding\"\n  value {\n    s: \"SAME\"\n  }\n}\nattr {\n  key: \"strides\"\n  value {\n    list {\n      i: 1\n      i: 1\n      i: 1\n      i: 1\n    }\n  }\n}\n\ninputs: [WrappedTensor(t=<tf.Tensor 'Placeholder:0' shape=(?, 2, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'MaxPool:0' shape=(?, 2, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/gradients_1/grad_ys_0/pfor/Identity:0' shape=(4, ?, 2, 2, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False)]. \nEither add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower\n\nDescribe the expected behavior\n(produced by running the above script with --op_conversion_fallback_to_while_loop)\n1.11.0\nTensor(\"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad:0\", shape=(?, 2, 2, 1), dtype=float32)\nWARNING:tensorflow:Using a while_loop for converting MaxPoolGradGrad\n[[4 1]\n [2 3]]\n[[4. 3.]\n [3. 3.]]\n[[[1. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]]\n\n [[0. 1.]\n  [1. 1.]]]\n\nP.S. If you are interested, I'd be happy to contribute my fwd_gradients-based batch_jacobian to TensorFlow once this performance issue with MaxPool ops is fixed and I've cleaned up my code.", "body": "I have written a `fwd_gradients`-based implementation of `batch_jacobian` (comparable to the `tf.gradients`-based `tensorflow.python.ops.parallel_for.batch_jacobian`). To efficiently implement `batch_jacobian`, TensorFlow added support `parallel_for`: unfortunately, `pfor` does not support the `MaxPoolGradGrad` op, requiring a fallback to a slow while loop. For performance reasons, it would be great to add a converter for `MaxPoolGradGrad` to `parallel_for`.\r\n\r\n**Code to reproduce the issue**\r\nThe following code is a minimal example to reproduce the issue and can be run as is.\r\n\r\n```python\r\n#!/usr/bin/env python3\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops.parallel_for import control_flow_ops\r\nfrom tensorflow.contrib.nn.python.ops.fwd_gradients import fwd_gradients\r\nfrom tensorflow.python.platform import flags\r\nimport sys\r\nimport numpy as np\r\n\r\n\r\ndef main():\r\n    sess = tf.InteractiveSession()\r\n\r\n    print(tf.__version__)\r\n\r\n    flags.FLAGS(sys.argv)\r\n\r\n    x = tf.placeholder(tf.float32, (None, 2, 2, 1))\r\n    y = tf.nn.max_pool(x, (1, 2, 2, 1), strides=(1, 1, 1, 1), padding='SAME')\r\n\r\n    input_shape = tf.shape(x)\r\n    batch_size = input_shape[0]\r\n\r\n    input_size = 4\r\n    one_hot_vectors = tf.eye(input_size)\r\n\r\n    def loop_fn(i):\r\n        one_hot = tf.gather(one_hot_vectors, i)\r\n        one_hot = one_hot[tf.newaxis]\r\n        grad_inputs = tf.tile(one_hot, (batch_size, 1))\r\n        grad_inputs = tf.reshape(grad_inputs, input_shape)\r\n        g = fwd_gradients([y], [x], [grad_inputs])\r\n        assert len(g) == 1\r\n        print(g[0])\r\n        return g[0]\r\n\r\n    J = control_flow_ops.pfor(loop_fn, 4)\r\n\r\n    x_ = np.array([4, 1, 2, 3]).reshape(1, 2, 2, 1)\r\n    y_, J_ = sess.run([y, J], feed_dict={x: x_})\r\n    print(x_.squeeze())\r\n    print(y_.squeeze())\r\n    print(J_.squeeze())\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n**Describe the current behavior**\r\n```\r\n1.11.0\r\nTensor(\"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad:0\", shape=(?, 2, 2, 1), dtype=float32)\r\nTraceback (most recent call last):\r\n  File \"./minimal_example.py\", line 46, in <module>\r\n    main()\r\n  File \"./minimal_example.py\", line 36, in main\r\n    J = control_flow_ops.pfor(loop_fn, 4)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 129, in pfor\r\n    outputs.append(converter.convert(loop_fn_output))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py\", line 1077, in convert\r\n    output = self._convert_helper(y)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py\", line 1223, in _convert_helper\r\n    \"which may run slower\" % (y_op.type, y_op, converted_inputs))\r\nValueError: No converter defined for MaxPoolGradGrad\r\nname: \"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad\"\r\nop: \"MaxPoolGradGrad\"\r\ninput: \"Placeholder\"\r\ninput: \"MaxPool\"\r\ninput: \"loop_body/gradients_1/grad_ys_0\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"data_format\"\r\n  value {\r\n    s: \"NHWC\"\r\n  }\r\n}\r\nattr {\r\n  key: \"ksize\"\r\n  value {\r\n    list {\r\n      i: 1\r\n      i: 2\r\n      i: 2\r\n      i: 1\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"padding\"\r\n  value {\r\n    s: \"SAME\"\r\n  }\r\n}\r\nattr {\r\n  key: \"strides\"\r\n  value {\r\n    list {\r\n      i: 1\r\n      i: 1\r\n      i: 1\r\n      i: 1\r\n    }\r\n  }\r\n}\r\n\r\ninputs: [WrappedTensor(t=<tf.Tensor 'Placeholder:0' shape=(?, 2, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'MaxPool:0' shape=(?, 2, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/gradients_1/grad_ys_0/pfor/Identity:0' shape=(4, ?, 2, 2, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False)]. \r\nEither add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower\r\n```\r\n\r\n**Describe the expected behavior**\r\n(produced by running the above script with `--op_conversion_fallback_to_while_loop`)\r\n\r\n```\r\n1.11.0\r\nTensor(\"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad:0\", shape=(?, 2, 2, 1), dtype=float32)\r\nWARNING:tensorflow:Using a while_loop for converting MaxPoolGradGrad\r\n[[4 1]\r\n [2 3]]\r\n[[4. 3.]\r\n [3. 3.]]\r\n[[[1. 0.]\r\n  [0. 0.]]\r\n\r\n [[0. 0.]\r\n  [0. 0.]]\r\n\r\n [[0. 0.]\r\n  [0. 0.]]\r\n\r\n [[0. 1.]\r\n  [1. 1.]]]\r\n```\r\n\r\nP.S. If you are interested, I'd be happy to contribute my `fwd_gradients`-based `batch_jacobian` to TensorFlow once this performance issue with MaxPool ops is fixed and I've cleaned up my code."}