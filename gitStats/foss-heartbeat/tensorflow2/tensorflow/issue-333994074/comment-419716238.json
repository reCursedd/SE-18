{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/419716238", "html_url": "https://github.com/tensorflow/tensorflow/issues/20141#issuecomment-419716238", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20141", "id": 419716238, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTcxNjIzOA==", "user": {"login": "calicratis19", "id": 1763767, "node_id": "MDQ6VXNlcjE3NjM3Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1763767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calicratis19", "html_url": "https://github.com/calicratis19", "followers_url": "https://api.github.com/users/calicratis19/followers", "following_url": "https://api.github.com/users/calicratis19/following{/other_user}", "gists_url": "https://api.github.com/users/calicratis19/gists{/gist_id}", "starred_url": "https://api.github.com/users/calicratis19/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calicratis19/subscriptions", "organizations_url": "https://api.github.com/users/calicratis19/orgs", "repos_url": "https://api.github.com/users/calicratis19/repos", "events_url": "https://api.github.com/users/calicratis19/events{/privacy}", "received_events_url": "https://api.github.com/users/calicratis19/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-09T13:31:39Z", "updated_at": "2018-09-09T13:34:26Z", "author_association": "NONE", "body_html": "<p>I'm getting same type of error for xception model.</p>\n<p><em>Array Cast, which is an input to the ResizeBilinear operator producing the output array ResizeBilinear, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.</em></p>\n<p>The model is downloaded from tensorflow deeplab repo.</p>\n<p>The command that generated the error was</p>\n<pre><code>bazel-bin/tensorflow/contrib/lite/toco/toco \\\n--input_file=frozen_inference_graph.pb \\\n--input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE \\\n--output_file=xception.lite \\\n--inference_type=QUANTIZED_UINT8 \\\n--input_arrays=ImageTensor \\\n--output_arrays=SemanticPredictions \\\n--input_shapes=1,299,299,3\n</code></pre>", "body_text": "I'm getting same type of error for xception model.\nArray Cast, which is an input to the ResizeBilinear operator producing the output array ResizeBilinear, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\nThe model is downloaded from tensorflow deeplab repo.\nThe command that generated the error was\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\n--input_file=frozen_inference_graph.pb \\\n--input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE \\\n--output_file=xception.lite \\\n--inference_type=QUANTIZED_UINT8 \\\n--input_arrays=ImageTensor \\\n--output_arrays=SemanticPredictions \\\n--input_shapes=1,299,299,3", "body": "I'm getting same type of error for xception model.\r\n\r\n_Array Cast, which is an input to the ResizeBilinear operator producing the output array ResizeBilinear, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation._\r\n\r\nThe model is downloaded from tensorflow deeplab repo.\r\n\r\nThe command that generated the error was\r\n\r\n```\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n--input_file=frozen_inference_graph.pb \\\r\n--input_format=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE \\\r\n--output_file=xception.lite \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--input_arrays=ImageTensor \\\r\n--output_arrays=SemanticPredictions \\\r\n--input_shapes=1,299,299,3\r\n```"}