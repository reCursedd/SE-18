{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347276740", "html_url": "https://github.com/tensorflow/tensorflow/issues/14732#issuecomment-347276740", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14732", "id": 347276740, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzI3Njc0MA==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-27T18:24:30Z", "updated_at": "2017-11-28T01:37:58Z", "author_association": "MEMBER", "body_html": "<p>Apologies for the late response, I was out. Long story short: This behavior is intended and it isn't a bug :)</p>\n<p>The <code>tf.data</code> API defines input processing as a dataflow graph that is executed by the TensorFlow runtime. In the code sample above, the call to <code>dataset.flat_map</code> expects a function that constructs the dataflow graph defining the transformations to be performed. As a result, you'll observe that breakpoint 1 will be triggered by the call to <code>dataset.flat_map</code> and not by the call to <code>i.next()</code>. In a program that iterates over the dataset, you'll observe that the breakpoint is hit exactly once, and not once per call to <code>i.next()</code>.</p>\n<p>Expressing the input pipeline as a dataflow graph enables efficient background input processing - allowing multiple input tensors to be processed concurrently (e.g., multiple threads for <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map\" rel=\"nofollow\"><code>tf.data.Dataset.map</code></a>), and for input processing to be conducted concurrently with model computation. By doing so, input processing isn't bottlenecked on the single Python interpreter thread.</p>\n<p>That said, a workaround would be to use something like a <code>tf.py_func</code> which will bring control to the Python interpreter. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1994308\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/akshayka\">@akshayka</a> is actively working on a <code>tfe.py_func</code> which will make this possible (at an efficiency cost of sharing the single Python interpreter thread).</p>\n<p>Please let me know if the comment makes sense.</p>\n<p>I'm going to keep the issue open and we can close it when <code>tfe.py_func</code> is in place and we can provide you with a sample of how to use it in your input pipeline.</p>\n<p>FYI <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1072079\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jsimsa\">@jsimsa</a></p>", "body_text": "Apologies for the late response, I was out. Long story short: This behavior is intended and it isn't a bug :)\nThe tf.data API defines input processing as a dataflow graph that is executed by the TensorFlow runtime. In the code sample above, the call to dataset.flat_map expects a function that constructs the dataflow graph defining the transformations to be performed. As a result, you'll observe that breakpoint 1 will be triggered by the call to dataset.flat_map and not by the call to i.next(). In a program that iterates over the dataset, you'll observe that the breakpoint is hit exactly once, and not once per call to i.next().\nExpressing the input pipeline as a dataflow graph enables efficient background input processing - allowing multiple input tensors to be processed concurrently (e.g., multiple threads for tf.data.Dataset.map), and for input processing to be conducted concurrently with model computation. By doing so, input processing isn't bottlenecked on the single Python interpreter thread.\nThat said, a workaround would be to use something like a tf.py_func which will bring control to the Python interpreter. @akshayka is actively working on a tfe.py_func which will make this possible (at an efficiency cost of sharing the single Python interpreter thread).\nPlease let me know if the comment makes sense.\nI'm going to keep the issue open and we can close it when tfe.py_func is in place and we can provide you with a sample of how to use it in your input pipeline.\nFYI @mrry @jsimsa", "body": "Apologies for the late response, I was out. Long story short: This behavior is intended and it isn't a bug :)\r\n\r\nThe `tf.data` API defines input processing as a dataflow graph that is executed by the TensorFlow runtime. In the code sample above, the call to `dataset.flat_map` expects a function that constructs the dataflow graph defining the transformations to be performed. As a result, you'll observe that breakpoint 1 will be triggered by the call to `dataset.flat_map` and not by the call to `i.next()`. In a program that iterates over the dataset, you'll observe that the breakpoint is hit exactly once, and not once per call to `i.next()`.\r\n\r\nExpressing the input pipeline as a dataflow graph enables efficient background input processing - allowing multiple input tensors to be processed concurrently (e.g., multiple threads for [`tf.data.Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map)), and for input processing to be conducted concurrently with model computation. By doing so, input processing isn't bottlenecked on the single Python interpreter thread.\r\n\r\nThat said, a workaround would be to use something like a `tf.py_func` which will bring control to the Python interpreter. @akshayka is actively working on a `tfe.py_func` which will make this possible (at an efficiency cost of sharing the single Python interpreter thread).\r\n\r\nPlease let me know if the comment makes sense.\r\n\r\nI'm going to keep the issue open and we can close it when `tfe.py_func` is in place and we can provide you with a sample of how to use it in your input pipeline.\r\n\r\nFYI @mrry @jsimsa "}