{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347263672", "html_url": "https://github.com/tensorflow/tensorflow/issues/13221#issuecomment-347263672", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13221", "id": 347263672, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzI2MzY3Mg==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-27T17:44:08Z", "updated_at": "2017-11-27T17:44:46Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5220571\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dantkz\">@dantkz</a> what you are seeing is related. Calling tf.contrib.memory_stats.MaxBytesInUse() in loop body appends a new op to your graph. Ideally this should only leak CPU memory and not GPU memory. However, the way const's are implemented, any modification of the graph will cause TensorFlow to create new copies of all consts (see reedwm comment on Oct 2). The bottom line is that const nodes will leak GPU memory, and by extension \"tf.ones/tf.zeros\" since they use const.</p>", "body_text": "@dantkz what you are seeing is related. Calling tf.contrib.memory_stats.MaxBytesInUse() in loop body appends a new op to your graph. Ideally this should only leak CPU memory and not GPU memory. However, the way const's are implemented, any modification of the graph will cause TensorFlow to create new copies of all consts (see reedwm comment on Oct 2). The bottom line is that const nodes will leak GPU memory, and by extension \"tf.ones/tf.zeros\" since they use const.", "body": "@dantkz what you are seeing is related. Calling tf.contrib.memory_stats.MaxBytesInUse() in loop body appends a new op to your graph. Ideally this should only leak CPU memory and not GPU memory. However, the way const's are implemented, any modification of the graph will cause TensorFlow to create new copies of all consts (see reedwm comment on Oct 2). The bottom line is that const nodes will leak GPU memory, and by extension \"tf.ones/tf.zeros\" since they use const."}