{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347199174", "html_url": "https://github.com/tensorflow/tensorflow/issues/13221#issuecomment-347199174", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13221", "id": 347199174, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzE5OTE3NA==", "user": {"login": "dantkz", "id": 5220571, "node_id": "MDQ6VXNlcjUyMjA1NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5220571?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dantkz", "html_url": "https://github.com/dantkz", "followers_url": "https://api.github.com/users/dantkz/followers", "following_url": "https://api.github.com/users/dantkz/following{/other_user}", "gists_url": "https://api.github.com/users/dantkz/gists{/gist_id}", "starred_url": "https://api.github.com/users/dantkz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dantkz/subscriptions", "organizations_url": "https://api.github.com/users/dantkz/orgs", "repos_url": "https://api.github.com/users/dantkz/repos", "events_url": "https://api.github.com/users/dantkz/events{/privacy}", "received_events_url": "https://api.github.com/users/dantkz/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-27T14:33:45Z", "updated_at": "2017-11-27T14:39:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I suspect the main leak is not from ones/ones_like but from tf.where.</p>\n<p>I modified the example code, so that it doesn't create new nodes in the computation graph while iterating. The script checks memory usage depending on which implementation of relu is in use.</p>\n<pre><code>import sys, os, math, random\nimport tensorflow as tf\nimport numpy as np\n\nif __name__=='__main__':\n  def run_iters(relu):\n    from tensorflow.core.protobuf import rewriter_config_pb2\n    rewrite_options = rewriter_config_pb2.RewriterConfig(\n      disable_model_pruning=True,\n      constant_folding=rewriter_config_pb2.RewriterConfig.OFF,\n      memory_optimization=rewriter_config_pb2.RewriterConfig.MANUAL)\n    optimizer_options = tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)\n    graph_options=tf.GraphOptions(optimizer_options=optimizer_options,\n                                  rewrite_options=rewrite_options)\n    config = tf.ConfigProto(graph_options=graph_options)\n\n    sess = tf.Session(config=config)\n    \n    size = 12000\n    num_runs = 20\n\n    images = tf.random_uniform([size, size])\n\n    var = tf.Variable(tf.ones_like(images))\n    sess.run(var.initializer)\n\n    cost = tf.reduce_sum(relu(images+var))\n    grads = tf.gradients(cost, var)\n\n    memuse, memuse2 = sess.run([tf.contrib.memory_stats.MaxBytesInUse(), tf.contrib.memory_stats.BytesInUse()])\n    print(\"Init: GBs in use %.2f, %.2f\"%(memuse/10**9,memuse2/10**9))\n    for i in range(10):\n      _, memuse, memuse2 = sess.run([grads, tf.contrib.memory_stats.MaxBytesInUse(), tf.contrib.memory_stats.BytesInUse()])\n      print(\"Run %d, GBs in use %.2f, %.2f\"%(i, memuse/10**9,memuse2/10**9))\n    [memuse] = sess.run([tf.contrib.memory_stats.MaxBytesInUse()])\n    print(\"Memory GBs in use %.2f\"%(memuse/10**9,))\n    \n    sess.close()\n\n  alpha = 0.1\n\n  def relu_nowhere(x):\n    retval = alpha*x*tf.cast(tf.less(x, 0.), dtype=tf.float32) + x*tf.cast(tf.less(-x, 0.), dtype=tf.float32)\n    return retval\n  run_iters(relu_nowhere)\n\n  tf.reset_default_graph()\n\n  def relu_where(x):\n    retval = tf.where(tf.less(x, 0.0), alpha*x, x, name='leaky_relu')\n    return retval\n  run_iters(relu_where)\n\n</code></pre>\n<p>This is the output on my machine with tensorflow 1.4:</p>\n<pre><code>(python3) daniyar@sleepy-prism:~/tmp/tile_leak$ python test.py\n2017-11-27 14:27:12.809165: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-11-27 14:27:13.038106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\npciBusID: 0000:02:00.0\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\n2017-11-27 14:27:13.038243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\nInit: GBs in use 1.15, 0.58\nRun 0, GBs in use 1.15, 0.58\nRun 1, GBs in use 2.45, 0.58\nRun 2, GBs in use 2.45, 0.58\nRun 3, GBs in use 2.45, 0.58\nRun 4, GBs in use 2.45, 0.58\nRun 5, GBs in use 2.45, 0.58\nRun 6, GBs in use 2.45, 0.58\nRun 7, GBs in use 2.45, 0.58\nRun 8, GBs in use 2.45, 0.58\nRun 9, GBs in use 2.45, 0.58\nMemory GBs in use 2.45\n2017-11-27 14:27:15.457164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\nInit: GBs in use 2.45, 0.58\nRun 0, GBs in use 2.45, 1.15\nRun 1, GBs in use 2.45, 1.73\nRun 2, GBs in use 3.02, 2.30\nRun 3, GBs in use 3.60, 2.88\nRun 4, GBs in use 4.18, 3.46\nRun 5, GBs in use 4.75, 4.03\nRun 6, GBs in use 5.33, 4.61\nRun 7, GBs in use 5.90, 5.18\nRun 8, GBs in use 6.48, 5.76\nRun 9, GBs in use 7.06, 6.34\nMemory GBs in use 7.63\n</code></pre>\n<p>As you can see, the memory usage doubles after the first iteration, but then stays the same, when using leaky relu without tf.where. On the other hand, leaky relu with tf.where keeps allocating more memory.</p>", "body_text": "I suspect the main leak is not from ones/ones_like but from tf.where.\nI modified the example code, so that it doesn't create new nodes in the computation graph while iterating. The script checks memory usage depending on which implementation of relu is in use.\nimport sys, os, math, random\nimport tensorflow as tf\nimport numpy as np\n\nif __name__=='__main__':\n  def run_iters(relu):\n    from tensorflow.core.protobuf import rewriter_config_pb2\n    rewrite_options = rewriter_config_pb2.RewriterConfig(\n      disable_model_pruning=True,\n      constant_folding=rewriter_config_pb2.RewriterConfig.OFF,\n      memory_optimization=rewriter_config_pb2.RewriterConfig.MANUAL)\n    optimizer_options = tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)\n    graph_options=tf.GraphOptions(optimizer_options=optimizer_options,\n                                  rewrite_options=rewrite_options)\n    config = tf.ConfigProto(graph_options=graph_options)\n\n    sess = tf.Session(config=config)\n    \n    size = 12000\n    num_runs = 20\n\n    images = tf.random_uniform([size, size])\n\n    var = tf.Variable(tf.ones_like(images))\n    sess.run(var.initializer)\n\n    cost = tf.reduce_sum(relu(images+var))\n    grads = tf.gradients(cost, var)\n\n    memuse, memuse2 = sess.run([tf.contrib.memory_stats.MaxBytesInUse(), tf.contrib.memory_stats.BytesInUse()])\n    print(\"Init: GBs in use %.2f, %.2f\"%(memuse/10**9,memuse2/10**9))\n    for i in range(10):\n      _, memuse, memuse2 = sess.run([grads, tf.contrib.memory_stats.MaxBytesInUse(), tf.contrib.memory_stats.BytesInUse()])\n      print(\"Run %d, GBs in use %.2f, %.2f\"%(i, memuse/10**9,memuse2/10**9))\n    [memuse] = sess.run([tf.contrib.memory_stats.MaxBytesInUse()])\n    print(\"Memory GBs in use %.2f\"%(memuse/10**9,))\n    \n    sess.close()\n\n  alpha = 0.1\n\n  def relu_nowhere(x):\n    retval = alpha*x*tf.cast(tf.less(x, 0.), dtype=tf.float32) + x*tf.cast(tf.less(-x, 0.), dtype=tf.float32)\n    return retval\n  run_iters(relu_nowhere)\n\n  tf.reset_default_graph()\n\n  def relu_where(x):\n    retval = tf.where(tf.less(x, 0.0), alpha*x, x, name='leaky_relu')\n    return retval\n  run_iters(relu_where)\n\n\nThis is the output on my machine with tensorflow 1.4:\n(python3) daniyar@sleepy-prism:~/tmp/tile_leak$ python test.py\n2017-11-27 14:27:12.809165: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-11-27 14:27:13.038106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\npciBusID: 0000:02:00.0\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\n2017-11-27 14:27:13.038243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\nInit: GBs in use 1.15, 0.58\nRun 0, GBs in use 1.15, 0.58\nRun 1, GBs in use 2.45, 0.58\nRun 2, GBs in use 2.45, 0.58\nRun 3, GBs in use 2.45, 0.58\nRun 4, GBs in use 2.45, 0.58\nRun 5, GBs in use 2.45, 0.58\nRun 6, GBs in use 2.45, 0.58\nRun 7, GBs in use 2.45, 0.58\nRun 8, GBs in use 2.45, 0.58\nRun 9, GBs in use 2.45, 0.58\nMemory GBs in use 2.45\n2017-11-27 14:27:15.457164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\nInit: GBs in use 2.45, 0.58\nRun 0, GBs in use 2.45, 1.15\nRun 1, GBs in use 2.45, 1.73\nRun 2, GBs in use 3.02, 2.30\nRun 3, GBs in use 3.60, 2.88\nRun 4, GBs in use 4.18, 3.46\nRun 5, GBs in use 4.75, 4.03\nRun 6, GBs in use 5.33, 4.61\nRun 7, GBs in use 5.90, 5.18\nRun 8, GBs in use 6.48, 5.76\nRun 9, GBs in use 7.06, 6.34\nMemory GBs in use 7.63\n\nAs you can see, the memory usage doubles after the first iteration, but then stays the same, when using leaky relu without tf.where. On the other hand, leaky relu with tf.where keeps allocating more memory.", "body": "I suspect the main leak is not from ones/ones_like but from tf.where.\r\n\r\nI modified the example code, so that it doesn't create new nodes in the computation graph while iterating. The script checks memory usage depending on which implementation of relu is in use. \r\n\r\n```\r\nimport sys, os, math, random\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nif __name__=='__main__':\r\n  def run_iters(relu):\r\n    from tensorflow.core.protobuf import rewriter_config_pb2\r\n    rewrite_options = rewriter_config_pb2.RewriterConfig(\r\n      disable_model_pruning=True,\r\n      constant_folding=rewriter_config_pb2.RewriterConfig.OFF,\r\n      memory_optimization=rewriter_config_pb2.RewriterConfig.MANUAL)\r\n    optimizer_options = tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)\r\n    graph_options=tf.GraphOptions(optimizer_options=optimizer_options,\r\n                                  rewrite_options=rewrite_options)\r\n    config = tf.ConfigProto(graph_options=graph_options)\r\n\r\n    sess = tf.Session(config=config)\r\n    \r\n    size = 12000\r\n    num_runs = 20\r\n\r\n    images = tf.random_uniform([size, size])\r\n\r\n    var = tf.Variable(tf.ones_like(images))\r\n    sess.run(var.initializer)\r\n\r\n    cost = tf.reduce_sum(relu(images+var))\r\n    grads = tf.gradients(cost, var)\r\n\r\n    memuse, memuse2 = sess.run([tf.contrib.memory_stats.MaxBytesInUse(), tf.contrib.memory_stats.BytesInUse()])\r\n    print(\"Init: GBs in use %.2f, %.2f\"%(memuse/10**9,memuse2/10**9))\r\n    for i in range(10):\r\n      _, memuse, memuse2 = sess.run([grads, tf.contrib.memory_stats.MaxBytesInUse(), tf.contrib.memory_stats.BytesInUse()])\r\n      print(\"Run %d, GBs in use %.2f, %.2f\"%(i, memuse/10**9,memuse2/10**9))\r\n    [memuse] = sess.run([tf.contrib.memory_stats.MaxBytesInUse()])\r\n    print(\"Memory GBs in use %.2f\"%(memuse/10**9,))\r\n    \r\n    sess.close()\r\n\r\n  alpha = 0.1\r\n\r\n  def relu_nowhere(x):\r\n    retval = alpha*x*tf.cast(tf.less(x, 0.), dtype=tf.float32) + x*tf.cast(tf.less(-x, 0.), dtype=tf.float32)\r\n    return retval\r\n  run_iters(relu_nowhere)\r\n\r\n  tf.reset_default_graph()\r\n\r\n  def relu_where(x):\r\n    retval = tf.where(tf.less(x, 0.0), alpha*x, x, name='leaky_relu')\r\n    return retval\r\n  run_iters(relu_where)\r\n\r\n```\r\n\r\nThis is the output on my machine with tensorflow 1.4:\r\n```\r\n(python3) daniyar@sleepy-prism:~/tmp/tile_leak$ python test.py\r\n2017-11-27 14:27:12.809165: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-11-27 14:27:13.038106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:\r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\r\n2017-11-27 14:27:13.038243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\r\nInit: GBs in use 1.15, 0.58\r\nRun 0, GBs in use 1.15, 0.58\r\nRun 1, GBs in use 2.45, 0.58\r\nRun 2, GBs in use 2.45, 0.58\r\nRun 3, GBs in use 2.45, 0.58\r\nRun 4, GBs in use 2.45, 0.58\r\nRun 5, GBs in use 2.45, 0.58\r\nRun 6, GBs in use 2.45, 0.58\r\nRun 7, GBs in use 2.45, 0.58\r\nRun 8, GBs in use 2.45, 0.58\r\nRun 9, GBs in use 2.45, 0.58\r\nMemory GBs in use 2.45\r\n2017-11-27 14:27:15.457164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\r\nInit: GBs in use 2.45, 0.58\r\nRun 0, GBs in use 2.45, 1.15\r\nRun 1, GBs in use 2.45, 1.73\r\nRun 2, GBs in use 3.02, 2.30\r\nRun 3, GBs in use 3.60, 2.88\r\nRun 4, GBs in use 4.18, 3.46\r\nRun 5, GBs in use 4.75, 4.03\r\nRun 6, GBs in use 5.33, 4.61\r\nRun 7, GBs in use 5.90, 5.18\r\nRun 8, GBs in use 6.48, 5.76\r\nRun 9, GBs in use 7.06, 6.34\r\nMemory GBs in use 7.63\r\n```\r\n\r\nAs you can see, the memory usage doubles after the first iteration, but then stays the same, when using leaky relu without tf.where. On the other hand, leaky relu with tf.where keeps allocating more memory."}