{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347291585", "html_url": "https://github.com/tensorflow/tensorflow/issues/13221#issuecomment-347291585", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13221", "id": 347291585, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzI5MTU4NQ==", "user": {"login": "dantkz", "id": 5220571, "node_id": "MDQ6VXNlcjUyMjA1NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5220571?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dantkz", "html_url": "https://github.com/dantkz", "followers_url": "https://api.github.com/users/dantkz/followers", "following_url": "https://api.github.com/users/dantkz/following{/other_user}", "gists_url": "https://api.github.com/users/dantkz/gists{/gist_id}", "starred_url": "https://api.github.com/users/dantkz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dantkz/subscriptions", "organizations_url": "https://api.github.com/users/dantkz/orgs", "repos_url": "https://api.github.com/users/dantkz/repos", "events_url": "https://api.github.com/users/dantkz/events{/privacy}", "received_events_url": "https://api.github.com/users/dantkz/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-27T19:09:11Z", "updated_at": "2017-11-27T19:09:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> Ah, yes, as you pointed out this behavior happens when the computation graph is being updated. I got carried away trying to find if a memory leak in my code is related to this memory leak, so I just re-did what you guys had above. My code doesn't grow the graph, but it uses <code>tf.scatter</code>/<code>tf.gather</code>/<code>tf.unique</code>/<code>tf.where</code> to modify <code>tf.ones</code> and <code>tf.constant</code> tensors depending on the input elements, I was trying to find a \"common denominator\" example.</p>\n<p>Anyway, there is another interesting behaviour of <code>tf.ones</code> and <code>tf.constant</code>:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport time\n\nif __name__=='__main__':\n    size_max = 2**8-1\n    iter_num = 20\n    size = tf.placeholder(shape=[], dtype=tf.int32)\n\n    with tf.device(\"/gpu:0\"):\n        ones_list = []\n        ones_list.append(tf.constant(np.ones([size_max, size_max, size_max], dtype=np.float32), dtype=tf.float32, name='tf.constant'))\n        ones_list.append(tf.ones([size_max, size_max, size_max], dtype=tf.float32, name='tf.ones'))\n        ones_list.append(tf.convert_to_tensor(np.ones([size_max, size_max, size_max], dtype=np.float32), dtype=tf.float32, name='tf.convert_to_tensor'))\n        ones_list.append(tf.get_variable('tf.get_variable', dtype=tf.float32, initializer=ones_list[0], trainable=False))\n\n        versions = []\n        for ones in ones_list:\n            ones_crop = ones[0:size, 0:size, 0:size]\n            noise = tf.random_uniform([size, size, size], dtype=tf.float32)\n            cost = tf.reduce_mean(ones_crop + noise)\n            grads = tf.gradients(cost, ones)\n            versions.append((cost, grads, ones))\n\n\n    get_mem_max = tf.contrib.memory_stats.MaxBytesInUse()\n\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=False)) as sess:\n        sess.run(tf.global_variables_initializer())\n        #sess.graph.finalize()\n\n        # hot start\n        for cost, grads, ones in versions:\n            cur_size = np.random.randint(size_max//2+1, size_max, dtype=np.int32)\n            cost_val, _, memuse = sess.run([cost, grads, get_mem_max], feed_dict={size: cur_size})\n\n        for cost, grads, ones in versions:\n            print(\"########################\")\n            print(\"Ones: \", ones)\n            bef_memuse = sess.run(get_mem_max)\n            bef_time = time.time()\n            #print(\"Memory GBs in use %.3f before iters\"%(bef_memuse/10**9))\n            for i in range(iter_num):\n                get_mem_use = tf.contrib.memory_stats.BytesInUse()\n                cur_size = np.random.randint(size_max//2+1, size_max, dtype=np.int32)\n                cost_val, _, memuse, memuse2 = sess.run([cost, grads, get_mem_max, get_mem_use], feed_dict={size: cur_size})\n                #print(\"Run %d, %f, GBs in use %.3f, %.3f.\"%(i, cost_val, memuse/10**9,memuse2/10**9))\n            aft_memuse = sess.run(get_mem_max)\n            aft_time = time.time()\n            print('Time for %d iters: %.3fs.' % (iter_num, aft_time-bef_time))\n            #print(\"Memory GBs in use %.3f after iters\"%(aft_memuse/10**9))\n            print(\"Diff GBs: %.3f\"%((aft_memuse-bef_memuse)/10**9))\n\n</code></pre>\n<p>The result:</p>\n<pre><code>2017-11-27 19:03:49.210727: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-11-27 19:03:49.389706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties:\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\npciBusID: 0000:01:00.0\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\n2017-11-27 19:03:49.389731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0, compute capability: 6.1)\n########################\nOnes:  Tensor(\"tf.constant:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\nTime for 20 iters: 2.445s.\nDiff GBs: 1.310\n########################\nOnes:  Tensor(\"tf.ones:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\nTime for 20 iters: 0.770s.\nDiff GBs: 1.302\n########################\nOnes:  Tensor(\"tf.convert_to_tensor:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\nTime for 20 iters: 2.467s.\nDiff GBs: 1.354\n########################\nOnes:  &lt;tf.Variable 'tf.get_variable:0' shape=(255, 255, 255) dtype=float32_ref&gt;\nTime for 20 iters: 0.411s.\nDiff GBs: 0.023\n</code></pre>\n<p>I assumed that <code>tf.constant</code> and <code>tf.ones</code> would be equivalent, but they have significantly different runtime.</p>\n<p>Also, a non-trainable <code>tf.Variable</code> is much more memory efficient. I guess it doesn't participate in the computation graph, so it doesn't get copied when the computation graph is updated.</p>", "body_text": "@yaroslavvb Ah, yes, as you pointed out this behavior happens when the computation graph is being updated. I got carried away trying to find if a memory leak in my code is related to this memory leak, so I just re-did what you guys had above. My code doesn't grow the graph, but it uses tf.scatter/tf.gather/tf.unique/tf.where to modify tf.ones and tf.constant tensors depending on the input elements, I was trying to find a \"common denominator\" example.\nAnyway, there is another interesting behaviour of tf.ones and tf.constant:\nimport tensorflow as tf\nimport numpy as np\nimport time\n\nif __name__=='__main__':\n    size_max = 2**8-1\n    iter_num = 20\n    size = tf.placeholder(shape=[], dtype=tf.int32)\n\n    with tf.device(\"/gpu:0\"):\n        ones_list = []\n        ones_list.append(tf.constant(np.ones([size_max, size_max, size_max], dtype=np.float32), dtype=tf.float32, name='tf.constant'))\n        ones_list.append(tf.ones([size_max, size_max, size_max], dtype=tf.float32, name='tf.ones'))\n        ones_list.append(tf.convert_to_tensor(np.ones([size_max, size_max, size_max], dtype=np.float32), dtype=tf.float32, name='tf.convert_to_tensor'))\n        ones_list.append(tf.get_variable('tf.get_variable', dtype=tf.float32, initializer=ones_list[0], trainable=False))\n\n        versions = []\n        for ones in ones_list:\n            ones_crop = ones[0:size, 0:size, 0:size]\n            noise = tf.random_uniform([size, size, size], dtype=tf.float32)\n            cost = tf.reduce_mean(ones_crop + noise)\n            grads = tf.gradients(cost, ones)\n            versions.append((cost, grads, ones))\n\n\n    get_mem_max = tf.contrib.memory_stats.MaxBytesInUse()\n\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=False)) as sess:\n        sess.run(tf.global_variables_initializer())\n        #sess.graph.finalize()\n\n        # hot start\n        for cost, grads, ones in versions:\n            cur_size = np.random.randint(size_max//2+1, size_max, dtype=np.int32)\n            cost_val, _, memuse = sess.run([cost, grads, get_mem_max], feed_dict={size: cur_size})\n\n        for cost, grads, ones in versions:\n            print(\"########################\")\n            print(\"Ones: \", ones)\n            bef_memuse = sess.run(get_mem_max)\n            bef_time = time.time()\n            #print(\"Memory GBs in use %.3f before iters\"%(bef_memuse/10**9))\n            for i in range(iter_num):\n                get_mem_use = tf.contrib.memory_stats.BytesInUse()\n                cur_size = np.random.randint(size_max//2+1, size_max, dtype=np.int32)\n                cost_val, _, memuse, memuse2 = sess.run([cost, grads, get_mem_max, get_mem_use], feed_dict={size: cur_size})\n                #print(\"Run %d, %f, GBs in use %.3f, %.3f.\"%(i, cost_val, memuse/10**9,memuse2/10**9))\n            aft_memuse = sess.run(get_mem_max)\n            aft_time = time.time()\n            print('Time for %d iters: %.3fs.' % (iter_num, aft_time-bef_time))\n            #print(\"Memory GBs in use %.3f after iters\"%(aft_memuse/10**9))\n            print(\"Diff GBs: %.3f\"%((aft_memuse-bef_memuse)/10**9))\n\n\nThe result:\n2017-11-27 19:03:49.210727: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-11-27 19:03:49.389706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties:\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\npciBusID: 0000:01:00.0\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\n2017-11-27 19:03:49.389731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0, compute capability: 6.1)\n########################\nOnes:  Tensor(\"tf.constant:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\nTime for 20 iters: 2.445s.\nDiff GBs: 1.310\n########################\nOnes:  Tensor(\"tf.ones:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\nTime for 20 iters: 0.770s.\nDiff GBs: 1.302\n########################\nOnes:  Tensor(\"tf.convert_to_tensor:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\nTime for 20 iters: 2.467s.\nDiff GBs: 1.354\n########################\nOnes:  <tf.Variable 'tf.get_variable:0' shape=(255, 255, 255) dtype=float32_ref>\nTime for 20 iters: 0.411s.\nDiff GBs: 0.023\n\nI assumed that tf.constant and tf.ones would be equivalent, but they have significantly different runtime.\nAlso, a non-trainable tf.Variable is much more memory efficient. I guess it doesn't participate in the computation graph, so it doesn't get copied when the computation graph is updated.", "body": "@yaroslavvb Ah, yes, as you pointed out this behavior happens when the computation graph is being updated. I got carried away trying to find if a memory leak in my code is related to this memory leak, so I just re-did what you guys had above. My code doesn't grow the graph, but it uses `tf.scatter`/`tf.gather`/`tf.unique`/`tf.where` to modify `tf.ones` and `tf.constant` tensors depending on the input elements, I was trying to find a \"common denominator\" example.\r\n\r\nAnyway, there is another interesting behaviour of `tf.ones` and `tf.constant`:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\nif __name__=='__main__':\r\n    size_max = 2**8-1\r\n    iter_num = 20\r\n    size = tf.placeholder(shape=[], dtype=tf.int32)\r\n\r\n    with tf.device(\"/gpu:0\"):\r\n        ones_list = []\r\n        ones_list.append(tf.constant(np.ones([size_max, size_max, size_max], dtype=np.float32), dtype=tf.float32, name='tf.constant'))\r\n        ones_list.append(tf.ones([size_max, size_max, size_max], dtype=tf.float32, name='tf.ones'))\r\n        ones_list.append(tf.convert_to_tensor(np.ones([size_max, size_max, size_max], dtype=np.float32), dtype=tf.float32, name='tf.convert_to_tensor'))\r\n        ones_list.append(tf.get_variable('tf.get_variable', dtype=tf.float32, initializer=ones_list[0], trainable=False))\r\n\r\n        versions = []\r\n        for ones in ones_list:\r\n            ones_crop = ones[0:size, 0:size, 0:size]\r\n            noise = tf.random_uniform([size, size, size], dtype=tf.float32)\r\n            cost = tf.reduce_mean(ones_crop + noise)\r\n            grads = tf.gradients(cost, ones)\r\n            versions.append((cost, grads, ones))\r\n\r\n\r\n    get_mem_max = tf.contrib.memory_stats.MaxBytesInUse()\r\n\r\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=False)) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        #sess.graph.finalize()\r\n\r\n        # hot start\r\n        for cost, grads, ones in versions:\r\n            cur_size = np.random.randint(size_max//2+1, size_max, dtype=np.int32)\r\n            cost_val, _, memuse = sess.run([cost, grads, get_mem_max], feed_dict={size: cur_size})\r\n\r\n        for cost, grads, ones in versions:\r\n            print(\"########################\")\r\n            print(\"Ones: \", ones)\r\n            bef_memuse = sess.run(get_mem_max)\r\n            bef_time = time.time()\r\n            #print(\"Memory GBs in use %.3f before iters\"%(bef_memuse/10**9))\r\n            for i in range(iter_num):\r\n                get_mem_use = tf.contrib.memory_stats.BytesInUse()\r\n                cur_size = np.random.randint(size_max//2+1, size_max, dtype=np.int32)\r\n                cost_val, _, memuse, memuse2 = sess.run([cost, grads, get_mem_max, get_mem_use], feed_dict={size: cur_size})\r\n                #print(\"Run %d, %f, GBs in use %.3f, %.3f.\"%(i, cost_val, memuse/10**9,memuse2/10**9))\r\n            aft_memuse = sess.run(get_mem_max)\r\n            aft_time = time.time()\r\n            print('Time for %d iters: %.3fs.' % (iter_num, aft_time-bef_time))\r\n            #print(\"Memory GBs in use %.3f after iters\"%(aft_memuse/10**9))\r\n            print(\"Diff GBs: %.3f\"%((aft_memuse-bef_memuse)/10**9))\r\n\r\n```\r\n\r\nThe result:\r\n```\r\n2017-11-27 19:03:49.210727: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-11-27 19:03:49.389706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties:\r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\r\n2017-11-27 19:03:49.389731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n########################\r\nOnes:  Tensor(\"tf.constant:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\r\nTime for 20 iters: 2.445s.\r\nDiff GBs: 1.310\r\n########################\r\nOnes:  Tensor(\"tf.ones:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\r\nTime for 20 iters: 0.770s.\r\nDiff GBs: 1.302\r\n########################\r\nOnes:  Tensor(\"tf.convert_to_tensor:0\", shape=(255, 255, 255), dtype=float32, device=/device:GPU:0)\r\nTime for 20 iters: 2.467s.\r\nDiff GBs: 1.354\r\n########################\r\nOnes:  <tf.Variable 'tf.get_variable:0' shape=(255, 255, 255) dtype=float32_ref>\r\nTime for 20 iters: 0.411s.\r\nDiff GBs: 0.023\r\n```\r\n\r\nI assumed that `tf.constant` and `tf.ones` would be equivalent, but they have significantly different runtime. \r\n\r\nAlso, a non-trainable `tf.Variable` is much more memory efficient. I guess it doesn't participate in the computation graph, so it doesn't get copied when the computation graph is updated. \r\n"}