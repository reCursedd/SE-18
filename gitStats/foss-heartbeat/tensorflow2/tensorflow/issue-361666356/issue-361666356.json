{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22377", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22377/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22377/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22377/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22377", "id": 361666356, "node_id": "MDU6SXNzdWUzNjE2NjYzNTY=", "number": 22377, "title": "tflite can't ResizeInputTensor size", "user": {"login": "TPcoding", "id": 17492681, "node_id": "MDQ6VXNlcjE3NDkyNjgx", "avatar_url": "https://avatars3.githubusercontent.com/u/17492681?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TPcoding", "html_url": "https://github.com/TPcoding", "followers_url": "https://api.github.com/users/TPcoding/followers", "following_url": "https://api.github.com/users/TPcoding/following{/other_user}", "gists_url": "https://api.github.com/users/TPcoding/gists{/gist_id}", "starred_url": "https://api.github.com/users/TPcoding/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TPcoding/subscriptions", "organizations_url": "https://api.github.com/users/TPcoding/orgs", "repos_url": "https://api.github.com/users/TPcoding/repos", "events_url": "https://api.github.com/users/TPcoding/events{/privacy}", "received_events_url": "https://api.github.com/users/TPcoding/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-09-19T09:49:10Z", "updated_at": "2018-11-19T23:27:24Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:N/A</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:16.04.1-Ubuntu</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:source</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.11.0rc0</li>\n<li><strong>Python version</strong>:3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:0.16.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609</li>\n<li><strong>CUDA/cuDNN version</strong>:N/A</li>\n<li><strong>GPU model and memory</strong>:N/A</li>\n<li><strong>Exact command to reproduce</strong>:See below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When I use tflite,I set ResizeInputTensor different from model, error show:</p>\n<pre><code>tensorflow/contrib/lite/kernels/reshape.cc:58 num_input_elements != num_output_elements (880 != 440)\nNode number 0 (RESHAPE) failed to prepare.\n</code></pre>\n<p>fisrt,my net input is [?,440], I convert it by set intput to [1,440]. I want to use it in forward with different size [n,440].Maybe I conert it to tflite wrong?</p>\n<h3>Source code / logs</h3>\n<p>*my code:</p>\n<pre><code>int main() {\n\n    // load model\n    std::unique_ptr&lt;tflite::FlatBufferModel&gt; model;\n    std::unique_ptr&lt;tflite::Interpreter&gt; interpreter;\n    model = tflite::FlatBufferModel::BuildFromFile(\"./moble.tflite\");\n    if (!model) {\n\tcout &lt;&lt; \"load model err.\" &lt;&lt; endl;\n\texit(-1);\n    }\n\n    // build op\n    tflite::ops::builtin::BuiltinOpResolver resolver;\n\n    tflite::InterpreterBuilder (*model, resolver)(&amp;interpreter);\n    if (!interpreter) {\n\tcout &lt;&lt; \"Failed to construct interpreter\\n\" &lt;&lt; endl;\n\texit(-1);\n    }\n\n    interpreter-&gt;UseNNAPI(0);\n    interpreter-&gt;SetNumThreads(1);\n\n    // allocate tensors space\n    int input = interpreter-&gt;inputs()[0];\n    interpreter-&gt;ResizeInputTensor(input, {2,440});\n    if (interpreter-&gt;AllocateTensors() != kTfLiteOk) {\n\tcout &lt;&lt; \"Failed to allocate tensors.\\n\";\n\texit(-1);\n    }\n\n    // set input\n    float *in = interpreter-&gt;typed_tensor&lt;float&gt;(input);\n    for (int i = 0; i &lt; 440 * 2; i++) {\n\tin[i] = i + 1.0f;\n    }\n\n    // inference\n    if (interpreter-&gt;Invoke() != kTfLiteOk) {\n\tcout &lt;&lt; \"Failed to invoke!\\n\";\n\texit(-1);\n    }\n\n    // get result\n    float *output = interpreter-&gt;typed_output_tensor&lt;float&gt;(0);\n    for (int i = 0; i &lt; 200; i++) {\n\tcout &lt;&lt; output[i] &lt;&lt; \" \";\n    }\n    cout &lt;&lt; endl;\n    return 0;\n}\n</code></pre>\n<ul>\n<li>python convert script<br>\n** my net</li>\n</ul>\n<pre><code>bazel run tensorflow/tools/graph_transforms:summarize_graph -- --in_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/graph_vprint.pb\n</code></pre>\n<p>result</p>\n<pre><code>Found 1 possible inputs: (name=ac_input, type=float(1), shape=[?,440]) \nNo variables spotted.\nFound 1 possible outputs: (name=Inference/final_output/output, op=Identity) \nFound 382867 (382.87k) const parameters, 0 (0) variable parameters, and 0 control_edges\nOp types used: 50 Const, 13 Reshape, 13 Identity, 12 Transpose, 6 BiasAdd, 4 Conv2D, 4 Relu, 3 ConcatV2, 3 Mul, 2 GatherV2, 2 Add, 2 Cast, 2 Prod, 2 Mean, 2 MaxPool, 2 MatMul, 1 Pack, 1 Placeholder, 1 Range, 1 ListDiff, 1 Less, 1 Shape, 1 Sqrt, 1 Sub, 1 GreaterEqual\n</code></pre>\n<p>** transform net</p>\n<pre><code>bazel run tensorflow/tools/graph_transforms:transform_graph -- --in_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/graph_vprint.pb --out_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/transformed_graph_simple.pb --inputs='ac_input' --outputs='Inference/final_output/output' --transforms='strip_unused_nodes(type=float,shape=\"1,440\") fold_constants(ingore_errors=true) fold_batch_norms fold_old_batch_norms'\n</code></pre>\n<p>** convert to lite</p>\n<pre><code>tflite_convert   --output_file=$(pwd)/model/cnn/vocal_print_model/moble.tflite  --graph_def_file=$(pwd)/model/cnn/vocal_print_model/transformed_graph_simple.pb   --input_arrays=ac_input   --output_arrays=Inference/final_output/output --input_shapes=1,440\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):N/A\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04.1-Ubuntu\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\nTensorFlow installed from (source or binary):source\nTensorFlow version (use command below):1.11.0rc0\nPython version:3.5\nBazel version (if compiling from source):0.16.1\nGCC/Compiler version (if compiling from source): (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCUDA/cuDNN version:N/A\nGPU model and memory:N/A\nExact command to reproduce:See below\n\nDescribe the problem\nWhen I use tflite,I set ResizeInputTensor different from model, error show:\ntensorflow/contrib/lite/kernels/reshape.cc:58 num_input_elements != num_output_elements (880 != 440)\nNode number 0 (RESHAPE) failed to prepare.\n\nfisrt,my net input is [?,440], I convert it by set intput to [1,440]. I want to use it in forward with different size [n,440].Maybe I conert it to tflite wrong?\nSource code / logs\n*my code:\nint main() {\n\n    // load model\n    std::unique_ptr<tflite::FlatBufferModel> model;\n    std::unique_ptr<tflite::Interpreter> interpreter;\n    model = tflite::FlatBufferModel::BuildFromFile(\"./moble.tflite\");\n    if (!model) {\n\tcout << \"load model err.\" << endl;\n\texit(-1);\n    }\n\n    // build op\n    tflite::ops::builtin::BuiltinOpResolver resolver;\n\n    tflite::InterpreterBuilder (*model, resolver)(&interpreter);\n    if (!interpreter) {\n\tcout << \"Failed to construct interpreter\\n\" << endl;\n\texit(-1);\n    }\n\n    interpreter->UseNNAPI(0);\n    interpreter->SetNumThreads(1);\n\n    // allocate tensors space\n    int input = interpreter->inputs()[0];\n    interpreter->ResizeInputTensor(input, {2,440});\n    if (interpreter->AllocateTensors() != kTfLiteOk) {\n\tcout << \"Failed to allocate tensors.\\n\";\n\texit(-1);\n    }\n\n    // set input\n    float *in = interpreter->typed_tensor<float>(input);\n    for (int i = 0; i < 440 * 2; i++) {\n\tin[i] = i + 1.0f;\n    }\n\n    // inference\n    if (interpreter->Invoke() != kTfLiteOk) {\n\tcout << \"Failed to invoke!\\n\";\n\texit(-1);\n    }\n\n    // get result\n    float *output = interpreter->typed_output_tensor<float>(0);\n    for (int i = 0; i < 200; i++) {\n\tcout << output[i] << \" \";\n    }\n    cout << endl;\n    return 0;\n}\n\n\npython convert script\n** my net\n\nbazel run tensorflow/tools/graph_transforms:summarize_graph -- --in_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/graph_vprint.pb\n\nresult\nFound 1 possible inputs: (name=ac_input, type=float(1), shape=[?,440]) \nNo variables spotted.\nFound 1 possible outputs: (name=Inference/final_output/output, op=Identity) \nFound 382867 (382.87k) const parameters, 0 (0) variable parameters, and 0 control_edges\nOp types used: 50 Const, 13 Reshape, 13 Identity, 12 Transpose, 6 BiasAdd, 4 Conv2D, 4 Relu, 3 ConcatV2, 3 Mul, 2 GatherV2, 2 Add, 2 Cast, 2 Prod, 2 Mean, 2 MaxPool, 2 MatMul, 1 Pack, 1 Placeholder, 1 Range, 1 ListDiff, 1 Less, 1 Shape, 1 Sqrt, 1 Sub, 1 GreaterEqual\n\n** transform net\nbazel run tensorflow/tools/graph_transforms:transform_graph -- --in_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/graph_vprint.pb --out_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/transformed_graph_simple.pb --inputs='ac_input' --outputs='Inference/final_output/output' --transforms='strip_unused_nodes(type=float,shape=\"1,440\") fold_constants(ingore_errors=true) fold_batch_norms fold_old_batch_norms'\n\n** convert to lite\ntflite_convert   --output_file=$(pwd)/model/cnn/vocal_print_model/moble.tflite  --graph_def_file=$(pwd)/model/cnn/vocal_print_model/transformed_graph_simple.pb   --input_arrays=ac_input   --output_arrays=Inference/final_output/output --input_shapes=1,440", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:16.04.1-Ubuntu\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:N/A\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:1.11.0rc0\r\n- **Python version**:3.5\r\n- **Bazel version (if compiling from source)**:0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**:N/A\r\n- **Exact command to reproduce**:See below\r\n### Describe the problem\r\nWhen I use tflite,I set ResizeInputTensor different from model, error show:\r\n```\r\ntensorflow/contrib/lite/kernels/reshape.cc:58 num_input_elements != num_output_elements (880 != 440)\r\nNode number 0 (RESHAPE) failed to prepare.\r\n```\r\nfisrt,my net input is [?,440], I convert it by set intput to [1,440]. I want to use it in forward with different size [n,440].Maybe I conert it to tflite wrong?\r\n### Source code / logs\r\n*my code:\r\n```\r\nint main() {\r\n\r\n    // load model\r\n    std::unique_ptr<tflite::FlatBufferModel> model;\r\n    std::unique_ptr<tflite::Interpreter> interpreter;\r\n    model = tflite::FlatBufferModel::BuildFromFile(\"./moble.tflite\");\r\n    if (!model) {\r\n\tcout << \"load model err.\" << endl;\r\n\texit(-1);\r\n    }\r\n\r\n    // build op\r\n    tflite::ops::builtin::BuiltinOpResolver resolver;\r\n\r\n    tflite::InterpreterBuilder (*model, resolver)(&interpreter);\r\n    if (!interpreter) {\r\n\tcout << \"Failed to construct interpreter\\n\" << endl;\r\n\texit(-1);\r\n    }\r\n\r\n    interpreter->UseNNAPI(0);\r\n    interpreter->SetNumThreads(1);\r\n\r\n    // allocate tensors space\r\n    int input = interpreter->inputs()[0];\r\n    interpreter->ResizeInputTensor(input, {2,440});\r\n    if (interpreter->AllocateTensors() != kTfLiteOk) {\r\n\tcout << \"Failed to allocate tensors.\\n\";\r\n\texit(-1);\r\n    }\r\n\r\n    // set input\r\n    float *in = interpreter->typed_tensor<float>(input);\r\n    for (int i = 0; i < 440 * 2; i++) {\r\n\tin[i] = i + 1.0f;\r\n    }\r\n\r\n    // inference\r\n    if (interpreter->Invoke() != kTfLiteOk) {\r\n\tcout << \"Failed to invoke!\\n\";\r\n\texit(-1);\r\n    }\r\n\r\n    // get result\r\n    float *output = interpreter->typed_output_tensor<float>(0);\r\n    for (int i = 0; i < 200; i++) {\r\n\tcout << output[i] << \" \";\r\n    }\r\n    cout << endl;\r\n    return 0;\r\n}\r\n```\r\n* python convert script\r\n** my net\r\n```\r\nbazel run tensorflow/tools/graph_transforms:summarize_graph -- --in_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/graph_vprint.pb\r\n```\r\nresult\r\n```\r\nFound 1 possible inputs: (name=ac_input, type=float(1), shape=[?,440]) \r\nNo variables spotted.\r\nFound 1 possible outputs: (name=Inference/final_output/output, op=Identity) \r\nFound 382867 (382.87k) const parameters, 0 (0) variable parameters, and 0 control_edges\r\nOp types used: 50 Const, 13 Reshape, 13 Identity, 12 Transpose, 6 BiasAdd, 4 Conv2D, 4 Relu, 3 ConcatV2, 3 Mul, 2 GatherV2, 2 Add, 2 Cast, 2 Prod, 2 Mean, 2 MaxPool, 2 MatMul, 1 Pack, 1 Placeholder, 1 Range, 1 ListDiff, 1 Less, 1 Shape, 1 Sqrt, 1 Sub, 1 GreaterEqual\r\n```\r\n** transform net\r\n```\r\nbazel run tensorflow/tools/graph_transforms:transform_graph -- --in_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/graph_vprint.pb --out_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/transformed_graph_simple.pb --inputs='ac_input' --outputs='Inference/final_output/output' --transforms='strip_unused_nodes(type=float,shape=\"1,440\") fold_constants(ingore_errors=true) fold_batch_norms fold_old_batch_norms'\r\n```\r\n** convert to lite\r\n```\r\ntflite_convert   --output_file=$(pwd)/model/cnn/vocal_print_model/moble.tflite  --graph_def_file=$(pwd)/model/cnn/vocal_print_model/transformed_graph_simple.pb   --input_arrays=ac_input   --output_arrays=Inference/final_output/output --input_shapes=1,440\r\n```"}