{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364505914", "html_url": "https://github.com/tensorflow/tensorflow/issues/16385#issuecomment-364505914", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16385", "id": 364505914, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDUwNTkxNA==", "user": {"login": "random-residual", "id": 14348792, "node_id": "MDQ6VXNlcjE0MzQ4Nzky", "avatar_url": "https://avatars1.githubusercontent.com/u/14348792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/random-residual", "html_url": "https://github.com/random-residual", "followers_url": "https://api.github.com/users/random-residual/followers", "following_url": "https://api.github.com/users/random-residual/following{/other_user}", "gists_url": "https://api.github.com/users/random-residual/gists{/gist_id}", "starred_url": "https://api.github.com/users/random-residual/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/random-residual/subscriptions", "organizations_url": "https://api.github.com/users/random-residual/orgs", "repos_url": "https://api.github.com/users/random-residual/repos", "events_url": "https://api.github.com/users/random-residual/events{/privacy}", "received_events_url": "https://api.github.com/users/random-residual/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-09T17:45:10Z", "updated_at": "2018-02-09T17:45:10Z", "author_association": "NONE", "body_html": "<p>I am having this problem as well on AWS SageMaker. I am using a simple example and transforming it to an estimator with <code>python tf.keras.estimator.model_to_estimator(keras_model=model)</code>. I can train the model but cannot save it, I get the following error:</p>\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-27-ed0372b11bae&gt; in &lt;module&gt;()\n      1 \n      2 \n----&gt; 3 exported_model = model.export_savedmodel(export_dir_base = 'export/Servo/', serving_input_receiver_fn = serving_input_fn)\n      4 \n      5 print (exported_model)\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in export_savedmodel(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path)\n    515           serving_input_receiver.receiver_tensors,\n    516           estimator_spec.export_outputs,\n--&gt; 517           serving_input_receiver.receiver_tensors_alternatives)\n    518 \n    519       if not checkpoint_path:\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/export/export.py in build_all_signature_defs(receiver_tensors, export_outputs, receiver_tensors_alternatives)\n    191     receiver_tensors = {_SINGLE_RECEIVER_DEFAULT_NAME: receiver_tensors}\n    192   if export_outputs is None or not isinstance(export_outputs, dict):\n--&gt; 193     raise ValueError('export_outputs must be a dict.')\n    194 \n    195   signature_def_map = {}\n\nValueError: export_outputs must be a dict.\n\n</code></pre>\n<p>My code is:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> sklearn.preprocessing <span class=\"pl-k\">import</span> LabelEncoder\n<span class=\"pl-k\">from</span> sklearn.externals <span class=\"pl-k\">import</span> joblib\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">featureTransform</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">max_words</span>):\n    tokenize <span class=\"pl-k\">=</span> tf.keras.preprocessing.text.Tokenizer(<span class=\"pl-v\">num_words</span><span class=\"pl-k\">=</span>max_words, <span class=\"pl-v\">char_level</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    tokenize.fit_on_texts(features) \n    <span class=\"pl-k\">return</span> tokenize.texts_to_matrix(features).astype(np.float32) \n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">encodeLabels</span>(<span class=\"pl-smi\">labels</span>):\n    encoder <span class=\"pl-k\">=</span> LabelEncoder()\n    encoder.fit(labels)\n    y <span class=\"pl-k\">=</span> encoder.transform(labels)\n    num_classes <span class=\"pl-k\">=</span> np.max(y) <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num classes: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(num_classes))\n    <span class=\"pl-k\">return</span> tf.keras.utils.to_categorical(y, num_classes).astype(np.float32)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">estimator_fn</span>(<span class=\"pl-smi\">run_config</span>, <span class=\"pl-smi\">params</span>):\n    model <span class=\"pl-k\">=</span> tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(<span class=\"pl-c1\">500</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">input_shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">500</span>,), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>features<span class=\"pl-pds\">\"</span></span>))\n    model.add(tf.keras.layers.Dropout(<span class=\"pl-c1\">0.5</span>))\n    model.add(tf.keras.layers.Dense(<span class=\"pl-c1\">500</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>))\n    model.add(tf.keras.layers.Dropout(<span class=\"pl-c1\">0.5</span>))\n    model.add(tf.keras.layers.Dense(<span class=\"pl-c1\">123</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>softmax<span class=\"pl-pds\">'</span></span>))\n    model.compile(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>categorical_crossentropy<span class=\"pl-pds\">'</span></span>,\n              <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>rmsprop<span class=\"pl-pds\">'</span></span>,\n              <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>])\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input names: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(model.input_names))\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>output names: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(model.output_names))\n    \n    <span class=\"pl-k\">return</span> tf.keras.estimator.model_to_estimator(<span class=\"pl-v\">keras_model</span><span class=\"pl-k\">=</span>model)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">serving_input_fn</span>():\n    feature_spec <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>features_input<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">500</span>])}\n    <span class=\"pl-k\">return</span> tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train_input_fn</span>(<span class=\"pl-smi\">training_dir</span>, <span class=\"pl-smi\">params</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Returns input function that would feed the model during training<span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">return</span> _generate_input_fn(training_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>assignment_train.csv<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">eval_input_fn</span>(<span class=\"pl-smi\">training_dir</span>, <span class=\"pl-smi\">params</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Returns input function that would feed the model during evaluation<span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">return</span> _generate_input_fn(training_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>assignment_test.csv<span class=\"pl-pds\">'</span></span>)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_generate_input_fn</span>(<span class=\"pl-smi\">training_dir</span>, <span class=\"pl-smi\">training_filename</span>, <span class=\"pl-smi\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n    training_set <span class=\"pl-k\">=</span> tf.contrib.learn.datasets.base.load_csv_without_header(\n    <span class=\"pl-v\">filename</span><span class=\"pl-k\">=</span>os.path.join(training_dir, training_filename), <span class=\"pl-v\">target_dtype</span><span class=\"pl-k\">=</span>np.str, <span class=\"pl-v\">features_dtype</span><span class=\"pl-k\">=</span>np.float32)\n    \n    input_fn <span class=\"pl-k\">=</span> tf.estimator.inputs.numpy_input_fn(\n        <span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>features_input<span class=\"pl-pds\">\"</span></span>:  np.array(training_set.data)}, \n        <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>encodeLabels(training_set.target),\n        <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>,\n        <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span>shuffle\n    )\n    <span class=\"pl-k\">return</span> input_fn\n</pre></div>\n<p>I can train the model locally in Jupyter in SageMaker.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> assignments <span class=\"pl-k\">import</span> estimator_fn, _generate_input_fn\n<span class=\"pl-k\">from</span> assignments <span class=\"pl-k\">import</span> serving_input_fn\n\nmodel <span class=\"pl-k\">=</span> estimator_fn(<span class=\"pl-v\">run_config</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>, <span class=\"pl-v\">params</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>)\n\nmodel.train(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>_generate_input_fn(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>data<span class=\"pl-pds\">'</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>assignment_train.csv<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n\n\nexported_model <span class=\"pl-k\">=</span> model.export_savedmodel(<span class=\"pl-v\">export_dir_base</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>export/Servo/<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">serving_input_receiver_fn</span> <span class=\"pl-k\">=</span> serving_input_fn)\n\n<span class=\"pl-c1\">print</span> (exported_model)\n<span class=\"pl-k\">import</span> tarfile\n<span class=\"pl-k\">with</span> tarfile.open(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>model.tar.gz<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>w:gz<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> archive:\n    archive.add(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>export<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">recursive</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n</pre></div>\n<p>I have spend quite a bit of time trying to get around this.</p>", "body_text": "I am having this problem as well on AWS SageMaker. I am using a simple example and transforming it to an estimator with python tf.keras.estimator.model_to_estimator(keras_model=model). I can train the model but cannot save it, I get the following error:\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-27-ed0372b11bae> in <module>()\n      1 \n      2 \n----> 3 exported_model = model.export_savedmodel(export_dir_base = 'export/Servo/', serving_input_receiver_fn = serving_input_fn)\n      4 \n      5 print (exported_model)\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in export_savedmodel(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path)\n    515           serving_input_receiver.receiver_tensors,\n    516           estimator_spec.export_outputs,\n--> 517           serving_input_receiver.receiver_tensors_alternatives)\n    518 \n    519       if not checkpoint_path:\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/export/export.py in build_all_signature_defs(receiver_tensors, export_outputs, receiver_tensors_alternatives)\n    191     receiver_tensors = {_SINGLE_RECEIVER_DEFAULT_NAME: receiver_tensors}\n    192   if export_outputs is None or not isinstance(export_outputs, dict):\n--> 193     raise ValueError('export_outputs must be a dict.')\n    194 \n    195   signature_def_map = {}\n\nValueError: export_outputs must be a dict.\n\n\nMy code is:\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.externals import joblib\n\n\ndef featureTransform(features, max_words):\n    tokenize = tf.keras.preprocessing.text.Tokenizer(num_words=max_words, char_level=False)\n    tokenize.fit_on_texts(features) \n    return tokenize.texts_to_matrix(features).astype(np.float32) \n\ndef encodeLabels(labels):\n    encoder = LabelEncoder()\n    encoder.fit(labels)\n    y = encoder.transform(labels)\n    num_classes = np.max(y) + 1\n    print(\"num classes: {}\".format(num_classes))\n    return tf.keras.utils.to_categorical(y, num_classes).astype(np.float32)\n\ndef estimator_fn(run_config, params):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(500, activation='relu', input_shape=(500,), name=\"features\"))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(500, activation='relu'))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(123, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n    print(\"input names: {}\".format(model.input_names))\n    print(\"output names: {}\".format(model.output_names))\n    \n    return tf.keras.estimator.model_to_estimator(keras_model=model)\n\ndef serving_input_fn():\n    feature_spec = {'features_input': tf.FixedLenFeature(dtype=tf.float32, shape=[500])}\n    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\n\ndef train_input_fn(training_dir, params):\n    \"\"\"Returns input function that would feed the model during training\"\"\"\n    return _generate_input_fn(training_dir, 'assignment_train.csv')\n\ndef eval_input_fn(training_dir, params):\n    \"\"\"Returns input function that would feed the model during evaluation\"\"\"\n    return _generate_input_fn(training_dir, 'assignment_test.csv')\n\n\ndef _generate_input_fn(training_dir, training_filename, shuffle=False):\n    training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n    filename=os.path.join(training_dir, training_filename), target_dtype=np.str, features_dtype=np.float32)\n    \n    input_fn = tf.estimator.inputs.numpy_input_fn(\n        x={\"features_input\":  np.array(training_set.data)}, \n        y=encodeLabels(training_set.target),\n        num_epochs=100,\n        shuffle=shuffle\n    )\n    return input_fn\n\nI can train the model locally in Jupyter in SageMaker.\nfrom assignments import estimator_fn, _generate_input_fn\nfrom assignments import serving_input_fn\n\nmodel = estimator_fn(run_config = None, params = None)\n\nmodel.train(input_fn=_generate_input_fn('data','assignment_train.csv', shuffle=True))\n\n\nexported_model = model.export_savedmodel(export_dir_base = 'export/Servo/', serving_input_receiver_fn = serving_input_fn)\n\nprint (exported_model)\nimport tarfile\nwith tarfile.open('model.tar.gz', mode='w:gz') as archive:\n    archive.add('export', recursive=True)\n\nI have spend quite a bit of time trying to get around this.", "body": "I am having this problem as well on AWS SageMaker. I am using a simple example and transforming it to an estimator with ```python tf.keras.estimator.model_to_estimator(keras_model=model)```. I can train the model but cannot save it, I get the following error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-27-ed0372b11bae> in <module>()\r\n      1 \r\n      2 \r\n----> 3 exported_model = model.export_savedmodel(export_dir_base = 'export/Servo/', serving_input_receiver_fn = serving_input_fn)\r\n      4 \r\n      5 print (exported_model)\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in export_savedmodel(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path)\r\n    515           serving_input_receiver.receiver_tensors,\r\n    516           estimator_spec.export_outputs,\r\n--> 517           serving_input_receiver.receiver_tensors_alternatives)\r\n    518 \r\n    519       if not checkpoint_path:\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/export/export.py in build_all_signature_defs(receiver_tensors, export_outputs, receiver_tensors_alternatives)\r\n    191     receiver_tensors = {_SINGLE_RECEIVER_DEFAULT_NAME: receiver_tensors}\r\n    192   if export_outputs is None or not isinstance(export_outputs, dict):\r\n--> 193     raise ValueError('export_outputs must be a dict.')\r\n    194 \r\n    195   signature_def_map = {}\r\n\r\nValueError: export_outputs must be a dict.\r\n\r\n```\r\n\r\nMy code is:\r\n\r\n```python\r\n\r\n\r\nimport numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nfrom sklearn.preprocessing import LabelEncoder\r\nfrom sklearn.externals import joblib\r\n\r\n\r\ndef featureTransform(features, max_words):\r\n    tokenize = tf.keras.preprocessing.text.Tokenizer(num_words=max_words, char_level=False)\r\n    tokenize.fit_on_texts(features) \r\n    return tokenize.texts_to_matrix(features).astype(np.float32) \r\n\r\ndef encodeLabels(labels):\r\n    encoder = LabelEncoder()\r\n    encoder.fit(labels)\r\n    y = encoder.transform(labels)\r\n    num_classes = np.max(y) + 1\r\n    print(\"num classes: {}\".format(num_classes))\r\n    return tf.keras.utils.to_categorical(y, num_classes).astype(np.float32)\r\n\r\ndef estimator_fn(run_config, params):\r\n    model = tf.keras.models.Sequential()\r\n    model.add(tf.keras.layers.Dense(500, activation='relu', input_shape=(500,), name=\"features\"))\r\n    model.add(tf.keras.layers.Dropout(0.5))\r\n    model.add(tf.keras.layers.Dense(500, activation='relu'))\r\n    model.add(tf.keras.layers.Dropout(0.5))\r\n    model.add(tf.keras.layers.Dense(123, activation='softmax'))\r\n    model.compile(loss='categorical_crossentropy',\r\n              optimizer='rmsprop',\r\n              metrics=['accuracy'])\r\n    print(\"input names: {}\".format(model.input_names))\r\n    print(\"output names: {}\".format(model.output_names))\r\n    \r\n    return tf.keras.estimator.model_to_estimator(keras_model=model)\r\n\r\ndef serving_input_fn():\r\n    feature_spec = {'features_input': tf.FixedLenFeature(dtype=tf.float32, shape=[500])}\r\n    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\r\n\r\ndef train_input_fn(training_dir, params):\r\n    \"\"\"Returns input function that would feed the model during training\"\"\"\r\n    return _generate_input_fn(training_dir, 'assignment_train.csv')\r\n\r\ndef eval_input_fn(training_dir, params):\r\n    \"\"\"Returns input function that would feed the model during evaluation\"\"\"\r\n    return _generate_input_fn(training_dir, 'assignment_test.csv')\r\n\r\n\r\ndef _generate_input_fn(training_dir, training_filename, shuffle=False):\r\n    training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\r\n    filename=os.path.join(training_dir, training_filename), target_dtype=np.str, features_dtype=np.float32)\r\n    \r\n    input_fn = tf.estimator.inputs.numpy_input_fn(\r\n        x={\"features_input\":  np.array(training_set.data)}, \r\n        y=encodeLabels(training_set.target),\r\n        num_epochs=100,\r\n        shuffle=shuffle\r\n    )\r\n    return input_fn\r\n\r\n```\r\n\r\nI can train the model locally in Jupyter in SageMaker.\r\n\r\n```python\r\n\r\nfrom assignments import estimator_fn, _generate_input_fn\r\nfrom assignments import serving_input_fn\r\n\r\nmodel = estimator_fn(run_config = None, params = None)\r\n\r\nmodel.train(input_fn=_generate_input_fn('data','assignment_train.csv', shuffle=True))\r\n\r\n\r\nexported_model = model.export_savedmodel(export_dir_base = 'export/Servo/', serving_input_receiver_fn = serving_input_fn)\r\n\r\nprint (exported_model)\r\nimport tarfile\r\nwith tarfile.open('model.tar.gz', mode='w:gz') as archive:\r\n    archive.add('export', recursive=True)\r\n\r\n```\r\n\r\nI have spend quite a bit of time trying to get around this."}