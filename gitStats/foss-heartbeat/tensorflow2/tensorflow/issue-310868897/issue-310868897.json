{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18205", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18205/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18205/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18205/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18205", "id": 310868897, "node_id": "MDU6SXNzdWUzMTA4Njg4OTc=", "number": 18205, "title": "Distribution Strategy not working with tf-nightly-gpu for Python3.5", "user": {"login": "macayaven", "id": 4790975, "node_id": "MDQ6VXNlcjQ3OTA5NzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/4790975?v=4", "gravatar_id": "", "url": "https://api.github.com/users/macayaven", "html_url": "https://github.com/macayaven", "followers_url": "https://api.github.com/users/macayaven/followers", "following_url": "https://api.github.com/users/macayaven/following{/other_user}", "gists_url": "https://api.github.com/users/macayaven/gists{/gist_id}", "starred_url": "https://api.github.com/users/macayaven/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/macayaven/subscriptions", "organizations_url": "https://api.github.com/users/macayaven/orgs", "repos_url": "https://api.github.com/users/macayaven/repos", "events_url": "https://api.github.com/users/macayaven/events{/privacy}", "received_events_url": "https://api.github.com/users/macayaven/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-04-03T14:47:52Z", "updated_at": "2018-04-04T05:33:13Z", "closed_at": "2018-04-04T05:33:12Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No, I am using the script <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py</a> provided as an example for DistributionStrategy API</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux  4.13.0-37-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115970699\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/42\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/42/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/42\">#42</a>~16.04.1-Ubuntu SMP Wed Mar 7 16:03:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux \"16.04.4 LTS (Xenial Xerus)\"</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary through pip3 install tf-nightly-gpu<br>\ntf.VERSION = 1.8.0-dev20180402<br>\ntf.GIT_VERSION = v1.7.0-rc1-1091-gc7a04561fb<br>\ntf.COMPILER_VERSION = v1.7.0-rc1-1091-gc7a04561fb<br>\nSanity check: array([1], dtype=int32)</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.7.0-rc1-1091-gc7a04561fb 1.8.0-dev20180402</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nCUDA version: 9.0, V9.0.176<br>\n#define CUDNN_MAJOR 7<br>\n#define CUDNN_MINOR 0<br>\n#define CUDNN_PATCHLEVEL 5</li>\n<li><strong>GPU model and memory</strong>: Quadro M6000 24GB</li>\n<li><strong>Exact command to reproduce</strong>: python3</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am trying to test the DistributionStrategy API. In order to do that I downloaded the tensorflow nightly build by executing<br>\npip3 install tf-nightly-gpu<br>\nThen I tried to execute the example provided here: <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py</a><br>\nBut it is not working, there is an exception shortly after the script starts to run ( I am copying the stack trace in the next section).<br>\nI have tried to do the same using the  tensorflow nightly build for python 2.7 downloaded by executing<br>\npip install tf-nightly-gpu and it works without any problem.<br>\nThe issue here, is that I would like to integrate this API with my multi-gpu training and inference processes, which are complete written for python3.<br>\nI would like to know, if DistributionStrategy API is already supported in for python 3.5 and the problem is that I am using a wrong example. Or, in case it is not supported yet, if there are plans to do it.</p>\n<p>Thanks in advance.</p>\n<h3>Source code / logs</h3>\n<p>(vtf_nightly_gpu) /ccrespo/mirrored_strategy/src$ python3 mirrored_strategy_test.py<br>\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmou3ft0t<br>\n2018-04-03 16:17:32.334622: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA<br>\n2018-04-03 16:17:32.686755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:<br>\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114<br>\npciBusID: 0000:03:00.0<br>\ntotalMemory: 23.90GiB freeMemory: 23.35GiB<br>\n2018-04-03 16:17:32.956384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties:<br>\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114<br>\npciBusID: 0000:04:00.0<br>\ntotalMemory: 23.90GiB freeMemory: 23.78GiB<br>\n2018-04-03 16:17:33.215141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties:<br>\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114<br>\npciBusID: 0000:a1:00.0<br>\ntotalMemory: 23.90GiB freeMemory: 23.78GiB<br>\n2018-04-03 16:17:33.215663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2<br>\n2018-04-03 16:17:34.314104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:<br>\n2018-04-03 16:17:34.314172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2<br>\n2018-04-03 16:17:34.314181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N<br>\n2018-04-03 16:17:34.314185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N<br>\n2018-04-03 16:17:34.314190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N<br>\n2018-04-03 16:17:34.315429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 22663 MB memory) -&gt; physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)<br>\n2018-04-03 16:17:34.802106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 23083 MB memory) -&gt; physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)<br>\n2018-04-03 16:17:35.250349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:2 with 23083 MB memory) -&gt; physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)<br>\n2018-04-03 16:17:35.726606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2<br>\n2018-04-03 16:17:35.726819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:<br>\n2018-04-03 16:17:35.726838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2<br>\n2018-04-03 16:17:35.726849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N<br>\n2018-04-03 16:17:35.726858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N<br>\n2018-04-03 16:17:35.726867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N<br>\n2018-04-03 16:17:35.727458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22663 MB memory) -&gt; physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)<br>\n2018-04-03 16:17:35.727626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 23083 MB memory) -&gt; physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)<br>\n2018-04-03 16:17:35.727819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 23083 MB memory) -&gt; physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)<br>\nTraceback (most recent call last):<br>\nFile \"mirrored_strategy_test.py\", line 86, in <br>\ntf.app.run()<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 126, in run<br>\n_sys.exit(main(argv))<br>\nFile \"mirrored_strategy_test.py\", line 70, in main<br>\nestimator.train(input_fn=input_fn, steps=10)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train<br>\nloss = self._train_model(input_fn, hooks, saving_listeners)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 841, in _train_model<br>\nreturn self._train_model_distributed(input_fn, hooks, saving_listeners)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 884, in _train_model_distributed<br>\nself.config)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py\", line 751, in call_for_each_tower<br>\nreturn self._call_for_each_tower(fn, *args, **kwargs)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 254, in _call_for_each_tower<br>\ncoord.join(threads)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join<br>\nsix.reraise(*self._exc_info_to_raise)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/six.py\", line 693, in reraise<br>\nraise value<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception<br>\nyield<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower<br>\nself, *merge_args, **merge_kwargs)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 667, in _distributed_apply<br>\nreduced_grads = distribution.batch_reduce(\"sum\", grads_and_vars)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py\", line 796, in batch_reduce<br>\nreturn self._batch_reduce(method_string, value_destination_pairs)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 295, in _batch_reduce<br>\nvalue_destination_pairs)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 175, in batch_reduce<br>\nreturn self._batch_reduce(method_string, value_destination_pairs)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 462, in _batch_reduce<br>\n[v[0] for v in value_destination_pairs])<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 517, in _batch_all_reduce<br>\nmethod_string)<br>\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 276, in _ungroup_and_make_mirrored<br>\nindex[i][destinations[d]] = v<br>\nTypeError: 'dict_keys' object does not support indexing</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No, I am using the script https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py provided as an example for DistributionStrategy API\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux  4.13.0-37-generic #42~16.04.1-Ubuntu SMP Wed Mar 7 16:03:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux \"16.04.4 LTS (Xenial Xerus)\"\nTensorFlow installed from (source or binary): binary through pip3 install tf-nightly-gpu\ntf.VERSION = 1.8.0-dev20180402\ntf.GIT_VERSION = v1.7.0-rc1-1091-gc7a04561fb\ntf.COMPILER_VERSION = v1.7.0-rc1-1091-gc7a04561fb\nSanity check: array([1], dtype=int32)\nTensorFlow version (use command below): v1.7.0-rc1-1091-gc7a04561fb 1.8.0-dev20180402\nPython version: 3.5\nCUDA/cuDNN version:\nCUDA version: 9.0, V9.0.176\n#define CUDNN_MAJOR 7\n#define CUDNN_MINOR 0\n#define CUDNN_PATCHLEVEL 5\nGPU model and memory: Quadro M6000 24GB\nExact command to reproduce: python3\n\nDescribe the problem\nI am trying to test the DistributionStrategy API. In order to do that I downloaded the tensorflow nightly build by executing\npip3 install tf-nightly-gpu\nThen I tried to execute the example provided here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py\nBut it is not working, there is an exception shortly after the script starts to run ( I am copying the stack trace in the next section).\nI have tried to do the same using the  tensorflow nightly build for python 2.7 downloaded by executing\npip install tf-nightly-gpu and it works without any problem.\nThe issue here, is that I would like to integrate this API with my multi-gpu training and inference processes, which are complete written for python3.\nI would like to know, if DistributionStrategy API is already supported in for python 3.5 and the problem is that I am using a wrong example. Or, in case it is not supported yet, if there are plans to do it.\nThanks in advance.\nSource code / logs\n(vtf_nightly_gpu) /ccrespo/mirrored_strategy/src$ python3 mirrored_strategy_test.py\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmou3ft0t\n2018-04-03 16:17:32.334622: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-04-03 16:17:32.686755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114\npciBusID: 0000:03:00.0\ntotalMemory: 23.90GiB freeMemory: 23.35GiB\n2018-04-03 16:17:32.956384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties:\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114\npciBusID: 0000:04:00.0\ntotalMemory: 23.90GiB freeMemory: 23.78GiB\n2018-04-03 16:17:33.215141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties:\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114\npciBusID: 0000:a1:00.0\ntotalMemory: 23.90GiB freeMemory: 23.78GiB\n2018-04-03 16:17:33.215663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2\n2018-04-03 16:17:34.314104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-04-03 16:17:34.314172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2\n2018-04-03 16:17:34.314181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N\n2018-04-03 16:17:34.314185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N\n2018-04-03 16:17:34.314190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N\n2018-04-03 16:17:34.315429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 22663 MB memory) -> physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)\n2018-04-03 16:17:34.802106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 23083 MB memory) -> physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)\n2018-04-03 16:17:35.250349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:2 with 23083 MB memory) -> physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)\n2018-04-03 16:17:35.726606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2\n2018-04-03 16:17:35.726819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-04-03 16:17:35.726838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2\n2018-04-03 16:17:35.726849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N\n2018-04-03 16:17:35.726858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N\n2018-04-03 16:17:35.726867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N\n2018-04-03 16:17:35.727458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22663 MB memory) -> physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)\n2018-04-03 16:17:35.727626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 23083 MB memory) -> physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)\n2018-04-03 16:17:35.727819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 23083 MB memory) -> physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)\nTraceback (most recent call last):\nFile \"mirrored_strategy_test.py\", line 86, in \ntf.app.run()\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 126, in run\n_sys.exit(main(argv))\nFile \"mirrored_strategy_test.py\", line 70, in main\nestimator.train(input_fn=input_fn, steps=10)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\nloss = self._train_model(input_fn, hooks, saving_listeners)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 841, in _train_model\nreturn self._train_model_distributed(input_fn, hooks, saving_listeners)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 884, in _train_model_distributed\nself.config)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py\", line 751, in call_for_each_tower\nreturn self._call_for_each_tower(fn, *args, **kwargs)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 254, in _call_for_each_tower\ncoord.join(threads)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\nsix.reraise(*self._exc_info_to_raise)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/six.py\", line 693, in reraise\nraise value\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\nyield\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower\nself, *merge_args, **merge_kwargs)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 667, in _distributed_apply\nreduced_grads = distribution.batch_reduce(\"sum\", grads_and_vars)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py\", line 796, in batch_reduce\nreturn self._batch_reduce(method_string, value_destination_pairs)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 295, in _batch_reduce\nvalue_destination_pairs)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 175, in batch_reduce\nreturn self._batch_reduce(method_string, value_destination_pairs)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 462, in _batch_reduce\n[v[0] for v in value_destination_pairs])\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 517, in _batch_all_reduce\nmethod_string)\nFile \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 276, in _ungroup_and_make_mirrored\nindex[i][destinations[d]] = v\nTypeError: 'dict_keys' object does not support indexing", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I am using the script https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py provided as an example for DistributionStrategy API\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux  4.13.0-37-generic #42~16.04.1-Ubuntu SMP Wed Mar 7 16:03:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux \"16.04.4 LTS (Xenial Xerus)\"\r\n- **TensorFlow installed from (source or binary)**: binary through pip3 install tf-nightly-gpu\r\ntf.VERSION = 1.8.0-dev20180402\r\ntf.GIT_VERSION = v1.7.0-rc1-1091-gc7a04561fb\r\ntf.COMPILER_VERSION = v1.7.0-rc1-1091-gc7a04561fb\r\nSanity check: array([1], dtype=int32)\r\n- **TensorFlow version (use command below)**: v1.7.0-rc1-1091-gc7a04561fb 1.8.0-dev20180402\r\n- **Python version**: 3.5\r\n- **CUDA/cuDNN version**: \r\nCUDA version: 9.0, V9.0.176\r\n#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 0\r\n#define CUDNN_PATCHLEVEL 5\r\n- **GPU model and memory**: Quadro M6000 24GB\r\n- **Exact command to reproduce**: python3 \r\n\r\n### Describe the problem\r\nI am trying to test the DistributionStrategy API. In order to do that I downloaded the tensorflow nightly build by executing  \r\npip3 install tf-nightly-gpu\r\nThen I tried to execute the example provided here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py\r\nBut it is not working, there is an exception shortly after the script starts to run ( I am copying the stack trace in the next section).\r\nI have tried to do the same using the  tensorflow nightly build for python 2.7 downloaded by executing  \r\npip install tf-nightly-gpu and it works without any problem.\r\nThe issue here, is that I would like to integrate this API with my multi-gpu training and inference processes, which are complete written for python3. \r\nI would like to know, if DistributionStrategy API is already supported in for python 3.5 and the problem is that I am using a wrong example. Or, in case it is not supported yet, if there are plans to do it.\r\n\r\nThanks in advance.\r\n\r\n\r\n### Source code / logs\r\n(vtf_nightly_gpu) /ccrespo/mirrored_strategy/src$ python3 mirrored_strategy_test.py \r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmou3ft0t\r\n2018-04-03 16:17:32.334622: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-04-03 16:17:32.686755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \r\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 23.90GiB freeMemory: 23.35GiB\r\n2018-04-03 16:17:32.956384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: \r\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 23.90GiB freeMemory: 23.78GiB\r\n2018-04-03 16:17:33.215141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties: \r\nname: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114\r\npciBusID: 0000:a1:00.0\r\ntotalMemory: 23.90GiB freeMemory: 23.78GiB\r\n2018-04-03 16:17:33.215663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2\r\n2018-04-03 16:17:34.314104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-04-03 16:17:34.314172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 \r\n2018-04-03 16:17:34.314181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N \r\n2018-04-03 16:17:34.314185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N \r\n2018-04-03 16:17:34.314190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N \r\n2018-04-03 16:17:34.315429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 22663 MB memory) -> physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2018-04-03 16:17:34.802106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 23083 MB memory) -> physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\n2018-04-03 16:17:35.250349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:2 with 23083 MB memory) -> physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)\r\n2018-04-03 16:17:35.726606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2\r\n2018-04-03 16:17:35.726819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-04-03 16:17:35.726838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 \r\n2018-04-03 16:17:35.726849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N \r\n2018-04-03 16:17:35.726858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N \r\n2018-04-03 16:17:35.726867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N \r\n2018-04-03 16:17:35.727458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22663 MB memory) -> physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2018-04-03 16:17:35.727626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 23083 MB memory) -> physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\n2018-04-03 16:17:35.727819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 23083 MB memory) -> physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)\r\nTraceback (most recent call last):\r\n  File \"mirrored_strategy_test.py\", line 86, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"mirrored_strategy_test.py\", line 70, in main\r\n    estimator.train(input_fn=input_fn, steps=10)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 841, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 884, in _train_model_distributed\r\n    self.config)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py\", line 751, in call_for_each_tower\r\n    return self._call_for_each_tower(fn, *args, **kwargs)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 254, in _call_for_each_tower\r\n    coord.join(threads)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 248, in _call_for_each_tower\r\n    self, *merge_args, **merge_kwargs)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 667, in _distributed_apply\r\n    reduced_grads = distribution.batch_reduce(\"sum\", grads_and_vars)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py\", line 796, in batch_reduce\r\n    return self._batch_reduce(method_string, value_destination_pairs)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 295, in _batch_reduce\r\n    value_destination_pairs)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 175, in batch_reduce\r\n    return self._batch_reduce(method_string, value_destination_pairs)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 462, in _batch_reduce\r\n    [v[0] for v in value_destination_pairs])\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 517, in _batch_all_reduce\r\n    method_string)\r\n  File \"/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 276, in _ungroup_and_make_mirrored\r\n    index[i][destinations[d]] = v\r\nTypeError: 'dict_keys' object does not support indexing\r\n"}