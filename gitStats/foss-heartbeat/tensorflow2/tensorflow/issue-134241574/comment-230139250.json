{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/230139250", "html_url": "https://github.com/tensorflow/tensorflow/issues/1140#issuecomment-230139250", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1140", "id": 230139250, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMDEzOTI1MA==", "user": {"login": "samjabrahams", "id": 11607205, "node_id": "MDQ6VXNlcjExNjA3MjA1", "avatar_url": "https://avatars0.githubusercontent.com/u/11607205?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samjabrahams", "html_url": "https://github.com/samjabrahams", "followers_url": "https://api.github.com/users/samjabrahams/followers", "following_url": "https://api.github.com/users/samjabrahams/following{/other_user}", "gists_url": "https://api.github.com/users/samjabrahams/gists{/gist_id}", "starred_url": "https://api.github.com/users/samjabrahams/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samjabrahams/subscriptions", "organizations_url": "https://api.github.com/users/samjabrahams/orgs", "repos_url": "https://api.github.com/users/samjabrahams/repos", "events_url": "https://api.github.com/users/samjabrahams/events{/privacy}", "received_events_url": "https://api.github.com/users/samjabrahams/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-03T07:07:47Z", "updated_at": "2016-07-03T07:07:47Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Definitely- no worries on your end, I should have been more diligent reading the original message.</p>\n<p>Something I've noticed is that some Ops have fleshed out GPU implementations, while others simply register to GPU using the same implementation as CPU. Is that due to some operations being able to take better advantage of highly-parallel computation, or am I missing something?</p>", "body_text": "Definitely- no worries on your end, I should have been more diligent reading the original message.\nSomething I've noticed is that some Ops have fleshed out GPU implementations, while others simply register to GPU using the same implementation as CPU. Is that due to some operations being able to take better advantage of highly-parallel computation, or am I missing something?", "body": "Definitely- no worries on your end, I should have been more diligent reading the original message.\n\nSomething I've noticed is that some Ops have fleshed out GPU implementations, while others simply register to GPU using the same implementation as CPU. Is that due to some operations being able to take better advantage of highly-parallel computation, or am I missing something?\n"}