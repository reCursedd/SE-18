{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/230147452", "html_url": "https://github.com/tensorflow/tensorflow/issues/1140#issuecomment-230147452", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1140", "id": 230147452, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMDE0NzQ1Mg==", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-03T10:59:46Z", "updated_at": "2016-07-03T10:59:46Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You will need to instantiate an explicit GPU implementation if you want to actually use the GPU.<br>\n<code>MatMul</code> for example actually runs on the GPU, so it wouldn't be correct to use <code>.HostMemory</code>.</p>\n<p>It might be a bit tricky to spot how running GPU computations is accomplished, because it is nicely abstracted by the Eigen interface.<br>\nWhenever you see a line like</p>\n<div class=\"highlight highlight-source-c++\"><pre>output.device(d) = <span class=\"pl-c\"><span class=\"pl-c\">//</span> ... some expression involving an `input` tensor</span></pre></div>\n<p>then this will either run on the host (if <code>d</code> is a <code>CPUDevice</code>) or will run on a GPU (if <code>d</code> is a <code>GPUDevice</code>).<br>\nYou can grab the device by calling <code>ctx-&gt;eigen_device&lt;Device&gt;()</code>.</p>\n<p>For example, the <code>MatMulOp</code> calls it's functor with the current device here:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L160\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L160</a><br>\nThen this line gets executed:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.h#L38\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.h#L38</a></p>", "body_text": "You will need to instantiate an explicit GPU implementation if you want to actually use the GPU.\nMatMul for example actually runs on the GPU, so it wouldn't be correct to use .HostMemory.\nIt might be a bit tricky to spot how running GPU computations is accomplished, because it is nicely abstracted by the Eigen interface.\nWhenever you see a line like\noutput.device(d) = // ... some expression involving an `input` tensor\nthen this will either run on the host (if d is a CPUDevice) or will run on a GPU (if d is a GPUDevice).\nYou can grab the device by calling ctx->eigen_device<Device>().\nFor example, the MatMulOp calls it's functor with the current device here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L160\nThen this line gets executed:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.h#L38", "body": "You will need to instantiate an explicit GPU implementation if you want to actually use the GPU.\n`MatMul` for example actually runs on the GPU, so it wouldn't be correct to use `.HostMemory`.\n\nIt might be a bit tricky to spot how running GPU computations is accomplished, because it is nicely abstracted by the Eigen interface.\nWhenever you see a line like\n\n``` cpp\noutput.device(d) = // ... some expression involving an `input` tensor\n```\n\nthen this will either run on the host (if `d` is a `CPUDevice`) or will run on a GPU (if `d` is a `GPUDevice`).\nYou can grab the device by calling `ctx->eigen_device<Device>()`.\n\nFor example, the `MatMulOp` calls it's functor with the current device here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L160\nThen this line gets executed:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.h#L38\n"}