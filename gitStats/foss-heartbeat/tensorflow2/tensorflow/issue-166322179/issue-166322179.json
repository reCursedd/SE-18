{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3389", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3389/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3389/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3389/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3389", "id": 166322179, "node_id": "MDU6SXNzdWUxNjYzMjIxNzk=", "number": 3389, "title": "Why doesn't tensorflow support tensor as the feed_dict?", "user": {"login": "wishforgood", "id": 9963412, "node_id": "MDQ6VXNlcjk5NjM0MTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/9963412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wishforgood", "html_url": "https://github.com/wishforgood", "followers_url": "https://api.github.com/users/wishforgood/followers", "following_url": "https://api.github.com/users/wishforgood/following{/other_user}", "gists_url": "https://api.github.com/users/wishforgood/gists{/gist_id}", "starred_url": "https://api.github.com/users/wishforgood/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wishforgood/subscriptions", "organizations_url": "https://api.github.com/users/wishforgood/orgs", "repos_url": "https://api.github.com/users/wishforgood/repos", "events_url": "https://api.github.com/users/wishforgood/events{/privacy}", "received_events_url": "https://api.github.com/users/wishforgood/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2016-07-19T12:45:36Z", "updated_at": "2018-04-23T09:11:48Z", "closed_at": "2016-07-21T01:50:18Z", "author_association": "NONE", "body_html": "<p><strong>What I'm trying to do</strong></p>\n<p>I am trying to extract CNN features for my own images with residual-net based on <a href=\"https://github.com/ry/tensorflow-resnet\">https://github.com/ry/tensorflow-resnet</a>. I plan to input image data from JPG files before exploring how to convert the images into a single file.</p>\n<p><strong>What I have done</strong></p>\n<p>I have read <a href=\"https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html\" rel=\"nofollow\">https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html</a> and some related materials about how to input data like feeding and placeholder. Here is my code:</p>\n<pre><code>import tensorflow as tf\nfrom convert import print_prob, checkpoint_fn, meta_fn\nfrom image_processing import image_preprocessing\ntf.app.flags.DEFINE_integer('batch_size', 1, \"batch size\")\ntf.app.flags.DEFINE_integer('input_size', 224, \"input image size\")\ntf.app.flags.DEFINE_integer('min_after_dequeue', 224, \"min after dequeue\")\ntf.app.flags.DEFINE_integer('layers', 152, \"The number of layers in the net\")\ntf.app.flags.DEFINE_integer('image_number', 6951, \"number of images\")\nFLAGS = tf.app.flags.FLAGS\n\n\ndef placeholder_inputs():\n    images_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.input_size, FLAGS.input_size, 3))\n    label_placeholder = tf.placeholder(tf.int32, shape=FLAGS.batch_size)\n    return images_placeholder, label_placeholder\n\n\ndef fill_feed_dict(image_ba, label_ba, images_pl, labels_pl):\n    feed_dict = {\n        images_pl: image_ba,\n    }\n    return feed_dict\n\nmin_fraction_of_examples_in_queue = 0.4\nmin_queue_examples = int(FLAGS.image_number *\n                     min_fraction_of_examples_in_queue)\ndataset = tf.train.string_input_producer([\"hollywood_test.txt\"])\nreader = tf.TextLineReader()\n_, file_content = reader.read(dataset)\nimage_name, label, _ = tf.decode_csv(file_content, [[\"\"], [\"\"], [\"\"]], \" \")\nlabel = tf.string_to_number(label)\nnum_preprocess_threads = 10\nimages_and_labels = []\nwith tf.Session() as sess:\n    for thread_id in range(num_preprocess_threads):\n        image_buffer = tf.read_file(image_name)\n        bbox = []\n        train = False\n        image = image_preprocessing(image_buffer, bbox, train, thread_id)\n        image = image_buffer\n        images_and_labels.append([image, label])\n    image_batch, label_batch = tf.train.batch_join(images_and_labels,\n                                            batch_size=FLAGS.batch_size,\n                                            capacity=min_queue_examples + 3 * FLAGS.batch_size)\n    images_placeholder, labels_placeholder = placeholder_inputs()\n    new_saver = tf.train.import_meta_graph(meta_fn(FLAGS.layers))\n    new_saver.restore(sess, checkpoint_fn(FLAGS.layers))\n    graph = tf.get_default_graph()\n    prob_tensor = graph.get_tensor_by_name(\"prob:0\")\n    images = graph.get_tensor_by_name(\"images:0\")\n    feed_dict = fill_feed_dict(image_batch, label_batch, images, labels_placeholder)\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n    sess.run(tf.initialize_all_variables())\n    prob = sess.run(prob_tensor, feed_dict=feed_dict)\n    print_prob(prob[0])\n    coord.request_stop()\n    coord.join(threads)\n</code></pre>\n<p><strong>What my question is</strong></p>\n<p>The code above got the error <code>TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.</code> You can see I am trying to do all the work in the context of tensorflow. As far as I know, tensorflow is a framework where all the inputs and outputs of the nodes are tensors. However, I am quite confused why feed_dict doesn't support tensor as an input. But the batch_join function return a tensor and so do other ops. I found that in the mnist example of tensorflow there is even another function to produce a batch when tensorflow is providing methods for batching. So I wonder if there is an elegant way to do these things. If this is because of my lack of searching and careful reading I really apologize.</p>", "body_text": "What I'm trying to do\nI am trying to extract CNN features for my own images with residual-net based on https://github.com/ry/tensorflow-resnet. I plan to input image data from JPG files before exploring how to convert the images into a single file.\nWhat I have done\nI have read https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html and some related materials about how to input data like feeding and placeholder. Here is my code:\nimport tensorflow as tf\nfrom convert import print_prob, checkpoint_fn, meta_fn\nfrom image_processing import image_preprocessing\ntf.app.flags.DEFINE_integer('batch_size', 1, \"batch size\")\ntf.app.flags.DEFINE_integer('input_size', 224, \"input image size\")\ntf.app.flags.DEFINE_integer('min_after_dequeue', 224, \"min after dequeue\")\ntf.app.flags.DEFINE_integer('layers', 152, \"The number of layers in the net\")\ntf.app.flags.DEFINE_integer('image_number', 6951, \"number of images\")\nFLAGS = tf.app.flags.FLAGS\n\n\ndef placeholder_inputs():\n    images_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.input_size, FLAGS.input_size, 3))\n    label_placeholder = tf.placeholder(tf.int32, shape=FLAGS.batch_size)\n    return images_placeholder, label_placeholder\n\n\ndef fill_feed_dict(image_ba, label_ba, images_pl, labels_pl):\n    feed_dict = {\n        images_pl: image_ba,\n    }\n    return feed_dict\n\nmin_fraction_of_examples_in_queue = 0.4\nmin_queue_examples = int(FLAGS.image_number *\n                     min_fraction_of_examples_in_queue)\ndataset = tf.train.string_input_producer([\"hollywood_test.txt\"])\nreader = tf.TextLineReader()\n_, file_content = reader.read(dataset)\nimage_name, label, _ = tf.decode_csv(file_content, [[\"\"], [\"\"], [\"\"]], \" \")\nlabel = tf.string_to_number(label)\nnum_preprocess_threads = 10\nimages_and_labels = []\nwith tf.Session() as sess:\n    for thread_id in range(num_preprocess_threads):\n        image_buffer = tf.read_file(image_name)\n        bbox = []\n        train = False\n        image = image_preprocessing(image_buffer, bbox, train, thread_id)\n        image = image_buffer\n        images_and_labels.append([image, label])\n    image_batch, label_batch = tf.train.batch_join(images_and_labels,\n                                            batch_size=FLAGS.batch_size,\n                                            capacity=min_queue_examples + 3 * FLAGS.batch_size)\n    images_placeholder, labels_placeholder = placeholder_inputs()\n    new_saver = tf.train.import_meta_graph(meta_fn(FLAGS.layers))\n    new_saver.restore(sess, checkpoint_fn(FLAGS.layers))\n    graph = tf.get_default_graph()\n    prob_tensor = graph.get_tensor_by_name(\"prob:0\")\n    images = graph.get_tensor_by_name(\"images:0\")\n    feed_dict = fill_feed_dict(image_batch, label_batch, images, labels_placeholder)\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n    sess.run(tf.initialize_all_variables())\n    prob = sess.run(prob_tensor, feed_dict=feed_dict)\n    print_prob(prob[0])\n    coord.request_stop()\n    coord.join(threads)\n\nWhat my question is\nThe code above got the error TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays. You can see I am trying to do all the work in the context of tensorflow. As far as I know, tensorflow is a framework where all the inputs and outputs of the nodes are tensors. However, I am quite confused why feed_dict doesn't support tensor as an input. But the batch_join function return a tensor and so do other ops. I found that in the mnist example of tensorflow there is even another function to produce a batch when tensorflow is providing methods for batching. So I wonder if there is an elegant way to do these things. If this is because of my lack of searching and careful reading I really apologize.", "body": "**What I'm trying to do**\n\nI am trying to extract CNN features for my own images with residual-net based on https://github.com/ry/tensorflow-resnet. I plan to input image data from JPG files before exploring how to convert the images into a single file.\n\n**What I have done**\n\nI have read https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html and some related materials about how to input data like feeding and placeholder. Here is my code:\n\n```\nimport tensorflow as tf\nfrom convert import print_prob, checkpoint_fn, meta_fn\nfrom image_processing import image_preprocessing\ntf.app.flags.DEFINE_integer('batch_size', 1, \"batch size\")\ntf.app.flags.DEFINE_integer('input_size', 224, \"input image size\")\ntf.app.flags.DEFINE_integer('min_after_dequeue', 224, \"min after dequeue\")\ntf.app.flags.DEFINE_integer('layers', 152, \"The number of layers in the net\")\ntf.app.flags.DEFINE_integer('image_number', 6951, \"number of images\")\nFLAGS = tf.app.flags.FLAGS\n\n\ndef placeholder_inputs():\n    images_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.input_size, FLAGS.input_size, 3))\n    label_placeholder = tf.placeholder(tf.int32, shape=FLAGS.batch_size)\n    return images_placeholder, label_placeholder\n\n\ndef fill_feed_dict(image_ba, label_ba, images_pl, labels_pl):\n    feed_dict = {\n        images_pl: image_ba,\n    }\n    return feed_dict\n\nmin_fraction_of_examples_in_queue = 0.4\nmin_queue_examples = int(FLAGS.image_number *\n                     min_fraction_of_examples_in_queue)\ndataset = tf.train.string_input_producer([\"hollywood_test.txt\"])\nreader = tf.TextLineReader()\n_, file_content = reader.read(dataset)\nimage_name, label, _ = tf.decode_csv(file_content, [[\"\"], [\"\"], [\"\"]], \" \")\nlabel = tf.string_to_number(label)\nnum_preprocess_threads = 10\nimages_and_labels = []\nwith tf.Session() as sess:\n    for thread_id in range(num_preprocess_threads):\n        image_buffer = tf.read_file(image_name)\n        bbox = []\n        train = False\n        image = image_preprocessing(image_buffer, bbox, train, thread_id)\n        image = image_buffer\n        images_and_labels.append([image, label])\n    image_batch, label_batch = tf.train.batch_join(images_and_labels,\n                                            batch_size=FLAGS.batch_size,\n                                            capacity=min_queue_examples + 3 * FLAGS.batch_size)\n    images_placeholder, labels_placeholder = placeholder_inputs()\n    new_saver = tf.train.import_meta_graph(meta_fn(FLAGS.layers))\n    new_saver.restore(sess, checkpoint_fn(FLAGS.layers))\n    graph = tf.get_default_graph()\n    prob_tensor = graph.get_tensor_by_name(\"prob:0\")\n    images = graph.get_tensor_by_name(\"images:0\")\n    feed_dict = fill_feed_dict(image_batch, label_batch, images, labels_placeholder)\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n    sess.run(tf.initialize_all_variables())\n    prob = sess.run(prob_tensor, feed_dict=feed_dict)\n    print_prob(prob[0])\n    coord.request_stop()\n    coord.join(threads)\n```\n\n**What my question is**\n\nThe code above got the error `TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.` You can see I am trying to do all the work in the context of tensorflow. As far as I know, tensorflow is a framework where all the inputs and outputs of the nodes are tensors. However, I am quite confused why feed_dict doesn't support tensor as an input. But the batch_join function return a tensor and so do other ops. I found that in the mnist example of tensorflow there is even another function to produce a batch when tensorflow is providing methods for batching. So I wonder if there is an elegant way to do these things. If this is because of my lack of searching and careful reading I really apologize.\n"}