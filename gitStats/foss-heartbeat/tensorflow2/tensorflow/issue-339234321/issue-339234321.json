{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20627", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20627/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20627/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20627/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20627", "id": 339234321, "node_id": "MDU6SXNzdWUzMzkyMzQzMjE=", "number": 20627, "title": "Predictions from provided tflite files of same Mobilenet model do not match", "user": {"login": "abhi-rf", "id": 19860524, "node_id": "MDQ6VXNlcjE5ODYwNTI0", "avatar_url": "https://avatars0.githubusercontent.com/u/19860524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhi-rf", "html_url": "https://github.com/abhi-rf", "followers_url": "https://api.github.com/users/abhi-rf/followers", "following_url": "https://api.github.com/users/abhi-rf/following{/other_user}", "gists_url": "https://api.github.com/users/abhi-rf/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhi-rf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhi-rf/subscriptions", "organizations_url": "https://api.github.com/users/abhi-rf/orgs", "repos_url": "https://api.github.com/users/abhi-rf/repos", "events_url": "https://api.github.com/users/abhi-rf/events{/privacy}", "received_events_url": "https://api.github.com/users/abhi-rf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-07-08T15:24:43Z", "updated_at": "2018-08-18T07:07:37Z", "closed_at": "2018-08-18T06:58:49Z", "author_association": "NONE", "body_html": "<p>Hi Guys. I downloaded the Mobilenet_v1_1.0_224 and Mobilenet_v1_1.0_224_quant from the links provided in the documentation. I then use the tflite models provided in both of these for prediction using the tflite interpeter <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/python_api.md#using-the-interpreter-from-a-model-file-\">Link</a> I am able to make the predictions. However, the tflite predictions from the 'quant' version are very random. The float tflite model makes the correct prediction while the quantised tfite model makes very weird predictions. I even comapred the answers to normal frozen models provided and the quantized tflite model does not match the predictions at all while the float tflite makes all the predictions same as the frozen .pb model.</p>\n<h2>I then tried the same thing with different mobilenet versions but the same observations.<br>\nKindly help.</h2>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10 dev</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>: NA</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I then use the tflite models provided in both of these for prediction using the tflite interpeter <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/python_api.md#using-the-interpreter-from-a-model-file-\">Link</a> I am able to make the predictions. However, the tflite predictions from the 'quant' version are very random. The float tflite model makes the correct prediction while the quantised tfite model makes very weird predictions. I even comapred the answers to normal frozen models provided and the quantized tflite model does not match the predictions at all while the float tflite makes all the predictions same as the frozen .pb model.</p>\n<p>I then tried the same thing with different mobilenet versions but the same observations.</p>\n<p>I am also making sure that I use the exact same images for both so that is not an issue just in case.<br>\nKindly help.</p>\n<h3>Source code / logs</h3>\n<p>img = np.array(PIL.Image.open(image_path).resize((224, 224))).astype(np.uint8) / 128 - 1</p>\n<pre><code>img = img.reshape(1,224,224,3)\n#print (img.shape)\n\nstart = time.time()\n\ninterpreter.set_tensor(input_details[0]['index'], img)\n\ninterpreter.invoke()\nend = time.time()\n\noutput_data = interpreter.get_tensor(output_details[0]['index'])\n#output_data_1 = interpreter.get_tensor(output_details[1]['index'])\n\n#print(output_data.argmax(),output_data.max())\nlabel_map = imagenet.create_readable_names_for_imagenet_labels()  \nprint(\"Top 1 Prediction: \", output_data.argmax(),label_map[output_data.argmax()], output_data.max(), k+1)\n</code></pre>", "body_text": "Hi Guys. I downloaded the Mobilenet_v1_1.0_224 and Mobilenet_v1_1.0_224_quant from the links provided in the documentation. I then use the tflite models provided in both of these for prediction using the tflite interpeter Link I am able to make the predictions. However, the tflite predictions from the 'quant' version are very random. The float tflite model makes the correct prediction while the quantised tfite model makes very weird predictions. I even comapred the answers to normal frozen models provided and the quantized tflite model does not match the predictions at all while the float tflite makes all the predictions same as the frozen .pb model.\nI then tried the same thing with different mobilenet versions but the same observations.\nKindly help.\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.10 dev\nPython version: 2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: NA\nGPU model and memory: NA\nExact command to reproduce:\n\nDescribe the problem\nI then use the tflite models provided in both of these for prediction using the tflite interpeter Link I am able to make the predictions. However, the tflite predictions from the 'quant' version are very random. The float tflite model makes the correct prediction while the quantised tfite model makes very weird predictions. I even comapred the answers to normal frozen models provided and the quantized tflite model does not match the predictions at all while the float tflite makes all the predictions same as the frozen .pb model.\nI then tried the same thing with different mobilenet versions but the same observations.\nI am also making sure that I use the exact same images for both so that is not an issue just in case.\nKindly help.\nSource code / logs\nimg = np.array(PIL.Image.open(image_path).resize((224, 224))).astype(np.uint8) / 128 - 1\nimg = img.reshape(1,224,224,3)\n#print (img.shape)\n\nstart = time.time()\n\ninterpreter.set_tensor(input_details[0]['index'], img)\n\ninterpreter.invoke()\nend = time.time()\n\noutput_data = interpreter.get_tensor(output_details[0]['index'])\n#output_data_1 = interpreter.get_tensor(output_details[1]['index'])\n\n#print(output_data.argmax(),output_data.max())\nlabel_map = imagenet.create_readable_names_for_imagenet_labels()  \nprint(\"Top 1 Prediction: \", output_data.argmax(),label_map[output_data.argmax()], output_data.max(), k+1)", "body": "Hi Guys. I downloaded the Mobilenet_v1_1.0_224 and Mobilenet_v1_1.0_224_quant from the links provided in the documentation. I then use the tflite models provided in both of these for prediction using the tflite interpeter [Link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/python_api.md#using-the-interpreter-from-a-model-file-) I am able to make the predictions. However, the tflite predictions from the 'quant' version are very random. The float tflite model makes the correct prediction while the quantised tfite model makes very weird predictions. I even comapred the answers to normal frozen models provided and the quantized tflite model does not match the predictions at all while the float tflite makes all the predictions same as the frozen .pb model. \r\n\r\nI then tried the same thing with different mobilenet versions but the same observations.\r\nKindly help.\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.10 dev\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**:\r\n\r\n\r\n\r\n### Describe the problem\r\nI then use the tflite models provided in both of these for prediction using the tflite interpeter [Link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/python_api.md#using-the-interpreter-from-a-model-file-) I am able to make the predictions. However, the tflite predictions from the 'quant' version are very random. The float tflite model makes the correct prediction while the quantised tfite model makes very weird predictions. I even comapred the answers to normal frozen models provided and the quantized tflite model does not match the predictions at all while the float tflite makes all the predictions same as the frozen .pb model. \r\n\r\nI then tried the same thing with different mobilenet versions but the same observations.\r\n\r\nI am also making sure that I use the exact same images for both so that is not an issue just in case.\r\nKindly help.\r\n\r\n### Source code / logs\r\nimg = np.array(PIL.Image.open(image_path).resize((224, 224))).astype(np.uint8) / 128 - 1\r\n\r\n\timg = img.reshape(1,224,224,3)\r\n\t#print (img.shape)\r\n\t\r\n\tstart = time.time()\r\n\r\n\tinterpreter.set_tensor(input_details[0]['index'], img)\r\n\r\n\tinterpreter.invoke()\r\n\tend = time.time()\r\n\r\n\toutput_data = interpreter.get_tensor(output_details[0]['index'])\r\n\t#output_data_1 = interpreter.get_tensor(output_details[1]['index'])\r\n\r\n\t#print(output_data.argmax(),output_data.max())\r\n\tlabel_map = imagenet.create_readable_names_for_imagenet_labels()  \r\n\tprint(\"Top 1 Prediction: \", output_data.argmax(),label_map[output_data.argmax()], output_data.max(), k+1)\r\n"}