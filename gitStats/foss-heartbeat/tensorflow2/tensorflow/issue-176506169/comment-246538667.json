{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/246538667", "html_url": "https://github.com/tensorflow/tensorflow/issues/4342#issuecomment-246538667", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4342", "id": 246538667, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NjUzODY2Nw==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-13T00:36:25Z", "updated_at": "2016-09-13T00:36:25Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You can do it by using stop_gradient --<br>\n<a href=\"http://stackoverflow.com/questions/36456436/how-can-i-define-only-the-gradient-for-a-tensorflow-subgraph/36480182#36480182\" rel=\"nofollow\">http://stackoverflow.com/questions/36456436/how-can-i-define-only-the-gradient-for-a-tensorflow-subgraph/36480182#36480182</a></p>\n<p>On Mon, Sep 12, 2016 at 3:58 PM, alexatknit <a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\nwrote:</p>\n<blockquote>\n<p>This one should be pretty simple. It would be nice to have an op that acts<br>\nas the identity function in feedforward, but during backpropagation it<br>\npropagates the negative of the gradients. This is useful when joining two<br>\ndatasets as it allows for the suppression of features that distinguish<br>\nbetween domains. Its referred to as a gradient reversal layer in<br>\n<a href=\"http://arxiv.org/pdf/1505.07818v4.pdf\" rel=\"nofollow\">http://arxiv.org/pdf/1505.07818v4.pdf</a></p>\n<p>\u2014<br>\nYou are receiving this because you are subscribed to this thread.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"176506169\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4342\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4342/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4342\">#4342</a>, or mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/AABaHODc8-bx34C_YTaS3JOlNbSBK5-Mks5qpdkRgaJpZM4J7Hwx\">https://github.com/notifications/unsubscribe-auth/AABaHODc8-bx34C_YTaS3JOlNbSBK5-Mks5qpdkRgaJpZM4J7Hwx</a><br>\n.</p>\n</blockquote>", "body_text": "You can do it by using stop_gradient --\nhttp://stackoverflow.com/questions/36456436/how-can-i-define-only-the-gradient-for-a-tensorflow-subgraph/36480182#36480182\nOn Mon, Sep 12, 2016 at 3:58 PM, alexatknit notifications@github.com\nwrote:\n\nThis one should be pretty simple. It would be nice to have an op that acts\nas the identity function in feedforward, but during backpropagation it\npropagates the negative of the gradients. This is useful when joining two\ndatasets as it allows for the suppression of features that distinguish\nbetween domains. Its referred to as a gradient reversal layer in\nhttp://arxiv.org/pdf/1505.07818v4.pdf\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\n#4342, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABaHODc8-bx34C_YTaS3JOlNbSBK5-Mks5qpdkRgaJpZM4J7Hwx\n.", "body": "You can do it by using stop_gradient --\nhttp://stackoverflow.com/questions/36456436/how-can-i-define-only-the-gradient-for-a-tensorflow-subgraph/36480182#36480182\n\nOn Mon, Sep 12, 2016 at 3:58 PM, alexatknit notifications@github.com\nwrote:\n\n> This one should be pretty simple. It would be nice to have an op that acts\n> as the identity function in feedforward, but during backpropagation it\n> propagates the negative of the gradients. This is useful when joining two\n> datasets as it allows for the suppression of features that distinguish\n> between domains. Its referred to as a gradient reversal layer in\n> http://arxiv.org/pdf/1505.07818v4.pdf\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4342, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHODc8-bx34C_YTaS3JOlNbSBK5-Mks5qpdkRgaJpZM4J7Hwx\n> .\n"}