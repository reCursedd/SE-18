{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23061", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23061/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23061/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23061/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23061", "id": 371340030, "node_id": "MDU6SXNzdWUzNzEzNDAwMzA=", "number": 23061, "title": "Xla and Ignite support always true from configure.py", "user": {"login": "bjascob", "id": 22728060, "node_id": "MDQ6VXNlcjIyNzI4MDYw", "avatar_url": "https://avatars1.githubusercontent.com/u/22728060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjascob", "html_url": "https://github.com/bjascob", "followers_url": "https://api.github.com/users/bjascob/followers", "following_url": "https://api.github.com/users/bjascob/following{/other_user}", "gists_url": "https://api.github.com/users/bjascob/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjascob/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjascob/subscriptions", "organizations_url": "https://api.github.com/users/bjascob/orgs", "repos_url": "https://api.github.com/users/bjascob/repos", "events_url": "https://api.github.com/users/bjascob/events{/privacy}", "received_events_url": "https://api.github.com/users/bjascob/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097543484, "node_id": "MDU6TGFiZWwxMDk3NTQzNDg0", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:runtime", "name": "comp:runtime", "color": "0052cc", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-10-18T02:47:30Z", "updated_at": "2018-11-20T07:57:23Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>OS Platform and Distribution: Ubuntu 18.04</li>\n<li>TensorFlow installed from source</li>\n<li>TensorFlow version: 1.12.0rc-1</li>\n<li>Python version: 3.6</li>\n<li>Installed using pip3</li>\n<li>Bazel version 0.18.0</li>\n<li>GCC/Compiler version 7.3.0</li>\n<li>CUDA/cuDNN version 7.3.1</li>\n<li>GPU model and memory: GTX Titan X (Maxwell w/12GB)</li>\n<li>Have I written custom code: No</li>\n<li>Mobile device: None</li>\n<li>Exact command to reproduce: ./configure  (see below)</li>\n</ul>\n<p><strong>Describe the problem</strong><br>\nIt looks as if the configure.py script is always setting ignite and xla support true.<br>\nTo see this, run configure and answer N to the options for ignite and xla...</p>\n<pre><code>Do you wish to build TensorFlow with Apache Ignite support? [Y/n]: n\nNo Apache Ignite support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: n\nNo XLA JIT support will be enabled for TensorFlow.\n</code></pre>\n<p>Afterwards .tf_configure.bazelrc has the following lines:</p>\n<pre><code>build:ignite --define with_ignite_support=true\nbuild:xla --define with_xla_support=true\n</code></pre>\n<p><strong>Code</strong><br>\nIt looks to me like the following lines in configure.py are the issue:<br>\nUnder def set_build_var (line 368)</p>\n<pre><code>  if var == '1':\n    write_to_bazelrc('build --define %s=true' % option_name)\n  elif bazel_config_name is not None:\n    write_to_bazelrc(\n        'build:%s --define %s=true' % (bazel_config_name, option_name))\n</code></pre>\n<p>In the above, if var is 0 and there's a bazel_config_name, the option still gets set to true.  That doesn't seem like the behavior we want.</p>", "body_text": "System information\n\nOS Platform and Distribution: Ubuntu 18.04\nTensorFlow installed from source\nTensorFlow version: 1.12.0rc-1\nPython version: 3.6\nInstalled using pip3\nBazel version 0.18.0\nGCC/Compiler version 7.3.0\nCUDA/cuDNN version 7.3.1\nGPU model and memory: GTX Titan X (Maxwell w/12GB)\nHave I written custom code: No\nMobile device: None\nExact command to reproduce: ./configure  (see below)\n\nDescribe the problem\nIt looks as if the configure.py script is always setting ignite and xla support true.\nTo see this, run configure and answer N to the options for ignite and xla...\nDo you wish to build TensorFlow with Apache Ignite support? [Y/n]: n\nNo Apache Ignite support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: n\nNo XLA JIT support will be enabled for TensorFlow.\n\nAfterwards .tf_configure.bazelrc has the following lines:\nbuild:ignite --define with_ignite_support=true\nbuild:xla --define with_xla_support=true\n\nCode\nIt looks to me like the following lines in configure.py are the issue:\nUnder def set_build_var (line 368)\n  if var == '1':\n    write_to_bazelrc('build --define %s=true' % option_name)\n  elif bazel_config_name is not None:\n    write_to_bazelrc(\n        'build:%s --define %s=true' % (bazel_config_name, option_name))\n\nIn the above, if var is 0 and there's a bazel_config_name, the option still gets set to true.  That doesn't seem like the behavior we want.", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: 1.12.0rc-1\r\n- Python version: 3.6\r\n- Installed using pip3\r\n- Bazel version 0.18.0\r\n- GCC/Compiler version 7.3.0\r\n- CUDA/cuDNN version 7.3.1\r\n- GPU model and memory: GTX Titan X (Maxwell w/12GB)\r\n- Have I written custom code: No\r\n- Mobile device: None\r\n- Exact command to reproduce: ./configure  (see below)\r\n\r\n\r\n**Describe the problem**\r\nIt looks as if the configure.py script is always setting ignite and xla support true.  \r\nTo see this, run configure and answer N to the options for ignite and xla...\r\n```\r\nDo you wish to build TensorFlow with Apache Ignite support? [Y/n]: n\r\nNo Apache Ignite support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n```\r\nAfterwards .tf_configure.bazelrc has the following lines:\r\n```\r\nbuild:ignite --define with_ignite_support=true\r\nbuild:xla --define with_xla_support=true\r\n```\r\n\r\n\r\n**Code**\r\nIt looks to me like the following lines in configure.py are the issue:\r\nUnder def set_build_var (line 368)\r\n```\r\n  if var == '1':\r\n    write_to_bazelrc('build --define %s=true' % option_name)\r\n  elif bazel_config_name is not None:\r\n    write_to_bazelrc(\r\n        'build:%s --define %s=true' % (bazel_config_name, option_name))\r\n```\r\nIn the above, if var is 0 and there's a bazel_config_name, the option still gets set to true.  That doesn't seem like the behavior we want.\r\n\r\n"}