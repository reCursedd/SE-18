{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/272625221", "html_url": "https://github.com/tensorflow/tensorflow/issues/6803#issuecomment-272625221", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6803", "id": 272625221, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjYyNTIyMQ==", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-14T13:49:13Z", "updated_at": "2017-01-14T13:50:27Z", "author_association": "NONE", "body_html": "<p>In seq2seq_test.py 108-119, might be a minor bug, here should</p>\n<pre><code>maximum_length=decoder_sequence_length\n\n# currently Inference decoder\n    decoder_fn_inference = Seq2SeqTest._decoder_fn_with_context_state(\n        decoder_fn_lib.simple_decoder_fn_inference(\n            output_fn=output_fn,\n            encoder_state=encoder_state,\n            embeddings=decoder_embeddings,\n            start_of_sequence_id=start_of_sequence_id,\n            end_of_sequence_id=end_of_sequence_id,\n            #TODO: find out why it goes to +1\n            maximum_length=decoder_sequence_length - 1,\n            num_decoder_symbols=num_decoder_symbols,\n            dtype=dtypes.int32))\n</code></pre>\n<p>while in decoder_fun.py , should be<br>\ndone = control_flow_ops.cond(math_ops.equal(time, maximum_length)</p>\n<pre><code># currently decoder_fun.py line 244\ndone = control_flow_ops.cond(math_ops.greater(time, maximum_length),\n        lambda: array_ops.ones([batch_size,], dtype=dtypes.bool),\n        lambda: done)\n</code></pre>\n<p>After the change the test can pass, with decoder_sequence_length 7 equal decoder_context_state_train_res 7,  meaning last time is 7,(time is from 0 to 7)<br>\nand output shape is (7,2,20)</p>\n<pre><code>self.assertEqual(decoder_sequence_length,\n                         decoder_context_state_train_res)\n</code></pre>", "body_text": "In seq2seq_test.py 108-119, might be a minor bug, here should\nmaximum_length=decoder_sequence_length\n\n# currently Inference decoder\n    decoder_fn_inference = Seq2SeqTest._decoder_fn_with_context_state(\n        decoder_fn_lib.simple_decoder_fn_inference(\n            output_fn=output_fn,\n            encoder_state=encoder_state,\n            embeddings=decoder_embeddings,\n            start_of_sequence_id=start_of_sequence_id,\n            end_of_sequence_id=end_of_sequence_id,\n            #TODO: find out why it goes to +1\n            maximum_length=decoder_sequence_length - 1,\n            num_decoder_symbols=num_decoder_symbols,\n            dtype=dtypes.int32))\n\nwhile in decoder_fun.py , should be\ndone = control_flow_ops.cond(math_ops.equal(time, maximum_length)\n# currently decoder_fun.py line 244\ndone = control_flow_ops.cond(math_ops.greater(time, maximum_length),\n        lambda: array_ops.ones([batch_size,], dtype=dtypes.bool),\n        lambda: done)\n\nAfter the change the test can pass, with decoder_sequence_length 7 equal decoder_context_state_train_res 7,  meaning last time is 7,(time is from 0 to 7)\nand output shape is (7,2,20)\nself.assertEqual(decoder_sequence_length,\n                         decoder_context_state_train_res)", "body": "In seq2seq_test.py 108-119, might be a minor bug, here should    \r\n\r\n    maximum_length=decoder_sequence_length\r\n\r\n    # currently Inference decoder\r\n        decoder_fn_inference = Seq2SeqTest._decoder_fn_with_context_state(\r\n            decoder_fn_lib.simple_decoder_fn_inference(\r\n                output_fn=output_fn,\r\n                encoder_state=encoder_state,\r\n                embeddings=decoder_embeddings,\r\n                start_of_sequence_id=start_of_sequence_id,\r\n                end_of_sequence_id=end_of_sequence_id,\r\n                #TODO: find out why it goes to +1\r\n                maximum_length=decoder_sequence_length - 1,\r\n                num_decoder_symbols=num_decoder_symbols,\r\n                dtype=dtypes.int32))\r\n\r\nwhile in decoder_fun.py , should be\r\n    done = control_flow_ops.cond(math_ops.equal(time, maximum_length)\r\n    \r\n    # currently decoder_fun.py line 244\r\n    done = control_flow_ops.cond(math_ops.greater(time, maximum_length),\r\n            lambda: array_ops.ones([batch_size,], dtype=dtypes.bool),\r\n            lambda: done)\r\n\r\nAfter the change the test can pass, with decoder_sequence_length 7 equal decoder_context_state_train_res 7,  meaning last time is 7,(time is from 0 to 7) \r\nand output shape is (7,2,20)\r\n\r\n    self.assertEqual(decoder_sequence_length,\r\n                             decoder_context_state_train_res)"}