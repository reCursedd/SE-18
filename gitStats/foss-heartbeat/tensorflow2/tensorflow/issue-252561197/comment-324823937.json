{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/324823937", "html_url": "https://github.com/tensorflow/tensorflow/issues/12556#issuecomment-324823937", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12556", "id": 324823937, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDgyMzkzNw==", "user": {"login": "kinsumliu", "id": 8632201, "node_id": "MDQ6VXNlcjg2MzIyMDE=", "avatar_url": "https://avatars0.githubusercontent.com/u/8632201?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kinsumliu", "html_url": "https://github.com/kinsumliu", "followers_url": "https://api.github.com/users/kinsumliu/followers", "following_url": "https://api.github.com/users/kinsumliu/following{/other_user}", "gists_url": "https://api.github.com/users/kinsumliu/gists{/gist_id}", "starred_url": "https://api.github.com/users/kinsumliu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kinsumliu/subscriptions", "organizations_url": "https://api.github.com/users/kinsumliu/orgs", "repos_url": "https://api.github.com/users/kinsumliu/repos", "events_url": "https://api.github.com/users/kinsumliu/events{/privacy}", "received_events_url": "https://api.github.com/users/kinsumliu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-25T04:56:31Z", "updated_at": "2017-08-25T04:56:31Z", "author_association": "NONE", "body_html": "<p>I don't have a definite answer yet. I suspect that there is some problem with the data feeding mechanism in your code which will cause this error. You mention that it runs fine if you disable them. Have you checked that the data really goes in and some meaningful training is done?</p>\n<p>Here is my suggestion:</p>\n<ol>\n<li>\n<p>MonitoredTrainingSession should create a Coordinator which start the queue runners. tf.train.start_queue_runners(sess=sess) looks duplicate to me and if you start the queue runners twice, I am not sure what will happen. Refer to <a href=\"https://stackoverflow.com/questions/43245231/how-do-monitored-training-sessions-work\" rel=\"nofollow\">this</a> for what MonitoredTrainingSession can do</p>\n</li>\n<li>\n<p>You can define the size for the placeholder. But as I understand it, it should not be the problem. No harm in trying :)</p>\n</li>\n<li>\n<p>I dont know what these are doing:</p>\n</li>\n</ol>\n<pre><code>with tf.device(\"/job:ps/task:0/cpu:0\"):\n                f = open(FLAGS.log_dir + \"accuracy_\" + str(learning_rate) +\n                        \"_with_\" + str(number_of_h_layer) + \"layers\", \"w+\")\n                print(\"loading data to queue....\")\n</code></pre>\n<p>If you want to log accuracy, the worker (not ps) should log accuracy since the worker is doing the training.</p>\n<ol start=\"4\">\n<li>Have you tried the non-distributed version of your code, does it work?</li>\n</ol>", "body_text": "I don't have a definite answer yet. I suspect that there is some problem with the data feeding mechanism in your code which will cause this error. You mention that it runs fine if you disable them. Have you checked that the data really goes in and some meaningful training is done?\nHere is my suggestion:\n\n\nMonitoredTrainingSession should create a Coordinator which start the queue runners. tf.train.start_queue_runners(sess=sess) looks duplicate to me and if you start the queue runners twice, I am not sure what will happen. Refer to this for what MonitoredTrainingSession can do\n\n\nYou can define the size for the placeholder. But as I understand it, it should not be the problem. No harm in trying :)\n\n\nI dont know what these are doing:\n\n\nwith tf.device(\"/job:ps/task:0/cpu:0\"):\n                f = open(FLAGS.log_dir + \"accuracy_\" + str(learning_rate) +\n                        \"_with_\" + str(number_of_h_layer) + \"layers\", \"w+\")\n                print(\"loading data to queue....\")\n\nIf you want to log accuracy, the worker (not ps) should log accuracy since the worker is doing the training.\n\nHave you tried the non-distributed version of your code, does it work?", "body": "I don't have a definite answer yet. I suspect that there is some problem with the data feeding mechanism in your code which will cause this error. You mention that it runs fine if you disable them. Have you checked that the data really goes in and some meaningful training is done?\r\n\r\nHere is my suggestion:\r\n\r\n1. MonitoredTrainingSession should create a Coordinator which start the queue runners. tf.train.start_queue_runners(sess=sess) looks duplicate to me and if you start the queue runners twice, I am not sure what will happen. Refer to [this](https://stackoverflow.com/questions/43245231/how-do-monitored-training-sessions-work) for what MonitoredTrainingSession can do\r\n\r\n2. You can define the size for the placeholder. But as I understand it, it should not be the problem. No harm in trying :)\r\n\r\n3. I dont know what these are doing:\r\n```\r\nwith tf.device(\"/job:ps/task:0/cpu:0\"):\r\n                f = open(FLAGS.log_dir + \"accuracy_\" + str(learning_rate) +\r\n                        \"_with_\" + str(number_of_h_layer) + \"layers\", \"w+\")\r\n                print(\"loading data to queue....\")\r\n```\r\nIf you want to log accuracy, the worker (not ps) should log accuracy since the worker is doing the training.\r\n\r\n4. Have you tried the non-distributed version of your code, does it work?"}