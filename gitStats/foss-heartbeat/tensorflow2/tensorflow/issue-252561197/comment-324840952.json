{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/324840952", "html_url": "https://github.com/tensorflow/tensorflow/issues/12556#issuecomment-324840952", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12556", "id": 324840952, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDg0MDk1Mg==", "user": {"login": "luvwinnie", "id": 13714992, "node_id": "MDQ6VXNlcjEzNzE0OTky", "avatar_url": "https://avatars1.githubusercontent.com/u/13714992?v=4", "gravatar_id": "", "url": "https://api.github.com/users/luvwinnie", "html_url": "https://github.com/luvwinnie", "followers_url": "https://api.github.com/users/luvwinnie/followers", "following_url": "https://api.github.com/users/luvwinnie/following{/other_user}", "gists_url": "https://api.github.com/users/luvwinnie/gists{/gist_id}", "starred_url": "https://api.github.com/users/luvwinnie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/luvwinnie/subscriptions", "organizations_url": "https://api.github.com/users/luvwinnie/orgs", "repos_url": "https://api.github.com/users/luvwinnie/repos", "events_url": "https://api.github.com/users/luvwinnie/events{/privacy}", "received_events_url": "https://api.github.com/users/luvwinnie/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-25T07:07:13Z", "updated_at": "2017-08-25T07:10:24Z", "author_association": "NONE", "body_html": "<p>However with the graph I build for training.</p>\n<pre>with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:%d\" %FLAGS.task_index,cluster=cluster)):\n        is_chief = (FLAGS.task_index == 0)\n        global_step = tf.get_variable('global_step',[],initializer=tf.constant_initializer(0),dtype=tf.int32)\n        x = tf.placeholder(tf.float32,shape=[None,num_input],name=\"mfcc_input\")\n        y = tf.placeholder(tf.int32,shape=[None,num_classes],name=\"labels\")\n        # is_training = tf.placeholder(dtype=bool, shape=(), name=\"is_training\")\n        # q_selector = tf.cond(is_training,lambda:[train_mfcc_batch,train_labels_batch],lambda:[test_mfcc_batch,test_labels_batch])\n\n        h = []\n        h.append(hidden_layer(x,num_input,h_layer_units))\n        for i in range(number_of_h_layer):\n            h.append(hidden_layer(h[i],h_layer_units,h_layer_units))\n\n        output = fully_connected_layer(h[number_of_h_layer],h_layer_units,num_classes)\n        saver = tf.train.Saver()\n\n        with tf.name_scope(\"x-entropy\"):\n            xent = tf.reduce_mean(\n            tf.nn.softmax_cross_entropy_with_logits(\n                    logits=output, labels=y), name=\"x-entropy\")\n\n        with tf.name_scope(\"train\"):\n            grad_op = tf.train.AdamOptimizer(learning_rate)\n            rep_op = tf.train.SyncReplicasOptimizer(grad_op,\n                                                    replicas_to_aggregate=len(workers),\n                                                    total_num_replicas=len(workers))\n            train_op = rep_op.minimize(xent,global_step=global_step)\n            sync_replicas_hook = rep_op.make_session_run_hook(is_chief)\n            \n        init_token_op = rep_op.get_init_tokens_op()\n        chief_queue_runner = rep_op.get_chief_queue_runner()\n        with tf.name_scope(\"accuracy\"):\n            correct_prediction = tf.equal(tf.argmax(output,1),tf.argmax(y,1))\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n\n        tf.summary.scalar(\"x-entropy\", xent)\n        tf.summary.scalar(\"accuracy\",accuracy)\n        \n        summary_op = tf.summary.merge_all()\n        global_init_op = tf.global_variables_initializer()\n        local_init_op = tf.local_variables_initializer()</pre>\n<p>It still shows the following error<br>\n<code>2017-08-25 16:04:20.162666: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,13] has negative dimensions 2017-08-25 16:04:20.162748: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,13] has negative dimensions [[Node: mfcc_input = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]] 2017-08-25 16:04:20.163809: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,13] has negative dimensions 2017-08-25 16:04:20.163855: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,13] has negative dimensions [[Node: mfcc_input = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]] 2017-08-25 16:04:20.165598: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,3] has negative dimensions 2017-08-25 16:04:20.165643: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,3] has negative dimensions [[Node: labels = Placeholder[dtype=DT_INT32, shape=[?,3], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]]</code></p>\n<p>which I asked at the 1st comment.<br>\nIt's shows the placeholder with [None,num_input] make's the error comes up again.<br>\nWasn't the placeholder with [None] value should handle the arbitrary shape of the input?<br>\nHow come it be [-1] dimension while training.</p>", "body_text": "However with the graph I build for training.\nwith tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:%d\" %FLAGS.task_index,cluster=cluster)):\n        is_chief = (FLAGS.task_index == 0)\n        global_step = tf.get_variable('global_step',[],initializer=tf.constant_initializer(0),dtype=tf.int32)\n        x = tf.placeholder(tf.float32,shape=[None,num_input],name=\"mfcc_input\")\n        y = tf.placeholder(tf.int32,shape=[None,num_classes],name=\"labels\")\n        # is_training = tf.placeholder(dtype=bool, shape=(), name=\"is_training\")\n        # q_selector = tf.cond(is_training,lambda:[train_mfcc_batch,train_labels_batch],lambda:[test_mfcc_batch,test_labels_batch])\n\n        h = []\n        h.append(hidden_layer(x,num_input,h_layer_units))\n        for i in range(number_of_h_layer):\n            h.append(hidden_layer(h[i],h_layer_units,h_layer_units))\n\n        output = fully_connected_layer(h[number_of_h_layer],h_layer_units,num_classes)\n        saver = tf.train.Saver()\n\n        with tf.name_scope(\"x-entropy\"):\n            xent = tf.reduce_mean(\n            tf.nn.softmax_cross_entropy_with_logits(\n                    logits=output, labels=y), name=\"x-entropy\")\n\n        with tf.name_scope(\"train\"):\n            grad_op = tf.train.AdamOptimizer(learning_rate)\n            rep_op = tf.train.SyncReplicasOptimizer(grad_op,\n                                                    replicas_to_aggregate=len(workers),\n                                                    total_num_replicas=len(workers))\n            train_op = rep_op.minimize(xent,global_step=global_step)\n            sync_replicas_hook = rep_op.make_session_run_hook(is_chief)\n            \n        init_token_op = rep_op.get_init_tokens_op()\n        chief_queue_runner = rep_op.get_chief_queue_runner()\n        with tf.name_scope(\"accuracy\"):\n            correct_prediction = tf.equal(tf.argmax(output,1),tf.argmax(y,1))\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n\n        tf.summary.scalar(\"x-entropy\", xent)\n        tf.summary.scalar(\"accuracy\",accuracy)\n        \n        summary_op = tf.summary.merge_all()\n        global_init_op = tf.global_variables_initializer()\n        local_init_op = tf.local_variables_initializer()\nIt still shows the following error\n2017-08-25 16:04:20.162666: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,13] has negative dimensions 2017-08-25 16:04:20.162748: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,13] has negative dimensions [[Node: mfcc_input = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]] 2017-08-25 16:04:20.163809: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,13] has negative dimensions 2017-08-25 16:04:20.163855: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,13] has negative dimensions [[Node: mfcc_input = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]] 2017-08-25 16:04:20.165598: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,3] has negative dimensions 2017-08-25 16:04:20.165643: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,3] has negative dimensions [[Node: labels = Placeholder[dtype=DT_INT32, shape=[?,3], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]]\nwhich I asked at the 1st comment.\nIt's shows the placeholder with [None,num_input] make's the error comes up again.\nWasn't the placeholder with [None] value should handle the arbitrary shape of the input?\nHow come it be [-1] dimension while training.", "body": "However with the graph I build for training.\r\n\r\n<pre>with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:%d\" %FLAGS.task_index,cluster=cluster)):\r\n        is_chief = (FLAGS.task_index == 0)\r\n        global_step = tf.get_variable('global_step',[],initializer=tf.constant_initializer(0),dtype=tf.int32)\r\n        x = tf.placeholder(tf.float32,shape=[None,num_input],name=\"mfcc_input\")\r\n        y = tf.placeholder(tf.int32,shape=[None,num_classes],name=\"labels\")\r\n        # is_training = tf.placeholder(dtype=bool, shape=(), name=\"is_training\")\r\n        # q_selector = tf.cond(is_training,lambda:[train_mfcc_batch,train_labels_batch],lambda:[test_mfcc_batch,test_labels_batch])\r\n\r\n        h = []\r\n        h.append(hidden_layer(x,num_input,h_layer_units))\r\n        for i in range(number_of_h_layer):\r\n            h.append(hidden_layer(h[i],h_layer_units,h_layer_units))\r\n\r\n        output = fully_connected_layer(h[number_of_h_layer],h_layer_units,num_classes)\r\n        saver = tf.train.Saver()\r\n\r\n        with tf.name_scope(\"x-entropy\"):\r\n            xent = tf.reduce_mean(\r\n            tf.nn.softmax_cross_entropy_with_logits(\r\n                    logits=output, labels=y), name=\"x-entropy\")\r\n\r\n        with tf.name_scope(\"train\"):\r\n            grad_op = tf.train.AdamOptimizer(learning_rate)\r\n            rep_op = tf.train.SyncReplicasOptimizer(grad_op,\r\n                                                    replicas_to_aggregate=len(workers),\r\n                                                    total_num_replicas=len(workers))\r\n            train_op = rep_op.minimize(xent,global_step=global_step)\r\n            sync_replicas_hook = rep_op.make_session_run_hook(is_chief)\r\n            \r\n        init_token_op = rep_op.get_init_tokens_op()\r\n        chief_queue_runner = rep_op.get_chief_queue_runner()\r\n        with tf.name_scope(\"accuracy\"):\r\n            correct_prediction = tf.equal(tf.argmax(output,1),tf.argmax(y,1))\r\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\r\n\r\n        tf.summary.scalar(\"x-entropy\", xent)\r\n        tf.summary.scalar(\"accuracy\",accuracy)\r\n        \r\n        summary_op = tf.summary.merge_all()\r\n        global_init_op = tf.global_variables_initializer()\r\n        local_init_op = tf.local_variables_initializer()</pre>\r\n\r\nIt still shows the following error \r\n`2017-08-25 16:04:20.162666: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,13] has negative dimensions\r\n2017-08-25 16:04:20.162748: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,13] has negative dimensions\r\n         [[Node: mfcc_input = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]]\r\n2017-08-25 16:04:20.163809: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,13] has negative dimensions\r\n2017-08-25 16:04:20.163855: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,13] has negative dimensions\r\n         [[Node: mfcc_input = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]]\r\n2017-08-25 16:04:20.165598: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,3] has negative dimensions\r\n2017-08-25 16:04:20.165643: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,3] has negative dimensions\r\n         [[Node: labels = Placeholder[dtype=DT_INT32, shape=[?,3], _device=\"/job:worker/replica:0/task:0/gpu:0\"]()]]`\r\n\r\nwhich I asked at the 1st comment.\r\nIt's shows the placeholder with [None,num_input] make's the error comes up again.\r\nWasn't the placeholder with [None] value should handle the arbitrary shape of the input?\r\nHow come it be [-1] dimension while training."}