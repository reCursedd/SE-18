{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/438197767", "html_url": "https://github.com/tensorflow/tensorflow/issues/22005#issuecomment-438197767", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22005", "id": 438197767, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODE5Nzc2Nw==", "user": {"login": "wwlaoxi", "id": 30012162, "node_id": "MDQ6VXNlcjMwMDEyMTYy", "avatar_url": "https://avatars3.githubusercontent.com/u/30012162?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wwlaoxi", "html_url": "https://github.com/wwlaoxi", "followers_url": "https://api.github.com/users/wwlaoxi/followers", "following_url": "https://api.github.com/users/wwlaoxi/following{/other_user}", "gists_url": "https://api.github.com/users/wwlaoxi/gists{/gist_id}", "starred_url": "https://api.github.com/users/wwlaoxi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wwlaoxi/subscriptions", "organizations_url": "https://api.github.com/users/wwlaoxi/orgs", "repos_url": "https://api.github.com/users/wwlaoxi/repos", "events_url": "https://api.github.com/users/wwlaoxi/events{/privacy}", "received_events_url": "https://api.github.com/users/wwlaoxi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-13T09:31:38Z", "updated_at": "2018-11-13T09:31:38Z", "author_association": "NONE", "body_html": "<blockquote>\n<blockquote>\n<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4759327\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dhingratul\">@dhingratul</a> in the end, it worked for me by adding required dependencies to the libtensorflow_cc.so target (as per Stackoverflow) but <em>not</em> compiling monolithically. I also do not need to use the TF_LoadLibrary. Then, I do not get this Duplicate Registration thing and can run the graph. Still, feels like an ugly hack since TensorRT should really be included as an op/kernel if you set TensorRT support to true.</p>\n</blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16327442\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fferroni\">@fferroni</a> I tried this, it doesn't work with r1.11</p>\n</blockquote>\n<p>I used TF 1.10.1, I have not tried with 1.11 yet, but these are the diffs that worked for me:</p>\n<pre><code>diff --git a/tensorflow/BUILD b/tensorflow/BUILD\nindex 518c2b0..154cfc3 100644\n--- a/tensorflow/BUILD\n+++ b/tensorflow/BUILD\n@@ -568,6 +568,8 @@ tf_cc_shared_object(\n         \"//tensorflow/cc:scope\",\n         \"//tensorflow/cc/profiler\",\n         \"//tensorflow/core:tensorflow\",\n+       \"//tensorflow/contrib/tensorrt:trt_conversion\",\n+        \"//tensorflow/contrib/tensorrt:trt_engine_op_kernel\",\n     ],\n )\n \ndiff --git a/tensorflow/contrib/tensorrt/BUILD b/tensorflow/contrib/tensorrt/BUILD\nindex 70ce4a4..14ce991 100644\n--- a/tensorflow/contrib/tensorrt/BUILD\n+++ b/tensorflow/contrib/tensorrt/BUILD\n@@ -73,6 +73,7 @@ cc_library(\n     name = \"trt_engine_op_kernel\",\n     srcs = [\n         \"kernels/trt_engine_op.cc\",\n+       \"ops/trt_engine_op.cc\",\n     ],\n     hdrs = [\n         \"kernels/trt_engine_op.h\",\n</code></pre>\n<p>I used Bazel 0.15.1. Also, do not add the monolithic argument to the build command as you will get the double registration problem.<br>\nIn terms of inference time, I observe a significant speedup.</p>\n</blockquote>\n<p>I used Bazel 0.16.1,TensorRT 4.0.1.6,tensorflow 1.10.1. I modify tensorflow/BUILD and /tensorflow/contrib/tensorrt/BUILD.<br>\nI used bazel command:<br>\nbazel build --config=opt --config=cuda //tensorflow:libtensorflow_cc.so</p>\n<p>Trying to run the graph in c++ fails with the following error\uff1a<br>\nthe error \"Not found: Op type not registered 'TRTEngineOp'\"</p>\n<p>can you help me ?<br>\nThanks.</p>", "body_text": "@dhingratul in the end, it worked for me by adding required dependencies to the libtensorflow_cc.so target (as per Stackoverflow) but not compiling monolithically. I also do not need to use the TF_LoadLibrary. Then, I do not get this Duplicate Registration thing and can run the graph. Still, feels like an ugly hack since TensorRT should really be included as an op/kernel if you set TensorRT support to true.\n\n@fferroni I tried this, it doesn't work with r1.11\n\nI used TF 1.10.1, I have not tried with 1.11 yet, but these are the diffs that worked for me:\ndiff --git a/tensorflow/BUILD b/tensorflow/BUILD\nindex 518c2b0..154cfc3 100644\n--- a/tensorflow/BUILD\n+++ b/tensorflow/BUILD\n@@ -568,6 +568,8 @@ tf_cc_shared_object(\n         \"//tensorflow/cc:scope\",\n         \"//tensorflow/cc/profiler\",\n         \"//tensorflow/core:tensorflow\",\n+       \"//tensorflow/contrib/tensorrt:trt_conversion\",\n+        \"//tensorflow/contrib/tensorrt:trt_engine_op_kernel\",\n     ],\n )\n \ndiff --git a/tensorflow/contrib/tensorrt/BUILD b/tensorflow/contrib/tensorrt/BUILD\nindex 70ce4a4..14ce991 100644\n--- a/tensorflow/contrib/tensorrt/BUILD\n+++ b/tensorflow/contrib/tensorrt/BUILD\n@@ -73,6 +73,7 @@ cc_library(\n     name = \"trt_engine_op_kernel\",\n     srcs = [\n         \"kernels/trt_engine_op.cc\",\n+       \"ops/trt_engine_op.cc\",\n     ],\n     hdrs = [\n         \"kernels/trt_engine_op.h\",\n\nI used Bazel 0.15.1. Also, do not add the monolithic argument to the build command as you will get the double registration problem.\nIn terms of inference time, I observe a significant speedup.\n\nI used Bazel 0.16.1,TensorRT 4.0.1.6,tensorflow 1.10.1. I modify tensorflow/BUILD and /tensorflow/contrib/tensorrt/BUILD.\nI used bazel command:\nbazel build --config=opt --config=cuda //tensorflow:libtensorflow_cc.so\nTrying to run the graph in c++ fails with the following error\uff1a\nthe error \"Not found: Op type not registered 'TRTEngineOp'\"\ncan you help me ?\nThanks.", "body": "> > > @dhingratul in the end, it worked for me by adding required dependencies to the libtensorflow_cc.so target (as per Stackoverflow) but _not_ compiling monolithically. I also do not need to use the TF_LoadLibrary. Then, I do not get this Duplicate Registration thing and can run the graph. Still, feels like an ugly hack since TensorRT should really be included as an op/kernel if you set TensorRT support to true.\r\n> > \r\n> > \r\n> > @fferroni I tried this, it doesn't work with r1.11\r\n> \r\n> I used TF 1.10.1, I have not tried with 1.11 yet, but these are the diffs that worked for me:\r\n> \r\n> ```\r\n> diff --git a/tensorflow/BUILD b/tensorflow/BUILD\r\n> index 518c2b0..154cfc3 100644\r\n> --- a/tensorflow/BUILD\r\n> +++ b/tensorflow/BUILD\r\n> @@ -568,6 +568,8 @@ tf_cc_shared_object(\r\n>          \"//tensorflow/cc:scope\",\r\n>          \"//tensorflow/cc/profiler\",\r\n>          \"//tensorflow/core:tensorflow\",\r\n> +       \"//tensorflow/contrib/tensorrt:trt_conversion\",\r\n> +        \"//tensorflow/contrib/tensorrt:trt_engine_op_kernel\",\r\n>      ],\r\n>  )\r\n>  \r\n> diff --git a/tensorflow/contrib/tensorrt/BUILD b/tensorflow/contrib/tensorrt/BUILD\r\n> index 70ce4a4..14ce991 100644\r\n> --- a/tensorflow/contrib/tensorrt/BUILD\r\n> +++ b/tensorflow/contrib/tensorrt/BUILD\r\n> @@ -73,6 +73,7 @@ cc_library(\r\n>      name = \"trt_engine_op_kernel\",\r\n>      srcs = [\r\n>          \"kernels/trt_engine_op.cc\",\r\n> +       \"ops/trt_engine_op.cc\",\r\n>      ],\r\n>      hdrs = [\r\n>          \"kernels/trt_engine_op.h\",\r\n> ```\r\n> \r\n> I used Bazel 0.15.1. Also, do not add the monolithic argument to the build command as you will get the double registration problem.\r\n> In terms of inference time, I observe a significant speedup.\r\n\r\nI used Bazel 0.16.1,TensorRT 4.0.1.6,tensorflow 1.10.1. I modify tensorflow/BUILD and /tensorflow/contrib/tensorrt/BUILD.  \r\nI used bazel command:\r\nbazel build --config=opt --config=cuda //tensorflow:libtensorflow_cc.so\r\n\r\nTrying to run the graph in c++ fails with the following error\uff1a\r\n the error \"Not found: Op type not registered 'TRTEngineOp'\"\r\n\r\ncan you help me ?\r\nThanks."}