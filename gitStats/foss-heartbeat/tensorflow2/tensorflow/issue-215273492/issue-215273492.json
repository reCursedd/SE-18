{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8536", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8536/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8536/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8536/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8536", "id": 215273492, "node_id": "MDU6SXNzdWUyMTUyNzM0OTI=", "number": 8536, "title": "pool allocator spending more than 18h to allocate and still not finished", "user": {"login": "kirk86", "id": 2902390, "node_id": "MDQ6VXNlcjI5MDIzOTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2902390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kirk86", "html_url": "https://github.com/kirk86", "followers_url": "https://api.github.com/users/kirk86/followers", "following_url": "https://api.github.com/users/kirk86/following{/other_user}", "gists_url": "https://api.github.com/users/kirk86/gists{/gist_id}", "starred_url": "https://api.github.com/users/kirk86/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kirk86/subscriptions", "organizations_url": "https://api.github.com/users/kirk86/orgs", "repos_url": "https://api.github.com/users/kirk86/repos", "events_url": "https://api.github.com/users/kirk86/events{/privacy}", "received_events_url": "https://api.github.com/users/kirk86/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-03-19T15:59:19Z", "updated_at": "2017-09-08T04:55:26Z", "closed_at": "2017-09-08T04:55:26Z", "author_association": "NONE", "body_html": "<p>Hey guys, I've been having this issue which I don't really understand if it's related to memory issues or not. I've tested it on cpu and the code runs fine without any issues. On gpu I get the following messages:</p>\n<pre><code>2017-03-18 14:21:51,379 INFO - I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\n2017-03-18 14:21:51,379 INFO - name: Tesla K80\n2017-03-18 14:21:51,379 INFO - major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n2017-03-18 14:21:51,380 INFO - pciBusID 0000:00:1e.0\n2017-03-18 14:21:51,380 INFO - Total memory: 11.17GiB\n2017-03-18 14:21:51,380 INFO - Free memory: 11.11GiB\n2017-03-18 14:21:51,381 INFO -  DMA: 0\n2017-03-18 14:21:51,381 INFO -  Y\n2017-03-18 14:21:51,394 INFO - Creating TensorFlow device (/gpu:0) -&gt; \n(device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0) 2017-03-18 14:22:06,005\nPoolAllocator: After 2898 get requests, put_count=2334 evicted_count=1000 \neviction_rate=0.428449 and unsatisfied allocation rate=0.574189\n2017-03-18 14:22:06,025 INFO - Raising pool_size_limit_ from 100 to 110\n2017-03-18 14:48:17,797 INFO -  PoolAllocator: After 2898 get requests, put_count=3604\n evicted_count=2000 eviction_rate=0.554939 and unsatisfied allocation rate=0.452381\n2017-03-18 14:48:17,800 INFO - Raising pool_size_limit_ from 193 to 212\n2017-03-18 15:30:38,803 INFO - PoolAllocator: After 2898 get requests, put_count=2881 \nevicted_count=1000 eviction_rate=0.347102 and unsatisfied allocation rate=0.364734\n2017-03-18 15:30:38,806 INFO - Raising pool_size_limit_ from 449 to 493\n2017-03-18 16:46:39,551 INFO - PoolAllocator: After 8694 get requests, put_count=8682 \nevicted_count=1000 eviction_rate=0.115181 and unsatisfied allocation rate=0.128479\n2017-03-18 16:46:39,554 INFO - Raising pool_size_limit_ from 1158 to 1273\n</code></pre>\n<p>It's been like this for 18h and still no output or training has started, is this a known issue. Why does it take so long for the memory allocator to finish?</p>", "body_text": "Hey guys, I've been having this issue which I don't really understand if it's related to memory issues or not. I've tested it on cpu and the code runs fine without any issues. On gpu I get the following messages:\n2017-03-18 14:21:51,379 INFO - I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\n2017-03-18 14:21:51,379 INFO - name: Tesla K80\n2017-03-18 14:21:51,379 INFO - major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n2017-03-18 14:21:51,380 INFO - pciBusID 0000:00:1e.0\n2017-03-18 14:21:51,380 INFO - Total memory: 11.17GiB\n2017-03-18 14:21:51,380 INFO - Free memory: 11.11GiB\n2017-03-18 14:21:51,381 INFO -  DMA: 0\n2017-03-18 14:21:51,381 INFO -  Y\n2017-03-18 14:21:51,394 INFO - Creating TensorFlow device (/gpu:0) -> \n(device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0) 2017-03-18 14:22:06,005\nPoolAllocator: After 2898 get requests, put_count=2334 evicted_count=1000 \neviction_rate=0.428449 and unsatisfied allocation rate=0.574189\n2017-03-18 14:22:06,025 INFO - Raising pool_size_limit_ from 100 to 110\n2017-03-18 14:48:17,797 INFO -  PoolAllocator: After 2898 get requests, put_count=3604\n evicted_count=2000 eviction_rate=0.554939 and unsatisfied allocation rate=0.452381\n2017-03-18 14:48:17,800 INFO - Raising pool_size_limit_ from 193 to 212\n2017-03-18 15:30:38,803 INFO - PoolAllocator: After 2898 get requests, put_count=2881 \nevicted_count=1000 eviction_rate=0.347102 and unsatisfied allocation rate=0.364734\n2017-03-18 15:30:38,806 INFO - Raising pool_size_limit_ from 449 to 493\n2017-03-18 16:46:39,551 INFO - PoolAllocator: After 8694 get requests, put_count=8682 \nevicted_count=1000 eviction_rate=0.115181 and unsatisfied allocation rate=0.128479\n2017-03-18 16:46:39,554 INFO - Raising pool_size_limit_ from 1158 to 1273\n\nIt's been like this for 18h and still no output or training has started, is this a known issue. Why does it take so long for the memory allocator to finish?", "body": "Hey guys, I've been having this issue which I don't really understand if it's related to memory issues or not. I've tested it on cpu and the code runs fine without any issues. On gpu I get the following messages:\r\n\r\n```\r\n2017-03-18 14:21:51,379 INFO - I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\r\n2017-03-18 14:21:51,379 INFO - name: Tesla K80\r\n2017-03-18 14:21:51,379 INFO - major: 3 minor: 7 memoryClockRate (GHz) 0.8235\r\n2017-03-18 14:21:51,380 INFO - pciBusID 0000:00:1e.0\r\n2017-03-18 14:21:51,380 INFO - Total memory: 11.17GiB\r\n2017-03-18 14:21:51,380 INFO - Free memory: 11.11GiB\r\n2017-03-18 14:21:51,381 INFO -  DMA: 0\r\n2017-03-18 14:21:51,381 INFO -  Y\r\n2017-03-18 14:21:51,394 INFO - Creating TensorFlow device (/gpu:0) -> \r\n(device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0) 2017-03-18 14:22:06,005\r\nPoolAllocator: After 2898 get requests, put_count=2334 evicted_count=1000 \r\neviction_rate=0.428449 and unsatisfied allocation rate=0.574189\r\n2017-03-18 14:22:06,025 INFO - Raising pool_size_limit_ from 100 to 110\r\n2017-03-18 14:48:17,797 INFO -  PoolAllocator: After 2898 get requests, put_count=3604\r\n evicted_count=2000 eviction_rate=0.554939 and unsatisfied allocation rate=0.452381\r\n2017-03-18 14:48:17,800 INFO - Raising pool_size_limit_ from 193 to 212\r\n2017-03-18 15:30:38,803 INFO - PoolAllocator: After 2898 get requests, put_count=2881 \r\nevicted_count=1000 eviction_rate=0.347102 and unsatisfied allocation rate=0.364734\r\n2017-03-18 15:30:38,806 INFO - Raising pool_size_limit_ from 449 to 493\r\n2017-03-18 16:46:39,551 INFO - PoolAllocator: After 8694 get requests, put_count=8682 \r\nevicted_count=1000 eviction_rate=0.115181 and unsatisfied allocation rate=0.128479\r\n2017-03-18 16:46:39,554 INFO - Raising pool_size_limit_ from 1158 to 1273\r\n```\r\nIt's been like this for 18h and still no output or training has started, is this a known issue. Why does it take so long for the memory allocator to finish?"}