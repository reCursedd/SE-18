{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/273211965", "html_url": "https://github.com/tensorflow/tensorflow/issues/3056#issuecomment-273211965", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3056", "id": 273211965, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MzIxMTk2NQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-17T16:02:42Z", "updated_at": "2017-01-17T16:02:42Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">That's right, a tuple may contain multiple tensors, each of which may have\ndifferent shapes.  Thus you must call .get_shape() on whichever tensor you\ncare about.  You can use encoder_state[0][0].get_shape() which is\nequivalent to encoder_state[0].c.get_shape().\n\nWe may add a get_shape() or shape property to LSTMStateTuple, feel free to\nopen a new issue for that.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Tue, Jan 17, 2017 at 3:29 AM, Chirag Jain ***@***.***&gt; wrote:\n import tensorflow as tf\n from tensorflow.python.ops import rnn\n from tensorflow.python.ops import rnn_cell\n\n batch_size = 100\n size = 20\n num_encoder_symbols = 30\n embedding_size = 64\n state_is_tuple = True\n num_layers = 3\n encoder_inputs = [tf.zeros([32],dtype=tf.int32) for _ in range(batch_size)]\n single_cell = tf.nn.rnn_cell.BasicLSTMCell(size, state_is_tuple=state_is_tuple) # Or GRU\n cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\n encoder_cell = rnn_cell.EmbeddingWrapper(cell, embedding_classes=num_encoder_symbols, embedding_size=embedding_size)\n _, encoder_state = rnn.rnn(encoder_cell, encoder_inputs, dtype=tf.float32)\n encoder_state[0].get_shape()\n\n encoder_state is a tuple of LSTMStateTuple of size num_layers\n\n Calling encoder_state[0].get_shape() fails with 'LSTMStateTuple' object\n has no attribute 'get_shape'\n\n For now encoder_state[0].c.get_shape() , encoder_state[0].h.get_shape()\n is the only way I know to work around this\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"162358870\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3056\" href=\"https://github.com/tensorflow/tensorflow/issues/3056#issuecomment-273114865\">#3056 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtimzmQ6V1B0vTmTYTUVTBZDw2qIGK4ks5rTKYVgaJpZM4I-sU0\">https://github.com/notifications/unsubscribe-auth/ABtimzmQ6V1B0vTmTYTUVTBZDw2qIGK4ks5rTKYVgaJpZM4I-sU0</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "That's right, a tuple may contain multiple tensors, each of which may have\ndifferent shapes.  Thus you must call .get_shape() on whichever tensor you\ncare about.  You can use encoder_state[0][0].get_shape() which is\nequivalent to encoder_state[0].c.get_shape().\n\nWe may add a get_shape() or shape property to LSTMStateTuple, feel free to\nopen a new issue for that.\n\u2026\nOn Tue, Jan 17, 2017 at 3:29 AM, Chirag Jain ***@***.***> wrote:\n import tensorflow as tf\n from tensorflow.python.ops import rnn\n from tensorflow.python.ops import rnn_cell\n\n batch_size = 100\n size = 20\n num_encoder_symbols = 30\n embedding_size = 64\n state_is_tuple = True\n num_layers = 3\n encoder_inputs = [tf.zeros([32],dtype=tf.int32) for _ in range(batch_size)]\n single_cell = tf.nn.rnn_cell.BasicLSTMCell(size, state_is_tuple=state_is_tuple) # Or GRU\n cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\n encoder_cell = rnn_cell.EmbeddingWrapper(cell, embedding_classes=num_encoder_symbols, embedding_size=embedding_size)\n _, encoder_state = rnn.rnn(encoder_cell, encoder_inputs, dtype=tf.float32)\n encoder_state[0].get_shape()\n\n encoder_state is a tuple of LSTMStateTuple of size num_layers\n\n Calling encoder_state[0].get_shape() fails with 'LSTMStateTuple' object\n has no attribute 'get_shape'\n\n For now encoder_state[0].c.get_shape() , encoder_state[0].h.get_shape()\n is the only way I know to work around this\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#3056 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtimzmQ6V1B0vTmTYTUVTBZDw2qIGK4ks5rTKYVgaJpZM4I-sU0>\n .", "body": "That's right, a tuple may contain multiple tensors, each of which may have\ndifferent shapes.  Thus you must call .get_shape() on whichever tensor you\ncare about.  You can use encoder_state[0][0].get_shape() which is\nequivalent to encoder_state[0].c.get_shape().\n\nWe may add a get_shape() or shape property to LSTMStateTuple, feel free to\nopen a new issue for that.\n\nOn Tue, Jan 17, 2017 at 3:29 AM, Chirag Jain <notifications@github.com>\nwrote:\n\n> import tensorflow as tf\n> from tensorflow.python.ops import rnn\n> from tensorflow.python.ops import rnn_cell\n>\n> batch_size = 100\n> size = 20\n> num_encoder_symbols = 30\n> embedding_size = 64\n> state_is_tuple = True\n> num_layers = 3\n> encoder_inputs = [tf.zeros([32],dtype=tf.int32) for _ in range(batch_size)]\n> single_cell = tf.nn.rnn_cell.BasicLSTMCell(size, state_is_tuple=state_is_tuple) # Or GRU\n> cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\n> encoder_cell = rnn_cell.EmbeddingWrapper(cell, embedding_classes=num_encoder_symbols, embedding_size=embedding_size)\n> _, encoder_state = rnn.rnn(encoder_cell, encoder_inputs, dtype=tf.float32)\n> encoder_state[0].get_shape()\n>\n> encoder_state is a tuple of LSTMStateTuple of size num_layers\n>\n> Calling encoder_state[0].get_shape() fails with 'LSTMStateTuple' object\n> has no attribute 'get_shape'\n>\n> For now encoder_state[0].c.get_shape() , encoder_state[0].h.get_shape()\n> is the only way I know to work around this\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/3056#issuecomment-273114865>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimzmQ6V1B0vTmTYTUVTBZDw2qIGK4ks5rTKYVgaJpZM4I-sU0>\n> .\n>\n"}