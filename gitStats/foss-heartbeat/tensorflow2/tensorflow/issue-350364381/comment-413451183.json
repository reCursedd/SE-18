{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/413451183", "html_url": "https://github.com/tensorflow/tensorflow/issues/21601#issuecomment-413451183", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21601", "id": 413451183, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzQ1MTE4Mw==", "user": {"login": "leandro-gracia-gil", "id": 8785797, "node_id": "MDQ6VXNlcjg3ODU3OTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/8785797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leandro-gracia-gil", "html_url": "https://github.com/leandro-gracia-gil", "followers_url": "https://api.github.com/users/leandro-gracia-gil/followers", "following_url": "https://api.github.com/users/leandro-gracia-gil/following{/other_user}", "gists_url": "https://api.github.com/users/leandro-gracia-gil/gists{/gist_id}", "starred_url": "https://api.github.com/users/leandro-gracia-gil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leandro-gracia-gil/subscriptions", "organizations_url": "https://api.github.com/users/leandro-gracia-gil/orgs", "repos_url": "https://api.github.com/users/leandro-gracia-gil/repos", "events_url": "https://api.github.com/users/leandro-gracia-gil/events{/privacy}", "received_events_url": "https://api.github.com/users/leandro-gracia-gil/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-16T07:23:18Z", "updated_at": "2018-08-16T07:23:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>An update on this. It seems that the core problem is not in the behavior of tf.add or enqueuing, but rather in underlying optimizations regarding constant tensors. If in the snippet above I replace the enqueue line with this, it works fine:</p>\n<div class=\"highlight highlight-source-python\"><pre>sess.run(q.enqueue(tf.add(v, tf.placeholder_with_default(<span class=\"pl-c1\">0</span>, ()))))</pre></div>\n<p>I've also found a different scenario where this problem manifests: in shape deduction for ranges.<br>\nFor example:</p>\n<div class=\"highlight highlight-source-python\"><pre>z <span class=\"pl-k\">=</span> tf.zeros((), tf.int32)\ntf.range(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span> <span class=\"pl-k\">+</span> z).shape  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Returns TensorShape([Dimension(2)]) in 1.10, returned TensorShape([Dimension(None)]) in 10.8</span>\n\nz <span class=\"pl-k\">=</span> tf.placeholder_with_default(z, z.shape)\ntf.range(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span> <span class=\"pl-k\">+</span> z).shape  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Returns TensorShape([Dimension(None)])</span></pre></div>\n<p>So, it seems like using tf.placeholder_with_default is a viable solution for my immediate problem, but this is nevertheless exposing a behavioral change with possible subtle implications (like the enqueue case), and an API behavior inconsistency between tf.Session and tf.InteractiveSession. I leave up to you to decide what to do regarding this bug.</p>", "body_text": "An update on this. It seems that the core problem is not in the behavior of tf.add or enqueuing, but rather in underlying optimizations regarding constant tensors. If in the snippet above I replace the enqueue line with this, it works fine:\nsess.run(q.enqueue(tf.add(v, tf.placeholder_with_default(0, ()))))\nI've also found a different scenario where this problem manifests: in shape deduction for ranges.\nFor example:\nz = tf.zeros((), tf.int32)\ntf.range(0, 2 + z).shape  # Returns TensorShape([Dimension(2)]) in 1.10, returned TensorShape([Dimension(None)]) in 10.8\n\nz = tf.placeholder_with_default(z, z.shape)\ntf.range(0, 2 + z).shape  # Returns TensorShape([Dimension(None)])\nSo, it seems like using tf.placeholder_with_default is a viable solution for my immediate problem, but this is nevertheless exposing a behavioral change with possible subtle implications (like the enqueue case), and an API behavior inconsistency between tf.Session and tf.InteractiveSession. I leave up to you to decide what to do regarding this bug.", "body": "An update on this. It seems that the core problem is not in the behavior of tf.add or enqueuing, but rather in underlying optimizations regarding constant tensors. If in the snippet above I replace the enqueue line with this, it works fine:\r\n\r\n```python\r\nsess.run(q.enqueue(tf.add(v, tf.placeholder_with_default(0, ()))))\r\n```\r\n\r\nI've also found a different scenario where this problem manifests: in shape deduction for ranges.\r\nFor example:\r\n```python\r\nz = tf.zeros((), tf.int32)\r\ntf.range(0, 2 + z).shape  # Returns TensorShape([Dimension(2)]) in 1.10, returned TensorShape([Dimension(None)]) in 10.8\r\n\r\nz = tf.placeholder_with_default(z, z.shape)\r\ntf.range(0, 2 + z).shape  # Returns TensorShape([Dimension(None)])\r\n```\r\n\r\nSo, it seems like using tf.placeholder_with_default is a viable solution for my immediate problem, but this is nevertheless exposing a behavioral change with possible subtle implications (like the enqueue case), and an API behavior inconsistency between tf.Session and tf.InteractiveSession. I leave up to you to decide what to do regarding this bug."}