{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/305047983", "html_url": "https://github.com/tensorflow/tensorflow/issues/10303#issuecomment-305047983", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10303", "id": 305047983, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNTA0Nzk4Mw==", "user": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-31T00:36:46Z", "updated_at": "2017-05-31T02:11:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=22623388\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/blake-varden\">@blake-varden</a> This is not a bug. The reason why you see no data dumped is because every node is constant folded in the graph set up by your code. <code>tf.ones</code> defines a TF constant. So all the downstream tensors like <code>stacked</code> and <code>concat</code> are effectively constant. TF's graph optimization knows that and folds all nodes into one for each fetched tensor.</p>\n<p>If you replace <code>tf.ones</code> with a <code>tf.Variable</code>, you'll see the data dumped:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python <span class=\"pl-k\">import</span> debug <span class=\"pl-k\">as</span> tf_debug\n\nbase <span class=\"pl-k\">=</span> tf.Variable(np.ones([<span class=\"pl-c1\">10</span>]), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>base<span class=\"pl-pds\">\"</span></span>)\nstacked <span class=\"pl-k\">=</span> tf.stack([base, base], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>stacked<span class=\"pl-pds\">'</span></span>)\nconcat <span class=\"pl-k\">=</span> tf.concat([[base], [base]], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>concat<span class=\"pl-pds\">'</span></span>)\n\nsession <span class=\"pl-k\">=</span> tf.Session()\nsession.run(tf.global_variables_initializer())\n\nsession <span class=\"pl-k\">=</span> tf_debug.LocalCLIDebugWrapperSession(session)\nres <span class=\"pl-k\">=</span> session.run([ stacked, concat])</pre></div>\n<p>This behavior is documented in a relatively obscure place:<br>\n<a href=\"https://www.tensorflow.org/api_docs/python/tfdbg/watch_graph\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tfdbg/watch_graph</a></p>\n<blockquote>\n<p>N.B.: 1. Under certain circumstances, the Tensor may not get actually watched (e.g., if the node of the Tensor is constant-folded during runtime).</p>\n</blockquote>\n<p>For more on constant folding in TF, see:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L83\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L83</a><br>\nand<br>\n<a href=\"https://www.tensorflow.org/api_docs/python/tf/OptimizerOptions\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tf/OptimizerOptions</a></p>\n<p>TFDBG is working as intended as I just checked in the <code>tensorflow/tensorflow:nightly</code> docker image.</p>", "body_text": "@blake-varden This is not a bug. The reason why you see no data dumped is because every node is constant folded in the graph set up by your code. tf.ones defines a TF constant. So all the downstream tensors like stacked and concat are effectively constant. TF's graph optimization knows that and folds all nodes into one for each fetched tensor.\nIf you replace tf.ones with a tf.Variable, you'll see the data dumped:\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python import debug as tf_debug\n\nbase = tf.Variable(np.ones([10]), dtype=tf.float32, name=\"base\")\nstacked = tf.stack([base, base], name='stacked')\nconcat = tf.concat([[base], [base]], axis=0, name='concat')\n\nsession = tf.Session()\nsession.run(tf.global_variables_initializer())\n\nsession = tf_debug.LocalCLIDebugWrapperSession(session)\nres = session.run([ stacked, concat])\nThis behavior is documented in a relatively obscure place:\nhttps://www.tensorflow.org/api_docs/python/tfdbg/watch_graph\n\nN.B.: 1. Under certain circumstances, the Tensor may not get actually watched (e.g., if the node of the Tensor is constant-folded during runtime).\n\nFor more on constant folding in TF, see:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L83\nand\nhttps://www.tensorflow.org/api_docs/python/tf/OptimizerOptions\nTFDBG is working as intended as I just checked in the tensorflow/tensorflow:nightly docker image.", "body": "@blake-varden This is not a bug. The reason why you see no data dumped is because every node is constant folded in the graph set up by your code. `tf.ones` defines a TF constant. So all the downstream tensors like `stacked` and `concat` are effectively constant. TF's graph optimization knows that and folds all nodes into one for each fetched tensor.\r\n\r\nIf you replace `tf.ones` with a `tf.Variable`, you'll see the data dumped:\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python import debug as tf_debug\r\n\r\nbase = tf.Variable(np.ones([10]), dtype=tf.float32, name=\"base\")\r\nstacked = tf.stack([base, base], name='stacked')\r\nconcat = tf.concat([[base], [base]], axis=0, name='concat')\r\n\r\nsession = tf.Session()\r\nsession.run(tf.global_variables_initializer())\r\n\r\nsession = tf_debug.LocalCLIDebugWrapperSession(session)\r\nres = session.run([ stacked, concat])\r\n```\r\n\r\nThis behavior is documented in a relatively obscure place:\r\nhttps://www.tensorflow.org/api_docs/python/tfdbg/watch_graph\r\n\r\n> N.B.: 1. Under certain circumstances, the Tensor may not get actually watched (e.g., if the node of the Tensor is constant-folded during runtime). \r\n\r\nFor more on constant folding in TF, see:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L83\r\nand\r\nhttps://www.tensorflow.org/api_docs/python/tf/OptimizerOptions\r\n\r\nTFDBG is working as intended as I just checked in the `tensorflow/tensorflow:nightly` docker image."}