{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/440271651", "html_url": "https://github.com/tensorflow/tensorflow/issues/7031#issuecomment-440271651", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7031", "id": 440271651, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDI3MTY1MQ==", "user": {"login": "dezibelkarate", "id": 45200124, "node_id": "MDQ6VXNlcjQ1MjAwMTI0", "avatar_url": "https://avatars3.githubusercontent.com/u/45200124?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dezibelkarate", "html_url": "https://github.com/dezibelkarate", "followers_url": "https://api.github.com/users/dezibelkarate/followers", "following_url": "https://api.github.com/users/dezibelkarate/following{/other_user}", "gists_url": "https://api.github.com/users/dezibelkarate/gists{/gist_id}", "starred_url": "https://api.github.com/users/dezibelkarate/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dezibelkarate/subscriptions", "organizations_url": "https://api.github.com/users/dezibelkarate/orgs", "repos_url": "https://api.github.com/users/dezibelkarate/repos", "events_url": "https://api.github.com/users/dezibelkarate/events{/privacy}", "received_events_url": "https://api.github.com/users/dezibelkarate/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-20T13:22:56Z", "updated_at": "2018-11-20T13:22:56Z", "author_association": "NONE", "body_html": "<p>Hi, i get the same TypeError message but i don't know why. I do not use <code>tf.concat()</code><br>\nI'd appreciate it if you could help me solve this issue. I have keras version 2.2.4 and tensorflow version 1.11.0 but i have tried it with several different versions as well. Furthermore i have python 3.6.3 on a MacOS 10.10.5.<br>\nHere's a snippet from the code<br>\n<code>word_model_in = Input(shape=(context_window,))</code><br>\n<code>word_model_out = Embedding(output_dim=embedding_matrix.shape[1], input_dim=embedding_matrix.shape[0], input_length=context_window, weights=[embedding_matrix], mask_zero=True)(word_model_in)</code><br>\n<code>word_model_out1 = Bidirectional(LSTM(100,input_shape=(None,3,300),return_sequences=False))(word_model_out)</code><br>\n<code>word_model = Model(word_model_in, word_model_out1)</code><br>\n<code>word_model.summary()</code></p>\n<p>And here's the error message<br>\nTypeError                                 Traceback (most recent call last)<br>\n in ()<br>\n5                          weights=[embedding_matrix],<br>\n6                          mask_zero=True)(word_model_in)<br>\n----&gt; 7 word_model_out1 = Bidirectional(LSTM(100,input_shape=(None,3,300),return_sequences=False))(word_model_out)<br>\n8 word_model = Model(word_model_in, word_model_out1)<br>\n9 word_model.summary()</p>\n<p>~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py in <strong>call</strong>(self, inputs, **kwargs)</p>\n<p>~/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py in call(self, inputs, mask)<br>\n210         kwargs = {}<br>\n211         if has_arg(self.layer.call, 'training'):<br>\n--&gt; 212             kwargs['training'] = training<br>\n213         uses_learning_phase = False<br>\n214</p>\n<p>~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py in call(self, inputs, mask, initial_state, training)<br>\n288             (e.g. via the <code>input_shape</code> argument)<br>\n289<br>\n--&gt; 290     # Input shape<br>\n291         3D tensor with shape <code>(batch_size, timesteps, input_dim)</code>.<br>\n292</p>\n<p>~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py in preprocess_input(self, inputs, training)<br>\n1031             warnings.warn('The <code>implementation</code> argument '<br>\n1032                           'in <code>SimpleRNN</code> has been deprecated. '<br>\n-&gt; 1033                           'Please remove it from your layer call.')<br>\n1034         if K.backend() == 'theano' and (dropout or recurrent_dropout):<br>\n1035             warnings.warn(</p>\n<p>~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in concatenate(tensors, axis)<br>\n1525     \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).<br>\n1526<br>\n-&gt; 1527     This function is more numerically stable than log(sum(exp(x))).<br>\n1528     It avoids overflows caused by taking the exp of large inputs and<br>\n1529     underflows caused by taking the log of small inputs.</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in concat(concat_dim, values, name)<br>\n1073   <code>1074  -&gt; 1075   would produce: 1076  1077  </code>python</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)<br>\n667       <code>TypeError</code>.<br>\n668     \"\"\"<br>\n--&gt; 669     raise TypeError(\"Using a <code>tf.Tensor</code> as a Python <code>bool</code> is not allowed. \"<br>\n670                     \"Use <code>if t is not None:</code> instead of <code>if t:</code> to test if a \"<br>\n671                     \"tensor is defined, and use TensorFlow ops such as \"</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)<br>\n174     TypeError: if shape is incorrectly specified or unsupported.<br>\n175   \"\"\"<br>\n--&gt; 176   ctx = context.context()<br>\n177   if ctx.executing_eagerly():<br>\n178     t = convert_to_eager_tensor(value, ctx, dtype)</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name, verify_shape)<br>\n163<br>\n164     shape:          Optional dimensions of resulting tensor.<br>\n--&gt; 165<br>\n166     name:           Optional name for the tensor.<br>\n167</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)<br>\n365<br>\n366   Returns:<br>\n--&gt; 367     A <code>TensorProto</code>. Depending on the type, it may contain data in the<br>\n368     \"tensor_content\" attribute, which is not directly useful to Python programs.<br>\n369     To access the values you should convert the proto back to a numpy ndarray</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in _AssertCompatible(values, dtype)<br>\n300<br>\n301<br>\n--&gt; 302 def _FilterStr(v):<br>\n303   if isinstance(v, (list, tuple)):<br>\n304     return _FirstNotNone([_FilterStr(x) for x in v])</p>\n<p>TypeError: Expected int32, got list containing Tensors of type '_Message' instead.`</p>", "body_text": "Hi, i get the same TypeError message but i don't know why. I do not use tf.concat()\nI'd appreciate it if you could help me solve this issue. I have keras version 2.2.4 and tensorflow version 1.11.0 but i have tried it with several different versions as well. Furthermore i have python 3.6.3 on a MacOS 10.10.5.\nHere's a snippet from the code\nword_model_in = Input(shape=(context_window,))\nword_model_out = Embedding(output_dim=embedding_matrix.shape[1], input_dim=embedding_matrix.shape[0], input_length=context_window, weights=[embedding_matrix], mask_zero=True)(word_model_in)\nword_model_out1 = Bidirectional(LSTM(100,input_shape=(None,3,300),return_sequences=False))(word_model_out)\nword_model = Model(word_model_in, word_model_out1)\nword_model.summary()\nAnd here's the error message\nTypeError                                 Traceback (most recent call last)\n in ()\n5                          weights=[embedding_matrix],\n6                          mask_zero=True)(word_model_in)\n----> 7 word_model_out1 = Bidirectional(LSTM(100,input_shape=(None,3,300),return_sequences=False))(word_model_out)\n8 word_model = Model(word_model_in, word_model_out1)\n9 word_model.summary()\n~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py in call(self, inputs, **kwargs)\n~/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py in call(self, inputs, mask)\n210         kwargs = {}\n211         if has_arg(self.layer.call, 'training'):\n--> 212             kwargs['training'] = training\n213         uses_learning_phase = False\n214\n~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py in call(self, inputs, mask, initial_state, training)\n288             (e.g. via the input_shape argument)\n289\n--> 290     # Input shape\n291         3D tensor with shape (batch_size, timesteps, input_dim).\n292\n~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py in preprocess_input(self, inputs, training)\n1031             warnings.warn('The implementation argument '\n1032                           'in SimpleRNN has been deprecated. '\n-> 1033                           'Please remove it from your layer call.')\n1034         if K.backend() == 'theano' and (dropout or recurrent_dropout):\n1035             warnings.warn(\n~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in concatenate(tensors, axis)\n1525     \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n1526\n-> 1527     This function is more numerically stable than log(sum(exp(x))).\n1528     It avoids overflows caused by taking the exp of large inputs and\n1529     underflows caused by taking the log of small inputs.\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in concat(concat_dim, values, name)\n1073   1074  -> 1075   would produce: 1076  1077  python\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\n667       TypeError.\n668     \"\"\"\n--> 669     raise TypeError(\"Using a tf.Tensor as a Python bool is not allowed. \"\n670                     \"Use if t is not None: instead of if t: to test if a \"\n671                     \"tensor is defined, and use TensorFlow ops such as \"\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\n174     TypeError: if shape is incorrectly specified or unsupported.\n175   \"\"\"\n--> 176   ctx = context.context()\n177   if ctx.executing_eagerly():\n178     t = convert_to_eager_tensor(value, ctx, dtype)\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name, verify_shape)\n163\n164     shape:          Optional dimensions of resulting tensor.\n--> 165\n166     name:           Optional name for the tensor.\n167\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)\n365\n366   Returns:\n--> 367     A TensorProto. Depending on the type, it may contain data in the\n368     \"tensor_content\" attribute, which is not directly useful to Python programs.\n369     To access the values you should convert the proto back to a numpy ndarray\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in _AssertCompatible(values, dtype)\n300\n301\n--> 302 def _FilterStr(v):\n303   if isinstance(v, (list, tuple)):\n304     return _FirstNotNone([_FilterStr(x) for x in v])\nTypeError: Expected int32, got list containing Tensors of type '_Message' instead.`", "body": "Hi, i get the same TypeError message but i don't know why. I do not use `tf.concat()`\r\nI'd appreciate it if you could help me solve this issue. I have keras version 2.2.4 and tensorflow version 1.11.0 but i have tried it with several different versions as well. Furthermore i have python 3.6.3 on a MacOS 10.10.5. \r\nHere's a snippet from the code\r\n`word_model_in = Input(shape=(context_window,))`\r\n`word_model_out = Embedding(output_dim=embedding_matrix.shape[1],\r\n                         input_dim=embedding_matrix.shape[0],\r\n                         input_length=context_window,\r\n                         weights=[embedding_matrix],\r\n                         mask_zero=True)(word_model_in)`\r\n`word_model_out1 = Bidirectional(LSTM(100,input_shape=(None,3,300),return_sequences=False))(word_model_out)`\r\n`word_model = Model(word_model_in, word_model_out1)`\r\n`word_model.summary()`\r\n\r\nAnd here's the error message\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-41-4a0bf7e03efd> in <module>()\r\n      5                          weights=[embedding_matrix],\r\n      6                          mask_zero=True)(word_model_in)\r\n----> 7 word_model_out1 = Bidirectional(LSTM(100,input_shape=(None,3,300),return_sequences=False))(word_model_out)\r\n      8 word_model = Model(word_model_in, word_model_out1)\r\n      9 word_model.summary()\r\n\r\n~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py in __call__(self, inputs, **kwargs)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py in call(self, inputs, mask)\r\n    210         kwargs = {}\r\n    211         if has_arg(self.layer.call, 'training'):\r\n--> 212             kwargs['training'] = training\r\n    213         uses_learning_phase = False\r\n    214 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py in call(self, inputs, mask, initial_state, training)\r\n    288             (e.g. via the `input_shape` argument)\r\n    289 \r\n--> 290     # Input shape\r\n    291         3D tensor with shape `(batch_size, timesteps, input_dim)`.\r\n    292 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py in preprocess_input(self, inputs, training)\r\n   1031             warnings.warn('The `implementation` argument '\r\n   1032                           'in `SimpleRNN` has been deprecated. '\r\n-> 1033                           'Please remove it from your layer call.')\r\n   1034         if K.backend() == 'theano' and (dropout or recurrent_dropout):\r\n   1035             warnings.warn(\r\n\r\n~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in concatenate(tensors, axis)\r\n   1525     \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\r\n   1526 \r\n-> 1527     This function is more numerically stable than log(sum(exp(x))).\r\n   1528     It avoids overflows caused by taking the exp of large inputs and\r\n   1529     underflows caused by taking the log of small inputs.\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in concat(concat_dim, values, name)\r\n   1073   ```\r\n   1074 \r\n-> 1075   would produce:\r\n   1076 \r\n   1077   ```python\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\r\n    667       `TypeError`.\r\n    668     \"\"\"\r\n--> 669     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\r\n    670                     \"Use `if t is not None:` instead of `if t:` to test if a \"\r\n    671                     \"tensor is defined, and use TensorFlow ops such as \"\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    174     TypeError: if shape is incorrectly specified or unsupported.\r\n    175   \"\"\"\r\n--> 176   ctx = context.context()\r\n    177   if ctx.executing_eagerly():\r\n    178     t = convert_to_eager_tensor(value, ctx, dtype)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name, verify_shape)\r\n    163 \r\n    164     shape:          Optional dimensions of resulting tensor.\r\n--> 165 \r\n    166     name:           Optional name for the tensor.\r\n    167 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)\r\n    365 \r\n    366   Returns:\r\n--> 367     A `TensorProto`. Depending on the type, it may contain data in the\r\n    368     \"tensor_content\" attribute, which is not directly useful to Python programs.\r\n    369     To access the values you should convert the proto back to a numpy ndarray\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in _AssertCompatible(values, dtype)\r\n    300 \r\n    301 \r\n--> 302 def _FilterStr(v):\r\n    303   if isinstance(v, (list, tuple)):\r\n    304     return _FirstNotNone([_FilterStr(x) for x in v])\r\n\r\nTypeError: Expected int32, got list containing Tensors of type '_Message' instead.`"}