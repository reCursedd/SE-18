{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21638", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21638/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21638/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21638/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21638", "id": 350924161, "node_id": "MDU6SXNzdWUzNTA5MjQxNjE=", "number": 21638, "title": "[XLA] ResourceExhaustedError when trying to define a Sequential model in Keras under jit_scope context manager", "user": {"login": "AlexandruBurlacu", "id": 16062020, "node_id": "MDQ6VXNlcjE2MDYyMDIw", "avatar_url": "https://avatars0.githubusercontent.com/u/16062020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AlexandruBurlacu", "html_url": "https://github.com/AlexandruBurlacu", "followers_url": "https://api.github.com/users/AlexandruBurlacu/followers", "following_url": "https://api.github.com/users/AlexandruBurlacu/following{/other_user}", "gists_url": "https://api.github.com/users/AlexandruBurlacu/gists{/gist_id}", "starred_url": "https://api.github.com/users/AlexandruBurlacu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AlexandruBurlacu/subscriptions", "organizations_url": "https://api.github.com/users/AlexandruBurlacu/orgs", "repos_url": "https://api.github.com/users/AlexandruBurlacu/repos", "events_url": "https://api.github.com/users/AlexandruBurlacu/events{/privacy}", "received_events_url": "https://api.github.com/users/AlexandruBurlacu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-08-15T18:54:39Z", "updated_at": "2018-10-02T14:39:41Z", "closed_at": "2018-09-28T21:43:44Z", "author_association": "NONE", "body_html": "<p>Intel i5-2430M, 6 GB RAM<br>\nLinux Ubuntu 16.04 | Python 3.6.5 | Bazel 0.16.0 | GCC 5.4.0<br>\nTensorFlow 1.8 compiled from source with MKL and XLA support</p>\n<hr>\n<p>So, my issue is that I try to use XLA for CPU via Keras that is embedded in TensorFlow 1.8 using the <code>tf.contrib.compiler.jit.experimental_jit_scope</code> (for CPU it's the only way I know to enable XLA, using <code>ConfigProto</code> doesn't work on CPU for me). For some strange reason I am thrown <code>ResourceExhaustedError</code> when trying to allocate 0 bytes.  Looks like something's wrong, either in TensorFlow or Keras. Below is the listing of the code I use and the full trace.</p>\n<h3>Code</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.client <span class=\"pl-k\">import</span> timeline\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-c1\">JIT_SCOPE</span> <span class=\"pl-k\">=</span> tf.contrib.compiler.jit.experimental_jit_scope\n\noptions <span class=\"pl-k\">=</span> tf.RunOptions(<span class=\"pl-v\">trace_level</span><span class=\"pl-k\">=</span>tf.RunOptions.<span class=\"pl-c1\">FULL_TRACE</span>)                   \nrun_metadata <span class=\"pl-k\">=</span> tf.RunMetadata()\n\n(train_x, train_y), _ <span class=\"pl-k\">=</span> tf.keras.datasets.mnist.load_data()\n\ntrain_x <span class=\"pl-k\">=</span> np.expand_dims(train_x, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>.\ntrain_y <span class=\"pl-k\">=</span> tf.keras.utils.to_categorical(train_y)\n\n<span class=\"pl-k\">with</span> JIT_SCOPE():                                                               \n    model <span class=\"pl-k\">=</span> tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(<span class=\"pl-c1\">16</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>relu<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">input_shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)),\n        tf.keras.layers.MaxPool2D((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(<span class=\"pl-c1\">10</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>softmax<span class=\"pl-pds\">\"</span></span>)\n    ])\n\n    model.compile(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>sgd<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>categorical_crossentropy<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">options</span><span class=\"pl-k\">=</span>options, <span class=\"pl-v\">run_metadata</span><span class=\"pl-k\">=</span>run_metadata)\n\nmodel.fit(train_x, train_y) <span class=\"pl-c\"><span class=\"pl-c\">#</span> error happens at this moment</span>\n\ntrace <span class=\"pl-k\">=</span> timeline.Timeline(<span class=\"pl-v\">step_stats</span><span class=\"pl-k\">=</span>run_metadata.step_stats)\n<span class=\"pl-k\">with</span> <span class=\"pl-c1\">open</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>timeline.ctr.json<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>w<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> f:\n    f.write(trace.generate_chrome_trace_format())\n</pre></div>\n<h3>Traceback</h3>\n<pre><code>Epoch 1/1\n2018-08-15 20:28:54.784459: I tensorflow/compiler/xla/service/service.cc:159] XLA service 0x7f70ec071a30 executing computations on platform Host. Devices:\n2018-08-15 20:28:54.784509: I tensorflow/compiler/xla/service/service.cc:167]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\n2018-08-15 20:28:55.548381: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\n2018-08-15 20:28:55.548481: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n2018-08-15 20:28:55.561315: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\n2018-08-15 20:28:55.561365: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n---------------------------------------------------------------------------\nResourceExhaustedError                    Traceback (most recent call last)\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1321     try:\n-&gt; 1322       return fn(*args)\n   1323     except errors.OpError as e:\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\n   1306       return self._call_tf_sessionrun(\n-&gt; 1307           options, feed_dict, fetch_list, target_list, run_metadata)\n   1308 \n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\n   1408           self._session, options, feed_dict, fetch_list, target_list,\n-&gt; 1409           run_metadata)\n   1410     else:\n\nResourceExhaustedError: Out of memory while trying to allocate 0 bytes.\n\t [[Node: cluster_1/_4/_5 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_1[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nDuring handling of the above exception, another exception occurred:\n\nResourceExhaustedError                    Traceback (most recent call last)\n&lt;ipython-input-46-dbab7a29ab1f&gt; in &lt;module&gt;()\n----&gt; 1 model.fit(train_x[:1000], train_y[:1000], epochs=1)\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1214           initial_epoch=initial_epoch,\n   1215           steps_per_epoch=steps_per_epoch,\n-&gt; 1216           validation_steps=validation_steps)\n   1217 \n   1218   def evaluate(self,\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py in fit_loop(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n    243           ins_batch[i] = ins_batch[i].toarray()\n    244 \n--&gt; 245         outs = f(ins_batch)\n    246         if not isinstance(outs, list):\n    247           outs = [outs]\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in __call__(self, inputs)\n   2797       feed_dict = {}\n   2798 \n-&gt; 2799     session = get_session()\n   2800     data_tensors_to_feed = []\n   2801     for tensor, value in zip(self.inputs, inputs):\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in get_session()\n    440   if not _MANUAL_VAR_INIT:\n    441     with session.graph.as_default():\n--&gt; 442       _initialize_variables(session)\n    443   return session\n    444 \n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in _initialize_variables(session)\n    671       v._keras_initialized = True\n    672     if uninitialized_vars:\n--&gt; 673       session.run(variables_module.variables_initializer(uninitialized_vars))\n    674 \n    675 \n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    898     try:\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 900                          run_metadata_ptr)\n    901       if run_metadata:\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1134       results = self._do_run(handle, final_targets, final_fetches,\n-&gt; 1135                              feed_dict_tensor, options, run_metadata)\n   1136     else:\n   1137       results = []\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1314     if handle is None:\n   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-&gt; 1316                            run_metadata)\n   1317     else:\n   1318       return self._do_call(_prun_fn, handle, feeds, fetches)\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1333         except KeyError:\n   1334           pass\n-&gt; 1335       raise type(e)(node_def, op, message)\n   1336 \n   1337   def _extend_graph(self):\n\nResourceExhaustedError: Out of memory while trying to allocate 0 bytes.\n\t [[Node: cluster_1/_4/_5 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_1[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n</code></pre>", "body_text": "Intel i5-2430M, 6 GB RAM\nLinux Ubuntu 16.04 | Python 3.6.5 | Bazel 0.16.0 | GCC 5.4.0\nTensorFlow 1.8 compiled from source with MKL and XLA support\n\nSo, my issue is that I try to use XLA for CPU via Keras that is embedded in TensorFlow 1.8 using the tf.contrib.compiler.jit.experimental_jit_scope (for CPU it's the only way I know to enable XLA, using ConfigProto doesn't work on CPU for me). For some strange reason I am thrown ResourceExhaustedError when trying to allocate 0 bytes.  Looks like something's wrong, either in TensorFlow or Keras. Below is the listing of the code I use and the full trace.\nCode\nimport tensorflow as tf\nfrom tensorflow.python.client import timeline\n\nimport numpy as np\n\nJIT_SCOPE = tf.contrib.compiler.jit.experimental_jit_scope\n\noptions = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)                   \nrun_metadata = tf.RunMetadata()\n\n(train_x, train_y), _ = tf.keras.datasets.mnist.load_data()\n\ntrain_x = np.expand_dims(train_x, axis=-1) / 255.\ntrain_y = tf.keras.utils.to_categorical(train_y)\n\nwith JIT_SCOPE():                                                               \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPool2D((2, 2)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(10, activation=\"softmax\")\n    ])\n\n    model.compile(\"sgd\", \"categorical_crossentropy\", options=options, run_metadata=run_metadata)\n\nmodel.fit(train_x, train_y) # error happens at this moment\n\ntrace = timeline.Timeline(step_stats=run_metadata.step_stats)\nwith open(\"timeline.ctr.json\", \"w\") as f:\n    f.write(trace.generate_chrome_trace_format())\n\nTraceback\nEpoch 1/1\n2018-08-15 20:28:54.784459: I tensorflow/compiler/xla/service/service.cc:159] XLA service 0x7f70ec071a30 executing computations on platform Host. Devices:\n2018-08-15 20:28:54.784509: I tensorflow/compiler/xla/service/service.cc:167]   StreamExecutor device (0): <undefined>, <undefined>\n2018-08-15 20:28:55.548381: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\n2018-08-15 20:28:55.548481: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n2018-08-15 20:28:55.561315: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\n2018-08-15 20:28:55.561365: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\n---------------------------------------------------------------------------\nResourceExhaustedError                    Traceback (most recent call last)\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1321     try:\n-> 1322       return fn(*args)\n   1323     except errors.OpError as e:\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\n   1306       return self._call_tf_sessionrun(\n-> 1307           options, feed_dict, fetch_list, target_list, run_metadata)\n   1308 \n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\n   1408           self._session, options, feed_dict, fetch_list, target_list,\n-> 1409           run_metadata)\n   1410     else:\n\nResourceExhaustedError: Out of memory while trying to allocate 0 bytes.\n\t [[Node: cluster_1/_4/_5 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_1[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nDuring handling of the above exception, another exception occurred:\n\nResourceExhaustedError                    Traceback (most recent call last)\n<ipython-input-46-dbab7a29ab1f> in <module>()\n----> 1 model.fit(train_x[:1000], train_y[:1000], epochs=1)\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1214           initial_epoch=initial_epoch,\n   1215           steps_per_epoch=steps_per_epoch,\n-> 1216           validation_steps=validation_steps)\n   1217 \n   1218   def evaluate(self,\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py in fit_loop(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n    243           ins_batch[i] = ins_batch[i].toarray()\n    244 \n--> 245         outs = f(ins_batch)\n    246         if not isinstance(outs, list):\n    247           outs = [outs]\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in __call__(self, inputs)\n   2797       feed_dict = {}\n   2798 \n-> 2799     session = get_session()\n   2800     data_tensors_to_feed = []\n   2801     for tensor, value in zip(self.inputs, inputs):\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in get_session()\n    440   if not _MANUAL_VAR_INIT:\n    441     with session.graph.as_default():\n--> 442       _initialize_variables(session)\n    443   return session\n    444 \n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in _initialize_variables(session)\n    671       v._keras_initialized = True\n    672     if uninitialized_vars:\n--> 673       session.run(variables_module.variables_initializer(uninitialized_vars))\n    674 \n    675 \n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    898     try:\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 900                          run_metadata_ptr)\n    901       if run_metadata:\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1134       results = self._do_run(handle, final_targets, final_fetches,\n-> 1135                              feed_dict_tensor, options, run_metadata)\n   1136     else:\n   1137       results = []\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1314     if handle is None:\n   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-> 1316                            run_metadata)\n   1317     else:\n   1318       return self._do_call(_prun_fn, handle, feeds, fetches)\n\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1333         except KeyError:\n   1334           pass\n-> 1335       raise type(e)(node_def, op, message)\n   1336 \n   1337   def _extend_graph(self):\n\nResourceExhaustedError: Out of memory while trying to allocate 0 bytes.\n\t [[Node: cluster_1/_4/_5 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_1[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.", "body": "Intel i5-2430M, 6 GB RAM\r\nLinux Ubuntu 16.04 | Python 3.6.5 | Bazel 0.16.0 | GCC 5.4.0\r\nTensorFlow 1.8 compiled from source with MKL and XLA support\r\n\r\n---\r\n\r\nSo, my issue is that I try to use XLA for CPU via Keras that is embedded in TensorFlow 1.8 using the `tf.contrib.compiler.jit.experimental_jit_scope` (for CPU it's the only way I know to enable XLA, using `ConfigProto` doesn't work on CPU for me). For some strange reason I am thrown `ResourceExhaustedError` when trying to allocate 0 bytes.  Looks like something's wrong, either in TensorFlow or Keras. Below is the listing of the code I use and the full trace.\r\n\r\n### Code\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import timeline\r\n\r\nimport numpy as np\r\n\r\nJIT_SCOPE = tf.contrib.compiler.jit.experimental_jit_scope\r\n\r\noptions = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)                   \r\nrun_metadata = tf.RunMetadata()\r\n\r\n(train_x, train_y), _ = tf.keras.datasets.mnist.load_data()\r\n\r\ntrain_x = np.expand_dims(train_x, axis=-1) / 255.\r\ntrain_y = tf.keras.utils.to_categorical(train_y)\r\n\r\nwith JIT_SCOPE():                                                               \r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\r\n        tf.keras.layers.MaxPool2D((2, 2)),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(10, activation=\"softmax\")\r\n    ])\r\n\r\n    model.compile(\"sgd\", \"categorical_crossentropy\", options=options, run_metadata=run_metadata)\r\n\r\nmodel.fit(train_x, train_y) # error happens at this moment\r\n\r\ntrace = timeline.Timeline(step_stats=run_metadata.step_stats)\r\nwith open(\"timeline.ctr.json\", \"w\") as f:\r\n    f.write(trace.generate_chrome_trace_format())\r\n\r\n```\r\n\r\n### Traceback\r\n\r\n```\r\nEpoch 1/1\r\n2018-08-15 20:28:54.784459: I tensorflow/compiler/xla/service/service.cc:159] XLA service 0x7f70ec071a30 executing computations on platform Host. Devices:\r\n2018-08-15 20:28:54.784509: I tensorflow/compiler/xla/service/service.cc:167]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-08-15 20:28:55.548381: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\r\n2018-08-15 20:28:55.548481: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2018-08-15 20:28:55.561315: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\r\n2018-08-15 20:28:55.561365: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1321     try:\r\n-> 1322       return fn(*args)\r\n   1323     except errors.OpError as e:\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1306       return self._call_tf_sessionrun(\r\n-> 1307           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1308 \r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1408           self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1409           run_metadata)\r\n   1410     else:\r\n\r\nResourceExhaustedError: Out of memory while trying to allocate 0 bytes.\r\n\t [[Node: cluster_1/_4/_5 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_1[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-46-dbab7a29ab1f> in <module>()\r\n----> 1 model.fit(train_x[:1000], train_y[:1000], epochs=1)\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1214           initial_epoch=initial_epoch,\r\n   1215           steps_per_epoch=steps_per_epoch,\r\n-> 1216           validation_steps=validation_steps)\r\n   1217 \r\n   1218   def evaluate(self,\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py in fit_loop(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\r\n    243           ins_batch[i] = ins_batch[i].toarray()\r\n    244 \r\n--> 245         outs = f(ins_batch)\r\n    246         if not isinstance(outs, list):\r\n    247           outs = [outs]\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in __call__(self, inputs)\r\n   2797       feed_dict = {}\r\n   2798 \r\n-> 2799     session = get_session()\r\n   2800     data_tensors_to_feed = []\r\n   2801     for tensor, value in zip(self.inputs, inputs):\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in get_session()\r\n    440   if not _MANUAL_VAR_INIT:\r\n    441     with session.graph.as_default():\r\n--> 442       _initialize_variables(session)\r\n    443   return session\r\n    444 \r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in _initialize_variables(session)\r\n    671       v._keras_initialized = True\r\n    672     if uninitialized_vars:\r\n--> 673       session.run(variables_module.variables_initializer(uninitialized_vars))\r\n    674 \r\n    675 \r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    898     try:\r\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 900                          run_metadata_ptr)\r\n    901       if run_metadata:\r\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1134       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1135                              feed_dict_tensor, options, run_metadata)\r\n   1136     else:\r\n   1137       results = []\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1314     if handle is None:\r\n   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1316                            run_metadata)\r\n   1317     else:\r\n   1318       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333         except KeyError:\r\n   1334           pass\r\n-> 1335       raise type(e)(node_def, op, message)\r\n   1336 \r\n   1337   def _extend_graph(self):\r\n\r\nResourceExhaustedError: Out of memory while trying to allocate 0 bytes.\r\n\t [[Node: cluster_1/_4/_5 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_1[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n```\r\n"}