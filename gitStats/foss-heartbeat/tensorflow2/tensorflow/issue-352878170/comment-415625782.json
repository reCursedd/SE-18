{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/415625782", "html_url": "https://github.com/tensorflow/tensorflow/issues/21796#issuecomment-415625782", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21796", "id": 415625782, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTYyNTc4Mg==", "user": {"login": "Q82822", "id": 36806042, "node_id": "MDQ6VXNlcjM2ODA2MDQy", "avatar_url": "https://avatars2.githubusercontent.com/u/36806042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Q82822", "html_url": "https://github.com/Q82822", "followers_url": "https://api.github.com/users/Q82822/followers", "following_url": "https://api.github.com/users/Q82822/following{/other_user}", "gists_url": "https://api.github.com/users/Q82822/gists{/gist_id}", "starred_url": "https://api.github.com/users/Q82822/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Q82822/subscriptions", "organizations_url": "https://api.github.com/users/Q82822/orgs", "repos_url": "https://api.github.com/users/Q82822/repos", "events_url": "https://api.github.com/users/Q82822/events{/privacy}", "received_events_url": "https://api.github.com/users/Q82822/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-24T01:46:23Z", "updated_at": "2018-08-24T01:46:23Z", "author_association": "NONE", "body_html": "<p>the error -------<br>\n`TypeError                                 Traceback (most recent call last)<br>\n in ()<br>\n1 startTime=time.time()<br>\n----&gt; 2 image_model =tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet')<br>\n3<br>\n4 #image_model = inception_v4.create_model(weights='imagenet', include_top=True)<br>\n5 new_input = image_model.input</p>\n<p>D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in InceptionResNetV2(include_top, weights, input_tensor, input_shape, pooling, classes)<br>\n304   for block_idx in range(1, 11):<br>\n305     x = inception_resnet_block(<br>\n--&gt; 306         x, scale=0.17, block_type='block35', block_idx=block_idx)<br>\n307<br>\n308   # Mixed 6a (Reduction-A block): 17 x 17 x 1088</p>\n<p>D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in inception_resnet_block(x, scale, block_type, block_idx, activation)<br>\n187       output_shape=K.int_shape(x)[1:],<br>\n188       arguments={'scale': scale},<br>\n--&gt; 189       name=block_name)([x, up])<br>\n190   if activation is not None:<br>\n191     x = Activation(activation, name=block_name + '_ac')(x)</p>\n<p>D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in <strong>call</strong>(self, inputs, *args, **kwargs)<br>\n712           input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)<br>\n713<br>\n--&gt; 714         output_shapes = self.compute_output_shape(input_shapes)<br>\n715         output_shapes = nest.flatten(output_shapes)<br>\n716         outputs = [</p>\n<p>D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py in compute_output_shape(self, input_shape)<br>\n675<br>\n676   def compute_output_shape(self, input_shape):<br>\n--&gt; 677     input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())<br>\n678<br>\n679     if self._output_shape is None:</p>\n<p>D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in <strong>init</strong>(self, dims)<br>\n539       else:<br>\n540         # Got a list of dimensions<br>\n--&gt; 541         self._dims = [as_dimension(d) for d in dims_iter]<br>\n542     self._ndims = None<br>\n543</p>\n<p>D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in (.0)<br>\n539       else:<br>\n540         # Got a list of dimensions<br>\n--&gt; 541         self._dims = [as_dimension(d) for d in dims_iter]<br>\n542     self._ndims = None<br>\n543</p>\n<p>D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in as_dimension(value)<br>\n480     return value<br>\n481   else:<br>\n--&gt; 482     return Dimension(value)<br>\n483<br>\n484</p>\n<p>D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in <strong>init</strong>(self, value)<br>\n35       raise TypeError(\"Cannot convert %s to Dimension\" % value)<br>\n36     else:<br>\n---&gt; 37       self._value = int(value)<br>\n38       if (not isinstance(value, compat.bytes_or_text_types) and<br>\n39           self._value != value):</p>\n<p>TypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'`</p>", "body_text": "the error -------\n`TypeError                                 Traceback (most recent call last)\n in ()\n1 startTime=time.time()\n----> 2 image_model =tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet')\n3\n4 #image_model = inception_v4.create_model(weights='imagenet', include_top=True)\n5 new_input = image_model.input\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in InceptionResNetV2(include_top, weights, input_tensor, input_shape, pooling, classes)\n304   for block_idx in range(1, 11):\n305     x = inception_resnet_block(\n--> 306         x, scale=0.17, block_type='block35', block_idx=block_idx)\n307\n308   # Mixed 6a (Reduction-A block): 17 x 17 x 1088\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in inception_resnet_block(x, scale, block_type, block_idx, activation)\n187       output_shape=K.int_shape(x)[1:],\n188       arguments={'scale': scale},\n--> 189       name=block_name)([x, up])\n190   if activation is not None:\n191     x = Activation(activation, name=block_name + '_ac')(x)\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in call(self, inputs, *args, **kwargs)\n712           input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)\n713\n--> 714         output_shapes = self.compute_output_shape(input_shapes)\n715         output_shapes = nest.flatten(output_shapes)\n716         outputs = [\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py in compute_output_shape(self, input_shape)\n675\n676   def compute_output_shape(self, input_shape):\n--> 677     input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())\n678\n679     if self._output_shape is None:\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in init(self, dims)\n539       else:\n540         # Got a list of dimensions\n--> 541         self._dims = [as_dimension(d) for d in dims_iter]\n542     self._ndims = None\n543\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in (.0)\n539       else:\n540         # Got a list of dimensions\n--> 541         self._dims = [as_dimension(d) for d in dims_iter]\n542     self._ndims = None\n543\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in as_dimension(value)\n480     return value\n481   else:\n--> 482     return Dimension(value)\n483\n484\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in init(self, value)\n35       raise TypeError(\"Cannot convert %s to Dimension\" % value)\n36     else:\n---> 37       self._value = int(value)\n38       if (not isinstance(value, compat.bytes_or_text_types) and\n39           self._value != value):\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'`", "body": "\r\nthe error -------\r\n`TypeError                                 Traceback (most recent call last)\r\n<ipython-input-8-fe73201476b6> in <module>()\r\n      1 startTime=time.time()\r\n----> 2 image_model =tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet')\r\n      3 \r\n      4 #image_model = inception_v4.create_model(weights='imagenet', include_top=True)\r\n      5 new_input = image_model.input\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in InceptionResNetV2(include_top, weights, input_tensor, input_shape, pooling, classes)\r\n    304   for block_idx in range(1, 11):\r\n    305     x = inception_resnet_block(\r\n--> 306         x, scale=0.17, block_type='block35', block_idx=block_idx)\r\n    307 \r\n    308   # Mixed 6a (Reduction-A block): 17 x 17 x 1088\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in inception_resnet_block(x, scale, block_type, block_idx, activation)\r\n    187       output_shape=K.int_shape(x)[1:],\r\n    188       arguments={'scale': scale},\r\n--> 189       name=block_name)([x, up])\r\n    190   if activation is not None:\r\n    191     x = Activation(activation, name=block_name + '_ac')(x)\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    712           input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)\r\n    713 \r\n--> 714         output_shapes = self.compute_output_shape(input_shapes)\r\n    715         output_shapes = nest.flatten(output_shapes)\r\n    716         outputs = [\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py in compute_output_shape(self, input_shape)\r\n    675 \r\n    676   def compute_output_shape(self, input_shape):\r\n--> 677     input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())\r\n    678 \r\n    679     if self._output_shape is None:\r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in __init__(self, dims)\r\n    539       else:\r\n    540         # Got a list of dimensions\r\n--> 541         self._dims = [as_dimension(d) for d in dims_iter]\r\n    542     self._ndims = None\r\n    543 \r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in <listcomp>(.0)\r\n    539       else:\r\n    540         # Got a list of dimensions\r\n--> 541         self._dims = [as_dimension(d) for d in dims_iter]\r\n    542     self._ndims = None\r\n    543 \r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in as_dimension(value)\r\n    480     return value\r\n    481   else:\r\n--> 482     return Dimension(value)\r\n    483 \r\n    484 \r\n\r\nD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in __init__(self, value)\r\n     35       raise TypeError(\"Cannot convert %s to Dimension\" % value)\r\n     36     else:\r\n---> 37       self._value = int(value)\r\n     38       if (not isinstance(value, compat.bytes_or_text_types) and\r\n     39           self._value != value):\r\n\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'`"}