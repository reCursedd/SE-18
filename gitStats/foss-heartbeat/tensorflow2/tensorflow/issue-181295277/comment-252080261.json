{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/252080261", "html_url": "https://github.com/tensorflow/tensorflow/issues/4790#issuecomment-252080261", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4790", "id": 252080261, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MjA4MDI2MQ==", "user": {"login": "civilman628", "id": 8059551, "node_id": "MDQ6VXNlcjgwNTk1NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8059551?v=4", "gravatar_id": "", "url": "https://api.github.com/users/civilman628", "html_url": "https://github.com/civilman628", "followers_url": "https://api.github.com/users/civilman628/followers", "following_url": "https://api.github.com/users/civilman628/following{/other_user}", "gists_url": "https://api.github.com/users/civilman628/gists{/gist_id}", "starred_url": "https://api.github.com/users/civilman628/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/civilman628/subscriptions", "organizations_url": "https://api.github.com/users/civilman628/orgs", "repos_url": "https://api.github.com/users/civilman628/repos", "events_url": "https://api.github.com/users/civilman628/events{/privacy}", "received_events_url": "https://api.github.com/users/civilman628/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-06T20:34:00Z", "updated_at": "2016-10-16T05:58:03Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3376817\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrewharp\">@andrewharp</a> I try  optimize_for_inference.py, But it seems that the issue is still there.</p>\n<p>1, I freeze the .ckpt file into .pb file, which size is 24M<br>\n2, run optimize_for_inference.py to ouput a new file. This new .pb file is 23.9M, which means very limited nodes are removed, as size drop 0.1M.<br>\n3, convert this .pd file into 8bit file, which size is 6.5M as well.<br>\n4, load into iOS and run. the error is the same:</p>\n<p>No OpKernel was registered to support Op 'RandomUniform' with these attrs. Registered kernels</p>\n\n<p>The current iOS example for inception v1 model should be different from what we trained from PC. I can judge this solely by the file size. Does google plan to provide the instruction about how the other developers to convert the models, which are trained on GPU or CPU into iOS? Now we can only use the inception v1 model from iOS example, which is for ImageNet 1000 classes.</p>", "body_text": "@andrewharp I try  optimize_for_inference.py, But it seems that the issue is still there.\n1, I freeze the .ckpt file into .pb file, which size is 24M\n2, run optimize_for_inference.py to ouput a new file. This new .pb file is 23.9M, which means very limited nodes are removed, as size drop 0.1M.\n3, convert this .pd file into 8bit file, which size is 6.5M as well.\n4, load into iOS and run. the error is the same:\nNo OpKernel was registered to support Op 'RandomUniform' with these attrs. Registered kernels\n\nThe current iOS example for inception v1 model should be different from what we trained from PC. I can judge this solely by the file size. Does google plan to provide the instruction about how the other developers to convert the models, which are trained on GPU or CPU into iOS? Now we can only use the inception v1 model from iOS example, which is for ImageNet 1000 classes.", "body": "@andrewharp I try  optimize_for_inference.py, But it seems that the issue is still there.\n\n1, I freeze the .ckpt file into .pb file, which size is 24M\n2, run optimize_for_inference.py to ouput a new file. This new .pb file is 23.9M, which means very limited nodes are removed, as size drop 0.1M.\n3, convert this .pd file into 8bit file, which size is 6.5M as well.\n4, load into iOS and run. the error is the same:\n\nNo OpKernel was registered to support Op 'RandomUniform' with these attrs. Registered kernels\n\n<no registered kernels>\n\nThe current iOS example for inception v1 model should be different from what we trained from PC. I can judge this solely by the file size. Does google plan to provide the instruction about how the other developers to convert the models, which are trained on GPU or CPU into iOS? Now we can only use the inception v1 model from iOS example, which is for ImageNet 1000 classes.\n"}