{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/439223966", "html_url": "https://github.com/tensorflow/tensorflow/issues/12948#issuecomment-439223966", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12948", "id": 439223966, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTIyMzk2Ng==", "user": {"login": "Ouwen", "id": 5455421, "node_id": "MDQ6VXNlcjU0NTU0MjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5455421?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ouwen", "html_url": "https://github.com/Ouwen", "followers_url": "https://api.github.com/users/Ouwen/followers", "following_url": "https://api.github.com/users/Ouwen/following{/other_user}", "gists_url": "https://api.github.com/users/Ouwen/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ouwen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ouwen/subscriptions", "organizations_url": "https://api.github.com/users/Ouwen/orgs", "repos_url": "https://api.github.com/users/Ouwen/repos", "events_url": "https://api.github.com/users/Ouwen/events{/privacy}", "received_events_url": "https://api.github.com/users/Ouwen/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-15T23:11:08Z", "updated_at": "2018-11-16T19:08:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> I was wondering if you can provide some guidance here</p>\n<p>The <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/inplace_ops.py\"><code>inplace_ops</code></a> are great that they allow you to do <strong>writes</strong> to an already memory allocated tensor, but it would be nice to have inplace <strong>reads</strong>.</p>\n<ul>\n<li>\n<p>Perhaps we could modify <code>tf.slice</code> to have an option to not allocate new memory for an output tensor.<br>\nedit: seems like this is already the case but the slices must be <a href=\"https://stackoverflow.com/questions/50779869/does-tensorflow-tf-slice-incur-allocation-and-or-memory-copy/53343932#53343932\" rel=\"nofollow\">0 dim aligned</a>.</p>\n</li>\n<li>\n<p>I was also wondering if <code>tf.TensorArray</code> could be utilized here instead of the <code>inplace_ops</code> where we just <code>concat</code> as the <code>tf.TensorArray</code> grows. However, it seems like this would be inefficient on GPUs (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"328900636\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/19733\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/19733/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/19733\">#19733</a>)</p>\n</li>\n</ul>", "body_text": "@drpngx I was wondering if you can provide some guidance here\nThe inplace_ops are great that they allow you to do writes to an already memory allocated tensor, but it would be nice to have inplace reads.\n\n\nPerhaps we could modify tf.slice to have an option to not allocate new memory for an output tensor.\nedit: seems like this is already the case but the slices must be 0 dim aligned.\n\n\nI was also wondering if tf.TensorArray could be utilized here instead of the inplace_ops where we just concat as the tf.TensorArray grows. However, it seems like this would be inefficient on GPUs (#19733)", "body": "@drpngx I was wondering if you can provide some guidance here\r\n\r\nThe [`inplace_ops`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/inplace_ops.py) are great that they allow you to do **writes** to an already memory allocated tensor, but it would be nice to have inplace **reads**.\r\n\r\n* Perhaps we could modify `tf.slice` to have an option to not allocate new memory for an output tensor.\r\nedit: seems like this is already the case but the slices must be [0 dim aligned](https://stackoverflow.com/questions/50779869/does-tensorflow-tf-slice-incur-allocation-and-or-memory-copy/53343932#53343932).\r\n\r\n* I was also wondering if `tf.TensorArray` could be utilized here instead of the `inplace_ops` where we just `concat` as the `tf.TensorArray` grows. However, it seems like this would be inefficient on GPUs (#19733)"}