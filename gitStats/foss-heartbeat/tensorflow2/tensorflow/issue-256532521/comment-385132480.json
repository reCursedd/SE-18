{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385132480", "html_url": "https://github.com/tensorflow/tensorflow/issues/12948#issuecomment-385132480", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12948", "id": 385132480, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTEzMjQ4MA==", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-28T02:14:42Z", "updated_at": "2018-04-28T02:14:42Z", "author_association": "MEMBER", "body_html": "<p>So, we finally pushed the feature. You can implement gradient checkpointing with that as well.</p>\n<p>You can take a look at <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/recurrent/python/ops/recurrent.py\"><code>recurrent.py</code></a>. It uses the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/inplace_ops.py\"><code>inplace_ops</code></a> that allow to  write to parts of a tensor. Effectively you can manage a large tensor as a random memory access buffer.</p>", "body_text": "So, we finally pushed the feature. You can implement gradient checkpointing with that as well.\nYou can take a look at recurrent.py. It uses the inplace_ops that allow to  write to parts of a tensor. Effectively you can manage a large tensor as a random memory access buffer.", "body": "So, we finally pushed the feature. You can implement gradient checkpointing with that as well.\r\n\r\nYou can take a look at [`recurrent.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/recurrent/python/ops/recurrent.py). It uses the [`inplace_ops`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/inplace_ops.py) that allow to  write to parts of a tensor. Effectively you can manage a large tensor as a random memory access buffer."}