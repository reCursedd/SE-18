{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2984", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2984/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2984/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2984/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2984", "id": 161551234, "node_id": "MDU6SXNzdWUxNjE1NTEyMzQ=", "number": 2984, "title": "Multiple Towers Not Applying Updates", "user": {"login": "ischlag", "id": 7107156, "node_id": "MDQ6VXNlcjcxMDcxNTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/7107156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ischlag", "html_url": "https://github.com/ischlag", "followers_url": "https://api.github.com/users/ischlag/followers", "following_url": "https://api.github.com/users/ischlag/following{/other_user}", "gists_url": "https://api.github.com/users/ischlag/gists{/gist_id}", "starred_url": "https://api.github.com/users/ischlag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ischlag/subscriptions", "organizations_url": "https://api.github.com/users/ischlag/orgs", "repos_url": "https://api.github.com/users/ischlag/repos", "events_url": "https://api.github.com/users/ischlag/events{/privacy}", "received_events_url": "https://api.github.com/users/ischlag/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-06-21T22:08:25Z", "updated_at": "2016-06-22T01:01:13Z", "closed_at": "2016-06-22T01:01:13Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>All 4 machines: 4.1.13-100.fc21.x86_64</p>\n<p>Setting 1:<br>\n1 machine with 1x 960 GTX (one of the workers from below)</p>\n<p>Setting 2:<br>\n1 machine with cpu (parameter server)<br>\n3 machines with 1x 960 GTX (worker)</p>\n<p>tensorflow 0.9.0, cudNN v4</p>\n<h3>Problem</h3>\n<p>I can train a mnist example on both settings while using the same input pipeline as in the following scripts.</p>\n<p>The following two scripts are almost identical but one is made to work on Setting 1 while the other one is made for Setting 2 to work in a distributed, parameter sharing, data parallelism manner. The scripts operates on a small set with coin images with 2 classes.</p>\n<p>Single Machine Script (Setting 1): <a href=\"https://gist.github.com/ischlag/96b10519a45727bd17fe0cce01c1bd15\">https://gist.github.com/ischlag/96b10519a45727bd17fe0cce01c1bd15</a><br>\nDistributed Script (Setting 2): <a href=\"https://gist.github.com/ischlag/d9fc4429971ce7c1957798de30c56372\">https://gist.github.com/ischlag/d9fc4429971ce7c1957798de30c56372</a></p>\n<p>The Single machine script works as expected and can generalize well:<br>\n'''<br>\nSession started!<br>\nPartial-Epoch Avg Error:  0.692565  AvgMsPerBatch: 0.56 ms<br>\nPartial-Epoch Avg Error:  0.686972  AvgMsPerBatch: 0.49 ms<br>\nPartial-Epoch Avg Error:  0.671962  AvgMsPerBatch: 0.46 ms<br>\nPartial-Epoch Avg Error:  0.645295  AvgMsPerBatch: 0.47 ms<br>\nPartial-Epoch Avg Error:  0.59795  AvgMsPerBatch: 0.47 ms<br>\nPartial-Epoch Avg Error:  0.607252  AvgMsPerBatch: 0.47 ms<br>\nPartial-Epoch Avg Error:  0.548216  AvgMsPerBatch: 0.49 ms<br>\nPartial-Epoch Avg Error:  0.5107  AvgMsPerBatch: 0.49 ms<br>\nPartial-Epoch Avg Error:  0.492883  AvgMsPerBatch: 0.47 ms<br>\nPartial-Epoch Avg Error:  0.466268  AvgMsPerBatch: 0.48 ms<br>\nPartial-Epoch Avg Error:  0.431923  AvgMsPerBatch: 0.49 ms<br>\nPartial-Epoch Avg Error:  0.407919  AvgMsPerBatch: 0.48 ms<br>\nPartial-Epoch Avg Error:  0.387163  AvgMsPerBatch: 0.47 ms<br>\nPartial-Epoch Avg Error:  0.340534  AvgMsPerBatch: 0.47 ms<br>\nPartial-Epoch Avg Error:  0.349155  AvgMsPerBatch: 0.47 ms<br>\nPartial-Epoch Avg Error:  0.327694  AvgMsPerBatch: 0.47 ms<br>\nPartial-Epoch Avg Error:  0.244313  AvgMsPerBatch: 0.46 ms<br>\nPartial-Epoch Avg Error:  0.256759  AvgMsPerBatch: 0.46 ms<br>\nPartial-Epoch Avg Error:  0.206276  AvgMsPerBatch: 0.46 ms<br>\nPartial-Epoch Avg Error:  0.184809  AvgMsPerBatch: 0.46 ms<br>\nPartial-Epoch Avg Error:  0.187335  AvgMsPerBatch: 0.46 ms<br>\n'''<br>\nThe distributed script is quite slower and fails to update the parameters.<br>\n'''<br>\nSession started!<br>\nPartial-Epoch Avg Error:  0.69339  AvgMsPerBatch: 3.25 ms<br>\nPartial-Epoch Avg Error:  0.692113  AvgMsPerBatch: 3.27 ms<br>\nPartial-Epoch Avg Error:  0.693958  AvgMsPerBatch: 3.27 ms<br>\nPartial-Epoch Avg Error:  0.688354  AvgMsPerBatch: 3.26 ms<br>\nPartial-Epoch Avg Error:  0.692994  AvgMsPerBatch: 3.25 ms<br>\nPartial-Epoch Avg Error:  0.692903  AvgMsPerBatch: 3.24 ms<br>\nPartial-Epoch Avg Error:  0.691708  AvgMsPerBatch: 3.29 ms<br>\nPartial-Epoch Avg Error:  0.691477  AvgMsPerBatch: 3.35 ms<br>\nPartial-Epoch Avg Error:  0.69129  AvgMsPerBatch: 3.37 ms<br>\nPartial-Epoch Avg Error:  0.691391  AvgMsPerBatch: 3.35 ms<br>\nPartial-Epoch Avg Error:  0.691415  AvgMsPerBatch: 3.30 ms<br>\nPartial-Epoch Avg Error:  0.69209  AvgMsPerBatch: 3.30 ms<br>\nPartial-Epoch Avg Error:  0.691746  AvgMsPerBatch: 3.32 ms<br>\nPartial-Epoch Avg Error:  0.690423  AvgMsPerBatch: 3.31 ms<br>\nPartial-Epoch Avg Error:  0.692738  AvgMsPerBatch: 3.30 ms<br>\n'''</p>\n<p>The same distributed script works well with the mnist dataset in a distributed manner. All the lines necessary to run it with mnist are there but commented out.</p>\n<p>Why is my distributed script not working in this case?</p>", "body_text": "Environment info\nAll 4 machines: 4.1.13-100.fc21.x86_64\nSetting 1:\n1 machine with 1x 960 GTX (one of the workers from below)\nSetting 2:\n1 machine with cpu (parameter server)\n3 machines with 1x 960 GTX (worker)\ntensorflow 0.9.0, cudNN v4\nProblem\nI can train a mnist example on both settings while using the same input pipeline as in the following scripts.\nThe following two scripts are almost identical but one is made to work on Setting 1 while the other one is made for Setting 2 to work in a distributed, parameter sharing, data parallelism manner. The scripts operates on a small set with coin images with 2 classes.\nSingle Machine Script (Setting 1): https://gist.github.com/ischlag/96b10519a45727bd17fe0cce01c1bd15\nDistributed Script (Setting 2): https://gist.github.com/ischlag/d9fc4429971ce7c1957798de30c56372\nThe Single machine script works as expected and can generalize well:\n'''\nSession started!\nPartial-Epoch Avg Error:  0.692565  AvgMsPerBatch: 0.56 ms\nPartial-Epoch Avg Error:  0.686972  AvgMsPerBatch: 0.49 ms\nPartial-Epoch Avg Error:  0.671962  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.645295  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.59795  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.607252  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.548216  AvgMsPerBatch: 0.49 ms\nPartial-Epoch Avg Error:  0.5107  AvgMsPerBatch: 0.49 ms\nPartial-Epoch Avg Error:  0.492883  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.466268  AvgMsPerBatch: 0.48 ms\nPartial-Epoch Avg Error:  0.431923  AvgMsPerBatch: 0.49 ms\nPartial-Epoch Avg Error:  0.407919  AvgMsPerBatch: 0.48 ms\nPartial-Epoch Avg Error:  0.387163  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.340534  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.349155  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.327694  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.244313  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.256759  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.206276  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.184809  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.187335  AvgMsPerBatch: 0.46 ms\n'''\nThe distributed script is quite slower and fails to update the parameters.\n'''\nSession started!\nPartial-Epoch Avg Error:  0.69339  AvgMsPerBatch: 3.25 ms\nPartial-Epoch Avg Error:  0.692113  AvgMsPerBatch: 3.27 ms\nPartial-Epoch Avg Error:  0.693958  AvgMsPerBatch: 3.27 ms\nPartial-Epoch Avg Error:  0.688354  AvgMsPerBatch: 3.26 ms\nPartial-Epoch Avg Error:  0.692994  AvgMsPerBatch: 3.25 ms\nPartial-Epoch Avg Error:  0.692903  AvgMsPerBatch: 3.24 ms\nPartial-Epoch Avg Error:  0.691708  AvgMsPerBatch: 3.29 ms\nPartial-Epoch Avg Error:  0.691477  AvgMsPerBatch: 3.35 ms\nPartial-Epoch Avg Error:  0.69129  AvgMsPerBatch: 3.37 ms\nPartial-Epoch Avg Error:  0.691391  AvgMsPerBatch: 3.35 ms\nPartial-Epoch Avg Error:  0.691415  AvgMsPerBatch: 3.30 ms\nPartial-Epoch Avg Error:  0.69209  AvgMsPerBatch: 3.30 ms\nPartial-Epoch Avg Error:  0.691746  AvgMsPerBatch: 3.32 ms\nPartial-Epoch Avg Error:  0.690423  AvgMsPerBatch: 3.31 ms\nPartial-Epoch Avg Error:  0.692738  AvgMsPerBatch: 3.30 ms\n'''\nThe same distributed script works well with the mnist dataset in a distributed manner. All the lines necessary to run it with mnist are there but commented out.\nWhy is my distributed script not working in this case?", "body": "### Environment info\n\nAll 4 machines: 4.1.13-100.fc21.x86_64\n\nSetting 1:\n1 machine with 1x 960 GTX (one of the workers from below)\n\nSetting 2:\n1 machine with cpu (parameter server)\n3 machines with 1x 960 GTX (worker)\n\ntensorflow 0.9.0, cudNN v4\n### Problem\n\nI can train a mnist example on both settings while using the same input pipeline as in the following scripts.\n\nThe following two scripts are almost identical but one is made to work on Setting 1 while the other one is made for Setting 2 to work in a distributed, parameter sharing, data parallelism manner. The scripts operates on a small set with coin images with 2 classes.\n\nSingle Machine Script (Setting 1): https://gist.github.com/ischlag/96b10519a45727bd17fe0cce01c1bd15\nDistributed Script (Setting 2): https://gist.github.com/ischlag/d9fc4429971ce7c1957798de30c56372\n\nThe Single machine script works as expected and can generalize well:\n'''\nSession started!\nPartial-Epoch Avg Error:  0.692565  AvgMsPerBatch: 0.56 ms\nPartial-Epoch Avg Error:  0.686972  AvgMsPerBatch: 0.49 ms\nPartial-Epoch Avg Error:  0.671962  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.645295  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.59795  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.607252  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.548216  AvgMsPerBatch: 0.49 ms\nPartial-Epoch Avg Error:  0.5107  AvgMsPerBatch: 0.49 ms\nPartial-Epoch Avg Error:  0.492883  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.466268  AvgMsPerBatch: 0.48 ms\nPartial-Epoch Avg Error:  0.431923  AvgMsPerBatch: 0.49 ms\nPartial-Epoch Avg Error:  0.407919  AvgMsPerBatch: 0.48 ms\nPartial-Epoch Avg Error:  0.387163  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.340534  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.349155  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.327694  AvgMsPerBatch: 0.47 ms\nPartial-Epoch Avg Error:  0.244313  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.256759  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.206276  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.184809  AvgMsPerBatch: 0.46 ms\nPartial-Epoch Avg Error:  0.187335  AvgMsPerBatch: 0.46 ms\n'''\nThe distributed script is quite slower and fails to update the parameters.\n''' \nSession started!\nPartial-Epoch Avg Error:  0.69339  AvgMsPerBatch: 3.25 ms\nPartial-Epoch Avg Error:  0.692113  AvgMsPerBatch: 3.27 ms\nPartial-Epoch Avg Error:  0.693958  AvgMsPerBatch: 3.27 ms\nPartial-Epoch Avg Error:  0.688354  AvgMsPerBatch: 3.26 ms\nPartial-Epoch Avg Error:  0.692994  AvgMsPerBatch: 3.25 ms\nPartial-Epoch Avg Error:  0.692903  AvgMsPerBatch: 3.24 ms\nPartial-Epoch Avg Error:  0.691708  AvgMsPerBatch: 3.29 ms\nPartial-Epoch Avg Error:  0.691477  AvgMsPerBatch: 3.35 ms\nPartial-Epoch Avg Error:  0.69129  AvgMsPerBatch: 3.37 ms\nPartial-Epoch Avg Error:  0.691391  AvgMsPerBatch: 3.35 ms\nPartial-Epoch Avg Error:  0.691415  AvgMsPerBatch: 3.30 ms\nPartial-Epoch Avg Error:  0.69209  AvgMsPerBatch: 3.30 ms\nPartial-Epoch Avg Error:  0.691746  AvgMsPerBatch: 3.32 ms\nPartial-Epoch Avg Error:  0.690423  AvgMsPerBatch: 3.31 ms\nPartial-Epoch Avg Error:  0.692738  AvgMsPerBatch: 3.30 ms\n''' \n\nThe same distributed script works well with the mnist dataset in a distributed manner. All the lines necessary to run it with mnist are there but commented out.\n\nWhy is my distributed script not working in this case?\n"}