{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12150", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12150/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12150/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12150/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12150", "id": 249090946, "node_id": "MDU6SXNzdWUyNDkwOTA5NDY=", "number": 12150, "title": "Unable to load saved model", "user": {"login": "prashantmaheshwari94", "id": 21172374, "node_id": "MDQ6VXNlcjIxMTcyMzc0", "avatar_url": "https://avatars0.githubusercontent.com/u/21172374?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prashantmaheshwari94", "html_url": "https://github.com/prashantmaheshwari94", "followers_url": "https://api.github.com/users/prashantmaheshwari94/followers", "following_url": "https://api.github.com/users/prashantmaheshwari94/following{/other_user}", "gists_url": "https://api.github.com/users/prashantmaheshwari94/gists{/gist_id}", "starred_url": "https://api.github.com/users/prashantmaheshwari94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prashantmaheshwari94/subscriptions", "organizations_url": "https://api.github.com/users/prashantmaheshwari94/orgs", "repos_url": "https://api.github.com/users/prashantmaheshwari94/repos", "events_url": "https://api.github.com/users/prashantmaheshwari94/events{/privacy}", "received_events_url": "https://api.github.com/users/prashantmaheshwari94/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-08-09T16:37:59Z", "updated_at": "2018-04-17T08:37:03Z", "closed_at": "2017-08-09T19:24:17Z", "author_association": "NONE", "body_html": "<p>I am facing similar issue but for GRU. I am using tensorflow  1.1.0 and I tried dumping the model in different ways:<br>\na)          saver = tf.train.Saver(tf.global_variables())<br>\nmodel_exporter = exporter.Exporter(saver)</p>\n<pre><code>    # Restore variables from training checkpoint\n    # TODO: This restores the most recent checkpoint, but if we use validation to counterract\n    #       over-fitting, we may want to restore an earlier checkpoint.\n    checkpoint = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n    checkpoint_path = checkpoint.model_checkpoint_path\n    saver.restore(session, checkpoint_path)\n    log_info('Restored checkpoint at training epoch %d' % (int(checkpoint_path.split('-')[-1]) + 1))\n\n    # Initialise the model exporter and export the model\n    model_exporter.init(session.graph.as_graph_def(),\n                        named_graph_signatures = {\n                            'inputs': exporter.generic_signature(\n                                { 'input': input_tensor,\n                                  'input_lengths': seq_length}),\n                            'outputs': exporter.generic_signature(\n                                { 'outputs': decoded})})\n    if FLAGS.remove_export:\n        actual_export_dir = os.path.join(FLAGS.export_dir, '%08d' % FLAGS.export_version)\n        if os.path.isdir(actual_export_dir):\n            log_info('Removing old export')\n            shutil.rmtree(actual_FLAGS.export_dir)\n    try:\n        # Export serving model\n        model_exporter.export(FLAGS.export_dir, tf.constant(FLAGS.export_version), session)\n\n        # Export graph\n        input_graph_name = 'input_graph.pb'\n        tf.train.write_graph(session.graph, FLAGS.export_dir, input_graph_name, as_text=False)\n\n        # Freeze graph\n        input_graph_path = os.path.join(FLAGS.export_dir, input_graph_name)\n        input_saver_def_path = ''\n        input_binary = True\n        output_node_names = 'output_node'\n        restore_op_name = 'save/restore_all'\n        filename_tensor_name = 'save/Const:0'\n        output_graph_path = os.path.join(FLAGS.export_dir, 'output_graph.pb')\n        clear_devices = False\n        freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n                                  input_binary, checkpoint_path, output_node_names,\n                                  restore_op_name, filename_tensor_name,\n                                  output_graph_path, clear_devices, '')\n</code></pre>\n<p>b)          output_graph_def = graph_util.convert_variables_to_constants(session, session.graph.as_graph_def(), ['output_node'])<br>\nwith gfile.FastGFile('./data/ldc93s1/output_graph2.pb', 'wb') as f:<br>\nf.write(output_graph_def.SerializeToString())</p>\n<p>but for both the dump I get the following error: -<br>\n'rnn/while/multi_rnn_cell/cell_0/gru_cell/gates/r/cond/rnn/while/multi_rnn_cell/cell_0/gru_cell/gates/r/strided_slice/_assign/RefEnter': Input tensor 'rnn/multi_rnn_cell/cell_0/gru_cell/gates/r/pop_mean:0' <strong>Cannot convert a tensor of type float32 to an input of type float32_ref</strong></p>\n<p>Any solution so far?<br>\nI followed the similar bug but that is specifically related to Batch norm <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"169195660\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3628\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3628/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/3628\">#3628</a> . And what is the reason behind this??</p>", "body_text": "I am facing similar issue but for GRU. I am using tensorflow  1.1.0 and I tried dumping the model in different ways:\na)          saver = tf.train.Saver(tf.global_variables())\nmodel_exporter = exporter.Exporter(saver)\n    # Restore variables from training checkpoint\n    # TODO: This restores the most recent checkpoint, but if we use validation to counterract\n    #       over-fitting, we may want to restore an earlier checkpoint.\n    checkpoint = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n    checkpoint_path = checkpoint.model_checkpoint_path\n    saver.restore(session, checkpoint_path)\n    log_info('Restored checkpoint at training epoch %d' % (int(checkpoint_path.split('-')[-1]) + 1))\n\n    # Initialise the model exporter and export the model\n    model_exporter.init(session.graph.as_graph_def(),\n                        named_graph_signatures = {\n                            'inputs': exporter.generic_signature(\n                                { 'input': input_tensor,\n                                  'input_lengths': seq_length}),\n                            'outputs': exporter.generic_signature(\n                                { 'outputs': decoded})})\n    if FLAGS.remove_export:\n        actual_export_dir = os.path.join(FLAGS.export_dir, '%08d' % FLAGS.export_version)\n        if os.path.isdir(actual_export_dir):\n            log_info('Removing old export')\n            shutil.rmtree(actual_FLAGS.export_dir)\n    try:\n        # Export serving model\n        model_exporter.export(FLAGS.export_dir, tf.constant(FLAGS.export_version), session)\n\n        # Export graph\n        input_graph_name = 'input_graph.pb'\n        tf.train.write_graph(session.graph, FLAGS.export_dir, input_graph_name, as_text=False)\n\n        # Freeze graph\n        input_graph_path = os.path.join(FLAGS.export_dir, input_graph_name)\n        input_saver_def_path = ''\n        input_binary = True\n        output_node_names = 'output_node'\n        restore_op_name = 'save/restore_all'\n        filename_tensor_name = 'save/Const:0'\n        output_graph_path = os.path.join(FLAGS.export_dir, 'output_graph.pb')\n        clear_devices = False\n        freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n                                  input_binary, checkpoint_path, output_node_names,\n                                  restore_op_name, filename_tensor_name,\n                                  output_graph_path, clear_devices, '')\n\nb)          output_graph_def = graph_util.convert_variables_to_constants(session, session.graph.as_graph_def(), ['output_node'])\nwith gfile.FastGFile('./data/ldc93s1/output_graph2.pb', 'wb') as f:\nf.write(output_graph_def.SerializeToString())\nbut for both the dump I get the following error: -\n'rnn/while/multi_rnn_cell/cell_0/gru_cell/gates/r/cond/rnn/while/multi_rnn_cell/cell_0/gru_cell/gates/r/strided_slice/_assign/RefEnter': Input tensor 'rnn/multi_rnn_cell/cell_0/gru_cell/gates/r/pop_mean:0' Cannot convert a tensor of type float32 to an input of type float32_ref\nAny solution so far?\nI followed the similar bug but that is specifically related to Batch norm #3628 . And what is the reason behind this??", "body": "I am facing similar issue but for GRU. I am using tensorflow  1.1.0 and I tried dumping the model in different ways: \r\na)          saver = tf.train.Saver(tf.global_variables())\r\n        model_exporter = exporter.Exporter(saver)\r\n\r\n        # Restore variables from training checkpoint\r\n        # TODO: This restores the most recent checkpoint, but if we use validation to counterract\r\n        #       over-fitting, we may want to restore an earlier checkpoint.\r\n        checkpoint = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\r\n        checkpoint_path = checkpoint.model_checkpoint_path\r\n        saver.restore(session, checkpoint_path)\r\n        log_info('Restored checkpoint at training epoch %d' % (int(checkpoint_path.split('-')[-1]) + 1))\r\n\r\n        # Initialise the model exporter and export the model\r\n        model_exporter.init(session.graph.as_graph_def(),\r\n                            named_graph_signatures = {\r\n                                'inputs': exporter.generic_signature(\r\n                                    { 'input': input_tensor,\r\n                                      'input_lengths': seq_length}),\r\n                                'outputs': exporter.generic_signature(\r\n                                    { 'outputs': decoded})})\r\n        if FLAGS.remove_export:\r\n            actual_export_dir = os.path.join(FLAGS.export_dir, '%08d' % FLAGS.export_version)\r\n            if os.path.isdir(actual_export_dir):\r\n                log_info('Removing old export')\r\n                shutil.rmtree(actual_FLAGS.export_dir)\r\n        try:\r\n            # Export serving model\r\n            model_exporter.export(FLAGS.export_dir, tf.constant(FLAGS.export_version), session)\r\n\r\n            # Export graph\r\n            input_graph_name = 'input_graph.pb'\r\n            tf.train.write_graph(session.graph, FLAGS.export_dir, input_graph_name, as_text=False)\r\n\r\n            # Freeze graph\r\n            input_graph_path = os.path.join(FLAGS.export_dir, input_graph_name)\r\n            input_saver_def_path = ''\r\n            input_binary = True\r\n            output_node_names = 'output_node'\r\n            restore_op_name = 'save/restore_all'\r\n            filename_tensor_name = 'save/Const:0'\r\n            output_graph_path = os.path.join(FLAGS.export_dir, 'output_graph.pb')\r\n            clear_devices = False\r\n            freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\r\n                                      input_binary, checkpoint_path, output_node_names,\r\n                                      restore_op_name, filename_tensor_name,\r\n                                      output_graph_path, clear_devices, '')\r\nb)          output_graph_def = graph_util.convert_variables_to_constants(session, session.graph.as_graph_def(), ['output_node'])\r\n        with gfile.FastGFile('./data/ldc93s1/output_graph2.pb', 'wb') as f:\r\n            f.write(output_graph_def.SerializeToString())\r\n\r\nbut for both the dump I get the following error: -\r\n'rnn/while/multi_rnn_cell/cell_0/gru_cell/gates/r/cond/rnn/while/multi_rnn_cell/cell_0/gru_cell/gates/r/strided_slice/_assign/RefEnter': Input tensor 'rnn/multi_rnn_cell/cell_0/gru_cell/gates/r/pop_mean:0' **Cannot convert a tensor of type float32 to an input of type float32_ref**\r\n\r\nAny solution so far? \r\nI followed the similar bug but that is specifically related to Batch norm #3628 . And what is the reason behind this??\r\n"}