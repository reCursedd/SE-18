{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19437", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19437/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19437/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19437/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19437", "id": 324942897, "node_id": "MDU6SXNzdWUzMjQ5NDI4OTc=", "number": 19437, "title": "My tensorflow model doesn't work on c++ iOS", "user": {"login": "cagrigider", "id": 28455404, "node_id": "MDQ6VXNlcjI4NDU1NDA0", "avatar_url": "https://avatars0.githubusercontent.com/u/28455404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cagrigider", "html_url": "https://github.com/cagrigider", "followers_url": "https://api.github.com/users/cagrigider/followers", "following_url": "https://api.github.com/users/cagrigider/following{/other_user}", "gists_url": "https://api.github.com/users/cagrigider/gists{/gist_id}", "starred_url": "https://api.github.com/users/cagrigider/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cagrigider/subscriptions", "organizations_url": "https://api.github.com/users/cagrigider/orgs", "repos_url": "https://api.github.com/users/cagrigider/repos", "events_url": "https://api.github.com/users/cagrigider/events{/privacy}", "received_events_url": "https://api.github.com/users/cagrigider/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-21T14:44:58Z", "updated_at": "2018-06-15T20:22:04Z", "closed_at": "2018-06-15T20:22:04Z", "author_association": "NONE", "body_html": "<p>I am trying to do character recognition mobile app with CNN. My model predict with %99,6 accuracy on python. But when I m trying to use same model with c++ in iOS app it can't predict any value.</p>\n<p>I am getting pixelBuffer values from images for my cnn model with this:</p>\n<pre><code>    pixelBuffer(width: width, height: height,\n                       pixelFormatType: kCVPixelFormatType_32BGRA,\n                       colorSpace: CGColorSpaceCreateDeviceRGB(),\n                       alphaInfo: .noneSkipFirst)\n\nfunc pixelBuffer(width: Int, height: Int, pixelFormatType: OSType,\n                 colorSpace: CGColorSpace, alphaInfo: CGImageAlphaInfo) -&gt; CVPixelBuffer? {\n    var maybePixelBuffer: CVPixelBuffer?\n    let attrs = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,\n                 kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue]\n    let status = CVPixelBufferCreate(kCFAllocatorDefault,\n                                     width,\n                                     height,\n                                     pixelFormatType,\n                                     attrs as CFDictionary,\n                                     &amp;maybePixelBuffer)\n    \n    guard status == kCVReturnSuccess, let pixelBuffer = maybePixelBuffer else {\n        return nil\n    }\n    \n    CVPixelBufferLockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))\n    let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer)\n    \n    guard let context = CGContext(data: pixelData,\n                                  width: width,\n                                  height: height,\n                                  bitsPerComponent: 8,\n                                  bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer),\n                                  space: colorSpace,\n                                  bitmapInfo: alphaInfo.rawValue)\n        else {\n            return nil\n    }\n    \n    UIGraphicsPushContext(context)\n    context.translateBy(x: 0, y: CGFloat(height))\n    context.scaleBy(x: 1, y: -1)\n    self.draw(in: CGRect(x: 0, y: 0, width: width, height: height))\n    UIGraphicsPopContext()\n    \n    CVPixelBufferUnlockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))\n    return pixelBuffer}\n</code></pre>\n<p>and then I m creating my model with this settings:</p>\n<pre><code>    static NSString* model_file_name = @\"inference_1_1_0\";\n    static NSString* model_file_type = @\"pb\";\n    static NSString* labels_file_name = @\"labels\";\n    static NSString* labels_file_type = @\"txt\";\n    std::unique_ptr&lt;tensorflow::Session&gt; tf_session;\n    std::vector&lt;std::string&gt; labels;\n\n    const int wanted_input_width = 38;\n    const int wanted_input_height = 45;\n    const int wanted_input_channels = 3;\n    const float input_mean = 117.0f;\n    const float input_std = 1.0f;\n    const std::string input_layer_name = \"input_input\";\n    const std::string output_layer_name = \"output_node0\";\n</code></pre>\n<p>but I have no idea what should I use for <code>input_mean</code> and <code>input_std</code> . Maybe they can be problem.<br>\nI got runCNN method default from <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/ios/camera/CameraExampleViewController.mm\">Tensorflow Example</a></p>\n<p>I really have no idea my image is wrong or should I change any default settings from tensorflow</p>\n<p>Thanks.</p>\n<ul>\n<li>Have I written custom code: Yes</li>\n<li>OS Platform and Distribution: Mac OS 10.13.3 High Sierra</li>\n<li>TensorFlow installed from (source or binary): source</li>\n<li>TensorFlow version: 1.1.0 on Mac (Tensorflow-Experimental on iOS)</li>\n<li>Python version: 3</li>\n<li>Bazel version: 0.13.0</li>\n<li>CUDA/cuDNN: N/A</li>\n<li>GPU model and Memory: N/A</li>\n<li>Exact command to reproduce: When I am trying to predict with my model it's always predict wrong.(Prediction)</li>\n</ul>", "body_text": "I am trying to do character recognition mobile app with CNN. My model predict with %99,6 accuracy on python. But when I m trying to use same model with c++ in iOS app it can't predict any value.\nI am getting pixelBuffer values from images for my cnn model with this:\n    pixelBuffer(width: width, height: height,\n                       pixelFormatType: kCVPixelFormatType_32BGRA,\n                       colorSpace: CGColorSpaceCreateDeviceRGB(),\n                       alphaInfo: .noneSkipFirst)\n\nfunc pixelBuffer(width: Int, height: Int, pixelFormatType: OSType,\n                 colorSpace: CGColorSpace, alphaInfo: CGImageAlphaInfo) -> CVPixelBuffer? {\n    var maybePixelBuffer: CVPixelBuffer?\n    let attrs = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,\n                 kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue]\n    let status = CVPixelBufferCreate(kCFAllocatorDefault,\n                                     width,\n                                     height,\n                                     pixelFormatType,\n                                     attrs as CFDictionary,\n                                     &maybePixelBuffer)\n    \n    guard status == kCVReturnSuccess, let pixelBuffer = maybePixelBuffer else {\n        return nil\n    }\n    \n    CVPixelBufferLockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))\n    let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer)\n    \n    guard let context = CGContext(data: pixelData,\n                                  width: width,\n                                  height: height,\n                                  bitsPerComponent: 8,\n                                  bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer),\n                                  space: colorSpace,\n                                  bitmapInfo: alphaInfo.rawValue)\n        else {\n            return nil\n    }\n    \n    UIGraphicsPushContext(context)\n    context.translateBy(x: 0, y: CGFloat(height))\n    context.scaleBy(x: 1, y: -1)\n    self.draw(in: CGRect(x: 0, y: 0, width: width, height: height))\n    UIGraphicsPopContext()\n    \n    CVPixelBufferUnlockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))\n    return pixelBuffer}\n\nand then I m creating my model with this settings:\n    static NSString* model_file_name = @\"inference_1_1_0\";\n    static NSString* model_file_type = @\"pb\";\n    static NSString* labels_file_name = @\"labels\";\n    static NSString* labels_file_type = @\"txt\";\n    std::unique_ptr<tensorflow::Session> tf_session;\n    std::vector<std::string> labels;\n\n    const int wanted_input_width = 38;\n    const int wanted_input_height = 45;\n    const int wanted_input_channels = 3;\n    const float input_mean = 117.0f;\n    const float input_std = 1.0f;\n    const std::string input_layer_name = \"input_input\";\n    const std::string output_layer_name = \"output_node0\";\n\nbut I have no idea what should I use for input_mean and input_std . Maybe they can be problem.\nI got runCNN method default from Tensorflow Example\nI really have no idea my image is wrong or should I change any default settings from tensorflow\nThanks.\n\nHave I written custom code: Yes\nOS Platform and Distribution: Mac OS 10.13.3 High Sierra\nTensorFlow installed from (source or binary): source\nTensorFlow version: 1.1.0 on Mac (Tensorflow-Experimental on iOS)\nPython version: 3\nBazel version: 0.13.0\nCUDA/cuDNN: N/A\nGPU model and Memory: N/A\nExact command to reproduce: When I am trying to predict with my model it's always predict wrong.(Prediction)", "body": "I am trying to do character recognition mobile app with CNN. My model predict with %99,6 accuracy on python. But when I m trying to use same model with c++ in iOS app it can't predict any value. \r\n\r\nI am getting pixelBuffer values from images for my cnn model with this:\r\n\r\n        pixelBuffer(width: width, height: height,\r\n                           pixelFormatType: kCVPixelFormatType_32BGRA,\r\n                           colorSpace: CGColorSpaceCreateDeviceRGB(),\r\n                           alphaInfo: .noneSkipFirst)\r\n\r\n    func pixelBuffer(width: Int, height: Int, pixelFormatType: OSType,\r\n                     colorSpace: CGColorSpace, alphaInfo: CGImageAlphaInfo) -> CVPixelBuffer? {\r\n        var maybePixelBuffer: CVPixelBuffer?\r\n        let attrs = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,\r\n                     kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue]\r\n        let status = CVPixelBufferCreate(kCFAllocatorDefault,\r\n                                         width,\r\n                                         height,\r\n                                         pixelFormatType,\r\n                                         attrs as CFDictionary,\r\n                                         &maybePixelBuffer)\r\n        \r\n        guard status == kCVReturnSuccess, let pixelBuffer = maybePixelBuffer else {\r\n            return nil\r\n        }\r\n        \r\n        CVPixelBufferLockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))\r\n        let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer)\r\n        \r\n        guard let context = CGContext(data: pixelData,\r\n                                      width: width,\r\n                                      height: height,\r\n                                      bitsPerComponent: 8,\r\n                                      bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer),\r\n                                      space: colorSpace,\r\n                                      bitmapInfo: alphaInfo.rawValue)\r\n            else {\r\n                return nil\r\n        }\r\n        \r\n        UIGraphicsPushContext(context)\r\n        context.translateBy(x: 0, y: CGFloat(height))\r\n        context.scaleBy(x: 1, y: -1)\r\n        self.draw(in: CGRect(x: 0, y: 0, width: width, height: height))\r\n        UIGraphicsPopContext()\r\n        \r\n        CVPixelBufferUnlockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))\r\n        return pixelBuffer}\r\n\r\nand then I m creating my model with this settings:\r\n\r\n        static NSString* model_file_name = @\"inference_1_1_0\";\r\n        static NSString* model_file_type = @\"pb\";\r\n        static NSString* labels_file_name = @\"labels\";\r\n        static NSString* labels_file_type = @\"txt\";\r\n        std::unique_ptr<tensorflow::Session> tf_session;\r\n        std::vector<std::string> labels;\r\n\r\n        const int wanted_input_width = 38;\r\n        const int wanted_input_height = 45;\r\n        const int wanted_input_channels = 3;\r\n        const float input_mean = 117.0f;\r\n        const float input_std = 1.0f;\r\n        const std::string input_layer_name = \"input_input\";\r\n        const std::string output_layer_name = \"output_node0\";\r\n\r\nbut I have no idea what should I use for `input_mean` and `input_std` . Maybe they can be problem. \r\nI got runCNN method default from [Tensorflow Example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/ios/camera/CameraExampleViewController.mm)\r\n\r\nI really have no idea my image is wrong or should I change any default settings from tensorflow\r\n\r\nThanks.\r\n\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Mac OS 10.13.3 High Sierra\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.1.0 on Mac (Tensorflow-Experimental on iOS)\r\n- Python version: 3\r\n- Bazel version: 0.13.0\r\n- CUDA/cuDNN: N/A\r\n- GPU model and Memory: N/A\r\n- Exact command to reproduce: When I am trying to predict with my model it's always predict wrong.(Prediction)"}