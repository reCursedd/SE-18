{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/135938746", "pull_request_review_id": 59411510, "id": 135938746, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNTkzODc0Ng==", "diff_hunk": "@@ -43,6 +45,66 @@ struct InvVarianceToVariance {\n   void operator()(const Eigen::GpuDevice& d, double epsilon, int sample_size,\n                   int channels, T* variance);\n };\n+\n+\n+// Functor used by FusedBatchNormGradOp to do the computations when is_training=False.\n+// Both CPU and GPU will use this functor.\n+template <typename Device, typename T>\n+struct FusedBatchNormFreezeGrad {\n+  void operator()(const Device& d, const Tensor& y_backprop_input,\n+                  const Tensor& x_input, const Tensor& scale_input,\n+                  const Tensor& mean_input, const Tensor& variance_input,\n+                  T epsilon, Tensor* x_backprop_output,\n+                  Tensor* scale_backprop_output, Tensor* offset_backprop_output,\n+                  typename TTypes<T>::Vec scratch1, typename TTypes<T>::Vec scratch2) {", "path": "tensorflow/core/kernels/fused_batch_norm_op.h", "position": null, "original_position": 24, "commit_id": "f33ea380e3615e052929b635e5fa998d27cefa11", "original_commit_id": "fcca24e2f7640fcd882418033b6f5baf128c205f", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "body": "Seems like `Eigen::Tensor<T, 1, Eigen::RowMajor> scratch1(depth)` only allocate memory on CPUs? In a GPU kernel, using this ends up with `CUDA_ERROR_ILLEGAL_ADDRESS`. Using the OpKernelContext seems like the standard device-agnostic way to allocate memory.", "created_at": "2017-08-29T23:39:04Z", "updated_at": "2017-09-20T02:21:36Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/12580#discussion_r135938746", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12580", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/135938746"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/12580#discussion_r135938746"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12580"}}, "body_html": "<p>Seems like <code>Eigen::Tensor&lt;T, 1, Eigen::RowMajor&gt; scratch1(depth)</code> only allocate memory on CPUs? In a GPU kernel, using this ends up with <code>CUDA_ERROR_ILLEGAL_ADDRESS</code>. Using the OpKernelContext seems like the standard device-agnostic way to allocate memory.</p>", "body_text": "Seems like Eigen::Tensor<T, 1, Eigen::RowMajor> scratch1(depth) only allocate memory on CPUs? In a GPU kernel, using this ends up with CUDA_ERROR_ILLEGAL_ADDRESS. Using the OpKernelContext seems like the standard device-agnostic way to allocate memory.", "in_reply_to_id": 135904930}