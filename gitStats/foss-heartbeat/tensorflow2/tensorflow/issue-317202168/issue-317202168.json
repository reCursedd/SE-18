{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18829", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18829/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18829/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18829/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18829", "id": 317202168, "node_id": "MDU6SXNzdWUzMTcyMDIxNjg=", "number": 18829, "title": "How to quantify ssd_mobilenet_v1_coco model and toco to .tflite ?", "user": {"login": "WenguoLi", "id": 31765154, "node_id": "MDQ6VXNlcjMxNzY1MTU0", "avatar_url": "https://avatars0.githubusercontent.com/u/31765154?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WenguoLi", "html_url": "https://github.com/WenguoLi", "followers_url": "https://api.github.com/users/WenguoLi/followers", "following_url": "https://api.github.com/users/WenguoLi/following{/other_user}", "gists_url": "https://api.github.com/users/WenguoLi/gists{/gist_id}", "starred_url": "https://api.github.com/users/WenguoLi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WenguoLi/subscriptions", "organizations_url": "https://api.github.com/users/WenguoLi/orgs", "repos_url": "https://api.github.com/users/WenguoLi/repos", "events_url": "https://api.github.com/users/WenguoLi/events{/privacy}", "received_events_url": "https://api.github.com/users/WenguoLi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 21, "created_at": "2018-04-24T12:26:29Z", "updated_at": "2018-11-02T09:43:29Z", "closed_at": "2018-04-25T23:21:10Z", "author_association": "NONE", "body_html": "<h2>System information</h2>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04</li>\n<li>TensorFlow installed from (source or binary): Source</li>\n<li>TensorFlow version (use command below): 1.8.0</li>\n<li>Python version:2.7.12</li>\n<li>Bazel version (if compiling from source): 0.12.0</li>\n<li>CUDA/cuDNN version: cuda-9.0/7.0</li>\n<li>GPU model and memory: GeForce GTX 1080/8105MiB</li>\n<li>Exact command to reproduce: N/A</li>\n<li>Phone: Moto G4 Play (need to use Camera, not Camera2)</li>\n</ul>\n<p>Hi,  guys,<br>\nI am trying to quantify ssd_mobilenet_v1 using tensorflow object detection api, according to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=37242917\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/coutner\">@coutner</a> <a href=\"https://github.com/tensorflow/tensorflow/issues/18342\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/18342/hovercard\">post </a>.<br>\nFirst, I replace all the graph_hook_fn in<br>\n<a href=\"https://github.com/tensorflow/models/blob/b6bcc450b981eba721ee2760c92d87da86900988/research/object_detection/trainer.py\">trainer.py</a> tf.contrib.quantize.create_training_graph and enable fused batch norm in <a href=\"https://github.com/tensorflow/models/blob/b6bcc450b981eba721ee2760c92d87da86900988/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py#L114\">ssd_mobilenet_v1_feature_extractor.py</a><br>\nAfter training, I used the following script to transform the model.</p>\n<ol>\n<li>when running optimize_for_inference, some warning had arisen.</li>\n</ol>\n<pre><code>$ bazel run -c opt tensorflow/python/tools/optimize_for_inference -- \\\n&gt;     --input=$DETECT_PB --output=$STRIPPED_PB --frozen_graph=True \\\n&gt;     --input_names=Preprocessor/sub --output_names=concat,concat_1 \\\n&gt;     --toco_compatible=True \\\n&gt;     --alsologtostderr\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/BatchNorm/FusedBatchNorm'\n</code></pre>\n<p>When Running toco,</p>\n<pre><code>$ bazel run tensorflow/contrib/lite/toco:toco -- \n&gt;   --input_file=$STRIPPED_PB \\\n&gt;   --output_file=$DETECT_FB \\\n&gt;   --input_format=TENSORFLOW_GRAPHDEF \\\n&gt;   --output_format=TFLITE \\\n&gt;   --inference_type=QUANTIZED_UINT8 \\\n&gt;   --input_shapes=1,300,300,3 \\\n&gt;   --input_arrays=Preprocessor/sub \\\n&gt;   --output_arrays=concat,concat_1 \\\n&gt;   --std_values=128 \\\n&gt;   --mean_values=127 \\\n&gt;   --dump_graphviz=/tmp\n2018-04-24 18:51:51.645315: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 253 operators, 450 arrays (0 quantized)\n2018-04-24 18:51:51.686011: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 253 operators, 450 arrays (0 quantized)\n2018-04-24 18:51:51.774563: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 62 operators, 169 arrays (1 quantized)\n2018-04-24 18:51:51.775525: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 62 operators, 169 arrays (1 quantized)\n2018-04-24 18:51:51.776094: F tensorflow/contrib/lite/toco/tooling_util.cc:1464] Array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6, is lacking min/max data, \nwhich is necessary for quantization. Either target a non-quantized output format, or change the input \ngraph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you \ndo not care about the accuracy of results.\nAborted (core dumped)\n</code></pre>\n<p>Is there anyone who can help ? <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3376817\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrewharp\">@andrewharp</a> ,<br>\nthanks.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.8.0\nPython version:2.7.12\nBazel version (if compiling from source): 0.12.0\nCUDA/cuDNN version: cuda-9.0/7.0\nGPU model and memory: GeForce GTX 1080/8105MiB\nExact command to reproduce: N/A\nPhone: Moto G4 Play (need to use Camera, not Camera2)\n\nHi,  guys,\nI am trying to quantify ssd_mobilenet_v1 using tensorflow object detection api, according to @coutner post .\nFirst, I replace all the graph_hook_fn in\ntrainer.py tf.contrib.quantize.create_training_graph and enable fused batch norm in ssd_mobilenet_v1_feature_extractor.py\nAfter training, I used the following script to transform the model.\n\nwhen running optimize_for_inference, some warning had arisen.\n\n$ bazel run -c opt tensorflow/python/tools/optimize_for_inference -- \\\n>     --input=$DETECT_PB --output=$STRIPPED_PB --frozen_graph=True \\\n>     --input_names=Preprocessor/sub --output_names=concat,concat_1 \\\n>     --toco_compatible=True \\\n>     --alsologtostderr\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/BatchNorm/FusedBatchNorm'\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/BatchNorm/FusedBatchNorm'\n\nWhen Running toco,\n$ bazel run tensorflow/contrib/lite/toco:toco -- \n>   --input_file=$STRIPPED_PB \\\n>   --output_file=$DETECT_FB \\\n>   --input_format=TENSORFLOW_GRAPHDEF \\\n>   --output_format=TFLITE \\\n>   --inference_type=QUANTIZED_UINT8 \\\n>   --input_shapes=1,300,300,3 \\\n>   --input_arrays=Preprocessor/sub \\\n>   --output_arrays=concat,concat_1 \\\n>   --std_values=128 \\\n>   --mean_values=127 \\\n>   --dump_graphviz=/tmp\n2018-04-24 18:51:51.645315: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 253 operators, 450 arrays (0 quantized)\n2018-04-24 18:51:51.686011: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 253 operators, 450 arrays (0 quantized)\n2018-04-24 18:51:51.774563: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 62 operators, 169 arrays (1 quantized)\n2018-04-24 18:51:51.775525: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 62 operators, 169 arrays (1 quantized)\n2018-04-24 18:51:51.776094: F tensorflow/contrib/lite/toco/tooling_util.cc:1464] Array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6, is lacking min/max data, \nwhich is necessary for quantization. Either target a non-quantized output format, or change the input \ngraph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you \ndo not care about the accuracy of results.\nAborted (core dumped)\n\nIs there anyone who can help ? @andrewharp ,\nthanks.", "body": "## System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 1.8.0\r\n- Python version:2.7.12\r\n- Bazel version (if compiling from source): 0.12.0\r\n- CUDA/cuDNN version: cuda-9.0/7.0\r\n- GPU model and memory: GeForce GTX 1080/8105MiB\r\n- Exact command to reproduce: N/A\r\n- Phone: Moto G4 Play (need to use Camera, not Camera2)\r\n\r\nHi,  guys,\r\nI am trying to quantify ssd_mobilenet_v1 using tensorflow object detection api, according to @coutner [post ](https://github.com/tensorflow/tensorflow/issues/18342).\r\nFirst, I replace all the graph_hook_fn in\r\n [trainer.py](https://github.com/tensorflow/models/blob/b6bcc450b981eba721ee2760c92d87da86900988/research/object_detection/trainer.py) tf.contrib.quantize.create_training_graph and enable fused batch norm in [ssd_mobilenet_v1_feature_extractor.py](https://github.com/tensorflow/models/blob/b6bcc450b981eba721ee2760c92d87da86900988/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py#L114)\r\nAfter training, I used the following script to transform the model.\r\n\r\n1. when running optimize_for_inference, some warning had arisen.\r\n```\r\n$ bazel run -c opt tensorflow/python/tools/optimize_for_inference -- \\\r\n>     --input=$DETECT_PB --output=$STRIPPED_PB --frozen_graph=True \\\r\n>     --input_names=Preprocessor/sub --output_names=concat,concat_1 \\\r\n>     --toco_compatible=True \\\r\n>     --alsologtostderr\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/BatchNorm/FusedBatchNorm'\r\nWARNING:tensorflow:Didn't find expected Conv2D input to 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/BatchNorm/FusedBatchNorm'\r\n```\r\nWhen Running toco,\r\n```\r\n$ bazel run tensorflow/contrib/lite/toco:toco -- \r\n>   --input_file=$STRIPPED_PB \\\r\n>   --output_file=$DETECT_FB \\\r\n>   --input_format=TENSORFLOW_GRAPHDEF \\\r\n>   --output_format=TFLITE \\\r\n>   --inference_type=QUANTIZED_UINT8 \\\r\n>   --input_shapes=1,300,300,3 \\\r\n>   --input_arrays=Preprocessor/sub \\\r\n>   --output_arrays=concat,concat_1 \\\r\n>   --std_values=128 \\\r\n>   --mean_values=127 \\\r\n>   --dump_graphviz=/tmp\r\n2018-04-24 18:51:51.645315: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 253 operators, 450 arrays (0 quantized)\r\n2018-04-24 18:51:51.686011: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 253 operators, 450 arrays (0 quantized)\r\n2018-04-24 18:51:51.774563: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 62 operators, 169 arrays (1 quantized)\r\n2018-04-24 18:51:51.775525: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 62 operators, 169 arrays (1 quantized)\r\n2018-04-24 18:51:51.776094: F tensorflow/contrib/lite/toco/tooling_util.cc:1464] Array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6, is lacking min/max data, \r\nwhich is necessary for quantization. Either target a non-quantized output format, or change the input \r\ngraph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you \r\ndo not care about the accuracy of results.\r\nAborted (core dumped)\r\n```\r\nIs there anyone who can help ? @andrewharp ,\r\nthanks.\r\n\r\n\r\n"}