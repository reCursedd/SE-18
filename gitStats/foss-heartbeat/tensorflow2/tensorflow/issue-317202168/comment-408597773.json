{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/408597773", "html_url": "https://github.com/tensorflow/tensorflow/issues/18829#issuecomment-408597773", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18829", "id": 408597773, "node_id": "MDEyOklzc3VlQ29tbWVudDQwODU5Nzc3Mw==", "user": {"login": "MohammadMoradi", "id": 23086313, "node_id": "MDQ6VXNlcjIzMDg2MzEz", "avatar_url": "https://avatars1.githubusercontent.com/u/23086313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MohammadMoradi", "html_url": "https://github.com/MohammadMoradi", "followers_url": "https://api.github.com/users/MohammadMoradi/followers", "following_url": "https://api.github.com/users/MohammadMoradi/following{/other_user}", "gists_url": "https://api.github.com/users/MohammadMoradi/gists{/gist_id}", "starred_url": "https://api.github.com/users/MohammadMoradi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MohammadMoradi/subscriptions", "organizations_url": "https://api.github.com/users/MohammadMoradi/orgs", "repos_url": "https://api.github.com/users/MohammadMoradi/repos", "events_url": "https://api.github.com/users/MohammadMoradi/events{/privacy}", "received_events_url": "https://api.github.com/users/MohammadMoradi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-28T10:24:19Z", "updated_at": "2018-07-28T10:24:19Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=31765154\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/WenguoLi\">@WenguoLi</a> have you tested your model on android device? I had the same problem and solved by changing to FLOAT but when I run it on android I get the following error:<br>\n<code>E/AndroidRuntime: FATAL EXCEPTION: inference Process: org.tensorflow.lite.demo, PID: 28270 java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1080000 bytes and a ByteBuffer with 270000 bytes. at org.tensorflow.lite.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:175) at org.tensorflow.lite.Tensor.setTo(Tensor.java:65) at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:126) at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:168) at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:194) at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:247) at android.os.Handler.handleCallback(Handler.java:751) at android.os.Handler.dispatchMessage(Handler.java:95) at android.os.Looper.loop(Looper.java:154) at android.os.HandlerThread.run(HandlerThread.java:61) </code></p>", "body_text": "@WenguoLi have you tested your model on android device? I had the same problem and solved by changing to FLOAT but when I run it on android I get the following error:\nE/AndroidRuntime: FATAL EXCEPTION: inference Process: org.tensorflow.lite.demo, PID: 28270 java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1080000 bytes and a ByteBuffer with 270000 bytes. at org.tensorflow.lite.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:175) at org.tensorflow.lite.Tensor.setTo(Tensor.java:65) at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:126) at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:168) at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:194) at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:247) at android.os.Handler.handleCallback(Handler.java:751) at android.os.Handler.dispatchMessage(Handler.java:95) at android.os.Looper.loop(Looper.java:154) at android.os.HandlerThread.run(HandlerThread.java:61)", "body": "@WenguoLi have you tested your model on android device? I had the same problem and solved by changing to FLOAT but when I run it on android I get the following error:\r\n`E/AndroidRuntime: FATAL EXCEPTION: inference\r\n                  Process: org.tensorflow.lite.demo, PID: 28270\r\n                  java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1080000 bytes and a ByteBuffer with 270000 bytes.\r\n                      at org.tensorflow.lite.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:175)\r\n                      at org.tensorflow.lite.Tensor.setTo(Tensor.java:65)\r\n                      at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:126)\r\n                      at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:168)\r\n                      at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:194)\r\n                      at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:247)\r\n                      at android.os.Handler.handleCallback(Handler.java:751)\r\n                      at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                      at android.os.Looper.loop(Looper.java:154)\r\n                      at android.os.HandlerThread.run(HandlerThread.java:61)\r\n`"}