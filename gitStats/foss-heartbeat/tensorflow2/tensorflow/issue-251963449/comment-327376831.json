{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/327376831", "html_url": "https://github.com/tensorflow/tensorflow/pull/12493#issuecomment-327376831", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12493", "id": 327376831, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNzM3NjgzMQ==", "user": {"login": "panyx0718", "id": 2887803, "node_id": "MDQ6VXNlcjI4ODc4MDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2887803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/panyx0718", "html_url": "https://github.com/panyx0718", "followers_url": "https://api.github.com/users/panyx0718/followers", "following_url": "https://api.github.com/users/panyx0718/following{/other_user}", "gists_url": "https://api.github.com/users/panyx0718/gists{/gist_id}", "starred_url": "https://api.github.com/users/panyx0718/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/panyx0718/subscriptions", "organizations_url": "https://api.github.com/users/panyx0718/orgs", "repos_url": "https://api.github.com/users/panyx0718/repos", "events_url": "https://api.github.com/users/panyx0718/events{/privacy}", "received_events_url": "https://api.github.com/users/panyx0718/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-06T05:14:27Z", "updated_at": "2017-09-06T05:14:27Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">No, the memory are not the same. The timeline.Timeline is based on\nestimation (which could be far from reality given today's TensorFlow\ncomplexity).\nThe profiler one is based on The real value (groundtruth) collected from\nTensorFlow's gpu memory allocator.\n\nThe currently limitation is, we don't yet know where are the current memory\nfrom (due to the ref-counted Tensor). You could have some guess by relating\ncomputation and memory timeline</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Tue, Sep 5, 2017 at 10:09 PM, qianyizhang ***@***.***&gt; wrote:\n In term of actual value, this should be consistent with\n timeline.Timeline(run_metadata.step_stats)? (since they all parse the\n same information from run_metadata?)\n But then someone says it's only the approximated memory usage by\n simulation, no the actual footprint, is it still the case?\n <a href=\"https://stackoverflow.com/questions/36123740/is-there-a-\">https://stackoverflow.com/questions/36123740/is-there-a-</a>\n way-of-determining-how-much-gpu-memory-is-in-use-by-tensorflow\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"251963449\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/12493\" href=\"https://github.com/tensorflow/tensorflow/pull/12493#issuecomment-327375922\">#12493 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ACwQe9RpB_IjyqEBu6WDL8VpAA9cpvJ-ks5sfikWgaJpZM4O-pcL\">https://github.com/notifications/unsubscribe-auth/ACwQe9RpB_IjyqEBu6WDL8VpAA9cpvJ-ks5sfikWgaJpZM4O-pcL</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \nThanks\nXin</div>\n</div>", "body_text": "No, the memory are not the same. The timeline.Timeline is based on\nestimation (which could be far from reality given today's TensorFlow\ncomplexity).\nThe profiler one is based on The real value (groundtruth) collected from\nTensorFlow's gpu memory allocator.\n\nThe currently limitation is, we don't yet know where are the current memory\nfrom (due to the ref-counted Tensor). You could have some guess by relating\ncomputation and memory timeline\n\u2026\nOn Tue, Sep 5, 2017 at 10:09 PM, qianyizhang ***@***.***> wrote:\n In term of actual value, this should be consistent with\n timeline.Timeline(run_metadata.step_stats)? (since they all parse the\n same information from run_metadata?)\n But then someone says it's only the approximated memory usage by\n simulation, no the actual footprint, is it still the case?\n https://stackoverflow.com/questions/36123740/is-there-a-\n way-of-determining-how-much-gpu-memory-is-in-use-by-tensorflow\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#12493 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ACwQe9RpB_IjyqEBu6WDL8VpAA9cpvJ-ks5sfikWgaJpZM4O-pcL>\n .\n\n\n-- \nThanks\nXin", "body": "No, the memory are not the same. The timeline.Timeline is based on\nestimation (which could be far from reality given today's TensorFlow\ncomplexity).\nThe profiler one is based on The real value (groundtruth) collected from\nTensorFlow's gpu memory allocator.\n\nThe currently limitation is, we don't yet know where are the current memory\nfrom (due to the ref-counted Tensor). You could have some guess by relating\ncomputation and memory timeline\n\nOn Tue, Sep 5, 2017 at 10:09 PM, qianyizhang <notifications@github.com>\nwrote:\n\n> In term of actual value, this should be consistent with\n> timeline.Timeline(run_metadata.step_stats)? (since they all parse the\n> same information from run_metadata?)\n> But then someone says it's only the approximated memory usage by\n> simulation, no the actual footprint, is it still the case?\n> https://stackoverflow.com/questions/36123740/is-there-a-\n> way-of-determining-how-much-gpu-memory-is-in-use-by-tensorflow\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12493#issuecomment-327375922>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ACwQe9RpB_IjyqEBu6WDL8VpAA9cpvJ-ks5sfikWgaJpZM4O-pcL>\n> .\n>\n\n\n\n-- \nThanks\nXin\n"}