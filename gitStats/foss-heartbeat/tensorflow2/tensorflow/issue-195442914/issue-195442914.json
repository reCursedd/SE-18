{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6298", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6298/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6298/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6298/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6298", "id": 195442914, "node_id": "MDU6SXNzdWUxOTU0NDI5MTQ=", "number": 6298, "title": "Long sentence take too much memory", "user": {"login": "333caowei", "id": 4569055, "node_id": "MDQ6VXNlcjQ1NjkwNTU=", "avatar_url": "https://avatars3.githubusercontent.com/u/4569055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/333caowei", "html_url": "https://github.com/333caowei", "followers_url": "https://api.github.com/users/333caowei/followers", "following_url": "https://api.github.com/users/333caowei/following{/other_user}", "gists_url": "https://api.github.com/users/333caowei/gists{/gist_id}", "starred_url": "https://api.github.com/users/333caowei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/333caowei/subscriptions", "organizations_url": "https://api.github.com/users/333caowei/orgs", "repos_url": "https://api.github.com/users/333caowei/repos", "events_url": "https://api.github.com/users/333caowei/events{/privacy}", "received_events_url": "https://api.github.com/users/333caowei/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-12-14T05:20:27Z", "updated_at": "2016-12-15T09:18:03Z", "closed_at": "2016-12-15T09:16:30Z", "author_association": "NONE", "body_html": "<p>I use one layer LSTM to train my data.<br>\nI use Dynamic_rnn, rnn_size=128, num_layers=1, seq_max_length=2500, batch_size=10, embedding_size=128, softmax_size=1600.</p>\n<p>My code like this:</p>\n<blockquote>\n<p>x_vec = tf.nn.embedding_lookup(embedding_matrix_variable, self.x)<br>\nlstm_fw_cell = rnn_cell.LSTMCell(num_units = hidden_unit, input_size = hidden_unit)<br>\nlstm_fw_cell = rnn_cell.DropoutWrapper(lstm_fw_cell, output_keep_prob=self.dropout_keep_prob, input_keep_prob=self.dropout_keep_prob)<br>\noutputs, _ = rnn.dynamic_rnn(lstm_fw_cell, x, dtype=tf.float32, sequence_length=real_length, swap_memory=False)</p>\n</blockquote>\n<p>I specify the GPU like this:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4569055/21170698/3bbf5de8-c20a-11e6-9b66-647830bdd371.png\"><img width=\"281\" alt=\"screenshot\" src=\"https://cloud.githubusercontent.com/assets/4569055/21170698/3bbf5de8-c20a-11e6-9b66-647830bdd371.png\" style=\"max-width:100%;\"></a></p>\n<p>Command \"nvidia-smi\" shows as:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4569055/21170316/7738d3b6-c207-11e6-860a-cdc5ea166f40.png\"><img width=\"511\" alt=\"screenshot\" src=\"https://cloud.githubusercontent.com/assets/4569055/21170316/7738d3b6-c207-11e6-860a-cdc5ea166f40.png\" style=\"max-width:100%;\"></a></p>\n<p>After lunching the program, it always shows :</p>\n<blockquote>\n<p>\"I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator:...............\":</p>\n</blockquote>\n<p>details show as below:</p>\n<blockquote>\n<p>Step: 0       (epoch: 0.00000)       time:28.85937s<br>\nMinibatch loss:          7.43977     Minibatch accuracy:  0.00000<br>\nTest loss:         nan     Test accuracy: 0.00000<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=9012 evicted_count=9000 eviction_rate=0.998668 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 9559 get requests, put_count=15572 evicted_count=6000 eviction_rate=0.385307 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 25809 get requests, put_count=41821 evicted_count=16000 eviction_rate=0.382583 and unsatisfied allocation rate=3.87462e-05<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 42059 get requests, put_count=68071 evicted_count=26000 eviction_rate=0.381954 and unsatisfied allocation rate=2.37761e-05<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 58309 get requests, put_count=94321 evicted_count=36000 eviction_rate=0.381675 and unsatisfied allocation rate=1.715e-05<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=8014 evicted_count=8000 eviction_rate=0.998253 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 7817 get requests, put_count=25828 evicted_count=18000 eviction_rate=0.696918 and unsatisfied allocation rate=0.000383779<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 24067 get requests, put_count=52078 evicted_count=28000 eviction_rate=0.537655 and unsatisfied allocation rate=0.000124652<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 40317 get requests, put_count=78328 evicted_count=38000 eviction_rate=0.485139 and unsatisfied allocation rate=7.44103e-05<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 56567 get requests, put_count=104578 evicted_count=48000 eviction_rate=0.458988 and unsatisfied allocation rate=5.30345e-05<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=7016 evicted_count=7000 eviction_rate=0.997719 and unsatisfied allocation rate=0<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 6070 get requests, put_count=23084 evicted_count=17000 eviction_rate=0.736441 and unsatisfied allocation rate=0.000329489<br>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 22320 get requests, put_count=49333 evicted_count=27000 eviction_rate=0.547301 and unsatisfied allocation rate=0.000134409</p>\n</blockquote>", "body_text": "I use one layer LSTM to train my data.\nI use Dynamic_rnn, rnn_size=128, num_layers=1, seq_max_length=2500, batch_size=10, embedding_size=128, softmax_size=1600.\nMy code like this:\n\nx_vec = tf.nn.embedding_lookup(embedding_matrix_variable, self.x)\nlstm_fw_cell = rnn_cell.LSTMCell(num_units = hidden_unit, input_size = hidden_unit)\nlstm_fw_cell = rnn_cell.DropoutWrapper(lstm_fw_cell, output_keep_prob=self.dropout_keep_prob, input_keep_prob=self.dropout_keep_prob)\noutputs, _ = rnn.dynamic_rnn(lstm_fw_cell, x, dtype=tf.float32, sequence_length=real_length, swap_memory=False)\n\nI specify the GPU like this:\n\nCommand \"nvidia-smi\" shows as:\n\nAfter lunching the program, it always shows :\n\n\"I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator:...............\":\n\ndetails show as below:\n\nStep: 0       (epoch: 0.00000)       time:28.85937s\nMinibatch loss:          7.43977     Minibatch accuracy:  0.00000\nTest loss:         nan     Test accuracy: 0.00000\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=9012 evicted_count=9000 eviction_rate=0.998668 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 9559 get requests, put_count=15572 evicted_count=6000 eviction_rate=0.385307 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 25809 get requests, put_count=41821 evicted_count=16000 eviction_rate=0.382583 and unsatisfied allocation rate=3.87462e-05\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 42059 get requests, put_count=68071 evicted_count=26000 eviction_rate=0.381954 and unsatisfied allocation rate=2.37761e-05\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 58309 get requests, put_count=94321 evicted_count=36000 eviction_rate=0.381675 and unsatisfied allocation rate=1.715e-05\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=8014 evicted_count=8000 eviction_rate=0.998253 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 7817 get requests, put_count=25828 evicted_count=18000 eviction_rate=0.696918 and unsatisfied allocation rate=0.000383779\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 24067 get requests, put_count=52078 evicted_count=28000 eviction_rate=0.537655 and unsatisfied allocation rate=0.000124652\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 40317 get requests, put_count=78328 evicted_count=38000 eviction_rate=0.485139 and unsatisfied allocation rate=7.44103e-05\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 56567 get requests, put_count=104578 evicted_count=48000 eviction_rate=0.458988 and unsatisfied allocation rate=5.30345e-05\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=7016 evicted_count=7000 eviction_rate=0.997719 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 6070 get requests, put_count=23084 evicted_count=17000 eviction_rate=0.736441 and unsatisfied allocation rate=0.000329489\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 22320 get requests, put_count=49333 evicted_count=27000 eviction_rate=0.547301 and unsatisfied allocation rate=0.000134409", "body": "I use one layer LSTM to train my data.\r\nI use Dynamic_rnn, rnn_size=128, num_layers=1, seq_max_length=2500, batch_size=10, embedding_size=128, softmax_size=1600.\r\n\r\n\r\nMy code like this:\r\n\r\n> x_vec = tf.nn.embedding_lookup(embedding_matrix_variable, self.x)\r\n> lstm_fw_cell = rnn_cell.LSTMCell(num_units = hidden_unit, input_size = hidden_unit)\r\n> lstm_fw_cell = rnn_cell.DropoutWrapper(lstm_fw_cell, output_keep_prob=self.dropout_keep_prob, input_keep_prob=self.dropout_keep_prob)\r\n> outputs, _ = rnn.dynamic_rnn(lstm_fw_cell, x, dtype=tf.float32, sequence_length=real_length, swap_memory=False)\r\n> \r\n\r\n\r\nI specify the GPU like this:\r\n<img width=\"281\" alt=\"screenshot\" src=\"https://cloud.githubusercontent.com/assets/4569055/21170698/3bbf5de8-c20a-11e6-9b66-647830bdd371.png\">\r\n\r\n\r\n\r\nCommand \"nvidia-smi\" shows as:\r\n<img width=\"511\" alt=\"screenshot\" src=\"https://cloud.githubusercontent.com/assets/4569055/21170316/7738d3b6-c207-11e6-860a-cdc5ea166f40.png\">\r\n\r\n\r\n\r\nAfter lunching the program, it always shows :\r\n\r\n> \"I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator:...............\":\r\n\r\ndetails show as below:\r\n\r\n> Step: 0       (epoch: 0.00000)       time:28.85937s\r\n> Minibatch loss:          7.43977     Minibatch accuracy:  0.00000\r\n> Test loss:         nan     Test accuracy: 0.00000\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=9012 evicted_count=9000 eviction_rate=0.998668 and unsatisfied allocation rate=0\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 9559 get requests, put_count=15572 evicted_count=6000 eviction_rate=0.385307 and unsatisfied allocation rate=0\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 25809 get requests, put_count=41821 evicted_count=16000 eviction_rate=0.382583 and unsatisfied allocation rate=3.87462e-05\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 42059 get requests, put_count=68071 evicted_count=26000 eviction_rate=0.381954 and unsatisfied allocation rate=2.37761e-05\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 58309 get requests, put_count=94321 evicted_count=36000 eviction_rate=0.381675 and unsatisfied allocation rate=1.715e-05\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=8014 evicted_count=8000 eviction_rate=0.998253 and unsatisfied allocation rate=0\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 7817 get requests, put_count=25828 evicted_count=18000 eviction_rate=0.696918 and unsatisfied allocation rate=0.000383779\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 24067 get requests, put_count=52078 evicted_count=28000 eviction_rate=0.537655 and unsatisfied allocation rate=0.000124652\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 40317 get requests, put_count=78328 evicted_count=38000 eviction_rate=0.485139 and unsatisfied allocation rate=7.44103e-05\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 56567 get requests, put_count=104578 evicted_count=48000 eviction_rate=0.458988 and unsatisfied allocation rate=5.30345e-05\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=7016 evicted_count=7000 eviction_rate=0.997719 and unsatisfied allocation rate=0\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 6070 get requests, put_count=23084 evicted_count=17000 eviction_rate=0.736441 and unsatisfied allocation rate=0.000329489\r\n> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 22320 get requests, put_count=49333 evicted_count=27000 eviction_rate=0.547301 and unsatisfied allocation rate=0.000134409\r\n> \r\n\r\n\r\n"}