{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/329912162", "html_url": "https://github.com/tensorflow/tensorflow/issues/8043#issuecomment-329912162", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8043", "id": 329912162, "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTkxMjE2Mg==", "user": {"login": "brightbytes-dude", "id": 6979675, "node_id": "MDQ6VXNlcjY5Nzk2NzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/6979675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brightbytes-dude", "html_url": "https://github.com/brightbytes-dude", "followers_url": "https://api.github.com/users/brightbytes-dude/followers", "following_url": "https://api.github.com/users/brightbytes-dude/following{/other_user}", "gists_url": "https://api.github.com/users/brightbytes-dude/gists{/gist_id}", "starred_url": "https://api.github.com/users/brightbytes-dude/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brightbytes-dude/subscriptions", "organizations_url": "https://api.github.com/users/brightbytes-dude/orgs", "repos_url": "https://api.github.com/users/brightbytes-dude/repos", "events_url": "https://api.github.com/users/brightbytes-dude/events{/privacy}", "received_events_url": "https://api.github.com/users/brightbytes-dude/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-15T21:49:03Z", "updated_at": "2017-09-15T21:49:03Z", "author_association": "NONE", "body_html": "<p>I was able to get this working by riffing off the suggested fix, and changing only the label definition provided by the input function for all my models as per this git diff:</p>\n<pre><code>-    label = tf.constant(\n-      df[self.schema.label_column].values,\n-      dtype=tf.bool\n+    label = tf.reshape(\n+      tf.constant(\n+        df[self.schema.label_column].values,\n+        dtype=tf.bool\n+      ),\n+      [-1, 1]\n     )\n</code></pre>\n<p>So, while I would hope that the Estimator would take care of this for me, it's not clear whether or not its responsibility is to take care of it for me. :-)</p>\n<p>IOW, I'm lucky I was able to suss this relatively quickly based upon <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19861701\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/honkentuber\">@honkentuber</a> 's comments: others might not be so fortunate, so some fix would be cool.  Just not sure where that would be.</p>\n<p>Finally, while I have you ;-) , two quick questions that you can send me to Stack Overflow for if you don't want to deal:</p>\n<p>I stupidly created my dev/test sets with the weight column.  But, obviously, for tuning and testing, I don't want the weight column in my features or defined by the model.  (I tried it, and the presence of the weight column garnered an accuracy of 99.4% because the weight column is completely correlated with the label). And, clearly, when making predictions, defining that column is right out.</p>\n<p>So, the first question is: Will it be possible to load a trained model (via its <code>model_dir</code>) into an Estimator definition that doesn't define the weight column in the features or as the <code>weight_column_name</code> param?  (If not, then what exactly is the utility of the <code>weight_column_name</code> param?)</p>\n<p>I'm going to try that soon, but can't immediately due to the the following question:</p>\n<p>I'm using the (deprecated) Early Stopping ValidationMonitor feature described in \"Logging and Monitoring\" tutorial ... that appears to have been taken down recently. (?!)  The problem is that the Early Stopping ValidationMonitor is passed into the model during training, and thus the input function it uses for test data may (?) need to provide the same features for the dev/test set as it does for the training set.</p>\n<p>The question then is: does its input function need to match the signature of the training input function?</p>\n<p>If so, I'll (tragically!) need to stop using this feature, which I love because it narrows the wide degree of freedom of manually tuning <code>training_steps</code>.  IOW, tuning <code>early_stopping_steps</code> can occur over a much narrower range of values than tuning <code>training_steps</code>, which I dig.</p>", "body_text": "I was able to get this working by riffing off the suggested fix, and changing only the label definition provided by the input function for all my models as per this git diff:\n-    label = tf.constant(\n-      df[self.schema.label_column].values,\n-      dtype=tf.bool\n+    label = tf.reshape(\n+      tf.constant(\n+        df[self.schema.label_column].values,\n+        dtype=tf.bool\n+      ),\n+      [-1, 1]\n     )\n\nSo, while I would hope that the Estimator would take care of this for me, it's not clear whether or not its responsibility is to take care of it for me. :-)\nIOW, I'm lucky I was able to suss this relatively quickly based upon @honkentuber 's comments: others might not be so fortunate, so some fix would be cool.  Just not sure where that would be.\nFinally, while I have you ;-) , two quick questions that you can send me to Stack Overflow for if you don't want to deal:\nI stupidly created my dev/test sets with the weight column.  But, obviously, for tuning and testing, I don't want the weight column in my features or defined by the model.  (I tried it, and the presence of the weight column garnered an accuracy of 99.4% because the weight column is completely correlated with the label). And, clearly, when making predictions, defining that column is right out.\nSo, the first question is: Will it be possible to load a trained model (via its model_dir) into an Estimator definition that doesn't define the weight column in the features or as the weight_column_name param?  (If not, then what exactly is the utility of the weight_column_name param?)\nI'm going to try that soon, but can't immediately due to the the following question:\nI'm using the (deprecated) Early Stopping ValidationMonitor feature described in \"Logging and Monitoring\" tutorial ... that appears to have been taken down recently. (?!)  The problem is that the Early Stopping ValidationMonitor is passed into the model during training, and thus the input function it uses for test data may (?) need to provide the same features for the dev/test set as it does for the training set.\nThe question then is: does its input function need to match the signature of the training input function?\nIf so, I'll (tragically!) need to stop using this feature, which I love because it narrows the wide degree of freedom of manually tuning training_steps.  IOW, tuning early_stopping_steps can occur over a much narrower range of values than tuning training_steps, which I dig.", "body": "I was able to get this working by riffing off the suggested fix, and changing only the label definition provided by the input function for all my models as per this git diff:\r\n\r\n```\r\n-    label = tf.constant(\r\n-      df[self.schema.label_column].values,\r\n-      dtype=tf.bool\r\n+    label = tf.reshape(\r\n+      tf.constant(\r\n+        df[self.schema.label_column].values,\r\n+        dtype=tf.bool\r\n+      ),\r\n+      [-1, 1]\r\n     )\r\n```\r\n\r\nSo, while I would hope that the Estimator would take care of this for me, it's not clear whether or not its responsibility is to take care of it for me. :-) \r\n\r\nIOW, I'm lucky I was able to suss this relatively quickly based upon @honkentuber 's comments: others might not be so fortunate, so some fix would be cool.  Just not sure where that would be.\r\n\r\nFinally, while I have you ;-) , two quick questions that you can send me to Stack Overflow for if you don't want to deal:\r\n\r\nI stupidly created my dev/test sets with the weight column.  But, obviously, for tuning and testing, I don't want the weight column in my features or defined by the model.  (I tried it, and the presence of the weight column garnered an accuracy of 99.4% because the weight column is completely correlated with the label). And, clearly, when making predictions, defining that column is right out.\r\n\r\nSo, the first question is: Will it be possible to load a trained model (via its `model_dir`) into an Estimator definition that doesn't define the weight column in the features or as the `weight_column_name` param?  (If not, then what exactly is the utility of the `weight_column_name` param?)\r\n\r\nI'm going to try that soon, but can't immediately due to the the following question:\r\n\r\nI'm using the (deprecated) Early Stopping ValidationMonitor feature described in \"Logging and Monitoring\" tutorial ... that appears to have been taken down recently. (?!)  The problem is that the Early Stopping ValidationMonitor is passed into the model during training, and thus the input function it uses for test data may (?) need to provide the same features for the dev/test set as it does for the training set.  \r\n\r\nThe question then is: does its input function need to match the signature of the training input function?  \r\n\r\nIf so, I'll (tragically!) need to stop using this feature, which I love because it narrows the wide degree of freedom of manually tuning `training_steps`.  IOW, tuning `early_stopping_steps` can occur over a much narrower range of values than tuning `training_steps`, which I dig."}