{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/367558215", "html_url": "https://github.com/tensorflow/tensorflow/issues/8043#issuecomment-367558215", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8043", "id": 367558215, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NzU1ODIxNQ==", "user": {"login": "brightbytes-dude", "id": 6979675, "node_id": "MDQ6VXNlcjY5Nzk2NzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/6979675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brightbytes-dude", "html_url": "https://github.com/brightbytes-dude", "followers_url": "https://api.github.com/users/brightbytes-dude/followers", "following_url": "https://api.github.com/users/brightbytes-dude/following{/other_user}", "gists_url": "https://api.github.com/users/brightbytes-dude/gists{/gist_id}", "starred_url": "https://api.github.com/users/brightbytes-dude/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brightbytes-dude/subscriptions", "organizations_url": "https://api.github.com/users/brightbytes-dude/orgs", "repos_url": "https://api.github.com/users/brightbytes-dude/repos", "events_url": "https://api.github.com/users/brightbytes-dude/events{/privacy}", "received_events_url": "https://api.github.com/users/brightbytes-dude/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-22T03:43:21Z", "updated_at": "2018-02-22T03:58:24Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=47031\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tilarids\">@tilarids</a> - Sorry for the (very!) long delay: I wasn't able to get back to the project until recently.</p>\n<p>The test case you indicated allowed me to get this working on my project: thank you very much for referencing it!!</p>\n<p>My mistake was to take the documentation literally when it says <code>weight_column_name: A string defining feature column name representing weights.</code>.  I assumed that meant that <code>weight_column_name</code> - <code>w</code> in the test - <strong>must</strong> be one of the model features.  Whereas, the test case clearly shows that it absolutely should not be.  (And, when not including it among the model features didn't work the first time, I assumed it was because the feature was broken, rather than what must have been the case: that something else in my code was broken.)</p>\n<p>Furthermore, using weights had exactly the effect I'd hoped: it improved training &amp; test Recall at 50% threshold in my binary classification problem, though of course at the expense of reducing Accuracy.  But AUC remains the same whether or not weights are used, demonstrating to my satisfaction that the TF implementation of case weighting is correct.</p>\n<p>Finally, I have one question about that test case: in that example, one of the the prediction cases for evaluation has a different weight than the rest.  What is the actual use case for having a batch of predictions where the individual cases have different weights associated with them?</p>\n<p>I ask because in my domain, all cases to be labelled with a prediction matter equally.  So, I was planning on just passing in the exact same weight for every single one of them, for every batch.  Thus, the second question: does it matter what constant weight I choose for the cases to be evaluated?</p>\n<p>Apologies in advance if I should be asking these questions elsewhere ...</p>", "body_text": "@tilarids - Sorry for the (very!) long delay: I wasn't able to get back to the project until recently.\nThe test case you indicated allowed me to get this working on my project: thank you very much for referencing it!!\nMy mistake was to take the documentation literally when it says weight_column_name: A string defining feature column name representing weights..  I assumed that meant that weight_column_name - w in the test - must be one of the model features.  Whereas, the test case clearly shows that it absolutely should not be.  (And, when not including it among the model features didn't work the first time, I assumed it was because the feature was broken, rather than what must have been the case: that something else in my code was broken.)\nFurthermore, using weights had exactly the effect I'd hoped: it improved training & test Recall at 50% threshold in my binary classification problem, though of course at the expense of reducing Accuracy.  But AUC remains the same whether or not weights are used, demonstrating to my satisfaction that the TF implementation of case weighting is correct.\nFinally, I have one question about that test case: in that example, one of the the prediction cases for evaluation has a different weight than the rest.  What is the actual use case for having a batch of predictions where the individual cases have different weights associated with them?\nI ask because in my domain, all cases to be labelled with a prediction matter equally.  So, I was planning on just passing in the exact same weight for every single one of them, for every batch.  Thus, the second question: does it matter what constant weight I choose for the cases to be evaluated?\nApologies in advance if I should be asking these questions elsewhere ...", "body": "@tilarids - Sorry for the (very!) long delay: I wasn't able to get back to the project until recently.\r\n\r\nThe test case you indicated allowed me to get this working on my project: thank you very much for referencing it!!\r\n\r\nMy mistake was to take the documentation literally when it says `weight_column_name: A string defining feature column name representing weights.`.  I assumed that meant that `weight_column_name` - `w` in the test - **must** be one of the model features.  Whereas, the test case clearly shows that it absolutely should not be.  (And, when not including it among the model features didn't work the first time, I assumed it was because the feature was broken, rather than what must have been the case: that something else in my code was broken.)\r\n\r\nFurthermore, using weights had exactly the effect I'd hoped: it improved training & test Recall at 50% threshold in my binary classification problem, though of course at the expense of reducing Accuracy.  But AUC remains the same whether or not weights are used, demonstrating to my satisfaction that the TF implementation of case weighting is correct.\r\n\r\nFinally, I have one question about that test case: in that example, one of the the prediction cases for evaluation has a different weight than the rest.  What is the actual use case for having a batch of predictions where the individual cases have different weights associated with them?\r\n\r\nI ask because in my domain, all cases to be labelled with a prediction matter equally.  So, I was planning on just passing in the exact same weight for every single one of them, for every batch.  Thus, the second question: does it matter what constant weight I choose for the cases to be evaluated?\r\n\r\nApologies in advance if I should be asking these questions elsewhere ..."}