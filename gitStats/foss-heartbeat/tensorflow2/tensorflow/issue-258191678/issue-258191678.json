{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13075", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13075/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13075/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13075/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13075", "id": 258191678, "node_id": "MDU6SXNzdWUyNTgxOTE2Nzg=", "number": 13075, "title": "distributed Tensorflow assign device issue", "user": {"login": "RuofanKong", "id": 7396554, "node_id": "MDQ6VXNlcjczOTY1NTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/7396554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RuofanKong", "html_url": "https://github.com/RuofanKong", "followers_url": "https://api.github.com/users/RuofanKong/followers", "following_url": "https://api.github.com/users/RuofanKong/following{/other_user}", "gists_url": "https://api.github.com/users/RuofanKong/gists{/gist_id}", "starred_url": "https://api.github.com/users/RuofanKong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RuofanKong/subscriptions", "organizations_url": "https://api.github.com/users/RuofanKong/orgs", "repos_url": "https://api.github.com/users/RuofanKong/repos", "events_url": "https://api.github.com/users/RuofanKong/events{/privacy}", "received_events_url": "https://api.github.com/users/RuofanKong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-09-15T23:59:49Z", "updated_at": "2018-01-05T02:50:21Z", "closed_at": "2017-09-16T17:13:37Z", "author_association": "NONE", "body_html": "<p>I recently found an interesting issue on device assignment when I ran the following simple code <code>test.py</code>:</p>\n<pre><code>import argparse\nimport tensorflow as tf\n\nCLUSTER_SPEC = {\"ps\": [\"localhost:2222\"],\n                \"worker\": [\"localhost:1111\", \"localhost:1112\"]}\n\n\ndef parse_command_arguments():\n    \"\"\" Set up and parse the command line arguments. \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Parameters and Arguments for the Test.\")\n    parser.add_argument(\n        \"--job_name\", type=str, default=\"\", help=\"One of 'ps', 'worker'\")\n    parser.add_argument(\n        \"--task_index\", type=int, default=0, help=\"Index of task\")\n    return parser.parse_args()\n\n\ndef start_server(job_name, task_index, tf_config):\n    \"\"\" Create a server based on a cluster spec. \"\"\"\n    cluster = tf.train.ClusterSpec(CLUSTER_SPEC)\n    server = tf.train.Server(\n        cluster, config=tf_config, job_name=job_name, task_index=task_index)\n    return server, cluster\n\n\ndef model(cluster=None, worker_device=None):\n    \"\"\" Build up a simple estimator model. \"\"\"\n    with tf.device(tf.train.replica_device_setter(\n            worker_device=worker_device, cluster=cluster)):\n        W = tf.Variable([1.0], tf.float32)\n        b = tf.Variable([10.0], tf.float32)\n        x = tf.placeholder(tf.float32)\n        y = W * x + b\n    return W, b, x, y\n\n\nif __name__ == \"__main__\":\n    arguments = parse_command_arguments()\n    job_name = arguments.job_name\n    task_index = arguments.task_index\n    # Set up tensorflow configuration.\n    tf_config = tf.ConfigProto(\n        allow_soft_placement=True, device_count={'GPU': 1},\n        log_device_placement=True)\n    # Start a server.\n    server, cluster = start_server(job_name, task_index, tf_config)\n\n    if job_name == \"ps\":\n        server.join()\n    else:\n        worker_device = \"/gpu:0\"\n        W, b, x, y = model(cluster, worker_device=worker_device)\n        is_chief = (arguments.task_index == 0) and (\n            arguments.job_name == 'worker')\n        sess = tf.train.MonitoredTrainingSession(\n             master=server.target, is_chief=is_chief, config=tf_config)\n        # Run the model.\n        step = 0\n        x_train = [1, 2, 3, 4]\n        y_train = [0, -1, -2, -3]\n        while not sess.should_stop() and step &lt; 1000:\n            sess.run([y], {x: x_train, y: y_train})\n            step += 1\n</code></pre>\n<p>As the code uses <code>tf.train.replica_device_setter()</code> with <code>worker_device=\"/gpu:0\"</code>, I imagine all tensorflow <code>Variable</code> ops go to the parameter server, while all other type of ops stay in the worker.</p>\n<p>However, if we run the above code:<br>\n<code>$ python test.py --job_name ps --task_index 0</code><br>\n<code>$ python test.py --job_name worker --task_index 0</code><br>\n<code>$ python test.py --job_name worker --task_index 1</code><br>\nI notice that all tensorflow ops go to parameter server, for example in the worker log:<br>\n<code>report_uninitialized_variables/boolean_mask/strided_slice/stack_2: (Const)/job:ps/replica:0/task:0/gpu:0</code>.</p>\n<p>But if I change <code>worker_device=\"/gpu:0\"</code> in the code to <code>worker_device=\"/job:worker/task:0/gpu:0\"</code>, then the result is correct (all non-Variable ops go to worker). So does it mean there is a bug for <code>tf.train.replica_device_setter()</code> to automatically assign devices?</p>\n<p>P.S The above code runs on single GPU (TITAN X (Pascal)/PCIe/SSE2) with Ubuntu 16.04, Python 3.5 and Tensorflow v1.2</p>", "body_text": "I recently found an interesting issue on device assignment when I ran the following simple code test.py:\nimport argparse\nimport tensorflow as tf\n\nCLUSTER_SPEC = {\"ps\": [\"localhost:2222\"],\n                \"worker\": [\"localhost:1111\", \"localhost:1112\"]}\n\n\ndef parse_command_arguments():\n    \"\"\" Set up and parse the command line arguments. \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Parameters and Arguments for the Test.\")\n    parser.add_argument(\n        \"--job_name\", type=str, default=\"\", help=\"One of 'ps', 'worker'\")\n    parser.add_argument(\n        \"--task_index\", type=int, default=0, help=\"Index of task\")\n    return parser.parse_args()\n\n\ndef start_server(job_name, task_index, tf_config):\n    \"\"\" Create a server based on a cluster spec. \"\"\"\n    cluster = tf.train.ClusterSpec(CLUSTER_SPEC)\n    server = tf.train.Server(\n        cluster, config=tf_config, job_name=job_name, task_index=task_index)\n    return server, cluster\n\n\ndef model(cluster=None, worker_device=None):\n    \"\"\" Build up a simple estimator model. \"\"\"\n    with tf.device(tf.train.replica_device_setter(\n            worker_device=worker_device, cluster=cluster)):\n        W = tf.Variable([1.0], tf.float32)\n        b = tf.Variable([10.0], tf.float32)\n        x = tf.placeholder(tf.float32)\n        y = W * x + b\n    return W, b, x, y\n\n\nif __name__ == \"__main__\":\n    arguments = parse_command_arguments()\n    job_name = arguments.job_name\n    task_index = arguments.task_index\n    # Set up tensorflow configuration.\n    tf_config = tf.ConfigProto(\n        allow_soft_placement=True, device_count={'GPU': 1},\n        log_device_placement=True)\n    # Start a server.\n    server, cluster = start_server(job_name, task_index, tf_config)\n\n    if job_name == \"ps\":\n        server.join()\n    else:\n        worker_device = \"/gpu:0\"\n        W, b, x, y = model(cluster, worker_device=worker_device)\n        is_chief = (arguments.task_index == 0) and (\n            arguments.job_name == 'worker')\n        sess = tf.train.MonitoredTrainingSession(\n             master=server.target, is_chief=is_chief, config=tf_config)\n        # Run the model.\n        step = 0\n        x_train = [1, 2, 3, 4]\n        y_train = [0, -1, -2, -3]\n        while not sess.should_stop() and step < 1000:\n            sess.run([y], {x: x_train, y: y_train})\n            step += 1\n\nAs the code uses tf.train.replica_device_setter() with worker_device=\"/gpu:0\", I imagine all tensorflow Variable ops go to the parameter server, while all other type of ops stay in the worker.\nHowever, if we run the above code:\n$ python test.py --job_name ps --task_index 0\n$ python test.py --job_name worker --task_index 0\n$ python test.py --job_name worker --task_index 1\nI notice that all tensorflow ops go to parameter server, for example in the worker log:\nreport_uninitialized_variables/boolean_mask/strided_slice/stack_2: (Const)/job:ps/replica:0/task:0/gpu:0.\nBut if I change worker_device=\"/gpu:0\" in the code to worker_device=\"/job:worker/task:0/gpu:0\", then the result is correct (all non-Variable ops go to worker). So does it mean there is a bug for tf.train.replica_device_setter() to automatically assign devices?\nP.S The above code runs on single GPU (TITAN X (Pascal)/PCIe/SSE2) with Ubuntu 16.04, Python 3.5 and Tensorflow v1.2", "body": "I recently found an interesting issue on device assignment when I ran the following simple code `test.py`:\r\n\r\n```\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\nCLUSTER_SPEC = {\"ps\": [\"localhost:2222\"],\r\n                \"worker\": [\"localhost:1111\", \"localhost:1112\"]}\r\n\r\n\r\ndef parse_command_arguments():\r\n    \"\"\" Set up and parse the command line arguments. \"\"\"\r\n    parser = argparse.ArgumentParser(\r\n        description=\"Parameters and Arguments for the Test.\")\r\n    parser.add_argument(\r\n        \"--job_name\", type=str, default=\"\", help=\"One of 'ps', 'worker'\")\r\n    parser.add_argument(\r\n        \"--task_index\", type=int, default=0, help=\"Index of task\")\r\n    return parser.parse_args()\r\n\r\n\r\ndef start_server(job_name, task_index, tf_config):\r\n    \"\"\" Create a server based on a cluster spec. \"\"\"\r\n    cluster = tf.train.ClusterSpec(CLUSTER_SPEC)\r\n    server = tf.train.Server(\r\n        cluster, config=tf_config, job_name=job_name, task_index=task_index)\r\n    return server, cluster\r\n\r\n\r\ndef model(cluster=None, worker_device=None):\r\n    \"\"\" Build up a simple estimator model. \"\"\"\r\n    with tf.device(tf.train.replica_device_setter(\r\n            worker_device=worker_device, cluster=cluster)):\r\n        W = tf.Variable([1.0], tf.float32)\r\n        b = tf.Variable([10.0], tf.float32)\r\n        x = tf.placeholder(tf.float32)\r\n        y = W * x + b\r\n    return W, b, x, y\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    arguments = parse_command_arguments()\r\n    job_name = arguments.job_name\r\n    task_index = arguments.task_index\r\n    # Set up tensorflow configuration.\r\n    tf_config = tf.ConfigProto(\r\n        allow_soft_placement=True, device_count={'GPU': 1},\r\n        log_device_placement=True)\r\n    # Start a server.\r\n    server, cluster = start_server(job_name, task_index, tf_config)\r\n\r\n    if job_name == \"ps\":\r\n        server.join()\r\n    else:\r\n        worker_device = \"/gpu:0\"\r\n        W, b, x, y = model(cluster, worker_device=worker_device)\r\n        is_chief = (arguments.task_index == 0) and (\r\n            arguments.job_name == 'worker')\r\n        sess = tf.train.MonitoredTrainingSession(\r\n             master=server.target, is_chief=is_chief, config=tf_config)\r\n        # Run the model.\r\n        step = 0\r\n        x_train = [1, 2, 3, 4]\r\n        y_train = [0, -1, -2, -3]\r\n        while not sess.should_stop() and step < 1000:\r\n            sess.run([y], {x: x_train, y: y_train})\r\n            step += 1\r\n```\r\nAs the code uses `tf.train.replica_device_setter()` with `worker_device=\"/gpu:0\"`, I imagine all tensorflow `Variable` ops go to the parameter server, while all other type of ops stay in the worker.\r\n\r\nHowever, if we run the above code:\r\n`$ python test.py --job_name ps --task_index 0`\r\n`$ python test.py --job_name worker --task_index 0`\r\n`$ python test.py --job_name worker --task_index 1`\r\nI notice that all tensorflow ops go to parameter server, for example in the worker log: \r\n`report_uninitialized_variables/boolean_mask/strided_slice/stack_2: (Const)/job:ps/replica:0/task:0/gpu:0`.\r\n\r\nBut if I change `worker_device=\"/gpu:0\"` in the code to `worker_device=\"/job:worker/task:0/gpu:0\"`, then the result is correct (all non-Variable ops go to worker). So does it mean there is a bug for `tf.train.replica_device_setter()` to automatically assign devices?\r\n\r\nP.S The above code runs on single GPU (TITAN X (Pascal)/PCIe/SSE2) with Ubuntu 16.04, Python 3.5 and Tensorflow v1.2"}