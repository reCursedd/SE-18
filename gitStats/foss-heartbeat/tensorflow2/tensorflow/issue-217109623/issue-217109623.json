{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8734", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8734/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8734/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8734/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8734", "id": 217109623, "node_id": "MDU6SXNzdWUyMTcxMDk2MjM=", "number": 8734, "title": "Tensorflow GPU \"no known devices\" after update from version 0.12.1 to 1.0.1 - everything was fine before", "user": {"login": "pierluigiferrari", "id": 17439178, "node_id": "MDQ6VXNlcjE3NDM5MTc4", "avatar_url": "https://avatars1.githubusercontent.com/u/17439178?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pierluigiferrari", "html_url": "https://github.com/pierluigiferrari", "followers_url": "https://api.github.com/users/pierluigiferrari/followers", "following_url": "https://api.github.com/users/pierluigiferrari/following{/other_user}", "gists_url": "https://api.github.com/users/pierluigiferrari/gists{/gist_id}", "starred_url": "https://api.github.com/users/pierluigiferrari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pierluigiferrari/subscriptions", "organizations_url": "https://api.github.com/users/pierluigiferrari/orgs", "repos_url": "https://api.github.com/users/pierluigiferrari/repos", "events_url": "https://api.github.com/users/pierluigiferrari/events{/privacy}", "received_events_url": "https://api.github.com/users/pierluigiferrari/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-03-27T00:50:41Z", "updated_at": "2017-06-16T21:32:35Z", "closed_at": "2017-06-16T21:32:35Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System:</p>\n<p>Ubuntu Linux 16.04</p>\n<p>Installed version of CUDA and cuDNN:</p>\n<p>CUDA 8.0.44<br>\ncuDNN 5.1.10<br>\nDriver version 367.57.0</p>\n<p>Output of <code>ls -l /path/to/cuda/lib/libcud*</code>:</p>\n<p>-rw-r--r-- 1 root root   558720 Sep 14  2016 /usr/local/cuda/lib64/libcudadevrt.a<br>\nlrwxrwxrwx 1 root root       16 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0<br>\nlrwxrwxrwx 1 root root       19 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44<br>\n-rw-r--r-- 1 root root   415432 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so.8.0.44<br>\n-rw-r--r-- 1 root root   775162 Sep 14  2016 /usr/local/cuda/lib64/libcudart_static.a<br>\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so<br>\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so.5<br>\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so.5.1.10<br>\n-rw-r--r-- 1 root root 70364814 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn_static.a</p>\n<p>If installed from binary pip package, provide:</p>\n<p>A link to the pip package you installed: I don't know what you mean by that :(</p>\n<p>Tensorflow versions:<br>\n0.12.1 before the issue<br>\n1.0.1 caused the issue</p>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>On an AWS g2.2xlarge instance with<br>\n* Ubuntu 16.04,<br>\n* CUDA and cuDNN versions as listed above<br>\n* tensorflow-gpu 0.12.1 installed using pip<br>\nrun the example code from the <a href=\"https://www.tensorflow.org/tutorials/using_gpu\" rel=\"nofollow\">tensorflow \"Using GPUs\" website</a>.</p>\n<p>The output for me is:</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 3.94GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GRID K520, pci bus id: 0000:00:03.0\nI tensorflow/core/common_runtime/direct_session.cc:255] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GRID K520, pci bus id: 0000:00:03.0\n\nMatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0\nb: (Const): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] b: (Const)/job:localhost/replica:0/task:0/gpu:0\na: (Const): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] a: (Const)/job:localhost/replica:0/task:0/gpu:0\n[[ 22.  28.]\n [ 49.  64.]]\n</code></pre>\n<p>Now update Tensorflow</p>\n<p><code>pip install tensorflow-gpu --upgrade</code></p>\n<p>and run the example code again. Now the output for me is:</p>\n<pre><code>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nDevice mapping: no known devices.\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\n\nMatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:841] MatMul: (MatMul)/job:localhost/replica:0/task:0/cpu:0\nb: (Const): /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:841] b: (Const)/job:localhost/replica:0/task:0/cpu:0\na: (Const): /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:841] a: (Const)/job:localhost/replica:0/task:0/cpu:0\n[[ 22.  28.]\n [ 49.  64.]]\n</code></pre>\n<p>It's not even giving me any hints as to what might be the problem, it just says \"no known devices\".</p>\n<p>How come the GRID K520 was a known device <strong>just</strong> before I updated Tensorflow and now it isn't anymore?</p>\n<p>Nothing else happened in the meantime apart from updating Tensorflow, no other changes to the system were made in any way (at least not from my side).</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>nvidia-smi output:</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.57                 Driver Version: 367.57                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   39C    P0    38W / 125W |      0MiB /  4036MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n</code></pre>", "body_text": "Environment info\nOperating System:\nUbuntu Linux 16.04\nInstalled version of CUDA and cuDNN:\nCUDA 8.0.44\ncuDNN 5.1.10\nDriver version 367.57.0\nOutput of ls -l /path/to/cuda/lib/libcud*:\n-rw-r--r-- 1 root root   558720 Sep 14  2016 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rw-r--r-- 1 root root   415432 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Sep 14  2016 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so.5.1.10\n-rw-r--r-- 1 root root 70364814 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn_static.a\nIf installed from binary pip package, provide:\nA link to the pip package you installed: I don't know what you mean by that :(\nTensorflow versions:\n0.12.1 before the issue\n1.0.1 caused the issue\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nOn an AWS g2.2xlarge instance with\n* Ubuntu 16.04,\n* CUDA and cuDNN versions as listed above\n* tensorflow-gpu 0.12.1 installed using pip\nrun the example code from the tensorflow \"Using GPUs\" website.\nThe output for me is:\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 3.94GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0\nI tensorflow/core/common_runtime/direct_session.cc:255] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0\n\nMatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0\nb: (Const): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] b: (Const)/job:localhost/replica:0/task:0/gpu:0\na: (Const): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] a: (Const)/job:localhost/replica:0/task:0/gpu:0\n[[ 22.  28.]\n [ 49.  64.]]\n\nNow update Tensorflow\npip install tensorflow-gpu --upgrade\nand run the example code again. Now the output for me is:\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nDevice mapping: no known devices.\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\n\nMatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:841] MatMul: (MatMul)/job:localhost/replica:0/task:0/cpu:0\nb: (Const): /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:841] b: (Const)/job:localhost/replica:0/task:0/cpu:0\na: (Const): /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:841] a: (Const)/job:localhost/replica:0/task:0/cpu:0\n[[ 22.  28.]\n [ 49.  64.]]\n\nIt's not even giving me any hints as to what might be the problem, it just says \"no known devices\".\nHow come the GRID K520 was a known device just before I updated Tensorflow and now it isn't anymore?\nNothing else happened in the meantime apart from updating Tensorflow, no other changes to the system were made in any way (at least not from my side).\nLogs or other output that would be helpful\nnvidia-smi output:\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.57                 Driver Version: 367.57                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   39C    P0    38W / 125W |      0MiB /  4036MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+", "body": "### Environment info\r\n\r\nOperating System:\r\n\r\nUbuntu Linux 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n\r\nCUDA 8.0.44\r\ncuDNN 5.1.10\r\nDriver version 367.57.0\r\n\r\nOutput of `ls -l /path/to/cuda/lib/libcud*`:\r\n\r\n-rw-r--r-- 1 root root   558720 Sep 14  2016 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   415432 Sep 14  2016 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 Sep 14  2016 /usr/local/cuda/lib64/libcudart_static.a\r\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so\r\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so.5\r\n-rwxr-xr-x 1 root root 84163560 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn.so.5.1.10\r\n-rw-r--r-- 1 root root 70364814 Mar 27 11:43 /usr/local/cuda/lib64/libcudnn_static.a\r\n\r\nIf installed from binary pip package, provide:\r\n\r\nA link to the pip package you installed: I don't know what you mean by that :(\r\n\r\nTensorflow versions:\r\n0.12.1 before the issue\r\n1.0.1 caused the issue\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nOn an AWS g2.2xlarge instance with\r\n    * Ubuntu 16.04, \r\n    * CUDA and cuDNN versions as listed above\r\n    * tensorflow-gpu 0.12.1 installed using pip\r\nrun the example code from the [tensorflow \"Using GPUs\" website](https://www.tensorflow.org/tutorials/using_gpu).\r\n\r\nThe output for me is:\r\n\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GRID K520\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\r\npciBusID 0000:00:03.0\r\nTotal memory: 3.94GiB\r\nFree memory: 3.91GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0\r\nI tensorflow/core/common_runtime/direct_session.cc:255] Device mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0\r\n\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0\r\nb: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] b: (Const)/job:localhost/replica:0/task:0/gpu:0\r\na: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] a: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n[[ 22.  28.]\r\n [ 49.  64.]]\r\n```\r\n\r\nNow update Tensorflow\r\n\r\n`pip install tensorflow-gpu --upgrade`\r\n\r\nand run the example code again. Now the output for me is:\r\n\r\n```\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nDevice mapping: no known devices.\r\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\r\n\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] MatMul: (MatMul)/job:localhost/replica:0/task:0/cpu:0\r\nb: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] b: (Const)/job:localhost/replica:0/task:0/cpu:0\r\na: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] a: (Const)/job:localhost/replica:0/task:0/cpu:0\r\n[[ 22.  28.]\r\n [ 49.  64.]]\r\n```\r\n\r\nIt's not even giving me any hints as to what might be the problem, it just says \"no known devices\". \r\n\r\nHow come the GRID K520 was a known device **just** before I updated Tensorflow and now it isn't anymore?\r\n\r\nNothing else happened in the meantime apart from updating Tensorflow, no other changes to the system were made in any way (at least not from my side).\r\n\r\n### Logs or other output that would be helpful\r\n\r\nnvidia-smi output:\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 367.57                 Driver Version: 367.57                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\r\n| N/A   39C    P0    38W / 125W |      0MiB /  4036MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```"}