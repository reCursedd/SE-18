{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/219056059", "html_url": "https://github.com/tensorflow/tensorflow/issues/2328#issuecomment-219056059", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2328", "id": 219056059, "node_id": "MDEyOklzc3VlQ29tbWVudDIxOTA1NjA1OQ==", "user": {"login": "rdadolf", "id": 6673605, "node_id": "MDQ6VXNlcjY2NzM2MDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/6673605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdadolf", "html_url": "https://github.com/rdadolf", "followers_url": "https://api.github.com/users/rdadolf/followers", "following_url": "https://api.github.com/users/rdadolf/following{/other_user}", "gists_url": "https://api.github.com/users/rdadolf/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdadolf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdadolf/subscriptions", "organizations_url": "https://api.github.com/users/rdadolf/orgs", "repos_url": "https://api.github.com/users/rdadolf/repos", "events_url": "https://api.github.com/users/rdadolf/events{/privacy}", "received_events_url": "https://api.github.com/users/rdadolf/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-13T14:17:55Z", "updated_at": "2016-05-13T14:17:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Just pulling in the conversation from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"154166354\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2318\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2318/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2318\">#2318</a>, since it's really more appropriate here.</p>\n<p>The downside of this feature is type errors can become harder to hunt down. For instance, having a dimension typo can become a logical error, especially if it's compounded with broadcasting.</p>\n<p>While manually converting heterogeneous structures may seem tedious, it's also clearer what's going on. It might seem that <code>tf.convert_to_tensor([tf.constant(1), 2])</code> is already pretty clear, but if you add a couple layers of variables in between and end up with <code>tf.convert_to_tensor([x,y])</code>, a type error is pretty easy to lose.</p>\n<p>My feeling is \"explicit is better than implicit\" here. Perhaps there's some compromise where we don't do recursive auto-coercion for all things that can take tensors? Maybe just allow a single explicit method to handle this behavior? <code>convert_to_tensor</code> <em>would</em> seem like a decent candidate, so the above code would become:</p>\n<pre><code>tf.convert_to_tensor([tf.constant(1), 2]) # works, this is the explicit coercion method\ntf.slice(..., tf.convert_to_tensor([0, 1, some_tensor]), ...)\n</code></pre>", "body_text": "Just pulling in the conversation from #2318, since it's really more appropriate here.\nThe downside of this feature is type errors can become harder to hunt down. For instance, having a dimension typo can become a logical error, especially if it's compounded with broadcasting.\nWhile manually converting heterogeneous structures may seem tedious, it's also clearer what's going on. It might seem that tf.convert_to_tensor([tf.constant(1), 2]) is already pretty clear, but if you add a couple layers of variables in between and end up with tf.convert_to_tensor([x,y]), a type error is pretty easy to lose.\nMy feeling is \"explicit is better than implicit\" here. Perhaps there's some compromise where we don't do recursive auto-coercion for all things that can take tensors? Maybe just allow a single explicit method to handle this behavior? convert_to_tensor would seem like a decent candidate, so the above code would become:\ntf.convert_to_tensor([tf.constant(1), 2]) # works, this is the explicit coercion method\ntf.slice(..., tf.convert_to_tensor([0, 1, some_tensor]), ...)", "body": "Just pulling in the conversation from #2318, since it's really more appropriate here.\n\nThe downside of this feature is type errors can become harder to hunt down. For instance, having a dimension typo can become a logical error, especially if it's compounded with broadcasting.\n\nWhile manually converting heterogeneous structures may seem tedious, it's also clearer what's going on. It might seem that `tf.convert_to_tensor([tf.constant(1), 2])` is already pretty clear, but if you add a couple layers of variables in between and end up with `tf.convert_to_tensor([x,y])`, a type error is pretty easy to lose.\n\nMy feeling is \"explicit is better than implicit\" here. Perhaps there's some compromise where we don't do recursive auto-coercion for all things that can take tensors? Maybe just allow a single explicit method to handle this behavior? `convert_to_tensor` _would_ seem like a decent candidate, so the above code would become:\n\n```\ntf.convert_to_tensor([tf.constant(1), 2]) # works, this is the explicit coercion method\ntf.slice(..., tf.convert_to_tensor([0, 1, some_tensor]), ...)\n```\n"}