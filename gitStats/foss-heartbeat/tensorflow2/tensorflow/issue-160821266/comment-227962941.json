{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227962941", "html_url": "https://github.com/tensorflow/tensorflow/issues/2923#issuecomment-227962941", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2923", "id": 227962941, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzk2Mjk0MQ==", "user": {"login": "qemb01", "id": 8786921, "node_id": "MDQ6VXNlcjg3ODY5MjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/8786921?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qemb01", "html_url": "https://github.com/qemb01", "followers_url": "https://api.github.com/users/qemb01/followers", "following_url": "https://api.github.com/users/qemb01/following{/other_user}", "gists_url": "https://api.github.com/users/qemb01/gists{/gist_id}", "starred_url": "https://api.github.com/users/qemb01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qemb01/subscriptions", "organizations_url": "https://api.github.com/users/qemb01/orgs", "repos_url": "https://api.github.com/users/qemb01/repos", "events_url": "https://api.github.com/users/qemb01/events{/privacy}", "received_events_url": "https://api.github.com/users/qemb01/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-23T06:38:42Z", "updated_at": "2016-06-23T20:42:08Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11547801\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/prb12\">@prb12</a> Of course, here is my code in cifar10_train.py:</p>\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom datetime import datetime\nimport os.path\nimport time\nimport os\n\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\nimport os\nfrom tensorflow.python.platform import gfile\n\nfrom tensorflow.models.image.cifar10 import cifar10\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\n                           \"\"\"Directory where to write event logs \"\"\"\n                           \"\"\"and checkpoint.\"\"\")\ntf.app.flags.DEFINE_integer('max_steps', 20000,\n                            \"\"\"Number of batches to run.\"\"\")\ntf.app.flags.DEFINE_boolean('log_device_placement', False,\n                            \"\"\"Whether to log device placement.\"\"\")\n\n\ndef train():\n  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n  with tf.Graph().as_default():\n    global_step = tf.Variable(0, trainable=False)\n\n    # Get images and labels for CIFAR-10.\n    images, labels = cifar10.distorted_inputs()\n\n    # Build a Graph that computes the logits predictions from the\n    # inference model.\n    logits = cifar10.inference(images)\n\n    # Calculate loss.\n    loss = cifar10.loss(logits, labels)\n\n    # Build a Graph that trains the model with one batch of examples and\n    # updates the model parameters.\n    train_op = cifar10.train(loss, global_step)\n\n    # Create a saver.\n    saver = tf.train.Saver(tf.all_variables())\n\n    # Build the summary operation based on the TF collection of Summaries.\n    summary_op = tf.merge_all_summaries()\n\n    # Build an initialization operation to run below.\n    init = tf.initialize_all_variables()\n\n    # Start running operations on the Graph.\n    sess = tf.Session(config=tf.ConfigProto(\n        log_device_placement=FLAGS.log_device_placement))\n    sess.run(init)\n\n\n    # Start the queue runners.\n    tf.train.start_queue_runners(sess=sess)\n\n    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir,\n                                            graph_def=sess.graph_def)\n\n    for step in xrange(FLAGS.max_steps):\n      start_time = time.time()\n      _, loss_value = sess.run([train_op, loss])\n      duration = time.time() - start_time\n\n      assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n\n      if step % 10 == 0:\n        num_examples_per_step = FLAGS.batch_size\n        examples_per_sec = num_examples_per_step / duration\n        sec_per_batch = float(duration)\n\n        format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n                      'sec/batch)')\n        print (format_str % (datetime.now(), step, loss_value,\n                             examples_per_sec, sec_per_batch))\n\n      if step % 100 == 0:\n        summary_str = sess.run(summary_op)\n        summary_writer.add_summary(summary_str, step)\n\n      # Save the model checkpoint periodically.\n      if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n        saver.save(sess, checkpoint_path, global_step=step)\n\ndef save_graph():\n\n    g = tf.Graph()\n    vars = {}\n    with g.as_default():\n        with tf.Session() as sess:\n            d = np.ones([128,24,24,3],dtype=np.float32)\n            images, labels = cifar10.distorted_inputs()\n            logits = cifar10.inference(images)\n\n            init = tf.initialize_all_variables()\n            sess.run(init)\n            saver = tf.train.Saver(tf.trainable_variables(),max_to_keep=0)\n            saver.restore(sess,os.path.join(FLAGS.train_dir, 'model.ckpt-19999'))\n\n            print (sess.run(logits,{images:d}))\n            for v in tf.trainable_variables():\n                vars[v.value().name] = sess.run(v)\n\n\n    g2 = tf.Graph()\n    consts = {}\n    with g2.as_default():\n        with tf.Session() as sess:\n            for k in vars.keys():\n                consts[k] = tf.constant(vars[k])\n            tf.import_graph_def(g.as_graph_def(),input_map={name:consts[name] for name in consts.keys()})\n\n            tf.train.write_graph(sess.graph_def,'/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb',False)\n\n    return os.path.join('/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb')\n\n\ndef main(argv=None):  # pylint: disable=unused-argument\n  cifar10.maybe_download_and_extract()\n  if tf.gfile.Exists(FLAGS.train_dir):\n    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n  tf.gfile.MakeDirs(FLAGS.train_dir)\n  train()\n  save_graph()\n\nif __name__ == '__main__':\n  tf.app.run()\n</code></pre>\n<p>I have run the cifar10_train.py to get pb file. Then I replace the tensorflow_inception_graph.pb with it. The tensorflow_inception_graph.pb is in the /tensorflow/tensorflow/tree/master/tensorflow/examples/android/assets/ of tensorflow android camera demo.</p>\n<p>Tensorflow android camera demo:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android</a></p>", "body_text": "@prb12 Of course, here is my code in cifar10_train.py:\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom datetime import datetime\nimport os.path\nimport time\nimport os\n\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\nimport os\nfrom tensorflow.python.platform import gfile\n\nfrom tensorflow.models.image.cifar10 import cifar10\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\n                           \"\"\"Directory where to write event logs \"\"\"\n                           \"\"\"and checkpoint.\"\"\")\ntf.app.flags.DEFINE_integer('max_steps', 20000,\n                            \"\"\"Number of batches to run.\"\"\")\ntf.app.flags.DEFINE_boolean('log_device_placement', False,\n                            \"\"\"Whether to log device placement.\"\"\")\n\n\ndef train():\n  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n  with tf.Graph().as_default():\n    global_step = tf.Variable(0, trainable=False)\n\n    # Get images and labels for CIFAR-10.\n    images, labels = cifar10.distorted_inputs()\n\n    # Build a Graph that computes the logits predictions from the\n    # inference model.\n    logits = cifar10.inference(images)\n\n    # Calculate loss.\n    loss = cifar10.loss(logits, labels)\n\n    # Build a Graph that trains the model with one batch of examples and\n    # updates the model parameters.\n    train_op = cifar10.train(loss, global_step)\n\n    # Create a saver.\n    saver = tf.train.Saver(tf.all_variables())\n\n    # Build the summary operation based on the TF collection of Summaries.\n    summary_op = tf.merge_all_summaries()\n\n    # Build an initialization operation to run below.\n    init = tf.initialize_all_variables()\n\n    # Start running operations on the Graph.\n    sess = tf.Session(config=tf.ConfigProto(\n        log_device_placement=FLAGS.log_device_placement))\n    sess.run(init)\n\n\n    # Start the queue runners.\n    tf.train.start_queue_runners(sess=sess)\n\n    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir,\n                                            graph_def=sess.graph_def)\n\n    for step in xrange(FLAGS.max_steps):\n      start_time = time.time()\n      _, loss_value = sess.run([train_op, loss])\n      duration = time.time() - start_time\n\n      assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n\n      if step % 10 == 0:\n        num_examples_per_step = FLAGS.batch_size\n        examples_per_sec = num_examples_per_step / duration\n        sec_per_batch = float(duration)\n\n        format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n                      'sec/batch)')\n        print (format_str % (datetime.now(), step, loss_value,\n                             examples_per_sec, sec_per_batch))\n\n      if step % 100 == 0:\n        summary_str = sess.run(summary_op)\n        summary_writer.add_summary(summary_str, step)\n\n      # Save the model checkpoint periodically.\n      if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n        saver.save(sess, checkpoint_path, global_step=step)\n\ndef save_graph():\n\n    g = tf.Graph()\n    vars = {}\n    with g.as_default():\n        with tf.Session() as sess:\n            d = np.ones([128,24,24,3],dtype=np.float32)\n            images, labels = cifar10.distorted_inputs()\n            logits = cifar10.inference(images)\n\n            init = tf.initialize_all_variables()\n            sess.run(init)\n            saver = tf.train.Saver(tf.trainable_variables(),max_to_keep=0)\n            saver.restore(sess,os.path.join(FLAGS.train_dir, 'model.ckpt-19999'))\n\n            print (sess.run(logits,{images:d}))\n            for v in tf.trainable_variables():\n                vars[v.value().name] = sess.run(v)\n\n\n    g2 = tf.Graph()\n    consts = {}\n    with g2.as_default():\n        with tf.Session() as sess:\n            for k in vars.keys():\n                consts[k] = tf.constant(vars[k])\n            tf.import_graph_def(g.as_graph_def(),input_map={name:consts[name] for name in consts.keys()})\n\n            tf.train.write_graph(sess.graph_def,'/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb',False)\n\n    return os.path.join('/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb')\n\n\ndef main(argv=None):  # pylint: disable=unused-argument\n  cifar10.maybe_download_and_extract()\n  if tf.gfile.Exists(FLAGS.train_dir):\n    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n  tf.gfile.MakeDirs(FLAGS.train_dir)\n  train()\n  save_graph()\n\nif __name__ == '__main__':\n  tf.app.run()\n\nI have run the cifar10_train.py to get pb file. Then I replace the tensorflow_inception_graph.pb with it. The tensorflow_inception_graph.pb is in the /tensorflow/tensorflow/tree/master/tensorflow/examples/android/assets/ of tensorflow android camera demo.\nTensorflow android camera demo:\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android", "body": "@prb12 Of course, here is my code in cifar10_train.py:\n\n```\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom datetime import datetime\nimport os.path\nimport time\nimport os\n\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\nimport os\nfrom tensorflow.python.platform import gfile\n\nfrom tensorflow.models.image.cifar10 import cifar10\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\n                           \"\"\"Directory where to write event logs \"\"\"\n                           \"\"\"and checkpoint.\"\"\")\ntf.app.flags.DEFINE_integer('max_steps', 20000,\n                            \"\"\"Number of batches to run.\"\"\")\ntf.app.flags.DEFINE_boolean('log_device_placement', False,\n                            \"\"\"Whether to log device placement.\"\"\")\n\n\ndef train():\n  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n  with tf.Graph().as_default():\n    global_step = tf.Variable(0, trainable=False)\n\n    # Get images and labels for CIFAR-10.\n    images, labels = cifar10.distorted_inputs()\n\n    # Build a Graph that computes the logits predictions from the\n    # inference model.\n    logits = cifar10.inference(images)\n\n    # Calculate loss.\n    loss = cifar10.loss(logits, labels)\n\n    # Build a Graph that trains the model with one batch of examples and\n    # updates the model parameters.\n    train_op = cifar10.train(loss, global_step)\n\n    # Create a saver.\n    saver = tf.train.Saver(tf.all_variables())\n\n    # Build the summary operation based on the TF collection of Summaries.\n    summary_op = tf.merge_all_summaries()\n\n    # Build an initialization operation to run below.\n    init = tf.initialize_all_variables()\n\n    # Start running operations on the Graph.\n    sess = tf.Session(config=tf.ConfigProto(\n        log_device_placement=FLAGS.log_device_placement))\n    sess.run(init)\n\n\n    # Start the queue runners.\n    tf.train.start_queue_runners(sess=sess)\n\n    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir,\n                                            graph_def=sess.graph_def)\n\n    for step in xrange(FLAGS.max_steps):\n      start_time = time.time()\n      _, loss_value = sess.run([train_op, loss])\n      duration = time.time() - start_time\n\n      assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n\n      if step % 10 == 0:\n        num_examples_per_step = FLAGS.batch_size\n        examples_per_sec = num_examples_per_step / duration\n        sec_per_batch = float(duration)\n\n        format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n                      'sec/batch)')\n        print (format_str % (datetime.now(), step, loss_value,\n                             examples_per_sec, sec_per_batch))\n\n      if step % 100 == 0:\n        summary_str = sess.run(summary_op)\n        summary_writer.add_summary(summary_str, step)\n\n      # Save the model checkpoint periodically.\n      if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n        saver.save(sess, checkpoint_path, global_step=step)\n\ndef save_graph():\n\n    g = tf.Graph()\n    vars = {}\n    with g.as_default():\n        with tf.Session() as sess:\n            d = np.ones([128,24,24,3],dtype=np.float32)\n            images, labels = cifar10.distorted_inputs()\n            logits = cifar10.inference(images)\n\n            init = tf.initialize_all_variables()\n            sess.run(init)\n            saver = tf.train.Saver(tf.trainable_variables(),max_to_keep=0)\n            saver.restore(sess,os.path.join(FLAGS.train_dir, 'model.ckpt-19999'))\n\n            print (sess.run(logits,{images:d}))\n            for v in tf.trainable_variables():\n                vars[v.value().name] = sess.run(v)\n\n\n    g2 = tf.Graph()\n    consts = {}\n    with g2.as_default():\n        with tf.Session() as sess:\n            for k in vars.keys():\n                consts[k] = tf.constant(vars[k])\n            tf.import_graph_def(g.as_graph_def(),input_map={name:consts[name] for name in consts.keys()})\n\n            tf.train.write_graph(sess.graph_def,'/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb',False)\n\n    return os.path.join('/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb')\n\n\ndef main(argv=None):  # pylint: disable=unused-argument\n  cifar10.maybe_download_and_extract()\n  if tf.gfile.Exists(FLAGS.train_dir):\n    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n  tf.gfile.MakeDirs(FLAGS.train_dir)\n  train()\n  save_graph()\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n\nI have run the cifar10_train.py to get pb file. Then I replace the tensorflow_inception_graph.pb with it. The tensorflow_inception_graph.pb is in the /tensorflow/tensorflow/tree/master/tensorflow/examples/android/assets/ of tensorflow android camera demo.\n\nTensorflow android camera demo:\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\n"}