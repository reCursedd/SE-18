{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8265", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8265/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8265/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8265/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8265", "id": 213254486, "node_id": "MDU6SXNzdWUyMTMyNTQ0ODY=", "number": 8265, "title": "Memory leak when writing to Logfile with Tensorboard summarywriter", "user": {"login": "falaktheoptimist", "id": 7119249, "node_id": "MDQ6VXNlcjcxMTkyNDk=", "avatar_url": "https://avatars0.githubusercontent.com/u/7119249?v=4", "gravatar_id": "", "url": "https://api.github.com/users/falaktheoptimist", "html_url": "https://github.com/falaktheoptimist", "followers_url": "https://api.github.com/users/falaktheoptimist/followers", "following_url": "https://api.github.com/users/falaktheoptimist/following{/other_user}", "gists_url": "https://api.github.com/users/falaktheoptimist/gists{/gist_id}", "starred_url": "https://api.github.com/users/falaktheoptimist/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/falaktheoptimist/subscriptions", "organizations_url": "https://api.github.com/users/falaktheoptimist/orgs", "repos_url": "https://api.github.com/users/falaktheoptimist/repos", "events_url": "https://api.github.com/users/falaktheoptimist/events{/privacy}", "received_events_url": "https://api.github.com/users/falaktheoptimist/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "decentralion", "id": 1400023, "node_id": "MDQ6VXNlcjE0MDAwMjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1400023?v=4", "gravatar_id": "", "url": "https://api.github.com/users/decentralion", "html_url": "https://github.com/decentralion", "followers_url": "https://api.github.com/users/decentralion/followers", "following_url": "https://api.github.com/users/decentralion/following{/other_user}", "gists_url": "https://api.github.com/users/decentralion/gists{/gist_id}", "starred_url": "https://api.github.com/users/decentralion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/decentralion/subscriptions", "organizations_url": "https://api.github.com/users/decentralion/orgs", "repos_url": "https://api.github.com/users/decentralion/repos", "events_url": "https://api.github.com/users/decentralion/events{/privacy}", "received_events_url": "https://api.github.com/users/decentralion/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "decentralion", "id": 1400023, "node_id": "MDQ6VXNlcjE0MDAwMjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1400023?v=4", "gravatar_id": "", "url": "https://api.github.com/users/decentralion", "html_url": "https://github.com/decentralion", "followers_url": "https://api.github.com/users/decentralion/followers", "following_url": "https://api.github.com/users/decentralion/following{/other_user}", "gists_url": "https://api.github.com/users/decentralion/gists{/gist_id}", "starred_url": "https://api.github.com/users/decentralion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/decentralion/subscriptions", "organizations_url": "https://api.github.com/users/decentralion/orgs", "repos_url": "https://api.github.com/users/decentralion/repos", "events_url": "https://api.github.com/users/decentralion/events{/privacy}", "received_events_url": "https://api.github.com/users/decentralion/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2017-03-10T06:16:04Z", "updated_at": "2017-04-18T05:01:42Z", "closed_at": "2017-04-11T05:38:32Z", "author_association": "NONE", "body_html": "<h3>Issue:</h3>\n<p>Memory occupied after call to Filewriter not being freed till python termination. This causes accumulation of data and subsequent filling up of RAM which is freed only when the entire script completes execution and python is terminated.</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 16.04<br>\nCUDA/cuDNN : Not installed<br>\nLink to the pip package you : <a href=\"https://github.com/tensorflow/tensorflow/releases/tag/v1.0.0\">https://github.com/tensorflow/tensorflow/releases/tag/v1.0.0</a><br>\nTensorflow version: 1.0.0</p>\n<h3>A small script replicating the issue</h3>\n<pre><code>import os\nimport numpy as np\nimport tensorflow as tf\nfrom memory_profiler import profile\nimport time\n\n@profile\ndef _write_into_log(images):\n    path_logdir = os.path.join(\"./MiniExample\")\n    if not os.path.exists(path_logdir):\n        os.makedirs(path_logdir)\n\n    with tf.Graph().as_default() as g:\n        image = tf.placeholder(tf.float32, shape = [None, None, None, 3])\n\n        image_summary = tf.summary.image(name = \"Images\", tensor = image, max_outputs = 2000)\n\n        with tf.Session() as sess:\n            summary = sess.run(image_summary, feed_dict = {image : np.concatenate(images, axis = 0)})\n            file_writer = tf.summary.FileWriter(path_logdir, g)\n            file_writer.add_summary(summary)\n            file_writer.close()\n\n@profile\ndef main():\n    out = [np.random.random((1, 224, 224, 3)) for i in range(2000)]\n    _write_into_log(out)\n    out = None\n    time.sleep(10)\n\nmain()\n</code></pre>\n<h3>Logs or other output that would be helpful</h3>\n<p>Python memory profiler output</p>\n<pre><code>$ python test.py \nFilename: test.py\n\nLine #    Mem usage    Increment   Line Contents\n================================================\n     7   2394.5 MiB      0.0 MiB   @profile\n     8                             def _write_into_log(images):\n     9   2394.5 MiB      0.0 MiB       path_logdir = os.path.join(\"./MiniExample\")\n    10   2394.5 MiB      0.0 MiB       if not os.path.exists(path_logdir):\n    11                                     os.makedirs(path_logdir)\n    12                             \n    13   2394.6 MiB      0.0 MiB       with tf.Graph().as_default() as g:\n    14   2399.0 MiB      4.4 MiB           image = tf.placeholder(tf.float32, shape = [None, None, None, 3])\n    15                             \n    16   2399.1 MiB      0.1 MiB           image_summary = tf.summary.image(name = \"Images\", tensor = image, max_outputs = 2000)\n    17                             \n    18   2407.9 MiB      8.9 MiB           with tf.Session() as sess:\n    19   2978.8 MiB    570.9 MiB               summary = sess.run(image_summary, feed_dict = {image : np.concatenate(images, axis = 0)})\n    20   2980.8 MiB      2.0 MiB               file_writer = tf.summary.FileWriter(path_logdir, g)\n    21   3269.7 MiB    288.9 MiB             file_writer.add_summary(summary)\n    22   3269.7 MiB      0.0 MiB               file_writer.close()\n\n\nFilename: test.py\n\nLine #    Mem usage    Increment   Line Contents\n================================================\n    24     89.6 MiB      0.0 MiB   @profile\n    25                             def main():\n    26   2394.5 MiB   2304.9 MiB       out = [np.random.random((1, 224, 224, 3)) for i in range(2000)]\n    27   2981.4 MiB    586.8 MiB       _write_into_log(out)\n    28    676.7 MiB  -2304.7 MiB       out = None\n    29    676.7 MiB      0.0 MiB       time.sleep(10)\n</code></pre>\n<p>As can be seen above, the additional 586.8 MB occupied after call to the _write_into_log is never cleared.</p>", "body_text": "Issue:\nMemory occupied after call to Filewriter not being freed till python termination. This causes accumulation of data and subsequent filling up of RAM which is freed only when the entire script completes execution and python is terminated.\nEnvironment info\nOperating System: Ubuntu 16.04\nCUDA/cuDNN : Not installed\nLink to the pip package you : https://github.com/tensorflow/tensorflow/releases/tag/v1.0.0\nTensorflow version: 1.0.0\nA small script replicating the issue\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom memory_profiler import profile\nimport time\n\n@profile\ndef _write_into_log(images):\n    path_logdir = os.path.join(\"./MiniExample\")\n    if not os.path.exists(path_logdir):\n        os.makedirs(path_logdir)\n\n    with tf.Graph().as_default() as g:\n        image = tf.placeholder(tf.float32, shape = [None, None, None, 3])\n\n        image_summary = tf.summary.image(name = \"Images\", tensor = image, max_outputs = 2000)\n\n        with tf.Session() as sess:\n            summary = sess.run(image_summary, feed_dict = {image : np.concatenate(images, axis = 0)})\n            file_writer = tf.summary.FileWriter(path_logdir, g)\n            file_writer.add_summary(summary)\n            file_writer.close()\n\n@profile\ndef main():\n    out = [np.random.random((1, 224, 224, 3)) for i in range(2000)]\n    _write_into_log(out)\n    out = None\n    time.sleep(10)\n\nmain()\n\nLogs or other output that would be helpful\nPython memory profiler output\n$ python test.py \nFilename: test.py\n\nLine #    Mem usage    Increment   Line Contents\n================================================\n     7   2394.5 MiB      0.0 MiB   @profile\n     8                             def _write_into_log(images):\n     9   2394.5 MiB      0.0 MiB       path_logdir = os.path.join(\"./MiniExample\")\n    10   2394.5 MiB      0.0 MiB       if not os.path.exists(path_logdir):\n    11                                     os.makedirs(path_logdir)\n    12                             \n    13   2394.6 MiB      0.0 MiB       with tf.Graph().as_default() as g:\n    14   2399.0 MiB      4.4 MiB           image = tf.placeholder(tf.float32, shape = [None, None, None, 3])\n    15                             \n    16   2399.1 MiB      0.1 MiB           image_summary = tf.summary.image(name = \"Images\", tensor = image, max_outputs = 2000)\n    17                             \n    18   2407.9 MiB      8.9 MiB           with tf.Session() as sess:\n    19   2978.8 MiB    570.9 MiB               summary = sess.run(image_summary, feed_dict = {image : np.concatenate(images, axis = 0)})\n    20   2980.8 MiB      2.0 MiB               file_writer = tf.summary.FileWriter(path_logdir, g)\n    21   3269.7 MiB    288.9 MiB             file_writer.add_summary(summary)\n    22   3269.7 MiB      0.0 MiB               file_writer.close()\n\n\nFilename: test.py\n\nLine #    Mem usage    Increment   Line Contents\n================================================\n    24     89.6 MiB      0.0 MiB   @profile\n    25                             def main():\n    26   2394.5 MiB   2304.9 MiB       out = [np.random.random((1, 224, 224, 3)) for i in range(2000)]\n    27   2981.4 MiB    586.8 MiB       _write_into_log(out)\n    28    676.7 MiB  -2304.7 MiB       out = None\n    29    676.7 MiB      0.0 MiB       time.sleep(10)\n\nAs can be seen above, the additional 586.8 MB occupied after call to the _write_into_log is never cleared.", "body": "### Issue:\r\nMemory occupied after call to Filewriter not being freed till python termination. This causes accumulation of data and subsequent filling up of RAM which is freed only when the entire script completes execution and python is terminated.\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\nCUDA/cuDNN : Not installed\r\nLink to the pip package you : https://github.com/tensorflow/tensorflow/releases/tag/v1.0.0\r\nTensorflow version: 1.0.0\r\n\r\n### A small script replicating the issue\r\n\r\n```\r\nimport os\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom memory_profiler import profile\r\nimport time\r\n\r\n@profile\r\ndef _write_into_log(images):\r\n    path_logdir = os.path.join(\"./MiniExample\")\r\n    if not os.path.exists(path_logdir):\r\n        os.makedirs(path_logdir)\r\n\r\n    with tf.Graph().as_default() as g:\r\n        image = tf.placeholder(tf.float32, shape = [None, None, None, 3])\r\n\r\n        image_summary = tf.summary.image(name = \"Images\", tensor = image, max_outputs = 2000)\r\n\r\n        with tf.Session() as sess:\r\n            summary = sess.run(image_summary, feed_dict = {image : np.concatenate(images, axis = 0)})\r\n            file_writer = tf.summary.FileWriter(path_logdir, g)\r\n            file_writer.add_summary(summary)\r\n            file_writer.close()\r\n\r\n@profile\r\ndef main():\r\n    out = [np.random.random((1, 224, 224, 3)) for i in range(2000)]\r\n    _write_into_log(out)\r\n    out = None\r\n    time.sleep(10)\r\n\r\nmain()\r\n```\r\n\r\n### Logs or other output that would be helpful\r\nPython memory profiler output\r\n```\r\n$ python test.py \r\nFilename: test.py\r\n\r\nLine #    Mem usage    Increment   Line Contents\r\n================================================\r\n     7   2394.5 MiB      0.0 MiB   @profile\r\n     8                             def _write_into_log(images):\r\n     9   2394.5 MiB      0.0 MiB       path_logdir = os.path.join(\"./MiniExample\")\r\n    10   2394.5 MiB      0.0 MiB       if not os.path.exists(path_logdir):\r\n    11                                     os.makedirs(path_logdir)\r\n    12                             \r\n    13   2394.6 MiB      0.0 MiB       with tf.Graph().as_default() as g:\r\n    14   2399.0 MiB      4.4 MiB           image = tf.placeholder(tf.float32, shape = [None, None, None, 3])\r\n    15                             \r\n    16   2399.1 MiB      0.1 MiB           image_summary = tf.summary.image(name = \"Images\", tensor = image, max_outputs = 2000)\r\n    17                             \r\n    18   2407.9 MiB      8.9 MiB           with tf.Session() as sess:\r\n    19   2978.8 MiB    570.9 MiB               summary = sess.run(image_summary, feed_dict = {image : np.concatenate(images, axis = 0)})\r\n    20   2980.8 MiB      2.0 MiB               file_writer = tf.summary.FileWriter(path_logdir, g)\r\n    21   3269.7 MiB    288.9 MiB             file_writer.add_summary(summary)\r\n    22   3269.7 MiB      0.0 MiB               file_writer.close()\r\n\r\n\r\nFilename: test.py\r\n\r\nLine #    Mem usage    Increment   Line Contents\r\n================================================\r\n    24     89.6 MiB      0.0 MiB   @profile\r\n    25                             def main():\r\n    26   2394.5 MiB   2304.9 MiB       out = [np.random.random((1, 224, 224, 3)) for i in range(2000)]\r\n    27   2981.4 MiB    586.8 MiB       _write_into_log(out)\r\n    28    676.7 MiB  -2304.7 MiB       out = None\r\n    29    676.7 MiB      0.0 MiB       time.sleep(10)\r\n```\r\nAs can be seen above, the additional 586.8 MB occupied after call to the _write_into_log is never cleared.\r\n"}