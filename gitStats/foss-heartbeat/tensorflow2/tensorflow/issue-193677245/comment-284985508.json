{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/284985508", "html_url": "https://github.com/tensorflow/tensorflow/issues/6111#issuecomment-284985508", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6111", "id": 284985508, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NDk4NTUwOA==", "user": {"login": "egavves", "id": 1257485, "node_id": "MDQ6VXNlcjEyNTc0ODU=", "avatar_url": "https://avatars2.githubusercontent.com/u/1257485?v=4", "gravatar_id": "", "url": "https://api.github.com/users/egavves", "html_url": "https://github.com/egavves", "followers_url": "https://api.github.com/users/egavves/followers", "following_url": "https://api.github.com/users/egavves/following{/other_user}", "gists_url": "https://api.github.com/users/egavves/gists{/gist_id}", "starred_url": "https://api.github.com/users/egavves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/egavves/subscriptions", "organizations_url": "https://api.github.com/users/egavves/orgs", "repos_url": "https://api.github.com/users/egavves/repos", "events_url": "https://api.github.com/users/egavves/events{/privacy}", "received_events_url": "https://api.github.com/users/egavves/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-08T09:02:09Z", "updated_at": "2017-03-08T09:02:09Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I am testing the TF Slim package, fine-tuning the flowers dataset using the instructions in <a href=\"https://github.com/tensorflow/models/tree/master/slim\">https://github.com/tensorflow/models/tree/master/slim</a></p>\n<p>To allow for memory growth, I use the following code:</p>\n<p><code>    session_config.gpu_options.allow_growth = True session_config.gpu_options.allocator_type = 'BFC' session_config.gpu_options.per_process_gpu_memory_fraction = 0.4 # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction) # Run the training: final_loss = slim.learning.train( train_op, logdir=train_dir, init_fn=get_init_fn(), number_of_steps=2000, session_config=session_config)</code></p>\n<p>There are mainly two issues.</p>\n<ol>\n<li>\n<p>As the GPU memory is not big enough, I want to try to allow for GPU growth, so that the process does not crash. The code I am using is the one below, however, it doesn't make any difference at all. Is allow_growth and/or per_process_gpu_memory_fraction really supported for TF slim or not? I suppose this will be anyways an issue, given the original message on the thread. So, I guess all left to ask Is whether there any development on the issue (to begin with, is it really an issue)?</p>\n</li>\n<li>\n<p>Is all the GPU needed for the allocation of the intermediate activation variables? Because the inception model is about 100 Mb, my total GPU memory (after killing also the X server) is 1.8 Gb, so it feels somewhat weird that the model needs in the end 18X more GPU RAM than the inception model size. When using Caffe with Alexnet (~350 Mb), there was no problem at all, no matter the batch size. I guess the way the gradients are computed is by allocating memory like: #MODEL_PARAMETERS x BATCH_SIZE, since for smaller batch sizes the code works. Given that batch gradients are cumultative over the batch samples, isn't this -although arguably faster- somehow redundant (?).</p>\n</li>\n</ol>\n<p>I will try to get the RAM metadata log file, if that is of any help.</p>", "body_text": "Hi,\nI am testing the TF Slim package, fine-tuning the flowers dataset using the instructions in https://github.com/tensorflow/models/tree/master/slim\nTo allow for memory growth, I use the following code:\n    session_config.gpu_options.allow_growth = True session_config.gpu_options.allocator_type = 'BFC' session_config.gpu_options.per_process_gpu_memory_fraction = 0.4 # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction) # Run the training: final_loss = slim.learning.train( train_op, logdir=train_dir, init_fn=get_init_fn(), number_of_steps=2000, session_config=session_config)\nThere are mainly two issues.\n\n\nAs the GPU memory is not big enough, I want to try to allow for GPU growth, so that the process does not crash. The code I am using is the one below, however, it doesn't make any difference at all. Is allow_growth and/or per_process_gpu_memory_fraction really supported for TF slim or not? I suppose this will be anyways an issue, given the original message on the thread. So, I guess all left to ask Is whether there any development on the issue (to begin with, is it really an issue)?\n\n\nIs all the GPU needed for the allocation of the intermediate activation variables? Because the inception model is about 100 Mb, my total GPU memory (after killing also the X server) is 1.8 Gb, so it feels somewhat weird that the model needs in the end 18X more GPU RAM than the inception model size. When using Caffe with Alexnet (~350 Mb), there was no problem at all, no matter the batch size. I guess the way the gradients are computed is by allocating memory like: #MODEL_PARAMETERS x BATCH_SIZE, since for smaller batch sizes the code works. Given that batch gradients are cumultative over the batch samples, isn't this -although arguably faster- somehow redundant (?).\n\n\nI will try to get the RAM metadata log file, if that is of any help.", "body": "Hi,\r\n\r\nI am testing the TF Slim package, fine-tuning the flowers dataset using the instructions in https://github.com/tensorflow/models/tree/master/slim\r\n\r\nTo allow for memory growth, I use the following code:\r\n\r\n`    session_config.gpu_options.allow_growth = True\r\n    session_config.gpu_options.allocator_type = 'BFC'\r\n    session_config.gpu_options.per_process_gpu_memory_fraction = 0.4\r\n    # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\r\n    # Run the training:\r\n    final_loss = slim.learning.train(\r\n        train_op,\r\n        logdir=train_dir,\r\n        init_fn=get_init_fn(),\r\n        number_of_steps=2000,\r\n        session_config=session_config)`\r\n\r\nThere are mainly two issues.\r\n\r\n1. As the GPU memory is not big enough, I want to try to allow for GPU growth, so that the process does not crash. The code I am using is the one below, however, it doesn't make any difference at all. Is allow_growth and/or per_process_gpu_memory_fraction really supported for TF slim or not? I suppose this will be anyways an issue, given the original message on the thread. So, I guess all left to ask Is whether there any development on the issue (to begin with, is it really an issue)?\r\n\r\n2. Is all the GPU needed for the allocation of the intermediate activation variables? Because the inception model is about 100 Mb, my total GPU memory (after killing also the X server) is 1.8 Gb, so it feels somewhat weird that the model needs in the end 18X more GPU RAM than the inception model size. When using Caffe with Alexnet (~350 Mb), there was no problem at all, no matter the batch size. I guess the way the gradients are computed is by allocating memory like: #MODEL_PARAMETERS x BATCH_SIZE, since for smaller batch sizes the code works. Given that batch gradients are cumultative over the batch samples, isn't this -although arguably faster- somehow redundant (?).\r\n\r\nI will try to get the RAM metadata log file, if that is of any help."}