{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17321", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17321/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17321/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17321/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17321", "id": 300994825, "node_id": "MDU6SXNzdWUzMDA5OTQ4MjU=", "number": 17321, "title": "toco convert to lite model incorrectly with slim.batch_norm not follows after conv.", "user": {"login": "apollo-time", "id": 9794932, "node_id": "MDQ6VXNlcjk3OTQ5MzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/9794932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apollo-time", "html_url": "https://github.com/apollo-time", "followers_url": "https://api.github.com/users/apollo-time/followers", "following_url": "https://api.github.com/users/apollo-time/following{/other_user}", "gists_url": "https://api.github.com/users/apollo-time/gists{/gist_id}", "starred_url": "https://api.github.com/users/apollo-time/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apollo-time/subscriptions", "organizations_url": "https://api.github.com/users/apollo-time/orgs", "repos_url": "https://api.github.com/users/apollo-time/repos", "events_url": "https://api.github.com/users/apollo-time/events{/privacy}", "received_events_url": "https://api.github.com/users/apollo-time/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-02-28T11:49:50Z", "updated_at": "2018-08-23T18:18:38Z", "closed_at": "2018-08-23T18:18:38Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution Linux Ubuntu 14.04</strong>:</li>\n<li><strong>TensorFlow installed from binary</strong>:</li>\n<li><strong>TensorFlow version 1.6.rc1</strong>:</li>\n<li><strong>Python version 3.6</strong>:</li>\n<li><strong>Have I written custom code N/A</strong>:</li>\n<li><strong>Bazel version N/A</strong>:</li>\n<li><strong>CUDA/cuDNN version N/A</strong>:</li>\n<li><strong>GPU model and memory N/A</strong>:</li>\n<li><strong>Exact command to reproduce N/A</strong>:</li>\n</ul>\n<p>I create simple model with slim and convert lite model using toco</p>\n<div class=\"highlight highlight-source-python\"><pre>      <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, (<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">120</span>, <span class=\"pl-c1\">120</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>)\n      net <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>\n      net <span class=\"pl-k\">=</span> slim.conv2d(net, <span class=\"pl-c1\">12</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv1<span class=\"pl-pds\">'</span></span>)\n      net <span class=\"pl-k\">=</span> slim.batch_norm(net)\n      net <span class=\"pl-k\">=</span> slim.max_pool2d(net, <span class=\"pl-c1\">3</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>)\n      net <span class=\"pl-k\">=</span> slim.batch_norm(net)\n      <span class=\"pl-c1\">...</span></pre></div>\n<p>The converted lite model from it can't allocate tensor with error<br>\n<code>tensorflow\\contrib\\lite\\kernels\\mul.cc:48 NumDimensions(input1) != NumDimensions(input2) (4 != 1)</code></p>\n<p>but if I insert conv2d layer befor batch_norm, the result is ok.</p>\n<div class=\"highlight highlight-source-python\"><pre>      <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, (<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">120</span>, <span class=\"pl-c1\">120</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>)\n      net <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>\n      net <span class=\"pl-k\">=</span> slim.conv2d(net, <span class=\"pl-c1\">12</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv1<span class=\"pl-pds\">'</span></span>)\n      net <span class=\"pl-k\">=</span> slim.batch_norm(net)\n      net <span class=\"pl-k\">=</span> slim.max_pool2d(net, <span class=\"pl-c1\">3</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>)\n      net <span class=\"pl-k\">=</span> slim.conv2d(net, <span class=\"pl-c1\">12</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv111<span class=\"pl-pds\">'</span></span>)\n      net <span class=\"pl-k\">=</span> slim.batch_norm(net)\n      <span class=\"pl-c1\">...</span></pre></div>\n<p>I had try insert relu and the other layers before batch_norm, but it can't allocate tensor when previous layer is not conv.<br>\nHow can I create batch_norm after any layer?</p>", "body_text": "System information\n\nOS Platform and Distribution Linux Ubuntu 14.04:\nTensorFlow installed from binary:\nTensorFlow version 1.6.rc1:\nPython version 3.6:\nHave I written custom code N/A:\nBazel version N/A:\nCUDA/cuDNN version N/A:\nGPU model and memory N/A:\nExact command to reproduce N/A:\n\nI create simple model with slim and convert lite model using toco\n      input = tf.placeholder(tf.float32, (None, 120, 120, 3), 'input')\n      net = input\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv1')\n      net = slim.batch_norm(net)\n      net = slim.max_pool2d(net, 3, stride=2, padding='SAME')\n      net = slim.batch_norm(net)\n      ...\nThe converted lite model from it can't allocate tensor with error\ntensorflow\\contrib\\lite\\kernels\\mul.cc:48 NumDimensions(input1) != NumDimensions(input2) (4 != 1)\nbut if I insert conv2d layer befor batch_norm, the result is ok.\n      input = tf.placeholder(tf.float32, (None, 120, 120, 3), 'input')\n      net = input\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv1')\n      net = slim.batch_norm(net)\n      net = slim.max_pool2d(net, 3, stride=2, padding='SAME')\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv111')\n      net = slim.batch_norm(net)\n      ...\nI had try insert relu and the other layers before batch_norm, but it can't allocate tensor when previous layer is not conv.\nHow can I create batch_norm after any layer?", "body": "### System information\r\n- **OS Platform and Distribution Linux Ubuntu 14.04**:\r\n- **TensorFlow installed from binary**:\r\n- **TensorFlow version 1.6.rc1**:\r\n- **Python version 3.6**: \r\n- **Have I written custom code N/A**:\r\n- **Bazel version N/A**:\r\n- **CUDA/cuDNN version N/A**:\r\n- **GPU model and memory N/A**:\r\n- **Exact command to reproduce N/A**:\r\n\r\nI create simple model with slim and convert lite model using toco\r\n```python\r\n      input = tf.placeholder(tf.float32, (None, 120, 120, 3), 'input')\r\n      net = input\r\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv1')\r\n      net = slim.batch_norm(net)\r\n      net = slim.max_pool2d(net, 3, stride=2, padding='SAME')\r\n      net = slim.batch_norm(net)\r\n      ...\r\n```\r\nThe converted lite model from it can't allocate tensor with error \r\n`tensorflow\\contrib\\lite\\kernels\\mul.cc:48 NumDimensions(input1) != NumDimensions(input2) (4 != 1)`\r\n\r\nbut if I insert conv2d layer befor batch_norm, the result is ok.\r\n```python\r\n      input = tf.placeholder(tf.float32, (None, 120, 120, 3), 'input')\r\n      net = input\r\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv1')\r\n      net = slim.batch_norm(net)\r\n      net = slim.max_pool2d(net, 3, stride=2, padding='SAME')\r\n      net = slim.conv2d(net, 12, 7, stride=2, scope='conv111')\r\n      net = slim.batch_norm(net)\r\n      ...\r\n```\r\nI had try insert relu and the other layers before batch_norm, but it can't allocate tensor when previous layer is not conv.\r\nHow can I create batch_norm after any layer?\r\n"}