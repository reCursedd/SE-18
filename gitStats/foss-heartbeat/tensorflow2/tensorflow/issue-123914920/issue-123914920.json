{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/621", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/621/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/621/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/621/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/621", "id": 123914920, "node_id": "MDU6SXNzdWUxMjM5MTQ5MjA=", "number": 621, "title": "word2vec_optimized.py fails with large training files", "user": {"login": "daikazoku", "id": 11365004, "node_id": "MDQ6VXNlcjExMzY1MDA0", "avatar_url": "https://avatars2.githubusercontent.com/u/11365004?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daikazoku", "html_url": "https://github.com/daikazoku", "followers_url": "https://api.github.com/users/daikazoku/followers", "following_url": "https://api.github.com/users/daikazoku/following{/other_user}", "gists_url": "https://api.github.com/users/daikazoku/gists{/gist_id}", "starred_url": "https://api.github.com/users/daikazoku/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daikazoku/subscriptions", "organizations_url": "https://api.github.com/users/daikazoku/orgs", "repos_url": "https://api.github.com/users/daikazoku/repos", "events_url": "https://api.github.com/users/daikazoku/events{/privacy}", "received_events_url": "https://api.github.com/users/daikazoku/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-12-26T07:27:16Z", "updated_at": "2015-12-26T20:18:40Z", "closed_at": "2015-12-26T20:10:49Z", "author_association": "NONE", "body_html": "<p>Here is the relevant part of the error for a 2400000000 byte file:</p>\n<pre><code>external/re2/re2/re2.cc:571: RE2: invalid startpos, endpos pair. [startpos: 0, endpos: -1894967296, text size: -1894967296]\nW tensorflow/models/embedding/word2vec_kernels.cc:38] Invalid argument: The text file _train.txt contains too little data: 0 words\nE tensorflow/core/framework/op_segment.cc:52] Create kernel failed: Invalid argument: The text file _train.txt contains too little data: 0 words\nE tensorflow/core/common_runtime/executor.cc:262] Executor failed to create kernel. Invalid argument: The text file _train.txt contains too little data: 0 words\n</code></pre>\n<p>This doesn't happen for a 1000000000 byte file. I suppose there might be an overflow somewhere.</p>\n<p>As an aside, how do I dump the embeddings from the final checkpoint?</p>", "body_text": "Here is the relevant part of the error for a 2400000000 byte file:\nexternal/re2/re2/re2.cc:571: RE2: invalid startpos, endpos pair. [startpos: 0, endpos: -1894967296, text size: -1894967296]\nW tensorflow/models/embedding/word2vec_kernels.cc:38] Invalid argument: The text file _train.txt contains too little data: 0 words\nE tensorflow/core/framework/op_segment.cc:52] Create kernel failed: Invalid argument: The text file _train.txt contains too little data: 0 words\nE tensorflow/core/common_runtime/executor.cc:262] Executor failed to create kernel. Invalid argument: The text file _train.txt contains too little data: 0 words\n\nThis doesn't happen for a 1000000000 byte file. I suppose there might be an overflow somewhere.\nAs an aside, how do I dump the embeddings from the final checkpoint?", "body": "Here is the relevant part of the error for a 2400000000 byte file:\n\n```\nexternal/re2/re2/re2.cc:571: RE2: invalid startpos, endpos pair. [startpos: 0, endpos: -1894967296, text size: -1894967296]\nW tensorflow/models/embedding/word2vec_kernels.cc:38] Invalid argument: The text file _train.txt contains too little data: 0 words\nE tensorflow/core/framework/op_segment.cc:52] Create kernel failed: Invalid argument: The text file _train.txt contains too little data: 0 words\nE tensorflow/core/common_runtime/executor.cc:262] Executor failed to create kernel. Invalid argument: The text file _train.txt contains too little data: 0 words\n```\n\nThis doesn't happen for a 1000000000 byte file. I suppose there might be an overflow somewhere.\n\nAs an aside, how do I dump the embeddings from the final checkpoint?\n"}