{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17771", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17771/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17771/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17771/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17771", "id": 305954758, "node_id": "MDU6SXNzdWUzMDU5NTQ3NTg=", "number": 17771, "title": "TypeError: Expected binary or unicode string, got None.  who can help me,thanks..", "user": {"login": "yanketao", "id": 35378153, "node_id": "MDQ6VXNlcjM1Mzc4MTUz", "avatar_url": "https://avatars2.githubusercontent.com/u/35378153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yanketao", "html_url": "https://github.com/yanketao", "followers_url": "https://api.github.com/users/yanketao/followers", "following_url": "https://api.github.com/users/yanketao/following{/other_user}", "gists_url": "https://api.github.com/users/yanketao/gists{/gist_id}", "starred_url": "https://api.github.com/users/yanketao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yanketao/subscriptions", "organizations_url": "https://api.github.com/users/yanketao/orgs", "repos_url": "https://api.github.com/users/yanketao/repos", "events_url": "https://api.github.com/users/yanketao/events{/privacy}", "received_events_url": "https://api.github.com/users/yanketao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-03-16T14:43:54Z", "updated_at": "2018-04-03T00:19:20Z", "closed_at": "2018-04-03T00:19:20Z", "author_association": "NONE", "body_html": "<p>this is code:</p>\n<h1>coding=utf-8</h1>\n<p>import tensorflow as tf<br>\nfrom PIL import Image<br>\nimport matplotlib.pyplot as plt<br>\nimport input_data<br>\nimport numpy as np<br>\nimport model<br>\nimport os<br>\nfrom skimage import io</p>\n<p>def get_one_image(train):<br>\nfiles = os.listdir (train)<br>\nn = len (files)<br>\nind = np.random.randint (0, n)<br>\nimg_dir = os.path.join (train, files[ind])<br>\nimage = io.imread (img_dir,as_grey=True)<br>\nplt.imshow (image,cmap ='gray')<br>\nplt.show ()<br>\nimage = image.resize ([50, 50,1])<br>\nimage = np.asarray (image)<br>\nreturn image</p>\n<p>def evaluate_one_image():<br>\ntrain = './tst/'</p>\n<pre><code>image_array = get_one_image (train)\n\nwith tf.Graph ().as_default ():\n    BATCH_SIZE = 1  \n    N_CLASSES = 2  \n\n    image = tf.cast (image_array, tf.float32)\n\n    image = tf.image.per_image_standardization (image)\n\n    image = tf.reshape (image, [1,50, 50,1])\n    logit = model.inference (image, BATCH_SIZE, N_CLASSES)\n\n    logit = tf.nn.softmax (logit)\n\n    x = tf.placeholder (tf.float32, shape=[50, 50,1])\n\n\n    logs_train_dir = './save/'\n\n    saver = tf.train.Saver ()\n\n    with tf.Session () as sess:\n\n        print (\"\u4ece\u6307\u5b9a\u7684\u8def\u5f84\u4e2d\u52a0\u8f7d\u6a21\u578b\u3002\u3002\u3002\u3002\")\n\n        ckpt = tf.train.get_checkpoint_state (logs_train_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            global_step = ckpt.model_checkpoint_path.split ('/')[-1].split ('-')[-1]\n            saver.restore (sess, ckpt.model_checkpoint_path)\n            print ('\u6a21\u578b\u52a0\u8f7d\u6210\u529f, \u8bad\u7ec3\u7684\u6b65\u6570\u4e3a %s' % global_step)\n        else:\n            print ('\u6a21\u578b\u52a0\u8f7d\u5931\u8d25\uff0c\uff0c\uff0c\u6587\u4ef6\u6ca1\u6709\u627e\u5230')\n            # \u5c06\u56fe\u7247\u8f93\u5165\u5230\u6a21\u578b\u8ba1\u7b97\n        prediction = sess.run (logit, feed_dict={x: image_array})\n        # \u83b7\u53d6\u8f93\u51fa\u7ed3\u679c\u4e2d\u6700\u5927\u6982\u7387\u7684\u7d22\u5f15\n        max_index = np.argmax (prediction)\n        if max_index == 0:\n            print ('\u732b\u7684\u6982\u7387 %.6f' % prediction[:, 0])\n        else:\n            print ('\u72d7\u7684\u6982\u7387 %.6f' % prediction[:, 1])\n</code></pre>\n<p>evaluate_one_image ()</p>", "body_text": "this is code:\ncoding=utf-8\nimport tensorflow as tf\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport input_data\nimport numpy as np\nimport model\nimport os\nfrom skimage import io\ndef get_one_image(train):\nfiles = os.listdir (train)\nn = len (files)\nind = np.random.randint (0, n)\nimg_dir = os.path.join (train, files[ind])\nimage = io.imread (img_dir,as_grey=True)\nplt.imshow (image,cmap ='gray')\nplt.show ()\nimage = image.resize ([50, 50,1])\nimage = np.asarray (image)\nreturn image\ndef evaluate_one_image():\ntrain = './tst/'\nimage_array = get_one_image (train)\n\nwith tf.Graph ().as_default ():\n    BATCH_SIZE = 1  \n    N_CLASSES = 2  \n\n    image = tf.cast (image_array, tf.float32)\n\n    image = tf.image.per_image_standardization (image)\n\n    image = tf.reshape (image, [1,50, 50,1])\n    logit = model.inference (image, BATCH_SIZE, N_CLASSES)\n\n    logit = tf.nn.softmax (logit)\n\n    x = tf.placeholder (tf.float32, shape=[50, 50,1])\n\n\n    logs_train_dir = './save/'\n\n    saver = tf.train.Saver ()\n\n    with tf.Session () as sess:\n\n        print (\"\u4ece\u6307\u5b9a\u7684\u8def\u5f84\u4e2d\u52a0\u8f7d\u6a21\u578b\u3002\u3002\u3002\u3002\")\n\n        ckpt = tf.train.get_checkpoint_state (logs_train_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            global_step = ckpt.model_checkpoint_path.split ('/')[-1].split ('-')[-1]\n            saver.restore (sess, ckpt.model_checkpoint_path)\n            print ('\u6a21\u578b\u52a0\u8f7d\u6210\u529f, \u8bad\u7ec3\u7684\u6b65\u6570\u4e3a %s' % global_step)\n        else:\n            print ('\u6a21\u578b\u52a0\u8f7d\u5931\u8d25\uff0c\uff0c\uff0c\u6587\u4ef6\u6ca1\u6709\u627e\u5230')\n            # \u5c06\u56fe\u7247\u8f93\u5165\u5230\u6a21\u578b\u8ba1\u7b97\n        prediction = sess.run (logit, feed_dict={x: image_array})\n        # \u83b7\u53d6\u8f93\u51fa\u7ed3\u679c\u4e2d\u6700\u5927\u6982\u7387\u7684\u7d22\u5f15\n        max_index = np.argmax (prediction)\n        if max_index == 0:\n            print ('\u732b\u7684\u6982\u7387 %.6f' % prediction[:, 0])\n        else:\n            print ('\u72d7\u7684\u6982\u7387 %.6f' % prediction[:, 1])\n\nevaluate_one_image ()", "body": "this is code:\r\n# coding=utf-8\r\nimport tensorflow as tf\r\nfrom PIL import Image\r\nimport matplotlib.pyplot as plt\r\nimport input_data\r\nimport numpy as np\r\nimport model\r\nimport os\r\nfrom skimage import io\r\n\r\n\r\ndef get_one_image(train):\r\n    files = os.listdir (train)\r\n    n = len (files)\r\n    ind = np.random.randint (0, n)\r\n    img_dir = os.path.join (train, files[ind])\r\n    image = io.imread (img_dir,as_grey=True)\r\n    plt.imshow (image,cmap ='gray')\r\n    plt.show ()\r\n    image = image.resize ([50, 50,1])\r\n    image = np.asarray (image)\r\n    return image\r\n\r\n\r\ndef evaluate_one_image():\r\n    train = './tst/'\r\n\r\n    image_array = get_one_image (train)\r\n\r\n    with tf.Graph ().as_default ():\r\n        BATCH_SIZE = 1  \r\n        N_CLASSES = 2  \r\n\r\n        image = tf.cast (image_array, tf.float32)\r\n\r\n        image = tf.image.per_image_standardization (image)\r\n\r\n        image = tf.reshape (image, [1,50, 50,1])\r\n        logit = model.inference (image, BATCH_SIZE, N_CLASSES)\r\n\r\n        logit = tf.nn.softmax (logit)\r\n\r\n        x = tf.placeholder (tf.float32, shape=[50, 50,1])\r\n\r\n\r\n        logs_train_dir = './save/'\r\n\r\n        saver = tf.train.Saver ()\r\n\r\n        with tf.Session () as sess:\r\n\r\n            print (\"\u4ece\u6307\u5b9a\u7684\u8def\u5f84\u4e2d\u52a0\u8f7d\u6a21\u578b\u3002\u3002\u3002\u3002\")\r\n\r\n            ckpt = tf.train.get_checkpoint_state (logs_train_dir)\r\n            if ckpt and ckpt.model_checkpoint_path:\r\n                global_step = ckpt.model_checkpoint_path.split ('/')[-1].split ('-')[-1]\r\n                saver.restore (sess, ckpt.model_checkpoint_path)\r\n                print ('\u6a21\u578b\u52a0\u8f7d\u6210\u529f, \u8bad\u7ec3\u7684\u6b65\u6570\u4e3a %s' % global_step)\r\n            else:\r\n                print ('\u6a21\u578b\u52a0\u8f7d\u5931\u8d25\uff0c\uff0c\uff0c\u6587\u4ef6\u6ca1\u6709\u627e\u5230')\r\n                # \u5c06\u56fe\u7247\u8f93\u5165\u5230\u6a21\u578b\u8ba1\u7b97\r\n            prediction = sess.run (logit, feed_dict={x: image_array})\r\n            # \u83b7\u53d6\u8f93\u51fa\u7ed3\u679c\u4e2d\u6700\u5927\u6982\u7387\u7684\u7d22\u5f15\r\n            max_index = np.argmax (prediction)\r\n            if max_index == 0:\r\n                print ('\u732b\u7684\u6982\u7387 %.6f' % prediction[:, 0])\r\n            else:\r\n                print ('\u72d7\u7684\u6982\u7387 %.6f' % prediction[:, 1])\r\n\r\nevaluate_one_image ()\r\n"}