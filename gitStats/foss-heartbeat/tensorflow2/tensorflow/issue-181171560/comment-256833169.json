{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256833169", "html_url": "https://github.com/tensorflow/tensorflow/issues/4781#issuecomment-256833169", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4781", "id": 256833169, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NjgzMzE2OQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-28T04:23:01Z", "updated_at": "2016-10-28T04:23:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>There are two problems:</p>\n<ol>\n<li>always create all your nodes before passing them to session.run.  even if it's a new local session.  strange things can happen if you don't.  this is because when you call session.run, it serializes your graph; and if you add new nodes after this, it'll serialize more of the graph and upload that.  but sometimes it'll still use some cached nodes.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2342391\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yuanbyu\">@yuanbyu</a> this may be a bug here.</li>\n<li>this code:</li>\n</ol>\n<pre><code>tf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n</code></pre>\n<p>is incorrect: replace the body with <code>[tf.to_int64(1), tf.to_int64(0)]</code> and it'll work.</p>\n<p>to summarize:</p>\n<pre><code>tf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n...\nInvalidArgumentError: Input 1 of node scan/while/Merge_1 was passed int32 from scan/while/NextIteration_1:0 incompatible with expected int64.\n\n\ntf.reset_default_graph()\n\ntf.Session().run(tf.scan(lambda a, x: [tf.to_int64(1), tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n\n[array([1, 1, 1, 1, 1]), array([0, 0, 0, 0, 0])]\n</code></pre>\n<p>but really, it's not idiomatic to create new sessions and immediately add new nodes to them and execute at the same time.  create your nodes first, and when you're done execute all your session.run calls.</p>", "body_text": "There are two problems:\n\nalways create all your nodes before passing them to session.run.  even if it's a new local session.  strange things can happen if you don't.  this is because when you call session.run, it serializes your graph; and if you add new nodes after this, it'll serialize more of the graph and upload that.  but sometimes it'll still use some cached nodes.  @yuanbyu this may be a bug here.\nthis code:\n\ntf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n\nis incorrect: replace the body with [tf.to_int64(1), tf.to_int64(0)] and it'll work.\nto summarize:\ntf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n...\nInvalidArgumentError: Input 1 of node scan/while/Merge_1 was passed int32 from scan/while/NextIteration_1:0 incompatible with expected int64.\n\n\ntf.reset_default_graph()\n\ntf.Session().run(tf.scan(lambda a, x: [tf.to_int64(1), tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n\n[array([1, 1, 1, 1, 1]), array([0, 0, 0, 0, 0])]\n\nbut really, it's not idiomatic to create new sessions and immediately add new nodes to them and execute at the same time.  create your nodes first, and when you're done execute all your session.run calls.", "body": "There are two problems:\n1. always create all your nodes before passing them to session.run.  even if it's a new local session.  strange things can happen if you don't.  this is because when you call session.run, it serializes your graph; and if you add new nodes after this, it'll serialize more of the graph and upload that.  but sometimes it'll still use some cached nodes.  @yuanbyu this may be a bug here.\n2. this code:\n\n```\ntf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n```\n\nis incorrect: replace the body with `[tf.to_int64(1), tf.to_int64(0)]` and it'll work.\n\nto summarize:\n\n```\ntf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n...\nInvalidArgumentError: Input 1 of node scan/while/Merge_1 was passed int32 from scan/while/NextIteration_1:0 incompatible with expected int64.\n\n\ntf.reset_default_graph()\n\ntf.Session().run(tf.scan(lambda a, x: [tf.to_int64(1), tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n\n[array([1, 1, 1, 1, 1]), array([0, 0, 0, 0, 0])]\n```\n\nbut really, it's not idiomatic to create new sessions and immediately add new nodes to them and execute at the same time.  create your nodes first, and when you're done execute all your session.run calls.\n"}