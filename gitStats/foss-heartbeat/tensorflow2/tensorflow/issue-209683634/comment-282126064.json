{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/282126064", "html_url": "https://github.com/tensorflow/tensorflow/issues/7810#issuecomment-282126064", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7810", "id": 282126064, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MjEyNjA2NA==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-23T21:25:32Z", "updated_at": "2017-02-23T21:25:32Z", "author_association": "MEMBER", "body_html": "<p>Do you want to disable all direct memory transfers between the two GPUs, or just make it so that only one GPU is visible to TF?  The second can be done with the CUDA_VISIBLE_DEVICES env variable.</p>\n<p>I believe that TF should never dereference a foreign GPU pointer and thus trigger automatic DMA.  If you're using 2 GPUs they should appear as separate devices and all memory transfers will be done via DeviceToDeviceCopy which ultimately turns into a cudaMemcpy call which uses DMA to do a transfer over the PCI bus.   If TF can only see and use one GPU, you'll never trigger a DMA operation involving the other GPU.  If you want to use both GPUs, but stage all transfers via CPU RAM and never direct DMA between the GPUs, that's harder: I don't think there's a setting to accomplish that.  One technique might be always to explicitly copy to a CPU resident tensor before forwarding a value to the other GPU.</p>", "body_text": "Do you want to disable all direct memory transfers between the two GPUs, or just make it so that only one GPU is visible to TF?  The second can be done with the CUDA_VISIBLE_DEVICES env variable.\nI believe that TF should never dereference a foreign GPU pointer and thus trigger automatic DMA.  If you're using 2 GPUs they should appear as separate devices and all memory transfers will be done via DeviceToDeviceCopy which ultimately turns into a cudaMemcpy call which uses DMA to do a transfer over the PCI bus.   If TF can only see and use one GPU, you'll never trigger a DMA operation involving the other GPU.  If you want to use both GPUs, but stage all transfers via CPU RAM and never direct DMA between the GPUs, that's harder: I don't think there's a setting to accomplish that.  One technique might be always to explicitly copy to a CPU resident tensor before forwarding a value to the other GPU.", "body": "Do you want to disable all direct memory transfers between the two GPUs, or just make it so that only one GPU is visible to TF?  The second can be done with the CUDA_VISIBLE_DEVICES env variable.\r\n\r\nI believe that TF should never dereference a foreign GPU pointer and thus trigger automatic DMA.  If you're using 2 GPUs they should appear as separate devices and all memory transfers will be done via DeviceToDeviceCopy which ultimately turns into a cudaMemcpy call which uses DMA to do a transfer over the PCI bus.   If TF can only see and use one GPU, you'll never trigger a DMA operation involving the other GPU.  If you want to use both GPUs, but stage all transfers via CPU RAM and never direct DMA between the GPUs, that's harder: I don't think there's a setting to accomplish that.  One technique might be always to explicitly copy to a CPU resident tensor before forwarding a value to the other GPU."}