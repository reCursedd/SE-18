{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8670", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8670/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8670/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8670/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8670", "id": 216527387, "node_id": "MDU6SXNzdWUyMTY1MjczODc=", "number": 8670, "title": "Outputs of a model are different depending on the batch size (tested for inception models)", "user": {"login": "jorgemf", "id": 1029554, "node_id": "MDQ6VXNlcjEwMjk1NTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/1029554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorgemf", "html_url": "https://github.com/jorgemf", "followers_url": "https://api.github.com/users/jorgemf/followers", "following_url": "https://api.github.com/users/jorgemf/following{/other_user}", "gists_url": "https://api.github.com/users/jorgemf/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorgemf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorgemf/subscriptions", "organizations_url": "https://api.github.com/users/jorgemf/orgs", "repos_url": "https://api.github.com/users/jorgemf/repos", "events_url": "https://api.github.com/users/jorgemf/events{/privacy}", "received_events_url": "https://api.github.com/users/jorgemf/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-03-23T18:24:09Z", "updated_at": "2017-07-05T13:12:39Z", "closed_at": "2017-04-12T12:38:35Z", "author_association": "NONE", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"136700507\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1299\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1299/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1299\">#1299</a></p>\n<h3>Environment info</h3>\n<p>Operating System: ArchLinux<br>\nCUDA: 8.0.61<br>\ncuDNN: 5.1.10<br>\nTensorFlow: 1.0.1 (both with and without GPU support for python 2.7)</p>\n<p>I  have also tested it with the latest nightly build:<br>\n<a href=\"http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-1.0.1-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-1.0.1-cp27-none-linux_x86_64.whl</a></p>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Minimun script for testing: <a href=\"https://gist.github.com/jorgemf/e1f1a97ad39c02ace3576d1248327d2a\">https://gist.github.com/jorgemf/e1f1a97ad39c02ace3576d1248327d2a</a></p>\n<p>I have tested it with the inception_v1 and inception_v4 models (commented in the code)</p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>None</p>\n<h3>Logs or other output that would be helpful.</h3>\n<p>Logs for inception_v1 for the GPU and CPU based on my previous script.  You should expect the same output regardless of the batch size. Output must be the same for all the items of the batch as the input is the same image (which doesn't happen for one of the cases of this logs, I can upload the image and the checkpoint to reproduce that exactly case if required)</p>\n<p>Please note that in this examples the errors in the output or the values of the layers are really small. You could think it is due to any weird conversion python does, but I have trained models based on inception_v1 where the outputs varies from 0.4 to 1.04.</p>\n<p>The logs shows the output of the model (num_classes=1) and whether the layers outputs are exactly the same as with previous batch sizes or are different. Note that for some layers the outputs are the same regardless of the batch size, you start seeing errors with deeper layers. I only show few layers as example.</p>\n<p>GPU</p>\n<pre><code>batch size: 1\n        outputs: [  5.03433178e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        OK Mixed_5c\nbatch size: 2\n        outputs: [  5.03433233e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        ERROR Mixed_4f  Different values than batch_sizes 1.\n        ERROR Mixed_5c  Different values than batch_sizes 1.\nbatch size: 10\n        outputs: [  5.03433233e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        ERROR Mixed_4f  Different values than batch_sizes 1. Same values as batch_sizes 2.\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2.\nbatch size: 16\n        outputs: [  5.03433233e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        ERROR Mixed_4f  Different values than batch_sizes 1, 2, 10.\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2, 10.\nbatch size: 20\n        outputs: [  5.03433287e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        ERROR Mixed_4f  Different values than batch_sizes 1, 16. Same values as batch_sizes 2, 10.\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2, 16. Same values as batch_sizes 10.\n</code></pre>\n<p>CPU</p>\n<pre><code>batch size: 1\n        outputs: [  5.03432962e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        OK Mixed_5c\nbatch size: 2\n        outputs: [  5.03433016e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        ERROR Mixed_5c  Different values than batch_sizes 1.\nbatch size: 10\n        outputs (ERROR: outputs must have the same value): [  5.03433178e-13   5.03433178e-13   5.03433178e-13   5.03433178e-13\n   5.03433178e-13   5.03433178e-13   5.03433178e-13   5.03433178e-13\n   5.03433016e-13   5.03433016e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2.\nbatch size: 16\n        outputs: [  5.03433178e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2, 10.\nbatch size: 20\n        outputs: [  5.03433178e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2, 10, 16.\n</code></pre>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n#1299\nEnvironment info\nOperating System: ArchLinux\nCUDA: 8.0.61\ncuDNN: 5.1.10\nTensorFlow: 1.0.1 (both with and without GPU support for python 2.7)\nI  have also tested it with the latest nightly build:\nhttp://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-1.0.1-cp27-none-linux_x86_64.whl\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nMinimun script for testing: https://gist.github.com/jorgemf/e1f1a97ad39c02ace3576d1248327d2a\nI have tested it with the inception_v1 and inception_v4 models (commented in the code)\nWhat other attempted solutions have you tried?\nNone\nLogs or other output that would be helpful.\nLogs for inception_v1 for the GPU and CPU based on my previous script.  You should expect the same output regardless of the batch size. Output must be the same for all the items of the batch as the input is the same image (which doesn't happen for one of the cases of this logs, I can upload the image and the checkpoint to reproduce that exactly case if required)\nPlease note that in this examples the errors in the output or the values of the layers are really small. You could think it is due to any weird conversion python does, but I have trained models based on inception_v1 where the outputs varies from 0.4 to 1.04.\nThe logs shows the output of the model (num_classes=1) and whether the layers outputs are exactly the same as with previous batch sizes or are different. Note that for some layers the outputs are the same regardless of the batch size, you start seeing errors with deeper layers. I only show few layers as example.\nGPU\nbatch size: 1\n        outputs: [  5.03433178e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        OK Mixed_5c\nbatch size: 2\n        outputs: [  5.03433233e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        ERROR Mixed_4f  Different values than batch_sizes 1.\n        ERROR Mixed_5c  Different values than batch_sizes 1.\nbatch size: 10\n        outputs: [  5.03433233e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        ERROR Mixed_4f  Different values than batch_sizes 1. Same values as batch_sizes 2.\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2.\nbatch size: 16\n        outputs: [  5.03433233e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        ERROR Mixed_4f  Different values than batch_sizes 1, 2, 10.\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2, 10.\nbatch size: 20\n        outputs: [  5.03433287e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        ERROR Mixed_4f  Different values than batch_sizes 1, 16. Same values as batch_sizes 2, 10.\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2, 16. Same values as batch_sizes 10.\n\nCPU\nbatch size: 1\n        outputs: [  5.03432962e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        OK Mixed_5c\nbatch size: 2\n        outputs: [  5.03433016e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        ERROR Mixed_5c  Different values than batch_sizes 1.\nbatch size: 10\n        outputs (ERROR: outputs must have the same value): [  5.03433178e-13   5.03433178e-13   5.03433178e-13   5.03433178e-13\n   5.03433178e-13   5.03433178e-13   5.03433178e-13   5.03433178e-13\n   5.03433016e-13   5.03433016e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2.\nbatch size: 16\n        outputs: [  5.03433178e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2, 10.\nbatch size: 20\n        outputs: [  5.03433178e-13]\n        OK inputs\n        OK Conv2d_1a_7x7\n        OK MaxPool_3a_3x3\n        OK Mixed_3b\n        OK Mixed_4b\n        OK Mixed_4f\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2, 10, 16.", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/1299\r\n\r\n### Environment info\r\nOperating System: ArchLinux\r\nCUDA: 8.0.61\r\ncuDNN: 5.1.10\r\nTensorFlow: 1.0.1 (both with and without GPU support for python 2.7)\r\n\r\nI  have also tested it with the latest nightly build:\r\nhttp://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-1.0.1-cp27-none-linux_x86_64.whl\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nMinimun script for testing: https://gist.github.com/jorgemf/e1f1a97ad39c02ace3576d1248327d2a\r\n\r\nI have tested it with the inception_v1 and inception_v4 models (commented in the code)\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nNone\r\n\r\n### Logs or other output that would be helpful.\r\n\r\nLogs for inception_v1 for the GPU and CPU based on my previous script.  You should expect the same output regardless of the batch size. Output must be the same for all the items of the batch as the input is the same image (which doesn't happen for one of the cases of this logs, I can upload the image and the checkpoint to reproduce that exactly case if required)\r\n\r\nPlease note that in this examples the errors in the output or the values of the layers are really small. You could think it is due to any weird conversion python does, but I have trained models based on inception_v1 where the outputs varies from 0.4 to 1.04.\r\n\r\nThe logs shows the output of the model (num_classes=1) and whether the layers outputs are exactly the same as with previous batch sizes or are different. Note that for some layers the outputs are the same regardless of the batch size, you start seeing errors with deeper layers. I only show few layers as example.\r\n\r\nGPU\r\n```\r\nbatch size: 1\r\n        outputs: [  5.03433178e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        OK Mixed_4f\r\n        OK Mixed_5c\r\nbatch size: 2\r\n        outputs: [  5.03433233e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        ERROR Mixed_4f  Different values than batch_sizes 1.\r\n        ERROR Mixed_5c  Different values than batch_sizes 1.\r\nbatch size: 10\r\n        outputs: [  5.03433233e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        ERROR Mixed_4f  Different values than batch_sizes 1. Same values as batch_sizes 2.\r\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2.\r\nbatch size: 16\r\n        outputs: [  5.03433233e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        ERROR Mixed_4f  Different values than batch_sizes 1, 2, 10.\r\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2, 10.\r\nbatch size: 20\r\n        outputs: [  5.03433287e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        ERROR Mixed_4f  Different values than batch_sizes 1, 16. Same values as batch_sizes 2, 10.\r\n        ERROR Mixed_5c  Different values than batch_sizes 1, 2, 16. Same values as batch_sizes 10.\r\n```\r\n\r\nCPU\r\n```\r\nbatch size: 1\r\n        outputs: [  5.03432962e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        OK Mixed_4f\r\n        OK Mixed_5c\r\nbatch size: 2\r\n        outputs: [  5.03433016e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        OK Mixed_4f\r\n        ERROR Mixed_5c  Different values than batch_sizes 1.\r\nbatch size: 10\r\n        outputs (ERROR: outputs must have the same value): [  5.03433178e-13   5.03433178e-13   5.03433178e-13   5.03433178e-13\r\n   5.03433178e-13   5.03433178e-13   5.03433178e-13   5.03433178e-13\r\n   5.03433016e-13   5.03433016e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        OK Mixed_4f\r\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2.\r\nbatch size: 16\r\n        outputs: [  5.03433178e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        OK Mixed_4f\r\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2, 10.\r\nbatch size: 20\r\n        outputs: [  5.03433178e-13]\r\n        OK inputs\r\n        OK Conv2d_1a_7x7\r\n        OK MaxPool_3a_3x3\r\n        OK Mixed_3b\r\n        OK Mixed_4b\r\n        OK Mixed_4f\r\n        ERROR Mixed_5c  Different values than batch_sizes 1. Same values as batch_sizes 2, 10, 16.\r\n```\r\n"}