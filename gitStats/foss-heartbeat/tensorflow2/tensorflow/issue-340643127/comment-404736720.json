{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/404736720", "html_url": "https://github.com/tensorflow/tensorflow/issues/20739#issuecomment-404736720", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20739", "id": 404736720, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDczNjcyMA==", "user": {"login": "Canxes", "id": 18511496, "node_id": "MDQ6VXNlcjE4NTExNDk2", "avatar_url": "https://avatars0.githubusercontent.com/u/18511496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Canxes", "html_url": "https://github.com/Canxes", "followers_url": "https://api.github.com/users/Canxes/followers", "following_url": "https://api.github.com/users/Canxes/following{/other_user}", "gists_url": "https://api.github.com/users/Canxes/gists{/gist_id}", "starred_url": "https://api.github.com/users/Canxes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Canxes/subscriptions", "organizations_url": "https://api.github.com/users/Canxes/orgs", "repos_url": "https://api.github.com/users/Canxes/repos", "events_url": "https://api.github.com/users/Canxes/events{/privacy}", "received_events_url": "https://api.github.com/users/Canxes/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-13T06:14:10Z", "updated_at": "2018-07-13T06:18:09Z", "author_association": "NONE", "body_html": "<p>By the way, I wonder, why <code>create_eval_graph</code> uses fixed fake quantization([-6.0, 6.0] -&gt; uint8)?</p>\n<p>According to the original <a href=\"https://arxiv.org/pdf/1712.05877.pdf\" rel=\"nofollow\">paper</a> the idea is to use min-max weights values and EMA during training. In my opinion it is expectable to do the same for the eval_graph. I mean, run <code>create_eval_graph</code>, evaluate network on the dataset to get the min-max values and then save -&gt; transform to tflite. In comparison to the fixed ranges it would be more similar to the actual training procedure.</p>\n<p>Also, I think it's questionable to avoid bias quantization during training and quantize activations instead. Yes, toco quantizes biases  as int32, but it's not the same as it was during training. I mean, during training <code>act_quant</code> performs <strong>8 bit</strong> quantization of the conv result + float biases.  And during inference we start to treat bias as 32 bit value, what results in the slightly different inference values. But this shift results in the overall network bias and, in my case, the <code>tflite</code> model result is significantly different from the <code>create_eval_graph</code> one.</p>\n<p>It would be great to find out the ideas behind this approach. On the first look it is a bit counterintuitive.</p>", "body_text": "By the way, I wonder, why create_eval_graph uses fixed fake quantization([-6.0, 6.0] -> uint8)?\nAccording to the original paper the idea is to use min-max weights values and EMA during training. In my opinion it is expectable to do the same for the eval_graph. I mean, run create_eval_graph, evaluate network on the dataset to get the min-max values and then save -> transform to tflite. In comparison to the fixed ranges it would be more similar to the actual training procedure.\nAlso, I think it's questionable to avoid bias quantization during training and quantize activations instead. Yes, toco quantizes biases  as int32, but it's not the same as it was during training. I mean, during training act_quant performs 8 bit quantization of the conv result + float biases.  And during inference we start to treat bias as 32 bit value, what results in the slightly different inference values. But this shift results in the overall network bias and, in my case, the tflite model result is significantly different from the create_eval_graph one.\nIt would be great to find out the ideas behind this approach. On the first look it is a bit counterintuitive.", "body": "By the way, I wonder, why `create_eval_graph` uses fixed fake quantization([-6.0, 6.0] -> uint8)?  \r\n\r\nAccording to the original [paper](https://arxiv.org/pdf/1712.05877.pdf) the idea is to use min-max weights values and EMA during training. In my opinion it is expectable to do the same for the eval_graph. I mean, run `create_eval_graph`, evaluate network on the dataset to get the min-max values and then save -> transform to tflite. In comparison to the fixed ranges it would be more similar to the actual training procedure.  \r\n\r\nAlso, I think it's questionable to avoid bias quantization during training and quantize activations instead. Yes, toco quantizes biases  as int32, but it's not the same as it was during training. I mean, during training `act_quant` performs **8 bit** quantization of the conv result + float biases.  And during inference we start to treat bias as 32 bit value, what results in the slightly different inference values. But this shift results in the overall network bias and, in my case, the `tflite` model result is significantly different from the `create_eval_graph` one.  \r\n\r\nIt would be great to find out the ideas behind this approach. On the first look it is a bit counterintuitive."}