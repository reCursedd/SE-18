{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/410770701", "html_url": "https://github.com/tensorflow/tensorflow/issues/20739#issuecomment-410770701", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20739", "id": 410770701, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDc3MDcwMQ==", "user": {"login": "Canxes", "id": 18511496, "node_id": "MDQ6VXNlcjE4NTExNDk2", "avatar_url": "https://avatars0.githubusercontent.com/u/18511496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Canxes", "html_url": "https://github.com/Canxes", "followers_url": "https://api.github.com/users/Canxes/followers", "following_url": "https://api.github.com/users/Canxes/following{/other_user}", "gists_url": "https://api.github.com/users/Canxes/gists{/gist_id}", "starred_url": "https://api.github.com/users/Canxes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Canxes/subscriptions", "organizations_url": "https://api.github.com/users/Canxes/orgs", "repos_url": "https://api.github.com/users/Canxes/repos", "events_url": "https://api.github.com/users/Canxes/events{/privacy}", "received_events_url": "https://api.github.com/users/Canxes/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-06T16:38:09Z", "updated_at": "2018-08-06T16:39:56Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=34699873\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/raghuraman-k\">@raghuraman-k</a> Thanks for answer.</p>\n<p>Unfortunately, I can't provide small and exhaustive source code example, because in my case drop in accuracy can be observed in complicated detection network, MaskRCNN. To be precise, ROIAlign seems to be rather sensitive to the input distribution changes. (Yes, ROIAlign and other related operations are not supported, however, I manually implemented them in C++ as separate functions. Also inserted additional fake quantization nodes for them).</p>\n<p>Back to the weights quantization. Yes, you are right, quantization procedure is not like I thought before, however it has some drawbacks.</p>\n<p>I was digging into the TOCO sources for a while and found out that weights are quantized 2 times, at least for the <code>quantize_weights=True</code> option. First, quantization parameters are applied <a href=\"https://github.com/tensorflow/tensorflow/blob/9ba6943a1dbbc415b72835517ad58808ca6a6a3d/tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fake_quant.cc\">here</a> and then arrays are requantized <a href=\"https://github.com/tensorflow/tensorflow/blob/9ba6943a1dbbc415b72835517ad58808ca6a6a3d/tensorflow/contrib/lite/toco/graph_transformations/quantize_weights.cc\">here</a>. Not sure about quantized inference, probably the same.</p>\n<p>Also there is a difference in the TOCO quantization procedure and tensorflow FakeQuantize operation. For instance, the second is less precise than first(clipping in floats instead integers, or something of the kind).</p>\n<p>Both described facts introduce small delta between fake quantized weights during training and tensorflow lite quantized weights. As I sad before in some cases this bias leads to significant accuracy drop.</p>\n<p>If you are interesting, I fixed described above and recieved machine eps between tensorflow lite weights after dequantization and FakeQuantize node results. However, I have implementation only for the weights quantization case.</p>", "body_text": "@raghuraman-k Thanks for answer.\nUnfortunately, I can't provide small and exhaustive source code example, because in my case drop in accuracy can be observed in complicated detection network, MaskRCNN. To be precise, ROIAlign seems to be rather sensitive to the input distribution changes. (Yes, ROIAlign and other related operations are not supported, however, I manually implemented them in C++ as separate functions. Also inserted additional fake quantization nodes for them).\nBack to the weights quantization. Yes, you are right, quantization procedure is not like I thought before, however it has some drawbacks.\nI was digging into the TOCO sources for a while and found out that weights are quantized 2 times, at least for the quantize_weights=True option. First, quantization parameters are applied here and then arrays are requantized here. Not sure about quantized inference, probably the same.\nAlso there is a difference in the TOCO quantization procedure and tensorflow FakeQuantize operation. For instance, the second is less precise than first(clipping in floats instead integers, or something of the kind).\nBoth described facts introduce small delta between fake quantized weights during training and tensorflow lite quantized weights. As I sad before in some cases this bias leads to significant accuracy drop.\nIf you are interesting, I fixed described above and recieved machine eps between tensorflow lite weights after dequantization and FakeQuantize node results. However, I have implementation only for the weights quantization case.", "body": "@raghuraman-k Thanks for answer.  \r\n\r\nUnfortunately, I can't provide small and exhaustive source code example, because in my case drop in accuracy can be observed in complicated detection network, MaskRCNN. To be precise, ROIAlign seems to be rather sensitive to the input distribution changes. (Yes, ROIAlign and other related operations are not supported, however, I manually implemented them in C++ as separate functions. Also inserted additional fake quantization nodes for them).  \r\n\r\nBack to the weights quantization. Yes, you are right, quantization procedure is not like I thought before, however it has some drawbacks.  \r\n\r\nI was digging into the TOCO sources for a while and found out that weights are quantized 2 times, at least for the `quantize_weights=True` option. First, quantization parameters are applied [here](https://github.com/tensorflow/tensorflow/blob/9ba6943a1dbbc415b72835517ad58808ca6a6a3d/tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fake_quant.cc\r\n) and then arrays are requantized [here](\r\nhttps://github.com/tensorflow/tensorflow/blob/9ba6943a1dbbc415b72835517ad58808ca6a6a3d/tensorflow/contrib/lite/toco/graph_transformations/quantize_weights.cc). Not sure about quantized inference, probably the same.\r\n\r\nAlso there is a difference in the TOCO quantization procedure and tensorflow FakeQuantize operation. For instance, the second is less precise than first(clipping in floats instead integers, or something of the kind).  \r\n\r\nBoth described facts introduce small delta between fake quantized weights during training and tensorflow lite quantized weights. As I sad before in some cases this bias leads to significant accuracy drop.  \r\n\r\nIf you are interesting, I fixed described above and recieved machine eps between tensorflow lite weights after dequantization and FakeQuantize node results. However, I have implementation only for the weights quantization case. "}