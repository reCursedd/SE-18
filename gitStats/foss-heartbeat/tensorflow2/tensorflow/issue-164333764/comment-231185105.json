{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231185105", "html_url": "https://github.com/tensorflow/tensorflow/issues/3220#issuecomment-231185105", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3220", "id": 231185105, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTE4NTEwNQ==", "user": {"login": "chasep255", "id": 15787797, "node_id": "MDQ6VXNlcjE1Nzg3Nzk3", "avatar_url": "https://avatars3.githubusercontent.com/u/15787797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chasep255", "html_url": "https://github.com/chasep255", "followers_url": "https://api.github.com/users/chasep255/followers", "following_url": "https://api.github.com/users/chasep255/following{/other_user}", "gists_url": "https://api.github.com/users/chasep255/gists{/gist_id}", "starred_url": "https://api.github.com/users/chasep255/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chasep255/subscriptions", "organizations_url": "https://api.github.com/users/chasep255/orgs", "repos_url": "https://api.github.com/users/chasep255/repos", "events_url": "https://api.github.com/users/chasep255/events{/privacy}", "received_events_url": "https://api.github.com/users/chasep255/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-07T19:40:01Z", "updated_at": "2016-07-07T19:40:01Z", "author_association": "NONE", "body_html": "<p>When I replaced the dynamic_rnn in the encoder scope with something I unrolled my self the issue goes away.</p>\n<pre><code>with tf.variable_scope('encoder') as scope:\n    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(1024) for _ in range(3)])\n    state = tf.zeros((BATCH_SIZE, rnn_cell.state_size))\n    output = [None] * TIME_STEPS\n    for t in range(TIME_STEPS):\n        y_t = tf.reshape(y[:, t, :], (BATCH_SIZE, -1))\n        output[t], state = rnn_cell(y_t, state)\n        scope.reuse_variables()\n    y = tf.pack(output, 1)\n</code></pre>", "body_text": "When I replaced the dynamic_rnn in the encoder scope with something I unrolled my self the issue goes away.\nwith tf.variable_scope('encoder') as scope:\n    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(1024) for _ in range(3)])\n    state = tf.zeros((BATCH_SIZE, rnn_cell.state_size))\n    output = [None] * TIME_STEPS\n    for t in range(TIME_STEPS):\n        y_t = tf.reshape(y[:, t, :], (BATCH_SIZE, -1))\n        output[t], state = rnn_cell(y_t, state)\n        scope.reuse_variables()\n    y = tf.pack(output, 1)", "body": "When I replaced the dynamic_rnn in the encoder scope with something I unrolled my self the issue goes away.\n\n```\nwith tf.variable_scope('encoder') as scope:\n    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(1024) for _ in range(3)])\n    state = tf.zeros((BATCH_SIZE, rnn_cell.state_size))\n    output = [None] * TIME_STEPS\n    for t in range(TIME_STEPS):\n        y_t = tf.reshape(y[:, t, :], (BATCH_SIZE, -1))\n        output[t], state = rnn_cell(y_t, state)\n        scope.reuse_variables()\n    y = tf.pack(output, 1)\n```\n"}