{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/129465679", "pull_request_review_id": 52240625, "id": 129465679, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyOTQ2NTY3OQ==", "diff_hunk": "@@ -54,6 +54,74 @@ __device__ __forceinline__ void AccumulateInto(\n   CudaAtomicAdd(dest_scalar + 1, value.imag());\n }\n \n+// SortedSegmentSumFunctor kernel reduces input data just as\n+// UnsortedSegmentSumCustomKernel does except that input data\n+// is partitioned along the outer reduction dimension. This is\n+// because consecutive rows (elements in a row share the same\n+// outer dimension index) in the flattened 2D input data likely\n+// belong to the same segment in sorted segment sum operation.\n+// Therefore such partitioning strategy has two advantages over\n+// the UnsortedSegmentSumFunctor kernel:\n+// 1. Each thread reduces across multiple rows before writing\n+// answers to the global memory, we can therefore\n+// write reduction results to global memory less often.\n+// 2. We may know that the current thread is the only contributor\n+// to an output element because of the increasing nature of segment\n+// ids. In such cases, we do not need to use atomic operations\n+// to write results to global memory.\n+// In the flattened view of input data (with only outer and inner\n+// dimension), every thread processes a strip of input data of\n+// size OUTER_DIM_TILE_SIZE x 1. This strip runs across multiple\n+// rows of input data and all reduction elements share one inner\n+// dimension index.\n+#define OUTER_DIM_TILE_SIZE 8\n+#define CEIL_DIV(x, y) (1 + (((x)-1) / (y)))\n+template <typename T, typename Index>\n+__global__ void SortedSegmentSumCustomKernel(const Index input_outer_dim_size,\n+                                             const Index inner_dim_size,\n+                                             const Index output_outer_dim_size,\n+                                             const Index* segment_ids,\n+                                             const T* input, T* output) {\n+  const Index input_outer_dim_num_strip =\n+      CEIL_DIV(input_outer_dim_size, OUTER_DIM_TILE_SIZE);\n+  const Index total_stripe_count = inner_dim_size * input_outer_dim_num_strip;\n+\n+  CUDA_1D_KERNEL_LOOP(strip_index, total_stripe_count) {\n+    const Index segment_offset = strip_index % inner_dim_size;\n+    const Index input_outer_dim_index_base =\n+        strip_index / inner_dim_size * OUTER_DIM_TILE_SIZE;\n+\n+    T sum = T(0);\n+    Index first_segment_id = segment_ids[input_outer_dim_index_base];\n+    Index last_output_segment_id = output_outer_dim_size;\n+    const Index actual_stripe_height = MIN(\n+        OUTER_DIM_TILE_SIZE, input_outer_dim_size - input_outer_dim_index_base);\n+    for (Index j = 0; j < actual_stripe_height; j++) {\n+      Index current_output_segment_id =\n+          segment_ids[input_outer_dim_index_base + j];\n+      // decide whether to write result to global memory\n+      if (current_output_segment_id > last_output_segment_id) {\n+        const Index output_index =\n+            last_output_segment_id * inner_dim_size + segment_offset;\n+        // decide whether to write result to global memory using atomic\n+        // operations\n+        if (last_output_segment_id == first_segment_id) {\n+          AccumulateInto<T>(output + output_index, sum);\n+        } else {\n+          *(output + output_index) = sum;", "path": "tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc", "position": 58, "original_position": 58, "commit_id": "50517c902261289b8163ded0979d5ac28bfe9c6d", "original_commit_id": "aba87c28d57d9fd16aacce476b405ebeed50263e", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "body": "I took a closer look at this code. I think we should definitely add more tests to make sure there is no hidden race condition. Also adding a benchmark showing there is no performance regression against unsorted_segment_sum is good. \r\n\r\nPlease make sure try a few different tensor shape aspect ratio in the benchmarks.\r\n", "created_at": "2017-07-26T01:38:14Z", "updated_at": "2017-08-29T00:31:24Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11630#discussion_r129465679", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11630", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/129465679"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11630#discussion_r129465679"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11630"}}, "body_html": "<p>I took a closer look at this code. I think we should definitely add more tests to make sure there is no hidden race condition. Also adding a benchmark showing there is no performance regression against unsorted_segment_sum is good.</p>\n<p>Please make sure try a few different tensor shape aspect ratio in the benchmarks.</p>", "body_text": "I took a closer look at this code. I think we should definitely add more tests to make sure there is no hidden race condition. Also adding a benchmark showing there is no performance regression against unsorted_segment_sum is good.\nPlease make sure try a few different tensor shape aspect ratio in the benchmarks."}