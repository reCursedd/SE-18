{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/129212864", "pull_request_review_id": 51960542, "id": 129212864, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyOTIxMjg2NA==", "diff_hunk": "@@ -54,6 +54,74 @@ __device__ __forceinline__ void AccumulateInto(\n   CudaAtomicAdd(dest_scalar + 1, value.imag());\n }\n \n+// SortedSegmentSumFunctor kernel reduces input data just as\n+// UnsortedSegmentSumCustomKernel does except that input data\n+// is partitioned along the outer reduction dimension. This is\n+// because consecutive rows (elements in a row share the same\n+// outer dimension index) in the flattened 2D input data likely\n+// belong to the same segment in sorted segment sum operation.\n+// Therefore such partitioning strategy has two advantages over\n+// the UnsortedSegmentSumFunctor kernel:\n+// 1. Each thread reduces across multiple rows before writing\n+// answers to the global memory, we can therefore\n+// write reduction results to global memory less often.\n+// 2. We may know that the current thread is the only contributor\n+// to an output element because of the increasing nature of segment\n+// ids. In such cases, we do not need to use atomic operations\n+// to write results to global memory.\n+// In the flattened view of input data (with only outer and inner\n+// dimension), every thread processes a strip of input data of\n+// size OUTER_DIM_TILE_SIZE x 1. This strip runs across multiple\n+// rows of input data and all reduction elements share one inner\n+// dimension index.\n+#define OUTER_DIM_TILE_SIZE 8\n+#define CEIL_DIV(x, y) (1 + (((x)-1) / (y)))", "path": "tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc", "position": null, "original_position": 25, "commit_id": "50517c902261289b8163ded0979d5ac28bfe9c6d", "original_commit_id": "aba87c28d57d9fd16aacce476b405ebeed50263e", "user": {"login": "tjingrant", "id": 6410074, "node_id": "MDQ6VXNlcjY0MTAwNzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/6410074?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tjingrant", "html_url": "https://github.com/tjingrant", "followers_url": "https://api.github.com/users/tjingrant/followers", "following_url": "https://api.github.com/users/tjingrant/following{/other_user}", "gists_url": "https://api.github.com/users/tjingrant/gists{/gist_id}", "starred_url": "https://api.github.com/users/tjingrant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tjingrant/subscriptions", "organizations_url": "https://api.github.com/users/tjingrant/orgs", "repos_url": "https://api.github.com/users/tjingrant/repos", "events_url": "https://api.github.com/users/tjingrant/events{/privacy}", "received_events_url": "https://api.github.com/users/tjingrant/received_events", "type": "User", "site_admin": false}, "body": "Thanks for picking up this mistake.", "created_at": "2017-07-25T05:06:03Z", "updated_at": "2017-08-29T00:31:24Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11630#discussion_r129212864", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11630", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/129212864"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11630#discussion_r129212864"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11630"}}, "body_html": "<p>Thanks for picking up this mistake.</p>", "body_text": "Thanks for picking up this mistake.", "in_reply_to_id": 129195273}