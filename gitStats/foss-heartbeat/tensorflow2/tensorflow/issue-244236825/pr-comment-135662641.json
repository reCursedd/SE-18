{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/135662641", "pull_request_review_id": 59098319, "id": 135662641, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNTY2MjY0MQ==", "diff_hunk": "@@ -646,56 +646,59 @@ def testGradientSegmentsInvalid4(self):\n         with self.assertRaisesOpError(r\"Segment id 0 out of range \\[0, 0\\)\"):\n           s.eval()\n \n-def type_to_str(t):\n-  if t == np.float32:\n-    return \"fp32\"\n-  if t == np.float64:\n-    return \"fp64\"\n-\n class SegmentReductionOpBenchmark(test.Benchmark):\n-\n-  def benchmarkSegmentSumGPU(self):\n-    repeat = 10\n-    outer_dim_options = [2**x for x in range(7, 14, 2)]\n-    ratio_options = [2**x for x in range(1, 6, 2)]\n-    inner_dim_options = [2**x for x in range(7, 14, 2)]\n-    dtype_options = [np.float32, np.float64]\n-\n-    for outer_dim, ratio, inner_dim, dtype in \\\n-      itertools.product(outer_dim_options,\n-                        ratio_options, inner_dim_options, dtype_options):\n-      output_outer_dim = int(outer_dim/ratio)\n-\n-      const = np.random.randint(5, size=(outer_dim, inner_dim))\n-      seg_ids = np.sort(np.random.randint(\n+  outer_dim_options = [2**x for x in range(9, 14, 2)]\n+  ratio_options = [2**x for x in range(1, 6, 2)]\n+  inner_dim_options = [2**x for x in range(9, 14, 2)]\n+  #randomly generated sizes with less alignments\n+  inner_dim_options += [1120, 1215, 1856, 1302, 1329, 1531, 1313, 1672, 1851, 1584]\n+  dtype_options = [np.float32, np.float64]\n+  options = (outer_dim_options,\n+                        ratio_options, inner_dim_options, dtype_options)\n+  op_functors = [lambda vc, vs, seg_ids:\n+                  (\"sorted\", math_ops.segment_sum(vc, vs)),\n+                  lambda vc, vs, seg_ids:\n+                  (\"unsorted\", math_ops.unsorted_segment_sum(vc, vs, seg_ids[-1]+1))]\n+  repeat = 10\n+\n+  def _npTypeToStr(self, t):\n+    if t == np.float32:\n+      return \"fp32\"\n+    if t == np.float64:\n+      return \"fp64\"\n+\n+  def _runGraph(self, op_functor, outer_dim, ratio, inner_dim, dtype):\n+    output_outer_dim = int(outer_dim/ratio)\n+    const = np.random.randint(5, size=(outer_dim, inner_dim))\n+    seg_ids = np.sort(np.random.randint(\n           output_outer_dim, size=outer_dim))\n-\n-      op_functors = [lambda vc, vs:\n-                     (\"sorted\", math_ops.segment_sum(vc, vs)),\n-                     lambda vc, vs, _seg_ids=seg_ids:\n-                     (\"unsorted\", math_ops.unsorted_segment_sum(vc, vs, _seg_ids[-1]+1))]\n-\n-      t = []\n-      for op_functor in op_functors:\n-        with ops.Graph().as_default():\n-          vs = variables.Variable(seg_ids.astype(np.int32))\n-          with ops.device(\"/gpu:0\"):\n-            vc = variables.Variable(const.astype(dtype))\n-          with session.Session() as sess:\n-            variables.global_variables_initializer().run()\n-            name, op = op_functor(vc, vs)\n-            r = self.run_op_benchmark(sess, op, min_iters=repeat,\n+    vs = variables.Variable(seg_ids.astype(np.int32))\n+    with ops.device(\"/gpu:0\"):\n+      vc = variables.Variable(const.astype(dtype))\n+    name, op = op_functor(vc, vs, seg_ids)\n+    with session.Session() as sess:\n+      variables.global_variables_initializer().run()\n+      r = self.run_op_benchmark(sess, op, min_iters=self.repeat,\n                                       name=\"_\".join(map(str,\n                                                         [name,\n                                                          outer_dim,\n                                                          ratio,\n                                                          inner_dim,\n-                                                         type_to_str(dtype)])))\n-            t.append(r[\"wall_time\"])\n+                                                         self._npTypeToStr(dtype)])))\n+    return name, r[\"wall_time\"]\n+\n+  def benchmarkSegmentSumGPUHelper(self):\n+    for outer_dim, ratio, inner_dim, dtype in itertools.product(*self.options):\n+      output_outer_dim = int(outer_dim/ratio)\n+      t = []\n+      for op_functor in self.op_functors:\n+        with ops.Graph().as_default():\n+          name, time = self._runGraph(op_functor, outer_dim, ratio, inner_dim, dtype)\n+          t.append(time)\n \n       # print out the speed up factor for each test\n-      print(\"{:d}\\t{:d}\\t{:d}\\t{:f}\".format(\n-          outer_dim, output_outer_dim, inner_dim, t[1]/t[0]))\n+      print(\"__bench__ {} {:d}\\t{:d}\\t{:d}\\t{:f}\".format(\n+          self._npTypeToStr(dtype), outer_dim, output_outer_dim, inner_dim, t[1]/t[0]))", "path": "tensorflow/python/kernel_tests/segment_reduction_ops_test.py", "position": null, "original_position": 97, "commit_id": "50517c902261289b8163ded0979d5ac28bfe9c6d", "original_commit_id": "11685ce4a55f65ac1d30960363bfc76263930772", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "body": "Most benchmark comparison uses percentage in the difference. But it's up to you. Also mention \"positive means the new implementation is faster\".\r\n\r\nGiven some kernels do get slower. Add a TODO to investigate why that is the case. \r\n\r\nThanks for your contribution!\r\n", "created_at": "2017-08-28T23:42:06Z", "updated_at": "2017-08-29T00:31:24Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11630#discussion_r135662641", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11630", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/135662641"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11630#discussion_r135662641"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11630"}}, "body_html": "<p>Most benchmark comparison uses percentage in the difference. But it's up to you. Also mention \"positive means the new implementation is faster\".</p>\n<p>Given some kernels do get slower. Add a TODO to investigate why that is the case.</p>\n<p>Thanks for your contribution!</p>", "body_text": "Most benchmark comparison uses percentage in the difference. But it's up to you. Also mention \"positive means the new implementation is faster\".\nGiven some kernels do get slower. Add a TODO to investigate why that is the case.\nThanks for your contribution!"}