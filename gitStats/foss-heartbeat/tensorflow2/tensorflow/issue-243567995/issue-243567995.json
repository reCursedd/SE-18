{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11564", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11564/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11564/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11564/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11564", "id": 243567995, "node_id": "MDU6SXNzdWUyNDM1Njc5OTU=", "number": 11564, "title": "XLA bugs on training accuracy", "user": {"login": "nurlonn", "id": 22808599, "node_id": "MDQ6VXNlcjIyODA4NTk5", "avatar_url": "https://avatars1.githubusercontent.com/u/22808599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nurlonn", "html_url": "https://github.com/nurlonn", "followers_url": "https://api.github.com/users/nurlonn/followers", "following_url": "https://api.github.com/users/nurlonn/following{/other_user}", "gists_url": "https://api.github.com/users/nurlonn/gists{/gist_id}", "starred_url": "https://api.github.com/users/nurlonn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nurlonn/subscriptions", "organizations_url": "https://api.github.com/users/nurlonn/orgs", "repos_url": "https://api.github.com/users/nurlonn/repos", "events_url": "https://api.github.com/users/nurlonn/events{/privacy}", "received_events_url": "https://api.github.com/users/nurlonn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "hpucha", "id": 9665833, "node_id": "MDQ6VXNlcjk2NjU4MzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/9665833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hpucha", "html_url": "https://github.com/hpucha", "followers_url": "https://api.github.com/users/hpucha/followers", "following_url": "https://api.github.com/users/hpucha/following{/other_user}", "gists_url": "https://api.github.com/users/hpucha/gists{/gist_id}", "starred_url": "https://api.github.com/users/hpucha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hpucha/subscriptions", "organizations_url": "https://api.github.com/users/hpucha/orgs", "repos_url": "https://api.github.com/users/hpucha/repos", "events_url": "https://api.github.com/users/hpucha/events{/privacy}", "received_events_url": "https://api.github.com/users/hpucha/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "hpucha", "id": 9665833, "node_id": "MDQ6VXNlcjk2NjU4MzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/9665833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hpucha", "html_url": "https://github.com/hpucha", "followers_url": "https://api.github.com/users/hpucha/followers", "following_url": "https://api.github.com/users/hpucha/following{/other_user}", "gists_url": "https://api.github.com/users/hpucha/gists{/gist_id}", "starred_url": "https://api.github.com/users/hpucha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hpucha/subscriptions", "organizations_url": "https://api.github.com/users/hpucha/orgs", "repos_url": "https://api.github.com/users/hpucha/repos", "events_url": "https://api.github.com/users/hpucha/events{/privacy}", "received_events_url": "https://api.github.com/users/hpucha/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 18, "created_at": "2017-07-18T00:42:31Z", "updated_at": "2018-02-22T17:40:05Z", "closed_at": "2018-02-22T00:58:31Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: r1.2.1</li>\n<li><strong>Python version</strong>: 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0 / 6.0</li>\n<li><strong>GPU model and memory</strong>: NVIDIA TITAN Xp 12GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>(At the tensorflow/model/inception directory)<br>\nbazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --train_dir=/tmp/imagenet_train --data_dir=/tmp/imagenet_data<br>\nbazel-bin/inception/imagenet_eval --checkpoint_dir=/tmp/imagenet_train --eval_dir=/tmp/imagenet_eval</p>\n<p>== cat /etc/issue ===============================================<br>\nLinux Ares 4.8.0-58-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116007605\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/63\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/63/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/63\">#63</a>~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux Ares 4.8.0-58-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116007605\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/63\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/63/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/63\">#63</a>~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy (1.13.1)<br>\nprotobuf (3.3.0)<br>\ntensorflow (1.2.1)<br>\ntensorflow-tensorboard (0.1.2)</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.2.1<br>\ntf.GIT_VERSION = v1.2.1-2-gc996c7b<br>\ntf.COMPILER_VERSION = v1.2.1-2-gc996c7b<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda/extras/CUPTI/lib64<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nTue Jul 18 09:26:11 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 381.09                 Driver Version: 381.09                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  TITAN Xp            Off  | 0000:01:00.0     Off |                  N/A |<br>\n| 48%   75C    P2   287W / 250W |  11771MiB / 12189MiB |     54%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID  Type  Process name                               Usage      |<br>\n|=============================================================================|<br>\n|    0      1005    G   /usr/lib/xorg/Xorg                              18MiB |<br>\n|    0     30938    C   /usr/bin/python                              11737MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61<br>\n/usr/local/cuda-8.0/lib64/libcudart_static.a<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7</p>\n<h3>Describe the problem</h3>\n<p>I activated XLA and trained the Inception model.<br>\nWhen I verify the training results, the accuracy is always 0.001.<br>\n(It is considered that the training is not performed normally.)</p>\n<p>When XLA is disabled, normal accuracy is achieved.</p>\n<h3>Source code / logs</h3>\n<p>I added some codes of model/inception/inception/inception_train.py to enable XLA.<br>\nI attached the file.</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/1154355/inception_train.zip\">inception_train.zip</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): r1.2.1\nPython version: 2.7.12\nBazel version (if compiling from source):\nCUDA/cuDNN version: 8.0 / 6.0\nGPU model and memory: NVIDIA TITAN Xp 12GB\nExact command to reproduce:\n\n(At the tensorflow/model/inception directory)\nbazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --train_dir=/tmp/imagenet_train --data_dir=/tmp/imagenet_data\nbazel-bin/inception/imagenet_eval --checkpoint_dir=/tmp/imagenet_train --eval_dir=/tmp/imagenet_eval\n== cat /etc/issue ===============================================\nLinux Ares 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux Ares 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.3.0)\ntensorflow (1.2.1)\ntensorflow-tensorboard (0.1.2)\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.2.1\ntf.GIT_VERSION = v1.2.1-2-gc996c7b\ntf.COMPILER_VERSION = v1.2.1-2-gc996c7b\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda/extras/CUPTI/lib64\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nTue Jul 18 09:26:11 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 381.09                 Driver Version: 381.09                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN Xp            Off  | 0000:01:00.0     Off |                  N/A |\n| 48%   75C    P2   287W / 250W |  11771MiB / 12189MiB |     54%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1005    G   /usr/lib/xorg/Xorg                              18MiB |\n|    0     30938    C   /usr/bin/python                              11737MiB |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\nDescribe the problem\nI activated XLA and trained the Inception model.\nWhen I verify the training results, the accuracy is always 0.001.\n(It is considered that the training is not performed normally.)\nWhen XLA is disabled, normal accuracy is achieved.\nSource code / logs\nI added some codes of model/inception/inception/inception_train.py to enable XLA.\nI attached the file.\ninception_train.zip", "body": "-----------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: r1.2.1\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0 / 6.0\r\n- **GPU model and memory**: NVIDIA TITAN Xp 12GB\r\n- **Exact command to reproduce**:\r\n\r\n(At the tensorflow/model/inception directory)\r\nbazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --train_dir=/tmp/imagenet_train --data_dir=/tmp/imagenet_data\r\nbazel-bin/inception/imagenet_eval --checkpoint_dir=/tmp/imagenet_train --eval_dir=/tmp/imagenet_eval\r\n\r\n== cat /etc/issue ===============================================\r\nLinux Ares 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux Ares 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\ntensorflow-tensorboard (0.1.2)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.1-2-gc996c7b\r\ntf.COMPILER_VERSION = v1.2.1-2-gc996c7b\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nTue Jul 18 09:26:11 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 381.09                 Driver Version: 381.09                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN Xp            Off  | 0000:01:00.0     Off |                  N/A |\r\n| 48%   75C    P2   287W / 250W |  11771MiB / 12189MiB |     54%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      1005    G   /usr/lib/xorg/Xorg                              18MiB |\r\n|    0     30938    C   /usr/bin/python                              11737MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n\r\n\r\n### Describe the problem\r\nI activated XLA and trained the Inception model.\r\nWhen I verify the training results, the accuracy is always 0.001.\r\n(It is considered that the training is not performed normally.)\r\n\r\nWhen XLA is disabled, normal accuracy is achieved.\r\n\r\n### Source code / logs\r\nI added some codes of model/inception/inception/inception_train.py to enable XLA.\r\nI attached the file.\r\n\r\n[inception_train.zip](https://github.com/tensorflow/tensorflow/files/1154355/inception_train.zip)\r\n\r\n\r\n"}