{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/317942304", "html_url": "https://github.com/tensorflow/tensorflow/issues/11564#issuecomment-317942304", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11564", "id": 317942304, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzk0MjMwNA==", "user": {"login": "nurlonn", "id": 22808599, "node_id": "MDQ6VXNlcjIyODA4NTk5", "avatar_url": "https://avatars1.githubusercontent.com/u/22808599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nurlonn", "html_url": "https://github.com/nurlonn", "followers_url": "https://api.github.com/users/nurlonn/followers", "following_url": "https://api.github.com/users/nurlonn/following{/other_user}", "gists_url": "https://api.github.com/users/nurlonn/gists{/gist_id}", "starred_url": "https://api.github.com/users/nurlonn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nurlonn/subscriptions", "organizations_url": "https://api.github.com/users/nurlonn/orgs", "repos_url": "https://api.github.com/users/nurlonn/repos", "events_url": "https://api.github.com/users/nurlonn/events{/privacy}", "received_events_url": "https://api.github.com/users/nurlonn/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-26T04:11:22Z", "updated_at": "2017-07-26T04:13:22Z", "author_association": "NONE", "body_html": "<p>I ran the simple example. (tensorflow/examples/tutorials/mnist/mnist_softmax_xla.py)</p>\n<p>This example seems to work correctly even with XLA.</p>\n<p>To ensure that xla optimization is enabled, the --xla_generate_hlo_graph option is enabled.</p>\n\n<pre><code>nurlonn@Ares:~/workspace/mnist$ ls\nmnist_softmax_xla.py\nnurlonn@Ares:~/workspace/mnist$ TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py --xla=''\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n2017-07-26 13:04:01.942110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-07-26 13:04:01.942576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \nname: TITAN Xp\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.582\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 11.72GiB\n2017-07-26 13:04:01.942595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n2017-07-26 13:04:01.942601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n2017-07-26 13:04:01.942609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0)\n2017-07-26 13:04:01.989717: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-07-26 13:04:01.989757: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\n2017-07-26 13:04:01.990281: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3f5d970 executing computations on platform Host. Devices:\n2017-07-26 13:04:01.990308: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\n2017-07-26 13:04:01.990549: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-07-26 13:04:01.990571: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\n2017-07-26 13:04:01.990868: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3f6bd50 executing computations on platform CUDA. Devices:\n2017-07-26 13:04:01.990884: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\n2017-07-26 13:04:03.225400: I tensorflow/stream_executor/dso_loader.cc:139] successfully opened CUDA library libcupti.so.8.0 locally\n0.9192\n</code></pre>\n\n<pre><code>nurlonn@Ares:~/workspace/mnist$ TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n2017-07-26 13:10:04.847645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-07-26 13:10:04.848130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \nname: TITAN Xp\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.582\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 11.72GiB\n2017-07-26 13:10:04.848148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n2017-07-26 13:10:04.848154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n2017-07-26 13:10:04.848163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0)\n2017-07-26 13:10:04.895322: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-07-26 13:10:04.895369: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\n2017-07-26 13:10:04.895798: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x55020d0 executing computations on platform Host. Devices:\n2017-07-26 13:10:04.895819: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\n2017-07-26 13:10:04.895980: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-07-26 13:10:04.895992: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\n2017-07-26 13:10:04.896399: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x55384d0 executing computations on platform CUDA. Devices:\n2017-07-26 13:10:04.896415: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\n2017-07-26 13:10:05.202342: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [optimization: pipeline start, before simplification]: /tmp/hlo_graph_0.DUlZcS.dot\n2017-07-26 13:10:05.202706: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: pipeline start, before algsimp]: /tmp/hlo_graph_1.7hTRMk.dot\n2017-07-26 13:10:05.203085: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: after algsimp, before reshape-motion]: /tmp/hlo_graph_2.46FPmN.dot\n2017-07-26 13:10:05.203403: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: after reshape-motion, before constant_folding]: /tmp/hlo_graph_3.jbcSWf.dot\n\n...\n&lt;omitted&gt;\n...\n\n2017-07-26 13:10:06.055764: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=0,_XlaNumResourceArgs=0].v11 [GPU-ir-emit-prepare: after dce, before flatten-call-graph]: /tmp/hlo_graph_91.569aPU.dot\n2017-07-26 13:10:06.055924: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=0,_XlaNumResourceArgs=0].v11 [GPU-ir-emit-prepare: after flatten-call-graph, pipeline end]: /tmp/hlo_graph_92.jcgozq.dot\n0.9212\n</code></pre>", "body_text": "I ran the simple example. (tensorflow/examples/tutorials/mnist/mnist_softmax_xla.py)\nThis example seems to work correctly even with XLA.\nTo ensure that xla optimization is enabled, the --xla_generate_hlo_graph option is enabled.\n\nnurlonn@Ares:~/workspace/mnist$ ls\nmnist_softmax_xla.py\nnurlonn@Ares:~/workspace/mnist$ TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py --xla=''\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n2017-07-26 13:04:01.942110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-07-26 13:04:01.942576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \nname: TITAN Xp\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.582\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 11.72GiB\n2017-07-26 13:04:01.942595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n2017-07-26 13:04:01.942601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n2017-07-26 13:04:01.942609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0)\n2017-07-26 13:04:01.989717: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-07-26 13:04:01.989757: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\n2017-07-26 13:04:01.990281: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3f5d970 executing computations on platform Host. Devices:\n2017-07-26 13:04:01.990308: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>\n2017-07-26 13:04:01.990549: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-07-26 13:04:01.990571: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\n2017-07-26 13:04:01.990868: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3f6bd50 executing computations on platform CUDA. Devices:\n2017-07-26 13:04:01.990884: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\n2017-07-26 13:04:03.225400: I tensorflow/stream_executor/dso_loader.cc:139] successfully opened CUDA library libcupti.so.8.0 locally\n0.9192\n\n\nnurlonn@Ares:~/workspace/mnist$ TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n2017-07-26 13:10:04.847645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-07-26 13:10:04.848130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \nname: TITAN Xp\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.582\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 11.72GiB\n2017-07-26 13:10:04.848148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n2017-07-26 13:10:04.848154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n2017-07-26 13:10:04.848163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0)\n2017-07-26 13:10:04.895322: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-07-26 13:10:04.895369: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\n2017-07-26 13:10:04.895798: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x55020d0 executing computations on platform Host. Devices:\n2017-07-26 13:10:04.895819: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>\n2017-07-26 13:10:04.895980: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-07-26 13:10:04.895992: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\n2017-07-26 13:10:04.896399: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x55384d0 executing computations on platform CUDA. Devices:\n2017-07-26 13:10:04.896415: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\n2017-07-26 13:10:05.202342: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [optimization: pipeline start, before simplification]: /tmp/hlo_graph_0.DUlZcS.dot\n2017-07-26 13:10:05.202706: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: pipeline start, before algsimp]: /tmp/hlo_graph_1.7hTRMk.dot\n2017-07-26 13:10:05.203085: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: after algsimp, before reshape-motion]: /tmp/hlo_graph_2.46FPmN.dot\n2017-07-26 13:10:05.203403: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: after reshape-motion, before constant_folding]: /tmp/hlo_graph_3.jbcSWf.dot\n\n...\n<omitted>\n...\n\n2017-07-26 13:10:06.055764: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=0,_XlaNumResourceArgs=0].v11 [GPU-ir-emit-prepare: after dce, before flatten-call-graph]: /tmp/hlo_graph_91.569aPU.dot\n2017-07-26 13:10:06.055924: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=0,_XlaNumResourceArgs=0].v11 [GPU-ir-emit-prepare: after flatten-call-graph, pipeline end]: /tmp/hlo_graph_92.jcgozq.dot\n0.9212", "body": "I ran the simple example. (tensorflow/examples/tutorials/mnist/mnist_softmax_xla.py)\r\n\r\nThis example seems to work correctly even with XLA.\r\n\r\nTo ensure that xla optimization is enabled, the --xla_generate_hlo_graph option is enabled.\r\n\r\n<Without XLA>\r\n\r\n```\r\nnurlonn@Ares:~/workspace/mnist$ ls\r\nmnist_softmax_xla.py\r\nnurlonn@Ares:~/workspace/mnist$ TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py --xla=''\r\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\r\n2017-07-26 13:04:01.942110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-07-26 13:04:01.942576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \r\nname: TITAN Xp\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.582\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.72GiB\r\n2017-07-26 13:04:01.942595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \r\n2017-07-26 13:04:01.942601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \r\n2017-07-26 13:04:01.942609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0)\r\n2017-07-26 13:04:01.989717: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\n2017-07-26 13:04:01.989757: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\r\n2017-07-26 13:04:01.990281: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3f5d970 executing computations on platform Host. Devices:\r\n2017-07-26 13:04:01.990308: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>\r\n2017-07-26 13:04:01.990549: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\n2017-07-26 13:04:01.990571: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\r\n2017-07-26 13:04:01.990868: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3f6bd50 executing computations on platform CUDA. Devices:\r\n2017-07-26 13:04:01.990884: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\r\n2017-07-26 13:04:03.225400: I tensorflow/stream_executor/dso_loader.cc:139] successfully opened CUDA library libcupti.so.8.0 locally\r\n0.9192\r\n```\r\n\r\n\r\n<With XLA>\r\n\r\n```\r\nnurlonn@Ares:~/workspace/mnist$ TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py\r\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\r\n2017-07-26 13:10:04.847645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-07-26 13:10:04.848130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \r\nname: TITAN Xp\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.582\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.72GiB\r\n2017-07-26 13:10:04.848148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \r\n2017-07-26 13:10:04.848154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \r\n2017-07-26 13:10:04.848163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0)\r\n2017-07-26 13:10:04.895322: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\n2017-07-26 13:10:04.895369: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\r\n2017-07-26 13:10:04.895798: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x55020d0 executing computations on platform Host. Devices:\r\n2017-07-26 13:10:04.895819: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>\r\n2017-07-26 13:10:04.895980: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\n2017-07-26 13:10:04.895992: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\r\n2017-07-26 13:10:04.896399: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x55384d0 executing computations on platform CUDA. Devices:\r\n2017-07-26 13:10:04.896415: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\r\n2017-07-26 13:10:05.202342: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [optimization: pipeline start, before simplification]: /tmp/hlo_graph_0.DUlZcS.dot\r\n2017-07-26 13:10:05.202706: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: pipeline start, before algsimp]: /tmp/hlo_graph_1.7hTRMk.dot\r\n2017-07-26 13:10:05.203085: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: after algsimp, before reshape-motion]: /tmp/hlo_graph_2.46FPmN.dot\r\n2017-07-26 13:10:05.203403: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v82 [simplification: after reshape-motion, before constant_folding]: /tmp/hlo_graph_3.jbcSWf.dot\r\n\r\n...\r\n<omitted>\r\n...\r\n\r\n2017-07-26 13:10:06.055764: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=0,_XlaNumResourceArgs=0].v11 [GPU-ir-emit-prepare: after dce, before flatten-call-graph]: /tmp/hlo_graph_91.569aPU.dot\r\n2017-07-26 13:10:06.055924: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:573] computation cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=0,_XlaNumResourceArgs=0].v11 [GPU-ir-emit-prepare: after flatten-call-graph, pipeline end]: /tmp/hlo_graph_92.jcgozq.dot\r\n0.9212\r\n```\r\n"}