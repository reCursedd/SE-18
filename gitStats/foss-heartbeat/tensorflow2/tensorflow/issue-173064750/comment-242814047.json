{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/242814047", "html_url": "https://github.com/tensorflow/tensorflow/issues/4025#issuecomment-242814047", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4025", "id": 242814047, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MjgxNDA0Nw==", "user": {"login": "gilberthendry", "id": 18124217, "node_id": "MDQ6VXNlcjE4MTI0MjE3", "avatar_url": "https://avatars0.githubusercontent.com/u/18124217?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gilberthendry", "html_url": "https://github.com/gilberthendry", "followers_url": "https://api.github.com/users/gilberthendry/followers", "following_url": "https://api.github.com/users/gilberthendry/following{/other_user}", "gists_url": "https://api.github.com/users/gilberthendry/gists{/gist_id}", "starred_url": "https://api.github.com/users/gilberthendry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gilberthendry/subscriptions", "organizations_url": "https://api.github.com/users/gilberthendry/orgs", "repos_url": "https://api.github.com/users/gilberthendry/repos", "events_url": "https://api.github.com/users/gilberthendry/events{/privacy}", "received_events_url": "https://api.github.com/users/gilberthendry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-26T18:27:26Z", "updated_at": "2016-08-26T18:27:26Z", "author_association": "NONE", "body_html": "<p>Sorry for all the troubles.  Long story short, TensorForestEstimator doesn't support such a heterogenous set of inputs as the wide_n_deep tutorial, partly because the TensorForest internal interfaces predate the estimator interface and a more general translation between the two was never put in place because we haven't had a driver for that yet.   What does work is:</p>\n<ol>\n<li>All continuous numerical inputs</li>\n<li>All sparse string inputs (that are hashed and mapped to a numerical space and treated as categorical)</li>\n<li>A mix of continuous and categorical numerical inputs.</li>\n</ol>\n<p>Let me try to comment on the things listed under Update:</p>\n<ol>\n<li>Let me clarify that continuous and categorical inputs are different than sparse and dense representation (you can have categorical dense inputs).  It's a slightly important distinction for forests, because they have the ability to implement a x[i] == T function at nodes instead of x[i] &lt; T.  But it is true that we only support sparse or dense input right now.</li>\n<li>This was quickly fixed a while ago, but unfortunately the last Tensorflow release seems to have included that mistake.  Installing the nightly build fixes this.</li>\n<li>This is usually a warning that a given example is totally empty when using sparse inputs.  If you don't think that any examples are totally empty, then it's probably something with the shape of the tensors being input (especially if they're all input 1 and 2).</li>\n<li>_ParseDense expects 2-D tensors, which is what you get when you use e.g. tf.FixedLenFeature with tf.contrib.learn.read_batch_features (which is what we normally do).  TensorForest is an online training algorithm, so it's really made for reasonable mini-batch sizes (100-10000) that sample from a larger data set. This allows us to train on data sets that are infeasible to read into memory, but also works fine for smaller data sets in our experience. If I'm reading it right it seems like the wide_n_deep tutorial throws the whole column into a 1-D tf.constant. We've set up TensorForest with the assumption that x,y is used for smaller data sets that fit in memory, and input_fn is used for batched large data sets.  Maybe that's not a good assumption, but in any case this should at least be documented better.</li>\n<li>Again, might be wrong here, but if not using mini-batching, it isn't surprising that training might take a long time.</li>\n<li>This is maybe related to 4 and mini-batching.</li>\n<li>What is confusion_matrix expecting?  TensorForest inference outputs class probabilities, so for e.g. streaming_accuracy, we wrap it in a function that does an argmax to get class prediction.<br>\ntensorflow/contrib/tensor_forest/client/eval_metrics.py</li>\n</ol>\n<p>Thanks for pointing these things out, I'll be addressing them in some combination of improved documentation, improved error conditions, patching up cases that we can make work, and maybe even some heavy refactoring.</p>", "body_text": "Sorry for all the troubles.  Long story short, TensorForestEstimator doesn't support such a heterogenous set of inputs as the wide_n_deep tutorial, partly because the TensorForest internal interfaces predate the estimator interface and a more general translation between the two was never put in place because we haven't had a driver for that yet.   What does work is:\n\nAll continuous numerical inputs\nAll sparse string inputs (that are hashed and mapped to a numerical space and treated as categorical)\nA mix of continuous and categorical numerical inputs.\n\nLet me try to comment on the things listed under Update:\n\nLet me clarify that continuous and categorical inputs are different than sparse and dense representation (you can have categorical dense inputs).  It's a slightly important distinction for forests, because they have the ability to implement a x[i] == T function at nodes instead of x[i] < T.  But it is true that we only support sparse or dense input right now.\nThis was quickly fixed a while ago, but unfortunately the last Tensorflow release seems to have included that mistake.  Installing the nightly build fixes this.\nThis is usually a warning that a given example is totally empty when using sparse inputs.  If you don't think that any examples are totally empty, then it's probably something with the shape of the tensors being input (especially if they're all input 1 and 2).\n_ParseDense expects 2-D tensors, which is what you get when you use e.g. tf.FixedLenFeature with tf.contrib.learn.read_batch_features (which is what we normally do).  TensorForest is an online training algorithm, so it's really made for reasonable mini-batch sizes (100-10000) that sample from a larger data set. This allows us to train on data sets that are infeasible to read into memory, but also works fine for smaller data sets in our experience. If I'm reading it right it seems like the wide_n_deep tutorial throws the whole column into a 1-D tf.constant. We've set up TensorForest with the assumption that x,y is used for smaller data sets that fit in memory, and input_fn is used for batched large data sets.  Maybe that's not a good assumption, but in any case this should at least be documented better.\nAgain, might be wrong here, but if not using mini-batching, it isn't surprising that training might take a long time.\nThis is maybe related to 4 and mini-batching.\nWhat is confusion_matrix expecting?  TensorForest inference outputs class probabilities, so for e.g. streaming_accuracy, we wrap it in a function that does an argmax to get class prediction.\ntensorflow/contrib/tensor_forest/client/eval_metrics.py\n\nThanks for pointing these things out, I'll be addressing them in some combination of improved documentation, improved error conditions, patching up cases that we can make work, and maybe even some heavy refactoring.", "body": "Sorry for all the troubles.  Long story short, TensorForestEstimator doesn't support such a heterogenous set of inputs as the wide_n_deep tutorial, partly because the TensorForest internal interfaces predate the estimator interface and a more general translation between the two was never put in place because we haven't had a driver for that yet.   What does work is:\n1. All continuous numerical inputs\n2. All sparse string inputs (that are hashed and mapped to a numerical space and treated as categorical)\n3. A mix of continuous and categorical numerical inputs.\n\nLet me try to comment on the things listed under Update:\n1. Let me clarify that continuous and categorical inputs are different than sparse and dense representation (you can have categorical dense inputs).  It's a slightly important distinction for forests, because they have the ability to implement a x[i] == T function at nodes instead of x[i] < T.  But it is true that we only support sparse or dense input right now.\n2. This was quickly fixed a while ago, but unfortunately the last Tensorflow release seems to have included that mistake.  Installing the nightly build fixes this.\n3. This is usually a warning that a given example is totally empty when using sparse inputs.  If you don't think that any examples are totally empty, then it's probably something with the shape of the tensors being input (especially if they're all input 1 and 2).\n4. _ParseDense expects 2-D tensors, which is what you get when you use e.g. tf.FixedLenFeature with tf.contrib.learn.read_batch_features (which is what we normally do).  TensorForest is an online training algorithm, so it's really made for reasonable mini-batch sizes (100-10000) that sample from a larger data set. This allows us to train on data sets that are infeasible to read into memory, but also works fine for smaller data sets in our experience. If I'm reading it right it seems like the wide_n_deep tutorial throws the whole column into a 1-D tf.constant. We've set up TensorForest with the assumption that x,y is used for smaller data sets that fit in memory, and input_fn is used for batched large data sets.  Maybe that's not a good assumption, but in any case this should at least be documented better.\n5. Again, might be wrong here, but if not using mini-batching, it isn't surprising that training might take a long time. \n6. This is maybe related to 4 and mini-batching.\n7. What is confusion_matrix expecting?  TensorForest inference outputs class probabilities, so for e.g. streaming_accuracy, we wrap it in a function that does an argmax to get class prediction.\n   tensorflow/contrib/tensor_forest/client/eval_metrics.py\n\nThanks for pointing these things out, I'll be addressing them in some combination of improved documentation, improved error conditions, patching up cases that we can make work, and maybe even some heavy refactoring.  \n"}