{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/358439208", "html_url": "https://github.com/tensorflow/tensorflow/issues/16106#issuecomment-358439208", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16106", "id": 358439208, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODQzOTIwOA==", "user": {"login": "kpot", "id": 93858, "node_id": "MDQ6VXNlcjkzODU4", "avatar_url": "https://avatars3.githubusercontent.com/u/93858?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kpot", "html_url": "https://github.com/kpot", "followers_url": "https://api.github.com/users/kpot/followers", "following_url": "https://api.github.com/users/kpot/following{/other_user}", "gists_url": "https://api.github.com/users/kpot/gists{/gist_id}", "starred_url": "https://api.github.com/users/kpot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kpot/subscriptions", "organizations_url": "https://api.github.com/users/kpot/orgs", "repos_url": "https://api.github.com/users/kpot/repos", "events_url": "https://api.github.com/users/kpot/events{/privacy}", "received_events_url": "https://api.github.com/users/kpot/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-17T20:45:17Z", "updated_at": "2018-01-17T20:45:17Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16018\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/asimshankar\">@asimshankar</a> While working with reinforcement learning I discovered that for some problems running on the same GPU not only the neural network, but the whole environment simulation, sometimes gives a big boost in performance (about 10x in my case). So now I often use TF more like \"a general computational framework for GPUs\" of which deep learning is only a part. And it doesn't disappoint. Hence the need for integer variables and perhaps some other peculiarities. A lot of data to track - a lot of indices. Unfortunately, writing and debugging such simulations can be painful sometimes, and eager execution looks very promising in that respect.</p>\n<p>I understand that writing a specialized kernel is a much better way to do such things. But for a rapid prototyping tools like TF are priceless. It doesn't matter if the performance suffers a little here and there if I still can get a decent speedup. Most importantly the things should be doable.</p>", "body_text": "@asimshankar While working with reinforcement learning I discovered that for some problems running on the same GPU not only the neural network, but the whole environment simulation, sometimes gives a big boost in performance (about 10x in my case). So now I often use TF more like \"a general computational framework for GPUs\" of which deep learning is only a part. And it doesn't disappoint. Hence the need for integer variables and perhaps some other peculiarities. A lot of data to track - a lot of indices. Unfortunately, writing and debugging such simulations can be painful sometimes, and eager execution looks very promising in that respect.\nI understand that writing a specialized kernel is a much better way to do such things. But for a rapid prototyping tools like TF are priceless. It doesn't matter if the performance suffers a little here and there if I still can get a decent speedup. Most importantly the things should be doable.", "body": "@asimshankar While working with reinforcement learning I discovered that for some problems running on the same GPU not only the neural network, but the whole environment simulation, sometimes gives a big boost in performance (about 10x in my case). So now I often use TF more like \"a general computational framework for GPUs\" of which deep learning is only a part. And it doesn't disappoint. Hence the need for integer variables and perhaps some other peculiarities. A lot of data to track - a lot of indices. Unfortunately, writing and debugging such simulations can be painful sometimes, and eager execution looks very promising in that respect.\r\n\r\nI understand that writing a specialized kernel is a much better way to do such things. But for a rapid prototyping tools like TF are priceless. It doesn't matter if the performance suffers a little here and there if I still can get a decent speedup. Most importantly the things should be doable."}