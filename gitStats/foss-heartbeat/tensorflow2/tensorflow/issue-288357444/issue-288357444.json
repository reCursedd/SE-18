{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16106", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16106/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16106/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16106/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16106", "id": 288357444, "node_id": "MDU6SXNzdWUyODgzNTc0NDQ=", "number": 16106, "title": "Eager: Invalid placement of vars/consts depending on their types and not the tf.device", "user": {"login": "kpot", "id": 93858, "node_id": "MDQ6VXNlcjkzODU4", "avatar_url": "https://avatars3.githubusercontent.com/u/93858?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kpot", "html_url": "https://github.com/kpot", "followers_url": "https://api.github.com/users/kpot/followers", "following_url": "https://api.github.com/users/kpot/following{/other_user}", "gists_url": "https://api.github.com/users/kpot/gists{/gist_id}", "starred_url": "https://api.github.com/users/kpot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kpot/subscriptions", "organizations_url": "https://api.github.com/users/kpot/orgs", "repos_url": "https://api.github.com/users/kpot/repos", "events_url": "https://api.github.com/users/kpot/events{/privacy}", "received_events_url": "https://api.github.com/users/kpot/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2018-01-13T20:28:29Z", "updated_at": "2018-01-31T07:01:51Z", "closed_at": "2018-01-25T00:10:50Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nI'm currently testing eager execution on TF 1.5.0-rc1 (built it with XLA and CUDA enabled) and observe strange behavior: variables and constants get created either on GPU or CPU depending on their types, and not <code>with tf.device(...):</code> block. Moreover, on creation of int32 variable it fails completely. For example, when I run the following code</p>\n<pre><code>import tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\ntfe.enable_eager_execution()\n\nprint('TensorFlow version:', tf.__version__)\n\nwith tf.device('/gpu:0'):\n    A = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n    print('Const A is placed on:', A.device)\n\n    B = tf.constant([1, 2, 3], dtype=tf.int32)\n    print('Const B is placed on:', B.device)\n\n    C = tfe.Variable([1.0, 2.0, 3.0], dtype=tf.float32)\n    print('Variable C is placed on:', C.device)\n\n    D = tfe.Variable([1, 2, 3], dtype=tf.int32)\n    print('Variable D is placed on:', D.device)\n</code></pre>\n<p>I get the following output:</p>\n<pre><code>TensorFlow version: 1.5.0-rc1\n2018-01-14 01:16:06.385929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-01-14 01:16:06.386198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:01:00.0\ntotalMemory: 10.91GiB freeMemory: 363.06MiB\n2018-01-14 01:16:06.386223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\nConst A is placed on: /job:localhost/replica:0/task:0/device:GPU:0\nConst B is placed on: CPU:0\nVariable C is placed on: /job:localhost/replica:0/task:0/device:GPU:0\nTraceback (most recent call last):\n  File \"tf_bug.py\", line 18, in &lt;module&gt;\n    D = tfe.Variable([1, 2, 3], dtype=tf.int32)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 277, in __init__\n    constraint=constraint)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 422, in _init_from_args\n    graph_mode=self._in_graph_mode)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 53, in _eager_safe_variable_handle\n    container=container)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 396, in var_handle_op\n    attrs=_attrs, ctx=_ctx, name=name)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\n    six.raise_from(core._status_to_exception(e.code, message), None)\n  File \"&lt;string&gt;\", line 3, in raise_from\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'VarHandleOp' OpKernel for GPU devices compatible with node VarHandleOp = VarHandleOp[container=\"eager-execution-2/\", dtype=DT_INT32, shape=[3], shared_name=\"11\"]()\n\t (OpKernel was found, but attributes didn't match)\n\t.  Registered:  device='GPU'; dtype in [DT_VARIANT]\n  device='GPU'; dtype in [DT_COMPLEX128]\n  device='GPU'; dtype in [DT_COMPLEX64]\n  device='GPU'; dtype in [DT_BOOL]\n  device='GPU'; dtype in [DT_DOUBLE]\n  device='GPU'; dtype in [DT_FLOAT]\n  device='GPU'; dtype in [DT_HALF]\n  device='CPU'\n  device='XLA_GPU'\n  device='XLA_CPU'\n [Op:VarHandleOp] name: Variable/\n</code></pre>\n<p>As you can see, the constants and variables get placed either on GPU:0 or CPU:0 despite all of them gathered inside the same <code>tf.device('/gpu:0')</code> block.</p>", "body_text": "Hi,\nI'm currently testing eager execution on TF 1.5.0-rc1 (built it with XLA and CUDA enabled) and observe strange behavior: variables and constants get created either on GPU or CPU depending on their types, and not with tf.device(...): block. Moreover, on creation of int32 variable it fails completely. For example, when I run the following code\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\ntfe.enable_eager_execution()\n\nprint('TensorFlow version:', tf.__version__)\n\nwith tf.device('/gpu:0'):\n    A = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n    print('Const A is placed on:', A.device)\n\n    B = tf.constant([1, 2, 3], dtype=tf.int32)\n    print('Const B is placed on:', B.device)\n\n    C = tfe.Variable([1.0, 2.0, 3.0], dtype=tf.float32)\n    print('Variable C is placed on:', C.device)\n\n    D = tfe.Variable([1, 2, 3], dtype=tf.int32)\n    print('Variable D is placed on:', D.device)\n\nI get the following output:\nTensorFlow version: 1.5.0-rc1\n2018-01-14 01:16:06.385929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-01-14 01:16:06.386198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:01:00.0\ntotalMemory: 10.91GiB freeMemory: 363.06MiB\n2018-01-14 01:16:06.386223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\nConst A is placed on: /job:localhost/replica:0/task:0/device:GPU:0\nConst B is placed on: CPU:0\nVariable C is placed on: /job:localhost/replica:0/task:0/device:GPU:0\nTraceback (most recent call last):\n  File \"tf_bug.py\", line 18, in <module>\n    D = tfe.Variable([1, 2, 3], dtype=tf.int32)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 277, in __init__\n    constraint=constraint)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 422, in _init_from_args\n    graph_mode=self._in_graph_mode)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 53, in _eager_safe_variable_handle\n    container=container)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 396, in var_handle_op\n    attrs=_attrs, ctx=_ctx, name=name)\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\n    six.raise_from(core._status_to_exception(e.code, message), None)\n  File \"<string>\", line 3, in raise_from\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'VarHandleOp' OpKernel for GPU devices compatible with node VarHandleOp = VarHandleOp[container=\"eager-execution-2/\", dtype=DT_INT32, shape=[3], shared_name=\"11\"]()\n\t (OpKernel was found, but attributes didn't match)\n\t.  Registered:  device='GPU'; dtype in [DT_VARIANT]\n  device='GPU'; dtype in [DT_COMPLEX128]\n  device='GPU'; dtype in [DT_COMPLEX64]\n  device='GPU'; dtype in [DT_BOOL]\n  device='GPU'; dtype in [DT_DOUBLE]\n  device='GPU'; dtype in [DT_FLOAT]\n  device='GPU'; dtype in [DT_HALF]\n  device='CPU'\n  device='XLA_GPU'\n  device='XLA_CPU'\n [Op:VarHandleOp] name: Variable/\n\nAs you can see, the constants and variables get placed either on GPU:0 or CPU:0 despite all of them gathered inside the same tf.device('/gpu:0') block.", "body": "Hi,\r\nI'm currently testing eager execution on TF 1.5.0-rc1 (built it with XLA and CUDA enabled) and observe strange behavior: variables and constants get created either on GPU or CPU depending on their types, and not `with tf.device(...):` block. Moreover, on creation of int32 variable it fails completely. For example, when I run the following code\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\n\r\nprint('TensorFlow version:', tf.__version__)\r\n\r\nwith tf.device('/gpu:0'):\r\n    A = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\r\n    print('Const A is placed on:', A.device)\r\n\r\n    B = tf.constant([1, 2, 3], dtype=tf.int32)\r\n    print('Const B is placed on:', B.device)\r\n\r\n    C = tfe.Variable([1.0, 2.0, 3.0], dtype=tf.float32)\r\n    print('Variable C is placed on:', C.device)\r\n\r\n    D = tfe.Variable([1, 2, 3], dtype=tf.int32)\r\n    print('Variable D is placed on:', D.device)\r\n```\r\n\r\nI get the following output:\r\n\r\n```\r\nTensorFlow version: 1.5.0-rc1\r\n2018-01-14 01:16:06.385929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-01-14 01:16:06.386198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 10.91GiB freeMemory: 363.06MiB\r\n2018-01-14 01:16:06.386223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nConst A is placed on: /job:localhost/replica:0/task:0/device:GPU:0\r\nConst B is placed on: CPU:0\r\nVariable C is placed on: /job:localhost/replica:0/task:0/device:GPU:0\r\nTraceback (most recent call last):\r\n  File \"tf_bug.py\", line 18, in <module>\r\n    D = tfe.Variable([1, 2, 3], dtype=tf.int32)\r\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 277, in __init__\r\n    constraint=constraint)\r\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 422, in _init_from_args\r\n    graph_mode=self._in_graph_mode)\r\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 53, in _eager_safe_variable_handle\r\n    container=container)\r\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 396, in var_handle_op\r\n    attrs=_attrs, ctx=_ctx, name=name)\r\n  File \"/home/kpot/pyves/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'VarHandleOp' OpKernel for GPU devices compatible with node VarHandleOp = VarHandleOp[container=\"eager-execution-2/\", dtype=DT_INT32, shape=[3], shared_name=\"11\"]()\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='GPU'; dtype in [DT_VARIANT]\r\n  device='GPU'; dtype in [DT_COMPLEX128]\r\n  device='GPU'; dtype in [DT_COMPLEX64]\r\n  device='GPU'; dtype in [DT_BOOL]\r\n  device='GPU'; dtype in [DT_DOUBLE]\r\n  device='GPU'; dtype in [DT_FLOAT]\r\n  device='GPU'; dtype in [DT_HALF]\r\n  device='CPU'\r\n  device='XLA_GPU'\r\n  device='XLA_CPU'\r\n [Op:VarHandleOp] name: Variable/\r\n```\r\n\r\nAs you can see, the constants and variables get placed either on GPU:0 or CPU:0 despite all of them gathered inside the same `tf.device('/gpu:0')` block."}