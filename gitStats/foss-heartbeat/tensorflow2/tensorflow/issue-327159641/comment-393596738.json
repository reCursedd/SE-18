{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/393596738", "html_url": "https://github.com/tensorflow/tensorflow/issues/19607#issuecomment-393596738", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19607", "id": 393596738, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MzU5NjczOA==", "user": {"login": "MistLiao", "id": 10419955, "node_id": "MDQ6VXNlcjEwNDE5OTU1", "avatar_url": "https://avatars1.githubusercontent.com/u/10419955?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MistLiao", "html_url": "https://github.com/MistLiao", "followers_url": "https://api.github.com/users/MistLiao/followers", "following_url": "https://api.github.com/users/MistLiao/following{/other_user}", "gists_url": "https://api.github.com/users/MistLiao/gists{/gist_id}", "starred_url": "https://api.github.com/users/MistLiao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MistLiao/subscriptions", "organizations_url": "https://api.github.com/users/MistLiao/orgs", "repos_url": "https://api.github.com/users/MistLiao/repos", "events_url": "https://api.github.com/users/MistLiao/events{/privacy}", "received_events_url": "https://api.github.com/users/MistLiao/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-31T16:44:00Z", "updated_at": "2018-05-31T16:44:00Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1450614\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/suharshs\">@suharshs</a> The issue should be caused by the operator CONCATENATION when quantization:</p>\n<p>`</p>\n<p>127 | [340, 370, 13] | [433] | {'axis': 3, 'fused_activation_function': 'NONE'} | CONCATENATION (opcode=1)</p>\n<p>340 | Openpose/MConv_Stage5_L1_5_pointwise/add_fold | UINT8 | [1, 32, 32, 38] | 347 | {'min': [-1.05201], 'max': [6.00753], 'scale': [0.027684], 'zero_point': [38]}<br>\n371 | Openpose/MConv_Stage5_L2_5_pointwise/weights_quant/FakeQuantWithMinMaxVars | UINT8 | [19, 1, 1, 64] | 139 | {'min': [-9.128201], 'max': [9.394188], 'scale': [0.072637], 'zero_point': [126]}<br>\n13 | MobilenetV1/Conv2d_11_pointwise/Relu6 | UINT8 | [1, 32, 32, 256] | 240 | {'min': [-1.05201], 'max': [6.00753], 'scale': [0.027684], 'zero_point': [38]}</p>\n<p>the warning message when do Toco convert:<br>\n2018-05-29 12:09:56.228183: W tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:105] Tweaking the MinMax of array Openpose/MConv_Stage1_L2_5_pointwise/add_fold, which is an input to {Concatenation operator with output Openpose/MConv_Stage2_concat}, because we want all inputs and outputs of a Concatenation operator to have the same MinMax so that it can be implemented as a pure byte-copy, no arithmetic.</p>\n<p>any suggestions?</p>\n<p>`</p>", "body_text": "@suharshs The issue should be caused by the operator CONCATENATION when quantization:\n`\n127 | [340, 370, 13] | [433] | {'axis': 3, 'fused_activation_function': 'NONE'} | CONCATENATION (opcode=1)\n340 | Openpose/MConv_Stage5_L1_5_pointwise/add_fold | UINT8 | [1, 32, 32, 38] | 347 | {'min': [-1.05201], 'max': [6.00753], 'scale': [0.027684], 'zero_point': [38]}\n371 | Openpose/MConv_Stage5_L2_5_pointwise/weights_quant/FakeQuantWithMinMaxVars | UINT8 | [19, 1, 1, 64] | 139 | {'min': [-9.128201], 'max': [9.394188], 'scale': [0.072637], 'zero_point': [126]}\n13 | MobilenetV1/Conv2d_11_pointwise/Relu6 | UINT8 | [1, 32, 32, 256] | 240 | {'min': [-1.05201], 'max': [6.00753], 'scale': [0.027684], 'zero_point': [38]}\nthe warning message when do Toco convert:\n2018-05-29 12:09:56.228183: W tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:105] Tweaking the MinMax of array Openpose/MConv_Stage1_L2_5_pointwise/add_fold, which is an input to {Concatenation operator with output Openpose/MConv_Stage2_concat}, because we want all inputs and outputs of a Concatenation operator to have the same MinMax so that it can be implemented as a pure byte-copy, no arithmetic.\nany suggestions?\n`", "body": "@suharshs The issue should be caused by the operator CONCATENATION when quantization:\r\n\r\n`\r\n\r\n127 | [340, 370, 13] | [433] | {'axis': 3, 'fused_activation_function': 'NONE'} | CONCATENATION (opcode=1)\r\n\r\n340 | Openpose/MConv_Stage5_L1_5_pointwise/add_fold | UINT8 | [1, 32, 32, 38] | 347 | {'min': [-1.05201], 'max': [6.00753], 'scale': [0.027684], 'zero_point': [38]}\r\n371 | Openpose/MConv_Stage5_L2_5_pointwise/weights_quant/FakeQuantWithMinMaxVars | UINT8 | [19, 1, 1, 64] | 139 | {'min': [-9.128201], 'max': [9.394188], 'scale': [0.072637], 'zero_point': [126]}\r\n13 | MobilenetV1/Conv2d_11_pointwise/Relu6 | UINT8 | [1, 32, 32, 256] | 240 | {'min': [-1.05201], 'max': [6.00753], 'scale': [0.027684], 'zero_point': [38]}\r\n\r\nthe warning message when do Toco convert:\r\n2018-05-29 12:09:56.228183: W tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:105] Tweaking the MinMax of array Openpose/MConv_Stage1_L2_5_pointwise/add_fold, which is an input to {Concatenation operator with output Openpose/MConv_Stage2_concat}, because we want all inputs and outputs of a Concatenation operator to have the same MinMax so that it can be implemented as a pure byte-copy, no arithmetic.\r\n\r\nany suggestions?\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n`\r\n\r\n"}