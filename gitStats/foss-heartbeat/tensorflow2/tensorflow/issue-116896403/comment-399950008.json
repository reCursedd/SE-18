{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/399950008", "html_url": "https://github.com/tensorflow/tensorflow/issues/216#issuecomment-399950008", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/216", "id": 399950008, "node_id": "MDEyOklzc3VlQ29tbWVudDM5OTk1MDAwOA==", "user": {"login": "guidocalvano", "id": 483044, "node_id": "MDQ6VXNlcjQ4MzA0NA==", "avatar_url": "https://avatars0.githubusercontent.com/u/483044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guidocalvano", "html_url": "https://github.com/guidocalvano", "followers_url": "https://api.github.com/users/guidocalvano/followers", "following_url": "https://api.github.com/users/guidocalvano/following{/other_user}", "gists_url": "https://api.github.com/users/guidocalvano/gists{/gist_id}", "starred_url": "https://api.github.com/users/guidocalvano/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guidocalvano/subscriptions", "organizations_url": "https://api.github.com/users/guidocalvano/orgs", "repos_url": "https://api.github.com/users/guidocalvano/repos", "events_url": "https://api.github.com/users/guidocalvano/events{/privacy}", "received_events_url": "https://api.github.com/users/guidocalvano/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-25T13:23:19Z", "updated_at": "2018-06-25T13:23:19Z", "author_association": "NONE", "body_html": "<p>I would also welcome broadcasting for matmul, because without broadcasting it is necessary to use tiling instead. Profiling shows this tiling is what I (and probably anyone else in need of broadcasting) lose the largest part of my (/our) processing power on. It seems plausible that a clever matmul broadcasting implementation can prevent any actual copying and thus speed up all our code by potentially eliminating the rate limiting step.</p>\n<p>Note that capsule and matrix capsule networks (two new networks released by Hinton) could potentially benefit a lot from a broadcasting matmul; see <a href=\"https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb\">https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb</a> (specifically section Compute the Predicted Output Vectors)</p>", "body_text": "I would also welcome broadcasting for matmul, because without broadcasting it is necessary to use tiling instead. Profiling shows this tiling is what I (and probably anyone else in need of broadcasting) lose the largest part of my (/our) processing power on. It seems plausible that a clever matmul broadcasting implementation can prevent any actual copying and thus speed up all our code by potentially eliminating the rate limiting step.\nNote that capsule and matrix capsule networks (two new networks released by Hinton) could potentially benefit a lot from a broadcasting matmul; see https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb (specifically section Compute the Predicted Output Vectors)", "body": "I would also welcome broadcasting for matmul, because without broadcasting it is necessary to use tiling instead. Profiling shows this tiling is what I (and probably anyone else in need of broadcasting) lose the largest part of my (/our) processing power on. It seems plausible that a clever matmul broadcasting implementation can prevent any actual copying and thus speed up all our code by potentially eliminating the rate limiting step.\r\n\r\nNote that capsule and matrix capsule networks (two new networks released by Hinton) could potentially benefit a lot from a broadcasting matmul; see https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb (specifically section Compute the Predicted Output Vectors)"}