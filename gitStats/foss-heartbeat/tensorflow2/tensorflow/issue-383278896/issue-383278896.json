{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23906", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23906/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23906/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23906/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23906", "id": 383278896, "node_id": "MDU6SXNzdWUzODMyNzg4OTY=", "number": 23906, "title": "Copy value of trainable variable to another trainable variable.", "user": {"login": "Firyuza", "id": 5341864, "node_id": "MDQ6VXNlcjUzNDE4NjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/5341864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Firyuza", "html_url": "https://github.com/Firyuza", "followers_url": "https://api.github.com/users/Firyuza/followers", "following_url": "https://api.github.com/users/Firyuza/following{/other_user}", "gists_url": "https://api.github.com/users/Firyuza/gists{/gist_id}", "starred_url": "https://api.github.com/users/Firyuza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Firyuza/subscriptions", "organizations_url": "https://api.github.com/users/Firyuza/orgs", "repos_url": "https://api.github.com/users/Firyuza/repos", "events_url": "https://api.github.com/users/Firyuza/events{/privacy}", "received_events_url": "https://api.github.com/users/Firyuza/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-21T20:18:51Z", "updated_at": "2018-11-22T10:01:02Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a feature request. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>TensorFlow version (you are using): 1.4.1</li>\n<li>Are you willing to contribute it (Yes/No): No.</li>\n</ul>\n<p><strong>Describe the feature and the current behavior/state.</strong><br>\nNow Tensorflow doesn't allow to copy value of trainable variable to another one. Operations like tf.assight, tf.identity, tf.Variable(source_variable.initialized_value()) or tf.contrib.copy_graph.copy_variable_to_graph(var, self.graph) DO NOT copy just value. After such operations the destination variable referes to the source variable and I can't pass this variable to optimizer for computing gradients: \"ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, ... \"<br>\n<strong>Will this change the current api? How?</strong><br>\nThis change won't change the existing functions, just will add new opportunity for trainable variables.<br>\n<strong>Who will benefit with this feature?</strong><br>\nIt will make more flexible structure that can be good for GANs, or when we have two networks and it is neccessary to copy values of one network parameters to second network parameters, and still train two networks independently.<br>\n<strong>Any Other info.</strong></p>", "body_text": "Please make sure that this is a feature request. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template\nSystem information\n\nTensorFlow version (you are using): 1.4.1\nAre you willing to contribute it (Yes/No): No.\n\nDescribe the feature and the current behavior/state.\nNow Tensorflow doesn't allow to copy value of trainable variable to another one. Operations like tf.assight, tf.identity, tf.Variable(source_variable.initialized_value()) or tf.contrib.copy_graph.copy_variable_to_graph(var, self.graph) DO NOT copy just value. After such operations the destination variable referes to the source variable and I can't pass this variable to optimizer for computing gradients: \"ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, ... \"\nWill this change the current api? How?\nThis change won't change the existing functions, just will add new opportunity for trainable variables.\nWho will benefit with this feature?\nIt will make more flexible structure that can be good for GANs, or when we have two networks and it is neccessary to copy values of one network parameters to second network parameters, and still train two networks independently.\nAny Other info.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.4.1\r\n- Are you willing to contribute it (Yes/No): No.\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nNow Tensorflow doesn't allow to copy value of trainable variable to another one. Operations like tf.assight, tf.identity, tf.Variable(source_variable.initialized_value()) or tf.contrib.copy_graph.copy_variable_to_graph(var, self.graph) DO NOT copy just value. After such operations the destination variable referes to the source variable and I can't pass this variable to optimizer for computing gradients: \"ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, ... \"\r\n**Will this change the current api? How?**\r\nThis change won't change the existing functions, just will add new opportunity for trainable variables.\r\n**Who will benefit with this feature?**\r\nIt will make more flexible structure that can be good for GANs, or when we have two networks and it is neccessary to copy values of one network parameters to second network parameters, and still train two networks independently.\r\n**Any Other info.**\r\n"}