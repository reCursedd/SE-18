{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5809", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5809/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5809/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5809/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5809", "id": 191289553, "node_id": "MDU6SXNzdWUxOTEyODk1NTM=", "number": 5809, "title": "multi-GPU training? ", "user": {"login": "astrude", "id": 5844703, "node_id": "MDQ6VXNlcjU4NDQ3MDM=", "avatar_url": "https://avatars1.githubusercontent.com/u/5844703?v=4", "gravatar_id": "", "url": "https://api.github.com/users/astrude", "html_url": "https://github.com/astrude", "followers_url": "https://api.github.com/users/astrude/followers", "following_url": "https://api.github.com/users/astrude/following{/other_user}", "gists_url": "https://api.github.com/users/astrude/gists{/gist_id}", "starred_url": "https://api.github.com/users/astrude/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/astrude/subscriptions", "organizations_url": "https://api.github.com/users/astrude/orgs", "repos_url": "https://api.github.com/users/astrude/repos", "events_url": "https://api.github.com/users/astrude/events{/privacy}", "received_events_url": "https://api.github.com/users/astrude/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-11-23T14:44:46Z", "updated_at": "2016-11-23T16:52:03Z", "closed_at": "2016-11-23T16:52:02Z", "author_association": "NONE", "body_html": "<p>We are trying to scale up one of the detection deep learning architecture written in Tensorflow for multi-GPU training. Here's the <a href=\"https://github.com/Russell91/TensorBox\">link</a> to the architecture.</p>\n<p>We need specific help in understanding the properties of the gradients such as shape, type and more importantly ways to access the same so that it can be built on two GPUs separately and synchronize like in the cifar_multi_gpu training..</p>\n<p>This is the grad step in build function and we would like to access in train function:</p>\n<p>if H['clip_norm'] &lt;= 0:<br>\ngrads = tf.gradients(loss['train'], tvars)<br>\nelse:<br>\ngrads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])</p>\n<p>We have the following functions in the train and build model steps in the overall architecture.</p>\n<p>def build(H, q):<br>\n'''<br>\nBuild full model for training, including forward / backward passes,<br>\noptimizers, and summary statistics.<br>\n'''<br>\narch = H<br>\nsolver = H[\"solver\"]</p>\n<pre><code>os.environ['CUDA_VISIBLE_DEVICES'] = str(solver.get('gpu', ''))\n\n#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\ngpu_options = tf.GPUOptions()\nconfig = tf.ConfigProto(gpu_options=gpu_options)\n\nlearning_rate = tf.placeholder(tf.float32)\nif solver['opt'] == 'RMS':\n    opt = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n                                    decay=0.9, epsilon=solver['epsilon'])\nelif solver['opt'] == 'Adam':\n    opt = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                    epsilon=solver['epsilon'])\nelif solver['opt'] == 'SGD':\n    opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\nelse:\n    raise ValueError('Unrecognized opt type')\nloss, accuracy, confidences_loss, boxes_loss = {}, {}, {}, {}\nfor phase in ['train', 'test']:\n    # generate predictions and losses from forward pass\n    x, confidences, boxes = q[phase].dequeue_many(arch['batch_size'])\n    flags = tf.argmax(confidences, 3)\n\n\n    grid_size = H['grid_width'] * H['grid_height']\n\n    (pred_boxes, pred_confidences,\n     loss[phase], confidences_loss[phase],\n     boxes_loss[phase]) = build_forward_backward(H, x, phase, boxes, flags)\n    pred_confidences_r = tf.reshape(pred_confidences, [H['batch_size'], grid_size, H['rnn_len'], arch['num_classes']])\n    pred_boxes_r = tf.reshape(pred_boxes, [H['batch_size'], grid_size, H['rnn_len'], 4])\n\n\n    # Set up summary operations for tensorboard\n    a = tf.equal(tf.argmax(confidences[:, :, 0, :], 2), tf.argmax(pred_confidences_r[:, :, 0, :], 2))\n    accuracy[phase] = tf.reduce_mean(tf.cast(a, 'float32'), name=phase+'/accuracy')\n\n    if phase == 'train':\n        global_step = tf.Variable(0, trainable=False)\n\n        tvars = tf.trainable_variables()\n        if H['clip_norm'] &lt;= 0:\n            grads = tf.gradients(loss['train'], tvars)\n        else:\n            grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])\n        train_op = opt.apply_gradients(zip(grads, tvars), global_step=global_step)\n    elif phase == 'test':\n        moving_avg = tf.train.ExponentialMovingAverage(0.95)\n        smooth_op = moving_avg.apply([accuracy['train'], accuracy['test'],\n                                      confidences_loss['train'], boxes_loss['train'],\n                                      confidences_loss['test'], boxes_loss['test'],\n                                      ])\n\n        for p in ['train', 'test']:\n            tf.scalar_summary('%s/accuracy' % p, accuracy[p])\n            tf.scalar_summary('%s/accuracy/smooth' % p, moving_avg.average(accuracy[p]))\n            tf.scalar_summary(\"%s/confidences_loss\" % p, confidences_loss[p])\n            tf.scalar_summary(\"%s/confidences_loss/smooth\" % p,\n                moving_avg.average(confidences_loss[p]))\n            tf.scalar_summary(\"%s/regression_loss\" % p, boxes_loss[p])\n            tf.scalar_summary(\"%s/regression_loss/smooth\" % p,\n                moving_avg.average(boxes_loss[p]))\n\n    if phase == 'test':\n        test_image = x\n        # show ground truth to verify labels are correct\n        test_true_confidences = confidences[0, :, :, :]\n        test_true_boxes = boxes[0, :, :, :]\n\n        # show predictions to visualize training progress\n        test_pred_confidences = pred_confidences_r[0, :, :, :]\n        test_pred_boxes = pred_boxes_r[0, :, :, :]\n\n        def log_image(np_img, np_confidences, np_boxes, np_global_step, pred_or_true):\n            \n            merged = train_utils.add_rectangles(H, np_img, np_confidences, np_boxes,\n                                                use_stitching=True,\n                                                rnn_len=H['rnn_len'])[0]\n            \n            num_images = 10\n            img_path = os.path.join(H['save_dir'], '%s_%s.jpg' % ((np_global_step / H['logging']['display_iter']) % num_images, pred_or_true))\n            misc.imsave(img_path, merged)\n            return merged\n\n        pred_log_img = tf.py_func(log_image,\n                                  [test_image, test_pred_confidences, test_pred_boxes, global_step, 'pred'],\n                                  [tf.float32])\n        true_log_img = tf.py_func(log_image,\n                                  [test_image, test_true_confidences, test_true_boxes, global_step, 'true'],\n                                  [tf.float32])\n        tf.image_summary(phase + '/pred_boxes', tf.pack(pred_log_img),max_images=10)\n        tf.image_summary(phase + '/true_boxes', tf.pack(true_log_img),max_images=10)\n\nsummary_op = tf.merge_all_summaries()\n\nreturn (config, loss, accuracy, summary_op, train_op,\n        smooth_op, global_step, learning_rate)\n</code></pre>\n<p>def train(H, test_images):<br>\n'''<br>\nSetup computation graph, run 2 prefetch data threads, and then run the main loop<br>\n'''</p>\n<pre><code>if not os.path.exists(H['save_dir']): os.makedirs(H['save_dir'])\n\nckpt_file = H['save_dir'] + '/save.ckpt'\nwith open(H['save_dir'] + '/hypes.json', 'w') as f:\n    json.dump(H, f, indent=4)\n\nx_in = tf.placeholder(tf.float32)\nconfs_in = tf.placeholder(tf.float32)\nboxes_in = tf.placeholder(tf.float32)\nq = {}\nenqueue_op = {}\nfor phase in ['train', 'test']:\n    dtypes = [tf.float32, tf.float32, tf.float32]\n    grid_size = H['grid_width'] * H['grid_height']\n    shapes = (\n        [H['image_height'], H['image_width'], 3],\n        [grid_size, H['rnn_len'], H['num_classes']],\n        [grid_size, H['rnn_len'], 4],\n        )\n    q[phase] = tf.FIFOQueue(capacity=30, dtypes=dtypes, shapes=shapes)\n    enqueue_op[phase] = q[phase].enqueue((x_in, confs_in, boxes_in))\n\ndef make_feed(d):\n    return {x_in: d['image'], confs_in: d['confs'], boxes_in: d['boxes'],\n            learning_rate: H['solver']['learning_rate']}\n\ndef thread_loop(sess, enqueue_op, phase, gen):\n    for d in gen:\n        sess.run(enqueue_op[phase], feed_dict=make_feed(d))\n\n(config, loss, accuracy, summary_op, train_op,\n smooth_op, global_step, learning_rate) = build(H, q)\n\nsaver = tf.train.Saver(max_to_keep=None)\nwriter = tf.train.SummaryWriter(\n    logdir=H['save_dir'],\n    flush_secs=10\n)\n\nwith tf.Session(config=config) as sess:\n    tf.train.start_queue_runners(sess=sess)\n    for phase in ['train', 'test']:\n        # enqueue once manually to avoid thread start delay\n        gen = train_utils.load_data_gen(H, phase, jitter=H['solver']['use_jitter'])\n        d = gen.next()\n        sess.run(enqueue_op[phase], feed_dict=make_feed(d))\n        t = tf.train.threading.Thread(target=thread_loop,\n                             args=(sess, enqueue_op, phase, gen))\n        t.daemon = True\n        t.start()\n\n    tf.set_random_seed(H['solver']['rnd_seed'])\n    sess.run(tf.initialize_all_variables())\n    writer.add_graph(sess.graph)\n    weights_str = H['solver']['weights']\n    if len(weights_str) &gt; 0:\n        print('Restoring from: %s' % weights_str)\n        saver.restore(sess, weights_str)\n    else:\n        init_fn = slim.assign_from_checkpoint_fn(\n              '%s/data/inception_v1.ckpt' % os.path.dirname(os.path.realpath(__file__)),\n              [x for x in tf.all_variables() if x.name.startswith('InceptionV1') and not H['solver']['opt'] in x.name])\n        init_fn(sess)\n\n    # train model for N iterations\n    start = time.time()\n    max_iter = H['solver'].get('max_iter', 10000000)\n    for i in xrange(max_iter):\n        display_iter = H['logging']['display_iter']\n        adjusted_lr = (H['solver']['learning_rate'] *\n                       0.5 ** max(0, (i / H['solver']['learning_rate_step']) - 2))\n        lr_feed = {learning_rate: adjusted_lr}\n\n        if i % display_iter != 0:\n            # train network\n            batch_loss_train, _ = sess.run([loss['train'], train_op], feed_dict=lr_feed)\n        else:\n            # test network every N iterations; log additional info\n            if i &gt; 0:\n                dt = (time.time() - start) / (H['batch_size'] * display_iter)\n            start = time.time()\n            (train_loss, test_accuracy, summary_str,\n                _, _) = sess.run([loss['train'], accuracy['test'],\n                                  summary_op, train_op, smooth_op,\n                                 ], feed_dict=lr_feed)\n            writer.add_summary(summary_str, global_step=global_step.eval())\n            print_str = string.join([\n                'Step: %d',\n                'lr: %f',\n                'Train Loss: %.2f',\n                'Softmax Test Accuracy: %.1f%%',\n                'Time/image (ms): %.1f'\n            ], ', ')\n            print(print_str %\n                  (i, adjusted_lr, train_loss,\n                   test_accuracy * 100, dt * 1000 if i &gt; 0 else 0))\n\n        if global_step.eval() % H['logging']['save_iter'] == 0 or global_step.eval() == max_iter - 1:\n            saver.save(sess, ckpt_file, global_step=global_step)\n</code></pre>\n<p>Thanks in advance!</p>", "body_text": "We are trying to scale up one of the detection deep learning architecture written in Tensorflow for multi-GPU training. Here's the link to the architecture.\nWe need specific help in understanding the properties of the gradients such as shape, type and more importantly ways to access the same so that it can be built on two GPUs separately and synchronize like in the cifar_multi_gpu training..\nThis is the grad step in build function and we would like to access in train function:\nif H['clip_norm'] <= 0:\ngrads = tf.gradients(loss['train'], tvars)\nelse:\ngrads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])\nWe have the following functions in the train and build model steps in the overall architecture.\ndef build(H, q):\n'''\nBuild full model for training, including forward / backward passes,\noptimizers, and summary statistics.\n'''\narch = H\nsolver = H[\"solver\"]\nos.environ['CUDA_VISIBLE_DEVICES'] = str(solver.get('gpu', ''))\n\n#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\ngpu_options = tf.GPUOptions()\nconfig = tf.ConfigProto(gpu_options=gpu_options)\n\nlearning_rate = tf.placeholder(tf.float32)\nif solver['opt'] == 'RMS':\n    opt = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n                                    decay=0.9, epsilon=solver['epsilon'])\nelif solver['opt'] == 'Adam':\n    opt = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                    epsilon=solver['epsilon'])\nelif solver['opt'] == 'SGD':\n    opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\nelse:\n    raise ValueError('Unrecognized opt type')\nloss, accuracy, confidences_loss, boxes_loss = {}, {}, {}, {}\nfor phase in ['train', 'test']:\n    # generate predictions and losses from forward pass\n    x, confidences, boxes = q[phase].dequeue_many(arch['batch_size'])\n    flags = tf.argmax(confidences, 3)\n\n\n    grid_size = H['grid_width'] * H['grid_height']\n\n    (pred_boxes, pred_confidences,\n     loss[phase], confidences_loss[phase],\n     boxes_loss[phase]) = build_forward_backward(H, x, phase, boxes, flags)\n    pred_confidences_r = tf.reshape(pred_confidences, [H['batch_size'], grid_size, H['rnn_len'], arch['num_classes']])\n    pred_boxes_r = tf.reshape(pred_boxes, [H['batch_size'], grid_size, H['rnn_len'], 4])\n\n\n    # Set up summary operations for tensorboard\n    a = tf.equal(tf.argmax(confidences[:, :, 0, :], 2), tf.argmax(pred_confidences_r[:, :, 0, :], 2))\n    accuracy[phase] = tf.reduce_mean(tf.cast(a, 'float32'), name=phase+'/accuracy')\n\n    if phase == 'train':\n        global_step = tf.Variable(0, trainable=False)\n\n        tvars = tf.trainable_variables()\n        if H['clip_norm'] <= 0:\n            grads = tf.gradients(loss['train'], tvars)\n        else:\n            grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])\n        train_op = opt.apply_gradients(zip(grads, tvars), global_step=global_step)\n    elif phase == 'test':\n        moving_avg = tf.train.ExponentialMovingAverage(0.95)\n        smooth_op = moving_avg.apply([accuracy['train'], accuracy['test'],\n                                      confidences_loss['train'], boxes_loss['train'],\n                                      confidences_loss['test'], boxes_loss['test'],\n                                      ])\n\n        for p in ['train', 'test']:\n            tf.scalar_summary('%s/accuracy' % p, accuracy[p])\n            tf.scalar_summary('%s/accuracy/smooth' % p, moving_avg.average(accuracy[p]))\n            tf.scalar_summary(\"%s/confidences_loss\" % p, confidences_loss[p])\n            tf.scalar_summary(\"%s/confidences_loss/smooth\" % p,\n                moving_avg.average(confidences_loss[p]))\n            tf.scalar_summary(\"%s/regression_loss\" % p, boxes_loss[p])\n            tf.scalar_summary(\"%s/regression_loss/smooth\" % p,\n                moving_avg.average(boxes_loss[p]))\n\n    if phase == 'test':\n        test_image = x\n        # show ground truth to verify labels are correct\n        test_true_confidences = confidences[0, :, :, :]\n        test_true_boxes = boxes[0, :, :, :]\n\n        # show predictions to visualize training progress\n        test_pred_confidences = pred_confidences_r[0, :, :, :]\n        test_pred_boxes = pred_boxes_r[0, :, :, :]\n\n        def log_image(np_img, np_confidences, np_boxes, np_global_step, pred_or_true):\n            \n            merged = train_utils.add_rectangles(H, np_img, np_confidences, np_boxes,\n                                                use_stitching=True,\n                                                rnn_len=H['rnn_len'])[0]\n            \n            num_images = 10\n            img_path = os.path.join(H['save_dir'], '%s_%s.jpg' % ((np_global_step / H['logging']['display_iter']) % num_images, pred_or_true))\n            misc.imsave(img_path, merged)\n            return merged\n\n        pred_log_img = tf.py_func(log_image,\n                                  [test_image, test_pred_confidences, test_pred_boxes, global_step, 'pred'],\n                                  [tf.float32])\n        true_log_img = tf.py_func(log_image,\n                                  [test_image, test_true_confidences, test_true_boxes, global_step, 'true'],\n                                  [tf.float32])\n        tf.image_summary(phase + '/pred_boxes', tf.pack(pred_log_img),max_images=10)\n        tf.image_summary(phase + '/true_boxes', tf.pack(true_log_img),max_images=10)\n\nsummary_op = tf.merge_all_summaries()\n\nreturn (config, loss, accuracy, summary_op, train_op,\n        smooth_op, global_step, learning_rate)\n\ndef train(H, test_images):\n'''\nSetup computation graph, run 2 prefetch data threads, and then run the main loop\n'''\nif not os.path.exists(H['save_dir']): os.makedirs(H['save_dir'])\n\nckpt_file = H['save_dir'] + '/save.ckpt'\nwith open(H['save_dir'] + '/hypes.json', 'w') as f:\n    json.dump(H, f, indent=4)\n\nx_in = tf.placeholder(tf.float32)\nconfs_in = tf.placeholder(tf.float32)\nboxes_in = tf.placeholder(tf.float32)\nq = {}\nenqueue_op = {}\nfor phase in ['train', 'test']:\n    dtypes = [tf.float32, tf.float32, tf.float32]\n    grid_size = H['grid_width'] * H['grid_height']\n    shapes = (\n        [H['image_height'], H['image_width'], 3],\n        [grid_size, H['rnn_len'], H['num_classes']],\n        [grid_size, H['rnn_len'], 4],\n        )\n    q[phase] = tf.FIFOQueue(capacity=30, dtypes=dtypes, shapes=shapes)\n    enqueue_op[phase] = q[phase].enqueue((x_in, confs_in, boxes_in))\n\ndef make_feed(d):\n    return {x_in: d['image'], confs_in: d['confs'], boxes_in: d['boxes'],\n            learning_rate: H['solver']['learning_rate']}\n\ndef thread_loop(sess, enqueue_op, phase, gen):\n    for d in gen:\n        sess.run(enqueue_op[phase], feed_dict=make_feed(d))\n\n(config, loss, accuracy, summary_op, train_op,\n smooth_op, global_step, learning_rate) = build(H, q)\n\nsaver = tf.train.Saver(max_to_keep=None)\nwriter = tf.train.SummaryWriter(\n    logdir=H['save_dir'],\n    flush_secs=10\n)\n\nwith tf.Session(config=config) as sess:\n    tf.train.start_queue_runners(sess=sess)\n    for phase in ['train', 'test']:\n        # enqueue once manually to avoid thread start delay\n        gen = train_utils.load_data_gen(H, phase, jitter=H['solver']['use_jitter'])\n        d = gen.next()\n        sess.run(enqueue_op[phase], feed_dict=make_feed(d))\n        t = tf.train.threading.Thread(target=thread_loop,\n                             args=(sess, enqueue_op, phase, gen))\n        t.daemon = True\n        t.start()\n\n    tf.set_random_seed(H['solver']['rnd_seed'])\n    sess.run(tf.initialize_all_variables())\n    writer.add_graph(sess.graph)\n    weights_str = H['solver']['weights']\n    if len(weights_str) > 0:\n        print('Restoring from: %s' % weights_str)\n        saver.restore(sess, weights_str)\n    else:\n        init_fn = slim.assign_from_checkpoint_fn(\n              '%s/data/inception_v1.ckpt' % os.path.dirname(os.path.realpath(__file__)),\n              [x for x in tf.all_variables() if x.name.startswith('InceptionV1') and not H['solver']['opt'] in x.name])\n        init_fn(sess)\n\n    # train model for N iterations\n    start = time.time()\n    max_iter = H['solver'].get('max_iter', 10000000)\n    for i in xrange(max_iter):\n        display_iter = H['logging']['display_iter']\n        adjusted_lr = (H['solver']['learning_rate'] *\n                       0.5 ** max(0, (i / H['solver']['learning_rate_step']) - 2))\n        lr_feed = {learning_rate: adjusted_lr}\n\n        if i % display_iter != 0:\n            # train network\n            batch_loss_train, _ = sess.run([loss['train'], train_op], feed_dict=lr_feed)\n        else:\n            # test network every N iterations; log additional info\n            if i > 0:\n                dt = (time.time() - start) / (H['batch_size'] * display_iter)\n            start = time.time()\n            (train_loss, test_accuracy, summary_str,\n                _, _) = sess.run([loss['train'], accuracy['test'],\n                                  summary_op, train_op, smooth_op,\n                                 ], feed_dict=lr_feed)\n            writer.add_summary(summary_str, global_step=global_step.eval())\n            print_str = string.join([\n                'Step: %d',\n                'lr: %f',\n                'Train Loss: %.2f',\n                'Softmax Test Accuracy: %.1f%%',\n                'Time/image (ms): %.1f'\n            ], ', ')\n            print(print_str %\n                  (i, adjusted_lr, train_loss,\n                   test_accuracy * 100, dt * 1000 if i > 0 else 0))\n\n        if global_step.eval() % H['logging']['save_iter'] == 0 or global_step.eval() == max_iter - 1:\n            saver.save(sess, ckpt_file, global_step=global_step)\n\nThanks in advance!", "body": "We are trying to scale up one of the detection deep learning architecture written in Tensorflow for multi-GPU training. Here's the [link](https://github.com/Russell91/TensorBox) to the architecture.\r\n\r\nWe need specific help in understanding the properties of the gradients such as shape, type and more importantly ways to access the same so that it can be built on two GPUs separately and synchronize like in the cifar_multi_gpu training.. \r\n\r\nThis is the grad step in build function and we would like to access in train function:\r\n\r\nif H['clip_norm'] <= 0:\r\n                grads = tf.gradients(loss['train'], tvars)\r\n            else:\r\n                grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])\r\n\r\n\r\nWe have the following functions in the train and build model steps in the overall architecture.\r\n\r\ndef build(H, q):\r\n    '''\r\n    Build full model for training, including forward / backward passes,\r\n    optimizers, and summary statistics.\r\n    '''\r\n    arch = H\r\n    solver = H[\"solver\"]\r\n\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = str(solver.get('gpu', ''))\r\n\r\n    #gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\r\n    gpu_options = tf.GPUOptions()\r\n    config = tf.ConfigProto(gpu_options=gpu_options)\r\n\r\n    learning_rate = tf.placeholder(tf.float32)\r\n    if solver['opt'] == 'RMS':\r\n        opt = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\r\n                                        decay=0.9, epsilon=solver['epsilon'])\r\n    elif solver['opt'] == 'Adam':\r\n        opt = tf.train.AdamOptimizer(learning_rate=learning_rate,\r\n                                        epsilon=solver['epsilon'])\r\n    elif solver['opt'] == 'SGD':\r\n        opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\r\n    else:\r\n        raise ValueError('Unrecognized opt type')\r\n    loss, accuracy, confidences_loss, boxes_loss = {}, {}, {}, {}\r\n    for phase in ['train', 'test']:\r\n        # generate predictions and losses from forward pass\r\n        x, confidences, boxes = q[phase].dequeue_many(arch['batch_size'])\r\n        flags = tf.argmax(confidences, 3)\r\n\r\n\r\n        grid_size = H['grid_width'] * H['grid_height']\r\n\r\n        (pred_boxes, pred_confidences,\r\n         loss[phase], confidences_loss[phase],\r\n         boxes_loss[phase]) = build_forward_backward(H, x, phase, boxes, flags)\r\n        pred_confidences_r = tf.reshape(pred_confidences, [H['batch_size'], grid_size, H['rnn_len'], arch['num_classes']])\r\n        pred_boxes_r = tf.reshape(pred_boxes, [H['batch_size'], grid_size, H['rnn_len'], 4])\r\n\r\n\r\n        # Set up summary operations for tensorboard\r\n        a = tf.equal(tf.argmax(confidences[:, :, 0, :], 2), tf.argmax(pred_confidences_r[:, :, 0, :], 2))\r\n        accuracy[phase] = tf.reduce_mean(tf.cast(a, 'float32'), name=phase+'/accuracy')\r\n\r\n        if phase == 'train':\r\n            global_step = tf.Variable(0, trainable=False)\r\n\r\n            tvars = tf.trainable_variables()\r\n            if H['clip_norm'] <= 0:\r\n                grads = tf.gradients(loss['train'], tvars)\r\n            else:\r\n                grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])\r\n            train_op = opt.apply_gradients(zip(grads, tvars), global_step=global_step)\r\n        elif phase == 'test':\r\n            moving_avg = tf.train.ExponentialMovingAverage(0.95)\r\n            smooth_op = moving_avg.apply([accuracy['train'], accuracy['test'],\r\n                                          confidences_loss['train'], boxes_loss['train'],\r\n                                          confidences_loss['test'], boxes_loss['test'],\r\n                                          ])\r\n\r\n            for p in ['train', 'test']:\r\n                tf.scalar_summary('%s/accuracy' % p, accuracy[p])\r\n                tf.scalar_summary('%s/accuracy/smooth' % p, moving_avg.average(accuracy[p]))\r\n                tf.scalar_summary(\"%s/confidences_loss\" % p, confidences_loss[p])\r\n                tf.scalar_summary(\"%s/confidences_loss/smooth\" % p,\r\n                    moving_avg.average(confidences_loss[p]))\r\n                tf.scalar_summary(\"%s/regression_loss\" % p, boxes_loss[p])\r\n                tf.scalar_summary(\"%s/regression_loss/smooth\" % p,\r\n                    moving_avg.average(boxes_loss[p]))\r\n\r\n        if phase == 'test':\r\n            test_image = x\r\n            # show ground truth to verify labels are correct\r\n            test_true_confidences = confidences[0, :, :, :]\r\n            test_true_boxes = boxes[0, :, :, :]\r\n\r\n            # show predictions to visualize training progress\r\n            test_pred_confidences = pred_confidences_r[0, :, :, :]\r\n            test_pred_boxes = pred_boxes_r[0, :, :, :]\r\n\r\n            def log_image(np_img, np_confidences, np_boxes, np_global_step, pred_or_true):\r\n                \r\n                merged = train_utils.add_rectangles(H, np_img, np_confidences, np_boxes,\r\n                                                    use_stitching=True,\r\n                                                    rnn_len=H['rnn_len'])[0]\r\n                \r\n                num_images = 10\r\n                img_path = os.path.join(H['save_dir'], '%s_%s.jpg' % ((np_global_step / H['logging']['display_iter']) % num_images, pred_or_true))\r\n                misc.imsave(img_path, merged)\r\n                return merged\r\n\r\n            pred_log_img = tf.py_func(log_image,\r\n                                      [test_image, test_pred_confidences, test_pred_boxes, global_step, 'pred'],\r\n                                      [tf.float32])\r\n            true_log_img = tf.py_func(log_image,\r\n                                      [test_image, test_true_confidences, test_true_boxes, global_step, 'true'],\r\n                                      [tf.float32])\r\n            tf.image_summary(phase + '/pred_boxes', tf.pack(pred_log_img),max_images=10)\r\n            tf.image_summary(phase + '/true_boxes', tf.pack(true_log_img),max_images=10)\r\n\r\n    summary_op = tf.merge_all_summaries()\r\n\r\n    return (config, loss, accuracy, summary_op, train_op,\r\n            smooth_op, global_step, learning_rate)\r\n\r\n\r\ndef train(H, test_images):\r\n    '''\r\n    Setup computation graph, run 2 prefetch data threads, and then run the main loop\r\n    '''\r\n\r\n    if not os.path.exists(H['save_dir']): os.makedirs(H['save_dir'])\r\n\r\n    ckpt_file = H['save_dir'] + '/save.ckpt'\r\n    with open(H['save_dir'] + '/hypes.json', 'w') as f:\r\n        json.dump(H, f, indent=4)\r\n\r\n    x_in = tf.placeholder(tf.float32)\r\n    confs_in = tf.placeholder(tf.float32)\r\n    boxes_in = tf.placeholder(tf.float32)\r\n    q = {}\r\n    enqueue_op = {}\r\n    for phase in ['train', 'test']:\r\n        dtypes = [tf.float32, tf.float32, tf.float32]\r\n        grid_size = H['grid_width'] * H['grid_height']\r\n        shapes = (\r\n            [H['image_height'], H['image_width'], 3],\r\n            [grid_size, H['rnn_len'], H['num_classes']],\r\n            [grid_size, H['rnn_len'], 4],\r\n            )\r\n        q[phase] = tf.FIFOQueue(capacity=30, dtypes=dtypes, shapes=shapes)\r\n        enqueue_op[phase] = q[phase].enqueue((x_in, confs_in, boxes_in))\r\n\r\n    def make_feed(d):\r\n        return {x_in: d['image'], confs_in: d['confs'], boxes_in: d['boxes'],\r\n                learning_rate: H['solver']['learning_rate']}\r\n\r\n    def thread_loop(sess, enqueue_op, phase, gen):\r\n        for d in gen:\r\n            sess.run(enqueue_op[phase], feed_dict=make_feed(d))\r\n\r\n    (config, loss, accuracy, summary_op, train_op,\r\n     smooth_op, global_step, learning_rate) = build(H, q)\r\n\r\n    saver = tf.train.Saver(max_to_keep=None)\r\n    writer = tf.train.SummaryWriter(\r\n        logdir=H['save_dir'],\r\n        flush_secs=10\r\n    )\r\n\r\n    with tf.Session(config=config) as sess:\r\n        tf.train.start_queue_runners(sess=sess)\r\n        for phase in ['train', 'test']:\r\n            # enqueue once manually to avoid thread start delay\r\n            gen = train_utils.load_data_gen(H, phase, jitter=H['solver']['use_jitter'])\r\n            d = gen.next()\r\n            sess.run(enqueue_op[phase], feed_dict=make_feed(d))\r\n            t = tf.train.threading.Thread(target=thread_loop,\r\n                                 args=(sess, enqueue_op, phase, gen))\r\n            t.daemon = True\r\n            t.start()\r\n\r\n        tf.set_random_seed(H['solver']['rnd_seed'])\r\n        sess.run(tf.initialize_all_variables())\r\n        writer.add_graph(sess.graph)\r\n        weights_str = H['solver']['weights']\r\n        if len(weights_str) > 0:\r\n            print('Restoring from: %s' % weights_str)\r\n            saver.restore(sess, weights_str)\r\n        else:\r\n            init_fn = slim.assign_from_checkpoint_fn(\r\n                  '%s/data/inception_v1.ckpt' % os.path.dirname(os.path.realpath(__file__)),\r\n                  [x for x in tf.all_variables() if x.name.startswith('InceptionV1') and not H['solver']['opt'] in x.name])\r\n            init_fn(sess)\r\n\r\n        # train model for N iterations\r\n        start = time.time()\r\n        max_iter = H['solver'].get('max_iter', 10000000)\r\n        for i in xrange(max_iter):\r\n            display_iter = H['logging']['display_iter']\r\n            adjusted_lr = (H['solver']['learning_rate'] *\r\n                           0.5 ** max(0, (i / H['solver']['learning_rate_step']) - 2))\r\n            lr_feed = {learning_rate: adjusted_lr}\r\n\r\n            if i % display_iter != 0:\r\n                # train network\r\n                batch_loss_train, _ = sess.run([loss['train'], train_op], feed_dict=lr_feed)\r\n            else:\r\n                # test network every N iterations; log additional info\r\n                if i > 0:\r\n                    dt = (time.time() - start) / (H['batch_size'] * display_iter)\r\n                start = time.time()\r\n                (train_loss, test_accuracy, summary_str,\r\n                    _, _) = sess.run([loss['train'], accuracy['test'],\r\n                                      summary_op, train_op, smooth_op,\r\n                                     ], feed_dict=lr_feed)\r\n                writer.add_summary(summary_str, global_step=global_step.eval())\r\n                print_str = string.join([\r\n                    'Step: %d',\r\n                    'lr: %f',\r\n                    'Train Loss: %.2f',\r\n                    'Softmax Test Accuracy: %.1f%%',\r\n                    'Time/image (ms): %.1f'\r\n                ], ', ')\r\n                print(print_str %\r\n                      (i, adjusted_lr, train_loss,\r\n                       test_accuracy * 100, dt * 1000 if i > 0 else 0))\r\n\r\n            if global_step.eval() % H['logging']['save_iter'] == 0 or global_step.eval() == max_iter - 1:\r\n                saver.save(sess, ckpt_file, global_step=global_step)\r\n\r\nThanks in advance!\r\n\r\n"}