{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/361464802", "html_url": "https://github.com/tensorflow/tensorflow/issues/16496#issuecomment-361464802", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16496", "id": 361464802, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTQ2NDgwMg==", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-30T03:22:21Z", "updated_at": "2018-01-30T03:22:21Z", "author_association": "MEMBER", "body_html": "<p>I think it's an interesting idea. In general, this could be useful if there are special patterns in the data, for instance, if words IDs are sorted by order of frequency, the first bit predictions would share that.</p>\n<p>Usually, though, it's better to make a global prediction (all bits at the same time) rather than individual decisions. The space is quite hard to describe. Let's say you have words like this:</p>\n<pre><code>ID; word\n00; small\n01; big\n10; medium\n11; tiny\n</code></pre>\n<p>Further supposing that the cost of mispredicting is according to size, e.g. big vs tiny is worse than small vs tiny. Then, when predicting bit <code>1</code>, then it really depends what bit <code>0</code> was set to.</p>\n<p>In any case, feel free to think more about the topic and maybe find some interesting application for this. I'm going to close this for admin purposes but feel free to re-open.</p>", "body_text": "I think it's an interesting idea. In general, this could be useful if there are special patterns in the data, for instance, if words IDs are sorted by order of frequency, the first bit predictions would share that.\nUsually, though, it's better to make a global prediction (all bits at the same time) rather than individual decisions. The space is quite hard to describe. Let's say you have words like this:\nID; word\n00; small\n01; big\n10; medium\n11; tiny\n\nFurther supposing that the cost of mispredicting is according to size, e.g. big vs tiny is worse than small vs tiny. Then, when predicting bit 1, then it really depends what bit 0 was set to.\nIn any case, feel free to think more about the topic and maybe find some interesting application for this. I'm going to close this for admin purposes but feel free to re-open.", "body": "I think it's an interesting idea. In general, this could be useful if there are special patterns in the data, for instance, if words IDs are sorted by order of frequency, the first bit predictions would share that.\r\n\r\nUsually, though, it's better to make a global prediction (all bits at the same time) rather than individual decisions. The space is quite hard to describe. Let's say you have words like this:\r\n```\r\nID; word\r\n00; small\r\n01; big\r\n10; medium\r\n11; tiny\r\n```\r\n\r\nFurther supposing that the cost of mispredicting is according to size, e.g. big vs tiny is worse than small vs tiny. Then, when predicting bit `1`, then it really depends what bit `0` was set to.\r\n\r\nIn any case, feel free to think more about the topic and maybe find some interesting application for this. I'm going to close this for admin purposes but feel free to re-open."}