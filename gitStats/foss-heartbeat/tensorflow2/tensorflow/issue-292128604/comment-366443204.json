{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/366443204", "html_url": "https://github.com/tensorflow/tensorflow/issues/16496#issuecomment-366443204", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16496", "id": 366443204, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjQ0MzIwNA==", "user": {"login": "Hvass-Labs", "id": 13588114, "node_id": "MDQ6VXNlcjEzNTg4MTE0", "avatar_url": "https://avatars2.githubusercontent.com/u/13588114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hvass-Labs", "html_url": "https://github.com/Hvass-Labs", "followers_url": "https://api.github.com/users/Hvass-Labs/followers", "following_url": "https://api.github.com/users/Hvass-Labs/following{/other_user}", "gists_url": "https://api.github.com/users/Hvass-Labs/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hvass-Labs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hvass-Labs/subscriptions", "organizations_url": "https://api.github.com/users/Hvass-Labs/orgs", "repos_url": "https://api.github.com/users/Hvass-Labs/repos", "events_url": "https://api.github.com/users/Hvass-Labs/events{/privacy}", "received_events_url": "https://api.github.com/users/Hvass-Labs/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-17T13:58:41Z", "updated_at": "2018-02-17T13:58:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have done a tiny bit of experimentation with this in the context of Machine Translation of human language. When it is possible to use a so-called embedding layer then that is far superior to these \"float-bits\" because the embedding layer also learns semantic similarities between words in a language.</p>\n<p>Regarding the use of \"float-bits\" instead of one-hot encoded arrays, my small experiments suggest that one-hot encoding is also much better than \"float-bits\". My guess is that it is because one-hot encoding is far more forgiving to the imprecise mappings performed by a neural network, while \"float-bits\" pack a lot more information in a very small number of floating-point values, so it is much more sensitive to tiny variations in the output of a neural network.</p>\n<p>Nevertheless, perhaps someone in the future will stumble upon this thread and find the idea useful for something completely different. In that case I have added a bit more code below.</p>\n<p>This function allows you to set the number of bits used in the \"float-bit\" encoding.</p>\n<pre><code>def int_to_floatbits(value, num_bits):\n    \"\"\"\n    Convert a single integer value to an array of 0.0 and 1.0 floats\n    corresponding to the bit-string. The length is given by num_bits.\n\n    Example: value==123 gives [0.  ... 0.  1.  1.  1.  1.  0.  1.  1.]\n    \"\"\"\n\n    # Formatting-string used to convert integer to binary-string.\n    # For example, \"016b\" for num_bits==16\n    format_str = \"0{}b\".format(num_bits)\n\n    bitstr = format(value, format_str)\n    floatbits = [1 if bit == '1' else 0 for bit in bitstr]\n    floatbits = np.array(floatbits)\n\n    return floatbits\n</code></pre>\n<p>The next function is a more efficient implementation when converting huge arrays of integers to \"float-bits\". Note that for memory-efficiency we use <code>np.uint8</code> to store these 0 and 1's instead of floating-points (the name \"float-bits\" is perhaps a bit misleading now). This is because I used this with huge data-sets so it saved many GB of memory using <code>uint8</code> instead of <code>float32</code>, and <code>uint8</code> can automatically be type-cast by Keras / TensorFlow when input to a neural network.</p>\n<pre><code>def ints_to_floatbits(values, num_bits):\n    \"\"\"\n    Convert a 2-dim array of integer values to a 3-dim array of 0.0 and 1.0\n    floats corresponding to the bit-strings. The length of each encoding\n    is given by num_bits.\n    \"\"\"\n\n    # Formatting-string used to convert integer to binary-string.\n    # For example, \"016b\" for num_bits==16\n    format_str = \"0{}b\".format(num_bits)\n\n    # Shape of output array.\n    shape = values.shape + (num_bits,)\n\n    # Pre-allocate output array for efficiency.\n    # This can be several GB!\n    floatbits = np.zeros(shape, dtype=np.uint8)\n\n    # Process all input values.\n    for i, row in enumerate(values):\n        for j, value in enumerate(row):\n            bitstr = format(value, format_str)\n            floatbits[i, j] = [1 if bit == '1' else 0 for bit in bitstr]\n\n            # The above is much faster than the following, even\n            # though we avoid the creation of the bit-string.\n            # floatbits[i, j] = [(value &gt;&gt; k) &amp; 1 for k in reversed(range(num_bits))]\n        \n    return floatbits\n</code></pre>", "body_text": "I have done a tiny bit of experimentation with this in the context of Machine Translation of human language. When it is possible to use a so-called embedding layer then that is far superior to these \"float-bits\" because the embedding layer also learns semantic similarities between words in a language.\nRegarding the use of \"float-bits\" instead of one-hot encoded arrays, my small experiments suggest that one-hot encoding is also much better than \"float-bits\". My guess is that it is because one-hot encoding is far more forgiving to the imprecise mappings performed by a neural network, while \"float-bits\" pack a lot more information in a very small number of floating-point values, so it is much more sensitive to tiny variations in the output of a neural network.\nNevertheless, perhaps someone in the future will stumble upon this thread and find the idea useful for something completely different. In that case I have added a bit more code below.\nThis function allows you to set the number of bits used in the \"float-bit\" encoding.\ndef int_to_floatbits(value, num_bits):\n    \"\"\"\n    Convert a single integer value to an array of 0.0 and 1.0 floats\n    corresponding to the bit-string. The length is given by num_bits.\n\n    Example: value==123 gives [0.  ... 0.  1.  1.  1.  1.  0.  1.  1.]\n    \"\"\"\n\n    # Formatting-string used to convert integer to binary-string.\n    # For example, \"016b\" for num_bits==16\n    format_str = \"0{}b\".format(num_bits)\n\n    bitstr = format(value, format_str)\n    floatbits = [1 if bit == '1' else 0 for bit in bitstr]\n    floatbits = np.array(floatbits)\n\n    return floatbits\n\nThe next function is a more efficient implementation when converting huge arrays of integers to \"float-bits\". Note that for memory-efficiency we use np.uint8 to store these 0 and 1's instead of floating-points (the name \"float-bits\" is perhaps a bit misleading now). This is because I used this with huge data-sets so it saved many GB of memory using uint8 instead of float32, and uint8 can automatically be type-cast by Keras / TensorFlow when input to a neural network.\ndef ints_to_floatbits(values, num_bits):\n    \"\"\"\n    Convert a 2-dim array of integer values to a 3-dim array of 0.0 and 1.0\n    floats corresponding to the bit-strings. The length of each encoding\n    is given by num_bits.\n    \"\"\"\n\n    # Formatting-string used to convert integer to binary-string.\n    # For example, \"016b\" for num_bits==16\n    format_str = \"0{}b\".format(num_bits)\n\n    # Shape of output array.\n    shape = values.shape + (num_bits,)\n\n    # Pre-allocate output array for efficiency.\n    # This can be several GB!\n    floatbits = np.zeros(shape, dtype=np.uint8)\n\n    # Process all input values.\n    for i, row in enumerate(values):\n        for j, value in enumerate(row):\n            bitstr = format(value, format_str)\n            floatbits[i, j] = [1 if bit == '1' else 0 for bit in bitstr]\n\n            # The above is much faster than the following, even\n            # though we avoid the creation of the bit-string.\n            # floatbits[i, j] = [(value >> k) & 1 for k in reversed(range(num_bits))]\n        \n    return floatbits", "body": "I have done a tiny bit of experimentation with this in the context of Machine Translation of human language. When it is possible to use a so-called embedding layer then that is far superior to these \"float-bits\" because the embedding layer also learns semantic similarities between words in a language.\r\n\r\nRegarding the use of \"float-bits\" instead of one-hot encoded arrays, my small experiments suggest that one-hot encoding is also much better than \"float-bits\". My guess is that it is because one-hot encoding is far more forgiving to the imprecise mappings performed by a neural network, while \"float-bits\" pack a lot more information in a very small number of floating-point values, so it is much more sensitive to tiny variations in the output of a neural network.\r\n\r\nNevertheless, perhaps someone in the future will stumble upon this thread and find the idea useful for something completely different. In that case I have added a bit more code below.\r\n\r\nThis function allows you to set the number of bits used in the \"float-bit\" encoding.\r\n\r\n    def int_to_floatbits(value, num_bits):\r\n        \"\"\"\r\n        Convert a single integer value to an array of 0.0 and 1.0 floats\r\n        corresponding to the bit-string. The length is given by num_bits.\r\n\r\n        Example: value==123 gives [0.  ... 0.  1.  1.  1.  1.  0.  1.  1.]\r\n        \"\"\"\r\n\r\n        # Formatting-string used to convert integer to binary-string.\r\n        # For example, \"016b\" for num_bits==16\r\n        format_str = \"0{}b\".format(num_bits)\r\n\r\n        bitstr = format(value, format_str)\r\n        floatbits = [1 if bit == '1' else 0 for bit in bitstr]\r\n        floatbits = np.array(floatbits)\r\n    \r\n        return floatbits\r\n\r\nThe next function is a more efficient implementation when converting huge arrays of integers to \"float-bits\". Note that for memory-efficiency we use `np.uint8` to store these 0 and 1's instead of floating-points (the name \"float-bits\" is perhaps a bit misleading now). This is because I used this with huge data-sets so it saved many GB of memory using `uint8` instead of `float32`, and `uint8` can automatically be type-cast by Keras / TensorFlow when input to a neural network.\r\n\r\n    def ints_to_floatbits(values, num_bits):\r\n        \"\"\"\r\n        Convert a 2-dim array of integer values to a 3-dim array of 0.0 and 1.0\r\n        floats corresponding to the bit-strings. The length of each encoding\r\n        is given by num_bits.\r\n        \"\"\"\r\n\r\n        # Formatting-string used to convert integer to binary-string.\r\n        # For example, \"016b\" for num_bits==16\r\n        format_str = \"0{}b\".format(num_bits)\r\n\r\n        # Shape of output array.\r\n        shape = values.shape + (num_bits,)\r\n    \r\n        # Pre-allocate output array for efficiency.\r\n        # This can be several GB!\r\n        floatbits = np.zeros(shape, dtype=np.uint8)\r\n\r\n        # Process all input values.\r\n        for i, row in enumerate(values):\r\n            for j, value in enumerate(row):\r\n                bitstr = format(value, format_str)\r\n                floatbits[i, j] = [1 if bit == '1' else 0 for bit in bitstr]\r\n\r\n                # The above is much faster than the following, even\r\n                # though we avoid the creation of the bit-string.\r\n                # floatbits[i, j] = [(value >> k) & 1 for k in reversed(range(num_bits))]\r\n            \r\n        return floatbits\r\n"}