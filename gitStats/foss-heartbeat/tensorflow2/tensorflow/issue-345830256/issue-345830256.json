{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21245", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21245/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21245/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21245/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21245", "id": 345830256, "node_id": "MDU6SXNzdWUzNDU4MzAyNTY=", "number": 21245, "title": "TFLite Android: Model file will not load. startOffset and declaredLength problems", "user": {"login": "andrewginns", "id": 25386449, "node_id": "MDQ6VXNlcjI1Mzg2NDQ5", "avatar_url": "https://avatars1.githubusercontent.com/u/25386449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewginns", "html_url": "https://github.com/andrewginns", "followers_url": "https://api.github.com/users/andrewginns/followers", "following_url": "https://api.github.com/users/andrewginns/following{/other_user}", "gists_url": "https://api.github.com/users/andrewginns/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewginns/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewginns/subscriptions", "organizations_url": "https://api.github.com/users/andrewginns/orgs", "repos_url": "https://api.github.com/users/andrewginns/repos", "events_url": "https://api.github.com/users/andrewginns/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewginns/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}, {"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}, {"login": "shashishekhar", "id": 1162712, "node_id": "MDQ6VXNlcjExNjI3MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashishekhar", "html_url": "https://github.com/shashishekhar", "followers_url": "https://api.github.com/users/shashishekhar/followers", "following_url": "https://api.github.com/users/shashishekhar/following{/other_user}", "gists_url": "https://api.github.com/users/shashishekhar/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashishekhar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashishekhar/subscriptions", "organizations_url": "https://api.github.com/users/shashishekhar/orgs", "repos_url": "https://api.github.com/users/shashishekhar/repos", "events_url": "https://api.github.com/users/shashishekhar/events{/privacy}", "received_events_url": "https://api.github.com/users/shashishekhar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-07-30T16:18:39Z", "updated_at": "2018-09-14T19:21:06Z", "closed_at": "2018-09-14T19:21:05Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: Pixel 2XL, Android studio emulator</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4</li>\n<li><strong>CUDA/cuDNN version</strong>: n/a</li>\n<li><strong>GPU model and memory</strong>: n/a</li>\n<li><strong>Exact command to reproduce</strong>: Loading TFLite model in an Android application</li>\n</ul>\n<p>Posted as an issue here based on comment from <a href=\"https://stackoverflow.com/questions/51341554/tflite-android-model-file-will-not-load-startoffset-and-declaredlength-problem?noredirect=1#comment90097492_51341554\" rel=\"nofollow\">https://stackoverflow.com/questions/51341554/tflite-android-model-file-will-not-load-startoffset-and-declaredlength-problem?noredirect=1#comment90097492_51341554</a></p>\n<p>I'm having issues with loading a TFLite model using the MappedByteBuffer method from the Tensorflow-for-poets-2 TFLite tutorial.</p>\n<pre><code>private MappedByteBuffer loadModelFile(Activity activity,String MODEL_FILE) throws IOException {\n    AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(MODEL_FILE);\n    FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\n    FileChannel fileChannel = inputStream.getChannel();\n    long startOffset = fileDescriptor.getStartOffset();\n    long declaredLength = fileDescriptor.getDeclaredLength();\n    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\n</code></pre>\n<p>In particular the model I have converted with the tflite_convert (formerly toco) tools fails when the fileChannel.map is returned. The model is a floating point TFLite mode.</p>\n<p>The problem seems to be caused by the startOffset and declaredLength variables. The error I receive in the logcat is</p>\n<pre><code>7525-7525/dp.thexor A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 7525 (dp.thexor), pid 7525 (dp.thexor)\nIf I fix these values to ones from a model that successfully loads then the method successfully returns the fileChannel.map. The values from my model are startOffset = 2846788 declaredLength = 45525464\n</code></pre>\n<p>I know that my TFlite model can successfully be mapped to memory as the tensorflow/contrib/lite/tools/benchmark:benchmark_model is able to benchmark it.</p>\n<p>I'd try to load a quantized TFLite model but currently my model contains ops that do not have quantized equivalents (transpose_conv).</p>\n<p>What could be causing this?</p>\n<p>My .tflite model can be found here: <a href=\"https://github.com/andrewginns/CycleGAN-Tensorflow-PyTorch/releases/download/tf1.7-py3.6.4/float.tflite\">https://github.com/andrewginns/CycleGAN-Tensorflow-PyTorch/releases/download/tf1.7-py3.6.4/float.tflite</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 2XL, Android studio emulator\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.9\nPython version: 2.7\nBazel version (if compiling from source): 0.11.0\nGCC/Compiler version (if compiling from source): 5.4\nCUDA/cuDNN version: n/a\nGPU model and memory: n/a\nExact command to reproduce: Loading TFLite model in an Android application\n\nPosted as an issue here based on comment from https://stackoverflow.com/questions/51341554/tflite-android-model-file-will-not-load-startoffset-and-declaredlength-problem?noredirect=1#comment90097492_51341554\nI'm having issues with loading a TFLite model using the MappedByteBuffer method from the Tensorflow-for-poets-2 TFLite tutorial.\nprivate MappedByteBuffer loadModelFile(Activity activity,String MODEL_FILE) throws IOException {\n    AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(MODEL_FILE);\n    FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\n    FileChannel fileChannel = inputStream.getChannel();\n    long startOffset = fileDescriptor.getStartOffset();\n    long declaredLength = fileDescriptor.getDeclaredLength();\n    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\n\nIn particular the model I have converted with the tflite_convert (formerly toco) tools fails when the fileChannel.map is returned. The model is a floating point TFLite mode.\nThe problem seems to be caused by the startOffset and declaredLength variables. The error I receive in the logcat is\n7525-7525/dp.thexor A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 7525 (dp.thexor), pid 7525 (dp.thexor)\nIf I fix these values to ones from a model that successfully loads then the method successfully returns the fileChannel.map. The values from my model are startOffset = 2846788 declaredLength = 45525464\n\nI know that my TFlite model can successfully be mapped to memory as the tensorflow/contrib/lite/tools/benchmark:benchmark_model is able to benchmark it.\nI'd try to load a quantized TFLite model but currently my model contains ops that do not have quantized equivalents (transpose_conv).\nWhat could be causing this?\nMy .tflite model can be found here: https://github.com/andrewginns/CycleGAN-Tensorflow-PyTorch/releases/download/tf1.7-py3.6.4/float.tflite", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Pixel 2XL, Android studio emulator\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: Loading TFLite model in an Android application\r\n\r\nPosted as an issue here based on comment from https://stackoverflow.com/questions/51341554/tflite-android-model-file-will-not-load-startoffset-and-declaredlength-problem?noredirect=1#comment90097492_51341554\r\n\r\nI'm having issues with loading a TFLite model using the MappedByteBuffer method from the Tensorflow-for-poets-2 TFLite tutorial.\r\n\r\n```\r\nprivate MappedByteBuffer loadModelFile(Activity activity,String MODEL_FILE) throws IOException {\r\n    AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(MODEL_FILE);\r\n    FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n    FileChannel fileChannel = inputStream.getChannel();\r\n    long startOffset = fileDescriptor.getStartOffset();\r\n    long declaredLength = fileDescriptor.getDeclaredLength();\r\n    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n```\r\n\r\nIn particular the model I have converted with the tflite_convert (formerly toco) tools fails when the fileChannel.map is returned. The model is a floating point TFLite mode.\r\n\r\nThe problem seems to be caused by the startOffset and declaredLength variables. The error I receive in the logcat is\r\n```\r\n7525-7525/dp.thexor A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 7525 (dp.thexor), pid 7525 (dp.thexor)\r\nIf I fix these values to ones from a model that successfully loads then the method successfully returns the fileChannel.map. The values from my model are startOffset = 2846788 declaredLength = 45525464\r\n```\r\n\r\nI know that my TFlite model can successfully be mapped to memory as the tensorflow/contrib/lite/tools/benchmark:benchmark_model is able to benchmark it.\r\n\r\nI'd try to load a quantized TFLite model but currently my model contains ops that do not have quantized equivalents (transpose_conv).\r\n\r\nWhat could be causing this?\r\n\r\nMy .tflite model can be found here: https://github.com/andrewginns/CycleGAN-Tensorflow-PyTorch/releases/download/tf1.7-py3.6.4/float.tflite\r\n"}