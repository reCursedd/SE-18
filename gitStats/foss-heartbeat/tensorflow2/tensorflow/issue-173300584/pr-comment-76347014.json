{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/76347014", "pull_request_review_id": null, "id": 76347014, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc2MzQ3MDE0", "diff_hunk": "@@ -0,0 +1,478 @@\n+/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// Implements convolution operations with other kernels baked into the\n+// processing, to optimize latency and memory usage.\n+\n+#include <string.h>\n+#include <map>\n+#include <vector>\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/numeric_op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/resource_mgr.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor_slice.h\"\n+#include \"tensorflow/core/kernels/bounds_check.h\"\n+#include \"tensorflow/core/kernels/conv_ops.h\"\n+#include \"tensorflow/core/kernels/gemm_functors.h\"\n+#include \"tensorflow/core/kernels/image_resizer_state.h\"\n+#include \"tensorflow/core/util/mirror_pad_mode.h\"\n+#include \"tensorflow/core/util/padding.h\"\n+#include \"tensorflow/core/util/tensor_format.h\"\n+\n+namespace tensorflow {\n+\n+namespace {\n+\n+// Combines bilinear resizing and mirror padding into the im2col transformation\n+// stage of convolution,\n+template <class T1, class T2, class T3, class TGemmFunctor>\n+class FusedResizeAndPadConvFunctor {\n+ public:\n+  void operator()(OpKernelContext* context, const Tensor& input,\n+                  int input_batches, int resized_height, int resized_width,\n+                  int padded_height, int padded_width, int input_depth,\n+                  const T2* filter_data, int filter_height, int filter_width,\n+                  int filter_count, int stride_rows, int stride_cols,\n+                  Padding padding, T3* output_data, int output_height,\n+                  int output_width, const ImageResizerState& st,\n+                  int top_padding, int bottom_padding, int left_padding,\n+                  int right_padding, int pad_offset) {\n+    if ((input_batches <= 0) || (padded_width <= 0) || (padded_height <= 0) ||\n+        (input_depth <= 0)) {\n+      LOG(WARNING) << \"Conv2D was called with bad input dimensions: \"\n+                   << input_batches << \", \" << padded_height << \", \"\n+                   << padded_width << \", \" << input_depth;\n+      return;\n+    }\n+    if ((filter_width <= 0) || (filter_height <= 0) || (filter_count <= 0)) {\n+      LOG(WARNING) << \"Conv2D was called with bad filter dimensions: \"\n+                   << filter_width << \", \" << filter_height << \", \"\n+                   << filter_count;\n+      return;\n+    }\n+    if ((output_width <= 0) || (output_height <= 0)) {\n+      LOG(WARNING) << \"Conv2D was called with bad output width or height: \"\n+                   << output_width << \", \" << output_height;\n+      return;\n+    }\n+\n+    // These calculations define how the patches will be positioned within the\n+    // input image. The actual definitions are quite complex, and rely on the\n+    // previously-calculated output size.\n+    int filter_left_offset;\n+    int filter_top_offset;\n+    if (padding == VALID) {\n+      filter_left_offset =\n+          ((output_width - 1) * stride_cols + filter_width - padded_width + 1) /\n+          2;\n+      filter_top_offset = ((output_height - 1) * stride_rows + filter_height -\n+                           padded_height + 1) /\n+                          2;\n+    } else {\n+      filter_left_offset =\n+          ((output_width - 1) * stride_cols + filter_width - padded_width) / 2;\n+      filter_top_offset =\n+          ((output_height - 1) * stride_rows + filter_height - padded_height) /\n+          2;\n+    }\n+\n+    // The im2col buffer has # of patches rows, and # of filters cols.\n+    // It's laid out like this, in row major order in memory:\n+    //        < filter value count >\n+    //   ^   +---------------------+\n+    // patch |                     |\n+    // count |                     |\n+    //   v   +---------------------+\n+    // Each patch row contains a filter_width x filter_height patch of the\n+    // input, with the depth channel as the most contiguous in memory, followed\n+    // by the width, then the height. This is the standard memory order in the\n+    // image world if it helps to visualize it.\n+    const int filter_value_count = filter_width * filter_height * input_depth;\n+\n+    // We don't want to allocate a buffer to hold all the patches if the size is\n+    // going to be extremely large, so break it into chunks if it's bigger than\n+    // a limit. Each chunk will be processed serially, so we can refill the\n+    // buffer for the next chunk and reuse it, keeping maximum memory size down.\n+    // In this case, we've picked 16 megabytes as a reasonable limit.\n+    const size_t max_chunk_size = (16 * 1024 * 1024);\n+    OP_REQUIRES(context, (filter_value_count * sizeof(T1)) <= max_chunk_size,\n+                errors::InvalidArgument(\"Im2Col patch too large for buffer\"));\n+    const size_t patches_per_chunk =\n+        max_chunk_size / (filter_value_count * sizeof(T1));\n+    // Because memory allocation is very expensive on mobile platforms, try to\n+    // allocate a persistent buffer that will be kept around between calls. We\n+    // use TensorFlow's resource management to ensure that the memory will be\n+    // released when the session is over.\n+    Im2ColBufferResource<T1, max_chunk_size>* im2col_buffer_resource;\n+    std::function<Status(Im2ColBufferResource<T1, max_chunk_size>**)> creator =\n+        [](Im2ColBufferResource<T1, max_chunk_size>** resource) {\n+          *resource = new Im2ColBufferResource<T1, max_chunk_size>();\n+          return Status::OK();\n+        };\n+    OP_REQUIRES_OK(context, context->resource_manager()->LookupOrCreate(\n+                                \"Conv2d\", \"im2col_buffer\",\n+                                &im2col_buffer_resource, creator));\n+    // This means that multiple ops can't be run simultaneously on different\n+    // threads, because we have a single shared resource. The platforms this is\n+    // aimed at have intra-op parallelism as their focus though, so it shouldn't\n+    // be an issue.\n+    mutex_lock lock_buffer(im2col_buffer_resource->mu);\n+    core::ScopedUnref unref_buffer(im2col_buffer_resource);\n+    T1* im2col_buffer = im2col_buffer_resource->data;\n+\n+    typename TTypes<T1, 4>::ConstTensor input_data = input.tensor<T1, 4>();\n+\n+    for (int batch = 0; batch < input_batches; ++batch) {\n+      for (int out_y = 0; out_y < output_height; ++out_y) {\n+        const int in_y_origin = (out_y * stride_rows) - filter_top_offset;\n+        for (int out_x = 0; out_x < output_width; ++out_x) {\n+          const int in_x_origin = (out_x * stride_cols) - filter_left_offset;\n+          const int patch_index = (batch * output_width * output_height) +\n+                                  (out_y * output_width) + out_x;\n+          const int patch_index_within_chunk = patch_index % patches_per_chunk;\n+          T1* im2col_patch_start =\n+              im2col_buffer + (patch_index_within_chunk * filter_value_count);\n+          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {\n+            const int conv_in_y = in_y_origin + filter_y;\n+            float in_y = (conv_in_y - top_padding);\n+            if (in_y < 0) {\n+              in_y = -(in_y + 1.0f - pad_offset);\n+            } else if (in_y >= resized_height) {\n+              in_y = (resized_height * 2.0f) - (in_y + 1.0f + pad_offset);\n+            }\n+            in_y *= st.height_scale;\n+            const int64 top_y_index = static_cast<int64>(floorf(in_y));\n+            const int64 bottom_y_index =\n+                std::min(static_cast<int64>(ceilf(in_y)), (st.in_height - 1));\n+            const T1 y_lerp = in_y - top_y_index;\n+            T1* im2col_row_start =\n+                im2col_patch_start + (filter_y * filter_width * input_depth);\n+            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {\n+              const int conv_in_x = in_x_origin + filter_x;\n+              float in_x = (conv_in_x - left_padding);\n+              if (in_x < 0) {\n+                in_x = -(in_x + 1.0f - pad_offset);\n+              } else if (in_x >= resized_width) {\n+                in_x = (resized_width * 2.0f) - (in_x + 1.0f + pad_offset);\n+              }\n+              in_x *= st.width_scale;\n+              const int64 left_x_index = static_cast<int64>(floorf(in_x));\n+              const int64 right_x_index =\n+                  std::min(static_cast<int64>(ceilf(in_x)), (st.in_width - 1));\n+              const T1 x_lerp = in_x - left_x_index;\n+              T1* im2col_row_pixel =\n+                  im2col_row_start + (filter_x * input_depth);\n+              for (int in_channel = 0; in_channel < input_depth; ++in_channel) {\n+                T1 in_value;\n+                if ((conv_in_x >= 0) && (conv_in_x < padded_width) &&", "path": "tensorflow/core/kernels/conv_ops_fused.cc", "position": 183, "original_position": 183, "commit_id": "8a7479a046882d729bd2ddea75c83d17cdfe059f", "original_commit_id": "8a7479a046882d729bd2ddea75c83d17cdfe059f", "user": {"login": "cwhipkey", "id": 17578177, "node_id": "MDQ6VXNlcjE3NTc4MTc3", "avatar_url": "https://avatars0.githubusercontent.com/u/17578177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cwhipkey", "html_url": "https://github.com/cwhipkey", "followers_url": "https://api.github.com/users/cwhipkey/followers", "following_url": "https://api.github.com/users/cwhipkey/following{/other_user}", "gists_url": "https://api.github.com/users/cwhipkey/gists{/gist_id}", "starred_url": "https://api.github.com/users/cwhipkey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cwhipkey/subscriptions", "organizations_url": "https://api.github.com/users/cwhipkey/orgs", "repos_url": "https://api.github.com/users/cwhipkey/repos", "events_url": "https://api.github.com/users/cwhipkey/events{/privacy}", "received_events_url": "https://api.github.com/users/cwhipkey/received_events", "type": "User", "site_admin": false}, "body": "this checks conv_in_x and conv_in_y, but then uses top_y_index and left_x_index, and right_x_index, etc.\n\nWhen the conv sees a value off the image, it should have the same mirror padding applied for that conv input pixel?\n", "created_at": "2016-08-26T00:08:27Z", "updated_at": "2016-08-26T00:08:27Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4046#discussion_r76347014", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4046", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/76347014"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4046#discussion_r76347014"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4046"}}, "body_html": "<p>this checks conv_in_x and conv_in_y, but then uses top_y_index and left_x_index, and right_x_index, etc.</p>\n<p>When the conv sees a value off the image, it should have the same mirror padding applied for that conv input pixel?</p>", "body_text": "this checks conv_in_x and conv_in_y, but then uses top_y_index and left_x_index, and right_x_index, etc.\nWhen the conv sees a value off the image, it should have the same mirror padding applied for that conv input pixel?"}