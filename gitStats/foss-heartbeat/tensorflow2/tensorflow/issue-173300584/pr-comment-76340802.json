{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/76340802", "pull_request_review_id": null, "id": 76340802, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc2MzQwODAy", "diff_hunk": "@@ -303,3 +307,92 @@ def fold_batch_norms(input_graph_def):\n \n   result_graph_def.node.extend(new_ops)\n   return result_graph_def\n+\n+\n+def fuse_resize_and_conv(input_graph_def):\n+  \"\"\"Merges preceding resize and mirror pad ops into a specialized convolution.\n+\n+  There's a common pattern of enlarging the input to a convolution using a\n+  resize operation, and also using MirrorPad to extend the boundaries to that\n+  zero edge pixels don't bleed inwards when convolving. This routine looks for\n+  that pattern of operations, and fuses them together into a Conv2DWithResizeOp.\n+\n+  Args:\n+    input_graph_def: A GraphDef containing a model.\n+\n+  Returns:\n+    Modified graph with resize and pad ops merged.\n+\n+  Raises:\n+    ValueError: If the graph is badly formed with duplicate node names.\n+  \"\"\"\n+\n+  input_node_map = {}\n+  for node in input_graph_def.node:\n+    if node.name not in input_node_map.keys():\n+      input_node_map[node.name] = node\n+    else:\n+      raise ValueError(\"Duplicate node names detected.\")\n+\n+  nodes_to_skip = {}\n+  new_ops = []\n+  for node in input_graph_def.node:\n+\n+    if node.op != \"Conv2D\":\n+      continue\n+    conv_op = node\n+\n+    input_op = node_from_map(input_node_map, conv_op.input[0])\n+    if input_op.op == \"MirrorPad\":\n+      mirror_pad_op = input_op\n+      resize_op = node_from_map(input_node_map, mirror_pad_op.input[0])\n+    else:\n+      mirror_pad_op = None\n+      resize_op = input_op\n+\n+    if resize_op.op != \"ResizeBilinear\":\n+      continue\n+\n+    nodes_to_skip[conv_op.name] = True\n+    if mirror_pad_op:\n+      nodes_to_skip[mirror_pad_op.name] = True\n+    nodes_to_skip[resize_op.name] = True\n+\n+    fused_conv_op = tf.NodeDef()\n+    fused_conv_op.op = \"FusedResizeAndPadConv2D\"\n+    fused_conv_op.name = conv_op.name\n+    if mirror_pad_op:\n+      mirror_paddings_name = mirror_pad_op.input[1]\n+      mirror_paddings_mode = mirror_pad_op.attr[\"mode\"]\n+    else:\n+      paddings_op = tf.NodeDef()\n+      paddings_op.op = \"Const\"\n+      paddings_op.name = conv_op.name + \"_dummy_paddings\"\n+      paddings_op.attr[\"dtype\"].CopyFrom(tf.AttrValue(\n+          type=tf.int32.as_datatype_enum))\n+      paddings_op.attr[\"value\"].CopyFrom(tf.AttrValue(\n+        tensor=tensor_util.make_tensor_proto(\n+            [0, 0, 0, 0, 0, 0, 0, 0], tf.int32, [4, 2])))\n+      new_ops.extend([paddings_op])\n+      mirror_paddings_name = paddings_op.name\n+      mirror_paddings_mode = tf.AttrValue(s=\"REFLECT\")\n+    fused_conv_op.input.extend([resize_op.input[0], resize_op.input[1],\n+                                mirror_paddings_name, conv_op.input[1]])\n+    fused_conv_op.attr[\"T\"].CopyFrom(conv_op.attr[\"T\"])\n+    fused_conv_op.attr[\"resize_align_corners\"].CopyFrom(\n+        resize_op.attr[\"align_corners\"])\n+    fused_conv_op.attr[\"mode\"].CopyFrom(mirror_paddings_mode)\n+    fused_conv_op.attr[\"strides\"].CopyFrom(conv_op.attr[\"strides\"])\n+    fused_conv_op.attr[\"padding\"].CopyFrom(conv_op.attr[\"padding\"])\n+    new_ops.extend([fused_conv_op])", "path": "tensorflow/python/tools/optimize_for_inference_lib.py", "position": 124, "original_position": 124, "commit_id": "8a7479a046882d729bd2ddea75c83d17cdfe059f", "original_commit_id": "8a7479a046882d729bd2ddea75c83d17cdfe059f", "user": {"login": "cwhipkey", "id": 17578177, "node_id": "MDQ6VXNlcjE3NTc4MTc3", "avatar_url": "https://avatars0.githubusercontent.com/u/17578177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cwhipkey", "html_url": "https://github.com/cwhipkey", "followers_url": "https://api.github.com/users/cwhipkey/followers", "following_url": "https://api.github.com/users/cwhipkey/following{/other_user}", "gists_url": "https://api.github.com/users/cwhipkey/gists{/gist_id}", "starred_url": "https://api.github.com/users/cwhipkey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cwhipkey/subscriptions", "organizations_url": "https://api.github.com/users/cwhipkey/orgs", "repos_url": "https://api.github.com/users/cwhipkey/repos", "events_url": "https://api.github.com/users/cwhipkey/events{/privacy}", "received_events_url": "https://api.github.com/users/cwhipkey/received_events", "type": "User", "site_admin": false}, "body": "is there a way (and is it even worth it) to protect the code from there being new attributes in any of the three ops being combined, that this code then doesn't handle?\n", "created_at": "2016-08-25T23:04:27Z", "updated_at": "2016-08-25T23:04:27Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4046#discussion_r76340802", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4046", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/76340802"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4046#discussion_r76340802"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4046"}}, "body_html": "<p>is there a way (and is it even worth it) to protect the code from there being new attributes in any of the three ops being combined, that this code then doesn't handle?</p>", "body_text": "is there a way (and is it even worth it) to protect the code from there being new attributes in any of the three ops being combined, that this code then doesn't handle?"}