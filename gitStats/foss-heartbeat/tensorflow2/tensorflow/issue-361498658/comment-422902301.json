{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/422902301", "html_url": "https://github.com/tensorflow/tensorflow/issues/22361#issuecomment-422902301", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22361", "id": 422902301, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjkwMjMwMQ==", "user": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T18:05:03Z", "updated_at": "2018-09-19T18:05:30Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7061933\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/joe-antognini\">@joe-antognini</a> good point. Just ran the above code snippets and both returned True. For image quantization conv2d is typically used, e.g. in your example. conv1d essentially does the same thing here, unless you want to do text quantization which would require different methodology.</p>", "body_text": "@joe-antognini good point. Just ran the above code snippets and both returned True. For image quantization conv2d is typically used, e.g. in your example. conv1d essentially does the same thing here, unless you want to do text quantization which would require different methodology.", "body": "@joe-antognini good point. Just ran the above code snippets and both returned True. For image quantization conv2d is typically used, e.g. in your example. conv1d essentially does the same thing here, unless you want to do text quantization which would require different methodology."}