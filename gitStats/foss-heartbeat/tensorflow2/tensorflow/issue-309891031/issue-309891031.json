{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18101", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18101/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18101/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18101/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18101", "id": 309891031, "node_id": "MDU6SXNzdWUzMDk4OTEwMzE=", "number": 18101, "title": "Issue in understanding tf.record and tf-slim. (I couldn't find Documentation)", "user": {"login": "sfarkya", "id": 6245078, "node_id": "MDQ6VXNlcjYyNDUwNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6245078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sfarkya", "html_url": "https://github.com/sfarkya", "followers_url": "https://api.github.com/users/sfarkya/followers", "following_url": "https://api.github.com/users/sfarkya/following{/other_user}", "gists_url": "https://api.github.com/users/sfarkya/gists{/gist_id}", "starred_url": "https://api.github.com/users/sfarkya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sfarkya/subscriptions", "organizations_url": "https://api.github.com/users/sfarkya/orgs", "repos_url": "https://api.github.com/users/sfarkya/repos", "events_url": "https://api.github.com/users/sfarkya/events{/privacy}", "received_events_url": "https://api.github.com/users/sfarkya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-03-29T20:22:25Z", "updated_at": "2018-04-06T00:54:32Z", "closed_at": "2018-04-06T00:54:32Z", "author_association": "NONE", "body_html": "<p>I am trying to fine-tune inceptionv3 model using slim tensorflow library.<br>\nI tried to read source code (no proper documentation) and figured out few things and I am able to fine-tune it and save the checkpoint. However, I am unable to understand certain things while writing the code for it.   Here are the steps I followed</p>\n<ol>\n<li>I created a tf.record for my training data which is fine, now I am reading the data using the below code.<br>\n[</li>\n</ol>\n<pre><code>import tensorflow as tf\n  import tensorflow.contrib.slim.nets as nets\n  import tensorflow.contrib.slim as slim\n  import matplotlib.pyplot as plt\n  import numpy as np\n  \n  # get the data and labels here\n  \n  data_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/train1.tfrecords'\n  \n  # Training setting\n  num_epochs = 100\n  initial_learning_rate = 0.0002\n  learning_rate_decay_factor = 0.7\n  num_epochs_before_decay = 5\n  num_classes = 5980\n  \n  # load the checkpoint\n  model_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/inception_v3.ckpt'\n  \n  # log directory\n  log_dir = '/home/sfarkya/nvidia_challenge/datasets/detrac/fine_tuned_model'\n  \n  with tf.Session() as sess:\n      feature = {'train/image': tf.FixedLenFeature([], tf.string),\n                 'train/label': tf.FixedLenFeature([], tf.int64)}\n  \n      # Create a list of filenames and pass it to a queue\n      filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n  \n      # Define a reader and read the next record\n      reader = tf.TFRecordReader()\n      _, serialized_example = reader.read(filename_queue)\n  \n      # Decode the record read by the reader\n      features = tf.parse_single_example(serialized_example, features=feature)\n  \n      # Convert the image data from string back to the numbers\n      image = tf.decode_raw(features['train/image'], tf.float32)\n  \n      # Cast label data into int32\n      label = tf.cast(features['train/label'], tf.int32)\n  \n      # Reshape image data into the original shape\n      image = tf.reshape(image, [128, 128, 3])\n  \n      # Creates batches by randomly shuffling tensors\n      images, labels = tf.train.shuffle_batch([image, label], batch_size=64, capacity=128, num_threads=2,\n                                              min_after_dequeue=64)](url)\n</code></pre>\n<p>Now I am finetuning the model using slim and this is the code.</p>\n<pre><code>  init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    sess.run(init_op)\n\n    # Create a coordinator and run all QueueRunner objects\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n\n    # load model\n\n    # load the inception model from the slim library - we are using inception v3\n    #inputL = tf.placeholder(tf.float32, (64, 128, 128, 3))\n\n    img, lbl = sess.run([images, labels])\n    one_hot_labels = slim.one_hot_encoding(lbl, num_classes)\n\n    with slim.arg_scope(slim.nets.inception.inception_v3_arg_scope()):\n        logits, inceptionv3 = nets.inception.inception_v3(inputs=img, num_classes=5980, is_training=True,\n                                                          dropout_keep_prob=.6)\n\n    # Restore convolutional layers:\n\n    variables_to_restore = slim.get_variables_to_restore(exclude=['InceptionV3/Logits', 'InceptionV3/AuxLogits'])\n    init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)\n\n    # loss function\n    loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)\n    total_loss = tf.losses.get_total_loss()\n\n    # train operation\n    train_op = slim.learning.create_train_op(total_loss + loss, optimizer= tf.train.AdamOptimizer(learning_rate=1e-4))\n\n    print('Im here')\n    # Start training.\n    slim.learning.train(train_op, log_dir, init_fn=init_fn, save_interval_secs=20, number_of_steps= 10)\n</code></pre>\n<p>Now I have few questions about the code, which I am quite unable to figure out. Once, the code reaches <strong>slim.learning.train</strong> I don't see anything printing however, it's training, I can see in the log. Now,</p>\n<ol>\n<li>How do I give the number of epochs to the code? Right now it's running step by step with each step has batch_size = 64.</li>\n<li>How do I make sure that in the code <strong>tf.train.shuffle_batch</strong> I am not repeating my images and I am training over the whole dataset?</li>\n<li>How can I print the loss values while it's training?</li>\n<li>If I create a validation set then how can I switch betweem training the model and validation?</li>\n</ol>\n<p>Thanks for the help!</p>", "body_text": "I am trying to fine-tune inceptionv3 model using slim tensorflow library.\nI tried to read source code (no proper documentation) and figured out few things and I am able to fine-tune it and save the checkpoint. However, I am unable to understand certain things while writing the code for it.   Here are the steps I followed\n\nI created a tf.record for my training data which is fine, now I am reading the data using the below code.\n[\n\nimport tensorflow as tf\n  import tensorflow.contrib.slim.nets as nets\n  import tensorflow.contrib.slim as slim\n  import matplotlib.pyplot as plt\n  import numpy as np\n  \n  # get the data and labels here\n  \n  data_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/train1.tfrecords'\n  \n  # Training setting\n  num_epochs = 100\n  initial_learning_rate = 0.0002\n  learning_rate_decay_factor = 0.7\n  num_epochs_before_decay = 5\n  num_classes = 5980\n  \n  # load the checkpoint\n  model_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/inception_v3.ckpt'\n  \n  # log directory\n  log_dir = '/home/sfarkya/nvidia_challenge/datasets/detrac/fine_tuned_model'\n  \n  with tf.Session() as sess:\n      feature = {'train/image': tf.FixedLenFeature([], tf.string),\n                 'train/label': tf.FixedLenFeature([], tf.int64)}\n  \n      # Create a list of filenames and pass it to a queue\n      filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n  \n      # Define a reader and read the next record\n      reader = tf.TFRecordReader()\n      _, serialized_example = reader.read(filename_queue)\n  \n      # Decode the record read by the reader\n      features = tf.parse_single_example(serialized_example, features=feature)\n  \n      # Convert the image data from string back to the numbers\n      image = tf.decode_raw(features['train/image'], tf.float32)\n  \n      # Cast label data into int32\n      label = tf.cast(features['train/label'], tf.int32)\n  \n      # Reshape image data into the original shape\n      image = tf.reshape(image, [128, 128, 3])\n  \n      # Creates batches by randomly shuffling tensors\n      images, labels = tf.train.shuffle_batch([image, label], batch_size=64, capacity=128, num_threads=2,\n                                              min_after_dequeue=64)](url)\n\nNow I am finetuning the model using slim and this is the code.\n  init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    sess.run(init_op)\n\n    # Create a coordinator and run all QueueRunner objects\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n\n    # load model\n\n    # load the inception model from the slim library - we are using inception v3\n    #inputL = tf.placeholder(tf.float32, (64, 128, 128, 3))\n\n    img, lbl = sess.run([images, labels])\n    one_hot_labels = slim.one_hot_encoding(lbl, num_classes)\n\n    with slim.arg_scope(slim.nets.inception.inception_v3_arg_scope()):\n        logits, inceptionv3 = nets.inception.inception_v3(inputs=img, num_classes=5980, is_training=True,\n                                                          dropout_keep_prob=.6)\n\n    # Restore convolutional layers:\n\n    variables_to_restore = slim.get_variables_to_restore(exclude=['InceptionV3/Logits', 'InceptionV3/AuxLogits'])\n    init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)\n\n    # loss function\n    loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)\n    total_loss = tf.losses.get_total_loss()\n\n    # train operation\n    train_op = slim.learning.create_train_op(total_loss + loss, optimizer= tf.train.AdamOptimizer(learning_rate=1e-4))\n\n    print('Im here')\n    # Start training.\n    slim.learning.train(train_op, log_dir, init_fn=init_fn, save_interval_secs=20, number_of_steps= 10)\n\nNow I have few questions about the code, which I am quite unable to figure out. Once, the code reaches slim.learning.train I don't see anything printing however, it's training, I can see in the log. Now,\n\nHow do I give the number of epochs to the code? Right now it's running step by step with each step has batch_size = 64.\nHow do I make sure that in the code tf.train.shuffle_batch I am not repeating my images and I am training over the whole dataset?\nHow can I print the loss values while it's training?\nIf I create a validation set then how can I switch betweem training the model and validation?\n\nThanks for the help!", "body": "I am trying to fine-tune inceptionv3 model using slim tensorflow library. \r\nI tried to read source code (no proper documentation) and figured out few things and I am able to fine-tune it and save the checkpoint. However, I am unable to understand certain things while writing the code for it.   Here are the steps I followed \r\n\r\n 1. I created a tf.record for my training data which is fine, now I am reading the data using the below code. \r\n[\r\n  ```\r\n  import tensorflow as tf\r\n    import tensorflow.contrib.slim.nets as nets\r\n    import tensorflow.contrib.slim as slim\r\n    import matplotlib.pyplot as plt\r\n    import numpy as np\r\n    \r\n    # get the data and labels here\r\n    \r\n    data_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/train1.tfrecords'\r\n    \r\n    # Training setting\r\n    num_epochs = 100\r\n    initial_learning_rate = 0.0002\r\n    learning_rate_decay_factor = 0.7\r\n    num_epochs_before_decay = 5\r\n    num_classes = 5980\r\n    \r\n    # load the checkpoint\r\n    model_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/inception_v3.ckpt'\r\n    \r\n    # log directory\r\n    log_dir = '/home/sfarkya/nvidia_challenge/datasets/detrac/fine_tuned_model'\r\n    \r\n    with tf.Session() as sess:\r\n        feature = {'train/image': tf.FixedLenFeature([], tf.string),\r\n                   'train/label': tf.FixedLenFeature([], tf.int64)}\r\n    \r\n        # Create a list of filenames and pass it to a queue\r\n        filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\r\n    \r\n        # Define a reader and read the next record\r\n        reader = tf.TFRecordReader()\r\n        _, serialized_example = reader.read(filename_queue)\r\n    \r\n        # Decode the record read by the reader\r\n        features = tf.parse_single_example(serialized_example, features=feature)\r\n    \r\n        # Convert the image data from string back to the numbers\r\n        image = tf.decode_raw(features['train/image'], tf.float32)\r\n    \r\n        # Cast label data into int32\r\n        label = tf.cast(features['train/label'], tf.int32)\r\n    \r\n        # Reshape image data into the original shape\r\n        image = tf.reshape(image, [128, 128, 3])\r\n    \r\n        # Creates batches by randomly shuffling tensors\r\n        images, labels = tf.train.shuffle_batch([image, label], batch_size=64, capacity=128, num_threads=2,\r\n                                                min_after_dequeue=64)](url)\r\n```\r\n\r\nNow I am finetuning the model using slim and this is the code. \r\n\r\n      init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\n        sess.run(init_op)\r\n    \r\n        # Create a coordinator and run all QueueRunner objects\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(coord=coord)\r\n    \r\n        # load model\r\n    \r\n        # load the inception model from the slim library - we are using inception v3\r\n        #inputL = tf.placeholder(tf.float32, (64, 128, 128, 3))\r\n    \r\n        img, lbl = sess.run([images, labels])\r\n        one_hot_labels = slim.one_hot_encoding(lbl, num_classes)\r\n    \r\n        with slim.arg_scope(slim.nets.inception.inception_v3_arg_scope()):\r\n            logits, inceptionv3 = nets.inception.inception_v3(inputs=img, num_classes=5980, is_training=True,\r\n                                                              dropout_keep_prob=.6)\r\n    \r\n        # Restore convolutional layers:\r\n    \r\n        variables_to_restore = slim.get_variables_to_restore(exclude=['InceptionV3/Logits', 'InceptionV3/AuxLogits'])\r\n        init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)\r\n    \r\n        # loss function\r\n        loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)\r\n        total_loss = tf.losses.get_total_loss()\r\n    \r\n        # train operation\r\n        train_op = slim.learning.create_train_op(total_loss + loss, optimizer= tf.train.AdamOptimizer(learning_rate=1e-4))\r\n    \r\n        print('Im here')\r\n        # Start training.\r\n        slim.learning.train(train_op, log_dir, init_fn=init_fn, save_interval_secs=20, number_of_steps= 10)\r\n\r\nNow I have few questions about the code, which I am quite unable to figure out. Once, the code reaches **slim.learning.train** I don't see anything printing however, it's training, I can see in the log. Now, \r\n1. How do I give the number of epochs to the code? Right now it's running step by step with each step has batch_size = 64.  \r\n2. How do I make sure that in the code **tf.train.shuffle_batch** I am not repeating my images and I am training over the whole dataset? \r\n3. How can I print the loss values while it's training?\r\n4. If I create a validation set then how can I switch betweem training the model and validation? \r\n\r\nThanks for the help!  "}