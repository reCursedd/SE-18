{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/178568951", "pull_request_review_id": 108645403, "id": 178568951, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODU2ODk1MQ==", "diff_hunk": "@@ -921,6 +932,55 @@ class MaxPoolingWithArgmaxOp : public OpKernel {\n template <typename Device, typename T>\n struct LaunchMaxPoolingGradWithArgmax;\n \n+template <typename T>\n+struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\n+  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n+      EigenMatrixMap;\n+\n+  static void launch(OpKernelContext* context, const PoolParameters& params,\n+                     const Tensor& grad_in, const Tensor& argmax,\n+                     Tensor* grad_out) {\n+    Tensor* output = nullptr;\n+\n+    const DeviceBase::CpuWorkerThreads& worker_threads =\n+        *(context->device()->tensorflow_cpu_worker_threads());\n+\n+    auto shard = [&grad_in, &argmax, &grad_out](int64 start, int64 limit) {\n+      const int64 batch_size =\n+          GetTensorDim(grad_out->shape(), FORMAT_NHWC, 'N');\n+      const int64 output_size_per_batch = grad_out->NumElements() / batch_size;\n+      const int64 input_size_per_batch = grad_in.NumElements() / batch_size;\n+\n+      {\n+        auto grad_out_flat = grad_out->flat<T>();\n+        auto argmax_flat = argmax.flat<int64>();\n+        auto grad_in_flat = grad_in.flat<T>();\n+\n+        const int64 output_start = start * output_size_per_batch;\n+        const int64 output_end = limit * output_size_per_batch;\n+        EigenMatrixMap inputShard(grad_out_flat.data() + output_start, 1,\n+                                  output_end - output_start);\n+        inputShard.setConstant(T(0));\n+\n+        const int input_start = start * input_size_per_batch;\n+        const int input_end = limit * input_size_per_batch;\n+        for (int64 index = input_start; index < input_end; index++) {\n+          const int64 grad_out_index = argmax_flat(index);\n+          CHECK(grad_out_index >= output_start && grad_out_index < output_end)", "path": "tensorflow/core/kernels/maxpooling_op.cc", "position": 101, "original_position": 83, "commit_id": "5e0a5c70f0448c4378da3e7a8879be8cbe4689ae", "original_commit_id": "58aea94b93eb56d7b7bbe3585fd0df6213d7b379", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "Please use FastBoundsCheck here.", "created_at": "2018-04-02T15:30:52Z", "updated_at": "2018-04-06T07:11:48Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18145#discussion_r178568951", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18145", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/178568951"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18145#discussion_r178568951"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18145"}}, "body_html": "<p>Please use FastBoundsCheck here.</p>", "body_text": "Please use FastBoundsCheck here."}