{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204527781", "pull_request_review_id": 139621974, "id": 204527781, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDUyNzc4MQ==", "diff_hunk": "@@ -547,125 +544,93 @@ class MklAvgPoolingGradOp : public MklPoolingBackwardOpBase<T> {\n \n   void Compute(OpKernelContext* context) override {\n     try {\n-      auto cpu_engine = engine(engine::cpu, 0);\n-      MklDnnShape original_input_mkl_shape, input_gradient_mkl_shape;\n-      const Tensor& tensor_in_shape =\n+      const Tensor& orig_input_tensor =\n           MklGetInput(context, kInputTensorIndexInputShape);\n-      const Tensor& input_gradient_tensor =\n+      const Tensor& grad_tensor =\n           MklGetInput(context, kInputTensorIndexInputGradient);\n+\n+      MklDnnShape orig_input_mkl_shape, grad_mkl_shape;\n       GetMklShape(context, kInputTensorIndexInputShape,\n-                  &original_input_mkl_shape);\n+                  &orig_input_mkl_shape);\n       GetMklShape(context, kInputTensorIndexInputGradient,\n-                  &input_gradient_mkl_shape);\n-\n-      SanityCheckInputs(context, tensor_in_shape, input_gradient_tensor,\n-                        original_input_mkl_shape, input_gradient_mkl_shape);\n+                  &grad_mkl_shape);\n       if (!context->status().ok()) return;\n \n       // Used to allocate output_diff_src/diff_src\n-      // and create pool_fwd mdm desc\n-      // 0. Input(\"orig_input_shape: int32\") //NOT a T Tensor!\n-      // 1. Input(\"grad: T\")\n-\n-      MklDnnData<T> input_gradient_diff_dst(&cpu_engine);\n-      MklDnnData<T> output_diff_src(&cpu_engine);\n-      Tensor* output_tensor_diff_src = nullptr;\n-      TensorShape original_input_shape;\n+      MklDnnData<T> grad_dnn_data(&cpu_engine_);\n       MklPoolParameters pool_params;\n-      memory::dims output_dims_mkl_order, original_input_dims_nchw;\n-      // Configure the original input memory descriptor\n-      memory::desc original_input_md = ConfigureOriginalInput(\n-          context, tensor_in_shape, original_input_mkl_shape,\n-          &original_input_dims_nchw, &pool_params, &original_input_shape);\n-\n-      // configure the original output memory descriptor\n-      // by definition, the shape of the original output is the same\n-      // as the shape of the gradient diff_dst\n-      memory::desc original_output_md = this->ConfigureOriginalOutput(\n-          pool_params, input_gradient_mkl_shape, output_dims_mkl_order);\n-\n-      memory::desc target_diff_dst_md = this->ConfigureInputGradient(\n-          input_gradient_mkl_shape, input_gradient_tensor,\n-          &input_gradient_diff_dst, original_output_md);\n-      // The shape of the output diff src needs to be the same shape as the\n-      // original input. But we will set its format to be same as the format of\n-      // input gradient. We won't use format of original input since it will\n-      // always be in Tensorflow layout (given that AvgPoolGrad gets shape of\n-      // the input rather than actual input).\n-      output_diff_src.SetUsrMem(\n-          original_input_dims_nchw,\n-          static_cast<memory::format>(target_diff_dst_md.data.format));\n-\n-      // Create the forward pooling primitive descriptor so we can reference it\n-      // in the backward pooling primitive descriptor\n-      auto pool_fwd_desc = pooling_forward::desc(\n-          prop_kind::forward, algorithm::pooling_avg_exclude_padding,\n-          original_input_md, original_output_md,\n-          memory::dims({pool_params.row_stride, pool_params.col_stride}),\n-          memory::dims({pool_params.window_rows, pool_params.window_cols}),\n-          memory::dims({static_cast<int>(pool_params.pad_top),\n-                        static_cast<int>(pool_params.pad_left)}),\n-          memory::dims({static_cast<int>(pool_params.pad_bottom),\n-                        static_cast<int>(pool_params.pad_right)}),\n-          TFPaddingToMklDnnPadding(this->padding_));\n-      auto pool_fwd_prim_desc =\n-          pooling_forward::primitive_desc(pool_fwd_desc, cpu_engine);\n-\n-      auto pool_bkwd_desc = pooling_backward::desc(\n-          algorithm::pooling_avg_exclude_padding,\n-          output_diff_src.GetUsrMemDesc(), target_diff_dst_md,\n-          memory::dims({pool_params.row_stride, pool_params.col_stride}),\n-          memory::dims({pool_params.window_rows, pool_params.window_cols}),\n-          memory::dims({static_cast<int>(pool_params.pad_top),\n-                        static_cast<int>(pool_params.pad_left)}),\n-          memory::dims({static_cast<int>(pool_params.pad_bottom),\n-                        static_cast<int>(pool_params.pad_right)}),\n-          TFPaddingToMklDnnPadding(this->padding_));\n-      auto pool_bkwd_prim_desc = pooling_backward::primitive_desc(\n-          pool_bkwd_desc, cpu_engine, pool_fwd_prim_desc);\n-      this->AllocateOutputTensor(\n-          context, pool_bkwd_prim_desc, original_input_dims_nchw,\n-          this->data_format_mkldnn_, &output_tensor_diff_src);\n-\n-      output_diff_src.SetUsrMemDataHandle(output_tensor_diff_src);\n-\n-      this->PrepareAndExecuteNet(\n-          pool_bkwd_prim_desc, &input_gradient_diff_dst, &output_diff_src,\n-          memory::primitive_desc(target_diff_dst_md, cpu_engine));\n+      auto shape_vec = orig_input_tensor.vec<int32>();\n+      TensorShape orig_input_shape;\n+      for (int i = 0; i < orig_input_tensor.NumElements(); i++) {\n+        orig_input_shape.AddDim(shape_vec(i));\n+      }\n+      this->InitMklPoolParameters(context, &pool_params, orig_input_mkl_shape,\n+                                  orig_input_shape);\n+\n+      memory::dims filter_dims, strides, padding_left, padding_right;\n+      this->PoolParamsToDims(&pool_params, &filter_dims, &strides,\n+          &padding_left, &padding_right);\n+\n+      memory::dims orig_input_dims_mkl_order =\n+          orig_input_mkl_shape.IsMklTensor()\n+          ? orig_input_mkl_shape.GetSizesAsMklDnnDims()\n+          : TFShapeToMklDnnDimsInNCHW(orig_input_shape, this->data_format_tf_);\n+\n+      memory::dims diff_dst_dims = grad_mkl_shape.IsMklTensor()\n+          ? grad_mkl_shape.GetSizesAsMklDnnDims()\n+          : TFShapeToMklDnnDimsInNCHW(grad_tensor.shape(),\n+                                      this->data_format_tf_);\n+      memory::dims output_dims_mkl_order;\n+      this->GetOutputDims(pool_params, &output_dims_mkl_order);\n+\n+      MklPoolingParams bwdParams(orig_input_dims_mkl_order,\n+          output_dims_mkl_order, filter_dims, strides,\n+          padding_left, padding_right, algorithm::pooling_avg_exclude_padding);\n+      MklPoolingBwdPrimitive<T> *pooling_bwd =\n+        MklPoolingBwdPrimitiveFactory<T>::Get(bwdParams);\n+\n+      Tensor* output_tensor = nullptr;\n+      this->AllocateOutputTensor(context, *(pooling_bwd->GetPoolingBwdPd()),\n+                                 orig_input_dims_mkl_order,\n+                                 this->data_format_mkldnn_, &output_tensor);\n+      // get diff_dst memory::desc\n+      memory::desc diff_dst_md = grad_mkl_shape.IsMklTensor()\n+                                 ? grad_mkl_shape.GetMklLayout()\n+                                 : memory::desc(diff_dst_dims, MklDnnType<T>(),\n+                                         this->data_format_mkldnn_);\n+      // Check whether we need to reorder diff_dst\n+      T* diff_dst_data = nullptr;", "path": "tensorflow/core/kernels/mkl_avgpooling_op.cc", "position": null, "original_position": 291, "commit_id": "6fdc6be324df7e3f7e3162e161ef4e869bd888fb", "original_commit_id": "d490493cd4848422e5480e8a30a0a88af07641ad", "user": {"login": "gzmkl", "id": 29215195, "node_id": "MDQ6VXNlcjI5MjE1MTk1", "avatar_url": "https://avatars0.githubusercontent.com/u/29215195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gzmkl", "html_url": "https://github.com/gzmkl", "followers_url": "https://api.github.com/users/gzmkl/followers", "following_url": "https://api.github.com/users/gzmkl/following{/other_user}", "gists_url": "https://api.github.com/users/gzmkl/gists{/gist_id}", "starred_url": "https://api.github.com/users/gzmkl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gzmkl/subscriptions", "organizations_url": "https://api.github.com/users/gzmkl/orgs", "repos_url": "https://api.github.com/users/gzmkl/repos", "events_url": "https://api.github.com/users/gzmkl/events{/privacy}", "received_events_url": "https://api.github.com/users/gzmkl/received_events", "type": "User", "site_admin": false}, "body": "Done with code change", "created_at": "2018-07-23T19:33:26Z", "updated_at": "2018-07-31T15:47:59Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19403#discussion_r204527781", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19403", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204527781"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19403#discussion_r204527781"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19403"}}, "body_html": "<p>Done with code change</p>", "body_text": "Done with code change", "in_reply_to_id": 203507807}