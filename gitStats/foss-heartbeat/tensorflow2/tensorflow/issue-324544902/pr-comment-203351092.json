{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203351092", "pull_request_review_id": 138220594, "id": 203351092, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzM1MTA5Mg==", "diff_hunk": "@@ -547,125 +565,97 @@ class MklAvgPoolingGradOp : public MklPoolingBackwardOpBase<T> {\n \n   void Compute(OpKernelContext* context) override {\n     try {\n-      auto cpu_engine = engine(engine::cpu, 0);\n-      MklDnnShape original_input_mkl_shape, input_gradient_mkl_shape;\n-      const Tensor& tensor_in_shape =\n+      const Tensor& orig_input_tensor =\n           MklGetInput(context, kInputTensorIndexInputShape);\n-      const Tensor& input_gradient_tensor =\n+      const Tensor& grad_tensor =\n           MklGetInput(context, kInputTensorIndexInputGradient);\n+\n+      MklDnnShape orig_input_mkl_shape, grad_mkl_shape;\n       GetMklShape(context, kInputTensorIndexInputShape,\n-                  &original_input_mkl_shape);\n+                  &orig_input_mkl_shape);\n       GetMklShape(context, kInputTensorIndexInputGradient,\n-                  &input_gradient_mkl_shape);\n-\n-      SanityCheckInputs(context, tensor_in_shape, input_gradient_tensor,\n-                        original_input_mkl_shape, input_gradient_mkl_shape);\n+                  &grad_mkl_shape);\n       if (!context->status().ok()) return;\n \n       // Used to allocate output_diff_src/diff_src\n-      // and create pool_fwd mdm desc\n-      // 0. Input(\"orig_input_shape: int32\") //NOT a T Tensor!\n-      // 1. Input(\"grad: T\")\n-\n-      MklDnnData<T> input_gradient_diff_dst(&cpu_engine);\n-      MklDnnData<T> output_diff_src(&cpu_engine);\n-      Tensor* output_tensor_diff_src = nullptr;\n-      TensorShape original_input_shape;\n+      MklDnnData<T> grad_dnn_data(&cpu_engine_);\n       MklPoolParameters pool_params;\n-      memory::dims output_dims_mkl_order, original_input_dims_nchw;\n-      // Configure the original input memory descriptor\n-      memory::desc original_input_md = ConfigureOriginalInput(\n-          context, tensor_in_shape, original_input_mkl_shape,\n-          &original_input_dims_nchw, &pool_params, &original_input_shape);\n-\n-      // configure the original output memory descriptor\n-      // by definition, the shape of the original output is the same\n-      // as the shape of the gradient diff_dst\n-      memory::desc original_output_md = this->ConfigureOriginalOutput(\n-          pool_params, input_gradient_mkl_shape, output_dims_mkl_order);\n-\n-      memory::desc target_diff_dst_md = this->ConfigureInputGradient(\n-          input_gradient_mkl_shape, input_gradient_tensor,\n-          &input_gradient_diff_dst, original_output_md);\n-      // The shape of the output diff src needs to be the same shape as the\n-      // original input. But we will set its format to be same as the format of\n-      // input gradient. We won't use format of original input since it will\n-      // always be in Tensorflow layout (given that AvgPoolGrad gets shape of\n-      // the input rather than actual input).\n-      output_diff_src.SetUsrMem(\n-          original_input_dims_nchw,\n-          static_cast<memory::format>(target_diff_dst_md.data.format));\n-\n-      // Create the forward pooling primitive descriptor so we can reference it\n-      // in the backward pooling primitive descriptor\n-      auto pool_fwd_desc = pooling_forward::desc(\n-          prop_kind::forward, algorithm::pooling_avg_exclude_padding,\n-          original_input_md, original_output_md,\n-          memory::dims({pool_params.row_stride, pool_params.col_stride}),\n-          memory::dims({pool_params.window_rows, pool_params.window_cols}),\n-          memory::dims({static_cast<int>(pool_params.pad_top),\n-                        static_cast<int>(pool_params.pad_left)}),\n-          memory::dims({static_cast<int>(pool_params.pad_bottom),\n-                        static_cast<int>(pool_params.pad_right)}),\n-          TFPaddingToMklDnnPadding(this->padding_));\n-      auto pool_fwd_prim_desc =\n-          pooling_forward::primitive_desc(pool_fwd_desc, cpu_engine);\n-\n-      auto pool_bkwd_desc = pooling_backward::desc(\n-          algorithm::pooling_avg_exclude_padding,\n-          output_diff_src.GetUsrMemDesc(), target_diff_dst_md,\n-          memory::dims({pool_params.row_stride, pool_params.col_stride}),\n-          memory::dims({pool_params.window_rows, pool_params.window_cols}),\n-          memory::dims({static_cast<int>(pool_params.pad_top),\n-                        static_cast<int>(pool_params.pad_left)}),\n-          memory::dims({static_cast<int>(pool_params.pad_bottom),\n-                        static_cast<int>(pool_params.pad_right)}),\n-          TFPaddingToMklDnnPadding(this->padding_));\n-      auto pool_bkwd_prim_desc = pooling_backward::primitive_desc(\n-          pool_bkwd_desc, cpu_engine, pool_fwd_prim_desc);\n-      this->AllocateOutputTensor(\n-          context, pool_bkwd_prim_desc, original_input_dims_nchw,\n-          this->data_format_mkldnn_, &output_tensor_diff_src);\n-\n-      output_diff_src.SetUsrMemDataHandle(output_tensor_diff_src);\n-\n-      this->PrepareAndExecuteNet(\n-          pool_bkwd_prim_desc, &input_gradient_diff_dst, &output_diff_src,\n-          memory::primitive_desc(target_diff_dst_md, cpu_engine));\n+      auto shape_vec = orig_input_tensor.vec<int32>();\n+      TensorShape orig_input_shape;\n+      for (int i = 0; i < orig_input_tensor.NumElements(); i++) {\n+        orig_input_shape.AddDim(shape_vec(i));\n+      }\n+      this->InitMklPoolParameters(context, &pool_params, orig_input_mkl_shape,\n+                                  orig_input_shape);\n+      memory::dims filter_dims = memory::dims(", "path": "tensorflow/core/kernels/mkl_avgpooling_op.cc", "position": null, "original_position": 243, "commit_id": "6fdc6be324df7e3f7e3162e161ef4e869bd888fb", "original_commit_id": "238eb51aeeeda23b3d2fe64c319b93f43ae4fd01", "user": {"login": "yiqianglee", "id": 19940939, "node_id": "MDQ6VXNlcjE5OTQwOTM5", "avatar_url": "https://avatars0.githubusercontent.com/u/19940939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yiqianglee", "html_url": "https://github.com/yiqianglee", "followers_url": "https://api.github.com/users/yiqianglee/followers", "following_url": "https://api.github.com/users/yiqianglee/following{/other_user}", "gists_url": "https://api.github.com/users/yiqianglee/gists{/gist_id}", "starred_url": "https://api.github.com/users/yiqianglee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yiqianglee/subscriptions", "organizations_url": "https://api.github.com/users/yiqianglee/orgs", "repos_url": "https://api.github.com/users/yiqianglee/repos", "events_url": "https://api.github.com/users/yiqianglee/events{/privacy}", "received_events_url": "https://api.github.com/users/yiqianglee/received_events", "type": "User", "site_admin": false}, "body": "Done by code change.", "created_at": "2018-07-18T12:02:19Z", "updated_at": "2018-07-31T15:47:59Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19403#discussion_r203351092", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19403", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203351092"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19403#discussion_r203351092"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19403"}}, "body_html": "<p>Done by code change.</p>", "body_text": "Done by code change.", "in_reply_to_id": 203174382}