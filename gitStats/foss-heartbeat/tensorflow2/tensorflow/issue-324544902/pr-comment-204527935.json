{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204527935", "pull_request_review_id": 139622177, "id": 204527935, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDUyNzkzNQ==", "diff_hunk": "@@ -525,64 +525,94 @@ class MklMaxPoolingOp : public MklPoolingForwardOpBase<T> {\n       // initialize variables for the pooling op\n       MklPoolParameters pool_params;\n       // Get the input tensor and initialize the pooling parameters\n-      this->ConfigureInput(context, dnn_shape_input, input_tensor, &pool_params,\n-                           &dnn_data_input);\n+      TensorShape input_tensor_shape = input_tensor.shape();\n+      this->InitMklPoolParameters(context, &pool_params,\n+          dnn_shape_input, input_tensor_shape);\n       OP_REQUIRES_OK(context, context->status());\n \n       // Declare output tensor\n       Tensor* output_tensor = nullptr;\n       memory::dims output_dims_mkl_order;\n       this->GetOutputDims(pool_params, &output_dims_mkl_order);\n \n-      // If input is in Mkl layout, then just get the memory format from it\n-      // directly, instead of using input data_format to MaxPool.\n-      if (dnn_shape_input.IsMklTensor()) {\n-        dnn_data_output.SetUsrMem(\n-            output_dims_mkl_order,\n-            static_cast<memory::format>(\n-                dnn_data_input.GetUsrMemDesc().data.format));\n-      } else {\n-        dnn_data_output.SetUsrMem(output_dims_mkl_order,\n-                                  this->data_format_mkldnn_);\n+      // If input is an empty tensor, allocate an empty output tensor and return\n+      if (input_tensor.NumElements() == 0) {\n+        const int kOutputIndex = 0;\n+        this->AllocateEmptyOutputTensor(context, kOutputIndex, &pool_params,\n+                                        output_dims_mkl_order, &output_tensor);\n+        return;\n       }\n \n-      // describe the memory layout; let mkl-dnn choose the best for the op\n-      dnn_data_output.SetOpMemDesc(output_dims_mkl_order, memory::format::any);\n-\n-      auto pool_desc = pooling_forward::desc(\n-          prop_kind::forward, algorithm::pooling_max,\n-          dnn_data_input.GetUsrMemDesc(), dnn_data_output.GetUsrMemDesc(),\n-          memory::dims({pool_params.row_stride, pool_params.col_stride}),\n-          memory::dims({pool_params.window_rows, pool_params.window_cols}),\n-          memory::dims({static_cast<int>(pool_params.pad_top),\n-                        static_cast<int>(pool_params.pad_left)}),\n-          memory::dims({static_cast<int>(pool_params.pad_bottom),\n-                        static_cast<int>(pool_params.pad_right)}),\n-          TFPaddingToMklDnnPadding(this->padding_));\n-      auto pool_fwd_desc =\n-          pooling_forward::primitive_desc(pool_desc, cpu_engine);\n-\n-      this->AllocateOutputTensor(context, pool_fwd_desc, output_dims_mkl_order,\n-                                 this->data_format_mkldnn_, &output_tensor);\n+      // Get the input memory descriptor\n+      memory::desc input_md = dnn_shape_input.IsMklTensor()\n+                                ? dnn_shape_input.GetMklLayout()\n+                                : memory::desc(TFShapeToMklDnnDimsInNCHW(\n+                                                 input_tensor_shape,\n+                                                 this->data_format_tf_),\n+                                          MklDnnType<T>(),\n+                                          this->data_format_mkldnn_);\n+\n+      // Get src/filter/stride/padding information\n+      memory::dims src_dims = dnn_shape_input.IsMklTensor()\n+                            ? dnn_shape_input.GetSizesAsMklDnnDims()\n+                            : TFShapeToMklDnnDimsInNCHW(input_tensor.shape(),\n+                                  this->data_format_tf_);\n+\n+      memory::dims filter_dims, strides, padding_left, padding_right;\n+      this->PoolParamsToDims(&pool_params, &filter_dims, &strides,\n+          &padding_left, &padding_right);\n+\n+      // Get a pooling op from the cached pool\n+      MklPoolingFwdPrimitive<T> *pooling_fwd = nullptr;\n+      MklPoolingParams fwdParams(src_dims, output_dims_mkl_order, filter_dims,\n+          strides, padding_left, padding_right, algorithm::pooling_max);\n+      pooling_fwd = MklPoolingFwdPrimitiveFactory<T>::Get(fwdParams);\n+\n+      // allocate output tensor\n+      this->AllocateOutputTensor(context, *(pooling_fwd->GetPoolingFwdPd()),\n+          output_dims_mkl_order, this->data_format_mkldnn_, &output_tensor);\n       OP_REQUIRES_OK(context, context->status());\n-      dnn_data_output.SetUsrMemDataHandle(output_tensor);\n+      dnn_data_output.SetUsrMem(output_dims_mkl_order,\n+          pooling_fwd->GetDstMemoryFormat(), output_tensor);\n \n-      AllocateWorkspaceTensor(context, pool_fwd_desc, &dnn_data_wksp);\n+      AllocateWorkspaceTensor(context, *(pooling_fwd->GetPoolingFwdPd()),\n+          &dnn_data_wksp);\n       OP_REQUIRES_OK(context, context->status());\n \n-      this->PrepareAndExecuteNet(pool_fwd_desc, &dnn_data_input,\n-                                 &dnn_data_output, &dnn_data_wksp);\n+      // check wehther we need to reorder src\n+      T* src_data = nullptr;\n+      if (input_md.data.format != pooling_fwd->GetSrcMemoryFormat()) {\n+        dnn_data_input.SetUsrMem(input_md, &input_tensor);\n+        auto src_target_primitive_desc = memory::primitive_desc(\n+            {{src_dims}, MklDnnType<T>(), pooling_fwd->GetSrcMemoryFormat()},\n+            cpu_engine);\n+        dnn_data_input.CheckReorderToOpMem(src_target_primitive_desc);\n+        src_data = static_cast<T*>(\n+                    dnn_data_input.GetOpMem().get_data_handle());\n+      } else {\n+        src_data = static_cast<T*>(const_cast<T*>(\n+                    input_tensor.flat<T>().data()));\n+      }\n+\n+      T* dst_data = static_cast<T*>(", "path": "tensorflow/core/kernels/mkl_maxpooling_op.cc", "position": null, "original_position": 123, "commit_id": "6fdc6be324df7e3f7e3162e161ef4e869bd888fb", "original_commit_id": "d490493cd4848422e5480e8a30a0a88af07641ad", "user": {"login": "gzmkl", "id": 29215195, "node_id": "MDQ6VXNlcjI5MjE1MTk1", "avatar_url": "https://avatars0.githubusercontent.com/u/29215195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gzmkl", "html_url": "https://github.com/gzmkl", "followers_url": "https://api.github.com/users/gzmkl/followers", "following_url": "https://api.github.com/users/gzmkl/following{/other_user}", "gists_url": "https://api.github.com/users/gzmkl/gists{/gist_id}", "starred_url": "https://api.github.com/users/gzmkl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gzmkl/subscriptions", "organizations_url": "https://api.github.com/users/gzmkl/orgs", "repos_url": "https://api.github.com/users/gzmkl/repos", "events_url": "https://api.github.com/users/gzmkl/events{/privacy}", "received_events_url": "https://api.github.com/users/gzmkl/received_events", "type": "User", "site_admin": false}, "body": "Done with code change. No cast is needed", "created_at": "2018-07-23T19:34:07Z", "updated_at": "2018-07-31T15:47:59Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19403#discussion_r204527935", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19403", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204527935"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19403#discussion_r204527935"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19403"}}, "body_html": "<p>Done with code change. No cast is needed</p>", "body_text": "Done with code change. No cast is needed", "in_reply_to_id": 203539278}