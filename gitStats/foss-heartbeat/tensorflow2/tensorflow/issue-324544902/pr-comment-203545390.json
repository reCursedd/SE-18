{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203545390", "pull_request_review_id": 138458059, "id": 203545390, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzU0NTM5MA==", "diff_hunk": "@@ -24,12 +24,192 @@ limitations under the License.\n \n namespace tensorflow {\n \n+#ifndef INTEL_MKL_ML\n+\n+using mkldnn::pooling_max;\n+using mkldnn::pooling_avg;\n+using mkldnn::pooling_avg_include_padding;\n+using mkldnn::pooling_avg_exclude_padding;\n+using mkldnn::prop_kind;\n+\n+template <typename T>\n+void MklPoolingFwdPrimitive<T>::Setup(const MklPoolingParams& fwdParams) {\n+  if (fwdParams.alg_kind != pooling_max &&\n+    fwdParams.alg_kind != pooling_avg &&\n+    fwdParams.alg_kind != pooling_avg_include_padding &&\n+    fwdParams.alg_kind != pooling_avg_exclude_padding) {\n+    assert(\"Pooling algorithm kind is not supported\\n\");\n+  }\n+\n+  context_.alg_kind = fwdParams.alg_kind;\n+  // create memory desc\n+  // FIXME: Pooling doesn't expose to get the src_primitive_desc,\n+  //        so src format is currently hard-coded.\n+  //        A utility function is used to do this,\n+  //        which may be broken with future CPU architectures\n+  context_.src_md.reset(new memory::desc({fwdParams.src_dims},\n+      MklDnnType<T>(), get_desired_format(fwdParams.src_dims[1])));\n+  context_.dst_md.reset(new memory::desc({fwdParams.dst_dims},\n+      MklDnnType<T>(), memory::format::any));\n+\n+  // create a pooling descriptor\n+  context_.fwd_desc.reset(new pooling_forward::desc(prop_kind::forward_training,\n+      fwdParams.alg_kind, *context_.src_md, *context_.dst_md, fwdParams.strides,\n+      fwdParams.filter_dims, fwdParams.padding_left,\n+      fwdParams.padding_right, padding_kind::zero));\n+  context_.fwd_pd.reset(\n+      new pooling_forward::primitive_desc(*context_.fwd_desc, cpu_engine_));\n+\n+  // store expected primitive format\n+  context_.src_fmt = get_desired_format(fwdParams.src_dims[1]);\n+  context_.dst_fmt = static_cast<mkldnn::memory::format>(\n+      context_.fwd_pd.get()->dst_primitive_desc().desc().data.format);\n+\n+  // create MKL-DNN internal memory object with dummy data\n+  context_.src_mem.reset(\n+      new memory({{{fwdParams.src_dims}, MklDnnType<T>(), context_.src_fmt},\n+      cpu_engine_}, DummyData));\n+  context_.dst_mem.reset(\n+      new memory(context_.fwd_pd.get()->dst_primitive_desc(), DummyData));\n+\n+  // for max pooling, need to return workspace(ws) for backward computing\n+  if (fwdParams.alg_kind == pooling_max) {\n+    auto ws_pd = context_.fwd_pd.get()->workspace_primitive_desc().desc().data;\n+    // store workspace's dims and format to create workspace tensor\n+    context_.ws_fmt = static_cast<mkldnn::memory::format>(ws_pd.format);\n+    context_.ws_dims.assign(ws_pd.dims, ws_pd.dims + ws_pd.ndims);\n+    context_.ws_dt = static_cast<mkldnn::memory::data_type>(ws_pd.data_type);\n+    context_.ws_size = \n+      context_.fwd_pd.get()->workspace_primitive_desc().get_size();\n+    context_.ws_mem.reset(\n+        new memory(context_.fwd_pd.get()->workspace_primitive_desc(),\n+                  DummyData));\n+    context_.fwd.reset(new pooling_forward(*context_.fwd_pd, \n+          *context_.src_mem, *context_.dst_mem, *context_.ws_mem));\n+  } else {\n+    context_.fwd.reset(new pooling_forward(*context_.fwd_pd, \n+          *context_.src_mem, *context_.dst_mem));\n+  }\n+\n+  context_.fwd_primitives.push_back(*context_.fwd);\n+}\n+\n+template <typename T>\n+void MklPoolingFwdPrimitive<T>::Execute(const T* src_data, const T* dst_data, ", "path": "tensorflow/core/kernels/mkl_pooling_ops_common.cc", "position": null, "original_position": 75, "commit_id": "6fdc6be324df7e3f7e3162e161ef4e869bd888fb", "original_commit_id": "d490493cd4848422e5480e8a30a0a88af07641ad", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "Pass dst_data and workspace pointers as non-const?\r\nWould it make sense to only make src_mem const in the context struct?\r\n\r\nI prefer to use such patterns to document the const versus non-const status of the data arrats and pass it around throughout the code.\r\n\r\nIf we are consistent, it improves readability, prevents bugs, and removes the need for some of the casts.", "created_at": "2018-07-18T22:06:12Z", "updated_at": "2018-07-31T15:47:59Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19403#discussion_r203545390", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19403", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203545390"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19403#discussion_r203545390"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19403"}}, "body_html": "<p>Pass dst_data and workspace pointers as non-const?<br>\nWould it make sense to only make src_mem const in the context struct?</p>\n<p>I prefer to use such patterns to document the const versus non-const status of the data arrats and pass it around throughout the code.</p>\n<p>If we are consistent, it improves readability, prevents bugs, and removes the need for some of the casts.</p>", "body_text": "Pass dst_data and workspace pointers as non-const?\nWould it make sense to only make src_mem const in the context struct?\nI prefer to use such patterns to document the const versus non-const status of the data arrats and pass it around throughout the code.\nIf we are consistent, it improves readability, prevents bugs, and removes the need for some of the casts."}