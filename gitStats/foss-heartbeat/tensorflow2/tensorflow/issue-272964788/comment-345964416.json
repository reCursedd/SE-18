{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/345964416", "html_url": "https://github.com/tensorflow/tensorflow/issues/14452#issuecomment-345964416", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14452", "id": 345964416, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTk2NDQxNg==", "user": {"login": "GPhilo", "id": 4441724, "node_id": "MDQ6VXNlcjQ0NDE3MjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/4441724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GPhilo", "html_url": "https://github.com/GPhilo", "followers_url": "https://api.github.com/users/GPhilo/followers", "following_url": "https://api.github.com/users/GPhilo/following{/other_user}", "gists_url": "https://api.github.com/users/GPhilo/gists{/gist_id}", "starred_url": "https://api.github.com/users/GPhilo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GPhilo/subscriptions", "organizations_url": "https://api.github.com/users/GPhilo/orgs", "repos_url": "https://api.github.com/users/GPhilo/repos", "events_url": "https://api.github.com/users/GPhilo/events{/privacy}", "received_events_url": "https://api.github.com/users/GPhilo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-21T09:18:06Z", "updated_at": "2017-11-21T09:19:49Z", "author_association": "NONE", "body_html": "<p>Any updates on this?</p>\n<p>From what I could see, it seems <code>freeze_graph</code> fails to remove the <code>global_step/*</code> part of the graph. I believe this is due to the introduction of the initialization check for <code>global_step</code>, which introduces an <code>add</code> node whose control output is then input to many <code>Const</code> or <code>NoOp</code> further nodes in the graph.</p>\n<p>It seems that the control input breaks <code>tensorflow.python.framework.graph_util_impl.convert_variables_to_constants()</code>. This is because, without the control output of the <code>add</code> node, the <code>global_step</code> subgraph is not connected to the inference graph output, so it gets pruned when calling <code>convert_variables_to_constants</code>. Since now there is a control input based on <code>add</code>, however, the function doesn't automatically prune the <code>global_step</code> and things break.</p>\n<p>This is the only node in the frozen graph where the <code>^add</code> input is still preserved:</p>\n<pre><code>node {\n  name: \"Reshape_1/shape\"\n  op: \"Const\"\n  input: \"^add\"\n  attr {\n    key: \"_output_shapes\"\n    value {\n      list {\n        shape {\n          dim {\n            size: 2\n          }\n        }\n      }\n    }\n  }\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: \"\\377\\377\\377\\377\\000\\006\\000\\000\"\n      }\n    }\n  }\n}\n</code></pre>\n<p>What is the purpose of this control input?</p>", "body_text": "Any updates on this?\nFrom what I could see, it seems freeze_graph fails to remove the global_step/* part of the graph. I believe this is due to the introduction of the initialization check for global_step, which introduces an add node whose control output is then input to many Const or NoOp further nodes in the graph.\nIt seems that the control input breaks tensorflow.python.framework.graph_util_impl.convert_variables_to_constants(). This is because, without the control output of the add node, the global_step subgraph is not connected to the inference graph output, so it gets pruned when calling convert_variables_to_constants. Since now there is a control input based on add, however, the function doesn't automatically prune the global_step and things break.\nThis is the only node in the frozen graph where the ^add input is still preserved:\nnode {\n  name: \"Reshape_1/shape\"\n  op: \"Const\"\n  input: \"^add\"\n  attr {\n    key: \"_output_shapes\"\n    value {\n      list {\n        shape {\n          dim {\n            size: 2\n          }\n        }\n      }\n    }\n  }\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: \"\\377\\377\\377\\377\\000\\006\\000\\000\"\n      }\n    }\n  }\n}\n\nWhat is the purpose of this control input?", "body": "Any updates on this?\r\n\r\nFrom what I could see, it seems `freeze_graph` fails to remove the `global_step/*` part of the graph. I believe this is due to the introduction of the initialization check for `global_step`, which introduces an `add` node whose control output is then input to many `Const` or `NoOp` further nodes in the graph.\r\n\r\nIt seems that the control input breaks `tensorflow.python.framework.graph_util_impl.convert_variables_to_constants()`. This is because, without the control output of the `add` node, the `global_step` subgraph is not connected to the inference graph output, so it gets pruned when calling `convert_variables_to_constants`. Since now there is a control input based on `add`, however, the function doesn't automatically prune the `global_step` and things break.\r\n\r\nThis is the only node in the frozen graph where the `^add` input is still preserved:\r\n```\r\nnode {\r\n  name: \"Reshape_1/shape\"\r\n  op: \"Const\"\r\n  input: \"^add\"\r\n  attr {\r\n    key: \"_output_shapes\"\r\n    value {\r\n      list {\r\n        shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_INT32\r\n        tensor_shape {\r\n          dim {\r\n            size: 2\r\n          }\r\n        }\r\n        tensor_content: \"\\377\\377\\377\\377\\000\\006\\000\\000\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nWhat is the purpose of this control input?"}