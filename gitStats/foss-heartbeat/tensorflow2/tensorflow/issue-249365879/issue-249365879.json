{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12181", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12181/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12181/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12181/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12181", "id": 249365879, "node_id": "MDU6SXNzdWUyNDkzNjU4Nzk=", "number": 12181, "title": "Cuda build fail with 1.3.0", "user": {"login": "phanousk", "id": 7148037, "node_id": "MDQ6VXNlcjcxNDgwMzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/7148037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phanousk", "html_url": "https://github.com/phanousk", "followers_url": "https://api.github.com/users/phanousk/followers", "following_url": "https://api.github.com/users/phanousk/following{/other_user}", "gists_url": "https://api.github.com/users/phanousk/gists{/gist_id}", "starred_url": "https://api.github.com/users/phanousk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phanousk/subscriptions", "organizations_url": "https://api.github.com/users/phanousk/orgs", "repos_url": "https://api.github.com/users/phanousk/repos", "events_url": "https://api.github.com/users/phanousk/events{/privacy}", "received_events_url": "https://api.github.com/users/phanousk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-08-10T14:29:08Z", "updated_at": "2017-08-17T07:01:06Z", "closed_at": "2017-08-17T02:38:12Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<ul>\n<li>issue with the same outcomes is here: <a href=\"https://stackoverflow.com/questions/45266594/tensorflow-with-gpu-cuda8-compile-error-shfl-up\" rel=\"nofollow\">https://stackoverflow.com/questions/45266594/tensorflow-with-gpu-cuda8-compile-error-shfl-up</a></li>\n</ul>\n<hr>\n<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nNO</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nDebian 8.4</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:</p>\n</li>\n</ul>\n<p>Trying to compile it from source.</p>\n<ul>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\nlatest git head</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\n2.7.10</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\n5.2</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nvarious, tried CUDA 8.0, 7.5, 7.0 and cuDNN 4.0, 5.0, 5.1</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\ngit clone <a href=\"https://github.com/tensorflow/tensorflow.git\">https://github.com/tensorflow/tensorflow.git</a> tensorflow-1.3.0<br>\n./configure<br>\nWARNING: Running Bazel server needs to be killed, because the startup options are different.<br>\nYou have bazel 0.5.2- (@non-git) installed.<br>\nPlease specify the location of python. [Default is /software/python/2.7.10/intel/bin/python]:<br>\nFound possible Python library paths:<br>\n/software/python/2.7.10/intel/lib/python2.7/site-packages<br>\n/software/python27-modules/software/python/2.7.10/intel/lib/python2.7/site-packages<br>\nPlease input the desired Python library path to use.  Default is /software/python/2.7.10/intel/lib/python2.7/site-packages<br>\n/software/python27-modules/software/python/2.7.10/intel/lib/python2.7/site-packages<br>\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]:<br>\njemalloc as malloc support will be enabled for TensorFlow.</p>\n</li>\n</ul>\n<p>Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]:<br>\nNo Google Cloud Platform support will be enabled for TensorFlow.</p>\n<p>Do you wish to build TensorFlow with Hadoop File System support? [y/N]:<br>\nNo Hadoop File System support will be enabled for TensorFlow.</p>\n<p>Do you wish to build TensorFlow with XLA JIT support? [y/N]:<br>\nNo XLA JIT support will be enabled for TensorFlow.</p>\n<p>Do you wish to build TensorFlow with GDR support? [y/N]:<br>\nNo GDR support will be enabled for TensorFlow.</p>\n<p>Do you wish to build TensorFlow with VERBS support? [y/N]:<br>\nNo VERBS support will be enabled for TensorFlow.</p>\n<p>Do you wish to build TensorFlow with OpenCL support? [y/N]:<br>\nNo OpenCL support will be enabled for TensorFlow.</p>\n<p>Do you wish to build TensorFlow with CUDA support? [y/N]: y<br>\nCUDA support will be enabled for TensorFlow.</p>\n<p>Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8.0<br>\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /software/cuda/8.0<br>\n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 5<br>\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /software/cuda/8.0]:/software/cudnn/5.1<br>\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.<br>\nYou can find the compute capability of your device at: <a href=\"https://developer.nvidia.com/cuda-gpus\" rel=\"nofollow\">https://developer.nvidia.com/cuda-gpus</a>.<br>\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]2.0,3.5<br>\nDo you want to use clang as CUDA compiler? [y/N]:<br>\nnvcc will be used as CUDA compiler.</p>\n<p>Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:<br>\nDo you wish to build TensorFlow with MPI support? [y/N]:<br>\nNo MPI support will be enabled for TensorFlow.</p>\n<p>Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:<br>\nAdd \"--config=mkl\" to your bazel command to build with MKL support.<br>\nPlease note that MKL on MacOS or windows is still not supported.<br>\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.<br>\nConfiguration finished</p>\n<p>bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package</p>\n<h3>Describe the problem</h3>\n<p>After some time of compiling this error is raised:</p>\n<blockquote>\n<p>./tensorflow/core/util/cuda_kernel_helper.h(620): error: identifier \"__shfl\" is undefined</p>\n<p>./tensorflow/core/util/cuda_kernel_helper.h(640): error: identifier \"__shfl_up\" is undefined</p>\n<p>./tensorflow/core/util/cuda_kernel_helper.h(660): error: identifier \"__shfl_down\" is undefined</p>\n<p>./tensorflow/core/util/cuda_kernel_helper.h(680): error: identifier \"__shfl_xor\" is undefined</p>\n<p>4 errors detected in the compilation of \"/tmp/tmpxft_000042b4_00000000-&gt;10_resampler_ops_gpu.cu.compute_20.cpp1.ii\".<br>\nERROR: /scratch/hanousek/tensorflow-1.3.0-rc2/tensorflow/contrib/resampler/BUILD:45:1: output &gt;'tensorflow/contrib/resampler/_objs/python/ops/_resampler_ops_gpu/tensorflow/contrib/resampler/kernels/resampler_ops_gpu.cu.pic.o' was not created.<br>\nERROR: /scratch/hanousek/tensorflow-1.3.0-rc2/tensorflow/contrib/resampler/BUILD:45:1: not all outputs were created or valid.</p>\n</blockquote>\n<p>More detailed error message is here: <a href=\"url\">https://pastebin.com/RArJfN3m</a> (expire after a month)</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\n\nissue with the same outcomes is here: https://stackoverflow.com/questions/45266594/tensorflow-with-gpu-cuda8-compile-error-shfl-up\n\n\nSystem information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nNO\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nDebian 8.4\n\n\nTensorFlow installed from (source or binary):\n\n\nTrying to compile it from source.\n\n\nTensorFlow version (use command below):\nlatest git head\n\n\nPython version:\n2.7.10\n\n\nBazel version (if compiling from source):\n5.2\n\n\nCUDA/cuDNN version:\nvarious, tried CUDA 8.0, 7.5, 7.0 and cuDNN 4.0, 5.0, 5.1\n\n\nExact command to reproduce:\ngit clone https://github.com/tensorflow/tensorflow.git tensorflow-1.3.0\n./configure\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\nYou have bazel 0.5.2- (@non-git) installed.\nPlease specify the location of python. [Default is /software/python/2.7.10/intel/bin/python]:\nFound possible Python library paths:\n/software/python/2.7.10/intel/lib/python2.7/site-packages\n/software/python27-modules/software/python/2.7.10/intel/lib/python2.7/site-packages\nPlease input the desired Python library path to use.  Default is /software/python/2.7.10/intel/lib/python2.7/site-packages\n/software/python27-modules/software/python/2.7.10/intel/lib/python2.7/site-packages\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]:\njemalloc as malloc support will be enabled for TensorFlow.\n\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]:\nNo Google Cloud Platform support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]:\nNo Hadoop File System support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\nNo XLA JIT support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with GDR support? [y/N]:\nNo GDR support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with VERBS support? [y/N]:\nNo VERBS support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with OpenCL support? [y/N]:\nNo OpenCL support will be enabled for TensorFlow.\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /software/cuda/8.0\n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 5\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /software/cuda/8.0]:/software/cudnn/5.1\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]2.0,3.5\nDo you want to use clang as CUDA compiler? [y/N]:\nnvcc will be used as CUDA compiler.\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\nDo you wish to build TensorFlow with MPI support? [y/N]:\nNo MPI support will be enabled for TensorFlow.\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\nAdd \"--config=mkl\" to your bazel command to build with MKL support.\nPlease note that MKL on MacOS or windows is still not supported.\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\nConfiguration finished\nbazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package\nDescribe the problem\nAfter some time of compiling this error is raised:\n\n./tensorflow/core/util/cuda_kernel_helper.h(620): error: identifier \"__shfl\" is undefined\n./tensorflow/core/util/cuda_kernel_helper.h(640): error: identifier \"__shfl_up\" is undefined\n./tensorflow/core/util/cuda_kernel_helper.h(660): error: identifier \"__shfl_down\" is undefined\n./tensorflow/core/util/cuda_kernel_helper.h(680): error: identifier \"__shfl_xor\" is undefined\n4 errors detected in the compilation of \"/tmp/tmpxft_000042b4_00000000->10_resampler_ops_gpu.cu.compute_20.cpp1.ii\".\nERROR: /scratch/hanousek/tensorflow-1.3.0-rc2/tensorflow/contrib/resampler/BUILD:45:1: output >'tensorflow/contrib/resampler/_objs/python/ops/_resampler_ops_gpu/tensorflow/contrib/resampler/kernels/resampler_ops_gpu.cu.pic.o' was not created.\nERROR: /scratch/hanousek/tensorflow-1.3.0-rc2/tensorflow/contrib/resampler/BUILD:45:1: not all outputs were created or valid.\n\nMore detailed error message is here: https://pastebin.com/RArJfN3m (expire after a month)", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n - issue with the same outcomes is here: https://stackoverflow.com/questions/45266594/tensorflow-with-gpu-cuda8-compile-error-shfl-up\r\n\r\n------------------------\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNO\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nDebian 8.4\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nTrying to compile it from source.\r\n\r\n- **TensorFlow version (use command below)**:\r\nlatest git head\r\n\r\n- **Python version**: \r\n2.7.10\r\n\r\n- **Bazel version (if compiling from source)**:\r\n5.2\r\n\r\n- **CUDA/cuDNN version**:\r\nvarious, tried CUDA 8.0, 7.5, 7.0 and cuDNN 4.0, 5.0, 5.1\r\n\r\n- **Exact command to reproduce**:\r\ngit clone https://github.com/tensorflow/tensorflow.git tensorflow-1.3.0\r\n./configure \r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nYou have bazel 0.5.2- (@non-git) installed.\r\nPlease specify the location of python. [Default is /software/python/2.7.10/intel/bin/python]: \r\nFound possible Python library paths:\r\n/software/python/2.7.10/intel/lib/python2.7/site-packages\r\n/software/python27-modules/software/python/2.7.10/intel/lib/python2.7/site-packages\r\nPlease input the desired Python library path to use.  Default is /software/python/2.7.10/intel/lib/python2.7/site-packages\r\n/software/python27-modules/software/python/2.7.10/intel/lib/python2.7/site-packages\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]: \r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]: \r\nNo Hadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: \r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: \r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]: \r\nNo OpenCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /software/cuda/8.0\r\n\"Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 5\r\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /software/cuda/8.0]:/software/cudnn/5.1\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]2.0,3.5\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nDo you wish to build TensorFlow with MPI support? [y/N]: \r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\nAdd \"--config=mkl\" to your bazel command to build with MKL support.\r\nPlease note that MKL on MacOS or windows is still not supported.\r\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\r\nConfiguration finished\r\n\r\nbazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\nAfter some time of compiling this error is raised:\r\n>./tensorflow/core/util/cuda_kernel_helper.h(620): error: identifier \"__shfl\" is undefined\r\n>\r\n>./tensorflow/core/util/cuda_kernel_helper.h(640): error: identifier \"__shfl_up\" is undefined\r\n>\r\n>./tensorflow/core/util/cuda_kernel_helper.h(660): error: identifier \"__shfl_down\" is undefined\r\n>\r\n>./tensorflow/core/util/cuda_kernel_helper.h(680): error: identifier \"__shfl_xor\" is undefined\r\n>\r\n>4 errors detected in the compilation of \"/tmp/tmpxft_000042b4_00000000->10_resampler_ops_gpu.cu.compute_20.cpp1.ii\".\r\n>ERROR: /scratch/hanousek/tensorflow-1.3.0-rc2/tensorflow/contrib/resampler/BUILD:45:1: output >'tensorflow/contrib/resampler/_objs/python/ops/_resampler_ops_gpu/tensorflow/contrib/resampler/kernels/resampler_ops_gpu.cu.pic.o' was not created.\r\n>ERROR: /scratch/hanousek/tensorflow-1.3.0-rc2/tensorflow/contrib/resampler/BUILD:45:1: not all outputs were created or valid.\r\n\r\nMore detailed error message is here: [https://pastebin.com/RArJfN3m](url) (expire after a month)\r\n"}