{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7916", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7916/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7916/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7916/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7916", "id": 210457379, "node_id": "MDU6SXNzdWUyMTA0NTczNzk=", "number": 7916, "title": "tf.TFRecordReader returns multiples copies of the same data with only 1 epoch", "user": {"login": "lfmaimo", "id": 24392208, "node_id": "MDQ6VXNlcjI0MzkyMjA4", "avatar_url": "https://avatars0.githubusercontent.com/u/24392208?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lfmaimo", "html_url": "https://github.com/lfmaimo", "followers_url": "https://api.github.com/users/lfmaimo/followers", "following_url": "https://api.github.com/users/lfmaimo/following{/other_user}", "gists_url": "https://api.github.com/users/lfmaimo/gists{/gist_id}", "starred_url": "https://api.github.com/users/lfmaimo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lfmaimo/subscriptions", "organizations_url": "https://api.github.com/users/lfmaimo/orgs", "repos_url": "https://api.github.com/users/lfmaimo/repos", "events_url": "https://api.github.com/users/lfmaimo/events{/privacy}", "received_events_url": "https://api.github.com/users/lfmaimo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-02-27T11:26:07Z", "updated_at": "2017-03-01T01:52:18Z", "closed_at": "2017-03-01T01:52:17Z", "author_association": "NONE", "body_html": "<p>I am using tf.TFRecordReader and tf.train.batch to evaluate one epoch of my dataset (it has only one file). In order to get a better performance I tried to use enqueue_many passing a list of reader calls, because supposedly it launches several reader threads. However its behaviour has not been as I expected. It returns each item duplicated, although I thought it would return the same list of items, but faster. I took the code from <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> github: <a href=\"https://github.com/yaroslavvb/stuff/blob/master/ericyue-slowreader/benchmark.py\">https://github.com/yaroslavvb/stuff/blob/master/ericyue-slowreader/benchmark.py</a></p>\n<p>Is this behaviour right? It seems really strange to me and I don't know if it is a bug or a feature.</p>\n<p>Here you can see a snippet of the code:</p>\n<pre><code>reader = tf.TFRecordReader()\nqueue_batch = []\nfor i in range(enqueue_many_size):\n    _, serialized_example = reader.read(filename_queue)\n    queue_batch.append(serialized_example)\nbatch_serialized_example = tf.train.batch(\n    [queue_batch],\n    batch_size=batch_size,\n    num_threads=thread_number,\n    capacity=capacity,\n    enqueue_many=True)\n</code></pre>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 16.04<br>\nNvidia Geforce 1080<br>\nPython 3.5<br>\nTensorflow version: 1.0.0</p>\n<p>Installed version of CUDA and cuDNN:<br>\n/usr/local/cuda-8.0/lib64/libcudadevrt.a       /usr/local/cuda-8.0/lib64/libcudnn.so<br>\n/usr/local/cuda-8.0/lib64/libcudart.so         /usr/local/cuda-8.0/lib64/libcudnn.so.5<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0     /usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44  /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5<br>\n/usr/local/cuda-8.0/lib64/libcudart_static.a   /usr/local/cuda-8.0/lib64/libcudnn_static.a</p>\n<p>The output for batch size of 4 records, enqueue_many_size=2, and record size of 16 floats, is:</p>\n<pre><code>[array([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n     11.,  12.,  13.,  14.,  15.],\n   [  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n     11.,  12.,  13.,  14.,  15.],\n   [ 16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\n     27.,  28.,  29.,  30.,  31.],\n   [ 16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\n     27.,  28.,  29.,  30.,  31.]], dtype=float32)]\n</code></pre>", "body_text": "I am using tf.TFRecordReader and tf.train.batch to evaluate one epoch of my dataset (it has only one file). In order to get a better performance I tried to use enqueue_many passing a list of reader calls, because supposedly it launches several reader threads. However its behaviour has not been as I expected. It returns each item duplicated, although I thought it would return the same list of items, but faster. I took the code from @yaroslavvb github: https://github.com/yaroslavvb/stuff/blob/master/ericyue-slowreader/benchmark.py\nIs this behaviour right? It seems really strange to me and I don't know if it is a bug or a feature.\nHere you can see a snippet of the code:\nreader = tf.TFRecordReader()\nqueue_batch = []\nfor i in range(enqueue_many_size):\n    _, serialized_example = reader.read(filename_queue)\n    queue_batch.append(serialized_example)\nbatch_serialized_example = tf.train.batch(\n    [queue_batch],\n    batch_size=batch_size,\n    num_threads=thread_number,\n    capacity=capacity,\n    enqueue_many=True)\n\nEnvironment info\nOperating System: Ubuntu 16.04\nNvidia Geforce 1080\nPython 3.5\nTensorflow version: 1.0.0\nInstalled version of CUDA and cuDNN:\n/usr/local/cuda-8.0/lib64/libcudadevrt.a       /usr/local/cuda-8.0/lib64/libcudnn.so\n/usr/local/cuda-8.0/lib64/libcudart.so         /usr/local/cuda-8.0/lib64/libcudnn.so.5\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0     /usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44  /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\n/usr/local/cuda-8.0/lib64/libcudart_static.a   /usr/local/cuda-8.0/lib64/libcudnn_static.a\nThe output for batch size of 4 records, enqueue_many_size=2, and record size of 16 floats, is:\n[array([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n     11.,  12.,  13.,  14.,  15.],\n   [  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n     11.,  12.,  13.,  14.,  15.],\n   [ 16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\n     27.,  28.,  29.,  30.,  31.],\n   [ 16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\n     27.,  28.,  29.,  30.,  31.]], dtype=float32)]", "body": "I am using tf.TFRecordReader and tf.train.batch to evaluate one epoch of my dataset (it has only one file). In order to get a better performance I tried to use enqueue_many passing a list of reader calls, because supposedly it launches several reader threads. However its behaviour has not been as I expected. It returns each item duplicated, although I thought it would return the same list of items, but faster. I took the code from @Yaroslavvb github: https://github.com/yaroslavvb/stuff/blob/master/ericyue-slowreader/benchmark.py\r\n\r\nIs this behaviour right? It seems really strange to me and I don't know if it is a bug or a feature.\r\n\r\nHere you can see a snippet of the code:\r\n\r\n    reader = tf.TFRecordReader()\r\n    queue_batch = []\r\n    for i in range(enqueue_many_size):\r\n        _, serialized_example = reader.read(filename_queue)\r\n        queue_batch.append(serialized_example)\r\n    batch_serialized_example = tf.train.batch(\r\n        [queue_batch],\r\n        batch_size=batch_size,\r\n        num_threads=thread_number,\r\n        capacity=capacity,\r\n        enqueue_many=True)\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\nNvidia Geforce 1080\r\nPython 3.5\r\nTensorflow version: 1.0.0\r\n\r\nInstalled version of CUDA and cuDNN: \r\n/usr/local/cuda-8.0/lib64/libcudadevrt.a       /usr/local/cuda-8.0/lib64/libcudnn.so\r\n/usr/local/cuda-8.0/lib64/libcudart.so         /usr/local/cuda-8.0/lib64/libcudnn.so.5\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0     /usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44  /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a   /usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n\r\nThe output for batch size of 4 records, enqueue_many_size=2, and record size of 16 floats, is:\r\n\r\n    [array([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\r\n         11.,  12.,  13.,  14.,  15.],\r\n       [  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\r\n         11.,  12.,  13.,  14.,  15.],\r\n       [ 16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\r\n         27.,  28.,  29.,  30.,  31.],\r\n       [ 16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\r\n         27.,  28.,  29.,  30.,  31.]], dtype=float32)]\r\n"}