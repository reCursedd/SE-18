{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/172114083", "html_url": "https://github.com/tensorflow/tensorflow/issues/583#issuecomment-172114083", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/583", "id": 172114083, "node_id": "MDEyOklzc3VlQ29tbWVudDE3MjExNDA4Mw==", "user": {"login": "jeremybarnes", "id": 112556, "node_id": "MDQ6VXNlcjExMjU1Ng==", "avatar_url": "https://avatars3.githubusercontent.com/u/112556?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeremybarnes", "html_url": "https://github.com/jeremybarnes", "followers_url": "https://api.github.com/users/jeremybarnes/followers", "following_url": "https://api.github.com/users/jeremybarnes/following{/other_user}", "gists_url": "https://api.github.com/users/jeremybarnes/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeremybarnes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeremybarnes/subscriptions", "organizations_url": "https://api.github.com/users/jeremybarnes/orgs", "repos_url": "https://api.github.com/users/jeremybarnes/repos", "events_url": "https://api.github.com/users/jeremybarnes/events{/privacy}", "received_events_url": "https://api.github.com/users/jeremybarnes/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-15T22:33:51Z", "updated_at": "2016-01-15T22:55:39Z", "author_association": "NONE", "body_html": "<p>Confirmed: part of this is caused by the thread pool locking.  The PR in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"126439730\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/763\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/763/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/763\">#763</a> nearly halves the elapsed wall time to train the mnist convolutional.py example:</p>\n<p>from:</p>\n<pre><code>2464.97user 767.13system 7:48.46elapsed 689%CPU (0avgtext+0avgdata 655848maxresident)k\n0inputs+0outputs (0major+84760819minor)pagefaults 0swap\n</code></pre>\n<p>to:</p>\n<pre><code>2827.11user 724.31system 4:19.43elapsed 1368%CPU (0avgtext+0avgdata 1441204maxresident)k\n0inputs+0outputs (0major+61934308minor)pagefaults 0swaps\n</code></pre>\n<p>We still only manage to 1/2 utilize the CPU, however.  Further improvements would probably come from splitting the minibatch into multiple shards that execute the whole graph independently, so that the holes during the reduction operations can be filled with convolutions from another batch.</p>", "body_text": "Confirmed: part of this is caused by the thread pool locking.  The PR in #763 nearly halves the elapsed wall time to train the mnist convolutional.py example:\nfrom:\n2464.97user 767.13system 7:48.46elapsed 689%CPU (0avgtext+0avgdata 655848maxresident)k\n0inputs+0outputs (0major+84760819minor)pagefaults 0swap\n\nto:\n2827.11user 724.31system 4:19.43elapsed 1368%CPU (0avgtext+0avgdata 1441204maxresident)k\n0inputs+0outputs (0major+61934308minor)pagefaults 0swaps\n\nWe still only manage to 1/2 utilize the CPU, however.  Further improvements would probably come from splitting the minibatch into multiple shards that execute the whole graph independently, so that the holes during the reduction operations can be filled with convolutions from another batch.", "body": "Confirmed: part of this is caused by the thread pool locking.  The PR in #763 nearly halves the elapsed wall time to train the mnist convolutional.py example:\n\nfrom:\n\n```\n2464.97user 767.13system 7:48.46elapsed 689%CPU (0avgtext+0avgdata 655848maxresident)k\n0inputs+0outputs (0major+84760819minor)pagefaults 0swap\n```\n\nto:\n\n```\n2827.11user 724.31system 4:19.43elapsed 1368%CPU (0avgtext+0avgdata 1441204maxresident)k\n0inputs+0outputs (0major+61934308minor)pagefaults 0swaps\n```\n\nWe still only manage to 1/2 utilize the CPU, however.  Further improvements would probably come from splitting the minibatch into multiple shards that execute the whole graph independently, so that the holes during the reduction operations can be filled with convolutions from another batch.\n"}