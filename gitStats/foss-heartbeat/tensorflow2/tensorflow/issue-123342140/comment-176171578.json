{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/176171578", "html_url": "https://github.com/tensorflow/tensorflow/issues/583#issuecomment-176171578", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/583", "id": 176171578, "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjE3MTU3OA==", "user": {"login": "dvyukov", "id": 1095328, "node_id": "MDQ6VXNlcjEwOTUzMjg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1095328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dvyukov", "html_url": "https://github.com/dvyukov", "followers_url": "https://api.github.com/users/dvyukov/followers", "following_url": "https://api.github.com/users/dvyukov/following{/other_user}", "gists_url": "https://api.github.com/users/dvyukov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dvyukov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dvyukov/subscriptions", "organizations_url": "https://api.github.com/users/dvyukov/orgs", "repos_url": "https://api.github.com/users/dvyukov/repos", "events_url": "https://api.github.com/users/dvyukov/events{/privacy}", "received_events_url": "https://api.github.com/users/dvyukov/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-28T12:59:59Z", "updated_at": "2016-01-28T12:59:59Z", "author_association": "NONE", "body_html": "<p>How can I expose this contention on a realistic program? Preferably from C++?</p>\n<p>I've tried to modify <code>tensorflow/examples/label_image/main.cc</code> to execute session-&gt;Run in parallel:</p>\n<div class=\"highlight highlight-source-c\"><pre>--- a/tensorflow/examples/label_image/main.cc\n+++ b/tensorflow/examples/label_image/main.cc\n@@ -<span class=\"pl-c1\">32</span>,<span class=\"pl-c1\">6</span> +<span class=\"pl-c1\">32</span>,<span class=\"pl-c1\">9</span> @@ limitations under the License.\n <span class=\"pl-c\"><span class=\"pl-c\">//</span> The googlenet_graph.pb file included by default is created from Inception.</span>\n\n #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>fstream<span class=\"pl-pds\">&gt;</span></span>\n+#include &lt;thread&gt;\n+#include &lt;memory&gt;\n+#include &lt;memory&gt;\n\n #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/cc/ops/const_op.h<span class=\"pl-pds\">\"</span></span>\n #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/cc/ops/image_ops.h<span class=\"pl-pds\">\"</span></span>\n@@ -<span class=\"pl-c1\">290</span>,<span class=\"pl-c1\">15</span> +<span class=\"pl-c1\">293</span>,<span class=\"pl-c1\">22</span> @@ <span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span>* argv[]) {\n   }\n   <span class=\"pl-k\">const</span> Tensor&amp; resized_tensor = resized_tensors[<span class=\"pl-c1\">0</span>];\n\n-  <span class=\"pl-c\"><span class=\"pl-c\">//</span> Actually run the image through the model.</span>\n-  std::vector&lt;Tensor&gt; outputs;\n-  Status run_status = session-&gt;<span class=\"pl-en\">Run</span>({{input_layer, resized_tensor}},\n+  <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> N = <span class=\"pl-c1\">20</span>;\n+  std::vector&lt;std::unique_ptr&lt;std::thread&gt;&gt; <span class=\"pl-en\">threads</span>(N);\n+  <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; N; i++)\n+    threads[i].reset(new std::thread([&amp;]() {\n+      <span class=\"pl-c\"><span class=\"pl-c\">//</span> Actually run the image through the model.</span>\n+      std::vector&lt;Tensor&gt; outputs;\n+      Status run_status = session-&gt;<span class=\"pl-c1\">Run</span>({{input_layer, resized_tensor}},\n                                    {output_layer}, {}, &amp;outputs);\n-  <span class=\"pl-k\">if</span> (!run_status.<span class=\"pl-c1\">ok</span>()) {\n-    <span class=\"pl-c1\">LOG</span>(ERROR) &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Running model failed: <span class=\"pl-pds\">\"</span></span> &lt;&lt; run_status;\n-    <span class=\"pl-k\">return</span> -<span class=\"pl-c1\">1</span>;\n-  }\n+      <span class=\"pl-k\">if</span> (!run_status.<span class=\"pl-c1\">ok</span>()) {\n+        <span class=\"pl-c1\">LOG</span>(ERROR) &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Running model failed: <span class=\"pl-pds\">\"</span></span> &lt;&lt; run_status;\n+      }\n+    }));\n+  <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; N; i++)\n+    threads[i]-&gt;<span class=\"pl-en\">join</span>();\n\n+  <span class=\"pl-c\"><span class=\"pl-c\">/*</span></span>\n<span class=\"pl-c\">   // This is for automated testing to make sure we get the expected result with</span>\n<span class=\"pl-c\">   // the default settings. We know that label 866 (military uniform) should be</span>\n<span class=\"pl-c\">   // the top label for the Admiral Hopper image.</span>\n<span class=\"pl-c\">@@ -321,6 +331,6 @@ int main(int argc, char* argv[]) {</span>\n<span class=\"pl-c\">     LOG(ERROR) &lt;&lt; \"Running print failed: \" &lt;&lt; print_status;</span>\n<span class=\"pl-c\">     return -1;</span>\n<span class=\"pl-c\">   }</span>\n<span class=\"pl-c\">-</span>\n<span class=\"pl-c\">+  <span class=\"pl-c\">*/</span></span>\n   <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n }</pre></div>\n<p>and to create multiple sessions as well:</p>\n<div class=\"highlight highlight-source-c\"><pre>--- a/tensorflow/examples/label_image/main.cc\n+++ b/tensorflow/examples/label_image/main.cc\n@@ -<span class=\"pl-c1\">32</span>,<span class=\"pl-c1\">6</span> +<span class=\"pl-c1\">32</span>,<span class=\"pl-c1\">9</span> @@ limitations under the License.\n <span class=\"pl-c\"><span class=\"pl-c\">//</span> The googlenet_graph.pb file included by default is created from Inception.</span>\n\n #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>fstream<span class=\"pl-pds\">&gt;</span></span>\n+#include &lt;thread&gt;\n+#include &lt;memory&gt;\n+#include &lt;memory&gt;\n\n #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/cc/ops/const_op.h<span class=\"pl-pds\">\"</span></span>\n #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/cc/ops/image_ops.h<span class=\"pl-pds\">\"</span></span>\n@@ -<span class=\"pl-c1\">268</span>,<span class=\"pl-c1\">13</span> +<span class=\"pl-c1\">271</span>,<span class=\"pl-c1\">18</span> @@ <span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span>* argv[]) {\n     <span class=\"pl-k\">return</span> -<span class=\"pl-c1\">1</span>;\n   }\n\n+  <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> N = <span class=\"pl-c1\">20</span>;\n+  std::vector&lt;std::unique_ptr&lt;std::thread&gt;&gt; <span class=\"pl-en\">threads</span>(N);\n+  <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; N; i++)\n+    threads[i].reset(new std::thread([&amp;]() {\n+\n   <span class=\"pl-c\"><span class=\"pl-c\">//</span> First we load and initialize the model.</span>\n   std::unique_ptr&lt;tensorflow::Session&gt; session;\n   string graph_path = <span class=\"pl-c1\">tensorflow::io::JoinPath</span>(root_dir, graph);\n   Status load_graph_status = <span class=\"pl-c1\">LoadGraph</span>(graph_path, &amp;session);\n   <span class=\"pl-k\">if</span> (!load_graph_status.<span class=\"pl-c1\">ok</span>()) {\n     <span class=\"pl-c1\">LOG</span>(ERROR) &lt;&lt; load_graph_status;\n-    <span class=\"pl-k\">return</span> -<span class=\"pl-c1\">1</span>;\n+    <span class=\"pl-c\"><span class=\"pl-c\">//</span>return -1;</span>\n   }\n\n   <span class=\"pl-c\"><span class=\"pl-c\">//</span> Get the image from disk as a float array of numbers, resized and normalized</span>\n@@ -<span class=\"pl-c1\">286</span>,<span class=\"pl-c1\">19</span> +<span class=\"pl-c1\">294</span>,<span class=\"pl-c1\">22</span> @@ <span class=\"pl-k\">int</span> <span class=\"pl-smi\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span>* argv[]) {\n                               input_std, &amp;resized_tensors);\n   <span class=\"pl-k\">if</span> (!read_tensor_status.<span class=\"pl-c1\">ok</span>()) {\n     <span class=\"pl-c1\">LOG</span>(ERROR) &lt;&lt; read_tensor_status;\n-    <span class=\"pl-k\">return</span> -<span class=\"pl-c1\">1</span>;\n+    <span class=\"pl-c\"><span class=\"pl-c\">//</span>return -1;</span>\n   }\n   <span class=\"pl-k\">const</span> Tensor&amp; resized_tensor = resized_tensors[<span class=\"pl-c1\">0</span>];\n\n-  <span class=\"pl-c\"><span class=\"pl-c\">//</span> Actually run the image through the model.</span>\n-  std::vector&lt;Tensor&gt; outputs;\n-  Status run_status = session-&gt;<span class=\"pl-c1\">Run</span>({{input_layer, resized_tensor}},\n+      <span class=\"pl-c\"><span class=\"pl-c\">//</span> Actually run the image through the model.</span>\n+      std::vector&lt;Tensor&gt; outputs;\n+      Status run_status = session-&gt;<span class=\"pl-c1\">Run</span>({{input_layer, resized_tensor}},\n                                    {output_layer}, {}, &amp;outputs);\n-  <span class=\"pl-k\">if</span> (!run_status.<span class=\"pl-c1\">ok</span>()) {\n-    <span class=\"pl-c1\">LOG</span>(ERROR) &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Running model failed: <span class=\"pl-pds\">\"</span></span> &lt;&lt; run_status;\n-    <span class=\"pl-k\">return</span> -<span class=\"pl-c1\">1</span>;\n-  }\n+      <span class=\"pl-k\">if</span> (!run_status.<span class=\"pl-c1\">ok</span>()) {\n+        <span class=\"pl-c1\">LOG</span>(ERROR) &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Running model failed: <span class=\"pl-pds\">\"</span></span> &lt;&lt; run_status;\n+      }\n+    }));\n+  <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; N; i++)\n+    threads[i]-&gt;<span class=\"pl-c1\">join</span>();\n\n+  <span class=\"pl-c\"><span class=\"pl-c\">/*</span></span>\n<span class=\"pl-c\">   // This is for automated testing to make sure we get the expected result with</span>\n<span class=\"pl-c\">   // the default settings. We know that label 866 (military uniform) should be</span>\n<span class=\"pl-c\">   // the top label for the Admiral Hopper image.</span>\n<span class=\"pl-c\">@@ -321,6 +332,6 @@ int main(int argc, char* argv[]) {</span>\n<span class=\"pl-c\">     LOG(ERROR) &lt;&lt; \"Running print failed: \" &lt;&lt; print_status;</span>\n<span class=\"pl-c\">     return -1;</span>\n<span class=\"pl-c\">   }</span>\n<span class=\"pl-c\">-</span>\n<span class=\"pl-c\">+  <span class=\"pl-c\">*/</span></span>\n   <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n }</pre></div>\n<p>But in both cases it nicely consumes all my cores, no significant time spent in system and top functions in profile are all doing useful work:</p>\n<pre><code>+  20.62%  label_image  label_image           [.] float __vector(4) Eigen::internal::pmul&lt;float __vector(4)&gt;(float __vector(4) const&amp;, float __vector(4) const&amp;)\n+  16.66%  label_image  label_image           [.] void Eigen::internal::gebp_traits&lt;float, float, false, false&gt;::madd&lt;float __vector(4), float __vector(4), float __vector(4)&gt;(float __vector(4) const&amp;, floa\n+  15.80%  label_image  label_image           [.] float __vector(4) Eigen::internal::padd&lt;float __vector(4)&gt;(float __vector(4) const&amp;, float __vector(4) const&amp;)\n+   6.55%  label_image  label_image           [.] float __vector(4) Eigen::internal::pload&lt;float __vector(4)&gt;(Eigen::internal::unpacket_traits&lt;float __vector(4)&gt;::type const*)\n+   6.20%  label_image  label_image           [.] void Eigen::internal::pbroadcast4&lt;float __vector(4)&gt;(Eigen::internal::unpacket_traits&lt;float __vector(4)&gt;::type const*, float __vector(4)&amp;, float __vector(4\n+   4.57%  label_image  label_image           [.] Eigen::internal::gebp_kernel&lt;float, float, long, Eigen::internal::blas_data_mapper&lt;float, long, 0, 0&gt;, 8, 4, false, false&gt;::operator()(Eigen::internal::bla\n+   4.25%  label_image  label_image           [.] Eigen::internal::TensorIntDivisor&lt;long, false&gt;::divide(long) const\n</code></pre>\n<p>Can somebody suggest a modification to existing C++ examples that would expose the contention? thanks.</p>\n<p>I am on commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/d4422ff4b2f142de1d0c626f73c734655d340e0d/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/d4422ff4b2f142de1d0c626f73c734655d340e0d\"><tt>d4422ff</tt></a> (Jan 26).</p>", "body_text": "How can I expose this contention on a realistic program? Preferably from C++?\nI've tried to modify tensorflow/examples/label_image/main.cc to execute session->Run in parallel:\n--- a/tensorflow/examples/label_image/main.cc\n+++ b/tensorflow/examples/label_image/main.cc\n@@ -32,6 +32,9 @@ limitations under the License.\n // The googlenet_graph.pb file included by default is created from Inception.\n\n #include <fstream>\n+#include <thread>\n+#include <memory>\n+#include <memory>\n\n #include \"tensorflow/cc/ops/const_op.h\"\n #include \"tensorflow/cc/ops/image_ops.h\"\n@@ -290,15 +293,22 @@ int main(int argc, char* argv[]) {\n   }\n   const Tensor& resized_tensor = resized_tensors[0];\n\n-  // Actually run the image through the model.\n-  std::vector<Tensor> outputs;\n-  Status run_status = session->Run({{input_layer, resized_tensor}},\n+  const int N = 20;\n+  std::vector<std::unique_ptr<std::thread>> threads(N);\n+  for (int i = 0; i < N; i++)\n+    threads[i].reset(new std::thread([&]() {\n+      // Actually run the image through the model.\n+      std::vector<Tensor> outputs;\n+      Status run_status = session->Run({{input_layer, resized_tensor}},\n                                    {output_layer}, {}, &outputs);\n-  if (!run_status.ok()) {\n-    LOG(ERROR) << \"Running model failed: \" << run_status;\n-    return -1;\n-  }\n+      if (!run_status.ok()) {\n+        LOG(ERROR) << \"Running model failed: \" << run_status;\n+      }\n+    }));\n+  for (int i = 0; i < N; i++)\n+    threads[i]->join();\n\n+  /*\n   // This is for automated testing to make sure we get the expected result with\n   // the default settings. We know that label 866 (military uniform) should be\n   // the top label for the Admiral Hopper image.\n@@ -321,6 +331,6 @@ int main(int argc, char* argv[]) {\n     LOG(ERROR) << \"Running print failed: \" << print_status;\n     return -1;\n   }\n-\n+  */\n   return 0;\n }\nand to create multiple sessions as well:\n--- a/tensorflow/examples/label_image/main.cc\n+++ b/tensorflow/examples/label_image/main.cc\n@@ -32,6 +32,9 @@ limitations under the License.\n // The googlenet_graph.pb file included by default is created from Inception.\n\n #include <fstream>\n+#include <thread>\n+#include <memory>\n+#include <memory>\n\n #include \"tensorflow/cc/ops/const_op.h\"\n #include \"tensorflow/cc/ops/image_ops.h\"\n@@ -268,13 +271,18 @@ int main(int argc, char* argv[]) {\n     return -1;\n   }\n\n+  const int N = 20;\n+  std::vector<std::unique_ptr<std::thread>> threads(N);\n+  for (int i = 0; i < N; i++)\n+    threads[i].reset(new std::thread([&]() {\n+\n   // First we load and initialize the model.\n   std::unique_ptr<tensorflow::Session> session;\n   string graph_path = tensorflow::io::JoinPath(root_dir, graph);\n   Status load_graph_status = LoadGraph(graph_path, &session);\n   if (!load_graph_status.ok()) {\n     LOG(ERROR) << load_graph_status;\n-    return -1;\n+    //return -1;\n   }\n\n   // Get the image from disk as a float array of numbers, resized and normalized\n@@ -286,19 +294,22 @@ int main(int argc, char* argv[]) {\n                               input_std, &resized_tensors);\n   if (!read_tensor_status.ok()) {\n     LOG(ERROR) << read_tensor_status;\n-    return -1;\n+    //return -1;\n   }\n   const Tensor& resized_tensor = resized_tensors[0];\n\n-  // Actually run the image through the model.\n-  std::vector<Tensor> outputs;\n-  Status run_status = session->Run({{input_layer, resized_tensor}},\n+      // Actually run the image through the model.\n+      std::vector<Tensor> outputs;\n+      Status run_status = session->Run({{input_layer, resized_tensor}},\n                                    {output_layer}, {}, &outputs);\n-  if (!run_status.ok()) {\n-    LOG(ERROR) << \"Running model failed: \" << run_status;\n-    return -1;\n-  }\n+      if (!run_status.ok()) {\n+        LOG(ERROR) << \"Running model failed: \" << run_status;\n+      }\n+    }));\n+  for (int i = 0; i < N; i++)\n+    threads[i]->join();\n\n+  /*\n   // This is for automated testing to make sure we get the expected result with\n   // the default settings. We know that label 866 (military uniform) should be\n   // the top label for the Admiral Hopper image.\n@@ -321,6 +332,6 @@ int main(int argc, char* argv[]) {\n     LOG(ERROR) << \"Running print failed: \" << print_status;\n     return -1;\n   }\n-\n+  */\n   return 0;\n }\nBut in both cases it nicely consumes all my cores, no significant time spent in system and top functions in profile are all doing useful work:\n+  20.62%  label_image  label_image           [.] float __vector(4) Eigen::internal::pmul<float __vector(4)>(float __vector(4) const&, float __vector(4) const&)\n+  16.66%  label_image  label_image           [.] void Eigen::internal::gebp_traits<float, float, false, false>::madd<float __vector(4), float __vector(4), float __vector(4)>(float __vector(4) const&, floa\n+  15.80%  label_image  label_image           [.] float __vector(4) Eigen::internal::padd<float __vector(4)>(float __vector(4) const&, float __vector(4) const&)\n+   6.55%  label_image  label_image           [.] float __vector(4) Eigen::internal::pload<float __vector(4)>(Eigen::internal::unpacket_traits<float __vector(4)>::type const*)\n+   6.20%  label_image  label_image           [.] void Eigen::internal::pbroadcast4<float __vector(4)>(Eigen::internal::unpacket_traits<float __vector(4)>::type const*, float __vector(4)&, float __vector(4\n+   4.57%  label_image  label_image           [.] Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false>::operator()(Eigen::internal::bla\n+   4.25%  label_image  label_image           [.] Eigen::internal::TensorIntDivisor<long, false>::divide(long) const\n\nCan somebody suggest a modification to existing C++ examples that would expose the contention? thanks.\nI am on commit d4422ff (Jan 26).", "body": "How can I expose this contention on a realistic program? Preferably from C++?\n\nI've tried to modify `tensorflow/examples/label_image/main.cc` to execute session->Run in parallel:\n\n``` c\n--- a/tensorflow/examples/label_image/main.cc\n+++ b/tensorflow/examples/label_image/main.cc\n@@ -32,6 +32,9 @@ limitations under the License.\n // The googlenet_graph.pb file included by default is created from Inception.\n\n #include <fstream>\n+#include <thread>\n+#include <memory>\n+#include <memory>\n\n #include \"tensorflow/cc/ops/const_op.h\"\n #include \"tensorflow/cc/ops/image_ops.h\"\n@@ -290,15 +293,22 @@ int main(int argc, char* argv[]) {\n   }\n   const Tensor& resized_tensor = resized_tensors[0];\n\n-  // Actually run the image through the model.\n-  std::vector<Tensor> outputs;\n-  Status run_status = session->Run({{input_layer, resized_tensor}},\n+  const int N = 20;\n+  std::vector<std::unique_ptr<std::thread>> threads(N);\n+  for (int i = 0; i < N; i++)\n+    threads[i].reset(new std::thread([&]() {\n+      // Actually run the image through the model.\n+      std::vector<Tensor> outputs;\n+      Status run_status = session->Run({{input_layer, resized_tensor}},\n                                    {output_layer}, {}, &outputs);\n-  if (!run_status.ok()) {\n-    LOG(ERROR) << \"Running model failed: \" << run_status;\n-    return -1;\n-  }\n+      if (!run_status.ok()) {\n+        LOG(ERROR) << \"Running model failed: \" << run_status;\n+      }\n+    }));\n+  for (int i = 0; i < N; i++)\n+    threads[i]->join();\n\n+  /*\n   // This is for automated testing to make sure we get the expected result with\n   // the default settings. We know that label 866 (military uniform) should be\n   // the top label for the Admiral Hopper image.\n@@ -321,6 +331,6 @@ int main(int argc, char* argv[]) {\n     LOG(ERROR) << \"Running print failed: \" << print_status;\n     return -1;\n   }\n-\n+  */\n   return 0;\n }\n```\n\nand to create multiple sessions as well:\n\n``` c\n--- a/tensorflow/examples/label_image/main.cc\n+++ b/tensorflow/examples/label_image/main.cc\n@@ -32,6 +32,9 @@ limitations under the License.\n // The googlenet_graph.pb file included by default is created from Inception.\n\n #include <fstream>\n+#include <thread>\n+#include <memory>\n+#include <memory>\n\n #include \"tensorflow/cc/ops/const_op.h\"\n #include \"tensorflow/cc/ops/image_ops.h\"\n@@ -268,13 +271,18 @@ int main(int argc, char* argv[]) {\n     return -1;\n   }\n\n+  const int N = 20;\n+  std::vector<std::unique_ptr<std::thread>> threads(N);\n+  for (int i = 0; i < N; i++)\n+    threads[i].reset(new std::thread([&]() {\n+\n   // First we load and initialize the model.\n   std::unique_ptr<tensorflow::Session> session;\n   string graph_path = tensorflow::io::JoinPath(root_dir, graph);\n   Status load_graph_status = LoadGraph(graph_path, &session);\n   if (!load_graph_status.ok()) {\n     LOG(ERROR) << load_graph_status;\n-    return -1;\n+    //return -1;\n   }\n\n   // Get the image from disk as a float array of numbers, resized and normalized\n@@ -286,19 +294,22 @@ int main(int argc, char* argv[]) {\n                               input_std, &resized_tensors);\n   if (!read_tensor_status.ok()) {\n     LOG(ERROR) << read_tensor_status;\n-    return -1;\n+    //return -1;\n   }\n   const Tensor& resized_tensor = resized_tensors[0];\n\n-  // Actually run the image through the model.\n-  std::vector<Tensor> outputs;\n-  Status run_status = session->Run({{input_layer, resized_tensor}},\n+      // Actually run the image through the model.\n+      std::vector<Tensor> outputs;\n+      Status run_status = session->Run({{input_layer, resized_tensor}},\n                                    {output_layer}, {}, &outputs);\n-  if (!run_status.ok()) {\n-    LOG(ERROR) << \"Running model failed: \" << run_status;\n-    return -1;\n-  }\n+      if (!run_status.ok()) {\n+        LOG(ERROR) << \"Running model failed: \" << run_status;\n+      }\n+    }));\n+  for (int i = 0; i < N; i++)\n+    threads[i]->join();\n\n+  /*\n   // This is for automated testing to make sure we get the expected result with\n   // the default settings. We know that label 866 (military uniform) should be\n   // the top label for the Admiral Hopper image.\n@@ -321,6 +332,6 @@ int main(int argc, char* argv[]) {\n     LOG(ERROR) << \"Running print failed: \" << print_status;\n     return -1;\n   }\n-\n+  */\n   return 0;\n }\n```\n\nBut in both cases it nicely consumes all my cores, no significant time spent in system and top functions in profile are all doing useful work:\n\n```\n+  20.62%  label_image  label_image           [.] float __vector(4) Eigen::internal::pmul<float __vector(4)>(float __vector(4) const&, float __vector(4) const&)\n+  16.66%  label_image  label_image           [.] void Eigen::internal::gebp_traits<float, float, false, false>::madd<float __vector(4), float __vector(4), float __vector(4)>(float __vector(4) const&, floa\n+  15.80%  label_image  label_image           [.] float __vector(4) Eigen::internal::padd<float __vector(4)>(float __vector(4) const&, float __vector(4) const&)\n+   6.55%  label_image  label_image           [.] float __vector(4) Eigen::internal::pload<float __vector(4)>(Eigen::internal::unpacket_traits<float __vector(4)>::type const*)\n+   6.20%  label_image  label_image           [.] void Eigen::internal::pbroadcast4<float __vector(4)>(Eigen::internal::unpacket_traits<float __vector(4)>::type const*, float __vector(4)&, float __vector(4\n+   4.57%  label_image  label_image           [.] Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false>::operator()(Eigen::internal::bla\n+   4.25%  label_image  label_image           [.] Eigen::internal::TensorIntDivisor<long, false>::divide(long) const\n```\n\nCan somebody suggest a modification to existing C++ examples that would expose the contention? thanks.\n\nI am on commit d4422ff4b2f142de1d0c626f73c734655d340e0d (Jan 26).\n"}