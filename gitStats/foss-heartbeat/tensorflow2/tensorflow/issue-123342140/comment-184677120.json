{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/184677120", "html_url": "https://github.com/tensorflow/tensorflow/issues/583#issuecomment-184677120", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/583", "id": 184677120, "node_id": "MDEyOklzc3VlQ29tbWVudDE4NDY3NzEyMA==", "user": {"login": "dvyukov", "id": 1095328, "node_id": "MDQ6VXNlcjEwOTUzMjg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1095328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dvyukov", "html_url": "https://github.com/dvyukov", "followers_url": "https://api.github.com/users/dvyukov/followers", "following_url": "https://api.github.com/users/dvyukov/following{/other_user}", "gists_url": "https://api.github.com/users/dvyukov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dvyukov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dvyukov/subscriptions", "organizations_url": "https://api.github.com/users/dvyukov/orgs", "repos_url": "https://api.github.com/users/dvyukov/repos", "events_url": "https://api.github.com/users/dvyukov/events{/privacy}", "received_events_url": "https://api.github.com/users/dvyukov/received_events", "type": "User", "site_admin": false}, "created_at": "2016-02-16T13:11:16Z", "updated_at": "2016-02-16T13:11:16Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5303155\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tridemax\">@tridemax</a> Do you mean some kind of higher-level partitioning?</p>\n<p>Even when I run tensorflow/models/image/mnist/convolutional with just 4 threads, it is still unable to utilize 4 cores (only about 3.5). The partitioning will also have some overheads for communicate between partitions (I don't know how large it is, though).<br>\nOverall it does not look like good strategy long-term. Partitioning is used to mitigate inherent communication overheads. In this case we try to mitigate artificial overheads. Real cost of shared memory synchronization is pretty low.</p>", "body_text": "@tridemax Do you mean some kind of higher-level partitioning?\nEven when I run tensorflow/models/image/mnist/convolutional with just 4 threads, it is still unable to utilize 4 cores (only about 3.5). The partitioning will also have some overheads for communicate between partitions (I don't know how large it is, though).\nOverall it does not look like good strategy long-term. Partitioning is used to mitigate inherent communication overheads. In this case we try to mitigate artificial overheads. Real cost of shared memory synchronization is pretty low.", "body": "@tridemax Do you mean some kind of higher-level partitioning?\n\nEven when I run tensorflow/models/image/mnist/convolutional with just 4 threads, it is still unable to utilize 4 cores (only about 3.5). The partitioning will also have some overheads for communicate between partitions (I don't know how large it is, though).\nOverall it does not look like good strategy long-term. Partitioning is used to mitigate inherent communication overheads. In this case we try to mitigate artificial overheads. Real cost of shared memory synchronization is pretty low.\n"}