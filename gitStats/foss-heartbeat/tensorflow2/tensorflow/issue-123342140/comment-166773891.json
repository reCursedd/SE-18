{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/166773891", "html_url": "https://github.com/tensorflow/tensorflow/issues/583#issuecomment-166773891", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/583", "id": 166773891, "node_id": "MDEyOklzc3VlQ29tbWVudDE2Njc3Mzg5MQ==", "user": {"login": "alantus", "id": 16088205, "node_id": "MDQ6VXNlcjE2MDg4MjA1", "avatar_url": "https://avatars0.githubusercontent.com/u/16088205?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alantus", "html_url": "https://github.com/alantus", "followers_url": "https://api.github.com/users/alantus/followers", "following_url": "https://api.github.com/users/alantus/following{/other_user}", "gists_url": "https://api.github.com/users/alantus/gists{/gist_id}", "starred_url": "https://api.github.com/users/alantus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alantus/subscriptions", "organizations_url": "https://api.github.com/users/alantus/orgs", "repos_url": "https://api.github.com/users/alantus/repos", "events_url": "https://api.github.com/users/alantus/events{/privacy}", "received_events_url": "https://api.github.com/users/alantus/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-23T01:32:00Z", "updated_at": "2015-12-23T01:32:00Z", "author_association": "NONE", "body_html": "<p>Two things:</p>\n<ol>\n<li>Here's what it writes to stderr:<br>\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 32<br>\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 32<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]<br>\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7f77dc0125c0 Compute status: Out of range: FIFOQueue '_0_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)<br>\n[[Node: fifo_queue_Dequeue = QueueDequeue<a href=\"fifo_queue\">component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"</a>]]<br>\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7f77dc012de0 Compute status: Aborted: Queue '_0_fifo_queue' is already closed.</li>\n</ol>\n<h2>[[Node: fifo_queue_Close_1 = QueueClose<a href=\"fifo_queue\">cancel_pending_enqueues=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"</a>]]</h2>\n<p>Is that ok?<br>\n2. I run it with the following line:<br>\nfor i in <code>seq 1 64</code>; do echo $i <code>./parallel.py $i 2&gt;/dev/null</code>; done<br>\nand here's the output:<br>\n1 done in 1.38, 7.26 ops/sec<br>\n2 done in 1.45, 13.79 ops/sec<br>\n3 done in 1.65, 18.21 ops/sec<br>\n4 done in 1.70, 23.50 ops/sec<br>\n5 done in 1.73, 28.98 ops/sec<br>\n6 done in 1.82, 33.05 ops/sec<br>\n7 done in 1.86, 37.70 ops/sec<br>\n8 done in 1.88, 42.65 ops/sec<br>\n9 done in 1.73, 52.05 ops/sec<br>\n10 done in 1.92, 52.03 ops/sec<br>\n11 done in 2.07, 53.13 ops/sec<br>\n12 done in 2.17, 55.29 ops/sec<br>\n13 done in 1.83, 70.92 ops/sec<br>\n14 done in 2.05, 68.13 ops/sec<br>\n15 done in 2.36, 63.45 ops/sec<br>\n16 done in 2.48, 64.64 ops/sec<br>\n17 done in 2.03, 83.89 ops/sec<br>\n18 done in 1.94, 92.69 ops/sec<br>\n19 done in 2.51, 75.74 ops/sec<br>\n20 done in 2.31, 86.41 ops/sec<br>\n21 done in 2.04, 102.80 ops/sec<br>\n22 done in 2.29, 96.04 ops/sec<br>\n23 done in 2.19, 105.18 ops/sec<br>\n24 done in 2.08, 115.29 ops/sec<br>\n25 done in 2.39, 104.58 ops/sec<br>\n26 done in 2.18, 119.52 ops/sec<br>\n27 done in 2.36, 114.33 ops/sec<br>\n28 done in 2.43, 115.42 ops/sec<br>\n29 done in 2.77, 104.66 ops/sec<br>\n30 done in 2.27, 132.39 ops/sec<br>\n31 done in 2.57, 120.63 ops/sec<br>\n32 done in 2.54, 126.02 ops/sec<br>\n33 done in 2.59, 127.47 ops/sec<br>\n34 done in 2.57, 132.32 ops/sec<br>\n35 done in 2.50, 139.96 ops/sec<br>\n36 done in 2.34, 153.63 ops/sec<br>\n37 done in 2.71, 136.65 ops/sec<br>\n38 done in 2.70, 140.72 ops/sec<br>\n39 done in 2.71, 144.05 ops/sec<br>\n40 done in 3.07, 130.32 ops/sec<br>\n41 done in 2.73, 150.23 ops/sec<br>\n42 done in 3.22, 130.30 ops/sec<br>\n43 done in 2.82, 152.70 ops/sec<br>\n44 done in 3.09, 142.43 ops/sec<br>\n45 done in 2.68, 167.86 ops/sec<br>\n46 done in 2.69, 170.91 ops/sec<br>\n47 done in 2.73, 172.44 ops/sec<br>\n48 done in 2.77, 173.29 ops/sec<br>\n49 done in 3.28, 149.27 ops/sec<br>\n50 done in 2.92, 171.16 ops/sec<br>\n51 done in 3.25, 157.13 ops/sec<br>\n52 done in 3.11, 167.12 ops/sec<br>\n53 done in 3.32, 159.57 ops/sec<br>\n54 done in 2.93, 184.45 ops/sec<br>\n55 done in 3.46, 158.80 ops/sec<br>\n56 done in 3.44, 162.72 ops/sec<br>\n57 done in 3.26, 174.85 ops/sec<br>\n58 done in 3.35, 173.29 ops/sec<br>\n59 done in 3.72, 158.64 ops/sec<br>\n60 done in 3.38, 177.43 ops/sec<br>\n61 done in 3.50, 174.10 ops/sec<br>\n62 done in 3.47, 178.43 ops/sec<br>\n63 done in 3.97, 158.81 ops/sec</p>\n<h2>64 done in 3.27, 195.81 ops/sec</h2>\n<p>So it does scale up to 64 threads...</p>", "body_text": "Two things:\n\nHere's what it writes to stderr:\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 32\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 32\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7f77dc0125c0 Compute status: Out of range: FIFOQueue '_0_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n[[Node: fifo_queue_Dequeue = QueueDequeuecomponent_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7f77dc012de0 Compute status: Aborted: Queue '_0_fifo_queue' is already closed.\n\n[[Node: fifo_queue_Close_1 = QueueClosecancel_pending_enqueues=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nIs that ok?\n2. I run it with the following line:\nfor i in seq 1 64; do echo $i ./parallel.py $i 2>/dev/null; done\nand here's the output:\n1 done in 1.38, 7.26 ops/sec\n2 done in 1.45, 13.79 ops/sec\n3 done in 1.65, 18.21 ops/sec\n4 done in 1.70, 23.50 ops/sec\n5 done in 1.73, 28.98 ops/sec\n6 done in 1.82, 33.05 ops/sec\n7 done in 1.86, 37.70 ops/sec\n8 done in 1.88, 42.65 ops/sec\n9 done in 1.73, 52.05 ops/sec\n10 done in 1.92, 52.03 ops/sec\n11 done in 2.07, 53.13 ops/sec\n12 done in 2.17, 55.29 ops/sec\n13 done in 1.83, 70.92 ops/sec\n14 done in 2.05, 68.13 ops/sec\n15 done in 2.36, 63.45 ops/sec\n16 done in 2.48, 64.64 ops/sec\n17 done in 2.03, 83.89 ops/sec\n18 done in 1.94, 92.69 ops/sec\n19 done in 2.51, 75.74 ops/sec\n20 done in 2.31, 86.41 ops/sec\n21 done in 2.04, 102.80 ops/sec\n22 done in 2.29, 96.04 ops/sec\n23 done in 2.19, 105.18 ops/sec\n24 done in 2.08, 115.29 ops/sec\n25 done in 2.39, 104.58 ops/sec\n26 done in 2.18, 119.52 ops/sec\n27 done in 2.36, 114.33 ops/sec\n28 done in 2.43, 115.42 ops/sec\n29 done in 2.77, 104.66 ops/sec\n30 done in 2.27, 132.39 ops/sec\n31 done in 2.57, 120.63 ops/sec\n32 done in 2.54, 126.02 ops/sec\n33 done in 2.59, 127.47 ops/sec\n34 done in 2.57, 132.32 ops/sec\n35 done in 2.50, 139.96 ops/sec\n36 done in 2.34, 153.63 ops/sec\n37 done in 2.71, 136.65 ops/sec\n38 done in 2.70, 140.72 ops/sec\n39 done in 2.71, 144.05 ops/sec\n40 done in 3.07, 130.32 ops/sec\n41 done in 2.73, 150.23 ops/sec\n42 done in 3.22, 130.30 ops/sec\n43 done in 2.82, 152.70 ops/sec\n44 done in 3.09, 142.43 ops/sec\n45 done in 2.68, 167.86 ops/sec\n46 done in 2.69, 170.91 ops/sec\n47 done in 2.73, 172.44 ops/sec\n48 done in 2.77, 173.29 ops/sec\n49 done in 3.28, 149.27 ops/sec\n50 done in 2.92, 171.16 ops/sec\n51 done in 3.25, 157.13 ops/sec\n52 done in 3.11, 167.12 ops/sec\n53 done in 3.32, 159.57 ops/sec\n54 done in 2.93, 184.45 ops/sec\n55 done in 3.46, 158.80 ops/sec\n56 done in 3.44, 162.72 ops/sec\n57 done in 3.26, 174.85 ops/sec\n58 done in 3.35, 173.29 ops/sec\n59 done in 3.72, 158.64 ops/sec\n60 done in 3.38, 177.43 ops/sec\n61 done in 3.50, 174.10 ops/sec\n62 done in 3.47, 178.43 ops/sec\n63 done in 3.97, 158.81 ops/sec\n64 done in 3.27, 195.81 ops/sec\nSo it does scale up to 64 threads...", "body": "Two things:\n1. Here's what it writes to stderr:\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 32\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 32\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nI tensorflow/core/kernels/logging_ops.cc:79] [heavy op #0]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7f77dc0125c0 Compute status: Out of range: FIFOQueue '_0_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n         [[Node: fifo_queue_Dequeue = QueueDequeue[component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x7f77dc012de0 Compute status: Aborted: Queue '_0_fifo_queue' is already closed.\n\n##          [[Node: fifo_queue_Close_1 = QueueClose[cancel_pending_enqueues=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue)]]\n\nIs that ok?\n2. I run it with the following line:\nfor i in `seq 1 64`; do echo $i `./parallel.py $i 2>/dev/null`; done\nand here's the output:\n1 done in 1.38, 7.26 ops/sec\n2 done in 1.45, 13.79 ops/sec\n3 done in 1.65, 18.21 ops/sec\n4 done in 1.70, 23.50 ops/sec\n5 done in 1.73, 28.98 ops/sec\n6 done in 1.82, 33.05 ops/sec\n7 done in 1.86, 37.70 ops/sec\n8 done in 1.88, 42.65 ops/sec\n9 done in 1.73, 52.05 ops/sec\n10 done in 1.92, 52.03 ops/sec\n11 done in 2.07, 53.13 ops/sec\n12 done in 2.17, 55.29 ops/sec\n13 done in 1.83, 70.92 ops/sec\n14 done in 2.05, 68.13 ops/sec\n15 done in 2.36, 63.45 ops/sec\n16 done in 2.48, 64.64 ops/sec\n17 done in 2.03, 83.89 ops/sec\n18 done in 1.94, 92.69 ops/sec\n19 done in 2.51, 75.74 ops/sec\n20 done in 2.31, 86.41 ops/sec\n21 done in 2.04, 102.80 ops/sec\n22 done in 2.29, 96.04 ops/sec\n23 done in 2.19, 105.18 ops/sec\n24 done in 2.08, 115.29 ops/sec\n25 done in 2.39, 104.58 ops/sec\n26 done in 2.18, 119.52 ops/sec\n27 done in 2.36, 114.33 ops/sec\n28 done in 2.43, 115.42 ops/sec\n29 done in 2.77, 104.66 ops/sec\n30 done in 2.27, 132.39 ops/sec\n31 done in 2.57, 120.63 ops/sec\n32 done in 2.54, 126.02 ops/sec\n33 done in 2.59, 127.47 ops/sec\n34 done in 2.57, 132.32 ops/sec\n35 done in 2.50, 139.96 ops/sec\n36 done in 2.34, 153.63 ops/sec\n37 done in 2.71, 136.65 ops/sec\n38 done in 2.70, 140.72 ops/sec\n39 done in 2.71, 144.05 ops/sec\n40 done in 3.07, 130.32 ops/sec\n41 done in 2.73, 150.23 ops/sec\n42 done in 3.22, 130.30 ops/sec\n43 done in 2.82, 152.70 ops/sec\n44 done in 3.09, 142.43 ops/sec\n45 done in 2.68, 167.86 ops/sec\n46 done in 2.69, 170.91 ops/sec\n47 done in 2.73, 172.44 ops/sec\n48 done in 2.77, 173.29 ops/sec\n49 done in 3.28, 149.27 ops/sec\n50 done in 2.92, 171.16 ops/sec\n51 done in 3.25, 157.13 ops/sec\n52 done in 3.11, 167.12 ops/sec\n53 done in 3.32, 159.57 ops/sec\n54 done in 2.93, 184.45 ops/sec\n55 done in 3.46, 158.80 ops/sec\n56 done in 3.44, 162.72 ops/sec\n57 done in 3.26, 174.85 ops/sec\n58 done in 3.35, 173.29 ops/sec\n59 done in 3.72, 158.64 ops/sec\n60 done in 3.38, 177.43 ops/sec\n61 done in 3.50, 174.10 ops/sec\n62 done in 3.47, 178.43 ops/sec\n63 done in 3.97, 158.81 ops/sec\n\n## 64 done in 3.27, 195.81 ops/sec\n\nSo it does scale up to 64 threads...\n"}