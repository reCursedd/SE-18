{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364132062", "html_url": "https://github.com/tensorflow/tensorflow/issues/13061#issuecomment-364132062", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13061", "id": 364132062, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDEzMjA2Mg==", "user": {"login": "tgamblin", "id": 299842, "node_id": "MDQ6VXNlcjI5OTg0Mg==", "avatar_url": "https://avatars3.githubusercontent.com/u/299842?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgamblin", "html_url": "https://github.com/tgamblin", "followers_url": "https://api.github.com/users/tgamblin/followers", "following_url": "https://api.github.com/users/tgamblin/following{/other_user}", "gists_url": "https://api.github.com/users/tgamblin/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgamblin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgamblin/subscriptions", "organizations_url": "https://api.github.com/users/tgamblin/orgs", "repos_url": "https://api.github.com/users/tgamblin/repos", "events_url": "https://api.github.com/users/tgamblin/events{/privacy}", "received_events_url": "https://api.github.com/users/tgamblin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-08T14:42:16Z", "updated_at": "2018-02-08T14:42:16Z", "author_association": "NONE", "body_html": "<p>I'll just chime in from the Spack side to say that everything <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=620876\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/boegel\">@boegel</a> said is true.  He also gave a nice talk -- I was there <g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji>.  We package software for Livermore Computing (i.e., all of <a href=\"https://hpc.llnl.gov/hardware/platforms\" rel=\"nofollow\">these machines</a>), for other large DOE HPC centers, and for HPC sites outside the DOE.  We have a lot of people who want to use TensorFlow, but it's not maintainable, and our attempts to package TF stagnated because of all the work involved.  We basically need to be TF developers to package the thing.</p>\n<p>The main issues we have are:</p>\n<ol>\n<li>Swapping compilers into the build with Bazel is a giant pain.  Spack wants to be able to customize that.  Bazel (last I checked) wants the compiler to be in <em>exactly</em> its preferred location, which is hardly ever the case on HPC machines.  There are a lot of things about Bazel that are incompatible with the way things need to be built for OSS projects.</li>\n<li>We tried the contributed CMake build to address this.  It's more manageable, but the way it used external project at the time didn't provide a way to use an existing installation of the external projects.  So we had to put some nasty hacks in to point the TF build at the spack-built dependencies (see <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"210336178\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/spack/spack/issues/3244\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/spack/spack/pull/3244/hovercard\" href=\"https://github.com/spack/spack/pull/3244\">spack/spack#3244</a>).</li>\n<li>To further complicate things, TF relies not only on the <em>installed</em> artifacts from its dependencies, but also internal libraries and headers that aren't usually installed.  It builds its dependencies and grabs stuff out of the build directory, not the install directory.  So even if you have properly packaged versions of the dependencies, you may not have all the things that TF needs.</li>\n</ol>\n<p>Maybe some of this stuff has changed -- If so, I'd love to take a look at this again when I have some time.  I am currently hesitant to do this, since I read here that the TF team was going to ditch the contributed builds, and Bazel is too painful to support in Spack.  See <a href=\"https://github.com/tensorflow/tensorflow/issues/6923#issuecomment-273671241\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/6923/hovercard\">#6923 (comment)</a> where <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=49262\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jart\">@jart</a> describes what we'd need to do to use Bazel.</p>\n<p>For now, we just have a person at Livermore Computing who maintains patches on the Bazel build and updates them (very tediously) when users ask for a newer TF version.</p>", "body_text": "I'll just chime in from the Spack side to say that everything @boegel said is true.  He also gave a nice talk -- I was there \ud83d\ude04.  We package software for Livermore Computing (i.e., all of these machines), for other large DOE HPC centers, and for HPC sites outside the DOE.  We have a lot of people who want to use TensorFlow, but it's not maintainable, and our attempts to package TF stagnated because of all the work involved.  We basically need to be TF developers to package the thing.\nThe main issues we have are:\n\nSwapping compilers into the build with Bazel is a giant pain.  Spack wants to be able to customize that.  Bazel (last I checked) wants the compiler to be in exactly its preferred location, which is hardly ever the case on HPC machines.  There are a lot of things about Bazel that are incompatible with the way things need to be built for OSS projects.\nWe tried the contributed CMake build to address this.  It's more manageable, but the way it used external project at the time didn't provide a way to use an existing installation of the external projects.  So we had to put some nasty hacks in to point the TF build at the spack-built dependencies (see spack/spack#3244).\nTo further complicate things, TF relies not only on the installed artifacts from its dependencies, but also internal libraries and headers that aren't usually installed.  It builds its dependencies and grabs stuff out of the build directory, not the install directory.  So even if you have properly packaged versions of the dependencies, you may not have all the things that TF needs.\n\nMaybe some of this stuff has changed -- If so, I'd love to take a look at this again when I have some time.  I am currently hesitant to do this, since I read here that the TF team was going to ditch the contributed builds, and Bazel is too painful to support in Spack.  See #6923 (comment) where @jart describes what we'd need to do to use Bazel.\nFor now, we just have a person at Livermore Computing who maintains patches on the Bazel build and updates them (very tediously) when users ask for a newer TF version.", "body": "I'll just chime in from the Spack side to say that everything @boegel said is true.  He also gave a nice talk -- I was there \ud83d\ude04.  We package software for Livermore Computing (i.e., all of [these machines](https://hpc.llnl.gov/hardware/platforms)), for other large DOE HPC centers, and for HPC sites outside the DOE.  We have a lot of people who want to use TensorFlow, but it's not maintainable, and our attempts to package TF stagnated because of all the work involved.  We basically need to be TF developers to package the thing.\r\n\r\nThe main issues we have are:\r\n1. Swapping compilers into the build with Bazel is a giant pain.  Spack wants to be able to customize that.  Bazel (last I checked) wants the compiler to be in *exactly* its preferred location, which is hardly ever the case on HPC machines.  There are a lot of things about Bazel that are incompatible with the way things need to be built for OSS projects.\r\n2. We tried the contributed CMake build to address this.  It's more manageable, but the way it used external project at the time didn't provide a way to use an existing installation of the external projects.  So we had to put some nasty hacks in to point the TF build at the spack-built dependencies (see spack/spack#3244).\r\n3. To further complicate things, TF relies not only on the *installed* artifacts from its dependencies, but also internal libraries and headers that aren't usually installed.  It builds its dependencies and grabs stuff out of the build directory, not the install directory.  So even if you have properly packaged versions of the dependencies, you may not have all the things that TF needs. \r\n\r\nMaybe some of this stuff has changed -- If so, I'd love to take a look at this again when I have some time.  I am currently hesitant to do this, since I read here that the TF team was going to ditch the contributed builds, and Bazel is too painful to support in Spack.  See [#6923 (comment)](https://github.com/tensorflow/tensorflow/issues/6923#issuecomment-273671241) where @jart describes what we'd need to do to use Bazel.\r\n\r\nFor now, we just have a person at Livermore Computing who maintains patches on the Bazel build and updates them (very tediously) when users ask for a newer TF version."}