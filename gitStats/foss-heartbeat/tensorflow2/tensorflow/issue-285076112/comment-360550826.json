{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/360550826", "html_url": "https://github.com/tensorflow/tensorflow/issues/15717#issuecomment-360550826", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15717", "id": 360550826, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDU1MDgyNg==", "user": {"login": "yzhwang", "id": 1002405, "node_id": "MDQ6VXNlcjEwMDI0MDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1002405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yzhwang", "html_url": "https://github.com/yzhwang", "followers_url": "https://api.github.com/users/yzhwang/followers", "following_url": "https://api.github.com/users/yzhwang/following{/other_user}", "gists_url": "https://api.github.com/users/yzhwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yzhwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yzhwang/subscriptions", "organizations_url": "https://api.github.com/users/yzhwang/orgs", "repos_url": "https://api.github.com/users/yzhwang/repos", "events_url": "https://api.github.com/users/yzhwang/events{/privacy}", "received_events_url": "https://api.github.com/users/yzhwang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-25T18:08:46Z", "updated_at": "2018-01-25T18:08:46Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1515754\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/acbellini\">@acbellini</a> , I modified your code a bit to get more info. Changed the NUM_RUNS to 100, added four tests: one session run for both const op and random op, two session runs for const op and random op, also session run for each op separately:</p>\n<pre><code>def combined_run():\n    s.run((_mul_const_a.op, _mul_random_a.op))\ndef separate_run():\n    s.run((_mul_random_a.op))\n    s.run((_mul_const_a.op))\ndef const_run():\n    s.run((_mul_const_a.op))\ndef random_run():\n    s.run((_mul_random_a.op))\n# timeit\nprint(\"run with separate const and random\\t\", timeit(lambda: separate_run(), number=NUM_RUNS))\nprint(\"run with combined const and random\\t\", timeit(lambda: combined_run(), number=NUM_RUNS))\n\nprint(\"run with const only\\t\", timeit(lambda: const_run(), number=NUM_RUNS))\nprint(\"run with random only\\t\", timeit(lambda: random_run(), number=NUM_RUNS))\n</code></pre>\n<p>I'm using TensorFlow 1.4.1 with CUDA 8. I haven't been able to reproduce your results on both GTX 1080 and P100. Here are my results:</p>\n<p>GTX 1080:<br>\nDevice mapping:<br>\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080, pci bus id: 0000:84:00.0, compute capability: 6.1<br>\nRandom_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0<br>\nMul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0<br>\nMul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\nConst_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\nrun with separate const and random\t 5.317255422996823<br>\nrun with combined const and random\t 5.299742974006222<br>\nrun with const only\t 0.02027931998600252<br>\nrun with random only\t 3.677839469004539</p>\n<p>P100:<br>\nDevice mapping:<br>\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:8a:00.0, compute capability: 6.0<br>\nRandom_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0<br>\nMul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0<br>\nMul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\nRandom_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\nConst_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0<br>\n('run with separate const and random\\t', 4.535215854644775)<br>\n('run with combined const and random\\t', 4.544884204864502)<br>\n('run with const only\\t', 0.008514881134033203)<br>\n('run with random only\\t', 2.8619189262390137)</p>\n<p>For me run with const op only shows much better performance, which meets the expectation. Could there be any other factor that affect the tests by your side?</p>", "body_text": "Hi @acbellini , I modified your code a bit to get more info. Changed the NUM_RUNS to 100, added four tests: one session run for both const op and random op, two session runs for const op and random op, also session run for each op separately:\ndef combined_run():\n    s.run((_mul_const_a.op, _mul_random_a.op))\ndef separate_run():\n    s.run((_mul_random_a.op))\n    s.run((_mul_const_a.op))\ndef const_run():\n    s.run((_mul_const_a.op))\ndef random_run():\n    s.run((_mul_random_a.op))\n# timeit\nprint(\"run with separate const and random\\t\", timeit(lambda: separate_run(), number=NUM_RUNS))\nprint(\"run with combined const and random\\t\", timeit(lambda: combined_run(), number=NUM_RUNS))\n\nprint(\"run with const only\\t\", timeit(lambda: const_run(), number=NUM_RUNS))\nprint(\"run with random only\\t\", timeit(lambda: random_run(), number=NUM_RUNS))\n\nI'm using TensorFlow 1.4.1 with CUDA 8. I haven't been able to reproduce your results on both GTX 1080 and P100. Here are my results:\nGTX 1080:\nDevice mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080, pci bus id: 0000:84:00.0, compute capability: 6.1\nRandom_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0\nMul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\nMul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nConst_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nrun with separate const and random\t 5.317255422996823\nrun with combined const and random\t 5.299742974006222\nrun with const only\t 0.02027931998600252\nrun with random only\t 3.677839469004539\nP100:\nDevice mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:8a:00.0, compute capability: 6.0\nRandom_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0\nMul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\nMul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nRandom_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nConst_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n('run with separate const and random\\t', 4.535215854644775)\n('run with combined const and random\\t', 4.544884204864502)\n('run with const only\\t', 0.008514881134033203)\n('run with random only\\t', 2.8619189262390137)\nFor me run with const op only shows much better performance, which meets the expectation. Could there be any other factor that affect the tests by your side?", "body": "Hi @acbellini , I modified your code a bit to get more info. Changed the NUM_RUNS to 100, added four tests: one session run for both const op and random op, two session runs for const op and random op, also session run for each op separately:\r\n\r\n    def combined_run():\r\n        s.run((_mul_const_a.op, _mul_random_a.op))\r\n    def separate_run():\r\n        s.run((_mul_random_a.op))\r\n        s.run((_mul_const_a.op))\r\n    def const_run():\r\n        s.run((_mul_const_a.op))\r\n    def random_run():\r\n        s.run((_mul_random_a.op))\r\n    # timeit\r\n    print(\"run with separate const and random\\t\", timeit(lambda: separate_run(), number=NUM_RUNS))\r\n    print(\"run with combined const and random\\t\", timeit(lambda: combined_run(), number=NUM_RUNS))\r\n\r\n    print(\"run with const only\\t\", timeit(lambda: const_run(), number=NUM_RUNS))\r\n    print(\"run with random only\\t\", timeit(lambda: random_run(), number=NUM_RUNS))\r\n\r\nI'm using TensorFlow 1.4.1 with CUDA 8. I haven't been able to reproduce your results on both GTX 1080 and P100. Here are my results:\r\n\r\nGTX 1080:\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080, pci bus id: 0000:84:00.0, compute capability: 6.1\r\nRandom_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0\r\nMul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\r\nMul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\nConst_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\nrun with separate const and random\t 5.317255422996823\r\nrun with combined const and random\t 5.299742974006222\r\nrun with const only\t 0.02027931998600252\r\nrun with random only\t 3.677839469004539\r\n\r\nP100:\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:8a:00.0, compute capability: 6.0\r\nRandom_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0\r\nMul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\r\nMul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\nRandom_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\nConst_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\n('run with separate const and random\\t', 4.535215854644775)\r\n('run with combined const and random\\t', 4.544884204864502)\r\n('run with const only\\t', 0.008514881134033203)\r\n('run with random only\\t', 2.8619189262390137)\r\n\r\nFor me run with const op only shows much better performance, which meets the expectation. Could there be any other factor that affect the tests by your side?"}