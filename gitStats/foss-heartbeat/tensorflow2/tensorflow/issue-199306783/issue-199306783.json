{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6702", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6702/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6702/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6702/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6702", "id": 199306783, "node_id": "MDU6SXNzdWUxOTkzMDY3ODM=", "number": 6702, "title": "Deadlock when decoding TFRecords", "user": {"login": "hannes-brt", "id": 323139, "node_id": "MDQ6VXNlcjMyMzEzOQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/323139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hannes-brt", "html_url": "https://github.com/hannes-brt", "followers_url": "https://api.github.com/users/hannes-brt/followers", "following_url": "https://api.github.com/users/hannes-brt/following{/other_user}", "gists_url": "https://api.github.com/users/hannes-brt/gists{/gist_id}", "starred_url": "https://api.github.com/users/hannes-brt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hannes-brt/subscriptions", "organizations_url": "https://api.github.com/users/hannes-brt/orgs", "repos_url": "https://api.github.com/users/hannes-brt/repos", "events_url": "https://api.github.com/users/hannes-brt/events{/privacy}", "received_events_url": "https://api.github.com/users/hannes-brt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2017-01-06T22:29:13Z", "updated_at": "2017-06-16T17:23:23Z", "closed_at": "2017-06-16T17:23:23Z", "author_association": "NONE", "body_html": "<p>I am storing my training examples as variable-length TFRecords using the following function for encoding:</p>\n<pre><code>def convert_to_tf_example(const_exonic_seq, const_intronic_seq,\n                          alt_exonic_seq, alt_intronic_seq,\n                          psi_distribution, psi_std,\n                          alt_ss_position, alt_ss_type,\n                          const_site_id, const_site_position,\n                          n_alt_ss, event_type):\n    \"\"\"Encode a COSSMO example as a TFRecord\"\"\"\n\n    assert len(alt_exonic_seq) == n_alt_ss\n    assert len(alt_intronic_seq) == n_alt_ss\n    # assert len(psi_distribution) == n_alt_ss\n    # assert len(psi_std) == n_alt_ss\n    assert event_type in ['acceptor', 'donor']\n    assert len(alt_ss_type) == n_alt_ss\n    assert all([t in ('annotated', 'gtex', 'maxent', 'hard_negative')\n                for t in alt_ss_type])\n\n    example = tf.train.SequenceExample(\n        context=tf.train.Features(feature={\n            'n_alt_ss': tf.train.Feature(\n                int64_list=tf.train.Int64List(value=[n_alt_ss])\n            ),\n            'event_type': tf.train.Feature(\n                bytes_list=tf.train.BytesList(value=[event_type])\n            ),\n            'const_seq': tf.train.Feature(\n                bytes_list=tf.train.BytesList(\n                    value=[const_exonic_seq, const_intronic_seq])\n            ),\n            'const_site_id': tf.train.Feature(\n                bytes_list=tf.train.BytesList(\n                    value=[const_site_id])\n            ),\n            'const_site_position': tf.train.Feature(\n                int64_list=tf.train.Int64List(\n                    value=[const_site_position])\n            )\n        }),\n        feature_lists=tf.train.FeatureLists(feature_list={\n            'alt_seq': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    bytes_list=tf.train.BytesList(value=[aes, ais])\n                ) for aes, ais in\n                         zip(alt_exonic_seq, alt_intronic_seq)]\n            ),\n            'psi': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    float_list=tf.train.FloatList(value=psi))\n                         for psi in psi_distribution]),\n            'psi_std': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    float_list=tf.train.FloatList(value=psi_sd))\n                         for psi_sd in psi_std]),\n            'alt_ss_position': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    int64_list=tf.train.Int64List(value=[pos]))\n                         for pos in alt_ss_position]),\n            'alt_ss_type': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    bytes_list=tf.train.BytesList(value=[t]))\n                        for t in alt_ss_type])\n        })\n    )\n    return example\n</code></pre>\n<p>The data stored here is genomic, but the details shouldn't matter.</p>\n<p>When I'm training, I use the following function to decode the TFRecords:</p>\n<pre><code>def read_single_cossmo_example(serialized_example, n_tissues):\n    \"\"\"Decode a single COSSMO example\"\"\"\n\n    decoded_features = tf.parse_single_sequence_example(\n        serialized_example,\n        context_features={\n            'n_alt_ss': tf.FixedLenFeature([], tf.int64),\n            'event_type': tf.FixedLenFeature([], tf.string),\n            'const_seq': tf.FixedLenFeature([2], tf.string),\n            'const_site_id': tf.FixedLenFeature([], tf.string),\n            'const_site_position': tf.FixedLenFeature([], tf.int64)\n        },\n        sequence_features={\n            'alt_seq': tf.FixedLenSequenceFeature([2], tf.string),\n            'psi': tf.FixedLenSequenceFeature([n_tissues], tf.float32),\n            'psi_std': tf.FixedLenSequenceFeature([n_tissues], tf.float32),\n            'alt_ss_position': tf.FixedLenSequenceFeature([], tf.int64),\n            'alt_ss_type': tf.FixedLenSequenceFeature([], tf.string)\n        }\n    )\n    return decoded_features\n</code></pre>\n<p>During training, I've been getting deadlocks with triple-digit CPU loads during training (running on a six-core i7) and I've isolated the problem to the above decoding function. A simple Tensorflow program like the following will reproduce the deadlock:</p>\n<pre><code> with tf.device('/cpu:0'):\n    filename_queue = tf.train.string_input_producer(\n        train_files, num_epochs=num_epochs, shuffle=shuffle)\n    file_reader = tf.TFRecordReader()\n    tf_record_key, serialized_example = file_reader.read(filename_queue)\n    decoded_example = read_single_cossmo_example(serialized_example,\n                                                  n_tissues)\n\nwith tf.Session() as sess:\n    sess.run(\n        tf.variables_initializer(\n            tf.global_variables() + tf.local_variables()\n        )\n    )\n\n    # Start queue runners\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        while not coord.should_stop():\n            fetch_vals = sess.run(decoded_example)\n    except tf.errors.OutOfRangeError:\n        pass\n    except KeyboardInterrupt:\n        print \"Training stopped by Ctrl+C.\"\n    finally:\n        coord.request_stop()\n    coord.join(threads)\n</code></pre>\n<p>Now, setting <code>intra_op_threads = 1</code> and <code>inter_op_threads = 1</code> will prevent the small script from deadlocking. However, even when restricting the thread pool I have run into deadlocks when using these TFRecords in long running training sessions, so I suspect there is a deeper issue.</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04</p>\n<p>Installed version of CUDA and cuDNN:<br>\nCUDA: 8.0<br>\ncuDNN: 5.1.5<br>\nIf installed from binary pip package, provide:<br>\n<a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp27-none-linux_x86_64.whl</a></p>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<h3>What other attempted solutions have you tried?</h3>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>", "body_text": "I am storing my training examples as variable-length TFRecords using the following function for encoding:\ndef convert_to_tf_example(const_exonic_seq, const_intronic_seq,\n                          alt_exonic_seq, alt_intronic_seq,\n                          psi_distribution, psi_std,\n                          alt_ss_position, alt_ss_type,\n                          const_site_id, const_site_position,\n                          n_alt_ss, event_type):\n    \"\"\"Encode a COSSMO example as a TFRecord\"\"\"\n\n    assert len(alt_exonic_seq) == n_alt_ss\n    assert len(alt_intronic_seq) == n_alt_ss\n    # assert len(psi_distribution) == n_alt_ss\n    # assert len(psi_std) == n_alt_ss\n    assert event_type in ['acceptor', 'donor']\n    assert len(alt_ss_type) == n_alt_ss\n    assert all([t in ('annotated', 'gtex', 'maxent', 'hard_negative')\n                for t in alt_ss_type])\n\n    example = tf.train.SequenceExample(\n        context=tf.train.Features(feature={\n            'n_alt_ss': tf.train.Feature(\n                int64_list=tf.train.Int64List(value=[n_alt_ss])\n            ),\n            'event_type': tf.train.Feature(\n                bytes_list=tf.train.BytesList(value=[event_type])\n            ),\n            'const_seq': tf.train.Feature(\n                bytes_list=tf.train.BytesList(\n                    value=[const_exonic_seq, const_intronic_seq])\n            ),\n            'const_site_id': tf.train.Feature(\n                bytes_list=tf.train.BytesList(\n                    value=[const_site_id])\n            ),\n            'const_site_position': tf.train.Feature(\n                int64_list=tf.train.Int64List(\n                    value=[const_site_position])\n            )\n        }),\n        feature_lists=tf.train.FeatureLists(feature_list={\n            'alt_seq': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    bytes_list=tf.train.BytesList(value=[aes, ais])\n                ) for aes, ais in\n                         zip(alt_exonic_seq, alt_intronic_seq)]\n            ),\n            'psi': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    float_list=tf.train.FloatList(value=psi))\n                         for psi in psi_distribution]),\n            'psi_std': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    float_list=tf.train.FloatList(value=psi_sd))\n                         for psi_sd in psi_std]),\n            'alt_ss_position': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    int64_list=tf.train.Int64List(value=[pos]))\n                         for pos in alt_ss_position]),\n            'alt_ss_type': tf.train.FeatureList(\n                feature=[tf.train.Feature(\n                    bytes_list=tf.train.BytesList(value=[t]))\n                        for t in alt_ss_type])\n        })\n    )\n    return example\n\nThe data stored here is genomic, but the details shouldn't matter.\nWhen I'm training, I use the following function to decode the TFRecords:\ndef read_single_cossmo_example(serialized_example, n_tissues):\n    \"\"\"Decode a single COSSMO example\"\"\"\n\n    decoded_features = tf.parse_single_sequence_example(\n        serialized_example,\n        context_features={\n            'n_alt_ss': tf.FixedLenFeature([], tf.int64),\n            'event_type': tf.FixedLenFeature([], tf.string),\n            'const_seq': tf.FixedLenFeature([2], tf.string),\n            'const_site_id': tf.FixedLenFeature([], tf.string),\n            'const_site_position': tf.FixedLenFeature([], tf.int64)\n        },\n        sequence_features={\n            'alt_seq': tf.FixedLenSequenceFeature([2], tf.string),\n            'psi': tf.FixedLenSequenceFeature([n_tissues], tf.float32),\n            'psi_std': tf.FixedLenSequenceFeature([n_tissues], tf.float32),\n            'alt_ss_position': tf.FixedLenSequenceFeature([], tf.int64),\n            'alt_ss_type': tf.FixedLenSequenceFeature([], tf.string)\n        }\n    )\n    return decoded_features\n\nDuring training, I've been getting deadlocks with triple-digit CPU loads during training (running on a six-core i7) and I've isolated the problem to the above decoding function. A simple Tensorflow program like the following will reproduce the deadlock:\n with tf.device('/cpu:0'):\n    filename_queue = tf.train.string_input_producer(\n        train_files, num_epochs=num_epochs, shuffle=shuffle)\n    file_reader = tf.TFRecordReader()\n    tf_record_key, serialized_example = file_reader.read(filename_queue)\n    decoded_example = read_single_cossmo_example(serialized_example,\n                                                  n_tissues)\n\nwith tf.Session() as sess:\n    sess.run(\n        tf.variables_initializer(\n            tf.global_variables() + tf.local_variables()\n        )\n    )\n\n    # Start queue runners\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        while not coord.should_stop():\n            fetch_vals = sess.run(decoded_example)\n    except tf.errors.OutOfRangeError:\n        pass\n    except KeyboardInterrupt:\n        print \"Training stopped by Ctrl+C.\"\n    finally:\n        coord.request_stop()\n    coord.join(threads)\n\nNow, setting intra_op_threads = 1 and inter_op_threads = 1 will prevent the small script from deadlocking. However, even when restricting the thread pool I have run into deadlocks when using these TFRecords in long running training sessions, so I suspect there is a deeper issue.\nEnvironment info\nOperating System: Ubuntu 14.04\nInstalled version of CUDA and cuDNN:\nCUDA: 8.0\ncuDNN: 5.1.5\nIf installed from binary pip package, provide:\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp27-none-linux_x86_64.whl\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nWhat other attempted solutions have you tried?\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).", "body": "I am storing my training examples as variable-length TFRecords using the following function for encoding:\r\n\r\n```\r\ndef convert_to_tf_example(const_exonic_seq, const_intronic_seq,\r\n                          alt_exonic_seq, alt_intronic_seq,\r\n                          psi_distribution, psi_std,\r\n                          alt_ss_position, alt_ss_type,\r\n                          const_site_id, const_site_position,\r\n                          n_alt_ss, event_type):\r\n    \"\"\"Encode a COSSMO example as a TFRecord\"\"\"\r\n\r\n    assert len(alt_exonic_seq) == n_alt_ss\r\n    assert len(alt_intronic_seq) == n_alt_ss\r\n    # assert len(psi_distribution) == n_alt_ss\r\n    # assert len(psi_std) == n_alt_ss\r\n    assert event_type in ['acceptor', 'donor']\r\n    assert len(alt_ss_type) == n_alt_ss\r\n    assert all([t in ('annotated', 'gtex', 'maxent', 'hard_negative')\r\n                for t in alt_ss_type])\r\n\r\n    example = tf.train.SequenceExample(\r\n        context=tf.train.Features(feature={\r\n            'n_alt_ss': tf.train.Feature(\r\n                int64_list=tf.train.Int64List(value=[n_alt_ss])\r\n            ),\r\n            'event_type': tf.train.Feature(\r\n                bytes_list=tf.train.BytesList(value=[event_type])\r\n            ),\r\n            'const_seq': tf.train.Feature(\r\n                bytes_list=tf.train.BytesList(\r\n                    value=[const_exonic_seq, const_intronic_seq])\r\n            ),\r\n            'const_site_id': tf.train.Feature(\r\n                bytes_list=tf.train.BytesList(\r\n                    value=[const_site_id])\r\n            ),\r\n            'const_site_position': tf.train.Feature(\r\n                int64_list=tf.train.Int64List(\r\n                    value=[const_site_position])\r\n            )\r\n        }),\r\n        feature_lists=tf.train.FeatureLists(feature_list={\r\n            'alt_seq': tf.train.FeatureList(\r\n                feature=[tf.train.Feature(\r\n                    bytes_list=tf.train.BytesList(value=[aes, ais])\r\n                ) for aes, ais in\r\n                         zip(alt_exonic_seq, alt_intronic_seq)]\r\n            ),\r\n            'psi': tf.train.FeatureList(\r\n                feature=[tf.train.Feature(\r\n                    float_list=tf.train.FloatList(value=psi))\r\n                         for psi in psi_distribution]),\r\n            'psi_std': tf.train.FeatureList(\r\n                feature=[tf.train.Feature(\r\n                    float_list=tf.train.FloatList(value=psi_sd))\r\n                         for psi_sd in psi_std]),\r\n            'alt_ss_position': tf.train.FeatureList(\r\n                feature=[tf.train.Feature(\r\n                    int64_list=tf.train.Int64List(value=[pos]))\r\n                         for pos in alt_ss_position]),\r\n            'alt_ss_type': tf.train.FeatureList(\r\n                feature=[tf.train.Feature(\r\n                    bytes_list=tf.train.BytesList(value=[t]))\r\n                        for t in alt_ss_type])\r\n        })\r\n    )\r\n    return example\r\n```\r\n\r\nThe data stored here is genomic, but the details shouldn't matter.\r\n\r\nWhen I'm training, I use the following function to decode the TFRecords:\r\n```\r\ndef read_single_cossmo_example(serialized_example, n_tissues):\r\n    \"\"\"Decode a single COSSMO example\"\"\"\r\n\r\n    decoded_features = tf.parse_single_sequence_example(\r\n        serialized_example,\r\n        context_features={\r\n            'n_alt_ss': tf.FixedLenFeature([], tf.int64),\r\n            'event_type': tf.FixedLenFeature([], tf.string),\r\n            'const_seq': tf.FixedLenFeature([2], tf.string),\r\n            'const_site_id': tf.FixedLenFeature([], tf.string),\r\n            'const_site_position': tf.FixedLenFeature([], tf.int64)\r\n        },\r\n        sequence_features={\r\n            'alt_seq': tf.FixedLenSequenceFeature([2], tf.string),\r\n            'psi': tf.FixedLenSequenceFeature([n_tissues], tf.float32),\r\n            'psi_std': tf.FixedLenSequenceFeature([n_tissues], tf.float32),\r\n            'alt_ss_position': tf.FixedLenSequenceFeature([], tf.int64),\r\n            'alt_ss_type': tf.FixedLenSequenceFeature([], tf.string)\r\n        }\r\n    )\r\n    return decoded_features\r\n```\r\n\r\nDuring training, I've been getting deadlocks with triple-digit CPU loads during training (running on a six-core i7) and I've isolated the problem to the above decoding function. A simple Tensorflow program like the following will reproduce the deadlock:\r\n\r\n```\r\n with tf.device('/cpu:0'):\r\n    filename_queue = tf.train.string_input_producer(\r\n        train_files, num_epochs=num_epochs, shuffle=shuffle)\r\n    file_reader = tf.TFRecordReader()\r\n    tf_record_key, serialized_example = file_reader.read(filename_queue)\r\n    decoded_example = read_single_cossmo_example(serialized_example,\r\n                                                  n_tissues)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(\r\n        tf.variables_initializer(\r\n            tf.global_variables() + tf.local_variables()\r\n        )\r\n    )\r\n\r\n    # Start queue runners\r\n    coord = tf.train.Coordinator()\r\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n    try:\r\n        while not coord.should_stop():\r\n            fetch_vals = sess.run(decoded_example)\r\n    except tf.errors.OutOfRangeError:\r\n        pass\r\n    except KeyboardInterrupt:\r\n        print \"Training stopped by Ctrl+C.\"\r\n    finally:\r\n        coord.request_stop()\r\n    coord.join(threads)\r\n```\r\n\r\nNow, setting `intra_op_threads = 1` and `inter_op_threads = 1` will prevent the small script from deadlocking. However, even when restricting the thread pool I have run into deadlocks when using these TFRecords in long running training sessions, so I suspect there is a deeper issue.\r\n\r\n### Environment info\r\nOperating System: Ubuntu 14.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\nCUDA: 8.0\r\ncuDNN: 5.1.5\r\nIf installed from binary pip package, provide:\r\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp27-none-linux_x86_64.whl\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n"}