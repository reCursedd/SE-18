{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8978", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8978/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8978/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8978/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8978", "id": 219591961, "node_id": "MDU6SXNzdWUyMTk1OTE5NjE=", "number": 8978, "title": "Synchronous Training using SyncReplicasOptimizer", "user": {"login": "tushar00jain", "id": 8455015, "node_id": "MDQ6VXNlcjg0NTUwMTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/8455015?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tushar00jain", "html_url": "https://github.com/tushar00jain", "followers_url": "https://api.github.com/users/tushar00jain/followers", "following_url": "https://api.github.com/users/tushar00jain/following{/other_user}", "gists_url": "https://api.github.com/users/tushar00jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/tushar00jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tushar00jain/subscriptions", "organizations_url": "https://api.github.com/users/tushar00jain/orgs", "repos_url": "https://api.github.com/users/tushar00jain/repos", "events_url": "https://api.github.com/users/tushar00jain/events{/privacy}", "received_events_url": "https://api.github.com/users/tushar00jain/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-04-05T13:58:01Z", "updated_at": "2017-04-13T18:06:57Z", "closed_at": "2017-04-05T17:13:30Z", "author_association": "NONE", "body_html": "<p>I'm trying to implement a synchronous distributed Recurrent Neural Network using TensorFlow on multiple servers. Here's the link to my code: <a href=\"https://github.com/tushar00jain/spark-ml/blob/master/rnn-sync.ipynb\">https://github.com/tushar00jain/spark-ml/blob/master/rnn-sync.ipynb</a>. I've also provided the relevant part below.</p>\n<p>I want the computations within the same batch to happen in parallel but I think it's still computing separate RNNs on each worker server and updating the parameters on the parameter server separately. I know this because I am printing the _current_state variable after I run the graph for each batch. Also, the _total_loss for the same global step is different on each worker server.</p>\n<p>I'm following the instructions provided at the following links: <a href=\"https://www.tensorflow.org/deploy/distributed#replicated_training\" rel=\"nofollow\">https://www.tensorflow.org/deploy/distributed#replicated_training</a> <a href=\"https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer</a></p>\n<p>Is this a bug or is there something wrong with my code?</p>\n<pre><code>    sess = sv.prepare_or_wait_for_session(server.target)\n    queue_runners = tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS)\n    sv.start_queue_runners(sess, queue_runners)\n\n    tf.logging.info('Started %d queues for processing input data.',\n                    len(queue_runners))\n\n    if is_chief:\n            sv.start_queue_runners(sess, chief_queue_runners)\n            sess.run(init_tokens_op)\n\n    print(\"{0} session ready\".format(datetime.now().isoformat()))\n    #####################################################################\n\n    ########################### training loop ###########################\n    _current_state = np.zeros((batch_size, state_size))\n    for batch_idx in range(args.steps):\n        if sv.should_stop() or tf_feed.should_stop():\n            break\n\n        batchX, batchY = feed_dict(tf_feed.next_batch(batch_size))\n\n        print('==========================================================')\n        print(_current_state)\n\n        if args.mode == \"train\":\n            _total_loss, _train_step, _current_state, _predictions_series, _global_step = sess.run(\n            [total_loss, train_step, current_state, predictions_series, global_step],\n            feed_dict={\n                batchX_placeholder:batchX,\n                batchY_placeholder:batchY,\n                init_state:_current_state\n            })\n\n            print(_global_step, batch_idx)\n            print(_current_state)\n            print('==========================================================')\n\n            if _global_step % 5 == 0:\n                print(\"Step\", _global_step, \"Loss\", _total_loss)  \n</code></pre>", "body_text": "I'm trying to implement a synchronous distributed Recurrent Neural Network using TensorFlow on multiple servers. Here's the link to my code: https://github.com/tushar00jain/spark-ml/blob/master/rnn-sync.ipynb. I've also provided the relevant part below.\nI want the computations within the same batch to happen in parallel but I think it's still computing separate RNNs on each worker server and updating the parameters on the parameter server separately. I know this because I am printing the _current_state variable after I run the graph for each batch. Also, the _total_loss for the same global step is different on each worker server.\nI'm following the instructions provided at the following links: https://www.tensorflow.org/deploy/distributed#replicated_training https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer\nIs this a bug or is there something wrong with my code?\n    sess = sv.prepare_or_wait_for_session(server.target)\n    queue_runners = tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS)\n    sv.start_queue_runners(sess, queue_runners)\n\n    tf.logging.info('Started %d queues for processing input data.',\n                    len(queue_runners))\n\n    if is_chief:\n            sv.start_queue_runners(sess, chief_queue_runners)\n            sess.run(init_tokens_op)\n\n    print(\"{0} session ready\".format(datetime.now().isoformat()))\n    #####################################################################\n\n    ########################### training loop ###########################\n    _current_state = np.zeros((batch_size, state_size))\n    for batch_idx in range(args.steps):\n        if sv.should_stop() or tf_feed.should_stop():\n            break\n\n        batchX, batchY = feed_dict(tf_feed.next_batch(batch_size))\n\n        print('==========================================================')\n        print(_current_state)\n\n        if args.mode == \"train\":\n            _total_loss, _train_step, _current_state, _predictions_series, _global_step = sess.run(\n            [total_loss, train_step, current_state, predictions_series, global_step],\n            feed_dict={\n                batchX_placeholder:batchX,\n                batchY_placeholder:batchY,\n                init_state:_current_state\n            })\n\n            print(_global_step, batch_idx)\n            print(_current_state)\n            print('==========================================================')\n\n            if _global_step % 5 == 0:\n                print(\"Step\", _global_step, \"Loss\", _total_loss)", "body": "I'm trying to implement a synchronous distributed Recurrent Neural Network using TensorFlow on multiple servers. Here's the link to my code: https://github.com/tushar00jain/spark-ml/blob/master/rnn-sync.ipynb. I've also provided the relevant part below.\r\n\r\nI want the computations within the same batch to happen in parallel but I think it's still computing separate RNNs on each worker server and updating the parameters on the parameter server separately. I know this because I am printing the _current_state variable after I run the graph for each batch. Also, the _total_loss for the same global step is different on each worker server.\r\n\r\nI'm following the instructions provided at the following links: https://www.tensorflow.org/deploy/distributed#replicated_training https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer\r\n\r\nIs this a bug or is there something wrong with my code?\r\n\r\n        sess = sv.prepare_or_wait_for_session(server.target)\r\n        queue_runners = tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS)\r\n        sv.start_queue_runners(sess, queue_runners)\r\n\r\n        tf.logging.info('Started %d queues for processing input data.',\r\n                        len(queue_runners))\r\n\r\n        if is_chief:\r\n                sv.start_queue_runners(sess, chief_queue_runners)\r\n                sess.run(init_tokens_op)\r\n\r\n        print(\"{0} session ready\".format(datetime.now().isoformat()))\r\n        #####################################################################\r\n\r\n        ########################### training loop ###########################\r\n        _current_state = np.zeros((batch_size, state_size))\r\n        for batch_idx in range(args.steps):\r\n            if sv.should_stop() or tf_feed.should_stop():\r\n                break\r\n\r\n            batchX, batchY = feed_dict(tf_feed.next_batch(batch_size))\r\n\r\n            print('==========================================================')\r\n            print(_current_state)\r\n\r\n            if args.mode == \"train\":\r\n                _total_loss, _train_step, _current_state, _predictions_series, _global_step = sess.run(\r\n                [total_loss, train_step, current_state, predictions_series, global_step],\r\n                feed_dict={\r\n                    batchX_placeholder:batchX,\r\n                    batchY_placeholder:batchY,\r\n                    init_state:_current_state\r\n                })\r\n\r\n                print(_global_step, batch_idx)\r\n                print(_current_state)\r\n                print('==========================================================')\r\n\r\n                if _global_step % 5 == 0:\r\n                    print(\"Step\", _global_step, \"Loss\", _total_loss)  "}