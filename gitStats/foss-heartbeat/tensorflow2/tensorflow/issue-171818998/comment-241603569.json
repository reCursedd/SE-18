{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/241603569", "html_url": "https://github.com/tensorflow/tensorflow/issues/3891#issuecomment-241603569", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3891", "id": 241603569, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MTYwMzU2OQ==", "user": {"login": "vivounicorn", "id": 3362154, "node_id": "MDQ6VXNlcjMzNjIxNTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/3362154?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vivounicorn", "html_url": "https://github.com/vivounicorn", "followers_url": "https://api.github.com/users/vivounicorn/followers", "following_url": "https://api.github.com/users/vivounicorn/following{/other_user}", "gists_url": "https://api.github.com/users/vivounicorn/gists{/gist_id}", "starred_url": "https://api.github.com/users/vivounicorn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vivounicorn/subscriptions", "organizations_url": "https://api.github.com/users/vivounicorn/orgs", "repos_url": "https://api.github.com/users/vivounicorn/repos", "events_url": "https://api.github.com/users/vivounicorn/events{/privacy}", "received_events_url": "https://api.github.com/users/vivounicorn/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-23T01:47:27Z", "updated_at": "2016-08-23T01:47:27Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11547801\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/prb12\">@prb12</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5105569\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/suiyuan2009\">@suiyuan2009</a> thank you for your reply , my GPU is shared by 3 persons, so sometimes there has insufficient memory, but the low accuracy result is got when on exclusive resources.<br>\nso my point is why a low accuracy  result in the mnist dataset is got when running on a GPU. the following message is from <strong>mnist_cnn.py</strong> (a cnn example from tensorflow)<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15737127\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vincentvanhoucke\">@vincentvanhoucke</a></p>\n<blockquote>\n<p>(tensorflow)liyiran@seele:<del>/dllearning/mnist$ vim mnist_cnn.py<br>\n(tensorflow)liyiran@seele:</del>/dllearning/mnist$ python mnist_cnn.py<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally<br>\nUsing TensorFlow backend.<br>\nX_train shape: (60000, 28, 28, 1)<br>\n60000 train samples<br>\n10000 test samples<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: GeForce GTX 1070<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7845<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 7.92GiB<br>\nFree memory: 7.10GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)<br>\nTrain on 60000 samples, validate on 10000 samples<br>\nEpoch 1/12<br>\n60000/60000 [==============================] - 8s - loss: 2.3031 - acc: 0.1116 - val_loss: 2.3021 - val_acc: 0.1114<br>\nEpoch 2/12<br>\n60000/60000 [==============================] - 3s - loss: 2.3051 - acc: 0.1120 - val_loss: 2.3011 - val_acc: 0.1135<br>\nEpoch 3/12<br>\n60000/60000 [==============================] - 3s - loss: 2.3016 - acc: 0.1122 - val_loss: 2.3032 - val_acc: 0.1134<br>\nEpoch 4/12<br>\n60000/60000 [==============================] - 2s - loss: 2.3028 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135<br>\nEpoch 5/12<br>\n60000/60000 [==============================] - 2s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3025 - val_acc: 0.1134<br>\nEpoch 6/12<br>\n60000/60000 [==============================] - 2s - loss: 2.3023 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135<br>\nEpoch 7/12<br>\n60000/60000 [==============================] - 2s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135<br>\nEpoch 8/12<br>\n60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135<br>\nEpoch 9/12<br>\n60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3022 - val_acc: 0.1135<br>\nEpoch 10/12<br>\n60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135<br>\nEpoch 11/12<br>\n60000/60000 [==============================] - 3s - loss: 2.3012 - acc: 0.1123 - val_loss: 2.3028 - val_acc: 0.1135<br>\nEpoch 12/12<br>\n60000/60000 [==============================] - 3s - loss: 2.3014 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135<br>\nTest score: 2.30167105103<br>\nTest accuracy: 0.1135</p>\n</blockquote>\n<p>the code of mnist_cnn.py is:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\nnp.random.seed(<span class=\"pl-c1\">1337</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> for reproducibility</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> keras.datasets <span class=\"pl-k\">import</span> mnist\n<span class=\"pl-k\">from</span> keras.models <span class=\"pl-k\">import</span> Sequential\n<span class=\"pl-k\">from</span> keras.layers <span class=\"pl-k\">import</span> Dense, Dropout, Activation, Flatten\n<span class=\"pl-k\">from</span> keras.layers <span class=\"pl-k\">import</span> Convolution2D, MaxPooling2D\n<span class=\"pl-k\">from</span> keras.utils <span class=\"pl-k\">import</span> np_utils\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run</span>():\n  batch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">128</span>\n  nb_classes <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n  nb_epoch <span class=\"pl-k\">=</span> <span class=\"pl-c1\">12</span>\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> input image dimensions</span>\n  img_rows, img_cols <span class=\"pl-k\">=</span> <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> number of convolutional filters to use</span>\n  nb_filters <span class=\"pl-k\">=</span> <span class=\"pl-c1\">32</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> size of pooling area for max pooling</span>\n  nb_pool <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> convolution kernel size</span>\n  nb_conv <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\n\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> the data, shuffled and split between train and test sets</span>\n  (X_train, y_train), (X_test, y_test) <span class=\"pl-k\">=</span> mnist.load_data()\n\n  X_train <span class=\"pl-k\">=</span> X_train.reshape(X_train.shape[<span class=\"pl-c1\">0</span>], img_rows, img_cols, <span class=\"pl-c1\">1</span>)\n  X_test <span class=\"pl-k\">=</span> X_test.reshape(X_test.shape[<span class=\"pl-c1\">0</span>], img_rows, img_cols, <span class=\"pl-c1\">1</span>)\n  X_train <span class=\"pl-k\">=</span> X_train.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)\n  X_test <span class=\"pl-k\">=</span> X_test.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)\n  X_train <span class=\"pl-k\">/=</span> <span class=\"pl-c1\">255</span>\n  X_test <span class=\"pl-k\">/=</span> <span class=\"pl-c1\">255</span>\n  <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>X_train shape:<span class=\"pl-pds\">'</span></span>, X_train.shape)\n  <span class=\"pl-c1\">print</span>(X_train.shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-s\"><span class=\"pl-pds\">'</span>train samples<span class=\"pl-pds\">'</span></span>)\n  <span class=\"pl-c1\">print</span>(X_test.shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-s\"><span class=\"pl-pds\">'</span>test samples<span class=\"pl-pds\">'</span></span>)\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> convert class vectors to binary class matrices</span>\n  Y_train <span class=\"pl-k\">=</span> np_utils.to_categorical(y_train, nb_classes)\n  Y_test <span class=\"pl-k\">=</span> np_utils.to_categorical(y_test, nb_classes)\n\n  model <span class=\"pl-k\">=</span> Sequential()\n\n  model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n                          <span class=\"pl-v\">border_mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>valid<span class=\"pl-pds\">'</span></span>,\n                          <span class=\"pl-v\">input_shape</span><span class=\"pl-k\">=</span>(img_rows, img_cols, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">dim_ordering</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>tf<span class=\"pl-pds\">'</span></span>))\n  model.add(Activation(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>))\n  model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n  model.add(Activation(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>))\n  model.add(MaxPooling2D(<span class=\"pl-v\">pool_size</span><span class=\"pl-k\">=</span>(nb_pool, nb_pool)))\n  model.add(Dropout(<span class=\"pl-c1\">0.25</span>))\n\n  model.add(Flatten())\n  model.add(Dense(<span class=\"pl-c1\">128</span>))\n  model.add(Activation(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>))\n  model.add(Dropout(<span class=\"pl-c1\">0.5</span>))\n  model.add(Dense(nb_classes))\n  model.add(Activation(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>softmax<span class=\"pl-pds\">'</span></span>))\n\n  model.compile(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>categorical_crossentropy<span class=\"pl-pds\">'</span></span>,\n                <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>adadelta<span class=\"pl-pds\">'</span></span>,\n                <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>])\n\n  model.fit(X_train, Y_train, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size, <span class=\"pl-v\">nb_epoch</span><span class=\"pl-k\">=</span>nb_epoch,\n            <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">validation_data</span><span class=\"pl-k\">=</span>(X_test, Y_test))\n  score <span class=\"pl-k\">=</span> model.evaluate(X_test, Y_test, <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n  <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Test score:<span class=\"pl-pds\">'</span></span>, score[<span class=\"pl-c1\">0</span>])\n  <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Test accuracy:<span class=\"pl-pds\">'</span></span>, score[<span class=\"pl-c1\">1</span>])\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n  <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>): \n  <span class=\"pl-c\"><span class=\"pl-c\">#</span>with tf.device('/cpu:0'): </span>\n    run()</pre></div>\n<p>when i replace gpu by cpu, then the result is like this:</p>\n<blockquote>\n<p>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally<br>\nUsing TensorFlow backend.<br>\nX_train shape: (60000, 28, 28, 1)<br>\n60000 train samples<br>\n10000 test samples<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: GeForce GTX 1070<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7845<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 7.92GiB<br>\nFree memory: 7.10GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)<br>\nTrain on 60000 samples, validate on 10000 samples<br>\nEpoch 1/12<br>\n60000/60000 [==============================] - 65s - loss: 0.3884 - acc: 0.8818 - val_loss: 0.1009 - val_acc: 0.9686<br>\nEpoch 2/12<br>\n60000/60000 [==============================] - 71s - loss: 0.1462 - acc: 0.9561 - val_loss: 0.0661 - val_acc: 0.9793<br>\nEpoch 3/12<br>\n60000/60000 [==============================] - 69s - loss: 0.1109 - acc: 0.9672 - val_loss: 0.0541 - val_acc: 0.9828<br>\nEpoch 4/12<br>\n60000/60000 [==============================] - 66s - loss: 0.0903 - acc: 0.9734 - val_loss: 0.0498 - val_acc: 0.9840<br>\nEpoch 5/12<br>\n60000/60000 [==============================] - 68s - loss: 0.0826 - acc: 0.9759 - val_loss: 0.0421 - val_acc: 0.9863<br>\nEpoch 6/12<br>\n60000/60000 [==============================] - 67s - loss: 0.0734 - acc: 0.9786 - val_loss: 0.0383 - val_acc: 0.9871<br>\nEpoch 7/12<br>\n60000/60000 [==============================] - 68s - loss: 0.0659 - acc: 0.9802 - val_loss: 0.0373 - val_acc: 0.9879<br>\nEpoch 8/12<br>\n60000/60000 [==============================] - 66s - loss: 0.0622 - acc: 0.9818 - val_loss: 0.0348 - val_acc: 0.9883<br>\nEpoch 9/12<br>\n60000/60000 [==============================] - 66s - loss: 0.0574 - acc: 0.9826 - val_loss: 0.0361 - val_acc: 0.9880<br>\nEpoch 10/12<br>\n60000/60000 [==============================] - 66s - loss: 0.0538 - acc: 0.9843 - val_loss: 0.0331 - val_acc: 0.9888<br>\nEpoch 11/12<br>\n60000/60000 [==============================] - 66s - loss: 0.0520 - acc: 0.9843 - val_loss: 0.0311 - val_acc: 0.9900<br>\nEpoch 12/12<br>\n60000/60000 [==============================] - 64s - loss: 0.0495 - acc: 0.9849 - val_loss: 0.0311 - val_acc: 0.9901<br>\nTest score: 0.0310514848216<br>\nTest accuracy: 0.9901</p>\n</blockquote>", "body_text": "@prb12 @suiyuan2009 thank you for your reply , my GPU is shared by 3 persons, so sometimes there has insufficient memory, but the low accuracy result is got when on exclusive resources.\nso my point is why a low accuracy  result in the mnist dataset is got when running on a GPU. the following message is from mnist_cnn.py (a cnn example from tensorflow)\n@vrv @vincentvanhoucke\n\n(tensorflow)liyiran@seele:/dllearning/mnist$ vim mnist_cnn.py\n(tensorflow)liyiran@seele:/dllearning/mnist$ python mnist_cnn.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nUsing TensorFlow backend.\nX_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7845\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.10GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/12\n60000/60000 [==============================] - 8s - loss: 2.3031 - acc: 0.1116 - val_loss: 2.3021 - val_acc: 0.1114\nEpoch 2/12\n60000/60000 [==============================] - 3s - loss: 2.3051 - acc: 0.1120 - val_loss: 2.3011 - val_acc: 0.1135\nEpoch 3/12\n60000/60000 [==============================] - 3s - loss: 2.3016 - acc: 0.1122 - val_loss: 2.3032 - val_acc: 0.1134\nEpoch 4/12\n60000/60000 [==============================] - 2s - loss: 2.3028 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\nEpoch 5/12\n60000/60000 [==============================] - 2s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3025 - val_acc: 0.1134\nEpoch 6/12\n60000/60000 [==============================] - 2s - loss: 2.3023 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\nEpoch 7/12\n60000/60000 [==============================] - 2s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\nEpoch 8/12\n60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\nEpoch 9/12\n60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3022 - val_acc: 0.1135\nEpoch 10/12\n60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\nEpoch 11/12\n60000/60000 [==============================] - 3s - loss: 2.3012 - acc: 0.1123 - val_loss: 2.3028 - val_acc: 0.1135\nEpoch 12/12\n60000/60000 [==============================] - 3s - loss: 2.3014 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\nTest score: 2.30167105103\nTest accuracy: 0.1135\n\nthe code of mnist_cnn.py is:\nfrom __future__ import print_function\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\nimport tensorflow as tf\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\n\ndef run():\n  batch_size = 128\n  nb_classes = 10\n  nb_epoch = 12\n\n  # input image dimensions\n  img_rows, img_cols = 28, 28\n  # number of convolutional filters to use\n  nb_filters = 32\n  # size of pooling area for max pooling\n  nb_pool = 2\n  # convolution kernel size\n  nb_conv = 3\n\n\n  # the data, shuffled and split between train and test sets\n  (X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n  X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n  X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n  X_train = X_train.astype('float32')\n  X_test = X_test.astype('float32')\n  X_train /= 255\n  X_test /= 255\n  print('X_train shape:', X_train.shape)\n  print(X_train.shape[0], 'train samples')\n  print(X_test.shape[0], 'test samples')\n\n  # convert class vectors to binary class matrices\n  Y_train = np_utils.to_categorical(y_train, nb_classes)\n  Y_test = np_utils.to_categorical(y_test, nb_classes)\n\n  model = Sequential()\n\n  model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n                          border_mode='valid',\n                          input_shape=(img_rows, img_cols, 1), dim_ordering='tf'))\n  model.add(Activation('relu'))\n  model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n  model.add(Dropout(0.25))\n\n  model.add(Flatten())\n  model.add(Dense(128))\n  model.add(Activation('relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(nb_classes))\n  model.add(Activation('softmax'))\n\n  model.compile(loss='categorical_crossentropy',\n                optimizer='adadelta',\n                metrics=['accuracy'])\n\n  model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n            verbose=1, validation_data=(X_test, Y_test))\n  score = model.evaluate(X_test, Y_test, verbose=0)\n  print('Test score:', score[0])\n  print('Test accuracy:', score[1])\n\nif __name__ == \"__main__\":\n  with tf.device('/gpu:0'): \n  #with tf.device('/cpu:0'): \n    run()\nwhen i replace gpu by cpu, then the result is like this:\n\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nUsing TensorFlow backend.\nX_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7845\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.10GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/12\n60000/60000 [==============================] - 65s - loss: 0.3884 - acc: 0.8818 - val_loss: 0.1009 - val_acc: 0.9686\nEpoch 2/12\n60000/60000 [==============================] - 71s - loss: 0.1462 - acc: 0.9561 - val_loss: 0.0661 - val_acc: 0.9793\nEpoch 3/12\n60000/60000 [==============================] - 69s - loss: 0.1109 - acc: 0.9672 - val_loss: 0.0541 - val_acc: 0.9828\nEpoch 4/12\n60000/60000 [==============================] - 66s - loss: 0.0903 - acc: 0.9734 - val_loss: 0.0498 - val_acc: 0.9840\nEpoch 5/12\n60000/60000 [==============================] - 68s - loss: 0.0826 - acc: 0.9759 - val_loss: 0.0421 - val_acc: 0.9863\nEpoch 6/12\n60000/60000 [==============================] - 67s - loss: 0.0734 - acc: 0.9786 - val_loss: 0.0383 - val_acc: 0.9871\nEpoch 7/12\n60000/60000 [==============================] - 68s - loss: 0.0659 - acc: 0.9802 - val_loss: 0.0373 - val_acc: 0.9879\nEpoch 8/12\n60000/60000 [==============================] - 66s - loss: 0.0622 - acc: 0.9818 - val_loss: 0.0348 - val_acc: 0.9883\nEpoch 9/12\n60000/60000 [==============================] - 66s - loss: 0.0574 - acc: 0.9826 - val_loss: 0.0361 - val_acc: 0.9880\nEpoch 10/12\n60000/60000 [==============================] - 66s - loss: 0.0538 - acc: 0.9843 - val_loss: 0.0331 - val_acc: 0.9888\nEpoch 11/12\n60000/60000 [==============================] - 66s - loss: 0.0520 - acc: 0.9843 - val_loss: 0.0311 - val_acc: 0.9900\nEpoch 12/12\n60000/60000 [==============================] - 64s - loss: 0.0495 - acc: 0.9849 - val_loss: 0.0311 - val_acc: 0.9901\nTest score: 0.0310514848216\nTest accuracy: 0.9901", "body": "@prb12 @suiyuan2009 thank you for your reply , my GPU is shared by 3 persons, so sometimes there has insufficient memory, but the low accuracy result is got when on exclusive resources.\nso my point is why a low accuracy  result in the mnist dataset is got when running on a GPU. the following message is from **mnist_cnn.py** (a cnn example from tensorflow)\n@vrv @vincentvanhoucke \n\n> (tensorflow)liyiran@seele:~/dllearning/mnist$ vim mnist_cnn.py \n> (tensorflow)liyiran@seele:~/dllearning/mnist$ python mnist_cnn.py \n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n> Using TensorFlow backend.\n> X_train shape: (60000, 28, 28, 1)\n> 60000 train samples\n> 10000 test samples\n> I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \n> name: GeForce GTX 1070\n> major: 6 minor: 1 memoryClockRate (GHz) 1.7845\n> pciBusID 0000:01:00.0\n> Total memory: 7.92GiB\n> Free memory: 7.10GiB\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\n> Train on 60000 samples, validate on 10000 samples\n> Epoch 1/12\n> 60000/60000 [==============================] - 8s - loss: 2.3031 - acc: 0.1116 - val_loss: 2.3021 - val_acc: 0.1114\n> Epoch 2/12\n> 60000/60000 [==============================] - 3s - loss: 2.3051 - acc: 0.1120 - val_loss: 2.3011 - val_acc: 0.1135\n> Epoch 3/12\n> 60000/60000 [==============================] - 3s - loss: 2.3016 - acc: 0.1122 - val_loss: 2.3032 - val_acc: 0.1134\n> Epoch 4/12\n> 60000/60000 [==============================] - 2s - loss: 2.3028 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\n> Epoch 5/12\n> 60000/60000 [==============================] - 2s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3025 - val_acc: 0.1134\n> Epoch 6/12\n> 60000/60000 [==============================] - 2s - loss: 2.3023 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\n> Epoch 7/12\n> 60000/60000 [==============================] - 2s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n> Epoch 8/12\n> 60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n> Epoch 9/12\n> 60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3022 - val_acc: 0.1135\n> Epoch 10/12\n> 60000/60000 [==============================] - 3s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n> Epoch 11/12\n> 60000/60000 [==============================] - 3s - loss: 2.3012 - acc: 0.1123 - val_loss: 2.3028 - val_acc: 0.1135\n> Epoch 12/12\n> 60000/60000 [==============================] - 3s - loss: 2.3014 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\n> Test score: 2.30167105103\n> Test accuracy: 0.1135\n\nthe code of mnist_cnn.py is:\n\n``` python\nfrom __future__ import print_function\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\nimport tensorflow as tf\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\n\ndef run():\n  batch_size = 128\n  nb_classes = 10\n  nb_epoch = 12\n\n  # input image dimensions\n  img_rows, img_cols = 28, 28\n  # number of convolutional filters to use\n  nb_filters = 32\n  # size of pooling area for max pooling\n  nb_pool = 2\n  # convolution kernel size\n  nb_conv = 3\n\n\n  # the data, shuffled and split between train and test sets\n  (X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n  X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n  X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n  X_train = X_train.astype('float32')\n  X_test = X_test.astype('float32')\n  X_train /= 255\n  X_test /= 255\n  print('X_train shape:', X_train.shape)\n  print(X_train.shape[0], 'train samples')\n  print(X_test.shape[0], 'test samples')\n\n  # convert class vectors to binary class matrices\n  Y_train = np_utils.to_categorical(y_train, nb_classes)\n  Y_test = np_utils.to_categorical(y_test, nb_classes)\n\n  model = Sequential()\n\n  model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n                          border_mode='valid',\n                          input_shape=(img_rows, img_cols, 1), dim_ordering='tf'))\n  model.add(Activation('relu'))\n  model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n  model.add(Dropout(0.25))\n\n  model.add(Flatten())\n  model.add(Dense(128))\n  model.add(Activation('relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(nb_classes))\n  model.add(Activation('softmax'))\n\n  model.compile(loss='categorical_crossentropy',\n                optimizer='adadelta',\n                metrics=['accuracy'])\n\n  model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n            verbose=1, validation_data=(X_test, Y_test))\n  score = model.evaluate(X_test, Y_test, verbose=0)\n  print('Test score:', score[0])\n  print('Test accuracy:', score[1])\n\nif __name__ == \"__main__\":\n  with tf.device('/gpu:0'): \n  #with tf.device('/cpu:0'): \n    run()\n```\n\nwhen i replace gpu by cpu, then the result is like this:\n\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n> Using TensorFlow backend.\n> X_train shape: (60000, 28, 28, 1)\n> 60000 train samples\n> 10000 test samples\n> I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \n> name: GeForce GTX 1070\n> major: 6 minor: 1 memoryClockRate (GHz) 1.7845\n> pciBusID 0000:01:00.0\n> Total memory: 7.92GiB\n> Free memory: 7.10GiB\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\n> Train on 60000 samples, validate on 10000 samples\n> Epoch 1/12\n> 60000/60000 [==============================] - 65s - loss: 0.3884 - acc: 0.8818 - val_loss: 0.1009 - val_acc: 0.9686\n> Epoch 2/12\n> 60000/60000 [==============================] - 71s - loss: 0.1462 - acc: 0.9561 - val_loss: 0.0661 - val_acc: 0.9793\n> Epoch 3/12\n> 60000/60000 [==============================] - 69s - loss: 0.1109 - acc: 0.9672 - val_loss: 0.0541 - val_acc: 0.9828\n> Epoch 4/12\n> 60000/60000 [==============================] - 66s - loss: 0.0903 - acc: 0.9734 - val_loss: 0.0498 - val_acc: 0.9840\n> Epoch 5/12\n> 60000/60000 [==============================] - 68s - loss: 0.0826 - acc: 0.9759 - val_loss: 0.0421 - val_acc: 0.9863\n> Epoch 6/12\n> 60000/60000 [==============================] - 67s - loss: 0.0734 - acc: 0.9786 - val_loss: 0.0383 - val_acc: 0.9871\n> Epoch 7/12\n> 60000/60000 [==============================] - 68s - loss: 0.0659 - acc: 0.9802 - val_loss: 0.0373 - val_acc: 0.9879\n> Epoch 8/12\n> 60000/60000 [==============================] - 66s - loss: 0.0622 - acc: 0.9818 - val_loss: 0.0348 - val_acc: 0.9883\n> Epoch 9/12\n> 60000/60000 [==============================] - 66s - loss: 0.0574 - acc: 0.9826 - val_loss: 0.0361 - val_acc: 0.9880\n> Epoch 10/12\n> 60000/60000 [==============================] - 66s - loss: 0.0538 - acc: 0.9843 - val_loss: 0.0331 - val_acc: 0.9888\n> Epoch 11/12\n> 60000/60000 [==============================] - 66s - loss: 0.0520 - acc: 0.9843 - val_loss: 0.0311 - val_acc: 0.9900\n> Epoch 12/12\n> 60000/60000 [==============================] - 64s - loss: 0.0495 - acc: 0.9849 - val_loss: 0.0311 - val_acc: 0.9901\n> Test score: 0.0310514848216\n> Test accuracy: 0.9901\n"}