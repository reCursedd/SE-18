{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15267", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15267/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15267/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15267/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15267", "id": 280966768, "node_id": "MDU6SXNzdWUyODA5NjY3Njg=", "number": 15267, "title": "2017-12-11 17:53:55.834374: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Slice", "user": {"login": "121649982", "id": 5317102, "node_id": "MDQ6VXNlcjUzMTcxMDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5317102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/121649982", "html_url": "https://github.com/121649982", "followers_url": "https://api.github.com/users/121649982/followers", "following_url": "https://api.github.com/users/121649982/following{/other_user}", "gists_url": "https://api.github.com/users/121649982/gists{/gist_id}", "starred_url": "https://api.github.com/users/121649982/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/121649982/subscriptions", "organizations_url": "https://api.github.com/users/121649982/orgs", "repos_url": "https://api.github.com/users/121649982/repos", "events_url": "https://api.github.com/users/121649982/events{/privacy}", "received_events_url": "https://api.github.com/users/121649982/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2017-12-11T10:33:15Z", "updated_at": "2018-04-10T22:44:28Z", "closed_at": "2018-04-10T22:44:27Z", "author_association": "NONE", "body_html": "<p>System information<br>\n<a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<h3>System information</h3>\n<ul>\n<li>**OS Platform and Distribution **:Linux Ubuntu 16.04</li>\n<li>**TensorFlow installed from **:source</li>\n<li><strong>TensorFlow version ,installed from source</strong>:1.4</li>\n<li><strong>Python version</strong>:2.7</li>\n<li>**Bazel version :1.5</li>\n<li><strong>GCC/Compiler version</strong>: 5.4.0   20160609</li>\n<li><strong>cpu version(</strong>:Intel\u00ae Core\u2122 i5-7500 CPU @ 3.40GHz \u00d7 4<br>\nCUDA/cuDNN version<br>\nN/A<br>\nGPU model and memory<br>\nN/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>use this command:</p>\n<p>bazel-bin/tensorflow/contrib/lite/toco/toco  <br>\n--input_file=/home/liu/az/caffe-tensorflow-master/MobileNet/frozen_graph.pb <br>\n--input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE <br>\n--output_file=/home/liu/az/caffe-tensorflow-master/MobileNet/mobilenet.lite --inference_type=FLOAT <br>\n--inference_input_type=FLOAT --input_arrays=img <br>\n--output_arrays=prob --input_shapes=1,20,20,3</p>\n<p><strong>I am trying to convert a graph from frozen .pb to .lite format using toco, but I get this error:</strong></p>\n<p>2017-12-11 17:53:55.833614: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1046] Converting unsupported operation: Pack<br>\n2017-12-11 17:53:55.833891: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 40 operators, 58 arrays (0 quantized)<br>\n2017-12-11 17:53:55.834169: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 14 operators, 30 arrays (0 quantized)<br>\n2017-12-11 17:53:55.834226: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 14 operators, 30 arrays (0 quantized)<br>\n2017-12-11 17:53:55.834281: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312] Total transient array allocated size: 128000 bytes, theoretical optimal value: 128000 bytes.<br>\n2017-12-11 17:53:55.834374: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Slice<br>\nAborted (core dumped)</p>\n<p>who can tell me how to get rid of this error?</p>\n<h3>Source code / logs</h3>\n<h1>-<em>- coding: utf-8 -</em>-</h1>\n<p>import tensorflow as tf<br>\nimport tensorflow.contrib.lite.python.lite<br>\n#\u521b\u5efa\u4e00\u4e2a\u4ea4\u4e92\u5f0fSession<br>\nsess = tf.InteractiveSession()<br>\n#\u521b\u5efa\u4e24\u4e2a\u5360\u4f4d\u7b26\uff0cx\u4e3a\u8f93\u5165\u7f51\u7edc\u7684\u56fe\u50cf\uff0cy_\u4e3a\u8f93\u5165\u7f51\u7edc\u7684\u56fe\u50cf\u7c7b\u522b<br>\nx = tf.placeholder(name=\"img\",dtype=tf.float32, shape=[1,20,20,3])<br>\ny_ = tf.placeholder(name=\"output\",dtype=tf.float32, shape=[None, 2])<br>\n#\u6743\u91cd\u521d\u59cb\u5316\u51fd\u6570<br>\ndef weight_variable(shape):<br>\n#\u8f93\u51fa\u670d\u4ece\u622a\u5c3e\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u503c<br>\ninitial = tf.truncated_normal(shape, stddev=0.1)<br>\nreturn tf.Variable(initial)<br>\n#\u504f\u7f6e\u521d\u59cb\u5316\u51fd\u6570<br>\ndef bias_variable(shape):<br>\ninitial = tf.constant(0.1, shape=shape)<br>\nreturn tf.Variable(initial)<br>\n#\u521b\u5efa\u5377\u79efop<br>\n#x \u662f\u4e00\u4e2a4\u7ef4\u5f20\u91cf\uff0cshape\u4e3a[batch,height,width,channels]<br>\n#\u5377\u79ef\u6838\u79fb\u52a8\u6b65\u957f\u4e3a1\u3002\u586b\u5145\u7c7b\u578b\u4e3aSAME,\u53ef\u4ee5\u4e0d\u4e22\u5f03\u4efb\u4f55\u50cf\u7d20\u70b9<br>\ndef conv2d(x, W, type):<br>\nif type == \"SAME\":<br>\nreturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\")<br>\nelse:<br>\nreturn tf.nn.conv2d(x,W, strides=[1,1,1,1],padding=\"VALID\")</p>\n<p>#\u521b\u5efa\u6c60\u5316op<br>\n#\u91c7\u7528\u6700\u5927\u6c60\u5316\uff0c\u4e5f\u5c31\u662f\u53d6\u7a97\u53e3\u4e2d\u7684\u6700\u5927\u503c\u4f5c\u4e3a\u7ed3\u679c<br>\n#x \u662f\u4e00\u4e2a4\u7ef4\u5f20\u91cf\uff0cshape\u4e3a[batch,height,width,channels]<br>\n#ksize\u8868\u793apool\u7a97\u53e3\u5927\u5c0f\u4e3a2x2,\u4e5f\u5c31\u662f\u9ad82\uff0c\u5bbd2<br>\n#strides\uff0c\u8868\u793a\u5728height\u548cwidth\u7ef4\u5ea6\u4e0a\u7684\u6b65\u957f\u90fd\u4e3a2<br>\ndef max_pool_2x2(x):<br>\nreturn tf.nn.max_pool(x, ksize=[1,2,2,1],<br>\nstrides=[1,2,2,1], padding=\"SAME\")<br>\n#\u7b2c1\u5c42\uff0c\u5377\u79ef\u5c42<br>\nW_conv1 = weight_variable([3,3,3,16])<br>\nb_conv1 = bias_variable([16])</p>\n<p>#x_image = tf.reshape(x, [-1,20,20,3])<br>\nx_image = x;</p>\n<p>h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1,\"SAME\") + b_conv1)<br>\nW_conv2 = weight_variable([3,3,16,64])<br>\nb_conv2 = bias_variable([64])<br>\nh_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2,\"SAME\") + b_conv2)<br>\nh_pool1 = max_pool_2x2(h_conv2)</p>\n<p>W_conv3 = weight_variable([3,3,64,64])<br>\nb_conv3 = weight_variable([64])<br>\nh_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv3,\"SAME\") + b_conv3)</p>\n<p>h_pool2 = max_pool_2x2(h_conv3)</p>\n<p>W_conv4 = weight_variable([2,2,64,16])<br>\nb_conv4 = weight_variable([16])<br>\nh_conv4 = tf.nn.relu(conv2d(h_pool2, W_conv4,\"VALID\") + b_conv4)</p>\n<p>W_conv5 = weight_variable([3,3,16,2])<br>\nb_conv5 = weight_variable([2])<br>\nh_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5,\"VALID\") + b_conv5)</p>\n<p>h_pool3 = max_pool_2x2(h_conv5)</p>\n<p>y_conv = tf.nn.softmax(h_pool3,name=\"prob\")<br>\nout = tf.identity(y_conv, name=\"prob\")<br>\n#\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u4ea4\u53c9\u5892<br>\ncross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))</p>\n<p>#train op, \u4f7f\u7528ADAM\u4f18\u5316\u5668\u6765\u505a\u68af\u5ea6\u4e0b\u964d\u3002\u5b66\u4e60\u7387\u4e3a0.0001<br>\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</p>\n<p>#\u8bc4\u4f30\u6a21\u578b\uff0ctf.argmax\u80fd\u7ed9\u51fa\u67d0\u4e2atensor\u5bf9\u8c61\u5728\u67d0\u4e00\u7ef4\u4e0a\u6570\u636e\u6700\u5927\u503c\u7684\u7d22\u5f15\u3002<br>\n#\u56e0\u4e3a\u6807\u7b7e\u662f\u75310,1\u7ec4\u6210\u4e86one-hot vector\uff0c\u8fd4\u56de\u7684\u7d22\u5f15\u5c31\u662f\u6570\u503c\u4e3a1\u7684\u4f4d\u7f6e<br>\ncorrect_predict = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))</p>\n<p>#\u8ba1\u7b97\u6b63\u786e\u9884\u6d4b\u9879\u7684\u6bd4\u4f8b\uff0c\u56e0\u4e3atf.equal\u8fd4\u56de\u7684\u662f\u5e03\u5c14\u503c\uff0c<br>\n#\u4f7f\u7528tf.cast\u628a\u5e03\u5c14\u503c\u8f6c\u6362\u6210\u6d6e\u70b9\u6570\uff0c\u7136\u540e\u7528tf.reduce_mean\u6c42\u5e73\u5747\u503c<br>\naccuracy = tf.reduce_mean(tf.cast(correct_predict, \"float\"))<br>\nsaver=tf.train.Saver()<br>\n#\u521d\u59cb\u5316\u53d8\u91cf<br>\nwith tf.Session() as sess:<br>\nsess.run(tf.initialize_all_variables())<br>\nconstant_graph = tf.get_default_graph().as_graph_def()<br>\nwith tf.gfile.FastGFile('../MobileNet/' + 'mobile.pb', mode='wb') as f:<br>\nf.write(constant_graph.SerializeToString())<br>\nsaver.save(sess, \"../MobileNet/mobile.ckpt\")<br>\ntflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [x], [out])<br>\nopen(\"converteds_model.tflite\", \"wb\").write(tflite_model)</p>", "body_text": "System information\nhttps://stackoverflow.com/questions/tagged/tensorflow\nSystem information\n\n**OS Platform and Distribution **:Linux Ubuntu 16.04\n**TensorFlow installed from **:source\nTensorFlow version ,installed from source:1.4\nPython version:2.7\n**Bazel version :1.5\nGCC/Compiler version: 5.4.0   20160609\ncpu version(:Intel\u00ae Core\u2122 i5-7500 CPU @ 3.40GHz \u00d7 4\nCUDA/cuDNN version\nN/A\nGPU model and memory\nN/A\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nuse this command:\nbazel-bin/tensorflow/contrib/lite/toco/toco  \n--input_file=/home/liu/az/caffe-tensorflow-master/MobileNet/frozen_graph.pb \n--input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \n--output_file=/home/liu/az/caffe-tensorflow-master/MobileNet/mobilenet.lite --inference_type=FLOAT \n--inference_input_type=FLOAT --input_arrays=img \n--output_arrays=prob --input_shapes=1,20,20,3\nI am trying to convert a graph from frozen .pb to .lite format using toco, but I get this error:\n2017-12-11 17:53:55.833614: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1046] Converting unsupported operation: Pack\n2017-12-11 17:53:55.833891: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 40 operators, 58 arrays (0 quantized)\n2017-12-11 17:53:55.834169: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 14 operators, 30 arrays (0 quantized)\n2017-12-11 17:53:55.834226: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 14 operators, 30 arrays (0 quantized)\n2017-12-11 17:53:55.834281: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312] Total transient array allocated size: 128000 bytes, theoretical optimal value: 128000 bytes.\n2017-12-11 17:53:55.834374: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Slice\nAborted (core dumped)\nwho can tell me how to get rid of this error?\nSource code / logs\n-- coding: utf-8 --\nimport tensorflow as tf\nimport tensorflow.contrib.lite.python.lite\n#\u521b\u5efa\u4e00\u4e2a\u4ea4\u4e92\u5f0fSession\nsess = tf.InteractiveSession()\n#\u521b\u5efa\u4e24\u4e2a\u5360\u4f4d\u7b26\uff0cx\u4e3a\u8f93\u5165\u7f51\u7edc\u7684\u56fe\u50cf\uff0cy_\u4e3a\u8f93\u5165\u7f51\u7edc\u7684\u56fe\u50cf\u7c7b\u522b\nx = tf.placeholder(name=\"img\",dtype=tf.float32, shape=[1,20,20,3])\ny_ = tf.placeholder(name=\"output\",dtype=tf.float32, shape=[None, 2])\n#\u6743\u91cd\u521d\u59cb\u5316\u51fd\u6570\ndef weight_variable(shape):\n#\u8f93\u51fa\u670d\u4ece\u622a\u5c3e\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u503c\ninitial = tf.truncated_normal(shape, stddev=0.1)\nreturn tf.Variable(initial)\n#\u504f\u7f6e\u521d\u59cb\u5316\u51fd\u6570\ndef bias_variable(shape):\ninitial = tf.constant(0.1, shape=shape)\nreturn tf.Variable(initial)\n#\u521b\u5efa\u5377\u79efop\n#x \u662f\u4e00\u4e2a4\u7ef4\u5f20\u91cf\uff0cshape\u4e3a[batch,height,width,channels]\n#\u5377\u79ef\u6838\u79fb\u52a8\u6b65\u957f\u4e3a1\u3002\u586b\u5145\u7c7b\u578b\u4e3aSAME,\u53ef\u4ee5\u4e0d\u4e22\u5f03\u4efb\u4f55\u50cf\u7d20\u70b9\ndef conv2d(x, W, type):\nif type == \"SAME\":\nreturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\")\nelse:\nreturn tf.nn.conv2d(x,W, strides=[1,1,1,1],padding=\"VALID\")\n#\u521b\u5efa\u6c60\u5316op\n#\u91c7\u7528\u6700\u5927\u6c60\u5316\uff0c\u4e5f\u5c31\u662f\u53d6\u7a97\u53e3\u4e2d\u7684\u6700\u5927\u503c\u4f5c\u4e3a\u7ed3\u679c\n#x \u662f\u4e00\u4e2a4\u7ef4\u5f20\u91cf\uff0cshape\u4e3a[batch,height,width,channels]\n#ksize\u8868\u793apool\u7a97\u53e3\u5927\u5c0f\u4e3a2x2,\u4e5f\u5c31\u662f\u9ad82\uff0c\u5bbd2\n#strides\uff0c\u8868\u793a\u5728height\u548cwidth\u7ef4\u5ea6\u4e0a\u7684\u6b65\u957f\u90fd\u4e3a2\ndef max_pool_2x2(x):\nreturn tf.nn.max_pool(x, ksize=[1,2,2,1],\nstrides=[1,2,2,1], padding=\"SAME\")\n#\u7b2c1\u5c42\uff0c\u5377\u79ef\u5c42\nW_conv1 = weight_variable([3,3,3,16])\nb_conv1 = bias_variable([16])\n#x_image = tf.reshape(x, [-1,20,20,3])\nx_image = x;\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1,\"SAME\") + b_conv1)\nW_conv2 = weight_variable([3,3,16,64])\nb_conv2 = bias_variable([64])\nh_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2,\"SAME\") + b_conv2)\nh_pool1 = max_pool_2x2(h_conv2)\nW_conv3 = weight_variable([3,3,64,64])\nb_conv3 = weight_variable([64])\nh_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv3,\"SAME\") + b_conv3)\nh_pool2 = max_pool_2x2(h_conv3)\nW_conv4 = weight_variable([2,2,64,16])\nb_conv4 = weight_variable([16])\nh_conv4 = tf.nn.relu(conv2d(h_pool2, W_conv4,\"VALID\") + b_conv4)\nW_conv5 = weight_variable([3,3,16,2])\nb_conv5 = weight_variable([2])\nh_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5,\"VALID\") + b_conv5)\nh_pool3 = max_pool_2x2(h_conv5)\ny_conv = tf.nn.softmax(h_pool3,name=\"prob\")\nout = tf.identity(y_conv, name=\"prob\")\n#\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u4ea4\u53c9\u5892\ncross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n#train op, \u4f7f\u7528ADAM\u4f18\u5316\u5668\u6765\u505a\u68af\u5ea6\u4e0b\u964d\u3002\u5b66\u4e60\u7387\u4e3a0.0001\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n#\u8bc4\u4f30\u6a21\u578b\uff0ctf.argmax\u80fd\u7ed9\u51fa\u67d0\u4e2atensor\u5bf9\u8c61\u5728\u67d0\u4e00\u7ef4\u4e0a\u6570\u636e\u6700\u5927\u503c\u7684\u7d22\u5f15\u3002\n#\u56e0\u4e3a\u6807\u7b7e\u662f\u75310,1\u7ec4\u6210\u4e86one-hot vector\uff0c\u8fd4\u56de\u7684\u7d22\u5f15\u5c31\u662f\u6570\u503c\u4e3a1\u7684\u4f4d\u7f6e\ncorrect_predict = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n#\u8ba1\u7b97\u6b63\u786e\u9884\u6d4b\u9879\u7684\u6bd4\u4f8b\uff0c\u56e0\u4e3atf.equal\u8fd4\u56de\u7684\u662f\u5e03\u5c14\u503c\uff0c\n#\u4f7f\u7528tf.cast\u628a\u5e03\u5c14\u503c\u8f6c\u6362\u6210\u6d6e\u70b9\u6570\uff0c\u7136\u540e\u7528tf.reduce_mean\u6c42\u5e73\u5747\u503c\naccuracy = tf.reduce_mean(tf.cast(correct_predict, \"float\"))\nsaver=tf.train.Saver()\n#\u521d\u59cb\u5316\u53d8\u91cf\nwith tf.Session() as sess:\nsess.run(tf.initialize_all_variables())\nconstant_graph = tf.get_default_graph().as_graph_def()\nwith tf.gfile.FastGFile('../MobileNet/' + 'mobile.pb', mode='wb') as f:\nf.write(constant_graph.SerializeToString())\nsaver.save(sess, \"../MobileNet/mobile.ckpt\")\ntflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [x], [out])\nopen(\"converteds_model.tflite\", \"wb\").write(tflite_model)", "body": "System information\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n### System information\r\n- **OS Platform and Distribution **:Linux Ubuntu 16.04\r\n- **TensorFlow installed from **:source\r\n- **TensorFlow version ,installed from source**:1.4\r\n- **Python version**:2.7 \r\n- **Bazel version :1.5\r\n- **GCC/Compiler version**: 5.4.0   20160609\r\n- **cpu version(**:Intel\u00ae Core\u2122 i5-7500 CPU @ 3.40GHz \u00d7 4\r\nCUDA/cuDNN version\r\nN/A\r\nGPU model and memory\r\nN/A\r\n- **Exact command to reproduce**:\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nuse this command:\r\n\r\nbazel-bin/tensorflow/contrib/lite/toco/toco  \\\r\n--input_file=/home/liu/az/caffe-tensorflow-master/MobileNet/frozen_graph.pb \\\r\n--input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\r\n--output_file=/home/liu/az/caffe-tensorflow-master/MobileNet/mobilenet.lite --inference_type=FLOAT \\\r\n--inference_input_type=FLOAT --input_arrays=img \\\r\n--output_arrays=prob --input_shapes=1,20,20,3\r\n\r\n**I am trying to convert a graph from frozen .pb to .lite format using toco, but I get this error:**\r\n\r\n2017-12-11 17:53:55.833614: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1046] Converting unsupported operation: Pack\r\n2017-12-11 17:53:55.833891: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 40 operators, 58 arrays (0 quantized)\r\n2017-12-11 17:53:55.834169: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 14 operators, 30 arrays (0 quantized)\r\n2017-12-11 17:53:55.834226: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 14 operators, 30 arrays (0 quantized)\r\n2017-12-11 17:53:55.834281: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312] Total transient array allocated size: 128000 bytes, theoretical optimal value: 128000 bytes.\r\n2017-12-11 17:53:55.834374: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Slice\r\nAborted (core dumped)\r\n\r\nwho can tell me how to get rid of this error?\r\n\r\n### Source code / logs\r\n\r\n# -*- coding: utf-8 -*-\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.lite.python.lite\r\n#\u521b\u5efa\u4e00\u4e2a\u4ea4\u4e92\u5f0fSession\r\nsess = tf.InteractiveSession()\r\n#\u521b\u5efa\u4e24\u4e2a\u5360\u4f4d\u7b26\uff0cx\u4e3a\u8f93\u5165\u7f51\u7edc\u7684\u56fe\u50cf\uff0cy_\u4e3a\u8f93\u5165\u7f51\u7edc\u7684\u56fe\u50cf\u7c7b\u522b\r\nx = tf.placeholder(name=\"img\",dtype=tf.float32, shape=[1,20,20,3])\r\ny_ = tf.placeholder(name=\"output\",dtype=tf.float32, shape=[None, 2])\r\n#\u6743\u91cd\u521d\u59cb\u5316\u51fd\u6570\r\ndef weight_variable(shape):\r\n    #\u8f93\u51fa\u670d\u4ece\u622a\u5c3e\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u503c\r\n    initial = tf.truncated_normal(shape, stddev=0.1)\r\n    return tf.Variable(initial)\r\n#\u504f\u7f6e\u521d\u59cb\u5316\u51fd\u6570\r\ndef bias_variable(shape):\r\n    initial = tf.constant(0.1, shape=shape)\r\n    return tf.Variable(initial)\r\n#\u521b\u5efa\u5377\u79efop\r\n#x \u662f\u4e00\u4e2a4\u7ef4\u5f20\u91cf\uff0cshape\u4e3a[batch,height,width,channels]\r\n#\u5377\u79ef\u6838\u79fb\u52a8\u6b65\u957f\u4e3a1\u3002\u586b\u5145\u7c7b\u578b\u4e3aSAME,\u53ef\u4ee5\u4e0d\u4e22\u5f03\u4efb\u4f55\u50cf\u7d20\u70b9\r\ndef conv2d(x, W, type):\r\n    if type == \"SAME\":\r\n        return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\")\r\n    else:\r\n        return tf.nn.conv2d(x,W, strides=[1,1,1,1],padding=\"VALID\")\r\n\r\n#\u521b\u5efa\u6c60\u5316op\r\n#\u91c7\u7528\u6700\u5927\u6c60\u5316\uff0c\u4e5f\u5c31\u662f\u53d6\u7a97\u53e3\u4e2d\u7684\u6700\u5927\u503c\u4f5c\u4e3a\u7ed3\u679c\r\n#x \u662f\u4e00\u4e2a4\u7ef4\u5f20\u91cf\uff0cshape\u4e3a[batch,height,width,channels]\r\n#ksize\u8868\u793apool\u7a97\u53e3\u5927\u5c0f\u4e3a2x2,\u4e5f\u5c31\u662f\u9ad82\uff0c\u5bbd2\r\n#strides\uff0c\u8868\u793a\u5728height\u548cwidth\u7ef4\u5ea6\u4e0a\u7684\u6b65\u957f\u90fd\u4e3a2\r\ndef max_pool_2x2(x):\r\n    return tf.nn.max_pool(x, ksize=[1,2,2,1],\r\n                          strides=[1,2,2,1], padding=\"SAME\")\r\n#\u7b2c1\u5c42\uff0c\u5377\u79ef\u5c42\r\nW_conv1 = weight_variable([3,3,3,16])\r\nb_conv1 = bias_variable([16])\r\n\r\n#x_image = tf.reshape(x, [-1,20,20,3])\r\nx_image = x;\r\n\r\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1,\"SAME\") + b_conv1)\r\nW_conv2 = weight_variable([3,3,16,64])\r\nb_conv2 = bias_variable([64])\r\nh_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2,\"SAME\") + b_conv2)\r\nh_pool1 = max_pool_2x2(h_conv2)\r\n\r\n\r\nW_conv3 = weight_variable([3,3,64,64])\r\nb_conv3 = weight_variable([64])\r\nh_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv3,\"SAME\") + b_conv3)\r\n\r\nh_pool2 = max_pool_2x2(h_conv3)\r\n\r\nW_conv4 = weight_variable([2,2,64,16])\r\nb_conv4 = weight_variable([16])\r\nh_conv4 = tf.nn.relu(conv2d(h_pool2, W_conv4,\"VALID\") + b_conv4)\r\n\r\nW_conv5 = weight_variable([3,3,16,2])\r\nb_conv5 = weight_variable([2])\r\nh_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5,\"VALID\") + b_conv5)\r\n\r\nh_pool3 = max_pool_2x2(h_conv5)\r\n\r\ny_conv = tf.nn.softmax(h_pool3,name=\"prob\")\r\nout = tf.identity(y_conv, name=\"prob\")\r\n#\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u4ea4\u53c9\u5892\r\ncross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\r\n\r\n#train op, \u4f7f\u7528ADAM\u4f18\u5316\u5668\u6765\u505a\u68af\u5ea6\u4e0b\u964d\u3002\u5b66\u4e60\u7387\u4e3a0.0001\r\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\r\n\r\n#\u8bc4\u4f30\u6a21\u578b\uff0ctf.argmax\u80fd\u7ed9\u51fa\u67d0\u4e2atensor\u5bf9\u8c61\u5728\u67d0\u4e00\u7ef4\u4e0a\u6570\u636e\u6700\u5927\u503c\u7684\u7d22\u5f15\u3002\r\n#\u56e0\u4e3a\u6807\u7b7e\u662f\u75310,1\u7ec4\u6210\u4e86one-hot vector\uff0c\u8fd4\u56de\u7684\u7d22\u5f15\u5c31\u662f\u6570\u503c\u4e3a1\u7684\u4f4d\u7f6e\r\ncorrect_predict = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\r\n\r\n#\u8ba1\u7b97\u6b63\u786e\u9884\u6d4b\u9879\u7684\u6bd4\u4f8b\uff0c\u56e0\u4e3atf.equal\u8fd4\u56de\u7684\u662f\u5e03\u5c14\u503c\uff0c\r\n#\u4f7f\u7528tf.cast\u628a\u5e03\u5c14\u503c\u8f6c\u6362\u6210\u6d6e\u70b9\u6570\uff0c\u7136\u540e\u7528tf.reduce_mean\u6c42\u5e73\u5747\u503c\r\naccuracy = tf.reduce_mean(tf.cast(correct_predict, \"float\"))\r\nsaver=tf.train.Saver()\r\n#\u521d\u59cb\u5316\u53d8\u91cf\r\nwith tf.Session() as sess:\r\n    sess.run(tf.initialize_all_variables())\r\n    constant_graph = tf.get_default_graph().as_graph_def()\r\n    with tf.gfile.FastGFile('../MobileNet/' + 'mobile.pb', mode='wb') as f:\r\n        f.write(constant_graph.SerializeToString())\r\n        saver.save(sess, \"../MobileNet/mobile.ckpt\")\r\n    tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [x], [out])\r\n    open(\"converteds_model.tflite\", \"wb\").write(tflite_model)\r\n"}