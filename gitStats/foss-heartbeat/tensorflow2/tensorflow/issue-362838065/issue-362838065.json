{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22463", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22463/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22463/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22463/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22463", "id": 362838065, "node_id": "MDU6SXNzdWUzNjI4MzgwNjU=", "number": 22463, "title": "Tensorflow mystique bug with MirroredStrategy freeze on particular local GPU combo", "user": {"login": "rr4rr", "id": 5888135, "node_id": "MDQ6VXNlcjU4ODgxMzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/5888135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rr4rr", "html_url": "https://github.com/rr4rr", "followers_url": "https://api.github.com/users/rr4rr/followers", "following_url": "https://api.github.com/users/rr4rr/following{/other_user}", "gists_url": "https://api.github.com/users/rr4rr/gists{/gist_id}", "starred_url": "https://api.github.com/users/rr4rr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rr4rr/subscriptions", "organizations_url": "https://api.github.com/users/rr4rr/orgs", "repos_url": "https://api.github.com/users/rr4rr/repos", "events_url": "https://api.github.com/users/rr4rr/events{/privacy}", "received_events_url": "https://api.github.com/users/rr4rr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-09-22T08:28:13Z", "updated_at": "2018-09-24T05:59:31Z", "closed_at": "2018-09-24T05:59:30Z", "author_association": "NONE", "body_html": "<p><a href=\"https://stackoverflow.com/questions/52425485/tensorflow-mirroredstrategy-freeze-on-particular-gpu-combo\" rel=\"nofollow\">https://stackoverflow.com/questions/52425485/tensorflow-mirroredstrategy-freeze-on-particular-gpu-combo</a></p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 18.04 host Linux Ubuntu 16.04 inside Docker container</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source and binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.1 - 1.11.rc1</li>\n<li><strong>Python version</strong>: 3.5 - 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.17.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0, 9,2/7.2</li>\n<li><strong>GPU model and memory</strong>:<br>\n(0) Nvidia Titan x 980 12gb<br>\n(1) Nvidia Titan x 980 12gb (same)<br>\n(2) Nvidia 1080ti 11gb<br>\n(3) Nvidia 1080ti 11gb (same)</li>\n<li><strong>Exact command to reproduce</strong>: example source below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Four GPUs on the same desktop:</p>\n<p>(0) Nvidia Titan x 980 12gb<br>\n(1) Nvidia Titan x 980 12gb (same)<br>\n(2) Nvidia 1080ti 11gb<br>\n(3) Nvidia 1080ti 11gb (same)</p>\n<p>MirroredStrategy (say from the obvious example code below) goes ok in combinations of the above (1,2), (1,3) but freezes on (2,3), (1,2,3).<br>\n(0 - not used at distribution as causes another sort of CUDA_WAIT_TIMEOUT error due to guessed kernel timeouts for being used to render display)</p>\n<p>Have no idea where to go further. Checked with original binary docker images both latest and nightly. Checked with compiled from source TensorFlow r1.10-r1.11 within original nvidia/cuda binary docker image. All the same behaviour.</p>\n<h3>Source code / logs</h3>\n<pre><code>import os\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\nos.environ['CUDA_VISIBLE_DEVICES']=\"2,3\"\n\nimport tensorflow as tf \n\ndef model_fn(features, labels, mode):\n  layer = tf.layers.Dense(1)\n  logits = layer(features)\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {\"logits\": logits}\n    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n  loss = tf.losses.mean_squared_error(\n               labels=labels, predictions=tf.reshape(logits, []))\n\n  if mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    train_op = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\ndef input_fn():\n  features = tf.data.Dataset.from_tensors([[1.]]).repeat(100)\n  labels = tf.data.Dataset.from_tensors(1.).repeat(100)\n  return tf.data.Dataset.zip((features, labels))\n\ndistribution = tf.contrib.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\nclassifier = tf.estimator.Estimator(model_fn=model_fn, config=config)\n\nclassifier.train(input_fn=input_fn)\n\nclassifier.evaluate(input_fn=input_fn)\n</code></pre>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/2407611/freeze_output_r1.10.txt\">freeze_output_r1.10.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2407612/freeze_output_r1.11.txt\">freeze_output_r1.11.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2407613/normal_completion_output_r1.10.1.txt\">normal_completion_output_r1.10.1.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2407614/normal_completion_output_r1.11.txt\">normal_completion_output_r1.11.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2407615/tf_env_r1.10.1.txt\">tf_env_r1.10.1.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2407616/tf_env_r1.11.txt\">tf_env_r1.11.txt</a></p>", "body_text": "https://stackoverflow.com/questions/52425485/tensorflow-mirroredstrategy-freeze-on-particular-gpu-combo\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 host Linux Ubuntu 16.04 inside Docker container\nTensorFlow installed from (source or binary): source and binary\nTensorFlow version (use command below): 1.10.1 - 1.11.rc1\nPython version: 3.5 - 3.6\nBazel version (if compiling from source): 0.17.1\nGCC/Compiler version (if compiling from source): 5\nCUDA/cuDNN version: 9.0, 9,2/7.2\nGPU model and memory:\n(0) Nvidia Titan x 980 12gb\n(1) Nvidia Titan x 980 12gb (same)\n(2) Nvidia 1080ti 11gb\n(3) Nvidia 1080ti 11gb (same)\nExact command to reproduce: example source below\n\nDescribe the problem\nFour GPUs on the same desktop:\n(0) Nvidia Titan x 980 12gb\n(1) Nvidia Titan x 980 12gb (same)\n(2) Nvidia 1080ti 11gb\n(3) Nvidia 1080ti 11gb (same)\nMirroredStrategy (say from the obvious example code below) goes ok in combinations of the above (1,2), (1,3) but freezes on (2,3), (1,2,3).\n(0 - not used at distribution as causes another sort of CUDA_WAIT_TIMEOUT error due to guessed kernel timeouts for being used to render display)\nHave no idea where to go further. Checked with original binary docker images both latest and nightly. Checked with compiled from source TensorFlow r1.10-r1.11 within original nvidia/cuda binary docker image. All the same behaviour.\nSource code / logs\nimport os\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\nos.environ['CUDA_VISIBLE_DEVICES']=\"2,3\"\n\nimport tensorflow as tf \n\ndef model_fn(features, labels, mode):\n  layer = tf.layers.Dense(1)\n  logits = layer(features)\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {\"logits\": logits}\n    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n  loss = tf.losses.mean_squared_error(\n               labels=labels, predictions=tf.reshape(logits, []))\n\n  if mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(mode, loss=loss)\n\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    train_op = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\ndef input_fn():\n  features = tf.data.Dataset.from_tensors([[1.]]).repeat(100)\n  labels = tf.data.Dataset.from_tensors(1.).repeat(100)\n  return tf.data.Dataset.zip((features, labels))\n\ndistribution = tf.contrib.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\nclassifier = tf.estimator.Estimator(model_fn=model_fn, config=config)\n\nclassifier.train(input_fn=input_fn)\n\nclassifier.evaluate(input_fn=input_fn)\n\nfreeze_output_r1.10.txt\nfreeze_output_r1.11.txt\nnormal_completion_output_r1.10.1.txt\nnormal_completion_output_r1.11.txt\ntf_env_r1.10.1.txt\ntf_env_r1.11.txt", "body": "https://stackoverflow.com/questions/52425485/tensorflow-mirroredstrategy-freeze-on-particular-gpu-combo\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04 host Linux Ubuntu 16.04 inside Docker container\r\n- **TensorFlow installed from (source or binary)**: source and binary\r\n- **TensorFlow version (use command below)**: 1.10.1 - 1.11.rc1\r\n- **Python version**: 3.5 - 3.6\r\n- **Bazel version (if compiling from source)**: 0.17.1\r\n- **GCC/Compiler version (if compiling from source)**: 5\r\n- **CUDA/cuDNN version**: 9.0, 9,2/7.2\r\n- **GPU model and memory**: \r\n    (0) Nvidia Titan x 980 12gb\r\n    (1) Nvidia Titan x 980 12gb (same)\r\n    (2) Nvidia 1080ti 11gb\r\n    (3) Nvidia 1080ti 11gb (same)\r\n- **Exact command to reproduce**: example source below\r\n\r\n\r\n### Describe the problem\r\nFour GPUs on the same desktop:\r\n\r\n(0) Nvidia Titan x 980 12gb\r\n(1) Nvidia Titan x 980 12gb (same)\r\n(2) Nvidia 1080ti 11gb\r\n(3) Nvidia 1080ti 11gb (same)\r\n\r\nMirroredStrategy (say from the obvious example code below) goes ok in combinations of the above (1,2), (1,3) but freezes on (2,3), (1,2,3). \r\n(0 - not used at distribution as causes another sort of CUDA_WAIT_TIMEOUT error due to guessed kernel timeouts for being used to render display)\r\n\r\nHave no idea where to go further. Checked with original binary docker images both latest and nightly. Checked with compiled from source TensorFlow r1.10-r1.11 within original nvidia/cuda binary docker image. All the same behaviour.\r\n\r\n\r\n### Source code / logs\r\n```\r\nimport os\r\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\r\nos.environ['CUDA_VISIBLE_DEVICES']=\"2,3\"\r\n\r\nimport tensorflow as tf \r\n\r\ndef model_fn(features, labels, mode):\r\n  layer = tf.layers.Dense(1)\r\n  logits = layer(features)\r\n\r\n  if mode == tf.estimator.ModeKeys.PREDICT:\r\n    predictions = {\"logits\": logits}\r\n    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n  loss = tf.losses.mean_squared_error(\r\n               labels=labels, predictions=tf.reshape(logits, []))\r\n\r\n  if mode == tf.estimator.ModeKeys.EVAL:\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss)\r\n\r\n  if mode == tf.estimator.ModeKeys.TRAIN:\r\n    train_op = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\ndef input_fn():\r\n  features = tf.data.Dataset.from_tensors([[1.]]).repeat(100)\r\n  labels = tf.data.Dataset.from_tensors(1.).repeat(100)\r\n  return tf.data.Dataset.zip((features, labels))\r\n\r\ndistribution = tf.contrib.distribute.MirroredStrategy()\r\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\r\nclassifier = tf.estimator.Estimator(model_fn=model_fn, config=config)\r\n\r\nclassifier.train(input_fn=input_fn)\r\n\r\nclassifier.evaluate(input_fn=input_fn)\r\n```\r\n\r\n[freeze_output_r1.10.txt](https://github.com/tensorflow/tensorflow/files/2407611/freeze_output_r1.10.txt)\r\n[freeze_output_r1.11.txt](https://github.com/tensorflow/tensorflow/files/2407612/freeze_output_r1.11.txt)\r\n[normal_completion_output_r1.10.1.txt](https://github.com/tensorflow/tensorflow/files/2407613/normal_completion_output_r1.10.1.txt)\r\n[normal_completion_output_r1.11.txt](https://github.com/tensorflow/tensorflow/files/2407614/normal_completion_output_r1.11.txt)\r\n[tf_env_r1.10.1.txt](https://github.com/tensorflow/tensorflow/files/2407615/tf_env_r1.10.1.txt)\r\n[tf_env_r1.11.txt](https://github.com/tensorflow/tensorflow/files/2407616/tf_env_r1.11.txt)"}