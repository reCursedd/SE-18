{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/197675166", "pull_request_review_id": 131461969, "id": 197675166, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NzY3NTE2Ng==", "diff_hunk": "@@ -0,0 +1,336 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/core/framework/dataset.h\"\n+#include \"tensorflow/core/lib/io/buffered_inputstream.h\"\n+#include \"tensorflow/core/platform/file_system.h\"\n+\n+namespace tensorflow {\n+namespace {\n+\n+static const size_t kSyncMarkerSize = 16;\n+static const size_t kSequenceFileBufferSize = 1024 * 1024;\n+\n+class SequenceFileReader {\n+ public:\n+  explicit SequenceFileReader(RandomAccessFile* file)\n+      : input_stream_(\n+            new io::BufferedInputStream(file, kSequenceFileBufferSize)) {}\n+\n+  Status ReadHeader() {\n+    std::string version;\n+    TF_RETURN_IF_ERROR(input_stream_->ReadNBytes(4, &version));\n+    if (version.substr(0, 3) != \"SEQ\" || version[3] != 6) {\n+      return errors::InvalidArgument(\n+          \"sequence file header must starts with `SEQ6`, received \\\"\",\n+          version.substr(0, 3), int(version[3]), \"\\\"\");\n+    }\n+    TF_RETURN_IF_ERROR(ReadString(&key_class_name_));\n+    TF_RETURN_IF_ERROR(ReadString(&value_class_name_));\n+\n+    // At the moment we only support `org.apache.hadoop.io.Text` for key/value.\n+    // TODO (yongtang): Add more class name support.\n+    if (key_class_name_ != \"org.apache.hadoop.io.Text\" ||\n+        value_class_name_ != \"org.apache.hadoop.io.Text\") {\n+      return errors::Unimplemented(\"key/value of '\", key_class_name_, \"/\",\n+                                   value_class_name_,\n+                                   \"' is currently not supported\");\n+    }\n+\n+    std::string buffer;\n+    TF_RETURN_IF_ERROR(input_stream_->ReadNBytes(2, &buffer));\n+    compression_ = buffer[0];\n+    block_compression_ = buffer[1];\n+    if (compression_ || block_compression_) {\n+      TF_RETURN_IF_ERROR(ReadString(&compression_codec_class_name_));\n+    }\n+\n+    // At the moment no compression is supported.\n+    // TODO (yongtang): Add compression support.\n+    if (compression_ || block_compression_) {\n+      return errors::Unimplemented(\"compression is currently not supported\");\n+    }\n+\n+    // Not interested in metadata for now.\n+    uint32 num_metadata_pairs = 0;\n+    TF_RETURN_IF_ERROR(ReadUInt32(&num_metadata_pairs));\n+    if (num_metadata_pairs > 1024) {\n+      return errors::InvalidArgument(\n+          \"sequence file metadata should have key value pairs < 1024,  \"\n+          \"received \",\n+          num_metadata_pairs);\n+    }\n+    for (int i = 0; i < num_metadata_pairs; i++) {\n+      TF_RETURN_IF_ERROR(ReadString(nullptr));\n+      TF_RETURN_IF_ERROR(ReadString(nullptr));\n+    }\n+\n+    TF_RETURN_IF_ERROR(\n+        input_stream_->ReadNBytes(kSyncMarkerSize, &sync_marker_));\n+\n+    return Status::OK();\n+  }\n+\n+  Status ReadRecord(std::string* key, std::string* value) {\n+    uint32 length = 0;\n+    TF_RETURN_IF_ERROR(ReadUInt32(&length));\n+    if (length == static_cast<uint32>(-1)) {\n+      // Sync marker.\n+      std::string sync_marker;\n+      TF_RETURN_IF_ERROR(\n+          input_stream_->ReadNBytes(kSyncMarkerSize, &sync_marker));\n+      if (sync_marker != sync_marker_) {\n+        return errors::InvalidArgument(\n+            \"sequence file should have sync marker \\\"\", sync_marker_,\n+            \"\\\" at pos \", input_stream_->Tell() - kSyncMarkerSize,\n+            \", received \\\"\", sync_marker, \"\\\"\");\n+      }\n+      return ReadRecord(key, value);\n+    }\n+    uint32 key_length = 0;\n+    TF_RETURN_IF_ERROR(ReadUInt32(&key_length));\n+    if (key_length > length) {\n+      return errors::InvalidArgument(\"key length (\", key_length,\n+                                     \") should be < record length (\", length,\n+                                     \")\");\n+    }\n+    uint32 value_length = length - key_length;\n+    // At the moment we only support `org.apache.hadoop.io.Text` for key/value.\n+    // TODO (yongtang): Expand supported format.\n+    TF_RETURN_IF_ERROR(ReadString(key));\n+    TF_RETURN_IF_ERROR(ReadString(value));\n+    return Status::OK();\n+  }\n+\n+  Status ReadString(std::string* value) {\n+    int64 length = 0;\n+    TF_RETURN_IF_ERROR(ReadVInt(&length));\n+    if (value == nullptr) {\n+      return input_stream_->SkipNBytes(length);\n+    }\n+    return input_stream_->ReadNBytes(length, value);\n+  }\n+\n+  Status ReadUInt32(uint32* value) {\n+    std::string buffer;\n+    TF_RETURN_IF_ERROR(input_stream_->ReadNBytes(4, &buffer));\n+    *value = (uint32(buffer[0]) << 24) | (uint32(buffer[1]) << 16) |\n+             (uint32(buffer[2]) << 8) | uint32(buffer[3]);\n+    return Status::OK();\n+  }\n+\n+  Status ReadVInt(int64* value) {\n+    std::string buffer;\n+    TF_RETURN_IF_ERROR(input_stream_->ReadNBytes(1, &buffer));\n+    if (buffer[0] >= -112) {\n+      *value = static_cast<int64>(buffer[0]);\n+      return Status::OK();\n+    }\n+\n+    int64 remaining = 0;\n+    bool negative = false;\n+    if (buffer[0] >= -120) {\n+      remaining = static_cast<int64>(-112) - static_cast<int64>(buffer[0]);\n+    } else {\n+      remaining = static_cast<int64>(-120) - static_cast<int64>(buffer[0]);\n+      negative = true;\n+    }\n+    buffer.clear();\n+    TF_RETURN_IF_ERROR(input_stream_->ReadNBytes(remaining, &buffer));\n+\n+    uint64 v = 0;\n+    for (int i = 0; i < buffer.size(); i++) {\n+      v = (v << 8) | (uint64)(buffer[i]);\n+    }\n+    if (negative) {\n+      v = ~v;\n+    }\n+    *value = static_cast<int64>(v);\n+    return Status::OK();\n+  }\n+\n+  virtual ~SequenceFileReader() = default;\n+\n+ private:\n+  std::unique_ptr<io::InputStreamInterface> input_stream_;\n+  std::string key_class_name_;\n+  std::string value_class_name_;\n+  std::string sync_marker_;\n+  bool compression_;\n+  bool block_compression_;\n+  std::string compression_codec_class_name_;\n+  TF_DISALLOW_COPY_AND_ASSIGN(SequenceFileReader);\n+};\n+}", "path": "tensorflow/contrib/hadoop/kernels/hadoop_dataset_ops.cc", "position": null, "original_position": 176, "commit_id": "c8e2668612189bcb2784334ce61636a6502c1603", "original_commit_id": "951f26d6af78707412434275efc769f4ec4194a6", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "body": "The `OpKernel` implementation should also be in the anonymous namespace.", "created_at": "2018-06-25T04:03:55Z", "updated_at": "2018-08-09T18:44:22Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19534#discussion_r197675166", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19534", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/197675166"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19534#discussion_r197675166"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19534"}}, "body_html": "<p>The <code>OpKernel</code> implementation should also be in the anonymous namespace.</p>", "body_text": "The OpKernel implementation should also be in the anonymous namespace."}