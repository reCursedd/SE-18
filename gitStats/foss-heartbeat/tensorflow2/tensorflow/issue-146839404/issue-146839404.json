{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1819", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1819/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1819/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1819/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1819", "id": 146839404, "node_id": "MDU6SXNzdWUxNDY4Mzk0MDQ=", "number": 1819, "title": "python cifar10_eval.py hang forever sometimes", "user": {"login": "zhanglix", "id": 8109462, "node_id": "MDQ6VXNlcjgxMDk0NjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/8109462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhanglix", "html_url": "https://github.com/zhanglix", "followers_url": "https://api.github.com/users/zhanglix/followers", "following_url": "https://api.github.com/users/zhanglix/following{/other_user}", "gists_url": "https://api.github.com/users/zhanglix/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhanglix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhanglix/subscriptions", "organizations_url": "https://api.github.com/users/zhanglix/orgs", "repos_url": "https://api.github.com/users/zhanglix/repos", "events_url": "https://api.github.com/users/zhanglix/events{/privacy}", "received_events_url": "https://api.github.com/users/zhanglix/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "sherrym", "id": 12770037, "node_id": "MDQ6VXNlcjEyNzcwMDM3", "avatar_url": "https://avatars0.githubusercontent.com/u/12770037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sherrym", "html_url": "https://github.com/sherrym", "followers_url": "https://api.github.com/users/sherrym/followers", "following_url": "https://api.github.com/users/sherrym/following{/other_user}", "gists_url": "https://api.github.com/users/sherrym/gists{/gist_id}", "starred_url": "https://api.github.com/users/sherrym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sherrym/subscriptions", "organizations_url": "https://api.github.com/users/sherrym/orgs", "repos_url": "https://api.github.com/users/sherrym/repos", "events_url": "https://api.github.com/users/sherrym/events{/privacy}", "received_events_url": "https://api.github.com/users/sherrym/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sherrym", "id": 12770037, "node_id": "MDQ6VXNlcjEyNzcwMDM3", "avatar_url": "https://avatars0.githubusercontent.com/u/12770037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sherrym", "html_url": "https://github.com/sherrym", "followers_url": "https://api.github.com/users/sherrym/followers", "following_url": "https://api.github.com/users/sherrym/following{/other_user}", "gists_url": "https://api.github.com/users/sherrym/gists{/gist_id}", "starred_url": "https://api.github.com/users/sherrym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sherrym/subscriptions", "organizations_url": "https://api.github.com/users/sherrym/orgs", "repos_url": "https://api.github.com/users/sherrym/repos", "events_url": "https://api.github.com/users/sherrym/events{/privacy}", "received_events_url": "https://api.github.com/users/sherrym/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2016-04-08T07:18:57Z", "updated_at": "2016-05-13T20:56:27Z", "closed_at": "2016-05-13T20:56:27Z", "author_association": "NONE", "body_html": "<p>GitHub issues are for bugs / installation problems / feature requests.<br>\nFor general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nLinux ubuntu 4.2.0-27-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115947948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/32\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/32/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/32\">#32</a>-Ubuntu SMP Fri Jan 22 04:49:08 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):<br>\njames@ubuntu:~/practice$ ls -l /usr/local/cuda*<br>\nlrwxrwxrwx 1 root root    8 Mar 29 13:21 /usr/local/cuda -&gt; cuda-7.5</p>\n<p>/usr/local/cuda-7.5:<br>\ntotal 32<br>\ndrwxr-xr-x  3 root root 4096 Mar 29 14:48 bin<br>\ndrwxr-xr-x  2 root root 4096 Mar 29 12:16 doc<br>\nlrwxrwxrwx  1 root root   28 Aug 16  2015 include -&gt; targets/x86_64-linux/include<br>\nlrwxrwxrwx  1 root root   24 Aug 16  2015 lib64 -&gt; targets/x86_64-linux/lib<br>\n-rw-r--r--  1 root root  365 Aug 16  2015 LICENSE<br>\ndrwxr-xr-x  7 root root 4096 Mar 29 12:16 nvvm<br>\n-rw-r--r--  1 root root  365 Aug 16  2015 README<br>\ndrwxr-xr-x 11 root root 4096 Mar 29 14:48 samples<br>\ndrwxr-xr-x  3 root root 4096 Feb  3 18:04 targets<br>\n-rw-r--r--  1 root root   20 Aug 15  2015 version.txt</p>\n<p>installed from docker.<br>\ntag   \"b.gcr.io/tensorflow/tensorflow:latest-devel-gpu\"<br>\n(id:7f61540f94b2951574fd313b5980b850c7326933fc5a857779a36a94443c64cb)</p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>pull images from docker<br>\n2.docker run -it -v /lib/modules/4.2.0-22-generic:/lib/modules/4.2.0-22-generic -v /lib/modules/4.2.0-23-generic:/lib/modules/4.2.0-23-generic -v /lib/modules/4.2.0-25-generic:/lib/modules/4.2.0-25-generic -v /lib/modules/4.2.0-27-generic:/lib/modules/4.2.0-27-generic -v /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1 -v /usr/lib/x86_64-linux-gnu/libcuda.so.352.79:/usr/lib/x86_64-linux-gnu/libcuda.so.352.79 --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm -v /home/james:/home/james -P tensor-james</li>\n<li>python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_train.py</li>\n<li>stop train after some checkpoint file been written to disk</li>\n<li>python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_eval.py  --run_once true</li>\n<li>the last step hanging forever some times.</li>\n</ol>\n<h3>What have you tried?</h3>\n<p>1.I add some logs to the cifar10_eval.py and it comes out that all threads of queue runner is active, and  it is hanging at the first call to   <code>predictions = sess.run([top_k_op])</code></p>\n<p>print([t.isAlive() for t in threads]);<br>\nwhile step &lt; num_iter and not coord.should_stop():<br>\nprint(\"begin step %d;\" %(step))<br>\npredictions = sess.run([top_k_op])<br>\nprint(\"step %d: %d;\" %(step, true_count))</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/209762/train_checkpoints.zip\">train_checkpoints.zip</a></p>\n<h3>Logs or other output that would be helpful</h3>\n<p>I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally<br>\n...<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning N<br>\nUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: GeForce GTX 980 Ti<br>\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.291<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 5.99GiB<br>\nFree memory: 5.43GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB<br>\n...<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 5.14GiB bytes.<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x706400000 extends to 0x84ef38000</p>", "body_text": "GitHub issues are for bugs / installation problems / feature requests.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nEnvironment info\nOperating System:\nLinux ubuntu 4.2.0-27-generic #32-Ubuntu SMP Fri Jan 22 04:49:08 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\njames@ubuntu:~/practice$ ls -l /usr/local/cuda*\nlrwxrwxrwx 1 root root    8 Mar 29 13:21 /usr/local/cuda -> cuda-7.5\n/usr/local/cuda-7.5:\ntotal 32\ndrwxr-xr-x  3 root root 4096 Mar 29 14:48 bin\ndrwxr-xr-x  2 root root 4096 Mar 29 12:16 doc\nlrwxrwxrwx  1 root root   28 Aug 16  2015 include -> targets/x86_64-linux/include\nlrwxrwxrwx  1 root root   24 Aug 16  2015 lib64 -> targets/x86_64-linux/lib\n-rw-r--r--  1 root root  365 Aug 16  2015 LICENSE\ndrwxr-xr-x  7 root root 4096 Mar 29 12:16 nvvm\n-rw-r--r--  1 root root  365 Aug 16  2015 README\ndrwxr-xr-x 11 root root 4096 Mar 29 14:48 samples\ndrwxr-xr-x  3 root root 4096 Feb  3 18:04 targets\n-rw-r--r--  1 root root   20 Aug 15  2015 version.txt\ninstalled from docker.\ntag   \"b.gcr.io/tensorflow/tensorflow:latest-devel-gpu\"\n(id:7f61540f94b2951574fd313b5980b850c7326933fc5a857779a36a94443c64cb)\nSteps to reproduce\n\npull images from docker\n2.docker run -it -v /lib/modules/4.2.0-22-generic:/lib/modules/4.2.0-22-generic -v /lib/modules/4.2.0-23-generic:/lib/modules/4.2.0-23-generic -v /lib/modules/4.2.0-25-generic:/lib/modules/4.2.0-25-generic -v /lib/modules/4.2.0-27-generic:/lib/modules/4.2.0-27-generic -v /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1 -v /usr/lib/x86_64-linux-gnu/libcuda.so.352.79:/usr/lib/x86_64-linux-gnu/libcuda.so.352.79 --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm -v /home/james:/home/james -P tensor-james\npython /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_train.py\nstop train after some checkpoint file been written to disk\npython /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_eval.py  --run_once true\nthe last step hanging forever some times.\n\nWhat have you tried?\n1.I add some logs to the cifar10_eval.py and it comes out that all threads of queue runner is active, and  it is hanging at the first call to   predictions = sess.run([top_k_op])\nprint([t.isAlive() for t in threads]);\nwhile step < num_iter and not coord.should_stop():\nprint(\"begin step %d;\" %(step))\npredictions = sess.run([top_k_op])\nprint(\"step %d: %d;\" %(step, true_count))\ntrain_checkpoints.zip\nLogs or other output that would be helpful\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n...\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning N\nUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 980 Ti\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.291\npciBusID 0000:01:00.0\nTotal memory: 5.99GiB\nFree memory: 5.43GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\n...\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 5.14GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x706400000 extends to 0x84ef38000", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System:\nLinux ubuntu 4.2.0-27-generic #32-Ubuntu SMP Fri Jan 22 04:49:08 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\njames@ubuntu:~/practice$ ls -l /usr/local/cuda*\nlrwxrwxrwx 1 root root    8 Mar 29 13:21 /usr/local/cuda -> cuda-7.5\n\n/usr/local/cuda-7.5:\ntotal 32\ndrwxr-xr-x  3 root root 4096 Mar 29 14:48 bin\ndrwxr-xr-x  2 root root 4096 Mar 29 12:16 doc\nlrwxrwxrwx  1 root root   28 Aug 16  2015 include -> targets/x86_64-linux/include\nlrwxrwxrwx  1 root root   24 Aug 16  2015 lib64 -> targets/x86_64-linux/lib\n-rw-r--r--  1 root root  365 Aug 16  2015 LICENSE\ndrwxr-xr-x  7 root root 4096 Mar 29 12:16 nvvm\n-rw-r--r--  1 root root  365 Aug 16  2015 README\ndrwxr-xr-x 11 root root 4096 Mar 29 14:48 samples\ndrwxr-xr-x  3 root root 4096 Feb  3 18:04 targets\n-rw-r--r--  1 root root   20 Aug 15  2015 version.txt\n\ninstalled from docker.\ntag   \"b.gcr.io/tensorflow/tensorflow:latest-devel-gpu\"\n(id:7f61540f94b2951574fd313b5980b850c7326933fc5a857779a36a94443c64cb)\n### Steps to reproduce\n1. pull images from docker\n   2.docker run -it -v /lib/modules/4.2.0-22-generic:/lib/modules/4.2.0-22-generic -v /lib/modules/4.2.0-23-generic:/lib/modules/4.2.0-23-generic -v /lib/modules/4.2.0-25-generic:/lib/modules/4.2.0-25-generic -v /lib/modules/4.2.0-27-generic:/lib/modules/4.2.0-27-generic -v /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1 -v /usr/lib/x86_64-linux-gnu/libcuda.so.352.79:/usr/lib/x86_64-linux-gnu/libcuda.so.352.79 --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm -v /home/james:/home/james -P tensor-james\n2. python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_train.py \n3. stop train after some checkpoint file been written to disk\n4. python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_eval.py  --run_once true\n5. the last step hanging forever some times. \n### What have you tried?\n\n1.I add some logs to the cifar10_eval.py and it comes out that all threads of queue runner is active, and  it is hanging at the first call to   `predictions = sess.run([top_k_op])`\n\nprint([t.isAlive() for t in threads]);\n      while step < num_iter and not coord.should_stop():\n        print(\"begin step %d;\" %(step))\n        predictions = sess.run([top_k_op])\n        print(\"step %d: %d;\" %(step, true_count))\n\n[train_checkpoints.zip](https://github.com/tensorflow/tensorflow/files/209762/train_checkpoints.zip)\n### Logs or other output that would be helpful\n\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n...\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning N\nUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 980 Ti\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.291\npciBusID 0000:01:00.0\nTotal memory: 5.99GiB\nFree memory: 5.43GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\n... \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 5.14GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x706400000 extends to 0x84ef38000\n"}