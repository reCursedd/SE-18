{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/313203223", "html_url": "https://github.com/tensorflow/tensorflow/issues/10982#issuecomment-313203223", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10982", "id": 313203223, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzIwMzIyMw==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-05T19:31:02Z", "updated_at": "2017-07-05T19:31:02Z", "author_association": "MEMBER", "body_html": "<p>I know this is not super helpful although I had an idea at the end.  I just ran the following setup and the example worked.  I double checked the timeline to ensure XLA was 100% running:</p>\n<ul>\n<li>CUDA 8</li>\n<li>cuDNN 5.1</li>\n<li>TF (head past 1.2):  <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/3a64879a86e46908ad90a387efe56ad32be61e94/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/3a64879a86e46908ad90a387efe56ad32be61e94\"><tt>3a64879</tt></a></li>\n<li>GTX 1080, which should not matter</li>\n<li>Python2.7, I doubt python is the issue as the error is coming from the <code>op</code> but it would not be the first time I was really wrong.</li>\n<li>The AVX,SSE stuff also doesn't matter and we are working on a simpler warning.</li>\n</ul>\n<p>Completely random thought.  I see you have two GPUs.  The code is not setup for multi-GPU, the example is also really basic but still I wonder if that is creating a problem.  You could try with one GPU and run something like this to try it out.  I have never tried the example on multi-GPU.</p>\n<div class=\"highlight highlight-source-shell\"><pre>CUDA_VISIBLE_DEVICES=0 python mnist_softmax_xla.py</pre></div>", "body_text": "I know this is not super helpful although I had an idea at the end.  I just ran the following setup and the example worked.  I double checked the timeline to ensure XLA was 100% running:\n\nCUDA 8\ncuDNN 5.1\nTF (head past 1.2):  3a64879\nGTX 1080, which should not matter\nPython2.7, I doubt python is the issue as the error is coming from the op but it would not be the first time I was really wrong.\nThe AVX,SSE stuff also doesn't matter and we are working on a simpler warning.\n\nCompletely random thought.  I see you have two GPUs.  The code is not setup for multi-GPU, the example is also really basic but still I wonder if that is creating a problem.  You could try with one GPU and run something like this to try it out.  I have never tried the example on multi-GPU.\nCUDA_VISIBLE_DEVICES=0 python mnist_softmax_xla.py", "body": "I know this is not super helpful although I had an idea at the end.  I just ran the following setup and the example worked.  I double checked the timeline to ensure XLA was 100% running:\r\n\r\n- CUDA 8\r\n- cuDNN 5.1\r\n- TF (head past 1.2):  3a64879a86e46908ad90a387efe56ad32be61e94\r\n- GTX 1080, which should not matter\r\n- Python2.7, I doubt python is the issue as the error is coming from the `op` but it would not be the first time I was really wrong.  \r\n- The AVX,SSE stuff also doesn't matter and we are working on a simpler warning.\r\n\r\nCompletely random thought.  I see you have two GPUs.  The code is not setup for multi-GPU, the example is also really basic but still I wonder if that is creating a problem.  You could try with one GPU and run something like this to try it out.  I have never tried the example on multi-GPU.      \r\n\r\n```bash\r\nCUDA_VISIBLE_DEVICES=0 python mnist_softmax_xla.py\r\n```\r\n"}