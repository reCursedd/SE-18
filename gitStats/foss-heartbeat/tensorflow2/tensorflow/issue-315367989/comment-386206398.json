{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/386206398", "html_url": "https://github.com/tensorflow/tensorflow/issues/18635#issuecomment-386206398", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18635", "id": 386206398, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjIwNjM5OA==", "user": {"login": "weichiche", "id": 7419189, "node_id": "MDQ6VXNlcjc0MTkxODk=", "avatar_url": "https://avatars2.githubusercontent.com/u/7419189?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weichiche", "html_url": "https://github.com/weichiche", "followers_url": "https://api.github.com/users/weichiche/followers", "following_url": "https://api.github.com/users/weichiche/following{/other_user}", "gists_url": "https://api.github.com/users/weichiche/gists{/gist_id}", "starred_url": "https://api.github.com/users/weichiche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weichiche/subscriptions", "organizations_url": "https://api.github.com/users/weichiche/orgs", "repos_url": "https://api.github.com/users/weichiche/repos", "events_url": "https://api.github.com/users/weichiche/events{/privacy}", "received_events_url": "https://api.github.com/users/weichiche/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-03T06:58:31Z", "updated_at": "2018-05-03T07:16:52Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5361725\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Benyuel\">@Benyuel</a>: I've made a misleading example in my first comment. Please allow me to rephrase my questions.</p>\n<p>Consider two <em>float32-by-float32</em> divisions:</p>\n<ul>\n<li>(<strong><em>TF</em></strong>) - dividing a <code>tf.float32</code> <code>Tensor</code> created by <code>tf.placeholder()</code> by a <code>float32</code> <code>Tensor</code> created by <code>tf.constant()</code> ,</li>\n<li>(<strong><em>NP</em></strong>) - dividing an <code>np.float32</code> (or <code>np.float32</code> <code>ndarray</code> created by <code>np.array()</code>) by another <code>np.float32</code> (or <code>np.float32</code> <code>ndarray</code> created by <code>np.array()</code>).</li>\n</ul>\n<p>and a statement:</p>\n<ul>\n<li>(<strong><em>EQ</em></strong>) - (<em>TF</em>) produces, numerically, the same quotient as (<em>NP</em>),</li>\n</ul>\n<p>Here're the questions:</p>\n<ol>\n<li>Can we expect (<em>EQ</em>)?</li>\n<li>Should we expect (<em>EQ</em>)?</li>\n</ol>\n<hr>\n<p>As to our long-discussed example (i.e. dividing 247 by 255).</p>\n<p>In Numpy, if the dividend is a scalar (created by <code>np.float32(247.)</code>) or a 0-dimensional array (created by <code>np.array(247., dtype=np.float32)</code>), the division by a Python <code>float</code> (which is actually a 64-bit float as you mentioned before) will be lifted to a <em>float64-by-float64</em> division. However, if the dividend is an array with one or more dimensions (e.g. created  by <code>np.array([247.], dtype=np.float32)</code>), then the divisor is converted to a 32-bit float, and the result is the same as <em>float32-by-float32</em> division. So the first snippet in your last comment, whether the divisor is 32-bit or 64-bit, gives exact result of (<em>NP</em>).</p>\n<p>Your second snippet is an example of (<em>TF</em>). Though the divisor is 64-bit, it is converted to a <code>DT_FLOAT</code>, which I think is 32-bit. This division should also be a <em>float32-by-float32</em> division. But somehow the result is slightly different from that of (<em>NP</em>), even if the divisor is explicitly created as 32-bit using <code>tf.constant(255., dtype=tf.float32)</code>. This is where my concern comes from.</p>\n<p>I've tried the same example in TensorFlow 1.1.0, and the result is consistent with (<em>NP</em>). It looks like this issue is introduced during TensorFlow upgrading.</p>\n<p>The third snippet is out of my consideration, as it gives expected result.</p>", "body_text": "@Benyuel: I've made a misleading example in my first comment. Please allow me to rephrase my questions.\nConsider two float32-by-float32 divisions:\n\n(TF) - dividing a tf.float32 Tensor created by tf.placeholder() by a float32 Tensor created by tf.constant() ,\n(NP) - dividing an np.float32 (or np.float32 ndarray created by np.array()) by another np.float32 (or np.float32 ndarray created by np.array()).\n\nand a statement:\n\n(EQ) - (TF) produces, numerically, the same quotient as (NP),\n\nHere're the questions:\n\nCan we expect (EQ)?\nShould we expect (EQ)?\n\n\nAs to our long-discussed example (i.e. dividing 247 by 255).\nIn Numpy, if the dividend is a scalar (created by np.float32(247.)) or a 0-dimensional array (created by np.array(247., dtype=np.float32)), the division by a Python float (which is actually a 64-bit float as you mentioned before) will be lifted to a float64-by-float64 division. However, if the dividend is an array with one or more dimensions (e.g. created  by np.array([247.], dtype=np.float32)), then the divisor is converted to a 32-bit float, and the result is the same as float32-by-float32 division. So the first snippet in your last comment, whether the divisor is 32-bit or 64-bit, gives exact result of (NP).\nYour second snippet is an example of (TF). Though the divisor is 64-bit, it is converted to a DT_FLOAT, which I think is 32-bit. This division should also be a float32-by-float32 division. But somehow the result is slightly different from that of (NP), even if the divisor is explicitly created as 32-bit using tf.constant(255., dtype=tf.float32). This is where my concern comes from.\nI've tried the same example in TensorFlow 1.1.0, and the result is consistent with (NP). It looks like this issue is introduced during TensorFlow upgrading.\nThe third snippet is out of my consideration, as it gives expected result.", "body": "@Benyuel: I've made a misleading example in my first comment. Please allow me to rephrase my questions.\r\n\r\nConsider two _float32-by-float32_ divisions:\r\n\r\n* (**_TF_**) - dividing a `tf.float32` `Tensor` created by `tf.placeholder()` by a `float32` `Tensor` created by `tf.constant()` ,\r\n* (**_NP_**) - dividing an `np.float32` (or `np.float32` `ndarray` created by `np.array()`) by another `np.float32` (or `np.float32` `ndarray` created by `np.array()`).\r\n\r\nand a statement:\r\n\r\n* (**_EQ_**) - (_TF_) produces, numerically, the same quotient as (_NP_),\r\n\r\nHere're the questions:\r\n\r\n1. Can we expect (_EQ_)?\r\n2. Should we expect (_EQ_)?\r\n\r\n---\r\n\r\nAs to our long-discussed example (i.e. dividing 247 by 255).\r\n\r\nIn Numpy, if the dividend is a scalar (created by `np.float32(247.)`) or a 0-dimensional array (created by `np.array(247., dtype=np.float32)`), the division by a Python `float` (which is actually a 64-bit float as you mentioned before) will be lifted to a _float64-by-float64_ division. However, if the dividend is an array with one or more dimensions (e.g. created  by `np.array([247.], dtype=np.float32)`), then the divisor is converted to a 32-bit float, and the result is the same as _float32-by-float32_ division. So the first snippet in your last comment, whether the divisor is 32-bit or 64-bit, gives exact result of (_NP_).\r\n\r\nYour second snippet is an example of (_TF_). Though the divisor is 64-bit, it is converted to a `DT_FLOAT`, which I think is 32-bit. This division should also be a _float32-by-float32_ division. But somehow the result is slightly different from that of (_NP_), even if the divisor is explicitly created as 32-bit using `tf.constant(255., dtype=tf.float32)`. This is where my concern comes from.\r\n\r\nI've tried the same example in TensorFlow 1.1.0, and the result is consistent with (_NP_). It looks like this issue is introduced during TensorFlow upgrading. \r\n\r\nThe third snippet is out of my consideration, as it gives expected result."}