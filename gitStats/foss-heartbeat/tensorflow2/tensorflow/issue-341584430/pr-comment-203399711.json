{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203399711", "pull_request_review_id": 138280195, "id": 203399711, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzM5OTcxMQ==", "diff_hunk": "@@ -24,7 +24,13 @@ class Platform;\n \n namespace tensorflow {\n \n-// Initializes the CUDA platform and returns OK if the CUDA\n+#if GOOGLE_CUDA\n+#define GPU_PLATFORM_NAME \"CUDA\"", "path": "tensorflow/core/common_runtime/gpu/gpu_init.h", "position": null, "original_position": 6, "commit_id": "c8ae8965ea75a28f30d80ed7657fd9f31b18b48d", "original_commit_id": "9af995ecf3ba1815a0a9cf6e0b4ca372f1ff0b9f", "user": {"login": "whchung", "id": 1673574, "node_id": "MDQ6VXNlcjE2NzM1NzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1673574?v=4", "gravatar_id": "", "url": "https://api.github.com/users/whchung", "html_url": "https://github.com/whchung", "followers_url": "https://api.github.com/users/whchung/followers", "following_url": "https://api.github.com/users/whchung/following{/other_user}", "gists_url": "https://api.github.com/users/whchung/gists{/gist_id}", "starred_url": "https://api.github.com/users/whchung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/whchung/subscriptions", "organizations_url": "https://api.github.com/users/whchung/orgs", "repos_url": "https://api.github.com/users/whchung/repos", "events_url": "https://api.github.com/users/whchung/events{/privacy}", "received_events_url": "https://api.github.com/users/whchung/received_events", "type": "User", "site_admin": false}, "body": "@hawkinsp Thanks for your comment and I think it deserves to discuss about what \"GPU\" means. The purpose of my PRs, and future PRs, is to decouple the generic notion \"GPU\" to a particular vendor.\r\n\r\nThe rationale I chose to make these changes a configure-time/compile-time option is because it's hard to imagine on a production system there would be GPUs coming from different vendors. On a development / test system it's possible but with VMs / docker containers / virtualenv it's possible to configure one system with 2 different TensorFlow installations.\r\n\r\nSince it's possible for users to explicitly specify devices be executed via `with tf.device(\"/device:GPU:0\")`, I honestly don't think introducing a new kind of device be a viable choice.", "created_at": "2018-07-18T14:26:14Z", "updated_at": "2018-08-29T21:18:39Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20845#discussion_r203399711", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20845", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203399711"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20845#discussion_r203399711"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20845"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=348932\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hawkinsp\">@hawkinsp</a> Thanks for your comment and I think it deserves to discuss about what \"GPU\" means. The purpose of my PRs, and future PRs, is to decouple the generic notion \"GPU\" to a particular vendor.</p>\n<p>The rationale I chose to make these changes a configure-time/compile-time option is because it's hard to imagine on a production system there would be GPUs coming from different vendors. On a development / test system it's possible but with VMs / docker containers / virtualenv it's possible to configure one system with 2 different TensorFlow installations.</p>\n<p>Since it's possible for users to explicitly specify devices be executed via <code>with tf.device(\"/device:GPU:0\")</code>, I honestly don't think introducing a new kind of device be a viable choice.</p>", "body_text": "@hawkinsp Thanks for your comment and I think it deserves to discuss about what \"GPU\" means. The purpose of my PRs, and future PRs, is to decouple the generic notion \"GPU\" to a particular vendor.\nThe rationale I chose to make these changes a configure-time/compile-time option is because it's hard to imagine on a production system there would be GPUs coming from different vendors. On a development / test system it's possible but with VMs / docker containers / virtualenv it's possible to configure one system with 2 different TensorFlow installations.\nSince it's possible for users to explicitly specify devices be executed via with tf.device(\"/device:GPU:0\"), I honestly don't think introducing a new kind of device be a viable choice.", "in_reply_to_id": 203363296}