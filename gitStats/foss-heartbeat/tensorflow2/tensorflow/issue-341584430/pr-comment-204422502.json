{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204422502", "pull_request_review_id": 139499535, "id": 204422502, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDQyMjUwMg==", "diff_hunk": "@@ -104,6 +104,23 @@ cc_library(\n     alwayslink = 1,\n )\n \n+cc_library(\n+    name = \"xla_amdgpu_device\",\n+    srcs = [\"xla_amdgpu_device.cc\"],\n+    visibility = [\":friends\"],\n+    deps = [\n+        \":jit_compilation_passes\",\n+        \":xla_device\",\n+        \"//tensorflow/compiler/jit/kernels:xla_launch_op\",\n+        \"//tensorflow/compiler/tf2xla:xla_compiler\",\n+        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n+        \"//tensorflow/compiler/xla/service:gpu_plugin\",  # buildcleaner: keep", "path": "tensorflow/compiler/jit/BUILD", "position": null, "original_position": 14, "commit_id": "c8ae8965ea75a28f30d80ed7657fd9f31b18b48d", "original_commit_id": "6b2d24a706a6ae20a94f05a4a49db8679e7ff058", "user": {"login": "hawkinsp", "id": 348932, "node_id": "MDQ6VXNlcjM0ODkzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/348932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hawkinsp", "html_url": "https://github.com/hawkinsp", "followers_url": "https://api.github.com/users/hawkinsp/followers", "following_url": "https://api.github.com/users/hawkinsp/following{/other_user}", "gists_url": "https://api.github.com/users/hawkinsp/gists{/gist_id}", "starred_url": "https://api.github.com/users/hawkinsp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hawkinsp/subscriptions", "organizations_url": "https://api.github.com/users/hawkinsp/orgs", "repos_url": "https://api.github.com/users/hawkinsp/repos", "events_url": "https://api.github.com/users/hawkinsp/events{/privacy}", "received_events_url": "https://api.github.com/users/hawkinsp/received_events", "type": "User", "site_admin": false}, "body": "Something seems odd here. Recall that at the XLA_GPU level, we agreed it should be possible to link both AMDGPU and NVIDIA GPU support into the same binary. They are mostly orthogonal features.\r\n\r\nThe dependencies of this device currently look exactly the same as the NVIDIA GPU plugin \u2014 you will need to separate them somehow. (e.g., I would expect that you would create an xla/service:amdgpu_plugin)\r\n\r\n(It isn't sufficient to use a configure time test to choose which GPU we are targeting, as we discussed.)", "created_at": "2018-07-23T14:29:39Z", "updated_at": "2018-08-29T21:18:39Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20845#discussion_r204422502", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20845", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204422502"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20845#discussion_r204422502"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20845"}}, "body_html": "<p>Something seems odd here. Recall that at the XLA_GPU level, we agreed it should be possible to link both AMDGPU and NVIDIA GPU support into the same binary. They are mostly orthogonal features.</p>\n<p>The dependencies of this device currently look exactly the same as the NVIDIA GPU plugin \u2014 you will need to separate them somehow. (e.g., I would expect that you would create an xla/service:amdgpu_plugin)</p>\n<p>(It isn't sufficient to use a configure time test to choose which GPU we are targeting, as we discussed.)</p>", "body_text": "Something seems odd here. Recall that at the XLA_GPU level, we agreed it should be possible to link both AMDGPU and NVIDIA GPU support into the same binary. They are mostly orthogonal features.\nThe dependencies of this device currently look exactly the same as the NVIDIA GPU plugin \u2014 you will need to separate them somehow. (e.g., I would expect that you would create an xla/service:amdgpu_plugin)\n(It isn't sufficient to use a configure time test to choose which GPU we are targeting, as we discussed.)"}