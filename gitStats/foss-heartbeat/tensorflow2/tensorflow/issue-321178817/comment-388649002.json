{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/388649002", "html_url": "https://github.com/tensorflow/tensorflow/issues/19145#issuecomment-388649002", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19145", "id": 388649002, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODY0OTAwMg==", "user": {"login": "srvasude", "id": 1048839, "node_id": "MDQ6VXNlcjEwNDg4Mzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1048839?v=4", "gravatar_id": "", "url": "https://api.github.com/users/srvasude", "html_url": "https://github.com/srvasude", "followers_url": "https://api.github.com/users/srvasude/followers", "following_url": "https://api.github.com/users/srvasude/following{/other_user}", "gists_url": "https://api.github.com/users/srvasude/gists{/gist_id}", "starred_url": "https://api.github.com/users/srvasude/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/srvasude/subscriptions", "organizations_url": "https://api.github.com/users/srvasude/orgs", "repos_url": "https://api.github.com/users/srvasude/repos", "events_url": "https://api.github.com/users/srvasude/events{/privacy}", "received_events_url": "https://api.github.com/users/srvasude/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-13T19:10:22Z", "updated_at": "2018-05-13T19:10:22Z", "author_association": "MEMBER", "body_html": "<p>Hi,<br>\nOne reason for slowness is compute_* adds nodes to the graph. Generally for benchmarking, one should create the graph up front, and then benchmark the sess.runs. The sess.run(...) should also be timed for the underlying op since eval'ing the tensor can include time from the CPU / GPU copies.</p>\n<p>What you want in the end is something like:</p>\n<p>with tf.Session() as sess:<br>\nmsolve = compute_matrix_solve(C, Z_tiled).op<br>\n....<br>\ndef sess_run_msolve():<br>\nreturn sess.run(msolve)<br>\nprint(timeit.timeit(sess_run_msolve, number=100))</p>\n<p>Doing the aforementioned changes (and changing D_in to 500 to see the difference for larger matrices), I get on CPU (in seconds):</p>\n<p>Matrix Solve 3.94200801849<br>\nOperator Solve 2.10899114609<br>\nDiag Solve 1.88388705254<br>\nMatrix Mul 2.18344807625<br>\nOperator Mul 2.28254699707<br>\nDiag Mul 1.86973500252</p>\n<p>Using <a href=\"https://www.tensorflow.org/api_docs/python/tf/test/Benchmark\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tf/test/Benchmark</a> is also an alternative, which would also do some burn in cycles.</p>", "body_text": "Hi,\nOne reason for slowness is compute_* adds nodes to the graph. Generally for benchmarking, one should create the graph up front, and then benchmark the sess.runs. The sess.run(...) should also be timed for the underlying op since eval'ing the tensor can include time from the CPU / GPU copies.\nWhat you want in the end is something like:\nwith tf.Session() as sess:\nmsolve = compute_matrix_solve(C, Z_tiled).op\n....\ndef sess_run_msolve():\nreturn sess.run(msolve)\nprint(timeit.timeit(sess_run_msolve, number=100))\nDoing the aforementioned changes (and changing D_in to 500 to see the difference for larger matrices), I get on CPU (in seconds):\nMatrix Solve 3.94200801849\nOperator Solve 2.10899114609\nDiag Solve 1.88388705254\nMatrix Mul 2.18344807625\nOperator Mul 2.28254699707\nDiag Mul 1.86973500252\nUsing https://www.tensorflow.org/api_docs/python/tf/test/Benchmark is also an alternative, which would also do some burn in cycles.", "body": "Hi,\r\n  One reason for slowness is compute_* adds nodes to the graph. Generally for benchmarking, one should create the graph up front, and then benchmark the sess.runs. The sess.run(...) should also be timed for the underlying op since eval'ing the tensor can include time from the CPU / GPU copies.\r\n\r\nWhat you want in the end is something like:\r\n\r\nwith tf.Session() as sess:\r\n  msolve = compute_matrix_solve(C, Z_tiled).op\r\n  ....\r\n  def sess_run_msolve():\r\n    return sess.run(msolve)\r\n  print(timeit.timeit(sess_run_msolve, number=100))\r\n\r\nDoing the aforementioned changes (and changing D_in to 500 to see the difference for larger matrices), I get on CPU (in seconds):\r\n\r\nMatrix Solve 3.94200801849\r\nOperator Solve 2.10899114609\r\nDiag Solve 1.88388705254\r\nMatrix Mul 2.18344807625\r\nOperator Mul 2.28254699707\r\nDiag Mul 1.86973500252\r\n\r\nUsing https://www.tensorflow.org/api_docs/python/tf/test/Benchmark is also an alternative, which would also do some burn in cycles.\r\n\r\n "}