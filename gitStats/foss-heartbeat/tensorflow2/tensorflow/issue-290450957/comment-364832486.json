{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364832486", "html_url": "https://github.com/tensorflow/tensorflow/issues/16284#issuecomment-364832486", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16284", "id": 364832486, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDgzMjQ4Ng==", "user": {"login": "ed-alertedh", "id": 24605895, "node_id": "MDQ6VXNlcjI0NjA1ODk1", "avatar_url": "https://avatars1.githubusercontent.com/u/24605895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ed-alertedh", "html_url": "https://github.com/ed-alertedh", "followers_url": "https://api.github.com/users/ed-alertedh/followers", "following_url": "https://api.github.com/users/ed-alertedh/following{/other_user}", "gists_url": "https://api.github.com/users/ed-alertedh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ed-alertedh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ed-alertedh/subscriptions", "organizations_url": "https://api.github.com/users/ed-alertedh/orgs", "repos_url": "https://api.github.com/users/ed-alertedh/repos", "events_url": "https://api.github.com/users/ed-alertedh/events{/privacy}", "received_events_url": "https://api.github.com/users/ed-alertedh/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-12T05:32:55Z", "updated_at": "2018-02-12T05:38:11Z", "author_association": "NONE", "body_html": "<p>Somewhat related to this: TF 1.4, Python 3.6.3 x64, Windows 10, CUDA 8, cuDNN 6, NVIDIA driver 385.69</p>\n<p>I was trying to set CUDA_VISIBLE_DEVICES=\"\" (as per <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"221681884\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/9201\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/9201/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/9201\">#9201</a>) to stop the GPU being grabbed at all and it goes ahead and open the device anyway. I only have one GPU on this laptop so I can't test what the behaviour is for multiple devices (the other machines I have access to are all running linux).</p>\n<pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; sess=tf.Session()\n2018-02-12 16:22:11.752327: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n2018-02-12 16:22:12.120254: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1030] Found device 0 with properties:\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\npciBusID: 0000:01:00.0\ntotalMemory: 6.00GiB freeMemory: 4.96GiB\n2018-02-12 16:22:12.120473: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\n</code></pre>\n<p>Confirmation that it is grabbing the GPU memory:</p>\n<pre><code>&gt;nvidia-smi\nMon Feb 12 16:23:12 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 385.69                 Driver Version: 385.69                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1060   WDDM  | 00000000:01:00.0  On |                  N/A |\n| N/A   57C    P2    27W /  N/A |   5763MiB /  6144MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n</code></pre>\n<p>Workaround for now is to set CUDA_VISIBLE_DEVICES=\"-1\" which generates a seemingly benign error message as a side effect:</p>\n<pre><code>2018-02-12 16:09:01.981599: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\n</code></pre>\n<p>edit: turns out that workaround came from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"152019987\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2175\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2175/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2175\">#2175</a> ... woops</p>", "body_text": "Somewhat related to this: TF 1.4, Python 3.6.3 x64, Windows 10, CUDA 8, cuDNN 6, NVIDIA driver 385.69\nI was trying to set CUDA_VISIBLE_DEVICES=\"\" (as per #9201) to stop the GPU being grabbed at all and it goes ahead and open the device anyway. I only have one GPU on this laptop so I can't test what the behaviour is for multiple devices (the other machines I have access to are all running linux).\n>>> import os\n>>> os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n>>> import tensorflow as tf\n>>> sess=tf.Session()\n2018-02-12 16:22:11.752327: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n2018-02-12 16:22:12.120254: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1030] Found device 0 with properties:\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\npciBusID: 0000:01:00.0\ntotalMemory: 6.00GiB freeMemory: 4.96GiB\n2018-02-12 16:22:12.120473: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\n\nConfirmation that it is grabbing the GPU memory:\n>nvidia-smi\nMon Feb 12 16:23:12 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 385.69                 Driver Version: 385.69                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1060   WDDM  | 00000000:01:00.0  On |                  N/A |\n| N/A   57C    P2    27W /  N/A |   5763MiB /  6144MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\nWorkaround for now is to set CUDA_VISIBLE_DEVICES=\"-1\" which generates a seemingly benign error message as a side effect:\n2018-02-12 16:09:01.981599: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\n\nedit: turns out that workaround came from #2175 ... woops", "body": "Somewhat related to this: TF 1.4, Python 3.6.3 x64, Windows 10, CUDA 8, cuDNN 6, NVIDIA driver 385.69\r\n\r\nI was trying to set CUDA_VISIBLE_DEVICES=\"\" (as per #9201) to stop the GPU being grabbed at all and it goes ahead and open the device anyway. I only have one GPU on this laptop so I can't test what the behaviour is for multiple devices (the other machines I have access to are all running linux).\r\n\r\n    >>> import os\r\n    >>> os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\r\n    >>> import tensorflow as tf\r\n    >>> sess=tf.Session()\r\n    2018-02-12 16:22:11.752327: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n    2018-02-12 16:22:12.120254: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1030] Found device 0 with properties:\r\n    name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\n    pciBusID: 0000:01:00.0\r\n    totalMemory: 6.00GiB freeMemory: 4.96GiB\r\n    2018-02-12 16:22:12.120473: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n\r\nConfirmation that it is grabbing the GPU memory:\r\n\r\n    >nvidia-smi\r\n    Mon Feb 12 16:23:12 2018\r\n    +-----------------------------------------------------------------------------+\r\n    | NVIDIA-SMI 385.69                 Driver Version: 385.69                    |\r\n    |-------------------------------+----------------------+----------------------+\r\n    | GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n    |===============================+======================+======================|\r\n    |   0  GeForce GTX 1060   WDDM  | 00000000:01:00.0  On |                  N/A |\r\n    | N/A   57C    P2    27W /  N/A |   5763MiB /  6144MiB |      0%      Default |\r\n    +-------------------------------+----------------------+----------------------+\r\n\r\nWorkaround for now is to set CUDA_VISIBLE_DEVICES=\"-1\" which generates a seemingly benign error message as a side effect:\r\n\r\n    2018-02-12 16:09:01.981599: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n\r\nedit: turns out that workaround came from #2175 ... woops"}