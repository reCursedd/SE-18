{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/402688206", "html_url": "https://github.com/tensorflow/tensorflow/issues/20527#issuecomment-402688206", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20527", "id": 402688206, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjY4ODIwNg==", "user": {"login": "ORippler", "id": 24656669, "node_id": "MDQ6VXNlcjI0NjU2NjY5", "avatar_url": "https://avatars0.githubusercontent.com/u/24656669?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ORippler", "html_url": "https://github.com/ORippler", "followers_url": "https://api.github.com/users/ORippler/followers", "following_url": "https://api.github.com/users/ORippler/following{/other_user}", "gists_url": "https://api.github.com/users/ORippler/gists{/gist_id}", "starred_url": "https://api.github.com/users/ORippler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ORippler/subscriptions", "organizations_url": "https://api.github.com/users/ORippler/orgs", "repos_url": "https://api.github.com/users/ORippler/repos", "events_url": "https://api.github.com/users/ORippler/events{/privacy}", "received_events_url": "https://api.github.com/users/ORippler/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-05T11:08:53Z", "updated_at": "2018-07-05T11:13:27Z", "author_association": "NONE", "body_html": "<p>According to <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/nn_ops.py#L1485-L1488\">documentation,</a> nn.bias_add supports N-d tensors due to broadcasting.</p>\n<p>However, the underlying <a href=\"https://github.com/tensorflow/tensorflow/blob/86f5ab7474825da756838b34e1b4eac93f5fc68a/tensorflow/core/ops/nn_ops.cc#L430-L455\">C implementation/documentation</a>  states explicitly that for NCHW, bias would be added to third-to-the-last dimension, which forces the reshape operations.</p>\n<p>I would therefore suggest a change here, such that bias is added to first dimension instead of third-to-the-last dimension, as channels will always be first dim in NCHW format. This would make reshaping operations obsolete.</p>\n<p>Unfortunately, I am unfamiliar with the tensorflow C backend, and therefore do not know where the change would need to be made.</p>", "body_text": "According to documentation, nn.bias_add supports N-d tensors due to broadcasting.\nHowever, the underlying C implementation/documentation  states explicitly that for NCHW, bias would be added to third-to-the-last dimension, which forces the reshape operations.\nI would therefore suggest a change here, such that bias is added to first dimension instead of third-to-the-last dimension, as channels will always be first dim in NCHW format. This would make reshaping operations obsolete.\nUnfortunately, I am unfamiliar with the tensorflow C backend, and therefore do not know where the change would need to be made.", "body": "According to [documentation,](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/nn_ops.py#L1485-L1488) nn.bias_add supports N-d tensors due to broadcasting.\r\n\r\nHowever, the underlying [C implementation/documentation](https://github.com/tensorflow/tensorflow/blob/86f5ab7474825da756838b34e1b4eac93f5fc68a/tensorflow/core/ops/nn_ops.cc#L430-L455)  states explicitly that for NCHW, bias would be added to third-to-the-last dimension, which forces the reshape operations.\r\n\r\nI would therefore suggest a change here, such that bias is added to first dimension instead of third-to-the-last dimension, as channels will always be first dim in NCHW format. This would make reshaping operations obsolete.\r\n\r\nUnfortunately, I am unfamiliar with the tensorflow C backend, and therefore do not know where the change would need to be made."}