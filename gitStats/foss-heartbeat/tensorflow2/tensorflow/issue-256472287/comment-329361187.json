{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/329361187", "html_url": "https://github.com/tensorflow/tensorflow/issues/12940#issuecomment-329361187", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12940", "id": 329361187, "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTM2MTE4Nw==", "user": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-14T03:42:01Z", "updated_at": "2017-09-14T03:42:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm not aware of any specific issues, kernels get faster as important models need them!  In general, convolutions of different sizes will have different performance characteristics, and it's possible our separable convolution implementations may be slow for some combinations of shapes.  I'm not sure whether that's the case here, but it could be.  I also don't know whether theory matches practice here, since separable convolutions are less compute dense than normal convolutions.  I believe the benefits you get are that you get to use fewer parameters to express a larger capacity convolution.</p>", "body_text": "I'm not aware of any specific issues, kernels get faster as important models need them!  In general, convolutions of different sizes will have different performance characteristics, and it's possible our separable convolution implementations may be slow for some combinations of shapes.  I'm not sure whether that's the case here, but it could be.  I also don't know whether theory matches practice here, since separable convolutions are less compute dense than normal convolutions.  I believe the benefits you get are that you get to use fewer parameters to express a larger capacity convolution.", "body": "I'm not aware of any specific issues, kernels get faster as important models need them!  In general, convolutions of different sizes will have different performance characteristics, and it's possible our separable convolution implementations may be slow for some combinations of shapes.  I'm not sure whether that's the case here, but it could be.  I also don't know whether theory matches practice here, since separable convolutions are less compute dense than normal convolutions.  I believe the benefits you get are that you get to use fewer parameters to express a larger capacity convolution."}