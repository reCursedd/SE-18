{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23630", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23630/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23630/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23630/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23630", "id": 379143137, "node_id": "MDU6SXNzdWUzNzkxNDMxMzc=", "number": 23630, "title": "The output of trained model is constant when using batch normalization", "user": {"login": "LJXLJXLJX", "id": 29445795, "node_id": "MDQ6VXNlcjI5NDQ1Nzk1", "avatar_url": "https://avatars2.githubusercontent.com/u/29445795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LJXLJXLJX", "html_url": "https://github.com/LJXLJXLJX", "followers_url": "https://api.github.com/users/LJXLJXLJX/followers", "following_url": "https://api.github.com/users/LJXLJXLJX/following{/other_user}", "gists_url": "https://api.github.com/users/LJXLJXLJX/gists{/gist_id}", "starred_url": "https://api.github.com/users/LJXLJXLJX/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LJXLJXLJX/subscriptions", "organizations_url": "https://api.github.com/users/LJXLJXLJX/orgs", "repos_url": "https://api.github.com/users/LJXLJXLJX/repos", "events_url": "https://api.github.com/users/LJXLJXLJX/events{/privacy}", "received_events_url": "https://api.github.com/users/LJXLJXLJX/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-09T12:28:15Z", "updated_at": "2018-11-11T12:54:17Z", "closed_at": "2018-11-11T12:54:17Z", "author_association": "NONE", "body_html": "<p>I have trained a model with tensorflow, with the use of batch normalization.</p>\n<pre><code>conv2 = slim.conv2d(\ninputs=pool1,\nnum_outputs=64,\nkernel_size=[5, 5],\npadding=\"same\",\nnormalizer_fn=slim.batch_norm,\nactivation_fn=tf.nn.relu)\n</code></pre>\n<p>And the model has been trained well, I can see the loss curve has been falling in tensorboard, and the validation accuracy reached 99%+</p>\n<p>Then I saved my model as ckpt files. But when I tried to load my model from ckpt files and do some prediction, what ever I feed to the model, the output is always an constant array.</p>\n<p>Then I removed all bn layer, and train my model and save it as ckpt again.When I load it and do prediction, it works well.</p>\n<p>Can anybody tell me why?</p>", "body_text": "I have trained a model with tensorflow, with the use of batch normalization.\nconv2 = slim.conv2d(\ninputs=pool1,\nnum_outputs=64,\nkernel_size=[5, 5],\npadding=\"same\",\nnormalizer_fn=slim.batch_norm,\nactivation_fn=tf.nn.relu)\n\nAnd the model has been trained well, I can see the loss curve has been falling in tensorboard, and the validation accuracy reached 99%+\nThen I saved my model as ckpt files. But when I tried to load my model from ckpt files and do some prediction, what ever I feed to the model, the output is always an constant array.\nThen I removed all bn layer, and train my model and save it as ckpt again.When I load it and do prediction, it works well.\nCan anybody tell me why?", "body": "I have trained a model with tensorflow, with the use of batch normalization.\r\n\r\n```\r\nconv2 = slim.conv2d(\r\ninputs=pool1,\r\nnum_outputs=64,\r\nkernel_size=[5, 5],\r\npadding=\"same\",\r\nnormalizer_fn=slim.batch_norm,\r\nactivation_fn=tf.nn.relu)\r\n```\r\nAnd the model has been trained well, I can see the loss curve has been falling in tensorboard, and the validation accuracy reached 99%+\r\n\r\nThen I saved my model as ckpt files. But when I tried to load my model from ckpt files and do some prediction, what ever I feed to the model, the output is always an constant array.\r\n\r\nThen I removed all bn layer, and train my model and save it as ckpt again.When I load it and do prediction, it works well.\r\n\r\nCan anybody tell me why?\r\n"}