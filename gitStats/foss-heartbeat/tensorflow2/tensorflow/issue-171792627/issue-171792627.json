{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3889", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3889/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3889/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3889/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3889", "id": 171792627, "node_id": "MDU6SXNzdWUxNzE3OTI2Mjc=", "number": 3889, "title": "Control flow gradient problem with `tf.float16` datatype", "user": {"login": "classner", "id": 731387, "node_id": "MDQ6VXNlcjczMTM4Nw==", "avatar_url": "https://avatars1.githubusercontent.com/u/731387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/classner", "html_url": "https://github.com/classner", "followers_url": "https://api.github.com/users/classner/followers", "following_url": "https://api.github.com/users/classner/following{/other_user}", "gists_url": "https://api.github.com/users/classner/gists{/gist_id}", "starred_url": "https://api.github.com/users/classner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/classner/subscriptions", "organizations_url": "https://api.github.com/users/classner/orgs", "repos_url": "https://api.github.com/users/classner/repos", "events_url": "https://api.github.com/users/classner/events{/privacy}", "received_events_url": "https://api.github.com/users/classner/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2016-08-18T00:40:05Z", "updated_at": "2017-01-24T22:12:35Z", "closed_at": "2017-01-24T22:12:35Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System:<br>\nLinux</p>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)<br>\n<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/3cb39956e622b322e43547cf2b6e337020643f21/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/3cb39956e622b322e43547cf2b6e337020643f21\"><tt>3cb3995</tt></a></li>\n<li>The output of <code>bazel version</code></li>\n</ol>\n<pre><code>Build label: 0.3.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:09:52 2016 (1469783392)\nBuild timestamp: 1469783392\nBuild timestamp as int: 1469783392\n\n</code></pre>\n<h3>Steps to reproduce</h3>\n<pre><code># Minimal example to reproduce the error.\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import conv2d, batch_norm\nsess = tf.InteractiveSession()\nis_train_var = tf.placeholder(tf.bool)\n# If `tf.float32` is used here, it works flawlessly. Alternatively,\n# if a constant instead of a variable is used for `is_training`,\n# everything works as expected.\ninp = tf.placeholder(tf.float16, [1, 5, 5, 3], name='data')\nconv1 = conv2d(inp, 1, 5, padding='VALID',\n               normalizer_fn=batch_norm,\n               normalizer_params={'is_training': is_train_var})\noptimizer = tf.train.MomentumOptimizer(learning_rate=0.1, momentum=0.9)\noptimizer.compute_gradients(conv1)\n</code></pre>\n<p>This results in the error</p>\n<pre><code>Traceback (most recent call last):\n  File \"repr.py\", line 10, in &lt;module&gt;\n    optimizer.compute_gradients(conv1)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/gradients.py\", line 478, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/control_flow_grad.py\", line 69, in _SwitchGrad\n    return merge([good_grad, zero_grad], name=\"cond_grad\")[0], None\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/control_flow_ops.py\", line 361, in merge\n    return gen_control_flow_ops._merge(inputs, name)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/gen_control_flow_ops.py\", line 153, in _merge\n    result = _op_def_lib.apply_op(\"Merge\", inputs=inputs, name=name)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 437, in apply_op\n    raise TypeError(\"%s that don't all match.\" % prefix)\nTypeError: Tensors in list passed to 'inputs' of 'Merge' Op have types [float16, float32] that don't all match.\n</code></pre>\n<h3>What have you tried?</h3>\n<p>I am currently using constant variables as a workaround as described.</p>", "body_text": "Environment info\nOperating System:\nLinux\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD)\n3cb3995\nThe output of bazel version\n\nBuild label: 0.3.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:09:52 2016 (1469783392)\nBuild timestamp: 1469783392\nBuild timestamp as int: 1469783392\n\n\nSteps to reproduce\n# Minimal example to reproduce the error.\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import conv2d, batch_norm\nsess = tf.InteractiveSession()\nis_train_var = tf.placeholder(tf.bool)\n# If `tf.float32` is used here, it works flawlessly. Alternatively,\n# if a constant instead of a variable is used for `is_training`,\n# everything works as expected.\ninp = tf.placeholder(tf.float16, [1, 5, 5, 3], name='data')\nconv1 = conv2d(inp, 1, 5, padding='VALID',\n               normalizer_fn=batch_norm,\n               normalizer_params={'is_training': is_train_var})\noptimizer = tf.train.MomentumOptimizer(learning_rate=0.1, momentum=0.9)\noptimizer.compute_gradients(conv1)\n\nThis results in the error\nTraceback (most recent call last):\n  File \"repr.py\", line 10, in <module>\n    optimizer.compute_gradients(conv1)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/gradients.py\", line 478, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/control_flow_grad.py\", line 69, in _SwitchGrad\n    return merge([good_grad, zero_grad], name=\"cond_grad\")[0], None\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/control_flow_ops.py\", line 361, in merge\n    return gen_control_flow_ops._merge(inputs, name)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/gen_control_flow_ops.py\", line 153, in _merge\n    result = _op_def_lib.apply_op(\"Merge\", inputs=inputs, name=name)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 437, in apply_op\n    raise TypeError(\"%s that don't all match.\" % prefix)\nTypeError: Tensors in list passed to 'inputs' of 'Merge' Op have types [float16, float32] that don't all match.\n\nWhat have you tried?\nI am currently using constant variables as a workaround as described.", "body": "### Environment info\n\nOperating System:\nLinux\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n   3cb39956e622b322e43547cf2b6e337020643f21\n2. The output of `bazel version`\n\n```\nBuild label: 0.3.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:09:52 2016 (1469783392)\nBuild timestamp: 1469783392\nBuild timestamp as int: 1469783392\n\n```\n### Steps to reproduce\n\n```\n# Minimal example to reproduce the error.\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import conv2d, batch_norm\nsess = tf.InteractiveSession()\nis_train_var = tf.placeholder(tf.bool)\n# If `tf.float32` is used here, it works flawlessly. Alternatively,\n# if a constant instead of a variable is used for `is_training`,\n# everything works as expected.\ninp = tf.placeholder(tf.float16, [1, 5, 5, 3], name='data')\nconv1 = conv2d(inp, 1, 5, padding='VALID',\n               normalizer_fn=batch_norm,\n               normalizer_params={'is_training': is_train_var})\noptimizer = tf.train.MomentumOptimizer(learning_rate=0.1, momentum=0.9)\noptimizer.compute_gradients(conv1)\n```\n\nThis results in the error\n\n```\nTraceback (most recent call last):\n  File \"repr.py\", line 10, in <module>\n    optimizer.compute_gradients(conv1)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/gradients.py\", line 478, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/control_flow_grad.py\", line 69, in _SwitchGrad\n    return merge([good_grad, zero_grad], name=\"cond_grad\")[0], None\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/control_flow_ops.py\", line 361, in merge\n    return gen_control_flow_ops._merge(inputs, name)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/ops/gen_control_flow_ops.py\", line 153, in _merge\n    result = _op_def_lib.apply_op(\"Merge\", inputs=inputs, name=name)\n  File \"/lustre/home/classner/git/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 437, in apply_op\n    raise TypeError(\"%s that don't all match.\" % prefix)\nTypeError: Tensors in list passed to 'inputs' of 'Merge' Op have types [float16, float32] that don't all match.\n```\n### What have you tried?\n\nI am currently using constant variables as a workaround as described.\n"}