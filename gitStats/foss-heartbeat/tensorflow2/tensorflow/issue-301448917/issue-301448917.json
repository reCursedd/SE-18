{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17358", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17358/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17358/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17358/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17358", "id": 301448917, "node_id": "MDU6SXNzdWUzMDE0NDg5MTc=", "number": 17358, "title": "Distributed training: Evaluation and inference best practices", "user": {"login": "apiro", "id": 2962472, "node_id": "MDQ6VXNlcjI5NjI0NzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2962472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apiro", "html_url": "https://github.com/apiro", "followers_url": "https://api.github.com/users/apiro/followers", "following_url": "https://api.github.com/users/apiro/following{/other_user}", "gists_url": "https://api.github.com/users/apiro/gists{/gist_id}", "starred_url": "https://api.github.com/users/apiro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apiro/subscriptions", "organizations_url": "https://api.github.com/users/apiro/orgs", "repos_url": "https://api.github.com/users/apiro/repos", "events_url": "https://api.github.com/users/apiro/events{/privacy}", "received_events_url": "https://api.github.com/users/apiro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-01T15:33:26Z", "updated_at": "2018-03-01T19:00:43Z", "closed_at": "2018-03-01T19:00:43Z", "author_association": "NONE", "body_html": "<p>I understand tensorflow distributed training and I implemented my own script.</p>\n<p>What I want to do now is to integrate the possibility of assigning some workers the task of asynchronously evaluate the model.</p>\n<p>Let's say we have 6 workers, what I want to do is to use 4 of them to do asynchronous training, one to periodically evaluate the model and another one to periodically make inference on it.</p>\n<p>My intuition to achieve this goal is to do the following:</p>\n<pre><code>...\nelif FLAGS.job_name == \"worker\":\n\n    if FLAGS.task_index &lt;= (len(cluster_dict[\"worker\"][:-2]) - 1):\n         logging.info(\"Training worker started\")\n         ...\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                cluster=cluster,\n                ps_tasks=len(cluster_dict[\"ps\"])\n            )):\n                train_model = Model(\n                    mode=tf.contrib.learn.ModeKeys.TRAIN\n                )\n               with tf.train.MonitoredTrainingSession(\n                    is_chief=(FLAGS.task_index == 0),\n                    master=server.target,\n                    checkpoint_dir=ckpt_dir,\n                    config=config_proto,\n                    hooks=hooks\n                ) as mon_sess:\n                    while not mon_sess.should_stop():\n                        res = train_model.train(...)\n                        ...\n\n   elif FLAGS.task_index == (len(cluster_dict[\"worker\"][-2]) - 1):\n         logging.info(\"Evaluation worker started\")\n         ...\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                cluster=cluster,\n                ps_tasks=len(cluster_dict[\"ps\"])\n            )):\n                eval_model = Model(\n                    mode=tf.contrib.learn.ModeKeys.EVAL\n                )\n                ...\n\n   elif FLAGS.task_index == (len(cluster_dict[\"worker\"][-1]) - 1):\n        logging.info(\"Inference worker started\")\n        ...\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                cluster=cluster,\n                ps_tasks=len(cluster_dict[\"ps\"])\n            )):\n                infer_model = Model(\n                    mode=tf.contrib.learn.ModeKeys.INFER\n                )\n                ...\n</code></pre>\n<p>Now, what about the evaluation and inference sessions?<br>\nFor training, I can use <code>tf.train.MonitoredTrainingSession</code>, but for evaluation and inference I don't see such a cozy solution and the only possibility that I see is to use <code>tf.Session</code>.</p>\n<p>Regarding the actual evaluation and inference loop, I thought to use a while loop inside which the worker periodically calls  <code>eval_model.eval(...)</code> or  <code>infer_model.infer(...)</code>, but this means that the evaluation is performed considering the time and not considering the global_step and the only meaning that I can give to \"periodically\" is to sleep the thread.</p>\n<p>What do you think about this solution? Is it the correct way to asynchronously perform training, evaluation, and inference?</p>\n<p>Alberto</p>", "body_text": "I understand tensorflow distributed training and I implemented my own script.\nWhat I want to do now is to integrate the possibility of assigning some workers the task of asynchronously evaluate the model.\nLet's say we have 6 workers, what I want to do is to use 4 of them to do asynchronous training, one to periodically evaluate the model and another one to periodically make inference on it.\nMy intuition to achieve this goal is to do the following:\n...\nelif FLAGS.job_name == \"worker\":\n\n    if FLAGS.task_index <= (len(cluster_dict[\"worker\"][:-2]) - 1):\n         logging.info(\"Training worker started\")\n         ...\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                cluster=cluster,\n                ps_tasks=len(cluster_dict[\"ps\"])\n            )):\n                train_model = Model(\n                    mode=tf.contrib.learn.ModeKeys.TRAIN\n                )\n               with tf.train.MonitoredTrainingSession(\n                    is_chief=(FLAGS.task_index == 0),\n                    master=server.target,\n                    checkpoint_dir=ckpt_dir,\n                    config=config_proto,\n                    hooks=hooks\n                ) as mon_sess:\n                    while not mon_sess.should_stop():\n                        res = train_model.train(...)\n                        ...\n\n   elif FLAGS.task_index == (len(cluster_dict[\"worker\"][-2]) - 1):\n         logging.info(\"Evaluation worker started\")\n         ...\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                cluster=cluster,\n                ps_tasks=len(cluster_dict[\"ps\"])\n            )):\n                eval_model = Model(\n                    mode=tf.contrib.learn.ModeKeys.EVAL\n                )\n                ...\n\n   elif FLAGS.task_index == (len(cluster_dict[\"worker\"][-1]) - 1):\n        logging.info(\"Inference worker started\")\n        ...\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                cluster=cluster,\n                ps_tasks=len(cluster_dict[\"ps\"])\n            )):\n                infer_model = Model(\n                    mode=tf.contrib.learn.ModeKeys.INFER\n                )\n                ...\n\nNow, what about the evaluation and inference sessions?\nFor training, I can use tf.train.MonitoredTrainingSession, but for evaluation and inference I don't see such a cozy solution and the only possibility that I see is to use tf.Session.\nRegarding the actual evaluation and inference loop, I thought to use a while loop inside which the worker periodically calls  eval_model.eval(...) or  infer_model.infer(...), but this means that the evaluation is performed considering the time and not considering the global_step and the only meaning that I can give to \"periodically\" is to sleep the thread.\nWhat do you think about this solution? Is it the correct way to asynchronously perform training, evaluation, and inference?\nAlberto", "body": "I understand tensorflow distributed training and I implemented my own script.\r\n\r\nWhat I want to do now is to integrate the possibility of assigning some workers the task of asynchronously evaluate the model.\r\n\r\nLet's say we have 6 workers, what I want to do is to use 4 of them to do asynchronous training, one to periodically evaluate the model and another one to periodically make inference on it.\r\n\r\nMy intuition to achieve this goal is to do the following:\r\n\r\n```\r\n...\r\nelif FLAGS.job_name == \"worker\":\r\n\r\n    if FLAGS.task_index <= (len(cluster_dict[\"worker\"][:-2]) - 1):\r\n         logging.info(\"Training worker started\")\r\n         ...\r\n        with tf.device(tf.train.replica_device_setter(\r\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\r\n                cluster=cluster,\r\n                ps_tasks=len(cluster_dict[\"ps\"])\r\n            )):\r\n                train_model = Model(\r\n                    mode=tf.contrib.learn.ModeKeys.TRAIN\r\n                )\r\n               with tf.train.MonitoredTrainingSession(\r\n                    is_chief=(FLAGS.task_index == 0),\r\n                    master=server.target,\r\n                    checkpoint_dir=ckpt_dir,\r\n                    config=config_proto,\r\n                    hooks=hooks\r\n                ) as mon_sess:\r\n                    while not mon_sess.should_stop():\r\n                        res = train_model.train(...)\r\n                        ...\r\n\r\n   elif FLAGS.task_index == (len(cluster_dict[\"worker\"][-2]) - 1):\r\n         logging.info(\"Evaluation worker started\")\r\n         ...\r\n        with tf.device(tf.train.replica_device_setter(\r\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\r\n                cluster=cluster,\r\n                ps_tasks=len(cluster_dict[\"ps\"])\r\n            )):\r\n                eval_model = Model(\r\n                    mode=tf.contrib.learn.ModeKeys.EVAL\r\n                )\r\n                ...\r\n\r\n   elif FLAGS.task_index == (len(cluster_dict[\"worker\"][-1]) - 1):\r\n        logging.info(\"Inference worker started\")\r\n        ...\r\n        with tf.device(tf.train.replica_device_setter(\r\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\r\n                cluster=cluster,\r\n                ps_tasks=len(cluster_dict[\"ps\"])\r\n            )):\r\n                infer_model = Model(\r\n                    mode=tf.contrib.learn.ModeKeys.INFER\r\n                )\r\n                ...\r\n```\r\n\r\nNow, what about the evaluation and inference sessions? \r\nFor training, I can use ```tf.train.MonitoredTrainingSession```, but for evaluation and inference I don't see such a cozy solution and the only possibility that I see is to use ```tf.Session```.\r\n\r\nRegarding the actual evaluation and inference loop, I thought to use a while loop inside which the worker periodically calls  ```eval_model.eval(...)``` or  ```infer_model.infer(...)```, but this means that the evaluation is performed considering the time and not considering the global_step and the only meaning that I can give to \"periodically\" is to sleep the thread.\r\n\r\nWhat do you think about this solution? Is it the correct way to asynchronously perform training, evaluation, and inference?\r\n\r\nAlberto\r\n"}