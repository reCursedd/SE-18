{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277161413", "html_url": "https://github.com/tensorflow/tensorflow/issues/7236#issuecomment-277161413", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7236", "id": 277161413, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NzE2MTQxMw==", "user": {"login": "altosaar", "id": 5317244, "node_id": "MDQ6VXNlcjUzMTcyNDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/5317244?v=4", "gravatar_id": "", "url": "https://api.github.com/users/altosaar", "html_url": "https://github.com/altosaar", "followers_url": "https://api.github.com/users/altosaar/followers", "following_url": "https://api.github.com/users/altosaar/following{/other_user}", "gists_url": "https://api.github.com/users/altosaar/gists{/gist_id}", "starred_url": "https://api.github.com/users/altosaar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/altosaar/subscriptions", "organizations_url": "https://api.github.com/users/altosaar/orgs", "repos_url": "https://api.github.com/users/altosaar/repos", "events_url": "https://api.github.com/users/altosaar/events{/privacy}", "received_events_url": "https://api.github.com/users/altosaar/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-03T04:22:02Z", "updated_at": "2017-02-03T04:22:02Z", "author_association": "NONE", "body_html": "<p>Thanks to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=718528\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/poolio\">@poolio</a> - it's because of reparameterization:</p>\n<pre><code>eps ~ N(0, 1)\nz = mu + sigma * eps\nq.log_pdf(z) ~= -(z - mu)^2 / 2 = - (mu + sigma * eps - mu)^2 / 2 = - (sigma * eps)^2 / 2\n</code></pre>\n<p>so it makes sense that the gradient is zero.</p>\n<p>This is very unexpected behavior and broke my regression model.</p>\n<p>Distributions should abstract parameters: a sample should be treated as a new tensor.</p>\n<p>Is there a discussion of this anywhere?</p>", "body_text": "Thanks to @poolio - it's because of reparameterization:\neps ~ N(0, 1)\nz = mu + sigma * eps\nq.log_pdf(z) ~= -(z - mu)^2 / 2 = - (mu + sigma * eps - mu)^2 / 2 = - (sigma * eps)^2 / 2\n\nso it makes sense that the gradient is zero.\nThis is very unexpected behavior and broke my regression model.\nDistributions should abstract parameters: a sample should be treated as a new tensor.\nIs there a discussion of this anywhere?", "body": "Thanks to @poolio - it's because of reparameterization:\r\n\r\n```\r\neps ~ N(0, 1)\r\nz = mu + sigma * eps\r\nq.log_pdf(z) ~= -(z - mu)^2 / 2 = - (mu + sigma * eps - mu)^2 / 2 = - (sigma * eps)^2 / 2\r\n```\r\n\r\nso it makes sense that the gradient is zero. \r\n\r\nThis is very unexpected behavior and broke my regression model. \r\n\r\nDistributions should abstract parameters: a sample should be treated as a new tensor. \r\n\r\nIs there a discussion of this anywhere?"}