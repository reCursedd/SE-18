{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21238", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21238/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21238/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21238/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21238", "id": 345679766, "node_id": "MDU6SXNzdWUzNDU2Nzk3NjY=", "number": 21238, "title": "DecodeBase64 is not supported for Android TensorFlowInferenceInterface", "user": {"login": "tobegit3hub", "id": 2715000, "node_id": "MDQ6VXNlcjI3MTUwMDA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2715000?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tobegit3hub", "html_url": "https://github.com/tobegit3hub", "followers_url": "https://api.github.com/users/tobegit3hub/followers", "following_url": "https://api.github.com/users/tobegit3hub/following{/other_user}", "gists_url": "https://api.github.com/users/tobegit3hub/gists{/gist_id}", "starred_url": "https://api.github.com/users/tobegit3hub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tobegit3hub/subscriptions", "organizations_url": "https://api.github.com/users/tobegit3hub/orgs", "repos_url": "https://api.github.com/users/tobegit3hub/repos", "events_url": "https://api.github.com/users/tobegit3hub/events{/privacy}", "received_events_url": "https://api.github.com/users/tobegit3hub/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-07-30T09:28:28Z", "updated_at": "2018-08-13T10:08:43Z", "closed_at": "2018-08-13T10:08:43Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<p>== cat /etc/issue ===============================================<br>\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64<br>\nMac OS X 10.13.4</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nApple LLVM version 9.1.0 (clang-902.0.39.1)<br>\nTarget: x86_64-apple-darwin17.5.0<br>\nThread model: posix<br>\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin</p>\n<p>== uname -a =====================================================<br>\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64</p>\n<p>== check pips ===================================================<br>\nnumpy                              1.14.2<br>\nprotobuf                           3.5.2.post1<br>\ntensorflow                         1.8.0<br>\ntensorflow-hub                     0.1.0<br>\ntensorflow-model-analysis          0.6.0<br>\ntensorflow-serving-api             1.8.0<br>\ntensorflow-tensorboard             1.5.0<br>\ntensorflow-transform               0.6.0<br>\ntensorflowjs                       0.1.0<br>\ntensorflowonspark                  1.0.0</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.8.0<br>\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072<br>\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072<br>\nSanity check: array([1], dtype=int32)<br>\n/usr/local/lib/python2.7/site-packages/h5py/<strong>init</strong>.py:36: FutureWarning: Conversion of the second argument of issubdtype from <code>float</code> to <code>np.floating</code> is deprecated. In future, it will be treated as <code>np.float64 == np.dtype(float).type</code>.<br>\nfrom ._conv import register_converters as _register_converters</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH is unset<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\ntf_env_collect.sh: line 105: nvidia-smi: command not found</p>\n<p>== cuda libs  ===================================================</p>\n<p>Have I written custom code:<br>\nNo</p>\n<p>OS Platform and Distribution:<br>\nMacOS</p>\n<p>TensorFlow installed from:<br>\n<code>pip install tensorflow</code></p>\n<p>TensorFlow version:<br>\n1.8.0</p>\n<p>Bazel version:<br>\n0.5.4</p>\n<p>CUDA/cuDNN version<br>\nN/A</p>\n<p>GPU model and memory:<br>\nN/A</p>\n<p>Exact command to reproduce:<br>\nFollow the official and deploy the model with DecodeBase64 operator.</p>\n<p>Mobile device:<br>\nXiaomi MIX 2</p>\n<h3>Describe the problem</h3>\n<p>We have the problem to deploy the image model to Android platform. It throws <code>No OpKernel was registered to support Op 'DecodeBase64' with these attrs</code>. And we have tried feeding string or byte array like these.</p>\n<pre><code>image_string = \"foo\"\n\nbyte[] image_bytes = image_string.getBytes();\n\nString inputName = \"model_input_b64_images\";\n \ninferenceInterface.feedString(inputName, image_bytes);\n\ninferenceInterface.feed(inputName, image_bytes, 1, 4860);\n</code></pre>\n<p>Is it possible to implement and registry the kernel for <code>DecodeBase64</code> which is really important for image models? Or we have another way to feed the data for this Operator.</p>\n<h3>Source code / logs</h3>\n<p>It is easy to re-produce the issue. Try exporting the model which has the <code>DecodeBase64</code> operator and use the <code>freeze_graph.py</code> to generated the Android model file.</p>\n<p>Here is the complete log when trying to run the inference in Android.</p>\n<pre><code>\n07-30 16:58:35.943 14616-14616/com.tobe.androidclient E/AndroidRuntime: FATAL EXCEPTION: main\nProcess: com.tobe.androidclient, PID: 14616\njava.lang.RuntimeException: Unable to start activity ComponentInfo{com.tobe.androidclient/com.tobe.androidclient.MainActivity}: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'DecodeBase64' with these attrs.  Registered devices: [CPU], Registered kernels:\n  &lt;no registered kernels&gt;\n\n\t [[Node: DecodeBase64 = DecodeBase64[](model_input_b64_images)]]\n    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2855)\n    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2930)\n    at android.app.ActivityThread.-wrap11(Unknown Source:0)\n    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1619)\n    at android.os.Handler.dispatchMessage(Handler.java:105)\n    at android.os.Looper.loop(Looper.java:171)\n    at android.app.ActivityThread.main(ActivityThread.java:6684)\n    at java.lang.reflect.Method.invoke(Native Method)\n    at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:246)\n    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:783)\n Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'DecodeBase64' with these attrs.  Registered devices: [CPU], Registered kernels:\n  &lt;no registered kernels&gt;\n\n\t [[Node: DecodeBase64 = DecodeBase64[](model_input_b64_images)]]\n    at org.tensorflow.Session.run(Native Method)\n    at org.tensorflow.Session.access$100(Session.java:48)\n    at org.tensorflow.Session$Runner.runHelper(Session.java:298)\n    at org.tensorflow.Session$Runner.runAndFetchMetadata(Session.java:260)\n    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:220)\n    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:197)\n    at com.tobe.androidclient.MainActivity.onCreate(MainActivity.java:98)\n    at android.app.Activity.performCreate(Activity.java:7057)\n    at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1214)\n    at android.app.ActivityThread.performLaun\n</code></pre>", "body_text": "System information\n== cat /etc/issue ===============================================\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\nMac OS X 10.13.4\n== are we in docker =============================================\nNo\n== compiler =====================================================\nApple LLVM version 9.1.0 (clang-902.0.39.1)\nTarget: x86_64-apple-darwin17.5.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n== uname -a =====================================================\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\n== check pips ===================================================\nnumpy                              1.14.2\nprotobuf                           3.5.2.post1\ntensorflow                         1.8.0\ntensorflow-hub                     0.1.0\ntensorflow-model-analysis          0.6.0\ntensorflow-serving-api             1.8.0\ntensorflow-tensorboard             1.5.0\ntensorflow-transform               0.6.0\ntensorflowjs                       0.1.0\ntensorflowonspark                  1.0.0\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.8.0\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\nSanity check: array([1], dtype=int32)\n/usr/local/lib/python2.7/site-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.\nfrom ._conv import register_converters as _register_converters\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\ntf_env_collect.sh: line 105: nvidia-smi: command not found\n== cuda libs  ===================================================\nHave I written custom code:\nNo\nOS Platform and Distribution:\nMacOS\nTensorFlow installed from:\npip install tensorflow\nTensorFlow version:\n1.8.0\nBazel version:\n0.5.4\nCUDA/cuDNN version\nN/A\nGPU model and memory:\nN/A\nExact command to reproduce:\nFollow the official and deploy the model with DecodeBase64 operator.\nMobile device:\nXiaomi MIX 2\nDescribe the problem\nWe have the problem to deploy the image model to Android platform. It throws No OpKernel was registered to support Op 'DecodeBase64' with these attrs. And we have tried feeding string or byte array like these.\nimage_string = \"foo\"\n\nbyte[] image_bytes = image_string.getBytes();\n\nString inputName = \"model_input_b64_images\";\n \ninferenceInterface.feedString(inputName, image_bytes);\n\ninferenceInterface.feed(inputName, image_bytes, 1, 4860);\n\nIs it possible to implement and registry the kernel for DecodeBase64 which is really important for image models? Or we have another way to feed the data for this Operator.\nSource code / logs\nIt is easy to re-produce the issue. Try exporting the model which has the DecodeBase64 operator and use the freeze_graph.py to generated the Android model file.\nHere is the complete log when trying to run the inference in Android.\n\n07-30 16:58:35.943 14616-14616/com.tobe.androidclient E/AndroidRuntime: FATAL EXCEPTION: main\nProcess: com.tobe.androidclient, PID: 14616\njava.lang.RuntimeException: Unable to start activity ComponentInfo{com.tobe.androidclient/com.tobe.androidclient.MainActivity}: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'DecodeBase64' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: DecodeBase64 = DecodeBase64[](model_input_b64_images)]]\n    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2855)\n    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2930)\n    at android.app.ActivityThread.-wrap11(Unknown Source:0)\n    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1619)\n    at android.os.Handler.dispatchMessage(Handler.java:105)\n    at android.os.Looper.loop(Looper.java:171)\n    at android.app.ActivityThread.main(ActivityThread.java:6684)\n    at java.lang.reflect.Method.invoke(Native Method)\n    at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:246)\n    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:783)\n Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'DecodeBase64' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: DecodeBase64 = DecodeBase64[](model_input_b64_images)]]\n    at org.tensorflow.Session.run(Native Method)\n    at org.tensorflow.Session.access$100(Session.java:48)\n    at org.tensorflow.Session$Runner.runHelper(Session.java:298)\n    at org.tensorflow.Session$Runner.runAndFetchMetadata(Session.java:260)\n    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:220)\n    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:197)\n    at com.tobe.androidclient.MainActivity.onCreate(MainActivity.java:98)\n    at android.app.Activity.performCreate(Activity.java:7057)\n    at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1214)\n    at android.app.ActivityThread.performLaun", "body": "### System information\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.1)\r\nTarget: x86_64-apple-darwin17.5.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.2\r\nprotobuf                           3.5.2.post1\r\ntensorflow                         1.8.0\r\ntensorflow-hub                     0.1.0\r\ntensorflow-model-analysis          0.6.0\r\ntensorflow-serving-api             1.8.0\r\ntensorflow-tensorboard             1.5.0\r\ntensorflow-transform               0.6.0\r\ntensorflowjs                       0.1.0\r\ntensorflowonspark                  1.0.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n\r\nHave I written custom code:\r\nNo\r\n\r\nOS Platform and Distribution:\r\nMacOS\r\n\r\nTensorFlow installed from:\r\n`pip install tensorflow`\r\n\r\nTensorFlow version:\r\n1.8.0\r\n\r\nBazel version:\r\n0.5.4\r\n\r\nCUDA/cuDNN version\r\nN/A\r\n\r\nGPU model and memory:\r\nN/A\r\n\r\nExact command to reproduce:\r\nFollow the official and deploy the model with DecodeBase64 operator.\r\n\r\nMobile device:\r\nXiaomi MIX 2\r\n\r\n### Describe the problem\r\n\r\nWe have the problem to deploy the image model to Android platform. It throws `No OpKernel was registered to support Op 'DecodeBase64' with these attrs`. And we have tried feeding string or byte array like these.\r\n\r\n```\r\nimage_string = \"foo\"\r\n\r\nbyte[] image_bytes = image_string.getBytes();\r\n\r\nString inputName = \"model_input_b64_images\";\r\n \r\ninferenceInterface.feedString(inputName, image_bytes);\r\n\r\ninferenceInterface.feed(inputName, image_bytes, 1, 4860);\r\n```\r\n\r\nIs it possible to implement and registry the kernel for `DecodeBase64` which is really important for image models? Or we have another way to feed the data for this Operator.\r\n\r\n### Source code / logs\r\n\r\nIt is easy to re-produce the issue. Try exporting the model which has the `DecodeBase64` operator and use the `freeze_graph.py` to generated the Android model file.\r\n\r\nHere is the complete log when trying to run the inference in Android.\r\n\r\n```\r\n\r\n07-30 16:58:35.943 14616-14616/com.tobe.androidclient E/AndroidRuntime: FATAL EXCEPTION: main\r\nProcess: com.tobe.androidclient, PID: 14616\r\njava.lang.RuntimeException: Unable to start activity ComponentInfo{com.tobe.androidclient/com.tobe.androidclient.MainActivity}: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'DecodeBase64' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Node: DecodeBase64 = DecodeBase64[](model_input_b64_images)]]\r\n    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2855)\r\n    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2930)\r\n    at android.app.ActivityThread.-wrap11(Unknown Source:0)\r\n    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1619)\r\n    at android.os.Handler.dispatchMessage(Handler.java:105)\r\n    at android.os.Looper.loop(Looper.java:171)\r\n    at android.app.ActivityThread.main(ActivityThread.java:6684)\r\n    at java.lang.reflect.Method.invoke(Native Method)\r\n    at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:246)\r\n    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:783)\r\n Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'DecodeBase64' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Node: DecodeBase64 = DecodeBase64[](model_input_b64_images)]]\r\n    at org.tensorflow.Session.run(Native Method)\r\n    at org.tensorflow.Session.access$100(Session.java:48)\r\n    at org.tensorflow.Session$Runner.runHelper(Session.java:298)\r\n    at org.tensorflow.Session$Runner.runAndFetchMetadata(Session.java:260)\r\n    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:220)\r\n    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:197)\r\n    at com.tobe.androidclient.MainActivity.onCreate(MainActivity.java:98)\r\n    at android.app.Activity.performCreate(Activity.java:7057)\r\n    at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1214)\r\n    at android.app.ActivityThread.performLaun\r\n```\r\n"}