{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412210286", "html_url": "https://github.com/tensorflow/tensorflow/issues/21238#issuecomment-412210286", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21238", "id": 412210286, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjIxMDI4Ng==", "user": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-10T21:23:11Z", "updated_at": "2018-08-10T21:23:11Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2715000\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tobegit3hub\">@tobegit3hub</a> , tensorflow mobile (and tflite) have limited number of ops to keep the frameworks small. Android already has a base64 decode function in it. We recommend you take that op out of your model and handle that ias a preprocess before invoking inference.</p>", "body_text": "@tobegit3hub , tensorflow mobile (and tflite) have limited number of ops to keep the frameworks small. Android already has a base64 decode function in it. We recommend you take that op out of your model and handle that ias a preprocess before invoking inference.", "body": "@tobegit3hub , tensorflow mobile (and tflite) have limited number of ops to keep the frameworks small. Android already has a base64 decode function in it. We recommend you take that op out of your model and handle that ias a preprocess before invoking inference."}