{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13629", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13629/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13629/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13629/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13629", "id": 264541015, "node_id": "MDU6SXNzdWUyNjQ1NDEwMTU=", "number": 13629, "title": "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP] [[Node: case/If_0/decode_image/cond_jpeg/cond_png/cond_gif", "user": {"login": "Ellie68", "id": 30722660, "node_id": "MDQ6VXNlcjMwNzIyNjYw", "avatar_url": "https://avatars1.githubusercontent.com/u/30722660?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ellie68", "html_url": "https://github.com/Ellie68", "followers_url": "https://api.github.com/users/Ellie68/followers", "following_url": "https://api.github.com/users/Ellie68/following{/other_user}", "gists_url": "https://api.github.com/users/Ellie68/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ellie68/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ellie68/subscriptions", "organizations_url": "https://api.github.com/users/Ellie68/orgs", "repos_url": "https://api.github.com/users/Ellie68/repos", "events_url": "https://api.github.com/users/Ellie68/events{/privacy}", "received_events_url": "https://api.github.com/users/Ellie68/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-10-11T10:52:06Z", "updated_at": "2017-10-11T10:57:21Z", "closed_at": "2017-10-11T10:57:21Z", "author_association": "NONE", "body_html": "<p>Hi all,<br>\nI use Python 2.7.13 and Tensorflow 1.3.0 on CPU.</p>\n<p>I want to use DensNet( <a href=\"url\">https://github.com/pudae/tensorflow-densenet</a> ) for regression problem. My data contains 60000 jpeg images with 37 float labels for each image.<br>\nI saved my data into tfrecords files by:</p>\n<p>`<br>\ndef Read_Labels(label_path):<br>\nlabels_csv = pd.read_csv(label_path)<br>\nlabels = np.array(labels_csv)<br>\nreturn labels[:,1:]</p>\n<p>def load_image(addr):<br>\n# read an image and resize to (224, 224)<br>\nimg = cv2.imread(addr)<br>\nimg = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)<br>\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)<br>\nimg = img.astype(np.float32)<br>\nreturn img</p>\n<p>def Shuffle_images_with_labels(shuffle_data, photo_filenames, labels):<br>\nif shuffle_data:<br>\nc = list(zip(photo_filenames, labels))<br>\nshuffle(c)<br>\naddrs, labels = zip(*c)<br>\nreturn addrs, labels</p>\n<p>def image_to_tfexample_mine(image_data, image_format, height, width, label):<br>\nreturn tf.train.Example(features=tf.train.Features(feature={<br>\n'image/encoded': bytes_feature(image_data),<br>\n'image/format': bytes_feature(image_format),<br>\n'image/class/label': _float_feature(label),<br>\n'image/height': int64_feature(height),<br>\n'image/width': int64_feature(width),<br>\n}))</p>\n<p>def _convert_dataset(split_name, filenames, labels, dataset_dir):<br>\nassert split_name in ['train', 'validation']</p>\n<p>num_per_shard = int(math.ceil(len(filenames) / float(_NUM_SHARDS)))</p>\n<p>with tf.Graph().as_default():</p>\n<pre><code>    for shard_id in range(_NUM_SHARDS):\n      output_filename = _get_dataset_filename(dataset_path, split_name, shard_id)\n     \n      with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:\n          start_ndx = shard_id * num_per_shard\n          end_ndx = min((shard_id+1) * num_per_shard, len(filenames))\n          for i in range(start_ndx, end_ndx):\n              sys.stdout.write('\\r&gt;&gt; Converting image %d/%d shard %d' % (\n                      i+1, len(filenames), shard_id))\n              sys.stdout.flush()\n\n              img = load_image(filenames[i])\n              image_data = tf.compat.as_bytes(img.tostring())\n                \n              label = labels[i]\n                \n              example = image_to_tfexample_mine(image_data, image_format, height, width, label)\n                \n              # Serialize to string and write on the file\n              tfrecord_writer.write(example.SerializeToString())\n</code></pre>\n<p>sys.stdout.write('\\n')<br>\nsys.stdout.flush()</p>\n<p>def run(dataset_dir):</p>\n<pre><code>labels = Read_Labels(dataset_dir + '/training_labels.csv')\n\nphoto_filenames = _get_filenames_and_classes(dataset_dir + '/images_training')\n\nshuffle_data = True \n\nphoto_filenames, labels = Shuffle_images_with_labels(\n        shuffle_data,photo_filenames, labels)\n\ntraining_filenames = photo_filenames[_NUM_VALIDATION:]\ntraining_labels = labels[_NUM_VALIDATION:]\n\nvalidation_filenames = photo_filenames[:_NUM_VALIDATION]\nvalidation_labels = labels[:_NUM_VALIDATION]\n\n_convert_dataset('train',\n                 training_filenames, training_labels, dataset_path)\n_convert_dataset('validation',\n                 validation_filenames, validation_labels, dataset_path)\n\nprint('\\nFinished converting the Flowers dataset!')` \n</code></pre>\n<hr>\n<p>And I decode it by:</p>\n<p>`<br>\nwith tf.Session() as sess:</p>\n<pre><code>feature = {\n  'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n  'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n  'image/class/label': tf.FixedLenFeature(\n      [37,], tf.float32, default_value=tf.zeros([37,], dtype=tf.float32)),\n   }\n\nfilename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n\nreader = tf.TFRecordReader()\n_, serialized_example = reader.read(filename_queue)\n\nfeatures = tf.parse_single_example(serialized_example, features=feature)\n\nimage = tf.decode_raw(features['image/encoded'], tf.float32)\nprint(image.get_shape())\n\nlabel = tf.cast(features['image/class/label'], tf.float32)\n\nimage = tf.reshape(image, [224, 224, 3])\n\nimages, labels = tf.train.shuffle_batch([image, label], batch_size=10, capacity=30, num_threads=1, min_after_dequeue=10)\n\ninit_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\nsess.run(init_op)\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(coord=coord)\n\nfor batch_index in range(6):\n    img, lbl = sess.run([images, labels])\n    img = img.astype(np.uint8)\n    print(img.shape)\n    for j in range(6):\n        plt.subplot(2, 3, j+1)\n        plt.imshow(img[j, ...])\n    plt.show()\n\ncoord.request_stop()\n\ncoord.join(threads)`\n</code></pre>\n<hr>\n<p>It's all fine up to this point. But when I use the bellow commands for decoding TFRecord files:</p>\n<p>`<br>\nreader = tf.TFRecordReader</p>\n<p>keys_to_features = {<br>\n'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),<br>\n'image/format': tf.FixedLenFeature((), tf.string, default_value='raw'),<br>\n'image/class/label': tf.FixedLenFeature(<br>\n[37,], tf.float32, default_value=tf.zeros([37,], dtype=tf.float32)),<br>\n}</p>\n<p>items_to_handlers = {<br>\n'image': slim.tfexample_decoder.Image('image/encoded'),<br>\n'label': slim.tfexample_decoder.Tensor('image/class/label'),<br>\n}</p>\n<p>decoder = slim.tfexample_decoder.TFExampleDecoder(<br>\nkeys_to_features, items_to_handlers)`</p>\n<hr>\n<p>I get the following error.</p>\n<blockquote>\n<p>INFO:tensorflow:Error reported to Coordinator: &lt;class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'&gt;, assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]<br>\n[[Node: case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert = Assert[T=[DT_STRING], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp, case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert/data_0)]]<br>\nINFO:tensorflow:Caught OutOfRangeError. Stopping Training.<br>\nINFO:sensorflow:Finished training! Saving model to disk.</p>\n</blockquote>\n<hr>\n<p>To use Densenet for my problem, I should fix this error first.<br>\nCould anybody please help me out of this problem. This code works perfectly for the datasets like flowers, MNIST and CIFAR10 available at <a href=\"url\">https://github.com/pudae/tensorflow-densenet/tree/master/datasets</a> but does not work for my data.</p>", "body_text": "Hi all,\nI use Python 2.7.13 and Tensorflow 1.3.0 on CPU.\nI want to use DensNet( https://github.com/pudae/tensorflow-densenet ) for regression problem. My data contains 60000 jpeg images with 37 float labels for each image.\nI saved my data into tfrecords files by:\n`\ndef Read_Labels(label_path):\nlabels_csv = pd.read_csv(label_path)\nlabels = np.array(labels_csv)\nreturn labels[:,1:]\ndef load_image(addr):\n# read an image and resize to (224, 224)\nimg = cv2.imread(addr)\nimg = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = img.astype(np.float32)\nreturn img\ndef Shuffle_images_with_labels(shuffle_data, photo_filenames, labels):\nif shuffle_data:\nc = list(zip(photo_filenames, labels))\nshuffle(c)\naddrs, labels = zip(*c)\nreturn addrs, labels\ndef image_to_tfexample_mine(image_data, image_format, height, width, label):\nreturn tf.train.Example(features=tf.train.Features(feature={\n'image/encoded': bytes_feature(image_data),\n'image/format': bytes_feature(image_format),\n'image/class/label': _float_feature(label),\n'image/height': int64_feature(height),\n'image/width': int64_feature(width),\n}))\ndef _convert_dataset(split_name, filenames, labels, dataset_dir):\nassert split_name in ['train', 'validation']\nnum_per_shard = int(math.ceil(len(filenames) / float(_NUM_SHARDS)))\nwith tf.Graph().as_default():\n    for shard_id in range(_NUM_SHARDS):\n      output_filename = _get_dataset_filename(dataset_path, split_name, shard_id)\n     \n      with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:\n          start_ndx = shard_id * num_per_shard\n          end_ndx = min((shard_id+1) * num_per_shard, len(filenames))\n          for i in range(start_ndx, end_ndx):\n              sys.stdout.write('\\r>> Converting image %d/%d shard %d' % (\n                      i+1, len(filenames), shard_id))\n              sys.stdout.flush()\n\n              img = load_image(filenames[i])\n              image_data = tf.compat.as_bytes(img.tostring())\n                \n              label = labels[i]\n                \n              example = image_to_tfexample_mine(image_data, image_format, height, width, label)\n                \n              # Serialize to string and write on the file\n              tfrecord_writer.write(example.SerializeToString())\n\nsys.stdout.write('\\n')\nsys.stdout.flush()\ndef run(dataset_dir):\nlabels = Read_Labels(dataset_dir + '/training_labels.csv')\n\nphoto_filenames = _get_filenames_and_classes(dataset_dir + '/images_training')\n\nshuffle_data = True \n\nphoto_filenames, labels = Shuffle_images_with_labels(\n        shuffle_data,photo_filenames, labels)\n\ntraining_filenames = photo_filenames[_NUM_VALIDATION:]\ntraining_labels = labels[_NUM_VALIDATION:]\n\nvalidation_filenames = photo_filenames[:_NUM_VALIDATION]\nvalidation_labels = labels[:_NUM_VALIDATION]\n\n_convert_dataset('train',\n                 training_filenames, training_labels, dataset_path)\n_convert_dataset('validation',\n                 validation_filenames, validation_labels, dataset_path)\n\nprint('\\nFinished converting the Flowers dataset!')` \n\n\nAnd I decode it by:\n`\nwith tf.Session() as sess:\nfeature = {\n  'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n  'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n  'image/class/label': tf.FixedLenFeature(\n      [37,], tf.float32, default_value=tf.zeros([37,], dtype=tf.float32)),\n   }\n\nfilename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n\nreader = tf.TFRecordReader()\n_, serialized_example = reader.read(filename_queue)\n\nfeatures = tf.parse_single_example(serialized_example, features=feature)\n\nimage = tf.decode_raw(features['image/encoded'], tf.float32)\nprint(image.get_shape())\n\nlabel = tf.cast(features['image/class/label'], tf.float32)\n\nimage = tf.reshape(image, [224, 224, 3])\n\nimages, labels = tf.train.shuffle_batch([image, label], batch_size=10, capacity=30, num_threads=1, min_after_dequeue=10)\n\ninit_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\nsess.run(init_op)\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(coord=coord)\n\nfor batch_index in range(6):\n    img, lbl = sess.run([images, labels])\n    img = img.astype(np.uint8)\n    print(img.shape)\n    for j in range(6):\n        plt.subplot(2, 3, j+1)\n        plt.imshow(img[j, ...])\n    plt.show()\n\ncoord.request_stop()\n\ncoord.join(threads)`\n\n\nIt's all fine up to this point. But when I use the bellow commands for decoding TFRecord files:\n`\nreader = tf.TFRecordReader\nkeys_to_features = {\n'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n'image/format': tf.FixedLenFeature((), tf.string, default_value='raw'),\n'image/class/label': tf.FixedLenFeature(\n[37,], tf.float32, default_value=tf.zeros([37,], dtype=tf.float32)),\n}\nitems_to_handlers = {\n'image': slim.tfexample_decoder.Image('image/encoded'),\n'label': slim.tfexample_decoder.Tensor('image/class/label'),\n}\ndecoder = slim.tfexample_decoder.TFExampleDecoder(\nkeys_to_features, items_to_handlers)`\n\nI get the following error.\n\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\n[[Node: case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert = Assert[T=[DT_STRING], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp, case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert/data_0)]]\nINFO:tensorflow:Caught OutOfRangeError. Stopping Training.\nINFO:sensorflow:Finished training! Saving model to disk.\n\n\nTo use Densenet for my problem, I should fix this error first.\nCould anybody please help me out of this problem. This code works perfectly for the datasets like flowers, MNIST and CIFAR10 available at https://github.com/pudae/tensorflow-densenet/tree/master/datasets but does not work for my data.", "body": "Hi all,\r\nI use Python 2.7.13 and Tensorflow 1.3.0 on CPU.\r\n\r\nI want to use DensNet( [https://github.com/pudae/tensorflow-densenet](url) ) for regression problem. My data contains 60000 jpeg images with 37 float labels for each image. \r\nI saved my data into tfrecords files by: \r\n\r\n`\r\ndef Read_Labels(label_path):\r\n    labels_csv = pd.read_csv(label_path)\r\n    labels = np.array(labels_csv)\r\n    return labels[:,1:]\r\n\r\ndef load_image(addr):\r\n    # read an image and resize to (224, 224)\r\n    img = cv2.imread(addr)\r\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\r\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n    img = img.astype(np.float32)\r\n    return img\r\n\r\ndef Shuffle_images_with_labels(shuffle_data, photo_filenames, labels):\r\n    if shuffle_data:\r\n        c = list(zip(photo_filenames, labels))\r\n        shuffle(c)\r\n        addrs, labels = zip(*c)\r\n        return addrs, labels\r\n\r\ndef image_to_tfexample_mine(image_data, image_format, height, width, label):\r\n  return tf.train.Example(features=tf.train.Features(feature={\r\n      'image/encoded': bytes_feature(image_data),    \r\n      'image/format': bytes_feature(image_format),\r\n      'image/class/label': _float_feature(label),\r\n      'image/height': int64_feature(height),\r\n      'image/width': int64_feature(width),\r\n  }))\r\n\r\ndef _convert_dataset(split_name, filenames, labels, dataset_dir):\r\n  assert split_name in ['train', 'validation']\r\n\r\n  num_per_shard = int(math.ceil(len(filenames) / float(_NUM_SHARDS)))\r\n\r\n  with tf.Graph().as_default():\r\n        \r\n        for shard_id in range(_NUM_SHARDS):\r\n          output_filename = _get_dataset_filename(dataset_path, split_name, shard_id)\r\n         \r\n          with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:\r\n              start_ndx = shard_id * num_per_shard\r\n              end_ndx = min((shard_id+1) * num_per_shard, len(filenames))\r\n              for i in range(start_ndx, end_ndx):\r\n                  sys.stdout.write('\\r>> Converting image %d/%d shard %d' % (\r\n                          i+1, len(filenames), shard_id))\r\n                  sys.stdout.flush()\r\n\r\n                  img = load_image(filenames[i])\r\n                  image_data = tf.compat.as_bytes(img.tostring())\r\n                    \r\n                  label = labels[i]\r\n                    \r\n                  example = image_to_tfexample_mine(image_data, image_format, height, width, label)\r\n                    \r\n                  # Serialize to string and write on the file\r\n                  tfrecord_writer.write(example.SerializeToString())\r\n                \r\n  sys.stdout.write('\\n')\r\n  sys.stdout.flush()\r\n  \r\ndef run(dataset_dir):\r\n\r\n    labels = Read_Labels(dataset_dir + '/training_labels.csv')\r\n    \r\n    photo_filenames = _get_filenames_and_classes(dataset_dir + '/images_training')\r\n    \r\n    shuffle_data = True \r\n    \r\n    photo_filenames, labels = Shuffle_images_with_labels(\r\n            shuffle_data,photo_filenames, labels)\r\n    \r\n    training_filenames = photo_filenames[_NUM_VALIDATION:]\r\n    training_labels = labels[_NUM_VALIDATION:]\r\n    \r\n    validation_filenames = photo_filenames[:_NUM_VALIDATION]\r\n    validation_labels = labels[:_NUM_VALIDATION]\r\n    \r\n    _convert_dataset('train',\r\n                     training_filenames, training_labels, dataset_path)\r\n    _convert_dataset('validation',\r\n                     validation_filenames, validation_labels, dataset_path)\r\n    \r\n    print('\\nFinished converting the Flowers dataset!')` \r\n________________________________________________________________________________\r\nAnd I decode it by:\r\n\r\n`\r\nwith tf.Session() as sess:\r\n\r\n    feature = {\r\n      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\r\n      'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\r\n      'image/class/label': tf.FixedLenFeature(\r\n          [37,], tf.float32, default_value=tf.zeros([37,], dtype=tf.float32)),\r\n       }\r\n\r\n    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\r\n    \r\n    reader = tf.TFRecordReader()\r\n    _, serialized_example = reader.read(filename_queue)\r\n   \r\n    features = tf.parse_single_example(serialized_example, features=feature)\r\n    \r\n    image = tf.decode_raw(features['image/encoded'], tf.float32)\r\n    print(image.get_shape())\r\n    \r\n    label = tf.cast(features['image/class/label'], tf.float32)\r\n\r\n    image = tf.reshape(image, [224, 224, 3])\r\n\r\n    images, labels = tf.train.shuffle_batch([image, label], batch_size=10, capacity=30, num_threads=1, min_after_dequeue=10)\r\n    \r\n    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\n    sess.run(init_op)\r\n\r\n    coord = tf.train.Coordinator()\r\n    threads = tf.train.start_queue_runners(coord=coord)\r\n    \r\n    for batch_index in range(6):\r\n        img, lbl = sess.run([images, labels])\r\n        img = img.astype(np.uint8)\r\n        print(img.shape)\r\n        for j in range(6):\r\n            plt.subplot(2, 3, j+1)\r\n            plt.imshow(img[j, ...])\r\n        plt.show()\r\n    \r\n    coord.request_stop()\r\n    \r\n    coord.join(threads)`\r\n______________________________________________________________________________________________________\r\nIt's all fine up to this point. But when I use the bellow commands for decoding TFRecord files:\r\n\r\n` \r\nreader = tf.TFRecordReader\r\n\r\n keys_to_features = {\r\n      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\r\n      'image/format': tf.FixedLenFeature((), tf.string, default_value='raw'),\r\n      'image/class/label': tf.FixedLenFeature(\r\n          [37,], tf.float32, default_value=tf.zeros([37,], dtype=tf.float32)),\r\n     }\r\n\r\n  items_to_handlers = {\r\n      'image': slim.tfexample_decoder.Image('image/encoded'),\r\n      'label': slim.tfexample_decoder.Tensor('image/class/label'),\r\n  }\r\n  \r\ndecoder = slim.tfexample_decoder.TFExampleDecoder(\r\n      keys_to_features, items_to_handlers)`\r\n_________________________________________________________________________________________________\r\n I get the following error.\r\n\r\n> INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\r\n         [[Node: case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert = Assert[T=[DT_STRING], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp, case/If_0/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert/data_0)]]\r\nINFO:tensorflow:Caught OutOfRangeError. Stopping Training.\r\nINFO:sensorflow:Finished training! Saving model to disk.\r\n_______________________________________________________________________________________________\r\nTo use Densenet for my problem, I should fix this error first. \r\nCould anybody please help me out of this problem. This code works perfectly for the datasets like flowers, MNIST and CIFAR10 available at [https://github.com/pudae/tensorflow-densenet/tree/master/datasets](url) but does not work for my data."}