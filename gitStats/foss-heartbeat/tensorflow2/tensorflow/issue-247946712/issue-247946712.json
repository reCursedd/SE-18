{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12032", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12032/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12032/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12032/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12032", "id": 247946712, "node_id": "MDU6SXNzdWUyNDc5NDY3MTI=", "number": 12032, "title": "Save and restore feature request", "user": {"login": "GoingMyWay", "id": 9346460, "node_id": "MDQ6VXNlcjkzNDY0NjA=", "avatar_url": "https://avatars0.githubusercontent.com/u/9346460?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GoingMyWay", "html_url": "https://github.com/GoingMyWay", "followers_url": "https://api.github.com/users/GoingMyWay/followers", "following_url": "https://api.github.com/users/GoingMyWay/following{/other_user}", "gists_url": "https://api.github.com/users/GoingMyWay/gists{/gist_id}", "starred_url": "https://api.github.com/users/GoingMyWay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GoingMyWay/subscriptions", "organizations_url": "https://api.github.com/users/GoingMyWay/orgs", "repos_url": "https://api.github.com/users/GoingMyWay/repos", "events_url": "https://api.github.com/users/GoingMyWay/events{/privacy}", "received_events_url": "https://api.github.com/users/GoingMyWay/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-08-04T09:08:01Z", "updated_at": "2017-08-28T03:34:48Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug or a feature request.</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: NO</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.2.1</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/v5.1</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX TITAN X / 12205MiB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>I am sorry to bother you all, here this is not a bug but, in my view, a feature request.</p>\n<p>I have trained a model and initialized a Saver instance by defining</p>\n\n<pre><code>value_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='global/old_scope')\nvalue_list.extend(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='global/actor_critic'))\nsaver = tf.train.Saver(value_list, max_to_keep=100)\n\nwith tf.Session(config=tf_configs) as sess:\n    coord = tf.train.Coordinator()\n    if load_model:\n        print('Loading Model...')\n        ckpt = tf.train.get_checkpoint_state(model_path)\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    else:\n        sess.run(tf.global_variables_initializer())\n</code></pre>\n<p>And later in a new sub-scope, I added a new layer, with the same <code>saver</code> defined above, I trained the model, however, I found that weights of the new layer were not saved.</p>\n<p>Here is my network</p>\n\n<pre><code>with tf.variable_scope(scope):\n    with tf.variable_scope('old_scope'):\n        self.inputs = tf.placeholder(shape=[None, 80, 80, 1], dtype=tf.float32)\n        self.conv_1 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.inputs, num_outputs=32,\n                                  kernel_size=[8, 8], stride=4, padding='SAME')\n        self.conv_2 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.conv_1, num_outputs=64,\n                                  kernel_size=[4, 4], stride=2, padding='SAME')\n        self.conv_3 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.conv_2, num_outputs=64,\n                                  kernel_size=[3, 3], stride=1, padding='SAME')\n        self.fc = slim.fully_connected(slim.flatten(self.conv_3), 512, activation_fn=tf.nn.elu)\n\n    with tf.variable_scope('added_layer'):\n        self.fc_1 = slim.fully_connected(self.fc, 512, activation_fn=tf.nn.elu)\n\n    with tf.variable_scope('actor_critic'):\n        # Output layers for policy and value estimations\n        self.policy = slim.fully_connected(self.fc_1,\n                                         cfg.ACTION_DIM,\n                                         activation_fn=tf.nn.softmax, \n                                         biases_initializer=None)\n        self.value = slim.fully_connected(self.fc_1,\n                                          1,\n                                          activation_fn=None,\n                                          biases_initializer=None)\n</code></pre>\n<p>And I found that the <a href=\"https://www.tensorflow.org/api_docs/python/tf/train/Saver#__init__\" rel=\"nofollow\"><code>var_list</code></a> defines values to be restored and saved. But in my case, there is no checkpoint data of the new layer in the checkpoint file.</p>\n<p>Since before adding the new layer, I have trained the model and save the checkpoint data, and then after adding the new layer, I wanna train the network.</p>\n<p>And I can define a new instance of Saver to save the model</p>\n<p><code>new_saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=GLOBAL_SCOPE))</code></p>\n<p>However, I think it is not an elegant way to do so.</p>\n<p>And can you add a feature to restore some values specified by users and also save some specified values when saving?</p>\n<p>And in fact, it is a question asked by me on <a href=\"https://stackoverflow.com/questions/45502149/tensorflow-save-and-restore-model-after-adding-one-layer\" rel=\"nofollow\">SO</a></p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug or a feature request.\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.2.1\nPython version: 3.5\nBazel version (if compiling from source):\nCUDA/cuDNN version: 8.0/v5.1\nGPU model and memory: GeForce GTX TITAN X / 12205MiB\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nI am sorry to bother you all, here this is not a bug but, in my view, a feature request.\nI have trained a model and initialized a Saver instance by defining\n\nvalue_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='global/old_scope')\nvalue_list.extend(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='global/actor_critic'))\nsaver = tf.train.Saver(value_list, max_to_keep=100)\n\nwith tf.Session(config=tf_configs) as sess:\n    coord = tf.train.Coordinator()\n    if load_model:\n        print('Loading Model...')\n        ckpt = tf.train.get_checkpoint_state(model_path)\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    else:\n        sess.run(tf.global_variables_initializer())\n\nAnd later in a new sub-scope, I added a new layer, with the same saver defined above, I trained the model, however, I found that weights of the new layer were not saved.\nHere is my network\n\nwith tf.variable_scope(scope):\n    with tf.variable_scope('old_scope'):\n        self.inputs = tf.placeholder(shape=[None, 80, 80, 1], dtype=tf.float32)\n        self.conv_1 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.inputs, num_outputs=32,\n                                  kernel_size=[8, 8], stride=4, padding='SAME')\n        self.conv_2 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.conv_1, num_outputs=64,\n                                  kernel_size=[4, 4], stride=2, padding='SAME')\n        self.conv_3 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.conv_2, num_outputs=64,\n                                  kernel_size=[3, 3], stride=1, padding='SAME')\n        self.fc = slim.fully_connected(slim.flatten(self.conv_3), 512, activation_fn=tf.nn.elu)\n\n    with tf.variable_scope('added_layer'):\n        self.fc_1 = slim.fully_connected(self.fc, 512, activation_fn=tf.nn.elu)\n\n    with tf.variable_scope('actor_critic'):\n        # Output layers for policy and value estimations\n        self.policy = slim.fully_connected(self.fc_1,\n                                         cfg.ACTION_DIM,\n                                         activation_fn=tf.nn.softmax, \n                                         biases_initializer=None)\n        self.value = slim.fully_connected(self.fc_1,\n                                          1,\n                                          activation_fn=None,\n                                          biases_initializer=None)\n\nAnd I found that the var_list defines values to be restored and saved. But in my case, there is no checkpoint data of the new layer in the checkpoint file.\nSince before adding the new layer, I have trained the model and save the checkpoint data, and then after adding the new layer, I wanna train the network.\nAnd I can define a new instance of Saver to save the model\nnew_saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=GLOBAL_SCOPE))\nHowever, I think it is not an elegant way to do so.\nAnd can you add a feature to restore some values specified by users and also save some specified values when saving?\nAnd in fact, it is a question asked by me on SO\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0/v5.1\r\n- **GPU model and memory**: GeForce GTX TITAN X / 12205MiB\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n I am sorry to bother you all, here this is not a bug but, in my view, a feature request. \r\n\r\nI have trained a model and initialized a Saver instance by defining\r\n\r\n\r\n<!-- language: python -->\r\n\r\n    value_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='global/old_scope')\r\n    value_list.extend(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='global/actor_critic'))\r\n    saver = tf.train.Saver(value_list, max_to_keep=100)\r\n\r\n    with tf.Session(config=tf_configs) as sess:\r\n        coord = tf.train.Coordinator()\r\n        if load_model:\r\n            print('Loading Model...')\r\n            ckpt = tf.train.get_checkpoint_state(model_path)\r\n            saver.restore(sess, ckpt.model_checkpoint_path)\r\n        else:\r\n            sess.run(tf.global_variables_initializer())\r\n\r\nAnd later in a new sub-scope, I added a new layer, with the same `saver` defined above, I trained the model, however, I found that weights of the new layer were not saved.\r\n\r\nHere is my network\r\n\r\n<!-- language: python -->\r\n\r\n    with tf.variable_scope(scope):\r\n        with tf.variable_scope('old_scope'):\r\n            self.inputs = tf.placeholder(shape=[None, 80, 80, 1], dtype=tf.float32)\r\n            self.conv_1 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.inputs, num_outputs=32,\r\n                                      kernel_size=[8, 8], stride=4, padding='SAME')\r\n            self.conv_2 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.conv_1, num_outputs=64,\r\n                                      kernel_size=[4, 4], stride=2, padding='SAME')\r\n            self.conv_3 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.conv_2, num_outputs=64,\r\n                                      kernel_size=[3, 3], stride=1, padding='SAME')\r\n            self.fc = slim.fully_connected(slim.flatten(self.conv_3), 512, activation_fn=tf.nn.elu)\r\n\r\n        with tf.variable_scope('added_layer'):\r\n            self.fc_1 = slim.fully_connected(self.fc, 512, activation_fn=tf.nn.elu)\r\n\r\n        with tf.variable_scope('actor_critic'):\r\n            # Output layers for policy and value estimations\r\n            self.policy = slim.fully_connected(self.fc_1,\r\n                                             cfg.ACTION_DIM,\r\n                                             activation_fn=tf.nn.softmax, \r\n                                             biases_initializer=None)\r\n            self.value = slim.fully_connected(self.fc_1,\r\n                                              1,\r\n                                              activation_fn=None,\r\n                                              biases_initializer=None)\r\n\r\nAnd I found that the [`var_list`][1] defines values to be restored and saved. But in my case, there is no checkpoint data of the new layer in the checkpoint file. \r\n\r\nSince before adding the new layer, I have trained the model and save the checkpoint data, and then after adding the new layer, I wanna train the network.\r\n\r\nAnd I can define a new instance of Saver to save the model\r\n\r\n`new_saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=GLOBAL_SCOPE))`\r\n\r\nHowever, I think it is not an elegant way to do so.\r\n\r\nAnd can you add a feature to restore some values specified by users and also save some specified values when saving?\r\n\r\nAnd in fact, it is a question asked by me on [SO](https://stackoverflow.com/questions/45502149/tensorflow-save-and-restore-model-after-adding-one-layer)\r\n\r\n  [1]: https://www.tensorflow.org/api_docs/python/tf/train/Saver#__init__\r\n\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"}