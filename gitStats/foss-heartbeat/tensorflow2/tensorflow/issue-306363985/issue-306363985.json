{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17819", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17819/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17819/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17819/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17819", "id": 306363985, "node_id": "MDU6SXNzdWUzMDYzNjM5ODU=", "number": 17819, "title": "i not understand what matter is my code about beamsearchdecoder", "user": {"login": "lyc712", "id": 32159175, "node_id": "MDQ6VXNlcjMyMTU5MTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/32159175?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lyc712", "html_url": "https://github.com/lyc712", "followers_url": "https://api.github.com/users/lyc712/followers", "following_url": "https://api.github.com/users/lyc712/following{/other_user}", "gists_url": "https://api.github.com/users/lyc712/gists{/gist_id}", "starred_url": "https://api.github.com/users/lyc712/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lyc712/subscriptions", "organizations_url": "https://api.github.com/users/lyc712/orgs", "repos_url": "https://api.github.com/users/lyc712/repos", "events_url": "https://api.github.com/users/lyc712/events{/privacy}", "received_events_url": "https://api.github.com/users/lyc712/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-03-19T08:00:35Z", "updated_at": "2018-03-19T09:16:02Z", "closed_at": "2018-03-19T09:16:02Z", "author_association": "NONE", "body_html": "<p>decoder_cell=[]<br>\nfor _ in range(n_layers):<br>\ndecoder_c=tf.nn.rnn_cell.BasicLSTMCell(num_units)<br>\nif train_state:<br>\ndecoder_c=tf.contrib.rnn.DropoutWrapper(decoder_c,input_keep_prob)<br>\ndecoder_cell.append(decoder_c)<br>\ndecoder_cell=tf.nn.rnn_cell.MultiRNNCell(decoder_cell,state_is_tuple=True)</p>\n<p>attention_mechanism=tf.contrib.seq2seq.BahdanauAttention(num_units,encoder_outputs)<br>\nattention_cell=tf.contrib.seq2seq.AttentionWrapper(decoder_cell,attention_mechanism)<br>\nhelper=tf.contrib.seq2seq.TrainingHelper(decoder_embedded,decoder_length)<br>\ninitial_state=attention_cell.zero_state(dtype=tf.float32,batch_size=50)<br>\ninitial_state=initial_state.clone(cell_state=encoder_state)<br>\ntraining_decoder=tf.contrib.seq2seq.BasicDecoder(attention_cell,helper,<br>\ninitial_state,<br>\noutput_layer=None)<br>\ntrain_decoder_outputs,train_decoder_state,_=tf.contrib.seq2seq.dynamic_decode(training_decoder)</p>\n<p>start_tokens=tf.placeholder(dtype=tf.int32,shape=[None])<br>\nend_token=tf.placeholder(dtype=tf.int32,shape=[])<br>\ntiled_encoder_outputs=tf.contrib.seq2seq.tile_batch(encoder_outputs,multiplier=beam_width)<br>\ntiled_encoder_state=tf.contrib.seq2seq.tile_batch(encoder_state,multiplier=beam_width)<br>\ntiled_sequence_length=tf.contrib.seq2seq.tile_batch(encoder_length,multiplier=beam_width)<br>\nattention_mechanism=tf.contrib.seq2seq.BahdanauAttention(num_units,tiled_encoder_state[-1][0])<br>\nattention_cell=tf.contrib.seq2seq.AttentionWrapper(decoder_cell,attention_mechanism)<br>\ninitial_state=attention_cell.zero_state(dtype=tf.float32,batch_size=50*beam_width)<br>\ninitial_state=initial_state.clone(cell_state=tiled_encoder_state)<br>\npredicting_decoder=tf.contrib.seq2seq.BeamSearchDecoder(attention_cell,<br>\nembeddings,<br>\nstart_tokens,<br>\nend_token,<br>\ninitial_state=initial_state,<br>\nbeam_width=beam_width,<br>\noutput_layer=None)</p>\n<p>predict_decoder_ouputs,<em>,</em>=tf.contrib.seq2seq.dynamic_decode(predicting_decoder)</p>\n<hr>\n<p>ndexError                                Traceback (most recent call last)<br>\n in ()<br>\n----&gt; 1 predict_decoder_ouputs,<em>,</em>=tf.contrib.seq2seq.dynamic_decode(predicting_decoder)</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)<br>\n284         ],<br>\n285         parallel_iterations=parallel_iterations,<br>\n--&gt; 286         swap_memory=swap_memory)<br>\n287<br>\n288     final_outputs_ta = res[1]</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)<br>\n2814     loop_context = WhileContext(parallel_iterations, back_prop, swap_memory)  # pylint: disable=redefined-outer-name<br>\n2815     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)<br>\n-&gt; 2816     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)<br>\n2817     return result<br>\n2818</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)<br>\n2638       self.Enter()<br>\n2639       original_body_result, exit_vars = self._BuildLoop(<br>\n-&gt; 2640           pred, body, original_loop_vars, loop_vars, shape_invariants)<br>\n2641     finally:<br>\n2642       self.Exit()</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)<br>\n2588         structure=original_loop_vars,<br>\n2589         flat_sequence=vars_for_body_with_tensor_arrays)<br>\n-&gt; 2590     body_result = body(*packed_vars_for_body)<br>\n2591     if not nest.is_sequence(body_result):<br>\n2592       body_result = [body_result]</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)<br>\n232       \"\"\"<br>\n233       (next_outputs, decoder_state, next_inputs,<br>\n--&gt; 234        decoder_finished) = decoder.step(time, inputs, state)<br>\n235       next_finished = math_ops.logical_or(decoder_finished, finished)<br>\n236       if maximum_iterations is not None:</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in step(self, time, inputs, state, name)<br>\n456           self._maybe_merge_batch_beams,<br>\n457           cell_state, self._cell.state_size)<br>\n--&gt; 458       cell_outputs, next_cell_state = self._cell(inputs, cell_state)<br>\n459       cell_outputs = nest.map_structure(<br>\n460           lambda out: self._split_batch_beams(out, out.shape[1:]), cell_outputs)</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py in <strong>call</strong>(self, inputs, state, scope)<br>\n181       with vs.variable_scope(vs.get_variable_scope(),<br>\n182                              custom_getter=self._rnn_get_variable):<br>\n--&gt; 183         return super(RNNCell, self).<strong>call</strong>(inputs, state)<br>\n184<br>\n185   def _rnn_get_variable(self, getter, *args, **kwargs):</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in <strong>call</strong>(self, inputs, *args, **kwargs)<br>\n573         if in_graph_mode:<br>\n574           self._assert_input_compatibility(inputs)<br>\n--&gt; 575         outputs = self.call(inputs, *args, **kwargs)<br>\n576<br>\n577         if outputs is None:</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in call(self, inputs, state)<br>\n1322       attention, alignments = _compute_attention(<br>\n1323           attention_mechanism, cell_output, previous_alignments[i],<br>\n-&gt; 1324           self._attention_layers[i] if self._attention_layers else None)<br>\n1325       alignment_history = previous_alignment_history[i].write(<br>\n1326           state.time, alignments) if self._alignment_history else ()</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _compute_attention(attention_mechanism, cell_output, previous_alignments, attention_layer)<br>\n971   \"\"\"Computes the attention and alignments for a given attention_mechanism.\"\"\"<br>\n972   alignments = attention_mechanism(<br>\n--&gt; 973       cell_output, previous_alignments=previous_alignments)<br>\n974<br>\n975   # Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in <strong>call</strong>(self, query, previous_alignments)<br>\n531     with variable_scope.variable_scope(None, \"bahdanau_attention\", [query]):<br>\n532       processed_query = self.query_layer(query) if self.query_layer else query<br>\n--&gt; 533       score = _bahdanau_score(processed_query, self._keys, self._normalize)<br>\n534     alignments = self._probability_fn(score, previous_alignments)<br>\n535     return alignments</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _bahdanau_score(processed_query, keys, normalize)<br>\n425   dtype = processed_query.dtype<br>\n426   # Get the number of hidden units from the trailing dimension of keys<br>\n--&gt; 427   num_units = keys.shape[2].value or array_ops.shape(keys)[2]<br>\n428   # Reshape from [batch_size, ...] to [batch_size, 1, ...] for broadcasting.<br>\n429   processed_query = array_ops.expand_dims(processed_query, 1)</p>\n<p>~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in <strong>getitem</strong>(self, key)<br>\n519         return TensorShape(self._dims[key])<br>\n520       else:<br>\n--&gt; 521         return self._dims[key]<br>\n522     else:<br>\n523       if isinstance(key, slice):</p>\n<p>IndexError: list index out of range</p>", "body_text": "decoder_cell=[]\nfor _ in range(n_layers):\ndecoder_c=tf.nn.rnn_cell.BasicLSTMCell(num_units)\nif train_state:\ndecoder_c=tf.contrib.rnn.DropoutWrapper(decoder_c,input_keep_prob)\ndecoder_cell.append(decoder_c)\ndecoder_cell=tf.nn.rnn_cell.MultiRNNCell(decoder_cell,state_is_tuple=True)\nattention_mechanism=tf.contrib.seq2seq.BahdanauAttention(num_units,encoder_outputs)\nattention_cell=tf.contrib.seq2seq.AttentionWrapper(decoder_cell,attention_mechanism)\nhelper=tf.contrib.seq2seq.TrainingHelper(decoder_embedded,decoder_length)\ninitial_state=attention_cell.zero_state(dtype=tf.float32,batch_size=50)\ninitial_state=initial_state.clone(cell_state=encoder_state)\ntraining_decoder=tf.contrib.seq2seq.BasicDecoder(attention_cell,helper,\ninitial_state,\noutput_layer=None)\ntrain_decoder_outputs,train_decoder_state,_=tf.contrib.seq2seq.dynamic_decode(training_decoder)\nstart_tokens=tf.placeholder(dtype=tf.int32,shape=[None])\nend_token=tf.placeholder(dtype=tf.int32,shape=[])\ntiled_encoder_outputs=tf.contrib.seq2seq.tile_batch(encoder_outputs,multiplier=beam_width)\ntiled_encoder_state=tf.contrib.seq2seq.tile_batch(encoder_state,multiplier=beam_width)\ntiled_sequence_length=tf.contrib.seq2seq.tile_batch(encoder_length,multiplier=beam_width)\nattention_mechanism=tf.contrib.seq2seq.BahdanauAttention(num_units,tiled_encoder_state[-1][0])\nattention_cell=tf.contrib.seq2seq.AttentionWrapper(decoder_cell,attention_mechanism)\ninitial_state=attention_cell.zero_state(dtype=tf.float32,batch_size=50*beam_width)\ninitial_state=initial_state.clone(cell_state=tiled_encoder_state)\npredicting_decoder=tf.contrib.seq2seq.BeamSearchDecoder(attention_cell,\nembeddings,\nstart_tokens,\nend_token,\ninitial_state=initial_state,\nbeam_width=beam_width,\noutput_layer=None)\npredict_decoder_ouputs,,=tf.contrib.seq2seq.dynamic_decode(predicting_decoder)\n\nndexError                                Traceback (most recent call last)\n in ()\n----> 1 predict_decoder_ouputs,,=tf.contrib.seq2seq.dynamic_decode(predicting_decoder)\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)\n284         ],\n285         parallel_iterations=parallel_iterations,\n--> 286         swap_memory=swap_memory)\n287\n288     final_outputs_ta = res[1]\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\n2814     loop_context = WhileContext(parallel_iterations, back_prop, swap_memory)  # pylint: disable=redefined-outer-name\n2815     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\n-> 2816     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n2817     return result\n2818\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)\n2638       self.Enter()\n2639       original_body_result, exit_vars = self._BuildLoop(\n-> 2640           pred, body, original_loop_vars, loop_vars, shape_invariants)\n2641     finally:\n2642       self.Exit()\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\n2588         structure=original_loop_vars,\n2589         flat_sequence=vars_for_body_with_tensor_arrays)\n-> 2590     body_result = body(*packed_vars_for_body)\n2591     if not nest.is_sequence(body_result):\n2592       body_result = [body_result]\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)\n232       \"\"\"\n233       (next_outputs, decoder_state, next_inputs,\n--> 234        decoder_finished) = decoder.step(time, inputs, state)\n235       next_finished = math_ops.logical_or(decoder_finished, finished)\n236       if maximum_iterations is not None:\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in step(self, time, inputs, state, name)\n456           self._maybe_merge_batch_beams,\n457           cell_state, self._cell.state_size)\n--> 458       cell_outputs, next_cell_state = self._cell(inputs, cell_state)\n459       cell_outputs = nest.map_structure(\n460           lambda out: self._split_batch_beams(out, out.shape[1:]), cell_outputs)\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py in call(self, inputs, state, scope)\n181       with vs.variable_scope(vs.get_variable_scope(),\n182                              custom_getter=self._rnn_get_variable):\n--> 183         return super(RNNCell, self).call(inputs, state)\n184\n185   def _rnn_get_variable(self, getter, *args, **kwargs):\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in call(self, inputs, *args, **kwargs)\n573         if in_graph_mode:\n574           self._assert_input_compatibility(inputs)\n--> 575         outputs = self.call(inputs, *args, **kwargs)\n576\n577         if outputs is None:\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in call(self, inputs, state)\n1322       attention, alignments = _compute_attention(\n1323           attention_mechanism, cell_output, previous_alignments[i],\n-> 1324           self._attention_layers[i] if self._attention_layers else None)\n1325       alignment_history = previous_alignment_history[i].write(\n1326           state.time, alignments) if self._alignment_history else ()\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _compute_attention(attention_mechanism, cell_output, previous_alignments, attention_layer)\n971   \"\"\"Computes the attention and alignments for a given attention_mechanism.\"\"\"\n972   alignments = attention_mechanism(\n--> 973       cell_output, previous_alignments=previous_alignments)\n974\n975   # Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in call(self, query, previous_alignments)\n531     with variable_scope.variable_scope(None, \"bahdanau_attention\", [query]):\n532       processed_query = self.query_layer(query) if self.query_layer else query\n--> 533       score = _bahdanau_score(processed_query, self._keys, self._normalize)\n534     alignments = self._probability_fn(score, previous_alignments)\n535     return alignments\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _bahdanau_score(processed_query, keys, normalize)\n425   dtype = processed_query.dtype\n426   # Get the number of hidden units from the trailing dimension of keys\n--> 427   num_units = keys.shape[2].value or array_ops.shape(keys)[2]\n428   # Reshape from [batch_size, ...] to [batch_size, 1, ...] for broadcasting.\n429   processed_query = array_ops.expand_dims(processed_query, 1)\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in getitem(self, key)\n519         return TensorShape(self._dims[key])\n520       else:\n--> 521         return self._dims[key]\n522     else:\n523       if isinstance(key, slice):\nIndexError: list index out of range", "body": "decoder_cell=[]\r\nfor _ in range(n_layers):\r\n    decoder_c=tf.nn.rnn_cell.BasicLSTMCell(num_units)\r\n    if train_state:\r\n        decoder_c=tf.contrib.rnn.DropoutWrapper(decoder_c,input_keep_prob)\r\n    decoder_cell.append(decoder_c)\r\ndecoder_cell=tf.nn.rnn_cell.MultiRNNCell(decoder_cell,state_is_tuple=True)\r\n\r\nattention_mechanism=tf.contrib.seq2seq.BahdanauAttention(num_units,encoder_outputs)\r\nattention_cell=tf.contrib.seq2seq.AttentionWrapper(decoder_cell,attention_mechanism)\r\nhelper=tf.contrib.seq2seq.TrainingHelper(decoder_embedded,decoder_length)\r\ninitial_state=attention_cell.zero_state(dtype=tf.float32,batch_size=50)\r\ninitial_state=initial_state.clone(cell_state=encoder_state)\r\ntraining_decoder=tf.contrib.seq2seq.BasicDecoder(attention_cell,helper,\r\n                                                     initial_state,\r\n                                                     output_layer=None)\r\ntrain_decoder_outputs,train_decoder_state,_=tf.contrib.seq2seq.dynamic_decode(training_decoder)\r\n\r\nstart_tokens=tf.placeholder(dtype=tf.int32,shape=[None])\r\nend_token=tf.placeholder(dtype=tf.int32,shape=[])\r\ntiled_encoder_outputs=tf.contrib.seq2seq.tile_batch(encoder_outputs,multiplier=beam_width)\r\ntiled_encoder_state=tf.contrib.seq2seq.tile_batch(encoder_state,multiplier=beam_width)\r\ntiled_sequence_length=tf.contrib.seq2seq.tile_batch(encoder_length,multiplier=beam_width)\r\nattention_mechanism=tf.contrib.seq2seq.BahdanauAttention(num_units,tiled_encoder_state[-1][0])\r\nattention_cell=tf.contrib.seq2seq.AttentionWrapper(decoder_cell,attention_mechanism)\r\ninitial_state=attention_cell.zero_state(dtype=tf.float32,batch_size=50*beam_width)\r\ninitial_state=initial_state.clone(cell_state=tiled_encoder_state)\r\npredicting_decoder=tf.contrib.seq2seq.BeamSearchDecoder(attention_cell,\r\n                                                        embeddings,\r\n                                                        start_tokens,\r\n                                                        end_token,\r\n                                                        initial_state=initial_state,\r\n                                                        beam_width=beam_width,\r\n                                                        output_layer=None)\r\n\r\npredict_decoder_ouputs,_,_=tf.contrib.seq2seq.dynamic_decode(predicting_decoder)\r\n\r\n------------------------------------------------------------------------------------------\r\n\r\nndexError                                Traceback (most recent call last)\r\n<ipython-input-43-08de1520bc78> in <module>()\r\n----> 1 predict_decoder_ouputs,_,_=tf.contrib.seq2seq.dynamic_decode(predicting_decoder)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)\r\n    284         ],\r\n    285         parallel_iterations=parallel_iterations,\r\n--> 286         swap_memory=swap_memory)\r\n    287 \r\n    288     final_outputs_ta = res[1]\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\r\n   2814     loop_context = WhileContext(parallel_iterations, back_prop, swap_memory)  # pylint: disable=redefined-outer-name\r\n   2815     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\r\n-> 2816     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n   2817     return result\r\n   2818 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)\r\n   2638       self.Enter()\r\n   2639       original_body_result, exit_vars = self._BuildLoop(\r\n-> 2640           pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2641     finally:\r\n   2642       self.Exit()\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2588         structure=original_loop_vars,\r\n   2589         flat_sequence=vars_for_body_with_tensor_arrays)\r\n-> 2590     body_result = body(*packed_vars_for_body)\r\n   2591     if not nest.is_sequence(body_result):\r\n   2592       body_result = [body_result]\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)\r\n    232       \"\"\"\r\n    233       (next_outputs, decoder_state, next_inputs,\r\n--> 234        decoder_finished) = decoder.step(time, inputs, state)\r\n    235       next_finished = math_ops.logical_or(decoder_finished, finished)\r\n    236       if maximum_iterations is not None:\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in step(self, time, inputs, state, name)\r\n    456           self._maybe_merge_batch_beams,\r\n    457           cell_state, self._cell.state_size)\r\n--> 458       cell_outputs, next_cell_state = self._cell(inputs, cell_state)\r\n    459       cell_outputs = nest.map_structure(\r\n    460           lambda out: self._split_batch_beams(out, out.shape[1:]), cell_outputs)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py in __call__(self, inputs, state, scope)\r\n    181       with vs.variable_scope(vs.get_variable_scope(),\r\n    182                              custom_getter=self._rnn_get_variable):\r\n--> 183         return super(RNNCell, self).__call__(inputs, state)\r\n    184 \r\n    185   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    573         if in_graph_mode:\r\n    574           self._assert_input_compatibility(inputs)\r\n--> 575         outputs = self.call(inputs, *args, **kwargs)\r\n    576 \r\n    577         if outputs is None:\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in call(self, inputs, state)\r\n   1322       attention, alignments = _compute_attention(\r\n   1323           attention_mechanism, cell_output, previous_alignments[i],\r\n-> 1324           self._attention_layers[i] if self._attention_layers else None)\r\n   1325       alignment_history = previous_alignment_history[i].write(\r\n   1326           state.time, alignments) if self._alignment_history else ()\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _compute_attention(attention_mechanism, cell_output, previous_alignments, attention_layer)\r\n    971   \"\"\"Computes the attention and alignments for a given attention_mechanism.\"\"\"\r\n    972   alignments = attention_mechanism(\r\n--> 973       cell_output, previous_alignments=previous_alignments)\r\n    974 \r\n    975   # Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in __call__(self, query, previous_alignments)\r\n    531     with variable_scope.variable_scope(None, \"bahdanau_attention\", [query]):\r\n    532       processed_query = self.query_layer(query) if self.query_layer else query\r\n--> 533       score = _bahdanau_score(processed_query, self._keys, self._normalize)\r\n    534     alignments = self._probability_fn(score, previous_alignments)\r\n    535     return alignments\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _bahdanau_score(processed_query, keys, normalize)\r\n    425   dtype = processed_query.dtype\r\n    426   # Get the number of hidden units from the trailing dimension of keys\r\n--> 427   num_units = keys.shape[2].value or array_ops.shape(keys)[2]\r\n    428   # Reshape from [batch_size, ...] to [batch_size, 1, ...] for broadcasting.\r\n    429   processed_query = array_ops.expand_dims(processed_query, 1)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in __getitem__(self, key)\r\n    519         return TensorShape(self._dims[key])\r\n    520       else:\r\n--> 521         return self._dims[key]\r\n    522     else:\r\n    523       if isinstance(key, slice):\r\n\r\nIndexError: list index out of range\r\n\r\n"}