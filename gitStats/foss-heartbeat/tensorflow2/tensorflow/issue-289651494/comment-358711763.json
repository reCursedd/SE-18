{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/358711763", "html_url": "https://github.com/tensorflow/tensorflow/issues/16221#issuecomment-358711763", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16221", "id": 358711763, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODcxMTc2Mw==", "user": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-18T17:01:36Z", "updated_at": "2018-01-18T17:01:36Z", "author_association": "MEMBER", "body_html": "<blockquote>\n<p>I am wondering why some entries occur multiple times? How can a single node have multiple<br>\nallocations? Why are they not summed?</p>\n</blockquote>\n<p>Probably each allocation is reported separately. One op might use multiple allocations.  It should be easy to filter them together with uniq and count in a unix shell pipe chain.</p>\n<blockquote>\n<p>Does Remaining 1252 nodes with 98.80MiB mean that all 1252<br>\nnodes together use 98.80MiB or each single one uses that amount?<br>\nThat means that there are smaller allocations that sum to 98MiB, i.e. it's stuff that is not a big enough allocation to report.</p>\n</blockquote>\n<blockquote>\n<p>When summing up all values I get 10.607822265625GiB but my free GPU space when starting my<br>\nprogram is 11.92GiB so shouldn't there still be enough space??</p>\n</blockquote>\n<p>Memory fragmentation can occur just like it can on the CPU. A tensor needs to be contiguous i.e. if you need 40MiB and you only have 10 x 4MiB chunks, you cannot complete the allocation</p>\n<p>Hope this helps.</p>", "body_text": "I am wondering why some entries occur multiple times? How can a single node have multiple\nallocations? Why are they not summed?\n\nProbably each allocation is reported separately. One op might use multiple allocations.  It should be easy to filter them together with uniq and count in a unix shell pipe chain.\n\nDoes Remaining 1252 nodes with 98.80MiB mean that all 1252\nnodes together use 98.80MiB or each single one uses that amount?\nThat means that there are smaller allocations that sum to 98MiB, i.e. it's stuff that is not a big enough allocation to report.\n\n\nWhen summing up all values I get 10.607822265625GiB but my free GPU space when starting my\nprogram is 11.92GiB so shouldn't there still be enough space??\n\nMemory fragmentation can occur just like it can on the CPU. A tensor needs to be contiguous i.e. if you need 40MiB and you only have 10 x 4MiB chunks, you cannot complete the allocation\nHope this helps.", "body": "> I am wondering why some entries occur multiple times? How can a single node have multiple\r\n> allocations? Why are they not summed?\r\n\r\nProbably each allocation is reported separately. One op might use multiple allocations.  It should be easy to filter them together with uniq and count in a unix shell pipe chain.\r\n\r\n> Does Remaining 1252 nodes with 98.80MiB mean that all 1252 \r\n> nodes together use 98.80MiB or each single one uses that amount?\r\nThat means that there are smaller allocations that sum to 98MiB, i.e. it's stuff that is not a big enough allocation to report.\r\n\r\n> When summing up all values I get 10.607822265625GiB but my free GPU space when starting my \r\n> program is 11.92GiB so shouldn't there still be enough space??\r\n\r\nMemory fragmentation can occur just like it can on the CPU. A tensor needs to be contiguous i.e. if you need 40MiB and you only have 10 x 4MiB chunks, you cannot complete the allocation\r\n\r\nHope this helps.\r\n"}