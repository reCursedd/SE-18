{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20425", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20425/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20425/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20425/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20425", "id": 337101695, "node_id": "MDU6SXNzdWUzMzcxMDE2OTU=", "number": 20425, "title": "Documentation Suggestion: mention and clarification of `tf.contrib.data.prefetch_to_device()` in \"Input Pipeline Performance Guide\"", "user": {"login": "mtpadilla", "id": 25699947, "node_id": "MDQ6VXNlcjI1Njk5OTQ3", "avatar_url": "https://avatars3.githubusercontent.com/u/25699947?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mtpadilla", "html_url": "https://github.com/mtpadilla", "followers_url": "https://api.github.com/users/mtpadilla/followers", "following_url": "https://api.github.com/users/mtpadilla/following{/other_user}", "gists_url": "https://api.github.com/users/mtpadilla/gists{/gist_id}", "starred_url": "https://api.github.com/users/mtpadilla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mtpadilla/subscriptions", "organizations_url": "https://api.github.com/users/mtpadilla/orgs", "repos_url": "https://api.github.com/users/mtpadilla/repos", "events_url": "https://api.github.com/users/mtpadilla/events{/privacy}", "received_events_url": "https://api.github.com/users/mtpadilla/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284443156, "node_id": "MDU6TGFiZWwyODQ0NDMxNTY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-06-29T18:51:29Z", "updated_at": "2018-07-31T14:17:58Z", "closed_at": "2018-07-31T14:17:58Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: n/a</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: n/a</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: n/a</li>\n<li><strong>TensorFlow version (use command below)</strong>: n/a</li>\n<li><strong>Python version</strong>:  n/a</li>\n<li><strong>Bazel version (if compiling from source)</strong>: n/a</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: n/a</li>\n<li><strong>CUDA/cuDNN version</strong>: n/a</li>\n<li><strong>GPU model and memory</strong>: n/a</li>\n<li><strong>Exact command to reproduce</strong>: n/a</li>\n</ul>\n<p>Documentation Suggestion: In <code>https://www.tensorflow.org/performance/datasets_performance</code> I think it would be worth:</p>\n<ul>\n<li>\n<p>Adding some mention of <code>tf.contrib.data.prefetch_to_device()</code>. This method isn't presented in this document, nor in the basic programming guide at <code>https://www.tensorflow.org/programmers_guide/datasets</code>. It's hard to know about this potentially useful method if it's not mentioned. I only learned of it when watching a Youtube video by Derek Murray from the TF Dev Summit 2018.</p>\n</li>\n<li>\n<p>In <code>https://www.tensorflow.org/performance/datasets_performance</code>, in addition to mentioning <code>.prefetch_to_device()</code> I think it would be useful to some to clarify how it's different from <code>.prefetch()</code>, perhaps with a useful diagram like the one presented to clarify <code>.prefetch()</code>. I've seen several questions online about this point. I think it's clear when one carefully reads the documentation, but some extra clarity wouldn't hurt.</p>\n</li>\n<li>\n<p>Also, more examples of how to use these tools would be nice...for example, some before (using <code>feed_dict</code> for all data into a model) vs after (using <code>tf.data.Dataset</code> and associated tools) would be helpful.</p>\n</li>\n</ul>\n<p>Thank you.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): n/a\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): n/a\nTensorFlow installed from (source or binary): n/a\nTensorFlow version (use command below): n/a\nPython version:  n/a\nBazel version (if compiling from source): n/a\nGCC/Compiler version (if compiling from source): n/a\nCUDA/cuDNN version: n/a\nGPU model and memory: n/a\nExact command to reproduce: n/a\n\nDocumentation Suggestion: In https://www.tensorflow.org/performance/datasets_performance I think it would be worth:\n\n\nAdding some mention of tf.contrib.data.prefetch_to_device(). This method isn't presented in this document, nor in the basic programming guide at https://www.tensorflow.org/programmers_guide/datasets. It's hard to know about this potentially useful method if it's not mentioned. I only learned of it when watching a Youtube video by Derek Murray from the TF Dev Summit 2018.\n\n\nIn https://www.tensorflow.org/performance/datasets_performance, in addition to mentioning .prefetch_to_device() I think it would be useful to some to clarify how it's different from .prefetch(), perhaps with a useful diagram like the one presented to clarify .prefetch(). I've seen several questions online about this point. I think it's clear when one carefully reads the documentation, but some extra clarity wouldn't hurt.\n\n\nAlso, more examples of how to use these tools would be nice...for example, some before (using feed_dict for all data into a model) vs after (using tf.data.Dataset and associated tools) would be helpful.\n\n\nThank you.", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: n/a\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a\r\n- **TensorFlow installed from (source or binary)**: n/a\r\n- **TensorFlow version (use command below)**: n/a\r\n- **Python version**:  n/a\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: n/a\r\n\r\nDocumentation Suggestion: In `https://www.tensorflow.org/performance/datasets_performance` I think it would be worth:\r\n\r\n- Adding some mention of `tf.contrib.data.prefetch_to_device()`. This method isn't presented in this document, nor in the basic programming guide at `https://www.tensorflow.org/programmers_guide/datasets`. It's hard to know about this potentially useful method if it's not mentioned. I only learned of it when watching a Youtube video by Derek Murray from the TF Dev Summit 2018.\r\n\r\n- In `https://www.tensorflow.org/performance/datasets_performance`, in addition to mentioning `.prefetch_to_device()` I think it would be useful to some to clarify how it's different from `.prefetch()`, perhaps with a useful diagram like the one presented to clarify `.prefetch()`. I've seen several questions online about this point. I think it's clear when one carefully reads the documentation, but some extra clarity wouldn't hurt.\r\n\r\n- Also, more examples of how to use these tools would be nice...for example, some before (using `feed_dict` for all data into a model) vs after (using `tf.data.Dataset` and associated tools) would be helpful.\r\n\r\nThank you.\r\n"}