{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/271884214", "html_url": "https://github.com/tensorflow/tensorflow/issues/5853#issuecomment-271884214", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5853", "id": 271884214, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MTg4NDIxNA==", "user": {"login": "fanyangxyz", "id": 10015975, "node_id": "MDQ6VXNlcjEwMDE1OTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/10015975?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fanyangxyz", "html_url": "https://github.com/fanyangxyz", "followers_url": "https://api.github.com/users/fanyangxyz/followers", "following_url": "https://api.github.com/users/fanyangxyz/following{/other_user}", "gists_url": "https://api.github.com/users/fanyangxyz/gists{/gist_id}", "starred_url": "https://api.github.com/users/fanyangxyz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fanyangxyz/subscriptions", "organizations_url": "https://api.github.com/users/fanyangxyz/orgs", "repos_url": "https://api.github.com/users/fanyangxyz/repos", "events_url": "https://api.github.com/users/fanyangxyz/events{/privacy}", "received_events_url": "https://api.github.com/users/fanyangxyz/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-11T14:37:02Z", "updated_at": "2017-01-11T14:40:09Z", "author_association": "NONE", "body_html": "<p>A related question: is it true that backpropagation involving sparse_tensor_dense_matmul is NOT supported on GPU in version r0.11?</p>\n<p>More specifically, the following code failed to run on GPU:</p>\n<pre><code>with tf.device(\"/gpu:0\"):\n    x = tf.sparse_placeholder(tf.float32)\n    v = tf.Variable(tf.random_normal([4, 1]))\n    cost = tf.reduce_sum(tf.sparse_tensor_dense_matmul(x, v))\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n    \n   with tf.Session() as sess:\n        sess.run(tf.initialize_all_variables())\n        indices = np.array([[2, 0], [3, 1]], dtype=np.int64)\n        values = np.array([1.0, 2.0], dtype=np.float32)\n        shape = np.array([4, 4], dtype=np.int64)\n        sess.run(optimizer, feed_dict={x: tf.SparseTensorValue(indices, values, shape)})\n</code></pre>\n<p>with error:<br>\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'gradients/SparseTensorDenseMatMul/SparseTensorDenseMatMul_grad/strided_slice_1': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.</p>\n<p>I wanted to know if it's because I'm not using <code>tf.sparse_tensor_dense_matmul</code> correctly in backpropagation, or it's simply because not supported.</p>\n<p>Thanks a lot in advance.</p>", "body_text": "A related question: is it true that backpropagation involving sparse_tensor_dense_matmul is NOT supported on GPU in version r0.11?\nMore specifically, the following code failed to run on GPU:\nwith tf.device(\"/gpu:0\"):\n    x = tf.sparse_placeholder(tf.float32)\n    v = tf.Variable(tf.random_normal([4, 1]))\n    cost = tf.reduce_sum(tf.sparse_tensor_dense_matmul(x, v))\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n    \n   with tf.Session() as sess:\n        sess.run(tf.initialize_all_variables())\n        indices = np.array([[2, 0], [3, 1]], dtype=np.int64)\n        values = np.array([1.0, 2.0], dtype=np.float32)\n        shape = np.array([4, 4], dtype=np.int64)\n        sess.run(optimizer, feed_dict={x: tf.SparseTensorValue(indices, values, shape)})\n\nwith error:\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'gradients/SparseTensorDenseMatMul/SparseTensorDenseMatMul_grad/strided_slice_1': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nI wanted to know if it's because I'm not using tf.sparse_tensor_dense_matmul correctly in backpropagation, or it's simply because not supported.\nThanks a lot in advance.", "body": "A related question: is it true that backpropagation involving sparse_tensor_dense_matmul is NOT supported on GPU in version r0.11? \r\n\r\nMore specifically, the following code failed to run on GPU:\r\n\r\n```\r\nwith tf.device(\"/gpu:0\"):\r\n    x = tf.sparse_placeholder(tf.float32)\r\n    v = tf.Variable(tf.random_normal([4, 1]))\r\n    cost = tf.reduce_sum(tf.sparse_tensor_dense_matmul(x, v))\r\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\r\n    \r\n   with tf.Session() as sess:\r\n        sess.run(tf.initialize_all_variables())\r\n        indices = np.array([[2, 0], [3, 1]], dtype=np.int64)\r\n        values = np.array([1.0, 2.0], dtype=np.float32)\r\n        shape = np.array([4, 4], dtype=np.int64)\r\n        sess.run(optimizer, feed_dict={x: tf.SparseTensorValue(indices, values, shape)})\r\n```\r\n\r\nwith error:\r\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'gradients/SparseTensorDenseMatMul/SparseTensorDenseMatMul_grad/strided_slice_1': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\n\r\nI wanted to know if it's because I'm not using `tf.sparse_tensor_dense_matmul` correctly in backpropagation, or it's simply because not supported. \r\n\r\nThanks a lot in advance. \r\n"}