{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256392098", "html_url": "https://github.com/tensorflow/tensorflow/issues/3663#issuecomment-256392098", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3663", "id": 256392098, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NjM5MjA5OA==", "user": {"login": "davidbuniat", "id": 7069390, "node_id": "MDQ6VXNlcjcwNjkzOTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/7069390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidbuniat", "html_url": "https://github.com/davidbuniat", "followers_url": "https://api.github.com/users/davidbuniat/followers", "following_url": "https://api.github.com/users/davidbuniat/following{/other_user}", "gists_url": "https://api.github.com/users/davidbuniat/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidbuniat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidbuniat/subscriptions", "organizations_url": "https://api.github.com/users/davidbuniat/orgs", "repos_url": "https://api.github.com/users/davidbuniat/repos", "events_url": "https://api.github.com/users/davidbuniat/events{/privacy}", "received_events_url": "https://api.github.com/users/davidbuniat/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-26T15:51:12Z", "updated_at": "2016-10-26T17:07:47Z", "author_association": "NONE", "body_html": "<p>The problem arises when I take one state from loop_state and concat with current state. Sorry if its not the minimal I just wanted to give the whole context.</p>\n<pre><code>        def loop_fn(time, cell_output, cell_state, loop_state):\n                emit_output = cell_output\n                if loop_state == None:\n                    loop_state = tf.TensorArray(dtype=tf.float32, size=args.width*args.height)\n                    for i in xrange(args.width):\n                         loop_state.write(i, cell.zero_state(args.batch_size, tf.float32))\n\n                if cell_state == None:\n                    state = cell.zero_state(args.batch_size, tf.float32)\n                else:  \n                    state = tf.cond(tf.reduce_all((time+1)%args.width == tf.constant(0)), \n                        lambda: cell.zero_state(args.batch_size, tf.float32), \n                        lambda: cell_state, name=None)\n\n                #State issues\n                prev_state_x = tf.slice(state, [0, 0], [-1, output_size*4])\n                prev_state_y = loop_state.read(time%args.width)\n                prev_state_y = tf.slice(prev_state_y, [0, output_size*4], [-1, output_size*2])\n                state = tf.concat(1,[prev_state_x, prev_state_y]) # &lt;---- Problem\n\n                next_cell_state = state\n\n                elements_finished = (time &gt;= sequence_length)\n                finished = tf.reduce_all(elements_finished)\n                next_input = tf.cond(\n                    finished,\n                    lambda: tf.zeros([args.batch_size, input_size], dtype=tf.float32),\n                    lambda: inputs_ta.read(time))\n\n                loop_state.write((time)%args.width, state)\n                next_loop_state = loop_state\n\n                return (elements_finished, next_input, next_cell_state,\n                        emit_output, next_loop_state)\n\n      outputs_ta, final_state, _ = rnn.raw_rnn(cell, loop_fn, parallel_iterations=1)\n</code></pre>", "body_text": "The problem arises when I take one state from loop_state and concat with current state. Sorry if its not the minimal I just wanted to give the whole context.\n        def loop_fn(time, cell_output, cell_state, loop_state):\n                emit_output = cell_output\n                if loop_state == None:\n                    loop_state = tf.TensorArray(dtype=tf.float32, size=args.width*args.height)\n                    for i in xrange(args.width):\n                         loop_state.write(i, cell.zero_state(args.batch_size, tf.float32))\n\n                if cell_state == None:\n                    state = cell.zero_state(args.batch_size, tf.float32)\n                else:  \n                    state = tf.cond(tf.reduce_all((time+1)%args.width == tf.constant(0)), \n                        lambda: cell.zero_state(args.batch_size, tf.float32), \n                        lambda: cell_state, name=None)\n\n                #State issues\n                prev_state_x = tf.slice(state, [0, 0], [-1, output_size*4])\n                prev_state_y = loop_state.read(time%args.width)\n                prev_state_y = tf.slice(prev_state_y, [0, output_size*4], [-1, output_size*2])\n                state = tf.concat(1,[prev_state_x, prev_state_y]) # <---- Problem\n\n                next_cell_state = state\n\n                elements_finished = (time >= sequence_length)\n                finished = tf.reduce_all(elements_finished)\n                next_input = tf.cond(\n                    finished,\n                    lambda: tf.zeros([args.batch_size, input_size], dtype=tf.float32),\n                    lambda: inputs_ta.read(time))\n\n                loop_state.write((time)%args.width, state)\n                next_loop_state = loop_state\n\n                return (elements_finished, next_input, next_cell_state,\n                        emit_output, next_loop_state)\n\n      outputs_ta, final_state, _ = rnn.raw_rnn(cell, loop_fn, parallel_iterations=1)", "body": "The problem arises when I take one state from loop_state and concat with current state. Sorry if its not the minimal I just wanted to give the whole context.\n\n```\n        def loop_fn(time, cell_output, cell_state, loop_state):\n                emit_output = cell_output\n                if loop_state == None:\n                    loop_state = tf.TensorArray(dtype=tf.float32, size=args.width*args.height)\n                    for i in xrange(args.width):\n                         loop_state.write(i, cell.zero_state(args.batch_size, tf.float32))\n\n                if cell_state == None:\n                    state = cell.zero_state(args.batch_size, tf.float32)\n                else:  \n                    state = tf.cond(tf.reduce_all((time+1)%args.width == tf.constant(0)), \n                        lambda: cell.zero_state(args.batch_size, tf.float32), \n                        lambda: cell_state, name=None)\n\n                #State issues\n                prev_state_x = tf.slice(state, [0, 0], [-1, output_size*4])\n                prev_state_y = loop_state.read(time%args.width)\n                prev_state_y = tf.slice(prev_state_y, [0, output_size*4], [-1, output_size*2])\n                state = tf.concat(1,[prev_state_x, prev_state_y]) # <---- Problem\n\n                next_cell_state = state\n\n                elements_finished = (time >= sequence_length)\n                finished = tf.reduce_all(elements_finished)\n                next_input = tf.cond(\n                    finished,\n                    lambda: tf.zeros([args.batch_size, input_size], dtype=tf.float32),\n                    lambda: inputs_ta.read(time))\n\n                loop_state.write((time)%args.width, state)\n                next_loop_state = loop_state\n\n                return (elements_finished, next_input, next_cell_state,\n                        emit_output, next_loop_state)\n\n      outputs_ta, final_state, _ = rnn.raw_rnn(cell, loop_fn, parallel_iterations=1)\n```\n"}