{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385060754", "html_url": "https://github.com/tensorflow/tensorflow/issues/18874#issuecomment-385060754", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18874", "id": 385060754, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTA2MDc1NA==", "user": {"login": "nikonikolov", "id": 11044035, "node_id": "MDQ6VXNlcjExMDQ0MDM1", "avatar_url": "https://avatars3.githubusercontent.com/u/11044035?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikonikolov", "html_url": "https://github.com/nikonikolov", "followers_url": "https://api.github.com/users/nikonikolov/followers", "following_url": "https://api.github.com/users/nikonikolov/following{/other_user}", "gists_url": "https://api.github.com/users/nikonikolov/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikonikolov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikonikolov/subscriptions", "organizations_url": "https://api.github.com/users/nikonikolov/orgs", "repos_url": "https://api.github.com/users/nikonikolov/repos", "events_url": "https://api.github.com/users/nikonikolov/events{/privacy}", "received_events_url": "https://api.github.com/users/nikonikolov/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-27T18:48:04Z", "updated_at": "2018-04-27T18:48:04Z", "author_association": "NONE", "body_html": "<p>Thanks for the response. I think you misunderstood what I was saying, maybe I was not clear enough.<br>\nHere is a mock up (just to illustrate the issue, it is not the <em>exact</em> piece of code which reproduces the problem):</p>\n<pre><code>seed = 42\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n\n# build graph\nsess = tf.Session()\nrands = []\n\nfor i in range(30000):\n  r = np.random.uniform(0,1)\n  rands.append(r)\n  sess.run(train_op, feed_dict=...)\n</code></pre>\n<p>The issue that I am experiencing is that <code>rands</code> ends up with different numbers between runs. This is happening only when using GPU. On CPU, the numbers are the same. When I remove the line <code>sess.run(train_op, feed_dict=...)</code>, everything works fine. Also if I use <code>prng = np.random.RandomState(); prng.seed(seed)</code> and then sample with <code>r = prng.uniform(0,1)</code>, the generated numbers are the same between runs on both CPU and GPU (<code>sess.run(train_op, feed_dict=...)</code> is also being executed).</p>\n<p>I was wondering whether this is expected behavior? If not, I will try to create a proper example which reproduces the problem so we can debug further.</p>", "body_text": "Thanks for the response. I think you misunderstood what I was saying, maybe I was not clear enough.\nHere is a mock up (just to illustrate the issue, it is not the exact piece of code which reproduces the problem):\nseed = 42\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n\n# build graph\nsess = tf.Session()\nrands = []\n\nfor i in range(30000):\n  r = np.random.uniform(0,1)\n  rands.append(r)\n  sess.run(train_op, feed_dict=...)\n\nThe issue that I am experiencing is that rands ends up with different numbers between runs. This is happening only when using GPU. On CPU, the numbers are the same. When I remove the line sess.run(train_op, feed_dict=...), everything works fine. Also if I use prng = np.random.RandomState(); prng.seed(seed) and then sample with r = prng.uniform(0,1), the generated numbers are the same between runs on both CPU and GPU (sess.run(train_op, feed_dict=...) is also being executed).\nI was wondering whether this is expected behavior? If not, I will try to create a proper example which reproduces the problem so we can debug further.", "body": "Thanks for the response. I think you misunderstood what I was saying, maybe I was not clear enough.\r\nHere is a mock up (just to illustrate the issue, it is not the *exact* piece of code which reproduces the problem):\r\n\r\n```\r\nseed = 42\r\nnp.random.seed(seed)\r\ntf.set_random_seed(seed)\r\n\r\n# build graph\r\nsess = tf.Session()\r\nrands = []\r\n\r\nfor i in range(30000):\r\n  r = np.random.uniform(0,1)\r\n  rands.append(r)\r\n  sess.run(train_op, feed_dict=...)\r\n```\r\n\r\nThe issue that I am experiencing is that `rands` ends up with different numbers between runs. This is happening only when using GPU. On CPU, the numbers are the same. When I remove the line `sess.run(train_op, feed_dict=...)`, everything works fine. Also if I use `prng = np.random.RandomState(); prng.seed(seed)` and then sample with `r = prng.uniform(0,1)`, the generated numbers are the same between runs on both CPU and GPU (`sess.run(train_op, feed_dict=...)` is also being executed).\r\n\r\nI was wondering whether this is expected behavior? If not, I will try to create a proper example which reproduces the problem so we can debug further.\r\n"}