{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/438484046", "html_url": "https://github.com/tensorflow/tensorflow/issues/23050#issuecomment-438484046", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23050", "id": 438484046, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODQ4NDA0Ng==", "user": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-13T23:55:02Z", "updated_at": "2018-11-13T23:55:02Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=44445\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ccurro\">@ccurro</a>  gamma and beta are parameters.</p>\n<blockquote>\n<blockquote>\n<p>but your last sess.run call is made on x_norm, i.e. tf.layers.batch_normalization of x during training where virtual_batch_size is used.<br>\nThe last sess.run call has training=False.</p>\n</blockquote>\n</blockquote>\n<p>Yes, but if you change virtual_batch in x_norm as below, sess.run would not incur error.</p>\n<pre><code>x_norm = tf.layers.batch_normalization(x, training=training, virtual_batch_size=1)\n</code></pre>", "body_text": "@ccurro  gamma and beta are parameters.\n\n\nbut your last sess.run call is made on x_norm, i.e. tf.layers.batch_normalization of x during training where virtual_batch_size is used.\nThe last sess.run call has training=False.\n\n\nYes, but if you change virtual_batch in x_norm as below, sess.run would not incur error.\nx_norm = tf.layers.batch_normalization(x, training=training, virtual_batch_size=1)", "body": "@ccurro  gamma and beta are parameters.\r\n\r\n> > but your last sess.run call is made on x_norm, i.e. tf.layers.batch_normalization of x during training where virtual_batch_size is used.\r\n> The last sess.run call has training=False.\r\n\r\nYes, but if you change virtual_batch in x_norm as below, sess.run would not incur error.\r\n```\r\nx_norm = tf.layers.batch_normalization(x, training=training, virtual_batch_size=1)\r\n```"}