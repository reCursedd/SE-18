{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23050", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23050/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23050/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23050/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23050", "id": 371151334, "node_id": "MDU6SXNzdWUzNzExNTEzMzQ=", "number": 23050, "title": "Batch Normalization with virtual_batch_size not equal to None not implemented correctly for inference time", "user": {"login": "ccurro", "id": 44445, "node_id": "MDQ6VXNlcjQ0NDQ1", "avatar_url": "https://avatars1.githubusercontent.com/u/44445?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ccurro", "html_url": "https://github.com/ccurro", "followers_url": "https://api.github.com/users/ccurro/followers", "following_url": "https://api.github.com/users/ccurro/following{/other_user}", "gists_url": "https://api.github.com/users/ccurro/gists{/gist_id}", "starred_url": "https://api.github.com/users/ccurro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ccurro/subscriptions", "organizations_url": "https://api.github.com/users/ccurro/orgs", "repos_url": "https://api.github.com/users/ccurro/repos", "events_url": "https://api.github.com/users/ccurro/events{/privacy}", "received_events_url": "https://api.github.com/users/ccurro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-10-17T15:59:51Z", "updated_at": "2018-11-14T12:44:19Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.10.1-0-g4dcfddc5d1 1.10.1</li>\n<li><strong>Python version</strong>: Python 3.6.2</li>\n<li><strong>Exact command to reproduce</strong>: python main.py</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Mobile device</strong>: N/A</li>\n<li><strong>Bazel version</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The batch normalization implementation respects the virtual_batch_size parameter in both train and inference modes. As such you are unable to do inference with batch sizes that are not multiples of the virtual_batch_size. Algorithm 1 in the <a href=\"https://arxiv.org/pdf/1705.08741.pdf\" rel=\"nofollow\">ghost batch norm paper</a> makes it clear that virtual_batch_size should only be respected in train mode.</p>\n<p>Relevant tf source code: <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py</a></p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\nvirtual_batch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">32</span>\n\ntraining <span class=\"pl-k\">=</span> tf.placeholder(tf.bool, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[])\nx <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>])\nx_norm <span class=\"pl-k\">=</span> tf.layers.batch_normalization(x, <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span>training, <span class=\"pl-v\">virtual_batch_size</span><span class=\"pl-k\">=</span>virtual_batch_size)\nupdate_ops <span class=\"pl-k\">=</span> tf.get_collection(tf.GraphKeys.<span class=\"pl-c1\">UPDATE_OPS</span>)\n\nsess <span class=\"pl-k\">=</span> tf.Session()\n\nsess.run(tf.global_variables_initializer())\n\n\n<span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n    sess.run([update_ops, x_norm], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x : np.random.random(<span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">4</span><span class=\"pl-k\">*</span>virtual_batch_size, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>]), training : <span class=\"pl-c1\">True</span>})\n\nsess.run(x_norm, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x : np.random.random(<span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>[virtual_batch_size, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>]), training : <span class=\"pl-c1\">False</span>})\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> fails after this line</span>\nsess.run(x_norm, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x : np.random.random(<span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>]), training : <span class=\"pl-c1\">False</span>})    </pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.10.1-0-g4dcfddc5d1 1.10.1\nPython version: Python 3.6.2\nExact command to reproduce: python main.py\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nMobile device: N/A\nBazel version: N/A\n\nDescribe the problem\nThe batch normalization implementation respects the virtual_batch_size parameter in both train and inference modes. As such you are unable to do inference with batch sizes that are not multiples of the virtual_batch_size. Algorithm 1 in the ghost batch norm paper makes it clear that virtual_batch_size should only be respected in train mode.\nRelevant tf source code: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py\nSource code / logs\nimport tensorflow as tf\nimport numpy as np\n\nvirtual_batch_size = 32\n\ntraining = tf.placeholder(tf.bool, shape=[])\nx = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\nx_norm = tf.layers.batch_normalization(x, training=training, virtual_batch_size=virtual_batch_size)\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\nsess = tf.Session()\n\nsess.run(tf.global_variables_initializer())\n\n\nfor _ in range(10):\n    sess.run([update_ops, x_norm], feed_dict={x : np.random.random(size=[4*virtual_batch_size, 28, 28, 1]), training : True})\n\nsess.run(x_norm, feed_dict={x : np.random.random(size=[virtual_batch_size, 28, 28, 1]), training : False})\n\n# fails after this line\nsess.run(x_norm, feed_dict={x : np.random.random(size=[1, 28, 28, 1]), training : False})", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.10.1-0-g4dcfddc5d1 1.10.1\r\n- **Python version**: Python 3.6.2\r\n- **Exact command to reproduce**: python main.py\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Mobile device**: N/A\r\n- **Bazel version**: N/A\r\n\r\n### Describe the problem\r\nThe batch normalization implementation respects the virtual_batch_size parameter in both train and inference modes. As such you are unable to do inference with batch sizes that are not multiples of the virtual_batch_size. Algorithm 1 in the [ghost batch norm paper](https://arxiv.org/pdf/1705.08741.pdf) makes it clear that virtual_batch_size should only be respected in train mode.\r\n\r\nRelevant tf source code: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py\r\n\r\n### Source code / logs\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nvirtual_batch_size = 32\r\n\r\ntraining = tf.placeholder(tf.bool, shape=[])\r\nx = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\r\nx_norm = tf.layers.batch_normalization(x, training=training, virtual_batch_size=virtual_batch_size)\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n\r\nsess = tf.Session()\r\n\r\nsess.run(tf.global_variables_initializer())\r\n\r\n\r\nfor _ in range(10):\r\n    sess.run([update_ops, x_norm], feed_dict={x : np.random.random(size=[4*virtual_batch_size, 28, 28, 1]), training : True})\r\n\r\nsess.run(x_norm, feed_dict={x : np.random.random(size=[virtual_batch_size, 28, 28, 1]), training : False})\r\n\r\n# fails after this line\r\nsess.run(x_norm, feed_dict={x : np.random.random(size=[1, 28, 28, 1]), training : False})    \r\n```\r\n"}