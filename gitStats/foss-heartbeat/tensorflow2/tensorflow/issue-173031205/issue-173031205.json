{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4022", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4022/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4022/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4022/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4022", "id": 173031205, "node_id": "MDU6SXNzdWUxNzMwMzEyMDU=", "number": 4022, "title": "train.batch with dynamic_pad=True and input as list of tensors not working as expected", "user": {"login": "alexbeloi", "id": 9807648, "node_id": "MDQ6VXNlcjk4MDc2NDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/9807648?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexbeloi", "html_url": "https://github.com/alexbeloi", "followers_url": "https://api.github.com/users/alexbeloi/followers", "following_url": "https://api.github.com/users/alexbeloi/following{/other_user}", "gists_url": "https://api.github.com/users/alexbeloi/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexbeloi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexbeloi/subscriptions", "organizations_url": "https://api.github.com/users/alexbeloi/orgs", "repos_url": "https://api.github.com/users/alexbeloi/repos", "events_url": "https://api.github.com/users/alexbeloi/events{/privacy}", "received_events_url": "https://api.github.com/users/alexbeloi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-08-24T18:58:18Z", "updated_at": "2017-02-18T21:56:48Z", "closed_at": "2016-10-07T16:54:45Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System:<br>\nUbuntu 14.04.4 LTS (running in Virtual Box 5.0.22 r108108)</p>\n<p>Installed version of CUDA and cuDNN:<br>\nNone</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.<br>\npip 8.1.2</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.<br>\n0.10.0rc0</li>\n</ol>\n<h3>Preface</h3>\n<p>This issue arose from attempting to expand on an example using dynamic padding as written in: <a href=\"http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\" rel=\"nofollow\">http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/</a><br>\nthe necessary code is copied below.</p>\n<h3>Steps to reproduce</h3>\n<p>Run the following minimal example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> [0, 1, 2, 3, 4 ,...]</span>\nx <span class=\"pl-k\">=</span> tf.range(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> A queue that outputs 0,1,2,3,...</span>\nrange_q <span class=\"pl-k\">=</span> tf.train.range_input_producer(<span class=\"pl-v\">limit</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\nslice_end <span class=\"pl-k\">=</span> range_q.dequeue()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....</span>\ny <span class=\"pl-k\">=</span> tf.slice(x, [<span class=\"pl-c1\">0</span>], [slice_end], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>)\n\nbatched_data <span class=\"pl-k\">=</span> tf.train.batch(\n    <span class=\"pl-v\">tensors</span><span class=\"pl-k\">=</span>[y],\n    <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>,\n    <span class=\"pl-v\">dynamic_pad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y_batch<span class=\"pl-pds\">\"</span></span>\n)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run the graph</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> tf.contrib.learn takes care of starting the queues for us</span>\nres <span class=\"pl-k\">=</span> tf.contrib.learn.run_n({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>: batched_data}, <span class=\"pl-v\">n</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Print the result</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Batch shape: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(res[<span class=\"pl-c1\">0</span>][<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>].shape))\n<span class=\"pl-c1\">print</span>(res[<span class=\"pl-c1\">0</span>][<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>])</pre></div>\n<p>Output (correct behavior):</p>\n<pre><code>Batch shape: (5, 4)\n[[0 0 0 0]\n [1 0 0 0]\n [1 2 0 0]\n [1 2 3 0]\n [1 2 3 4]]\n</code></pre>\n<p>When attempted with different input (list of tensors of different lengths)</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\ny <span class=\"pl-k\">=</span> [tf.constant(<span class=\"pl-c1\">range</span>(n)) <span class=\"pl-k\">for</span> n <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">10</span>)]\n\nbatched_data <span class=\"pl-k\">=</span> tf.train.batch(\n    <span class=\"pl-v\">tensors</span><span class=\"pl-k\">=</span>[y],\n    <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>,\n    <span class=\"pl-v\">dynamic_pad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y_batch<span class=\"pl-pds\">\"</span></span>\n)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run the graph</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> tf.contrib.learn takes care of starting the queues for us</span>\nres <span class=\"pl-k\">=</span> tf.contrib.learn.run_n({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>: batched_data}, <span class=\"pl-v\">n</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Print the result</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Batch shape: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(res[<span class=\"pl-c1\">0</span>][<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>].shape))\n<span class=\"pl-c1\">print</span>(res[<span class=\"pl-c1\">0</span>][<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>])</pre></div>\n<p>Output:</p>\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-12-8b4d52a4df68&gt; in &lt;module&gt;()\n     19     batch_size=5,\n     20     dynamic_pad=True,\n---&gt; 21     name=\"y_batch\"\n     22 )\n     23 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.pyc in batch(tensors, batch_size, num_threads, capacity, enqueue_many, shapes, dynamic_pad, allow_smaller_final_batch, shared_name, name)\n    577   tensor_list = _as_tensor_list(tensors)\n    578   with ops.op_scope(tensor_list, name, \"batch\") as name:\n--&gt; 579     tensor_list = _validate(tensor_list)\n    580     (tensor_list, sparse_info) = _serialize_sparse_tensors(\n    581         tensor_list, enqueue_many)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.pyc in _validate(tensor_list)\n    411 \n    412 def _validate(tensor_list):\n--&gt; 413   tensor_list = ops.convert_n_to_tensor_or_indexed_slices(tensor_list)\n    414   if not tensor_list:\n    415     raise ValueError(\"Expected at least one tensor in batch().\")\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_n_to_tensor_or_indexed_slices(values, dtype, name, as_ref)\n    735       ret.append(\n    736           convert_to_tensor_or_indexed_slices(value, dtype=dtype, name=n,\n--&gt; 737                                               as_ref=as_ref))\n    738   return ret\n    739 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_to_tensor_or_indexed_slices(value, dtype, name, as_ref)\n    696     return value\n    697   else:\n--&gt; 698     return convert_to_tensor(value, dtype=dtype, name=name, as_ref=as_ref)\n    699 \n    700 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_to_tensor(value, dtype, name, as_ref)\n    619     for base_type, conversion_func in funcs_at_priority:\n    620       if isinstance(value, base_type):\n--&gt; 621         ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    622         if ret is NotImplemented:\n    623           continue\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _autopacking_conversion_function(v, dtype, name, as_ref)\n    628   if dtype is not None and dtype != inferred_dtype:\n    629     return NotImplemented\n--&gt; 630   return _autopacking_helper(v, inferred_dtype, name or \"packed\")\n    631 # pylint: enable=invalid-name\n    632 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _autopacking_helper(list_or_tuple, dtype, name)\n    591           elems_as_tensors.append(\n    592               constant_op.constant(elem, dtype=dtype, name=str(i)))\n--&gt; 593       return gen_array_ops._pack(elems_as_tensors, name=scope)\n    594     else:\n    595       return converted_elems\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.pyc in _pack(values, axis, name)\n   1452     A `Tensor`. Has the same type as `values`. The packed tensor.\n   1453   \"\"\"\n-&gt; 1454   result = _op_def_lib.apply_op(\"Pack\", values=values, axis=axis, name=name)\n   1455   return result\n   1456 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)\n    701           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    702                            input_types=input_types, attrs=attr_protos,\n--&gt; 703                            op_def=op_def)\n    704           outputs = op.outputs\n    705           return _Restructure(ops.convert_n_to_tensor(outputs),\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\n   2310                     original_op=self._default_original_op, op_def=op_def)\n   2311     if compute_shapes:\n-&gt; 2312       set_shapes_for_outputs(ret)\n   2313     self._add_op(ret)\n   2314     self._record_op_seen_by_control_dependencies(ret)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)\n   1702       raise RuntimeError(\"No shape function registered for standard op: %s\"\n   1703                          % op.type)\n-&gt; 1704   shapes = shape_func(op)\n   1705   if shapes is None:\n   1706     raise RuntimeError(\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _PackShape(op)\n    767 \n    768   for inp in op.inputs[1:]:\n--&gt; 769     input_shape = input_shape.merge_with(inp.get_shape())\n    770 \n    771   input_shape = input_shape.as_list()\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)\n    568       except ValueError:\n    569         raise ValueError(\"Shapes %s and %s are not compatible\" %\n--&gt; 570                          (self, other))\n    571 \n    572   def concatenate(self, other):\n\nValueError: Shapes (1,) and (2,) are not compatible\n</code></pre>\n<p>Expected same result as previous script.</p>\n<h3>What have you tried?</h3>\n<ul>\n<li>Attempted transforming <code>y</code> into a tensor but have not found a way. Given the first example, it appears possible to construct tensors with variable size in some dimension, but given a dataset in the form of List of List of primitive (with inner lists being of varying lengths), I don't know how to transform this into a tensor without padding the entire dataset.</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> [0, 1, 2, 3, 4 ,...]</span>\nx <span class=\"pl-k\">=</span> tf.range(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> A queue that outputs 0,1,2,3,...</span>\nrange_q <span class=\"pl-k\">=</span> tf.train.range_input_producer(<span class=\"pl-v\">limit</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\nslice_end <span class=\"pl-k\">=</span> range_q.dequeue()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....</span>\ny <span class=\"pl-k\">=</span> tf.slice(x, [<span class=\"pl-c1\">0</span>], [slice_end], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Dynamic shape of y:<span class=\"pl-pds\">'</span></span>, tf.shape(y)\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Static shape of y:<span class=\"pl-pds\">'</span></span>, y.get_shape()</pre></div>\n<p>Output:</p>\n<pre><code>Dynamic shape of y: Tensor(\"Shape_16:0\", shape=(1,), dtype=int32)\nStatic shape of y: (?,)\n</code></pre>\n<ul>\n<li>Attempted replacing <code>tf.train.batch</code> line with the <code>tf.PaddingFIFOQueue</code> as follows</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Creating a new queue</span>\npadding_q <span class=\"pl-k\">=</span> tf.PaddingFIFOQueue(\n    <span class=\"pl-v\">capacity</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>,\n    <span class=\"pl-v\">dtypes</span><span class=\"pl-k\">=</span>tf.int32,\n    <span class=\"pl-v\">shapes</span><span class=\"pl-k\">=</span>[[<span class=\"pl-c1\">None</span>]])\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Enqueue the examples</span>\nenqueue_op <span class=\"pl-k\">=</span> padding_q.enqueue([y])\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Add the queue runner to the graph</span>\nqr <span class=\"pl-k\">=</span> tf.train.QueueRunner(padding_q, [enqueue_op])\ntf.train.add_queue_runner(qr)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Dequeue padded data</span>\nbatched_data <span class=\"pl-k\">=</span> padding_q.dequeue_many(<span class=\"pl-c1\">5</span>)</pre></div>\n<p>Output: identical to above</p>\n<ul>\n<li>Using placeholders: tried replacing <code>y</code> with a placeholder of shape <code>[None]</code> and feeding it the data, cannot seem to get this to work either.</li>\n<li>Padding entire dataset: this works, but defeats the purpose of dynamic padding</li>\n<li>Todo: am going to try passing dataset through <code>tf.train.SequenceExample()</code>, constructing an example for each sequence, but I would rather this not be necessary.</li>\n</ul>", "body_text": "Environment info\nOperating System:\nUbuntu 14.04.4 LTS (running in Virtual Box 5.0.22 r108108)\nInstalled version of CUDA and cuDNN:\nNone\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\npip 8.1.2\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n0.10.0rc0\n\nPreface\nThis issue arose from attempting to expand on an example using dynamic padding as written in: http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\nthe necessary code is copied below.\nSteps to reproduce\nRun the following minimal example:\nimport tensorflow as tf\n\n# [0, 1, 2, 3, 4 ,...]\nx = tf.range(1, 10, name=\"x\")\n\n# A queue that outputs 0,1,2,3,...\nrange_q = tf.train.range_input_producer(limit=5, shuffle=False)\nslice_end = range_q.dequeue()\n\n# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\ny = tf.slice(x, [0], [slice_end], name=\"y\")\n\nbatched_data = tf.train.batch(\n    tensors=[y],\n    batch_size=5,\n    dynamic_pad=True,\n    name=\"y_batch\"\n)\n\n# Run the graph\n# tf.contrib.learn takes care of starting the queues for us\nres = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n\n# Print the result\nprint(\"Batch shape: {}\".format(res[0][\"y\"].shape))\nprint(res[0][\"y\"])\nOutput (correct behavior):\nBatch shape: (5, 4)\n[[0 0 0 0]\n [1 0 0 0]\n [1 2 0 0]\n [1 2 3 0]\n [1 2 3 4]]\n\nWhen attempted with different input (list of tensors of different lengths)\nimport tensorflow as tf\n\ny = [tf.constant(range(n)) for n in range(1,10)]\n\nbatched_data = tf.train.batch(\n    tensors=[y],\n    batch_size=5,\n    dynamic_pad=True,\n    name=\"y_batch\"\n)\n\n# Run the graph\n# tf.contrib.learn takes care of starting the queues for us\nres = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n\n# Print the result\nprint(\"Batch shape: {}\".format(res[0][\"y\"].shape))\nprint(res[0][\"y\"])\nOutput:\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-12-8b4d52a4df68> in <module>()\n     19     batch_size=5,\n     20     dynamic_pad=True,\n---> 21     name=\"y_batch\"\n     22 )\n     23 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.pyc in batch(tensors, batch_size, num_threads, capacity, enqueue_many, shapes, dynamic_pad, allow_smaller_final_batch, shared_name, name)\n    577   tensor_list = _as_tensor_list(tensors)\n    578   with ops.op_scope(tensor_list, name, \"batch\") as name:\n--> 579     tensor_list = _validate(tensor_list)\n    580     (tensor_list, sparse_info) = _serialize_sparse_tensors(\n    581         tensor_list, enqueue_many)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.pyc in _validate(tensor_list)\n    411 \n    412 def _validate(tensor_list):\n--> 413   tensor_list = ops.convert_n_to_tensor_or_indexed_slices(tensor_list)\n    414   if not tensor_list:\n    415     raise ValueError(\"Expected at least one tensor in batch().\")\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_n_to_tensor_or_indexed_slices(values, dtype, name, as_ref)\n    735       ret.append(\n    736           convert_to_tensor_or_indexed_slices(value, dtype=dtype, name=n,\n--> 737                                               as_ref=as_ref))\n    738   return ret\n    739 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_to_tensor_or_indexed_slices(value, dtype, name, as_ref)\n    696     return value\n    697   else:\n--> 698     return convert_to_tensor(value, dtype=dtype, name=name, as_ref=as_ref)\n    699 \n    700 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_to_tensor(value, dtype, name, as_ref)\n    619     for base_type, conversion_func in funcs_at_priority:\n    620       if isinstance(value, base_type):\n--> 621         ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    622         if ret is NotImplemented:\n    623           continue\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _autopacking_conversion_function(v, dtype, name, as_ref)\n    628   if dtype is not None and dtype != inferred_dtype:\n    629     return NotImplemented\n--> 630   return _autopacking_helper(v, inferred_dtype, name or \"packed\")\n    631 # pylint: enable=invalid-name\n    632 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _autopacking_helper(list_or_tuple, dtype, name)\n    591           elems_as_tensors.append(\n    592               constant_op.constant(elem, dtype=dtype, name=str(i)))\n--> 593       return gen_array_ops._pack(elems_as_tensors, name=scope)\n    594     else:\n    595       return converted_elems\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.pyc in _pack(values, axis, name)\n   1452     A `Tensor`. Has the same type as `values`. The packed tensor.\n   1453   \"\"\"\n-> 1454   result = _op_def_lib.apply_op(\"Pack\", values=values, axis=axis, name=name)\n   1455   return result\n   1456 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)\n    701           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    702                            input_types=input_types, attrs=attr_protos,\n--> 703                            op_def=op_def)\n    704           outputs = op.outputs\n    705           return _Restructure(ops.convert_n_to_tensor(outputs),\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\n   2310                     original_op=self._default_original_op, op_def=op_def)\n   2311     if compute_shapes:\n-> 2312       set_shapes_for_outputs(ret)\n   2313     self._add_op(ret)\n   2314     self._record_op_seen_by_control_dependencies(ret)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)\n   1702       raise RuntimeError(\"No shape function registered for standard op: %s\"\n   1703                          % op.type)\n-> 1704   shapes = shape_func(op)\n   1705   if shapes is None:\n   1706     raise RuntimeError(\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _PackShape(op)\n    767 \n    768   for inp in op.inputs[1:]:\n--> 769     input_shape = input_shape.merge_with(inp.get_shape())\n    770 \n    771   input_shape = input_shape.as_list()\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)\n    568       except ValueError:\n    569         raise ValueError(\"Shapes %s and %s are not compatible\" %\n--> 570                          (self, other))\n    571 \n    572   def concatenate(self, other):\n\nValueError: Shapes (1,) and (2,) are not compatible\n\nExpected same result as previous script.\nWhat have you tried?\n\nAttempted transforming y into a tensor but have not found a way. Given the first example, it appears possible to construct tensors with variable size in some dimension, but given a dataset in the form of List of List of primitive (with inner lists being of varying lengths), I don't know how to transform this into a tensor without padding the entire dataset.\n\nimport tensorflow as tf\n\n# [0, 1, 2, 3, 4 ,...]\nx = tf.range(1, 10, name=\"x\")\n\n# A queue that outputs 0,1,2,3,...\nrange_q = tf.train.range_input_producer(limit=5, shuffle=False)\nslice_end = range_q.dequeue()\n\n# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\ny = tf.slice(x, [0], [slice_end], name=\"y\")\n\nprint 'Dynamic shape of y:', tf.shape(y)\nprint 'Static shape of y:', y.get_shape()\nOutput:\nDynamic shape of y: Tensor(\"Shape_16:0\", shape=(1,), dtype=int32)\nStatic shape of y: (?,)\n\n\nAttempted replacing tf.train.batch line with the tf.PaddingFIFOQueue as follows\n\n# Creating a new queue\npadding_q = tf.PaddingFIFOQueue(\n    capacity=10,\n    dtypes=tf.int32,\n    shapes=[[None]])\n\n# Enqueue the examples\nenqueue_op = padding_q.enqueue([y])\n\n# Add the queue runner to the graph\nqr = tf.train.QueueRunner(padding_q, [enqueue_op])\ntf.train.add_queue_runner(qr)\n\n# Dequeue padded data\nbatched_data = padding_q.dequeue_many(5)\nOutput: identical to above\n\nUsing placeholders: tried replacing y with a placeholder of shape [None] and feeding it the data, cannot seem to get this to work either.\nPadding entire dataset: this works, but defeats the purpose of dynamic padding\nTodo: am going to try passing dataset through tf.train.SequenceExample(), constructing an example for each sequence, but I would rather this not be necessary.", "body": "### Environment info\n\nOperating System: \nUbuntu 14.04.4 LTS (running in Virtual Box 5.0.22 r108108)\n\nInstalled version of CUDA and cuDNN: \nNone\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\npip 8.1.2\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n0.10.0rc0\n### Preface\n\nThis issue arose from attempting to expand on an example using dynamic padding as written in: http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\nthe necessary code is copied below.\n### Steps to reproduce\n\nRun the following minimal example:\n\n``` python\nimport tensorflow as tf\n\n# [0, 1, 2, 3, 4 ,...]\nx = tf.range(1, 10, name=\"x\")\n\n# A queue that outputs 0,1,2,3,...\nrange_q = tf.train.range_input_producer(limit=5, shuffle=False)\nslice_end = range_q.dequeue()\n\n# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\ny = tf.slice(x, [0], [slice_end], name=\"y\")\n\nbatched_data = tf.train.batch(\n    tensors=[y],\n    batch_size=5,\n    dynamic_pad=True,\n    name=\"y_batch\"\n)\n\n# Run the graph\n# tf.contrib.learn takes care of starting the queues for us\nres = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n\n# Print the result\nprint(\"Batch shape: {}\".format(res[0][\"y\"].shape))\nprint(res[0][\"y\"])\n```\n\nOutput (correct behavior):\n\n```\nBatch shape: (5, 4)\n[[0 0 0 0]\n [1 0 0 0]\n [1 2 0 0]\n [1 2 3 0]\n [1 2 3 4]]\n```\n\nWhen attempted with different input (list of tensors of different lengths)\n\n``` python\nimport tensorflow as tf\n\ny = [tf.constant(range(n)) for n in range(1,10)]\n\nbatched_data = tf.train.batch(\n    tensors=[y],\n    batch_size=5,\n    dynamic_pad=True,\n    name=\"y_batch\"\n)\n\n# Run the graph\n# tf.contrib.learn takes care of starting the queues for us\nres = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n\n# Print the result\nprint(\"Batch shape: {}\".format(res[0][\"y\"].shape))\nprint(res[0][\"y\"])\n```\n\nOutput:\n\n```\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-12-8b4d52a4df68> in <module>()\n     19     batch_size=5,\n     20     dynamic_pad=True,\n---> 21     name=\"y_batch\"\n     22 )\n     23 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.pyc in batch(tensors, batch_size, num_threads, capacity, enqueue_many, shapes, dynamic_pad, allow_smaller_final_batch, shared_name, name)\n    577   tensor_list = _as_tensor_list(tensors)\n    578   with ops.op_scope(tensor_list, name, \"batch\") as name:\n--> 579     tensor_list = _validate(tensor_list)\n    580     (tensor_list, sparse_info) = _serialize_sparse_tensors(\n    581         tensor_list, enqueue_many)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.pyc in _validate(tensor_list)\n    411 \n    412 def _validate(tensor_list):\n--> 413   tensor_list = ops.convert_n_to_tensor_or_indexed_slices(tensor_list)\n    414   if not tensor_list:\n    415     raise ValueError(\"Expected at least one tensor in batch().\")\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_n_to_tensor_or_indexed_slices(values, dtype, name, as_ref)\n    735       ret.append(\n    736           convert_to_tensor_or_indexed_slices(value, dtype=dtype, name=n,\n--> 737                                               as_ref=as_ref))\n    738   return ret\n    739 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_to_tensor_or_indexed_slices(value, dtype, name, as_ref)\n    696     return value\n    697   else:\n--> 698     return convert_to_tensor(value, dtype=dtype, name=name, as_ref=as_ref)\n    699 \n    700 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in convert_to_tensor(value, dtype, name, as_ref)\n    619     for base_type, conversion_func in funcs_at_priority:\n    620       if isinstance(value, base_type):\n--> 621         ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    622         if ret is NotImplemented:\n    623           continue\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _autopacking_conversion_function(v, dtype, name, as_ref)\n    628   if dtype is not None and dtype != inferred_dtype:\n    629     return NotImplemented\n--> 630   return _autopacking_helper(v, inferred_dtype, name or \"packed\")\n    631 # pylint: enable=invalid-name\n    632 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _autopacking_helper(list_or_tuple, dtype, name)\n    591           elems_as_tensors.append(\n    592               constant_op.constant(elem, dtype=dtype, name=str(i)))\n--> 593       return gen_array_ops._pack(elems_as_tensors, name=scope)\n    594     else:\n    595       return converted_elems\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.pyc in _pack(values, axis, name)\n   1452     A `Tensor`. Has the same type as `values`. The packed tensor.\n   1453   \"\"\"\n-> 1454   result = _op_def_lib.apply_op(\"Pack\", values=values, axis=axis, name=name)\n   1455   return result\n   1456 \n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)\n    701           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    702                            input_types=input_types, attrs=attr_protos,\n--> 703                            op_def=op_def)\n    704           outputs = op.outputs\n    705           return _Restructure(ops.convert_n_to_tensor(outputs),\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\n   2310                     original_op=self._default_original_op, op_def=op_def)\n   2311     if compute_shapes:\n-> 2312       set_shapes_for_outputs(ret)\n   2313     self._add_op(ret)\n   2314     self._record_op_seen_by_control_dependencies(ret)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)\n   1702       raise RuntimeError(\"No shape function registered for standard op: %s\"\n   1703                          % op.type)\n-> 1704   shapes = shape_func(op)\n   1705   if shapes is None:\n   1706     raise RuntimeError(\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _PackShape(op)\n    767 \n    768   for inp in op.inputs[1:]:\n--> 769     input_shape = input_shape.merge_with(inp.get_shape())\n    770 \n    771   input_shape = input_shape.as_list()\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)\n    568       except ValueError:\n    569         raise ValueError(\"Shapes %s and %s are not compatible\" %\n--> 570                          (self, other))\n    571 \n    572   def concatenate(self, other):\n\nValueError: Shapes (1,) and (2,) are not compatible\n```\n\nExpected same result as previous script.\n### What have you tried?\n- Attempted transforming `y` into a tensor but have not found a way. Given the first example, it appears possible to construct tensors with variable size in some dimension, but given a dataset in the form of List of List of primitive (with inner lists being of varying lengths), I don't know how to transform this into a tensor without padding the entire dataset.\n\n``` python\nimport tensorflow as tf\n\n# [0, 1, 2, 3, 4 ,...]\nx = tf.range(1, 10, name=\"x\")\n\n# A queue that outputs 0,1,2,3,...\nrange_q = tf.train.range_input_producer(limit=5, shuffle=False)\nslice_end = range_q.dequeue()\n\n# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\ny = tf.slice(x, [0], [slice_end], name=\"y\")\n\nprint 'Dynamic shape of y:', tf.shape(y)\nprint 'Static shape of y:', y.get_shape()\n```\n\nOutput:\n\n```\nDynamic shape of y: Tensor(\"Shape_16:0\", shape=(1,), dtype=int32)\nStatic shape of y: (?,)\n```\n- Attempted replacing `tf.train.batch` line with the `tf.PaddingFIFOQueue` as follows\n\n``` python\n# Creating a new queue\npadding_q = tf.PaddingFIFOQueue(\n    capacity=10,\n    dtypes=tf.int32,\n    shapes=[[None]])\n\n# Enqueue the examples\nenqueue_op = padding_q.enqueue([y])\n\n# Add the queue runner to the graph\nqr = tf.train.QueueRunner(padding_q, [enqueue_op])\ntf.train.add_queue_runner(qr)\n\n# Dequeue padded data\nbatched_data = padding_q.dequeue_many(5)\n```\n\nOutput: identical to above\n- Using placeholders: tried replacing `y` with a placeholder of shape `[None]` and feeding it the data, cannot seem to get this to work either.\n- Padding entire dataset: this works, but defeats the purpose of dynamic padding\n- Todo: am going to try passing dataset through `tf.train.SequenceExample()`, constructing an example for each sequence, but I would rather this not be necessary.\n"}