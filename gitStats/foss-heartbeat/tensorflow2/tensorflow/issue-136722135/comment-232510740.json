{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/232510740", "html_url": "https://github.com/tensorflow/tensorflow/issues/1300#issuecomment-232510740", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1300", "id": 232510740, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMjUxMDc0MA==", "user": {"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-13T22:56:24Z", "updated_at": "2016-07-13T22:56:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The performance of the cifar10 model is limited by the speed at which we can perform the local response normalization. This operation is currently implemented for CPU only. Since most CPUs don't support fp16, we have to emulate the corresponding computations, which is incredibly slow.</p>\n<p>The performance should improve significantly once we add support for LRN on GPU. Another option would be to compile tensorflow with support for the f16c instruction that's been introduced with the Haswell architecture. That should reduce the performance gap between fp16 and fp32.</p>", "body_text": "The performance of the cifar10 model is limited by the speed at which we can perform the local response normalization. This operation is currently implemented for CPU only. Since most CPUs don't support fp16, we have to emulate the corresponding computations, which is incredibly slow.\nThe performance should improve significantly once we add support for LRN on GPU. Another option would be to compile tensorflow with support for the f16c instruction that's been introduced with the Haswell architecture. That should reduce the performance gap between fp16 and fp32.", "body": "The performance of the cifar10 model is limited by the speed at which we can perform the local response normalization. This operation is currently implemented for CPU only. Since most CPUs don't support fp16, we have to emulate the corresponding computations, which is incredibly slow.\n\nThe performance should improve significantly once we add support for LRN on GPU. Another option would be to compile tensorflow with support for the f16c instruction that's been introduced with the Haswell architecture. That should reduce the performance gap between fp16 and fp32.\n"}