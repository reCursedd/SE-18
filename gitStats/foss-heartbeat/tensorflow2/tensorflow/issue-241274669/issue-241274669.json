{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11351", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11351/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11351/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11351/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11351", "id": 241274669, "node_id": "MDU6SXNzdWUyNDEyNzQ2Njk=", "number": 11351, "title": "transform_graph quantize_weights doesn't compile on windows", "user": {"login": "MaxBareiss", "id": 1223902, "node_id": "MDQ6VXNlcjEyMjM5MDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1223902?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MaxBareiss", "html_url": "https://github.com/MaxBareiss", "followers_url": "https://api.github.com/users/MaxBareiss/followers", "following_url": "https://api.github.com/users/MaxBareiss/following{/other_user}", "gists_url": "https://api.github.com/users/MaxBareiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/MaxBareiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MaxBareiss/subscriptions", "organizations_url": "https://api.github.com/users/MaxBareiss/orgs", "repos_url": "https://api.github.com/users/MaxBareiss/repos", "events_url": "https://api.github.com/users/MaxBareiss/events{/privacy}", "received_events_url": "https://api.github.com/users/MaxBareiss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-07-07T14:06:34Z", "updated_at": "2018-02-08T16:58:37Z", "closed_at": "2018-02-08T16:58:37Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n</ul>\n<p>I'm executing a command from documentation, and I don't think that my custom model is part of the issue.</p>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n</ul>\n<p>Windows Server 2012 R2 64-bit</p>\n<ul>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n</ul>\n<p>Latest master (7/7/2017) compiled with bazel and msvc</p>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n</ul>\n<p>commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/1e037850f1a63cbc22a49a4d54a8b067cf43b57f/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/1e037850f1a63cbc22a49a4d54a8b067cf43b57f\"><tt>1e03785</tt></a> (July 6 21:55:34 2017 -0400)</p>\n<ul>\n<li><strong>Python version</strong>:</li>\n</ul>\n<p>3.5.3 Anaconda 64-bit</p>\n<ul>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n</ul>\n<p>0.5.1</p>\n<ul>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n</ul>\n<p>CPU Only</p>\n<ul>\n<li><strong>GPU model and memory</strong>:</li>\n</ul>\n<p>CPU Only (CPU is dual socket Xeon E5-2687W v2)</p>\n<ul>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)\nfold_batch_norms\nfold_old_batch_norms\nquantize_weights'\n</code></pre>\n<h3>Describe the problem</h3>\n<p>I originally asked this question on StackOverflow and I was recommended to file a bug report:</p>\n<p><a href=\"https://stackoverflow.com/questions/44955491/tensorflow-transform-graph-doesnt-have-quantize-weights\" rel=\"nofollow\">https://stackoverflow.com/questions/44955491/tensorflow-transform-graph-doesnt-have-quantize-weights</a></p>\n<p>The <code>transform_graph</code> program in tensorflow does not include the <code>quantize_weights</code> transform. If I execute the command above without the <code>quantize_weights</code> transform it works correctly.</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<pre><code>$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)\nfold_batch_norms\nfold_old_batch_norms\nquantize_weights'\n</code></pre>\n<pre><code>2017-07-06 13:21:10.361492: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_constants\n2017-07-06 13:21:10.476001: W C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-06 13:21:13.241688: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_batch_norms\n2017-07-06 13:21:16.088969: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_old_batch_norms\n2017-07-06 13:21:16.650913: E C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:209] Transform 'quantize_weights' not recognized.\n2017-07-06 13:21:16.650934: E C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:210] usage: C:\\Users\\name\\git-repos\\tensorflow\\bazel-bin\\tensorflow\\tools\\graph_transforms\\transform_graph.exe\nFlags:\n        --in_graph=\"\"                           string  input graph file name\n        --out_graph=\"\"                          string  output graph file name\n        --inputs=\"\"                             string  inputs\n        --outputs=\"\"                            string  outputs\n        --transforms=\"\"                         string  list of transforms\n        --output_as_text=false                  bool    whether to write the graph in text protobuf format\n\nTransforms are:\nadd_default_attributes\nbackport_concatv2\nbackport_tensor_array_v3\nfold_batch_norms\nfold_constants\nfold_old_batch_norms\nfreeze_requantization_ranges\nfuse_pad_and_conv\nfuse_resize_and_conv\nfuse_resize_pad_and_conv\ninsert_logging\nobfuscate_names\nremove_attribute\nremove_device\nremove_nodes\nrename_attribute\nrename_op\nset_device\nsort_by_execution_order\nsparsify_gather\nstrip_unused_nodes\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nI'm executing a command from documentation, and I don't think that my custom model is part of the issue.\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n\nWindows Server 2012 R2 64-bit\n\nTensorFlow installed from (source or binary):\n\nLatest master (7/7/2017) compiled with bazel and msvc\n\nTensorFlow version (use command below):\n\ncommit 1e03785 (July 6 21:55:34 2017 -0400)\n\nPython version:\n\n3.5.3 Anaconda 64-bit\n\nBazel version (if compiling from source):\n\n0.5.1\n\nCUDA/cuDNN version:\n\nCPU Only\n\nGPU model and memory:\n\nCPU Only (CPU is dual socket Xeon E5-2687W v2)\n\nExact command to reproduce:\n\n$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)\nfold_batch_norms\nfold_old_batch_norms\nquantize_weights'\n\nDescribe the problem\nI originally asked this question on StackOverflow and I was recommended to file a bug report:\nhttps://stackoverflow.com/questions/44955491/tensorflow-transform-graph-doesnt-have-quantize-weights\nThe transform_graph program in tensorflow does not include the quantize_weights transform. If I execute the command above without the quantize_weights transform it works correctly.\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\n$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)\nfold_batch_norms\nfold_old_batch_norms\nquantize_weights'\n\n2017-07-06 13:21:10.361492: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_constants\n2017-07-06 13:21:10.476001: W C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-06 13:21:13.241688: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_batch_norms\n2017-07-06 13:21:16.088969: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_old_batch_norms\n2017-07-06 13:21:16.650913: E C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:209] Transform 'quantize_weights' not recognized.\n2017-07-06 13:21:16.650934: E C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:210] usage: C:\\Users\\name\\git-repos\\tensorflow\\bazel-bin\\tensorflow\\tools\\graph_transforms\\transform_graph.exe\nFlags:\n        --in_graph=\"\"                           string  input graph file name\n        --out_graph=\"\"                          string  output graph file name\n        --inputs=\"\"                             string  inputs\n        --outputs=\"\"                            string  outputs\n        --transforms=\"\"                         string  list of transforms\n        --output_as_text=false                  bool    whether to write the graph in text protobuf format\n\nTransforms are:\nadd_default_attributes\nbackport_concatv2\nbackport_tensor_array_v3\nfold_batch_norms\nfold_constants\nfold_old_batch_norms\nfreeze_requantization_ranges\nfuse_pad_and_conv\nfuse_resize_and_conv\nfuse_resize_pad_and_conv\ninsert_logging\nobfuscate_names\nremove_attribute\nremove_device\nremove_nodes\nrename_attribute\nrename_op\nset_device\nsort_by_execution_order\nsparsify_gather\nstrip_unused_nodes", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nI'm executing a command from documentation, and I don't think that my custom model is part of the issue.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nWindows Server 2012 R2 64-bit\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nLatest master (7/7/2017) compiled with bazel and msvc\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\ncommit 1e037850f1a (July 6 21:55:34 2017 -0400)\r\n\r\n- **Python version**: \r\n\r\n3.5.3 Anaconda 64-bit\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\n0.5.1\r\n\r\n- **CUDA/cuDNN version**:\r\n\r\nCPU Only\r\n\r\n- **GPU model and memory**:\r\n\r\nCPU Only (CPU is dual socket Xeon E5-2687W v2)\r\n\r\n- **Exact command to reproduce**:\r\n```\r\n$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)\r\nfold_batch_norms\r\nfold_old_batch_norms\r\nquantize_weights'\r\n```\r\n\r\n### Describe the problem\r\n\r\nI originally asked this question on StackOverflow and I was recommended to file a bug report:\r\n\r\nhttps://stackoverflow.com/questions/44955491/tensorflow-transform-graph-doesnt-have-quantize-weights\r\n\r\nThe `transform_graph` program in tensorflow does not include the `quantize_weights` transform. If I execute the command above without the `quantize_weights` transform it works correctly.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)\r\nfold_batch_norms\r\nfold_old_batch_norms\r\nquantize_weights'\r\n```\r\n```\r\n2017-07-06 13:21:10.361492: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_constants\r\n2017-07-06 13:21:10.476001: W C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-06 13:21:13.241688: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_batch_norms\r\n2017-07-06 13:21:16.088969: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_old_batch_norms\r\n2017-07-06 13:21:16.650913: E C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:209] Transform 'quantize_weights' not recognized.\r\n2017-07-06 13:21:16.650934: E C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:210] usage: C:\\Users\\name\\git-repos\\tensorflow\\bazel-bin\\tensorflow\\tools\\graph_transforms\\transform_graph.exe\r\nFlags:\r\n        --in_graph=\"\"                           string  input graph file name\r\n        --out_graph=\"\"                          string  output graph file name\r\n        --inputs=\"\"                             string  inputs\r\n        --outputs=\"\"                            string  outputs\r\n        --transforms=\"\"                         string  list of transforms\r\n        --output_as_text=false                  bool    whether to write the graph in text protobuf format\r\n\r\nTransforms are:\r\nadd_default_attributes\r\nbackport_concatv2\r\nbackport_tensor_array_v3\r\nfold_batch_norms\r\nfold_constants\r\nfold_old_batch_norms\r\nfreeze_requantization_ranges\r\nfuse_pad_and_conv\r\nfuse_resize_and_conv\r\nfuse_resize_pad_and_conv\r\ninsert_logging\r\nobfuscate_names\r\nremove_attribute\r\nremove_device\r\nremove_nodes\r\nrename_attribute\r\nrename_op\r\nset_device\r\nsort_by_execution_order\r\nsparsify_gather\r\nstrip_unused_nodes\r\n```\r\n"}