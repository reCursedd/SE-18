{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/425189904", "html_url": "https://github.com/tensorflow/tensorflow/issues/22569#issuecomment-425189904", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22569", "id": 425189904, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTE4OTkwNA==", "user": {"login": "Giribushan", "id": 17400995, "node_id": "MDQ6VXNlcjE3NDAwOTk1", "avatar_url": "https://avatars1.githubusercontent.com/u/17400995?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Giribushan", "html_url": "https://github.com/Giribushan", "followers_url": "https://api.github.com/users/Giribushan/followers", "following_url": "https://api.github.com/users/Giribushan/following{/other_user}", "gists_url": "https://api.github.com/users/Giribushan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Giribushan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Giribushan/subscriptions", "organizations_url": "https://api.github.com/users/Giribushan/orgs", "repos_url": "https://api.github.com/users/Giribushan/repos", "events_url": "https://api.github.com/users/Giribushan/events{/privacy}", "received_events_url": "https://api.github.com/users/Giribushan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-27T18:08:18Z", "updated_at": "2018-09-27T18:08:18Z", "author_association": "NONE", "body_html": "<p>I want to run the inference using tensorflow serving on ml engine. But the model fails without giving any stack trace.</p>\n<p>Like to know if there is any debug level logging I can enable during inference</p>", "body_text": "I want to run the inference using tensorflow serving on ml engine. But the model fails without giving any stack trace.\nLike to know if there is any debug level logging I can enable during inference", "body": "I want to run the inference using tensorflow serving on ml engine. But the model fails without giving any stack trace. \r\n\r\nLike to know if there is any debug level logging I can enable during inference"}