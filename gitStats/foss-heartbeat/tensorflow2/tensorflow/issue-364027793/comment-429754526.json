{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/429754526", "html_url": "https://github.com/tensorflow/tensorflow/issues/22535#issuecomment-429754526", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22535", "id": 429754526, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTc1NDUyNg==", "user": {"login": "minizon", "id": 11333107, "node_id": "MDQ6VXNlcjExMzMzMTA3", "avatar_url": "https://avatars2.githubusercontent.com/u/11333107?v=4", "gravatar_id": "", "url": "https://api.github.com/users/minizon", "html_url": "https://github.com/minizon", "followers_url": "https://api.github.com/users/minizon/followers", "following_url": "https://api.github.com/users/minizon/following{/other_user}", "gists_url": "https://api.github.com/users/minizon/gists{/gist_id}", "starred_url": "https://api.github.com/users/minizon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/minizon/subscriptions", "organizations_url": "https://api.github.com/users/minizon/orgs", "repos_url": "https://api.github.com/users/minizon/repos", "events_url": "https://api.github.com/users/minizon/events{/privacy}", "received_events_url": "https://api.github.com/users/minizon/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-15T08:31:12Z", "updated_at": "2018-10-15T08:43:52Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11818862\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/GQYYY\">@GQYYY</a> I didn't use the CLI toco. Please follow <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/tutorials/post_training_quant.ipynb\">the python tutorial</a>  to make it. You can use tf.contrib.lite.TocoConverter.from_frozen_graph for the pb file. <strong>Please make sure that you've installed a recent tf release (maybe tf-nightly) version</strong>.  And be aware that after this kind of conversion, the model is still muck like a floating model, so maybe better set the inference_type and inference_input_type to float. What I understood is that once you had quantization-aware training, you could set them to uint8.</p>", "body_text": "@GQYYY I didn't use the CLI toco. Please follow the python tutorial  to make it. You can use tf.contrib.lite.TocoConverter.from_frozen_graph for the pb file. Please make sure that you've installed a recent tf release (maybe tf-nightly) version.  And be aware that after this kind of conversion, the model is still muck like a floating model, so maybe better set the inference_type and inference_input_type to float. What I understood is that once you had quantization-aware training, you could set them to uint8.", "body": "@GQYYY I didn't use the CLI toco. Please follow [the python tutorial](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/tutorials/post_training_quant.ipynb)  to make it. You can use tf.contrib.lite.TocoConverter.from_frozen_graph for the pb file. **Please make sure that you've installed a recent tf release (maybe tf-nightly) version**.  And be aware that after this kind of conversion, the model is still muck like a floating model, so maybe better set the inference_type and inference_input_type to float. What I understood is that once you had quantization-aware training, you could set them to uint8."}