{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22025", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22025/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22025/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22025/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22025", "id": 356448549, "node_id": "MDU6SXNzdWUzNTY0NDg1NDk=", "number": 22025, "title": "[Bug] max_pool_with_argmax has different behaviour on CPU and GPU", "user": {"login": "mpaillassa", "id": 9745094, "node_id": "MDQ6VXNlcjk3NDUwOTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/9745094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mpaillassa", "html_url": "https://github.com/mpaillassa", "followers_url": "https://api.github.com/users/mpaillassa/followers", "following_url": "https://api.github.com/users/mpaillassa/following{/other_user}", "gists_url": "https://api.github.com/users/mpaillassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/mpaillassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mpaillassa/subscriptions", "organizations_url": "https://api.github.com/users/mpaillassa/orgs", "repos_url": "https://api.github.com/users/mpaillassa/repos", "events_url": "https://api.github.com/users/mpaillassa/events{/privacy}", "received_events_url": "https://api.github.com/users/mpaillassa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-09-03T10:31:16Z", "updated_at": "2018-11-08T04:04:46Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>The function <code>max_pool_with_argmax</code> has different behaviour concerning the returned indices depending on the GPU or CPU backend.</p>\n<ul>\n<li>On GPU, returned indices do not take into account batch dimension.<br>\nIt returns indices such that <code>[b, y, x, c] -&gt; (y * width + x) * channels + c </code></li>\n<li>On CPU, returned indices take into account batch dimension.<br>\nIt returns indices such that <code>[b, y, x, c] -&gt; ((b * height + y) * width + x) * channels + c </code></li>\n</ul>\n<p>Isn't it a problem if one wants to run models with the same graph including this op both on CPU and GPU ?</p>\n<p>Here is an example to show the problem:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf \n\ni <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">1</span>])\np, ind <span class=\"pl-k\">=</span> tf.nn.max_pool_with_argmax(i, <span class=\"pl-v\">ksize</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    a <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">10</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">1</span>))\n    <span class=\"pl-c1\">print</span> a[:,:,:,<span class=\"pl-c1\">0</span>]\n    <span class=\"pl-c1\">print</span> sess.run(p, {i: a})[:,:,:,<span class=\"pl-c1\">0</span>]\n    <span class=\"pl-c1\">print</span> sess.run(ind, {i: a})[:,:,:,<span class=\"pl-c1\">0</span>]</pre></div>\n<p>Which results in something like this on CPU:</p>\n<pre><code>[[[0 3 0 0]\n  [4 0 4 8]\n  [7 8 4 5]\n  [2 3 4 5]]\n\n [[2 5 2 7]\n  [4 3 4 6]\n  [8 3 2 0]\n  [7 5 9 3]]]\n[[[4. 8.]\n  [8. 5.]]\n\n [[5. 7.]\n  [8. 9.]]]\n[[[ 4  7]\n  [ 9 11]]\n\n [[17 19]\n  [24 30]]]\n</code></pre>\n<p>And something like this on GPU:</p>\n<pre><code>[[[8 3 5 5]\n  [0 0 0 3]\n  [6 9 4 1]\n  [2 0 8 8]]\n\n [[4 6 6 5]\n  [5 7 9 3]\n  [7 6 1 3]\n  [1 6 1 0]]]\n[[[8. 5.]\n  [9. 8.]]\n\n [[7. 9.]\n  [7. 3.]]]\n[[[ 0  2]\n  [ 9 14]]\n [[ 5  6]\n  [ 8 11]]]\n</code></pre>\n<p>This was obtained with 1.9 CPU/GPU tensorflow versions.<br>\nI think it would be more convenient to have the same behaviour on CPU and GPU, isn't it ?</p>", "body_text": "The function max_pool_with_argmax has different behaviour concerning the returned indices depending on the GPU or CPU backend.\n\nOn GPU, returned indices do not take into account batch dimension.\nIt returns indices such that [b, y, x, c] -> (y * width + x) * channels + c \nOn CPU, returned indices take into account batch dimension.\nIt returns indices such that [b, y, x, c] -> ((b * height + y) * width + x) * channels + c \n\nIsn't it a problem if one wants to run models with the same graph including this op both on CPU and GPU ?\nHere is an example to show the problem:\nimport numpy as np\nimport tensorflow as tf \n\ni = tf.placeholder(tf.float32, [None, 4, 4, 1])\np, ind = tf.nn.max_pool_with_argmax(i, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\nwith tf.Session() as sess:\n    a = np.random.randint(10, size=(2, 4, 4, 1))\n    print a[:,:,:,0]\n    print sess.run(p, {i: a})[:,:,:,0]\n    print sess.run(ind, {i: a})[:,:,:,0]\nWhich results in something like this on CPU:\n[[[0 3 0 0]\n  [4 0 4 8]\n  [7 8 4 5]\n  [2 3 4 5]]\n\n [[2 5 2 7]\n  [4 3 4 6]\n  [8 3 2 0]\n  [7 5 9 3]]]\n[[[4. 8.]\n  [8. 5.]]\n\n [[5. 7.]\n  [8. 9.]]]\n[[[ 4  7]\n  [ 9 11]]\n\n [[17 19]\n  [24 30]]]\n\nAnd something like this on GPU:\n[[[8 3 5 5]\n  [0 0 0 3]\n  [6 9 4 1]\n  [2 0 8 8]]\n\n [[4 6 6 5]\n  [5 7 9 3]\n  [7 6 1 3]\n  [1 6 1 0]]]\n[[[8. 5.]\n  [9. 8.]]\n\n [[7. 9.]\n  [7. 3.]]]\n[[[ 0  2]\n  [ 9 14]]\n [[ 5  6]\n  [ 8 11]]]\n\nThis was obtained with 1.9 CPU/GPU tensorflow versions.\nI think it would be more convenient to have the same behaviour on CPU and GPU, isn't it ?", "body": "The function ``max_pool_with_argmax`` has different behaviour concerning the returned indices depending on the GPU or CPU backend.\r\n\r\n- On GPU, returned indices do not take into account batch dimension. \r\nIt returns indices such that `[b, y, x, c] -> (y * width + x) * channels + c `\r\n- On CPU, returned indices take into account batch dimension.\r\nIt returns indices such that `[b, y, x, c] -> ((b * height + y) * width + x) * channels + c `\r\n\r\nIsn't it a problem if one wants to run models with the same graph including this op both on CPU and GPU ?\r\n\r\nHere is an example to show the problem:\r\n``` python\r\nimport numpy as np\r\nimport tensorflow as tf \r\n\r\ni = tf.placeholder(tf.float32, [None, 4, 4, 1])\r\np, ind = tf.nn.max_pool_with_argmax(i, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n\r\nwith tf.Session() as sess:\r\n    a = np.random.randint(10, size=(2, 4, 4, 1))\r\n    print a[:,:,:,0]\r\n    print sess.run(p, {i: a})[:,:,:,0]\r\n    print sess.run(ind, {i: a})[:,:,:,0]\r\n```\r\nWhich results in something like this on CPU:\r\n```\r\n[[[0 3 0 0]\r\n  [4 0 4 8]\r\n  [7 8 4 5]\r\n  [2 3 4 5]]\r\n\r\n [[2 5 2 7]\r\n  [4 3 4 6]\r\n  [8 3 2 0]\r\n  [7 5 9 3]]]\r\n[[[4. 8.]\r\n  [8. 5.]]\r\n\r\n [[5. 7.]\r\n  [8. 9.]]]\r\n[[[ 4  7]\r\n  [ 9 11]]\r\n\r\n [[17 19]\r\n  [24 30]]]\r\n```\r\nAnd something like this on GPU:\r\n```\r\n[[[8 3 5 5]\r\n  [0 0 0 3]\r\n  [6 9 4 1]\r\n  [2 0 8 8]]\r\n\r\n [[4 6 6 5]\r\n  [5 7 9 3]\r\n  [7 6 1 3]\r\n  [1 6 1 0]]]\r\n[[[8. 5.]\r\n  [9. 8.]]\r\n\r\n [[7. 9.]\r\n  [7. 3.]]]\r\n[[[ 0  2]\r\n  [ 9 14]]\r\n [[ 5  6]\r\n  [ 8 11]]]\r\n```\r\nThis was obtained with 1.9 CPU/GPU tensorflow versions.\r\nI think it would be more convenient to have the same behaviour on CPU and GPU, isn't it ?"}