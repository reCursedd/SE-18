{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/284923453", "html_url": "https://github.com/tensorflow/tensorflow/issues/492#issuecomment-284923453", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/492", "id": 284923453, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NDkyMzQ1Mw==", "user": {"login": "ericloveland", "id": 26264595, "node_id": "MDQ6VXNlcjI2MjY0NTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/26264595?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ericloveland", "html_url": "https://github.com/ericloveland", "followers_url": "https://api.github.com/users/ericloveland/followers", "following_url": "https://api.github.com/users/ericloveland/following{/other_user}", "gists_url": "https://api.github.com/users/ericloveland/gists{/gist_id}", "starred_url": "https://api.github.com/users/ericloveland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ericloveland/subscriptions", "organizations_url": "https://api.github.com/users/ericloveland/orgs", "repos_url": "https://api.github.com/users/ericloveland/repos", "events_url": "https://api.github.com/users/ericloveland/events{/privacy}", "received_events_url": "https://api.github.com/users/ericloveland/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-08T02:04:58Z", "updated_at": "2017-03-08T02:04:58Z", "author_association": "NONE", "body_html": "<p>I have been trying to find the largest models my box will run (neural_gpu) given that my box has 128gb ram and 3x 1080 gpu's, but tensorflow seems to run out of memory arbitrarily when it is only using about 71.5gb (minus a bit for the OS)... the dumps say that the total allocs = 64gb, so I wonder if it is self limiting to 64gb somewhere... when I built tensorflow and the box it only had 64gb... swap stays at zero... would rebuilding tensor flow help or is there a setting that could increase this?</p>", "body_text": "I have been trying to find the largest models my box will run (neural_gpu) given that my box has 128gb ram and 3x 1080 gpu's, but tensorflow seems to run out of memory arbitrarily when it is only using about 71.5gb (minus a bit for the OS)... the dumps say that the total allocs = 64gb, so I wonder if it is self limiting to 64gb somewhere... when I built tensorflow and the box it only had 64gb... swap stays at zero... would rebuilding tensor flow help or is there a setting that could increase this?", "body": "I have been trying to find the largest models my box will run (neural_gpu) given that my box has 128gb ram and 3x 1080 gpu's, but tensorflow seems to run out of memory arbitrarily when it is only using about 71.5gb (minus a bit for the OS)... the dumps say that the total allocs = 64gb, so I wonder if it is self limiting to 64gb somewhere... when I built tensorflow and the box it only had 64gb... swap stays at zero... would rebuilding tensor flow help or is there a setting that could increase this?  "}