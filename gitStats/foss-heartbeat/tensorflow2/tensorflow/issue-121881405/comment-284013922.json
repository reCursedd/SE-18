{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/284013922", "html_url": "https://github.com/tensorflow/tensorflow/issues/492#issuecomment-284013922", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/492", "id": 284013922, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NDAxMzkyMg==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-03T17:16:55Z", "updated_at": "2017-03-03T17:16:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The memory is released as soon as soon as the tensor is not needed by downstream consumers. So it depends how your gradInput/gradOutputs are wired (ie, you can rewire them to be more memory efficient, like <a href=\"https://github.com/yaroslavvb/notebooks/blob/master/simple_rewiring.ipynb\">here</a>) .</p>\n<p>Even though TensorFlow releases memory right after it's needed, but there's nothing forcing TensorFlow to allocate memory right before it's needed. So TF could compute an op early and hold it's output in memory longer than necessary, which can increase peak memory. This greedy approach favors speed in multi-device setting over memory efficiency.</p>\n<p>In a single device setting, a simple heuristic of executing an op as late as possible saves memory without affecting computation speed, I use this utility to force TensorFlow to compute ops as late as possible -- <a href=\"https://github.com/yaroslavvb/stuff/blob/master/linearize\">https://github.com/yaroslavvb/stuff/blob/master/linearize</a></p>", "body_text": "The memory is released as soon as soon as the tensor is not needed by downstream consumers. So it depends how your gradInput/gradOutputs are wired (ie, you can rewire them to be more memory efficient, like here) .\nEven though TensorFlow releases memory right after it's needed, but there's nothing forcing TensorFlow to allocate memory right before it's needed. So TF could compute an op early and hold it's output in memory longer than necessary, which can increase peak memory. This greedy approach favors speed in multi-device setting over memory efficiency.\nIn a single device setting, a simple heuristic of executing an op as late as possible saves memory without affecting computation speed, I use this utility to force TensorFlow to compute ops as late as possible -- https://github.com/yaroslavvb/stuff/blob/master/linearize", "body": "The memory is released as soon as soon as the tensor is not needed by downstream consumers. So it depends how your gradInput/gradOutputs are wired (ie, you can rewire them to be more memory efficient, like [here](https://github.com/yaroslavvb/notebooks/blob/master/simple_rewiring.ipynb)) . \r\n\r\nEven though TensorFlow releases memory right after it's needed, but there's nothing forcing TensorFlow to allocate memory right before it's needed. So TF could compute an op early and hold it's output in memory longer than necessary, which can increase peak memory. This greedy approach favors speed in multi-device setting over memory efficiency.\r\n\r\nIn a single device setting, a simple heuristic of executing an op as late as possible saves memory without affecting computation speed, I use this utility to force TensorFlow to compute ops as late as possible -- https://github.com/yaroslavvb/stuff/blob/master/linearize"}