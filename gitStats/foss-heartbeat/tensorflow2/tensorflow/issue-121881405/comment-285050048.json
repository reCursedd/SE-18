{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285050048", "html_url": "https://github.com/tensorflow/tensorflow/issues/492#issuecomment-285050048", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/492", "id": 285050048, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTA1MDA0OA==", "user": {"login": "belavenir", "id": 12731312, "node_id": "MDQ6VXNlcjEyNzMxMzEy", "avatar_url": "https://avatars0.githubusercontent.com/u/12731312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/belavenir", "html_url": "https://github.com/belavenir", "followers_url": "https://api.github.com/users/belavenir/followers", "following_url": "https://api.github.com/users/belavenir/following{/other_user}", "gists_url": "https://api.github.com/users/belavenir/gists{/gist_id}", "starred_url": "https://api.github.com/users/belavenir/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/belavenir/subscriptions", "organizations_url": "https://api.github.com/users/belavenir/orgs", "repos_url": "https://api.github.com/users/belavenir/repos", "events_url": "https://api.github.com/users/belavenir/events{/privacy}", "received_events_url": "https://api.github.com/users/belavenir/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-08T14:10:02Z", "updated_at": "2017-03-08T14:10:02Z", "author_association": "NONE", "body_html": "<p>I also face memory thing when I train a transfer learning based model. I solve it by freezing some layers by pre-trained weights and fine tuning layer from layer. It works in this way.  But when I train the entire model, too many trainable parameters will still cause the OOM in AWS.</p>", "body_text": "I also face memory thing when I train a transfer learning based model. I solve it by freezing some layers by pre-trained weights and fine tuning layer from layer. It works in this way.  But when I train the entire model, too many trainable parameters will still cause the OOM in AWS.", "body": "I also face memory thing when I train a transfer learning based model. I solve it by freezing some layers by pre-trained weights and fine tuning layer from layer. It works in this way.  But when I train the entire model, too many trainable parameters will still cause the OOM in AWS."}