{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22577", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22577/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22577/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22577/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22577", "id": 364704216, "node_id": "MDU6SXNzdWUzNjQ3MDQyMTY=", "number": 22577, "title": "[Bug] TensorRT conversion error", "user": {"login": "mike199515", "id": 6950999, "node_id": "MDQ6VXNlcjY5NTA5OTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/6950999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mike199515", "html_url": "https://github.com/mike199515", "followers_url": "https://api.github.com/users/mike199515/followers", "following_url": "https://api.github.com/users/mike199515/following{/other_user}", "gists_url": "https://api.github.com/users/mike199515/gists{/gist_id}", "starred_url": "https://api.github.com/users/mike199515/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mike199515/subscriptions", "organizations_url": "https://api.github.com/users/mike199515/orgs", "repos_url": "https://api.github.com/users/mike199515/repos", "events_url": "https://api.github.com/users/mike199515/events{/privacy}", "received_events_url": "https://api.github.com/users/mike199515/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-09-28T01:04:27Z", "updated_at": "2018-11-02T21:00:57Z", "closed_at": "2018-10-16T22:43:02Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:No</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.11.0 dev build from dockerhub, last commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/c19e29306ce1777456b2dbb3a14f511edf7883a8/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/c19e29306ce1777456b2dbb3a14f511edf7883a8\"><tt>c19e293</tt></a></li>\n<li><strong>Python version</strong>:2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:0.15.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7.0.5</li>\n<li><strong>GPU model and memory</strong>: GTX 1080 with 8G memory</li>\n<li><strong>Exact command to reproduce</strong>: python minimal_graph.py</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Met with another conversion error when using latest tensorRT conversion pipeline. After localization of the problem, it seems that the problem is caused by NHWC -&gt; NCHW conversion: If we have a constant of shape (C) (usually bias add term) added after the convolution, after the NHWC -&gt; NCHW conversion, we should expect it to be of shape (C, 1, 1) in order to be broadcast-able, yet current pipeline failed to do so.<br>\nMy guess may be incorrect, hopefully this would be helpful though.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=31743510\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aaroey\">@aaroey</a></p>\n<h3>Source code / logs</h3>\n<p>Test case:</p>\n<pre><code> import numpy as np\n import tensorflow as tf\n from tensorflow.contrib import tensorrt as trt\n \n def build_graph_from_def(graph_def, input_nodes, output_nodes):\n     \"\"\"\n     build the actual graph from definition\n     \"\"\"\n     tf.reset_default_graph()\n     graph = tf.Graph()\n     with graph.as_default():\n         return_tensors = [operation_name + \":0\" for operation_name in input_nodes + output_nodes]\n         tensors = tf.import_graph_def(graph_def=graph_def, name=\"\",\n                                       return_elements=return_tensors)\n         input_tensor_list = tensors[:len(input_nodes)]\n         output_tensor_list = tensors[len(input_nodes):]\n \n     return graph, input_tensor_list, output_tensor_list\n \n \n def main():\n \n     with tf.variable_scope(\"Net\"):\n         inp = tf.placeholder(tf.float32, shape=(1, 32, 32, 3), name=\"input_image\")\n         weight = tf.zeros([3,3,3,8] ,tf.float32)\n         conv = tf.nn.conv2d(inp, weight, strides=[1,1,1,1], padding=\"SAME\")\n         bn = conv + tf.ones((8,), tf.float32, name=\"add\")\n         bn = tf.nn.relu(bn, name=\"output\")\n \n     input_nodes = [\"Net/input_image\"]\n     output_nodes = [\"Net/output\"]\n \n     with tf.Session() as sess:\n         sess.run(tf.global_variables_initializer())\n         const_graph_def = tf.graph_util.convert_variables_to_constants(\n             sess, sess.graph.as_graph_def(), output_nodes)\n \n     optimized_graph_def = trt.create_inference_graph(\n         input_graph_def=const_graph_def,\n         outputs=output_nodes,\n         max_batch_size=1,\n         max_workspace_size_bytes=1 &lt;&lt; 25)\n     graph, input_tensors, output_tensors = build_graph_from_def(\n         optimized_graph_def, input_nodes, output_nodes)\n \n     with tf.Session(graph=graph) as sess:\n         output_value = sess.run(output_tensors[0], feed_dict={input_tensors[0]: np.zeros((1, 32,    32, 3))})\n     print(\"output:{}\".format(output_value.shape))\n \n if __name__ == \"__main__\":\n     main()\n</code></pre>\n<p>Sample Output:</p>\n<pre><code>$ python minimal_graph2.py\n2018-09-27 17:44:41.357261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-09-27 17:44:41.357805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\npciBusID: 0000:01:00.0\ntotalMemory: 7.92GiB freeMemory: 5.67GiB\n2018-09-27 17:44:41.357817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-09-27 17:44:41.632033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-09-27 17:44:41.632053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-09-27 17:44:41.632058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-09-27 17:44:41.632205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5419 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-09-27 17:44:41.689349: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count &gt;= 8): 1\n2018-09-27 17:44:41.689390: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\n2018-09-27 17:44:41.689539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-09-27 17:44:41.689552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-09-27 17:44:41.689557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-09-27 17:44:41.689562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-09-27 17:44:41.689643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5419 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-09-27 17:44:41.693257: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'Net/', converted to graph\n2018-09-27 17:44:41.693268: E tensorflow/contrib/tensorrt/convert/convert_graph.cc:418] Can't find a device placement for the op!\npython: customWinogradConvActLayer.cpp:48: nvinfer1::cudnn::WinogradConvActLayer::WinogradConvActLayer(const string&amp;, const EngineTensors&amp;, const EngineTensors&amp;, const nvinfer1::ConvolutionParameters&amp;, bool, const std::vector&lt;float&gt;&amp;): Assertion `matchNbDims(inputs[0], outputs[0]) &amp;&amp; (inputs.size() == 1 || inputs[1].extent == outputs[0].extent)' failed.\n[1]    28090 abort (core dumped)  python minimal_graph2.py\n\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\nTensorFlow installed from (source or binary):source\nTensorFlow version (use command below): 1.11.0 dev build from dockerhub, last commit c19e293\nPython version:2.7\nBazel version (if compiling from source):0.15.0\nGCC/Compiler version (if compiling from source):5.4.0\nCUDA/cuDNN version: 9.0/7.0.5\nGPU model and memory: GTX 1080 with 8G memory\nExact command to reproduce: python minimal_graph.py\n\nDescribe the problem\nMet with another conversion error when using latest tensorRT conversion pipeline. After localization of the problem, it seems that the problem is caused by NHWC -> NCHW conversion: If we have a constant of shape (C) (usually bias add term) added after the convolution, after the NHWC -> NCHW conversion, we should expect it to be of shape (C, 1, 1) in order to be broadcast-able, yet current pipeline failed to do so.\nMy guess may be incorrect, hopefully this would be helpful though.\n@aaroey\nSource code / logs\nTest case:\n import numpy as np\n import tensorflow as tf\n from tensorflow.contrib import tensorrt as trt\n \n def build_graph_from_def(graph_def, input_nodes, output_nodes):\n     \"\"\"\n     build the actual graph from definition\n     \"\"\"\n     tf.reset_default_graph()\n     graph = tf.Graph()\n     with graph.as_default():\n         return_tensors = [operation_name + \":0\" for operation_name in input_nodes + output_nodes]\n         tensors = tf.import_graph_def(graph_def=graph_def, name=\"\",\n                                       return_elements=return_tensors)\n         input_tensor_list = tensors[:len(input_nodes)]\n         output_tensor_list = tensors[len(input_nodes):]\n \n     return graph, input_tensor_list, output_tensor_list\n \n \n def main():\n \n     with tf.variable_scope(\"Net\"):\n         inp = tf.placeholder(tf.float32, shape=(1, 32, 32, 3), name=\"input_image\")\n         weight = tf.zeros([3,3,3,8] ,tf.float32)\n         conv = tf.nn.conv2d(inp, weight, strides=[1,1,1,1], padding=\"SAME\")\n         bn = conv + tf.ones((8,), tf.float32, name=\"add\")\n         bn = tf.nn.relu(bn, name=\"output\")\n \n     input_nodes = [\"Net/input_image\"]\n     output_nodes = [\"Net/output\"]\n \n     with tf.Session() as sess:\n         sess.run(tf.global_variables_initializer())\n         const_graph_def = tf.graph_util.convert_variables_to_constants(\n             sess, sess.graph.as_graph_def(), output_nodes)\n \n     optimized_graph_def = trt.create_inference_graph(\n         input_graph_def=const_graph_def,\n         outputs=output_nodes,\n         max_batch_size=1,\n         max_workspace_size_bytes=1 << 25)\n     graph, input_tensors, output_tensors = build_graph_from_def(\n         optimized_graph_def, input_nodes, output_nodes)\n \n     with tf.Session(graph=graph) as sess:\n         output_value = sess.run(output_tensors[0], feed_dict={input_tensors[0]: np.zeros((1, 32,    32, 3))})\n     print(\"output:{}\".format(output_value.shape))\n \n if __name__ == \"__main__\":\n     main()\n\nSample Output:\n$ python minimal_graph2.py\n2018-09-27 17:44:41.357261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-09-27 17:44:41.357805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\npciBusID: 0000:01:00.0\ntotalMemory: 7.92GiB freeMemory: 5.67GiB\n2018-09-27 17:44:41.357817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-09-27 17:44:41.632033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-09-27 17:44:41.632053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-09-27 17:44:41.632058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-09-27 17:44:41.632205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5419 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-09-27 17:44:41.689349: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 1\n2018-09-27 17:44:41.689390: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\n2018-09-27 17:44:41.689539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-09-27 17:44:41.689552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-09-27 17:44:41.689557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-09-27 17:44:41.689562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-09-27 17:44:41.689643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5419 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-09-27 17:44:41.693257: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'Net/', converted to graph\n2018-09-27 17:44:41.693268: E tensorflow/contrib/tensorrt/convert/convert_graph.cc:418] Can't find a device placement for the op!\npython: customWinogradConvActLayer.cpp:48: nvinfer1::cudnn::WinogradConvActLayer::WinogradConvActLayer(const string&, const EngineTensors&, const EngineTensors&, const nvinfer1::ConvolutionParameters&, bool, const std::vector<float>&): Assertion `matchNbDims(inputs[0], outputs[0]) && (inputs.size() == 1 || inputs[1].extent == outputs[0].extent)' failed.\n[1]    28090 abort (core dumped)  python minimal_graph2.py", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:No\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**: 1.11.0 dev build from dockerhub, last commit c19e29306ce1777456b2dbb3a14f511edf7883a8\r\n- **Python version**:2.7\r\n- **Bazel version (if compiling from source)**:0.15.0\r\n- **GCC/Compiler version (if compiling from source)**:5.4.0\r\n- **CUDA/cuDNN version**: 9.0/7.0.5\r\n- **GPU model and memory**: GTX 1080 with 8G memory\r\n- **Exact command to reproduce**: python minimal_graph.py \r\n\r\n### Describe the problem\r\nMet with another conversion error when using latest tensorRT conversion pipeline. After localization of the problem, it seems that the problem is caused by NHWC -> NCHW conversion: If we have a constant of shape (C) (usually bias add term) added after the convolution, after the NHWC -> NCHW conversion, we should expect it to be of shape (C, 1, 1) in order to be broadcast-able, yet current pipeline failed to do so.\r\nMy guess may be incorrect, hopefully this would be helpful though.\r\n\r\n@aaroey \r\n\r\n### Source code / logs\r\nTest case:\r\n```\r\n import numpy as np\r\n import tensorflow as tf\r\n from tensorflow.contrib import tensorrt as trt\r\n \r\n def build_graph_from_def(graph_def, input_nodes, output_nodes):\r\n     \"\"\"\r\n     build the actual graph from definition\r\n     \"\"\"\r\n     tf.reset_default_graph()\r\n     graph = tf.Graph()\r\n     with graph.as_default():\r\n         return_tensors = [operation_name + \":0\" for operation_name in input_nodes + output_nodes]\r\n         tensors = tf.import_graph_def(graph_def=graph_def, name=\"\",\r\n                                       return_elements=return_tensors)\r\n         input_tensor_list = tensors[:len(input_nodes)]\r\n         output_tensor_list = tensors[len(input_nodes):]\r\n \r\n     return graph, input_tensor_list, output_tensor_list\r\n \r\n \r\n def main():\r\n \r\n     with tf.variable_scope(\"Net\"):\r\n         inp = tf.placeholder(tf.float32, shape=(1, 32, 32, 3), name=\"input_image\")\r\n         weight = tf.zeros([3,3,3,8] ,tf.float32)\r\n         conv = tf.nn.conv2d(inp, weight, strides=[1,1,1,1], padding=\"SAME\")\r\n         bn = conv + tf.ones((8,), tf.float32, name=\"add\")\r\n         bn = tf.nn.relu(bn, name=\"output\")\r\n \r\n     input_nodes = [\"Net/input_image\"]\r\n     output_nodes = [\"Net/output\"]\r\n \r\n     with tf.Session() as sess:\r\n         sess.run(tf.global_variables_initializer())\r\n         const_graph_def = tf.graph_util.convert_variables_to_constants(\r\n             sess, sess.graph.as_graph_def(), output_nodes)\r\n \r\n     optimized_graph_def = trt.create_inference_graph(\r\n         input_graph_def=const_graph_def,\r\n         outputs=output_nodes,\r\n         max_batch_size=1,\r\n         max_workspace_size_bytes=1 << 25)\r\n     graph, input_tensors, output_tensors = build_graph_from_def(\r\n         optimized_graph_def, input_nodes, output_nodes)\r\n \r\n     with tf.Session(graph=graph) as sess:\r\n         output_value = sess.run(output_tensors[0], feed_dict={input_tensors[0]: np.zeros((1, 32,    32, 3))})\r\n     print(\"output:{}\".format(output_value.shape))\r\n \r\n if __name__ == \"__main__\":\r\n     main()\r\n```\r\nSample Output:\r\n```\r\n$ python minimal_graph2.py\r\n2018-09-27 17:44:41.357261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-09-27 17:44:41.357805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.92GiB freeMemory: 5.67GiB\r\n2018-09-27 17:44:41.357817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-09-27 17:44:41.632033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-27 17:44:41.632053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-09-27 17:44:41.632058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-09-27 17:44:41.632205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5419 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-09-27 17:44:41.689349: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 1\r\n2018-09-27 17:44:41.689390: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2018-09-27 17:44:41.689539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-09-27 17:44:41.689552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-27 17:44:41.689557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-09-27 17:44:41.689562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-09-27 17:44:41.689643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5419 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-09-27 17:44:41.693257: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'Net/', converted to graph\r\n2018-09-27 17:44:41.693268: E tensorflow/contrib/tensorrt/convert/convert_graph.cc:418] Can't find a device placement for the op!\r\npython: customWinogradConvActLayer.cpp:48: nvinfer1::cudnn::WinogradConvActLayer::WinogradConvActLayer(const string&, const EngineTensors&, const EngineTensors&, const nvinfer1::ConvolutionParameters&, bool, const std::vector<float>&): Assertion `matchNbDims(inputs[0], outputs[0]) && (inputs.size() == 1 || inputs[1].extent == outputs[0].extent)' failed.\r\n[1]    28090 abort (core dumped)  python minimal_graph2.py\r\n\r\n```\r\n"}