{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5280", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5280/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5280/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5280/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5280", "id": 186107966, "node_id": "MDU6SXNzdWUxODYxMDc5NjY=", "number": 5280, "title": "Ubuntu 16.04 - GPU-enabled binary for Python3.5 in Anaconda - NVidia Compute Capability 2.1 GPU not detected", "user": {"login": "paulwasit", "id": 11413829, "node_id": "MDQ6VXNlcjExNDEzODI5", "avatar_url": "https://avatars0.githubusercontent.com/u/11413829?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulwasit", "html_url": "https://github.com/paulwasit", "followers_url": "https://api.github.com/users/paulwasit/followers", "following_url": "https://api.github.com/users/paulwasit/following{/other_user}", "gists_url": "https://api.github.com/users/paulwasit/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulwasit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulwasit/subscriptions", "organizations_url": "https://api.github.com/users/paulwasit/orgs", "repos_url": "https://api.github.com/users/paulwasit/repos", "events_url": "https://api.github.com/users/paulwasit/events{/privacy}", "received_events_url": "https://api.github.com/users/paulwasit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-10-29T23:55:40Z", "updated_at": "2016-10-30T00:31:13Z", "closed_at": "2016-10-30T00:30:32Z", "author_association": "NONE", "body_html": "<h3>Issue</h3>\n<p>I have an old GPU (GTX 560 Ti) with a power compute of 2.1, according to the Nvidia website.</p>\n<p>I am using Anaconda3 on Ubuntu, and I used the following binary to install Tensorflow:</p>\n<pre><code>export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl\n</code></pre>\n<p>Tensorflow is running, but trying the <a href=\"https://www.tensorflow.org/versions/r0.11/how_tos/using_gpu/index.html\" rel=\"nofollow\">Tensorflow.org test about using GPUs</a>, I get this output:</p>\n<pre><code>Device mapping: no known devices.\nI tensorflow/core/common_runtime/direct_session.cc:252] Device mapping:\n\nMatMul_5: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/cpu:0\n</code></pre>\n<p>Trying a manual device placement using <code>with tf.device('/gpu:0'):</code>, I get</p>\n<pre><code>InvalidArgumentError: Cannot assign a device to node 'MatMul_4': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n     [[Node: MatMul_4 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_4, b_4)]]\n</code></pre>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>I found this [https://github.com/<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116982674\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/227\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/227/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/227\">/issues/227</a>](old issue): Compute capability &lt; 3.5. The OP had the same GPU, but it was for a build from source.</p>\n<h3>Environment info</h3>\n<p>Operating System: <strong>Ubuntu 16.04</strong></p>\n<p>Installed version of CUDA and cuDNN: <strong>8.0.27 + 5.1.5</strong><br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<pre><code>-rw-r--r-- 1 root root   560184 Okt 29 20:06 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Okt 29 20:06 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Okt 29 20:06 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn_static.a\n</code></pre>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:</li>\n</ol>\n<pre><code>export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl\n</code></pre>\n<ol>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<pre><code>0.11.0rc1\n</code></pre>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>I tried the example in the test from the link above:</p>\n<pre><code># Creates a graph.\nwith tf.device('/gpu:0'):\n  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  c = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint sess.run(c)\n</code></pre>", "body_text": "Issue\nI have an old GPU (GTX 560 Ti) with a power compute of 2.1, according to the Nvidia website.\nI am using Anaconda3 on Ubuntu, and I used the following binary to install Tensorflow:\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl\n\nTensorflow is running, but trying the Tensorflow.org test about using GPUs, I get this output:\nDevice mapping: no known devices.\nI tensorflow/core/common_runtime/direct_session.cc:252] Device mapping:\n\nMatMul_5: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/cpu:0\n\nTrying a manual device placement using with tf.device('/gpu:0'):, I get\nInvalidArgumentError: Cannot assign a device to node 'MatMul_4': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n     [[Node: MatMul_4 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_4, b_4)]]\n\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nI found this [https://github.com//issues/227](old issue): Compute capability < 3.5. The OP had the same GPU, but it was for a build from source.\nEnvironment info\nOperating System: Ubuntu 16.04\nInstalled version of CUDA and cuDNN: 8.0.27 + 5.1.5\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n-rw-r--r-- 1 root root   560184 Okt 29 20:06 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Okt 29 20:06 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Okt 29 20:06 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\n\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl\n\n\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\n0.11.0rc1\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nI tried the example in the test from the link above:\n# Creates a graph.\nwith tf.device('/gpu:0'):\n  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  c = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint sess.run(c)", "body": "### Issue\n\nI have an old GPU (GTX 560 Ti) with a power compute of 2.1, according to the Nvidia website. \n\nI am using Anaconda3 on Ubuntu, and I used the following binary to install Tensorflow:\n\n```\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl\n```\n\nTensorflow is running, but trying the [Tensorflow.org test about using GPUs](https://www.tensorflow.org/versions/r0.11/how_tos/using_gpu/index.html), I get this output:\n\n```\nDevice mapping: no known devices.\nI tensorflow/core/common_runtime/direct_session.cc:252] Device mapping:\n\nMatMul_5: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/cpu:0\n```\n\nTrying a manual device placement using `with tf.device('/gpu:0'):`, I get \n\n```\nInvalidArgumentError: Cannot assign a device to node 'MatMul_4': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n     [[Node: MatMul_4 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_4, b_4)]]\n```\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nI found this [https://github.com/tensorflow/tensorflow/issues/227](old issue): Compute capability < 3.5. The OP had the same GPU, but it was for a build from source.\n### Environment info\n\nOperating System: **Ubuntu 16.04**\n\nInstalled version of CUDA and cuDNN: **8.0.27 + 5.1.5**\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\n-rw-r--r-- 1 root root   560184 Okt 29 20:06 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Okt 29 20:06 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Okt 29 20:06 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn_static.a\n```\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n\n```\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl\n```\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\n0.11.0rc1\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nI tried the example in the test from the link above:\n\n```\n# Creates a graph.\nwith tf.device('/gpu:0'):\n  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  c = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint sess.run(c)\n```\n"}