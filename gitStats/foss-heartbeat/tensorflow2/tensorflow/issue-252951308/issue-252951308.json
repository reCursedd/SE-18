{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12601", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12601/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12601/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12601/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12601", "id": 252951308, "node_id": "MDU6SXNzdWUyNTI5NTEzMDg=", "number": 12601, "title": "Produce mask when padding batches", "user": {"login": "rightaditya", "id": 1624945, "node_id": "MDQ6VXNlcjE2MjQ5NDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1624945?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rightaditya", "html_url": "https://github.com/rightaditya", "followers_url": "https://api.github.com/users/rightaditya/followers", "following_url": "https://api.github.com/users/rightaditya/following{/other_user}", "gists_url": "https://api.github.com/users/rightaditya/gists{/gist_id}", "starred_url": "https://api.github.com/users/rightaditya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rightaditya/subscriptions", "organizations_url": "https://api.github.com/users/rightaditya/orgs", "repos_url": "https://api.github.com/users/rightaditya/repos", "events_url": "https://api.github.com/users/rightaditya/events{/privacy}", "received_events_url": "https://api.github.com/users/rightaditya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-08-25T16:18:01Z", "updated_at": "2017-12-01T07:07:27Z", "closed_at": "2017-12-01T07:04:35Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 17.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary via pip</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.3.0-rc2-20-g0787eee 1.3.0</li>\n<li><strong>Python version</strong>: 3.5.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: See source code below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Currently, the Dataset API (as well as the older queue-based API) allows for batches to be padded, but there is no way to determine which values were inserted for padding in the resulting output tensors unless care is taken to pick a padding value that will never occur in the original dataset. It would be useful if this could be indicated via a separate mask tensor that indicates this rather than having the user compute it manually (if it's even possible for their particular data). E.g., this is useful for sequential tagging (like part-of-speech tagging), where each example is a multi-word sentence and each label is actually a sequence of labels. Computing the correct losses requires knowledge of which values were just included for padding.</p>\n<p>Currently, I do this using Fuel, which, for a given batch, gives me one array for the input data, one for the label, and then one mask each for the input and the label. The masks are binary and of the same shape as the input/label array, respectively. I then feed these into TensorFlow via the feed_dict mechanism.</p>\n<p>Here's an example from the programmer's guide:</p>\n<pre><code>dataset = tf.contrib.data.Dataset.range(100)\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\ndataset = dataset.padded_batch(4, padded_shapes=[None])\n\niterator = dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\n\nprint(sess.run(next_element))  # ==&gt; [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]\nprint(sess.run(next_element))  # ==&gt; [[4, 4, 4, 4, 0, 0, 0],\n                               #      [5, 5, 5, 5, 5, 0, 0],\n                               #      [6, 6, 6, 6, 6, 6, 0],\n                               #      [7, 7, 7, 7, 7, 7, 7]]\n</code></pre>\n<p>With a mask, this might look like:</p>\n<pre><code>dataset = tf.contrib.data.Dataset.range(100)\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\ndataset = dataset.padded_batch(4, padded_shapes=[None], mask=True)\n\niterator = dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\n\nprint(sess.run(next_element))  # ==&gt; ([[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]],\n                               #      [[0, 0, 0], [1, 0, 0], [1, 1, 0], [1, 1, 1]])\nprint(sess.run(next_element))  # ==&gt; ([[4, 4, 4, 4, 0, 0, 0],\n                               #       [5, 5, 5, 5, 5, 0, 0],\n                               #       [6, 6, 6, 6, 6, 6, 0],\n                               #       [7, 7, 7, 7, 7, 7, 7]],\n                               #      [[1, 1, 1, 1, 0, 0, 0],\n                               #       [1, 1, 1, 1, 1, 0, 0],\n                               #       [1, 1, 1, 1, 1, 1, 0],\n                               #       [1, 1, 1, 1, 1, 1, 1]])\n</code></pre>\n<p>(Obviously, this particular example is simple to compute manually, but imagine the case where there is no obvious padding value to pick that wouldn't occur in the data.)</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 17.04\nTensorFlow installed from (source or binary): binary via pip\nTensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0\nPython version: 3.5.3\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: See source code below\n\nDescribe the problem\nCurrently, the Dataset API (as well as the older queue-based API) allows for batches to be padded, but there is no way to determine which values were inserted for padding in the resulting output tensors unless care is taken to pick a padding value that will never occur in the original dataset. It would be useful if this could be indicated via a separate mask tensor that indicates this rather than having the user compute it manually (if it's even possible for their particular data). E.g., this is useful for sequential tagging (like part-of-speech tagging), where each example is a multi-word sentence and each label is actually a sequence of labels. Computing the correct losses requires knowledge of which values were just included for padding.\nCurrently, I do this using Fuel, which, for a given batch, gives me one array for the input data, one for the label, and then one mask each for the input and the label. The masks are binary and of the same shape as the input/label array, respectively. I then feed these into TensorFlow via the feed_dict mechanism.\nHere's an example from the programmer's guide:\ndataset = tf.contrib.data.Dataset.range(100)\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\ndataset = dataset.padded_batch(4, padded_shapes=[None])\n\niterator = dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\n\nprint(sess.run(next_element))  # ==> [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]\nprint(sess.run(next_element))  # ==> [[4, 4, 4, 4, 0, 0, 0],\n                               #      [5, 5, 5, 5, 5, 0, 0],\n                               #      [6, 6, 6, 6, 6, 6, 0],\n                               #      [7, 7, 7, 7, 7, 7, 7]]\n\nWith a mask, this might look like:\ndataset = tf.contrib.data.Dataset.range(100)\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\ndataset = dataset.padded_batch(4, padded_shapes=[None], mask=True)\n\niterator = dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\n\nprint(sess.run(next_element))  # ==> ([[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]],\n                               #      [[0, 0, 0], [1, 0, 0], [1, 1, 0], [1, 1, 1]])\nprint(sess.run(next_element))  # ==> ([[4, 4, 4, 4, 0, 0, 0],\n                               #       [5, 5, 5, 5, 5, 0, 0],\n                               #       [6, 6, 6, 6, 6, 6, 0],\n                               #       [7, 7, 7, 7, 7, 7, 7]],\n                               #      [[1, 1, 1, 1, 0, 0, 0],\n                               #       [1, 1, 1, 1, 1, 0, 0],\n                               #       [1, 1, 1, 1, 1, 1, 0],\n                               #       [1, 1, 1, 1, 1, 1, 1]])\n\n(Obviously, this particular example is simple to compute manually, but imagine the case where there is no obvious padding value to pick that wouldn't occur in the data.)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.04\r\n- **TensorFlow installed from (source or binary)**: binary via pip\r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: 3.5.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See source code below\r\n\r\n### Describe the problem\r\nCurrently, the Dataset API (as well as the older queue-based API) allows for batches to be padded, but there is no way to determine which values were inserted for padding in the resulting output tensors unless care is taken to pick a padding value that will never occur in the original dataset. It would be useful if this could be indicated via a separate mask tensor that indicates this rather than having the user compute it manually (if it's even possible for their particular data). E.g., this is useful for sequential tagging (like part-of-speech tagging), where each example is a multi-word sentence and each label is actually a sequence of labels. Computing the correct losses requires knowledge of which values were just included for padding.\r\n\r\nCurrently, I do this using Fuel, which, for a given batch, gives me one array for the input data, one for the label, and then one mask each for the input and the label. The masks are binary and of the same shape as the input/label array, respectively. I then feed these into TensorFlow via the feed_dict mechanism.\r\n\r\nHere's an example from the programmer's guide:\r\n```\r\ndataset = tf.contrib.data.Dataset.range(100)\r\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\r\ndataset = dataset.padded_batch(4, padded_shapes=[None])\r\n\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\nprint(sess.run(next_element))  # ==> [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]\r\nprint(sess.run(next_element))  # ==> [[4, 4, 4, 4, 0, 0, 0],\r\n                               #      [5, 5, 5, 5, 5, 0, 0],\r\n                               #      [6, 6, 6, 6, 6, 6, 0],\r\n                               #      [7, 7, 7, 7, 7, 7, 7]]\r\n```\r\nWith a mask, this might look like:\r\n```\r\ndataset = tf.contrib.data.Dataset.range(100)\r\ndataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\r\ndataset = dataset.padded_batch(4, padded_shapes=[None], mask=True)\r\n\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\nprint(sess.run(next_element))  # ==> ([[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]],\r\n                               #      [[0, 0, 0], [1, 0, 0], [1, 1, 0], [1, 1, 1]])\r\nprint(sess.run(next_element))  # ==> ([[4, 4, 4, 4, 0, 0, 0],\r\n                               #       [5, 5, 5, 5, 5, 0, 0],\r\n                               #       [6, 6, 6, 6, 6, 6, 0],\r\n                               #       [7, 7, 7, 7, 7, 7, 7]],\r\n                               #      [[1, 1, 1, 1, 0, 0, 0],\r\n                               #       [1, 1, 1, 1, 1, 0, 0],\r\n                               #       [1, 1, 1, 1, 1, 1, 0],\r\n                               #       [1, 1, 1, 1, 1, 1, 1]])\r\n```\r\n\r\n(Obviously, this particular example is simple to compute manually, but imagine the case where there is no obvious padding value to pick that wouldn't occur in the data.)"}