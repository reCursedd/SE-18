{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385703030", "html_url": "https://github.com/tensorflow/tensorflow/issues/15636#issuecomment-385703030", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15636", "id": 385703030, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTcwMzAzMA==", "user": {"login": "tslater", "id": 449326, "node_id": "MDQ6VXNlcjQ0OTMyNg==", "avatar_url": "https://avatars0.githubusercontent.com/u/449326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tslater", "html_url": "https://github.com/tslater", "followers_url": "https://api.github.com/users/tslater/followers", "following_url": "https://api.github.com/users/tslater/following{/other_user}", "gists_url": "https://api.github.com/users/tslater/gists{/gist_id}", "starred_url": "https://api.github.com/users/tslater/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tslater/subscriptions", "organizations_url": "https://api.github.com/users/tslater/orgs", "repos_url": "https://api.github.com/users/tslater/repos", "events_url": "https://api.github.com/users/tslater/events{/privacy}", "received_events_url": "https://api.github.com/users/tslater/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-01T15:40:27Z", "updated_at": "2018-05-01T15:40:27Z", "author_association": "NONE", "body_html": "<p>I figured it out. The example is quantized...but I'm using floats. Here's how I changed it to work.</p>\n<pre><code>    \n    int input = interpreter-&gt;inputs()[0];\n    \n\n    \n    auto* out = interpreter-&gt;typed_tensor&lt;float&gt;(input);\n    for (int y = 0; y &lt; wanted_input_height; ++y) {\n        auto* out_row = out + (y * wanted_input_width * wanted_input_channels);\n        for (int x = 0; x &lt; wanted_input_width; ++x) {\n            const int in_x = (y * image_width) / wanted_input_width;\n            const int in_y = (x * image_height) / wanted_input_height;\n            auto* in_pixel = in + (in_y * image_width * image_channels) + (in_x * image_channels);\n            auto* out_pixel = out_row + (x * wanted_input_channels);\n            for (int c = 0; c &lt; wanted_input_channels; ++c) {\n                out_pixel[c] = in_pixel[c];\n            }\n        }\n    }\n    \n    double startTimestamp = [[NSDate new] timeIntervalSince1970];\n    if (interpreter-&gt;Invoke() != kTfLiteOk) {\n        LOG(FATAL) &lt;&lt; \"Failed to invoke!\";\n    }\n    double endTimestamp = [[NSDate new] timeIntervalSince1970];\n    total_latency += (endTimestamp - startTimestamp);\n    total_count += 1;\n    NSLog(@\"Time: %.4lf, avg: %.4lf, count: %d\", endTimestamp - startTimestamp,\n          total_latency / total_count, total_count);\n    \n      const int output_size = 256;\n      const int kNumResults = 5;\n      const float kThreshold = 0.1f;\n    \n    std::vector&lt;std::pair&lt;float, int&gt;&gt; top_results;\n    \n    auto* output = interpreter-&gt;typed_output_tensor&lt;float&gt;(0);\n    \n    NSData *dataData = [NSData dataWithBytes:output length:sizeof(output)];\n    NSLog(@\"output %@\", dataData);\n</code></pre>", "body_text": "I figured it out. The example is quantized...but I'm using floats. Here's how I changed it to work.\n    \n    int input = interpreter->inputs()[0];\n    \n\n    \n    auto* out = interpreter->typed_tensor<float>(input);\n    for (int y = 0; y < wanted_input_height; ++y) {\n        auto* out_row = out + (y * wanted_input_width * wanted_input_channels);\n        for (int x = 0; x < wanted_input_width; ++x) {\n            const int in_x = (y * image_width) / wanted_input_width;\n            const int in_y = (x * image_height) / wanted_input_height;\n            auto* in_pixel = in + (in_y * image_width * image_channels) + (in_x * image_channels);\n            auto* out_pixel = out_row + (x * wanted_input_channels);\n            for (int c = 0; c < wanted_input_channels; ++c) {\n                out_pixel[c] = in_pixel[c];\n            }\n        }\n    }\n    \n    double startTimestamp = [[NSDate new] timeIntervalSince1970];\n    if (interpreter->Invoke() != kTfLiteOk) {\n        LOG(FATAL) << \"Failed to invoke!\";\n    }\n    double endTimestamp = [[NSDate new] timeIntervalSince1970];\n    total_latency += (endTimestamp - startTimestamp);\n    total_count += 1;\n    NSLog(@\"Time: %.4lf, avg: %.4lf, count: %d\", endTimestamp - startTimestamp,\n          total_latency / total_count, total_count);\n    \n      const int output_size = 256;\n      const int kNumResults = 5;\n      const float kThreshold = 0.1f;\n    \n    std::vector<std::pair<float, int>> top_results;\n    \n    auto* output = interpreter->typed_output_tensor<float>(0);\n    \n    NSData *dataData = [NSData dataWithBytes:output length:sizeof(output)];\n    NSLog(@\"output %@\", dataData);", "body": "I figured it out. The example is quantized...but I'm using floats. Here's how I changed it to work.\r\n```\r\n    \r\n    int input = interpreter->inputs()[0];\r\n    \r\n\r\n    \r\n    auto* out = interpreter->typed_tensor<float>(input);\r\n    for (int y = 0; y < wanted_input_height; ++y) {\r\n        auto* out_row = out + (y * wanted_input_width * wanted_input_channels);\r\n        for (int x = 0; x < wanted_input_width; ++x) {\r\n            const int in_x = (y * image_width) / wanted_input_width;\r\n            const int in_y = (x * image_height) / wanted_input_height;\r\n            auto* in_pixel = in + (in_y * image_width * image_channels) + (in_x * image_channels);\r\n            auto* out_pixel = out_row + (x * wanted_input_channels);\r\n            for (int c = 0; c < wanted_input_channels; ++c) {\r\n                out_pixel[c] = in_pixel[c];\r\n            }\r\n        }\r\n    }\r\n    \r\n    double startTimestamp = [[NSDate new] timeIntervalSince1970];\r\n    if (interpreter->Invoke() != kTfLiteOk) {\r\n        LOG(FATAL) << \"Failed to invoke!\";\r\n    }\r\n    double endTimestamp = [[NSDate new] timeIntervalSince1970];\r\n    total_latency += (endTimestamp - startTimestamp);\r\n    total_count += 1;\r\n    NSLog(@\"Time: %.4lf, avg: %.4lf, count: %d\", endTimestamp - startTimestamp,\r\n          total_latency / total_count, total_count);\r\n    \r\n      const int output_size = 256;\r\n      const int kNumResults = 5;\r\n      const float kThreshold = 0.1f;\r\n    \r\n    std::vector<std::pair<float, int>> top_results;\r\n    \r\n    auto* output = interpreter->typed_output_tensor<float>(0);\r\n    \r\n    NSData *dataData = [NSData dataWithBytes:output length:sizeof(output)];\r\n    NSLog(@\"output %@\", dataData);\r\n```"}