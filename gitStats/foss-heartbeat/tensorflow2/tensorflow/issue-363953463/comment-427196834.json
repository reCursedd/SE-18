{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/427196834", "html_url": "https://github.com/tensorflow/tensorflow/issues/22528#issuecomment-427196834", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22528", "id": 427196834, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNzE5NjgzNA==", "user": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-04T23:04:11Z", "updated_at": "2018-10-04T23:04:11Z", "author_association": "MEMBER", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21051830\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/johncf\">@johncf</a> , please use converter.post_training_quantize=True (formerly quantize_weights)</p>\n<p>Also, set your inference type to Float for post_training_quantize=True. This is because the edges in the graph are still float for this mode, but the weights are quantized and the kernels dynamically quantize inputs.</p>", "body_text": "Hi @johncf , please use converter.post_training_quantize=True (formerly quantize_weights)\nAlso, set your inference type to Float for post_training_quantize=True. This is because the edges in the graph are still float for this mode, but the weights are quantized and the kernels dynamically quantize inputs.", "body": "Hi @johncf , please use converter.post_training_quantize=True (formerly quantize_weights)\r\n\r\nAlso, set your inference type to Float for post_training_quantize=True. This is because the edges in the graph are still float for this mode, but the weights are quantized and the kernels dynamically quantize inputs."}