{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/346229137", "html_url": "https://github.com/tensorflow/tensorflow/issues/14535#issuecomment-346229137", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14535", "id": 346229137, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NjIyOTEzNw==", "user": {"login": "offbye", "id": 836403, "node_id": "MDQ6VXNlcjgzNjQwMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/836403?v=4", "gravatar_id": "", "url": "https://api.github.com/users/offbye", "html_url": "https://github.com/offbye", "followers_url": "https://api.github.com/users/offbye/followers", "following_url": "https://api.github.com/users/offbye/following{/other_user}", "gists_url": "https://api.github.com/users/offbye/gists{/gist_id}", "starred_url": "https://api.github.com/users/offbye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/offbye/subscriptions", "organizations_url": "https://api.github.com/users/offbye/orgs", "repos_url": "https://api.github.com/users/offbye/repos", "events_url": "https://api.github.com/users/offbye/events{/privacy}", "received_events_url": "https://api.github.com/users/offbye/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-22T03:00:57Z", "updated_at": "2017-11-22T03:16:14Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (Linux Ubuntu 14.04.5 LTS)</strong>:</li>\n<li><strong>TensorFlow installed from ( binary)</strong>:</li>\n<li>**TensorFlow version : 1.2.1</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li>**Bazel version : 0.70</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 4.8.4</li>\n<li>**CUDA/cuDNN version : 8.0</li>\n<li>**GPU model and memory: Tesla P100-PCIE</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I quantize the ssd_mobilenet_v1 model o ubuntu 14,  using the below command</p>\n<pre><code>bazel-bin/tensorflow/tools/graph_transforms/transform_graph \n--in_graph=/data5/zxt/coco_log/export/frozen_inference_graph.pb  \n--out_graph=/home/zxt/git/ssd_optimized.pb --inputs='image_tensor'\n --outputs='detection_boxes,detection_scores,num_detections,detection_classes' --transforms='\n  add_default_attributes\n  strip_unused_nodes(type=float, shape=\"-1,-1,-1,3\")\n  remove_nodes(op=Identity, op=CheckNumerics)\n  fold_batch_norms\n  fold_old_batch_norms\n  quantize_weights\n  strip_unused_nodes\n  sort_by_execution_order'\n</code></pre>\n<p>I also have tried some other parameters\uff0cbut all failed with same issue.<br>\nthe  frozen_inference_graph.pb   is ok on Android, but the quantized pb is can NOT load.<br>\nWhen run the quantized pb on android phone, met errors</p>\n<pre><code>      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:799)\n   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:689)\n    Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'T' not in Op&lt;name=Where; signature=input:bool -&gt; index:int64&gt;; \nNodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). \n(Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\n           at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:535)\n \n</code></pre>", "body_text": "System information\n\nOS Platform and Distribution (Linux Ubuntu 14.04.5 LTS):\nTensorFlow installed from ( binary):\n**TensorFlow version : 1.2.1\nPython version: 2.7\n**Bazel version : 0.70\nGCC/Compiler version (if compiling from source): 4.8.4\n**CUDA/cuDNN version : 8.0\n**GPU model and memory: Tesla P100-PCIE\nExact command to reproduce:\n\nDescribe the problem\nI quantize the ssd_mobilenet_v1 model o ubuntu 14,  using the below command\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \n--in_graph=/data5/zxt/coco_log/export/frozen_inference_graph.pb  \n--out_graph=/home/zxt/git/ssd_optimized.pb --inputs='image_tensor'\n --outputs='detection_boxes,detection_scores,num_detections,detection_classes' --transforms='\n  add_default_attributes\n  strip_unused_nodes(type=float, shape=\"-1,-1,-1,3\")\n  remove_nodes(op=Identity, op=CheckNumerics)\n  fold_batch_norms\n  fold_old_batch_norms\n  quantize_weights\n  strip_unused_nodes\n  sort_by_execution_order'\n\nI also have tried some other parameters\uff0cbut all failed with same issue.\nthe  frozen_inference_graph.pb   is ok on Android, but the quantized pb is can NOT load.\nWhen run the quantized pb on android phone, met errors\n      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:799)\n   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:689)\n    Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; \nNodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). \n(Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\n           at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:535)", "body": "### System information\r\n- **OS Platform and Distribution (Linux Ubuntu 14.04.5 LTS)**:\r\n- **TensorFlow installed from ( binary)**:\r\n- **TensorFlow version : 1.2.1\r\n- **Python version**: 2.7\r\n- **Bazel version : 0.70\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.4 \r\n- **CUDA/cuDNN version : 8.0\r\n- **GPU model and memory: Tesla P100-PCIE \r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\n\r\nI quantize the ssd_mobilenet_v1 model o ubuntu 14,  using the below command\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \r\n--in_graph=/data5/zxt/coco_log/export/frozen_inference_graph.pb  \r\n--out_graph=/home/zxt/git/ssd_optimized.pb --inputs='image_tensor'\r\n --outputs='detection_boxes,detection_scores,num_detections,detection_classes' --transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=float, shape=\"-1,-1,-1,3\")\r\n  remove_nodes(op=Identity, op=CheckNumerics)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  strip_unused_nodes\r\n  sort_by_execution_order'\r\n```\r\nI also have tried some other parameters\uff0cbut all failed with same issue.\r\nthe  frozen_inference_graph.pb   is ok on Android, but the quantized pb is can NOT load.\r\nWhen run the quantized pb on android phone, met errors\r\n```\r\n      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:799)\r\n   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:689)\r\n    Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; \r\nNodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). \r\n(Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n           at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:535)\r\n \r\n```"}