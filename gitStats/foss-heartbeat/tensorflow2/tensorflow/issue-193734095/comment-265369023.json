{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/265369023", "html_url": "https://github.com/tensorflow/tensorflow/issues/6117#issuecomment-265369023", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6117", "id": 265369023, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NTM2OTAyMw==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-07T06:42:59Z", "updated_at": "2016-12-07T06:42:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Individual tensors larger than 2GB are not supported by protobuf, which the distributed runtime uses as the format for tensors exchanged over the network. Generally speaking, if you have to transfer &gt;2GB over the network in a single step, you are probably not going to get very good performance. There are two main workarounds for dealing with this problem when checkpointing:</p>\n<ol>\n<li>Create the <a href=\"https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops.html#Saver.__init__\" rel=\"nofollow\"><code>tf.train.Saver</code></a> with the <code>sharded=True</code> optional argument. This causes each parameter server to write its data directly to the filesystem, avoiding the protobuf limit.</li>\n<li>Use a <a href=\"https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops.html#variable-partitioners-for-sharding\" rel=\"nofollow\">partitioner</a> when creating the variable (i.e. with <code>tf.get_variable()</code>) so that the individual variables are smaller. You can still use these partitioned variables directly with <code>tf.nn.embedding_lookup()</code>, and the lookup will be distributed across the parameter servers.</li>\n</ol>", "body_text": "Individual tensors larger than 2GB are not supported by protobuf, which the distributed runtime uses as the format for tensors exchanged over the network. Generally speaking, if you have to transfer >2GB over the network in a single step, you are probably not going to get very good performance. There are two main workarounds for dealing with this problem when checkpointing:\n\nCreate the tf.train.Saver with the sharded=True optional argument. This causes each parameter server to write its data directly to the filesystem, avoiding the protobuf limit.\nUse a partitioner when creating the variable (i.e. with tf.get_variable()) so that the individual variables are smaller. You can still use these partitioned variables directly with tf.nn.embedding_lookup(), and the lookup will be distributed across the parameter servers.", "body": "Individual tensors larger than 2GB are not supported by protobuf, which the distributed runtime uses as the format for tensors exchanged over the network. Generally speaking, if you have to transfer >2GB over the network in a single step, you are probably not going to get very good performance. There are two main workarounds for dealing with this problem when checkpointing:\r\n\r\n1. Create the [`tf.train.Saver`](https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops.html#Saver.__init__) with the `sharded=True` optional argument. This causes each parameter server to write its data directly to the filesystem, avoiding the protobuf limit.\r\n2. Use a [partitioner](https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops.html#variable-partitioners-for-sharding) when creating the variable (i.e. with `tf.get_variable()`) so that the individual variables are smaller. You can still use these partitioned variables directly with `tf.nn.embedding_lookup()`, and the lookup will be distributed across the parameter servers."}