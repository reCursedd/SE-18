{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12093", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12093/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12093/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12093/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12093", "id": 248569216, "node_id": "MDU6SXNzdWUyNDg1NjkyMTY=", "number": 12093, "title": "Feature Request - Return final loss from tf.estimator.Estimator.train along with self.", "user": {"login": "GrandathePanda", "id": 6426407, "node_id": "MDQ6VXNlcjY0MjY0MDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6426407?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GrandathePanda", "html_url": "https://github.com/GrandathePanda", "followers_url": "https://api.github.com/users/GrandathePanda/followers", "following_url": "https://api.github.com/users/GrandathePanda/following{/other_user}", "gists_url": "https://api.github.com/users/GrandathePanda/gists{/gist_id}", "starred_url": "https://api.github.com/users/GrandathePanda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GrandathePanda/subscriptions", "organizations_url": "https://api.github.com/users/GrandathePanda/orgs", "repos_url": "https://api.github.com/users/GrandathePanda/repos", "events_url": "https://api.github.com/users/GrandathePanda/events{/privacy}", "received_events_url": "https://api.github.com/users/GrandathePanda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2017-08-08T00:41:40Z", "updated_at": "2018-02-20T04:56:48Z", "closed_at": "2017-08-13T00:42:48Z", "author_association": "NONE", "body_html": "<h3>Describe the problem</h3>\n<p>Things like hyper opt need to know the loss so that it can effectively pick the best hyper parameters for the model. Right now self is just returned, it is a one line change to the code since the loss is set the exact line before. I would be happy to initiate the PR myself assuming its wanted.</p>\n<h3>Source code / logs</h3>\n<p>From:</p>\n<pre><code>loss = self._train_model(input_fn=input_fn, hooks=hooks)\nlogging.info('Loss for final step: %s.', loss)\nreturn self\n</code></pre>\n<p>To:</p>\n<pre><code>loss = self._train_model(input_fn=input_fn, hooks=hooks)\nlogging.info('Loss for final step: %s.', loss)\nreturn self, loss\n</code></pre>", "body_text": "Describe the problem\nThings like hyper opt need to know the loss so that it can effectively pick the best hyper parameters for the model. Right now self is just returned, it is a one line change to the code since the loss is set the exact line before. I would be happy to initiate the PR myself assuming its wanted.\nSource code / logs\nFrom:\nloss = self._train_model(input_fn=input_fn, hooks=hooks)\nlogging.info('Loss for final step: %s.', loss)\nreturn self\n\nTo:\nloss = self._train_model(input_fn=input_fn, hooks=hooks)\nlogging.info('Loss for final step: %s.', loss)\nreturn self, loss", "body": "### Describe the problem\r\nThings like hyper opt need to know the loss so that it can effectively pick the best hyper parameters for the model. Right now self is just returned, it is a one line change to the code since the loss is set the exact line before. I would be happy to initiate the PR myself assuming its wanted.\r\n\r\n### Source code / logs\r\nFrom:\r\n```\r\nloss = self._train_model(input_fn=input_fn, hooks=hooks)\r\nlogging.info('Loss for final step: %s.', loss)\r\nreturn self\r\n```\r\n\r\nTo:\r\n```\r\nloss = self._train_model(input_fn=input_fn, hooks=hooks)\r\nlogging.info('Loss for final step: %s.', loss)\r\nreturn self, loss\r\n```\r\n"}