{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163028350", "pull_request_review_id": 90578124, "id": 163028350, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzAyODM1MA==", "diff_hunk": "@@ -16,11 +16,14 @@ limitations under the License.\n #ifndef TENSORFLOW_CONTRIB_S3_S3_FILE_SYSTEM_H_\n #define TENSORFLOW_CONTRIB_S3_S3_FILE_SYSTEM_H_\n \n+#include <aws/s3/S3Client.h>\n #include \"tensorflow/core/platform/env.h\"\n \n namespace tensorflow {\n \n class S3FileSystem : public FileSystem {\n+ private:\n+  std::shared_ptr<Aws::S3::S3Client> s3Client_;", "path": "tensorflow/core/platform/s3/s3_file_system.h", "position": null, "original_position": 11, "commit_id": "2b3ecbc3a7374082487a38dcf81f9c329a52e414", "original_commit_id": "4cab2db90661e5f4b472ace55c45ba4befa6b27c", "user": {"login": "jkinkead", "id": 1548392, "node_id": "MDQ6VXNlcjE1NDgzOTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/1548392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkinkead", "html_url": "https://github.com/jkinkead", "followers_url": "https://api.github.com/users/jkinkead/followers", "following_url": "https://api.github.com/users/jkinkead/following{/other_user}", "gists_url": "https://api.github.com/users/jkinkead/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkinkead/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkinkead/subscriptions", "organizations_url": "https://api.github.com/users/jkinkead/orgs", "repos_url": "https://api.github.com/users/jkinkead/repos", "events_url": "https://api.github.com/users/jkinkead/events{/privacy}", "received_events_url": "https://api.github.com/users/jkinkead/received_events", "type": "User", "site_admin": false}, "body": "Renamed.\r\n\r\nI'm passing this pointer to the file objects (`S3RandomAccessFile`, `S3WritableFile`) using `shared_ptr`. This ensures that the client will be valid even if the underlying `S3FileSystem` goes away. I don't think this normally happens, but it's not clear from reading the documentation, and I felt it was more correct this way.", "created_at": "2018-01-22T18:38:27Z", "updated_at": "2018-01-23T20:11:22Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16232#discussion_r163028350", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16232", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163028350"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16232#discussion_r163028350"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16232"}}, "body_html": "<p>Renamed.</p>\n<p>I'm passing this pointer to the file objects (<code>S3RandomAccessFile</code>, <code>S3WritableFile</code>) using <code>shared_ptr</code>. This ensures that the client will be valid even if the underlying <code>S3FileSystem</code> goes away. I don't think this normally happens, but it's not clear from reading the documentation, and I felt it was more correct this way.</p>", "body_text": "Renamed.\nI'm passing this pointer to the file objects (S3RandomAccessFile, S3WritableFile) using shared_ptr. This ensures that the client will be valid even if the underlying S3FileSystem goes away. I don't think this normally happens, but it's not clear from reading the documentation, and I felt it was more correct this way.", "in_reply_to_id": 162790162}