{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8198", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8198/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8198/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8198/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8198", "id": 212742281, "node_id": "MDU6SXNzdWUyMTI3NDIyODE=", "number": 8198, "title": "OOM although very small network", "user": {"login": "oranshayer", "id": 24811814, "node_id": "MDQ6VXNlcjI0ODExODE0", "avatar_url": "https://avatars2.githubusercontent.com/u/24811814?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oranshayer", "html_url": "https://github.com/oranshayer", "followers_url": "https://api.github.com/users/oranshayer/followers", "following_url": "https://api.github.com/users/oranshayer/following{/other_user}", "gists_url": "https://api.github.com/users/oranshayer/gists{/gist_id}", "starred_url": "https://api.github.com/users/oranshayer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oranshayer/subscriptions", "organizations_url": "https://api.github.com/users/oranshayer/orgs", "repos_url": "https://api.github.com/users/oranshayer/repos", "events_url": "https://api.github.com/users/oranshayer/events{/privacy}", "received_events_url": "https://api.github.com/users/oranshayer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-03-08T14:02:32Z", "updated_at": "2017-03-08T17:24:41Z", "closed_at": "2017-03-08T17:24:41Z", "author_association": "NONE", "body_html": "<p>Operating System:<br>\nUbuntu 16.04</p>\n<p>Installed version of CUDA and cuDNN:<br>\nCUDA 8.0<br>\nCuDNN 5.1</p>\n<p>TensorFlow v0.12.1</p>\n<p>Hi,<br>\nI'm getting an OOM message on a very small network, and running on 2 GTX 1080.<br>\nIt's a 2 layer network, first 2 layers of VGG, conv1_1, conv1_2.<br>\nThe input image is 400x400 and I am trying to run a batch of size 16.</p>\n<p>My training is taking a feature vector from 4 spatial positions and training with some loss on it.<br>\nSo for example, after 2 VGG conv layers I will have a feature vector of size 64 at each pixel, or to be exact, a tensor of size [16,400,400,64].<br>\nI want to take these vectors from 4 locations, meaning I will have 4 vectors of length 64, then calculating some loss function on them.</p>\n<p>So this is my inference function:</p>\n<pre><code>def inference(images, x1, y, x2, z, train=False):\n  # conv1_1\n  with tf.variable_scope('conv1_1') as scope:\n    kernel = _variable_with_weight_decay('weights', shape=[3, 3, 3, 64], wd=0.000, layer_name=scope.name)\n    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0), layer_name=scope.name)\n    conv1_1 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope.name)\n\n  # conv1_2\n  with tf.variable_scope('conv1_2') as scope:\n    kernel = _variable_with_weight_decay('weights', shape=[3, 3, 64, 64], wd=0.000, layer_name=scope.name)\n    conv = tf.nn.conv2d(conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0), layer_name=scope.name)\n    conv1_2 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope.name)\n\n  in1=tf.reshape(conv1_2[0, x1[0][0], x1[0][1], :],[1,64])\n  in2=tf.reshape(conv1_2[0, y[0][0], y[0][1], :],[1,64])\n  in3=tf.reshape(conv1_2[0, x2[0][0], x2[0][1], :],[1,64])\n  in4=tf.reshape(conv1_2[0, z[0][0], z[0][1], :],[1,64])\n\n  for i in range (1, FLAGS.batch_size):\n      in1 = tf.concat(0,[in1,tf.reshape(conv1_2[i, x1[i][0], x1[i][1], :],[1,64])])\n      in2 = tf.concat(0,[in2,tf.reshape(conv1_2[i, y[i][0], y[i][1], :],[1,64])])\n      in3 = tf.concat(0,[in3,tf.reshape(conv1_2[i, x2[i][0], x2[i][1], :],[1,64])])\n      in4 = tf.concat(0,[in4,tf.reshape(conv1_2[i, z[i][0], z[i][1], :],[1,64])])\n</code></pre>\n<p>Now, each in1,in2,in3,in4 is of size [16,64]<br>\nFrom here on I calculate some loss with that.<br>\nFor some reason I am getting an OOM message, although this is a very small network. <strong>I guess that the way I am taking these feature vectors makes the tool allocate way bigger memory than needed.</strong></p>\n<blockquote>\n<p>ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,400,400,64]<br>\n[[Node: gradients/strided_slice_84_grad/StridedSliceGrad = StridedSliceGrad[Index=DT_INT32, T=DT_FLOAT, begin_mask=8, ellipsis_mask=0, end_mask=8, new_axis_mask=0, shrink_axis_mask=7, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/strided_slice_84_grad/Shape, strided_slice_84/stack, strided_slice_84/stack_1, strided_slice_84/stack_2, gradients/Reshape_16_grad/Reshape)]]<br>\n[[Node: gradients/conv1_1/BiasAdd_grad/tuple/control_dependency_1/_99 = _Recv<a href=\"\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2359_gradients/conv1_1/BiasAdd_grad/tuple/control_dependency_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"</a>]]</p>\n</blockquote>\n<p>Thanks in advance for the help!</p>", "body_text": "Operating System:\nUbuntu 16.04\nInstalled version of CUDA and cuDNN:\nCUDA 8.0\nCuDNN 5.1\nTensorFlow v0.12.1\nHi,\nI'm getting an OOM message on a very small network, and running on 2 GTX 1080.\nIt's a 2 layer network, first 2 layers of VGG, conv1_1, conv1_2.\nThe input image is 400x400 and I am trying to run a batch of size 16.\nMy training is taking a feature vector from 4 spatial positions and training with some loss on it.\nSo for example, after 2 VGG conv layers I will have a feature vector of size 64 at each pixel, or to be exact, a tensor of size [16,400,400,64].\nI want to take these vectors from 4 locations, meaning I will have 4 vectors of length 64, then calculating some loss function on them.\nSo this is my inference function:\ndef inference(images, x1, y, x2, z, train=False):\n  # conv1_1\n  with tf.variable_scope('conv1_1') as scope:\n    kernel = _variable_with_weight_decay('weights', shape=[3, 3, 3, 64], wd=0.000, layer_name=scope.name)\n    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0), layer_name=scope.name)\n    conv1_1 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope.name)\n\n  # conv1_2\n  with tf.variable_scope('conv1_2') as scope:\n    kernel = _variable_with_weight_decay('weights', shape=[3, 3, 64, 64], wd=0.000, layer_name=scope.name)\n    conv = tf.nn.conv2d(conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0), layer_name=scope.name)\n    conv1_2 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope.name)\n\n  in1=tf.reshape(conv1_2[0, x1[0][0], x1[0][1], :],[1,64])\n  in2=tf.reshape(conv1_2[0, y[0][0], y[0][1], :],[1,64])\n  in3=tf.reshape(conv1_2[0, x2[0][0], x2[0][1], :],[1,64])\n  in4=tf.reshape(conv1_2[0, z[0][0], z[0][1], :],[1,64])\n\n  for i in range (1, FLAGS.batch_size):\n      in1 = tf.concat(0,[in1,tf.reshape(conv1_2[i, x1[i][0], x1[i][1], :],[1,64])])\n      in2 = tf.concat(0,[in2,tf.reshape(conv1_2[i, y[i][0], y[i][1], :],[1,64])])\n      in3 = tf.concat(0,[in3,tf.reshape(conv1_2[i, x2[i][0], x2[i][1], :],[1,64])])\n      in4 = tf.concat(0,[in4,tf.reshape(conv1_2[i, z[i][0], z[i][1], :],[1,64])])\n\nNow, each in1,in2,in3,in4 is of size [16,64]\nFrom here on I calculate some loss with that.\nFor some reason I am getting an OOM message, although this is a very small network. I guess that the way I am taking these feature vectors makes the tool allocate way bigger memory than needed.\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,400,400,64]\n[[Node: gradients/strided_slice_84_grad/StridedSliceGrad = StridedSliceGrad[Index=DT_INT32, T=DT_FLOAT, begin_mask=8, ellipsis_mask=0, end_mask=8, new_axis_mask=0, shrink_axis_mask=7, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/strided_slice_84_grad/Shape, strided_slice_84/stack, strided_slice_84/stack_1, strided_slice_84/stack_2, gradients/Reshape_16_grad/Reshape)]]\n[[Node: gradients/conv1_1/BiasAdd_grad/tuple/control_dependency_1/_99 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2359_gradients/conv1_1/BiasAdd_grad/tuple/control_dependency_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\n\nThanks in advance for the help!", "body": "Operating System:\r\nUbuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\nCUDA 8.0\r\nCuDNN 5.1\r\n\r\nTensorFlow v0.12.1\r\n\r\nHi,\r\nI'm getting an OOM message on a very small network, and running on 2 GTX 1080.\r\nIt's a 2 layer network, first 2 layers of VGG, conv1_1, conv1_2.\r\nThe input image is 400x400 and I am trying to run a batch of size 16.\r\n\r\nMy training is taking a feature vector from 4 spatial positions and training with some loss on it.\r\nSo for example, after 2 VGG conv layers I will have a feature vector of size 64 at each pixel, or to be exact, a tensor of size [16,400,400,64].\r\nI want to take these vectors from 4 locations, meaning I will have 4 vectors of length 64, then calculating some loss function on them.\r\n\r\nSo this is my inference function:\r\n\r\n```\r\ndef inference(images, x1, y, x2, z, train=False):\r\n  # conv1_1\r\n  with tf.variable_scope('conv1_1') as scope:\r\n    kernel = _variable_with_weight_decay('weights', shape=[3, 3, 3, 64], wd=0.000, layer_name=scope.name)\r\n    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\r\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0), layer_name=scope.name)\r\n    conv1_1 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope.name)\r\n\r\n  # conv1_2\r\n  with tf.variable_scope('conv1_2') as scope:\r\n    kernel = _variable_with_weight_decay('weights', shape=[3, 3, 64, 64], wd=0.000, layer_name=scope.name)\r\n    conv = tf.nn.conv2d(conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\r\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0), layer_name=scope.name)\r\n    conv1_2 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope.name)\r\n\r\n  in1=tf.reshape(conv1_2[0, x1[0][0], x1[0][1], :],[1,64])\r\n  in2=tf.reshape(conv1_2[0, y[0][0], y[0][1], :],[1,64])\r\n  in3=tf.reshape(conv1_2[0, x2[0][0], x2[0][1], :],[1,64])\r\n  in4=tf.reshape(conv1_2[0, z[0][0], z[0][1], :],[1,64])\r\n\r\n  for i in range (1, FLAGS.batch_size):\r\n      in1 = tf.concat(0,[in1,tf.reshape(conv1_2[i, x1[i][0], x1[i][1], :],[1,64])])\r\n      in2 = tf.concat(0,[in2,tf.reshape(conv1_2[i, y[i][0], y[i][1], :],[1,64])])\r\n      in3 = tf.concat(0,[in3,tf.reshape(conv1_2[i, x2[i][0], x2[i][1], :],[1,64])])\r\n      in4 = tf.concat(0,[in4,tf.reshape(conv1_2[i, z[i][0], z[i][1], :],[1,64])])\r\n```\r\n\r\nNow, each in1,in2,in3,in4 is of size [16,64]\r\nFrom here on I calculate some loss with that.\r\nFor some reason I am getting an OOM message, although this is a very small network. **I guess that the way I am taking these feature vectors makes the tool allocate way bigger memory than needed.**\r\n\r\n> ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,400,400,64]\r\n> \t [[Node: gradients/strided_slice_84_grad/StridedSliceGrad = StridedSliceGrad[Index=DT_INT32, T=DT_FLOAT, begin_mask=8, ellipsis_mask=0, end_mask=8, new_axis_mask=0, shrink_axis_mask=7, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/strided_slice_84_grad/Shape, strided_slice_84/stack, strided_slice_84/stack_1, strided_slice_84/stack_2, gradients/Reshape_16_grad/Reshape)]]\r\n> \t [[Node: gradients/conv1_1/BiasAdd_grad/tuple/control_dependency_1/_99 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2359_gradients/conv1_1/BiasAdd_grad/tuple/control_dependency_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n> \r\n> \r\n\r\nThanks in advance for the help!"}