{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/220482325", "html_url": "https://github.com/tensorflow/tensorflow/issues/1592#issuecomment-220482325", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1592", "id": 220482325, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDQ4MjMyNQ==", "user": {"login": "zhengwy888", "id": 1190730, "node_id": "MDQ6VXNlcjExOTA3MzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1190730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhengwy888", "html_url": "https://github.com/zhengwy888", "followers_url": "https://api.github.com/users/zhengwy888/followers", "following_url": "https://api.github.com/users/zhengwy888/following{/other_user}", "gists_url": "https://api.github.com/users/zhengwy888/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhengwy888/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhengwy888/subscriptions", "organizations_url": "https://api.github.com/users/zhengwy888/orgs", "repos_url": "https://api.github.com/users/zhengwy888/repos", "events_url": "https://api.github.com/users/zhengwy888/events{/privacy}", "received_events_url": "https://api.github.com/users/zhengwy888/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-19T23:47:56Z", "updated_at": "2016-05-19T23:48:47Z", "author_association": "NONE", "body_html": "<p>I have implemented a primitive op on cpu for the XOR + bitcount. but it's too slow right now. Does any one know how to speed this up? if this ever gets to the same speed as tf.matmul than I should provide a patch. Note this is not for convolution., this is simply replacing matmul() with a xnor + bit count.</p>\n<div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">void</span> <span class=\"pl-en\">concatenate_col</span>(\n          <span class=\"pl-k\">typename</span> MatMulTypes&lt;T&gt;::in_type array,\n          MaskMatrix &amp;out)\n  {\n      <span class=\"pl-k\">int</span> rowSize = <span class=\"pl-c1\">int</span>((array.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">0</span>)+<span class=\"pl-c1\">31</span>)/ <span class=\"pl-c1\">32</span>);\n      out.<span class=\"pl-c1\">resize</span>(array.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">1</span>),rowSize );\n\n      <span class=\"pl-k\">for</span> ( <span class=\"pl-k\">int</span> c=<span class=\"pl-c1\">0</span>; c&lt; array.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">1</span>); ++ c)\n      {\n          <span class=\"pl-k\">for</span> ( <span class=\"pl-k\">int</span> r = <span class=\"pl-c1\">0</span>; r &lt; rowSize; ++ r )\n          {\n              <span class=\"pl-c1\">uint32_t</span> rvalue=<span class=\"pl-c1\">0</span>;\n              <span class=\"pl-c1\">uint32_t</span> sign;\n              <span class=\"pl-k\">for</span> ( <span class=\"pl-k\">int</span> i=<span class=\"pl-c1\">0</span>; i&lt; <span class=\"pl-c1\">32</span>; ++i ) {\n                  <span class=\"pl-k\">int</span> rowIdx = r*<span class=\"pl-c1\">32</span> + i;\n                  <span class=\"pl-k\">if</span> ( rowIdx &gt; array.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">0</span>)-<span class=\"pl-c1\">1</span> ) {\n                      <span class=\"pl-k\">break</span>;\n                  }\n                  sign = (<span class=\"pl-c1\">array</span>(rowIdx, c )&gt;=<span class=\"pl-c1\">0</span>);\n                  rvalue = rvalue | (sign &lt;&lt;i);\n              }\n              <span class=\"pl-c1\">out</span>(c, r) = rvalue;\n          }\n      }\n  }\n  <span class=\"pl-k\">void</span> <span class=\"pl-en\">concatenate_row</span>(\n          <span class=\"pl-k\">typename</span> MatMulTypes&lt;T&gt;::in_type array,\n          MaskMatrix &amp;out)\n  {\n      <span class=\"pl-k\">int</span> colSize = <span class=\"pl-c1\">int</span>((array.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">1</span>)+<span class=\"pl-c1\">31</span> )/ <span class=\"pl-c1\">32</span>);\n      out.<span class=\"pl-c1\">resize</span>(array.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">0</span>), colSize);\n      <span class=\"pl-k\">for</span> ( <span class=\"pl-k\">int</span> r = <span class=\"pl-c1\">0</span>; r &lt; array.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">0</span>); ++ r )\n      {\n          <span class=\"pl-k\">for</span> ( <span class=\"pl-k\">int</span> c=<span class=\"pl-c1\">0</span>; c&lt; colSize; ++ c)\n          {\n              <span class=\"pl-c1\">uint32_t</span> rvalue=<span class=\"pl-c1\">0</span>;\n              <span class=\"pl-c1\">uint32_t</span> sign;\n              <span class=\"pl-k\">for</span> ( <span class=\"pl-k\">int</span> i=<span class=\"pl-c1\">0</span>; i&lt; <span class=\"pl-c1\">32</span>; ++i ) {\n                  <span class=\"pl-k\">int</span> colIdx = c*<span class=\"pl-c1\">32</span> + i;\n                  <span class=\"pl-k\">if</span> ( colIdx &gt; array.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">1</span>)-<span class=\"pl-c1\">1</span> ) {\n                      <span class=\"pl-k\">break</span>;\n                  }\n                  sign = (<span class=\"pl-c1\">array</span>(r, colIdx)&gt;=<span class=\"pl-c1\">0</span>);\n                  rvalue = rvalue | (sign &lt;&lt;i);\n              }\n              <span class=\"pl-c1\">out</span>(r,c) = rvalue;\n          }\n      }\n  }\n\n  <span class=\"pl-k\">void</span> <span class=\"pl-en\">concatenate_and_compute</span>(\n          <span class=\"pl-k\">const</span> CPUDevice &amp;d,\n          <span class=\"pl-k\">typename</span> MatMulTypes&lt;T&gt;::in_type a,\n          <span class=\"pl-k\">typename</span> MatMulTypes&lt;T&gt;::in_type b,\n          <span class=\"pl-k\">typename</span> MatMulTypes&lt;T&gt;::out_type out)\n  {\n      MaskMatrix a_;\n      MaskMatrix b_;\n\n      <span class=\"pl-c1\">concatenate_row</span>(a, a_);\n      <span class=\"pl-c1\">concatenate_col</span>(b, b_);\n\n      <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> ar=<span class=\"pl-c1\">0</span>; ar &lt; a_.<span class=\"pl-c1\">rows</span>(); ar++)\n      {\n          <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> br=<span class=\"pl-c1\">0</span>; br&lt; b_.<span class=\"pl-c1\">rows</span>(); br++) {\n              <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> Cvalue = <span class=\"pl-c1\">0</span>;\n              <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> c=<span class=\"pl-c1\">0</span>; c&lt; a_.<span class=\"pl-c1\">cols</span>(); c++)\n              {\n                  <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> value =<span class=\"pl-c1\">popcnt</span>(<span class=\"pl-c1\">a_</span>(ar, c) ^ <span class=\"pl-c1\">b_</span>(br,c));\n                  Cvalue += value;\n              }\n              <span class=\"pl-c1\">out</span>(ar, br) = - ( <span class=\"pl-c1\">2</span>*(<span class=\"pl-k\">float</span>)Cvalue - a.<span class=\"pl-c1\">dimension</span>(<span class=\"pl-c1\">1</span>) );\n          }\n      }\n\n  }\n</pre></div>", "body_text": "I have implemented a primitive op on cpu for the XOR + bitcount. but it's too slow right now. Does any one know how to speed this up? if this ever gets to the same speed as tf.matmul than I should provide a patch. Note this is not for convolution., this is simply replacing matmul() with a xnor + bit count.\n  void concatenate_col(\n          typename MatMulTypes<T>::in_type array,\n          MaskMatrix &out)\n  {\n      int rowSize = int((array.dimension(0)+31)/ 32);\n      out.resize(array.dimension(1),rowSize );\n\n      for ( int c=0; c< array.dimension(1); ++ c)\n      {\n          for ( int r = 0; r < rowSize; ++ r )\n          {\n              uint32_t rvalue=0;\n              uint32_t sign;\n              for ( int i=0; i< 32; ++i ) {\n                  int rowIdx = r*32 + i;\n                  if ( rowIdx > array.dimension(0)-1 ) {\n                      break;\n                  }\n                  sign = (array(rowIdx, c )>=0);\n                  rvalue = rvalue | (sign <<i);\n              }\n              out(c, r) = rvalue;\n          }\n      }\n  }\n  void concatenate_row(\n          typename MatMulTypes<T>::in_type array,\n          MaskMatrix &out)\n  {\n      int colSize = int((array.dimension(1)+31 )/ 32);\n      out.resize(array.dimension(0), colSize);\n      for ( int r = 0; r < array.dimension(0); ++ r )\n      {\n          for ( int c=0; c< colSize; ++ c)\n          {\n              uint32_t rvalue=0;\n              uint32_t sign;\n              for ( int i=0; i< 32; ++i ) {\n                  int colIdx = c*32 + i;\n                  if ( colIdx > array.dimension(1)-1 ) {\n                      break;\n                  }\n                  sign = (array(r, colIdx)>=0);\n                  rvalue = rvalue | (sign <<i);\n              }\n              out(r,c) = rvalue;\n          }\n      }\n  }\n\n  void concatenate_and_compute(\n          const CPUDevice &d,\n          typename MatMulTypes<T>::in_type a,\n          typename MatMulTypes<T>::in_type b,\n          typename MatMulTypes<T>::out_type out)\n  {\n      MaskMatrix a_;\n      MaskMatrix b_;\n\n      concatenate_row(a, a_);\n      concatenate_col(b, b_);\n\n      for (int ar=0; ar < a_.rows(); ar++)\n      {\n          for (int br=0; br< b_.rows(); br++) {\n              unsigned int Cvalue = 0;\n              for (int c=0; c< a_.cols(); c++)\n              {\n                  unsigned int value =popcnt(a_(ar, c) ^ b_(br,c));\n                  Cvalue += value;\n              }\n              out(ar, br) = - ( 2*(float)Cvalue - a.dimension(1) );\n          }\n      }\n\n  }", "body": "I have implemented a primitive op on cpu for the XOR + bitcount. but it's too slow right now. Does any one know how to speed this up? if this ever gets to the same speed as tf.matmul than I should provide a patch. Note this is not for convolution., this is simply replacing matmul() with a xnor + bit count.\n\n``` c++\n  void concatenate_col(\n          typename MatMulTypes<T>::in_type array,\n          MaskMatrix &out)\n  {\n      int rowSize = int((array.dimension(0)+31)/ 32);\n      out.resize(array.dimension(1),rowSize );\n\n      for ( int c=0; c< array.dimension(1); ++ c)\n      {\n          for ( int r = 0; r < rowSize; ++ r )\n          {\n              uint32_t rvalue=0;\n              uint32_t sign;\n              for ( int i=0; i< 32; ++i ) {\n                  int rowIdx = r*32 + i;\n                  if ( rowIdx > array.dimension(0)-1 ) {\n                      break;\n                  }\n                  sign = (array(rowIdx, c )>=0);\n                  rvalue = rvalue | (sign <<i);\n              }\n              out(c, r) = rvalue;\n          }\n      }\n  }\n  void concatenate_row(\n          typename MatMulTypes<T>::in_type array,\n          MaskMatrix &out)\n  {\n      int colSize = int((array.dimension(1)+31 )/ 32);\n      out.resize(array.dimension(0), colSize);\n      for ( int r = 0; r < array.dimension(0); ++ r )\n      {\n          for ( int c=0; c< colSize; ++ c)\n          {\n              uint32_t rvalue=0;\n              uint32_t sign;\n              for ( int i=0; i< 32; ++i ) {\n                  int colIdx = c*32 + i;\n                  if ( colIdx > array.dimension(1)-1 ) {\n                      break;\n                  }\n                  sign = (array(r, colIdx)>=0);\n                  rvalue = rvalue | (sign <<i);\n              }\n              out(r,c) = rvalue;\n          }\n      }\n  }\n\n  void concatenate_and_compute(\n          const CPUDevice &d,\n          typename MatMulTypes<T>::in_type a,\n          typename MatMulTypes<T>::in_type b,\n          typename MatMulTypes<T>::out_type out)\n  {\n      MaskMatrix a_;\n      MaskMatrix b_;\n\n      concatenate_row(a, a_);\n      concatenate_col(b, b_);\n\n      for (int ar=0; ar < a_.rows(); ar++)\n      {\n          for (int br=0; br< b_.rows(); br++) {\n              unsigned int Cvalue = 0;\n              for (int c=0; c< a_.cols(); c++)\n              {\n                  unsigned int value =popcnt(a_(ar, c) ^ b_(br,c));\n                  Cvalue += value;\n              }\n              out(ar, br) = - ( 2*(float)Cvalue - a.dimension(1) );\n          }\n      }\n\n  }\n\n```\n"}