{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234221361", "html_url": "https://github.com/tensorflow/tensorflow/issues/1592#issuecomment-234221361", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1592", "id": 234221361, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDIyMTM2MQ==", "user": {"login": "isabel-schwende", "id": 19379953, "node_id": "MDQ6VXNlcjE5Mzc5OTUz", "avatar_url": "https://avatars3.githubusercontent.com/u/19379953?v=4", "gravatar_id": "", "url": "https://api.github.com/users/isabel-schwende", "html_url": "https://github.com/isabel-schwende", "followers_url": "https://api.github.com/users/isabel-schwende/followers", "following_url": "https://api.github.com/users/isabel-schwende/following{/other_user}", "gists_url": "https://api.github.com/users/isabel-schwende/gists{/gist_id}", "starred_url": "https://api.github.com/users/isabel-schwende/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/isabel-schwende/subscriptions", "organizations_url": "https://api.github.com/users/isabel-schwende/orgs", "repos_url": "https://api.github.com/users/isabel-schwende/repos", "events_url": "https://api.github.com/users/isabel-schwende/events{/privacy}", "received_events_url": "https://api.github.com/users/isabel-schwende/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-21T10:55:50Z", "updated_at": "2016-07-21T10:55:50Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1381301\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ppwwyyxx\">@ppwwyyxx</a> Thanks a lot for your answer. I definitely agree. For that reason I started with the quantization available by TensorFlow. It seems like using it for inference is currently very slow. As several others have described here <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"159782222\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2807\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2807/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2807\">#2807</a> the memory might be much lower for saving the model but inference time is approximately doubled, which is undesirable in our project. I've been searching for something that is fast and has low memory requirements but it seems like the available code is still in research phase. I guess we will do some hacking to get something customised for our project.</p>", "body_text": "@ppwwyyxx Thanks a lot for your answer. I definitely agree. For that reason I started with the quantization available by TensorFlow. It seems like using it for inference is currently very slow. As several others have described here #2807 the memory might be much lower for saving the model but inference time is approximately doubled, which is undesirable in our project. I've been searching for something that is fast and has low memory requirements but it seems like the available code is still in research phase. I guess we will do some hacking to get something customised for our project.", "body": "@ppwwyyxx Thanks a lot for your answer. I definitely agree. For that reason I started with the quantization available by TensorFlow. It seems like using it for inference is currently very slow. As several others have described here https://github.com/tensorflow/tensorflow/issues/2807 the memory might be much lower for saving the model but inference time is approximately doubled, which is undesirable in our project. I've been searching for something that is fast and has low memory requirements but it seems like the available code is still in research phase. I guess we will do some hacking to get something customised for our project. \n"}