{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234138349", "html_url": "https://github.com/tensorflow/tensorflow/issues/1592#issuecomment-234138349", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1592", "id": 234138349, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDEzODM0OQ==", "user": {"login": "isabel-schwende", "id": 19379953, "node_id": "MDQ6VXNlcjE5Mzc5OTUz", "avatar_url": "https://avatars3.githubusercontent.com/u/19379953?v=4", "gravatar_id": "", "url": "https://api.github.com/users/isabel-schwende", "html_url": "https://github.com/isabel-schwende", "followers_url": "https://api.github.com/users/isabel-schwende/followers", "following_url": "https://api.github.com/users/isabel-schwende/following{/other_user}", "gists_url": "https://api.github.com/users/isabel-schwende/gists{/gist_id}", "starred_url": "https://api.github.com/users/isabel-schwende/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/isabel-schwende/subscriptions", "organizations_url": "https://api.github.com/users/isabel-schwende/orgs", "repos_url": "https://api.github.com/users/isabel-schwende/repos", "events_url": "https://api.github.com/users/isabel-schwende/events{/privacy}", "received_events_url": "https://api.github.com/users/isabel-schwende/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-21T02:16:08Z", "updated_at": "2016-07-21T02:16:08Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6743242\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wangyida\">@wangyida</a> Yes, I agree that it seems that the intention of the authors of DoReFa was mostly to reduce training and inference time by using low bitwidth. I don't expect them to release an 8bit version. However they also mention in their paper the idea to use this kind of network on embedded devices. If you want to use AlexNet on a very small device, I don't see the reason to use 32 bit floats if there is no information held in them anyways. To me, the quantization to a smaller datatype is just the next logical step.</p>", "body_text": "@wangyida Yes, I agree that it seems that the intention of the authors of DoReFa was mostly to reduce training and inference time by using low bitwidth. I don't expect them to release an 8bit version. However they also mention in their paper the idea to use this kind of network on embedded devices. If you want to use AlexNet on a very small device, I don't see the reason to use 32 bit floats if there is no information held in them anyways. To me, the quantization to a smaller datatype is just the next logical step.", "body": "@Wangyida Yes, I agree that it seems that the intention of the authors of DoReFa was mostly to reduce training and inference time by using low bitwidth. I don't expect them to release an 8bit version. However they also mention in their paper the idea to use this kind of network on embedded devices. If you want to use AlexNet on a very small device, I don't see the reason to use 32 bit floats if there is no information held in them anyways. To me, the quantization to a smaller datatype is just the next logical step. \n"}