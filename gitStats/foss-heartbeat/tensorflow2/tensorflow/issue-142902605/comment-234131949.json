{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234131949", "html_url": "https://github.com/tensorflow/tensorflow/issues/1592#issuecomment-234131949", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1592", "id": 234131949, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDEzMTk0OQ==", "user": {"login": "isabel-schwende", "id": 19379953, "node_id": "MDQ6VXNlcjE5Mzc5OTUz", "avatar_url": "https://avatars3.githubusercontent.com/u/19379953?v=4", "gravatar_id": "", "url": "https://api.github.com/users/isabel-schwende", "html_url": "https://github.com/isabel-schwende", "followers_url": "https://api.github.com/users/isabel-schwende/followers", "following_url": "https://api.github.com/users/isabel-schwende/following{/other_user}", "gists_url": "https://api.github.com/users/isabel-schwende/gists{/gist_id}", "starred_url": "https://api.github.com/users/isabel-schwende/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/isabel-schwende/subscriptions", "organizations_url": "https://api.github.com/users/isabel-schwende/orgs", "repos_url": "https://api.github.com/users/isabel-schwende/repos", "events_url": "https://api.github.com/users/isabel-schwende/events{/privacy}", "received_events_url": "https://api.github.com/users/isabel-schwende/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-21T01:26:39Z", "updated_at": "2016-07-21T01:26:39Z", "author_association": "NONE", "body_html": "<p>Thanks for sharing everyone. But as I understood the DoReFa implementation so far, it still uses the standard 32 bit tensors. I've been thinking about ways to use the official TensorFlow quantization methods to reduce the memory at least to a quarter. The 8-bit datatype is available. Of course the question would be how to use it with the least hassle.</p>", "body_text": "Thanks for sharing everyone. But as I understood the DoReFa implementation so far, it still uses the standard 32 bit tensors. I've been thinking about ways to use the official TensorFlow quantization methods to reduce the memory at least to a quarter. The 8-bit datatype is available. Of course the question would be how to use it with the least hassle.", "body": "Thanks for sharing everyone. But as I understood the DoReFa implementation so far, it still uses the standard 32 bit tensors. I've been thinking about ways to use the official TensorFlow quantization methods to reduce the memory at least to a quarter. The 8-bit datatype is available. Of course the question would be how to use it with the least hassle. \n"}