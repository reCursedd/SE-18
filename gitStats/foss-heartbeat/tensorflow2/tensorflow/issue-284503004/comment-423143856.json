{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/423143856", "html_url": "https://github.com/tensorflow/tensorflow/issues/15633#issuecomment-423143856", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15633", "id": 423143856, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMzE0Mzg1Ng==", "user": {"login": "KaviSanth", "id": 43197238, "node_id": "MDQ6VXNlcjQzMTk3MjM4", "avatar_url": "https://avatars0.githubusercontent.com/u/43197238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KaviSanth", "html_url": "https://github.com/KaviSanth", "followers_url": "https://api.github.com/users/KaviSanth/followers", "following_url": "https://api.github.com/users/KaviSanth/following{/other_user}", "gists_url": "https://api.github.com/users/KaviSanth/gists{/gist_id}", "starred_url": "https://api.github.com/users/KaviSanth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KaviSanth/subscriptions", "organizations_url": "https://api.github.com/users/KaviSanth/orgs", "repos_url": "https://api.github.com/users/KaviSanth/repos", "events_url": "https://api.github.com/users/KaviSanth/events{/privacy}", "received_events_url": "https://api.github.com/users/KaviSanth/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-20T11:09:52Z", "updated_at": "2018-09-20T11:09:52Z", "author_association": "NONE", "body_html": "<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3376817\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrewharp\">@andrewharp</a> Thank you so much for your cutosm inference class <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java\">TFLiteObjectDetectionAPIModel.java</a> , I've tried it with your ssd mobilenet v1 tflite <a href=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_ssd_tflite_v1.zip\" rel=\"nofollow\">mobilenet_ssd_tflite_v1.zip</a> but when the app starts seems there is problem in the function recognizeImage(final Bitmap bitmap) when i call tfLite.runForMultipleInputsOutputs(inputArray, outputMap); it throws this exception</p>\n<pre><code>07-18 10:37:02.416 19957-19996/com.app.cerist.realtimeobjectdetectionapi E/AndroidRuntime: FATAL EXCEPTION: Camera\n    Process: com.app.cerist.realtimeobjectdetectionapi, PID: 19957\n    java.lang.IllegalArgumentException: Output error: Outputs do not match with model outputs.\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:170)\n        at com.app.cerist.realtimeobjectdetectionapi.ImageClassifierTFLiteAPI.recognizeImage(ImageClassifierTFLiteAPI.java:207)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.classifyFrame(MainActivity.java:421)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.access$1000(MainActivity.java:48)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity$4.run(MainActivity.java:455)\n        at android.os.Handler.handleCallback(Handler.java:739)\n        at android.os.Handler.dispatchMessage(Handler.java:95)\n        at android.os.Looper.loop(Looper.java:159)\n        at android.os.HandlerThread.run(HandlerThread.java:61)\n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi V/Process: killProcess [19957] Callers=com.android.internal.os.RuntimeInit$UncaughtHandler.uncaughtException:99 java.lang.ThreadGroup.uncaughtException:693 java.lang.ThreadGroup.uncaughtException:690 &lt;bottom of call stack&gt; \n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi I/Process: Sending signal. PID: 19957 SIG: 9\n</code></pre>\n<p>the error said that the length of outputs array is bigger than the length of inputs array<br>\nHere is the condition in Interpreter.java</p>\n<pre><code>public void runForMultipleInputsOutputs(Object[] inputs, @NonNull Map&lt;Integer, Object&gt; outputs) {\n        if (this.wrapper == null) {\n            throw new IllegalStateException(\"Internal error: The Interpreter has already been closed.\");\n        } else {\n            Tensor[] tensors = this.wrapper.run(inputs);\n            if (outputs != null &amp;&amp; tensors != null &amp;&amp; outputs.size() &lt;= tensors.length) {\n                int size = tensors.length;\n                Iterator var5 = outputs.keySet().iterator();\n            }\n       }\n}\n</code></pre>\n<p>and this is my inputs and outputs arrays :</p>\n<pre><code>d.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\nd.imgData.order(ByteOrder.nativeOrder());\nd.intValues = new int[d.inputSize * d.inputSize];\n</code></pre>\n<pre><code> imgData.rewind();\n        for (int i = 0; i &lt; inputSize; ++i) {\n            for (int j = 0; j &lt; inputSize; ++j) {\n                int pixelValue = intValues[i * inputSize + j];\n                if (isModelQuantized) {\n                    // Quantized model\n                    imgData.put((byte) ((pixelValue &gt;&gt; 16) &amp; 0xFF));\n                    imgData.put((byte) ((pixelValue &gt;&gt; 8) &amp; 0xFF));\n                    imgData.put((byte) (pixelValue &amp; 0xFF));\n                } else { // Float model\n                    imgData.putFloat((((pixelValue &gt;&gt; 16) &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n                    imgData.putFloat((((pixelValue &gt;&gt; 8) &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n                    imgData.putFloat(((pixelValue &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n</code></pre>\n<p>The outputs array :</p>\n<pre><code>// Copy the input data into TensorFlow.\n        Trace.beginSection(\"feed\");\n        outputLocations = new float[1][NUM_DETECTIONS][4];\n        outputClasses = new float[1][NUM_DETECTIONS];\n        outputScores = new float[1][NUM_DETECTIONS];\n        numDetections = new float[1];\n\n        Object[] inputArray = {imgData};\n        Map&lt;Integer, Object&gt; outputMap = new HashMap&lt;&gt;();\n        outputMap.put(0, outputLocations);\n        outputMap.put(1, outputScores);\n        outputMap.put(2, numDetections);\n        outputMap.put(3, outputClasses);\n        Trace.endSection();\n</code></pre>\n<p>And the Inference :</p>\n<pre><code>// Run the inference call.\n        Trace.beginSection(\"run\");\n        Log.d(\"TAG_INPUT\",\"\"+String.valueOf(inputArray.length));\n        Log.d(\"TAG_OUTPUT\",\"\"+String.valueOf(outputMap.size()));\n\n        tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\n        Trace.endSection();\n</code></pre>\n<p>I didn't understand the meaning of this Error cuz i did exactly the same as your TFLiteObjectDetectionAPIModel.java class .<br>\nthank you for Help</p>\n</blockquote>\n<p>i have the same issue.. got solution?<br>\nthanks..</p>", "body_text": "@andrewharp Thank you so much for your cutosm inference class TFLiteObjectDetectionAPIModel.java , I've tried it with your ssd mobilenet v1 tflite mobilenet_ssd_tflite_v1.zip but when the app starts seems there is problem in the function recognizeImage(final Bitmap bitmap) when i call tfLite.runForMultipleInputsOutputs(inputArray, outputMap); it throws this exception\n07-18 10:37:02.416 19957-19996/com.app.cerist.realtimeobjectdetectionapi E/AndroidRuntime: FATAL EXCEPTION: Camera\n    Process: com.app.cerist.realtimeobjectdetectionapi, PID: 19957\n    java.lang.IllegalArgumentException: Output error: Outputs do not match with model outputs.\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:170)\n        at com.app.cerist.realtimeobjectdetectionapi.ImageClassifierTFLiteAPI.recognizeImage(ImageClassifierTFLiteAPI.java:207)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.classifyFrame(MainActivity.java:421)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.access$1000(MainActivity.java:48)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity$4.run(MainActivity.java:455)\n        at android.os.Handler.handleCallback(Handler.java:739)\n        at android.os.Handler.dispatchMessage(Handler.java:95)\n        at android.os.Looper.loop(Looper.java:159)\n        at android.os.HandlerThread.run(HandlerThread.java:61)\n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi V/Process: killProcess [19957] Callers=com.android.internal.os.RuntimeInit$UncaughtHandler.uncaughtException:99 java.lang.ThreadGroup.uncaughtException:693 java.lang.ThreadGroup.uncaughtException:690 <bottom of call stack> \n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi I/Process: Sending signal. PID: 19957 SIG: 9\n\nthe error said that the length of outputs array is bigger than the length of inputs array\nHere is the condition in Interpreter.java\npublic void runForMultipleInputsOutputs(Object[] inputs, @NonNull Map<Integer, Object> outputs) {\n        if (this.wrapper == null) {\n            throw new IllegalStateException(\"Internal error: The Interpreter has already been closed.\");\n        } else {\n            Tensor[] tensors = this.wrapper.run(inputs);\n            if (outputs != null && tensors != null && outputs.size() <= tensors.length) {\n                int size = tensors.length;\n                Iterator var5 = outputs.keySet().iterator();\n            }\n       }\n}\n\nand this is my inputs and outputs arrays :\nd.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\nd.imgData.order(ByteOrder.nativeOrder());\nd.intValues = new int[d.inputSize * d.inputSize];\n\n imgData.rewind();\n        for (int i = 0; i < inputSize; ++i) {\n            for (int j = 0; j < inputSize; ++j) {\n                int pixelValue = intValues[i * inputSize + j];\n                if (isModelQuantized) {\n                    // Quantized model\n                    imgData.put((byte) ((pixelValue >> 16) & 0xFF));\n                    imgData.put((byte) ((pixelValue >> 8) & 0xFF));\n                    imgData.put((byte) (pixelValue & 0xFF));\n                } else { // Float model\n                    imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n                    imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n                    imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n\nThe outputs array :\n// Copy the input data into TensorFlow.\n        Trace.beginSection(\"feed\");\n        outputLocations = new float[1][NUM_DETECTIONS][4];\n        outputClasses = new float[1][NUM_DETECTIONS];\n        outputScores = new float[1][NUM_DETECTIONS];\n        numDetections = new float[1];\n\n        Object[] inputArray = {imgData};\n        Map<Integer, Object> outputMap = new HashMap<>();\n        outputMap.put(0, outputLocations);\n        outputMap.put(1, outputScores);\n        outputMap.put(2, numDetections);\n        outputMap.put(3, outputClasses);\n        Trace.endSection();\n\nAnd the Inference :\n// Run the inference call.\n        Trace.beginSection(\"run\");\n        Log.d(\"TAG_INPUT\",\"\"+String.valueOf(inputArray.length));\n        Log.d(\"TAG_OUTPUT\",\"\"+String.valueOf(outputMap.size()));\n\n        tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\n        Trace.endSection();\n\nI didn't understand the meaning of this Error cuz i did exactly the same as your TFLiteObjectDetectionAPIModel.java class .\nthank you for Help\n\ni have the same issue.. got solution?\nthanks..", "body": "> @andrewharp Thank you so much for your cutosm inference class [TFLiteObjectDetectionAPIModel.java](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java) , I've tried it with your ssd mobilenet v1 tflite [mobilenet_ssd_tflite_v1.zip](https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_ssd_tflite_v1.zip) but when the app starts seems there is problem in the function recognizeImage(final Bitmap bitmap) when i call tfLite.runForMultipleInputsOutputs(inputArray, outputMap); it throws this exception\r\n> \r\n> ```\r\n> 07-18 10:37:02.416 19957-19996/com.app.cerist.realtimeobjectdetectionapi E/AndroidRuntime: FATAL EXCEPTION: Camera\r\n>     Process: com.app.cerist.realtimeobjectdetectionapi, PID: 19957\r\n>     java.lang.IllegalArgumentException: Output error: Outputs do not match with model outputs.\r\n>         at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:170)\r\n>         at com.app.cerist.realtimeobjectdetectionapi.ImageClassifierTFLiteAPI.recognizeImage(ImageClassifierTFLiteAPI.java:207)\r\n>         at com.app.cerist.realtimeobjectdetectionapi.MainActivity.classifyFrame(MainActivity.java:421)\r\n>         at com.app.cerist.realtimeobjectdetectionapi.MainActivity.access$1000(MainActivity.java:48)\r\n>         at com.app.cerist.realtimeobjectdetectionapi.MainActivity$4.run(MainActivity.java:455)\r\n>         at android.os.Handler.handleCallback(Handler.java:739)\r\n>         at android.os.Handler.dispatchMessage(Handler.java:95)\r\n>         at android.os.Looper.loop(Looper.java:159)\r\n>         at android.os.HandlerThread.run(HandlerThread.java:61)\r\n> 07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi V/Process: killProcess [19957] Callers=com.android.internal.os.RuntimeInit$UncaughtHandler.uncaughtException:99 java.lang.ThreadGroup.uncaughtException:693 java.lang.ThreadGroup.uncaughtException:690 <bottom of call stack> \r\n> 07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi I/Process: Sending signal. PID: 19957 SIG: 9\r\n> ```\r\n> the error said that the length of outputs array is bigger than the length of inputs array\r\n> Here is the condition in Interpreter.java\r\n> \r\n> ```\r\n> public void runForMultipleInputsOutputs(Object[] inputs, @NonNull Map<Integer, Object> outputs) {\r\n>         if (this.wrapper == null) {\r\n>             throw new IllegalStateException(\"Internal error: The Interpreter has already been closed.\");\r\n>         } else {\r\n>             Tensor[] tensors = this.wrapper.run(inputs);\r\n>             if (outputs != null && tensors != null && outputs.size() <= tensors.length) {\r\n>                 int size = tensors.length;\r\n>                 Iterator var5 = outputs.keySet().iterator();\r\n>             }\r\n>        }\r\n> }\r\n> ```\r\n> and this is my inputs and outputs arrays :\r\n> \r\n> ```\r\n> d.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\r\n> d.imgData.order(ByteOrder.nativeOrder());\r\n> d.intValues = new int[d.inputSize * d.inputSize];\r\n> ```\r\n> ```\r\n>  imgData.rewind();\r\n>         for (int i = 0; i < inputSize; ++i) {\r\n>             for (int j = 0; j < inputSize; ++j) {\r\n>                 int pixelValue = intValues[i * inputSize + j];\r\n>                 if (isModelQuantized) {\r\n>                     // Quantized model\r\n>                     imgData.put((byte) ((pixelValue >> 16) & 0xFF));\r\n>                     imgData.put((byte) ((pixelValue >> 8) & 0xFF));\r\n>                     imgData.put((byte) (pixelValue & 0xFF));\r\n>                 } else { // Float model\r\n>                     imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n>                     imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n>                     imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n> ```\r\n> The outputs array :\r\n> \r\n> ```\r\n> // Copy the input data into TensorFlow.\r\n>         Trace.beginSection(\"feed\");\r\n>         outputLocations = new float[1][NUM_DETECTIONS][4];\r\n>         outputClasses = new float[1][NUM_DETECTIONS];\r\n>         outputScores = new float[1][NUM_DETECTIONS];\r\n>         numDetections = new float[1];\r\n> \r\n>         Object[] inputArray = {imgData};\r\n>         Map<Integer, Object> outputMap = new HashMap<>();\r\n>         outputMap.put(0, outputLocations);\r\n>         outputMap.put(1, outputScores);\r\n>         outputMap.put(2, numDetections);\r\n>         outputMap.put(3, outputClasses);\r\n>         Trace.endSection();\r\n> ```\r\n> And the Inference :\r\n> \r\n> ```\r\n> // Run the inference call.\r\n>         Trace.beginSection(\"run\");\r\n>         Log.d(\"TAG_INPUT\",\"\"+String.valueOf(inputArray.length));\r\n>         Log.d(\"TAG_OUTPUT\",\"\"+String.valueOf(outputMap.size()));\r\n> \r\n>         tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\r\n>         Trace.endSection();\r\n> ```\r\n> I didn't understand the meaning of this Error cuz i did exactly the same as your TFLiteObjectDetectionAPIModel.java class .\r\n> thank you for Help\r\n\r\ni have the same issue.. got solution?\r\nthanks.."}