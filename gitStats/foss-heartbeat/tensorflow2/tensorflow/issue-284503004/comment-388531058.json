{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/388531058", "html_url": "https://github.com/tensorflow/tensorflow/issues/15633#issuecomment-388531058", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15633", "id": 388531058, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODUzMTA1OA==", "user": {"login": "Haijunlv", "id": 28926237, "node_id": "MDQ6VXNlcjI4OTI2MjM3", "avatar_url": "https://avatars2.githubusercontent.com/u/28926237?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Haijunlv", "html_url": "https://github.com/Haijunlv", "followers_url": "https://api.github.com/users/Haijunlv/followers", "following_url": "https://api.github.com/users/Haijunlv/following{/other_user}", "gists_url": "https://api.github.com/users/Haijunlv/gists{/gist_id}", "starred_url": "https://api.github.com/users/Haijunlv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Haijunlv/subscriptions", "organizations_url": "https://api.github.com/users/Haijunlv/orgs", "repos_url": "https://api.github.com/users/Haijunlv/repos", "events_url": "https://api.github.com/users/Haijunlv/events{/privacy}", "received_events_url": "https://api.github.com/users/Haijunlv/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-12T05:21:45Z", "updated_at": "2018-05-12T05:22:32Z", "author_association": "NONE", "body_html": "<p>@Eddy-zheng If you saw the node \"concat\"  in the frozen graph, you will find the squeeze op is excuted after concat op. I think that is the reason why the shape is incompatable. I did not test the speed of the squeeze op. But I think there are two ways to solve the problem.</p>\n<ol>\n<li>change the order of squeeze and concat op. In the ssd_meta_arch.py, slightly change \" box_encodings = tf.squeeze(tf.concat(prediction_dict['box_encodings'], axis=1), axis=2)\"</li>\n<li>directly kill the shape 1 at the axis 2. In the box_predictor.py, slightly change \" box_encodings =tf.reshape(<br>\nbox_encodings, tf.stack([combined_feature_map_shape[0],<br>\ncombined_feature_map_shape[1] *<br>\ncombined_feature_map_shape[2] *<br>\nnum_predictions_per_location,<br>\n1, self._box_code_size]))\"</li>\n</ol>\n<p>Actually i donot understand the reason why reshape tensor with extra \"1\" shape. May be it is a redundant<br>\nop.<br>\nI have tried way 1 and success to run model in mobile. But still a little slow.  later i will try way 2 to see if it can get a better speed</p>", "body_text": "@Eddy-zheng If you saw the node \"concat\"  in the frozen graph, you will find the squeeze op is excuted after concat op. I think that is the reason why the shape is incompatable. I did not test the speed of the squeeze op. But I think there are two ways to solve the problem.\n\nchange the order of squeeze and concat op. In the ssd_meta_arch.py, slightly change \" box_encodings = tf.squeeze(tf.concat(prediction_dict['box_encodings'], axis=1), axis=2)\"\ndirectly kill the shape 1 at the axis 2. In the box_predictor.py, slightly change \" box_encodings =tf.reshape(\nbox_encodings, tf.stack([combined_feature_map_shape[0],\ncombined_feature_map_shape[1] *\ncombined_feature_map_shape[2] *\nnum_predictions_per_location,\n1, self._box_code_size]))\"\n\nActually i donot understand the reason why reshape tensor with extra \"1\" shape. May be it is a redundant\nop.\nI have tried way 1 and success to run model in mobile. But still a little slow.  later i will try way 2 to see if it can get a better speed", "body": "@Eddy-zheng If you saw the node \"concat\"  in the frozen graph, you will find the squeeze op is excuted after concat op. I think that is the reason why the shape is incompatable. I did not test the speed of the squeeze op. But I think there are two ways to solve the problem.\r\n1. change the order of squeeze and concat op. In the ssd_meta_arch.py, slightly change \" box_encodings = tf.squeeze(tf.concat(prediction_dict['box_encodings'], axis=1), axis=2)\"\r\n2. directly kill the shape 1 at the axis 2. In the box_predictor.py, slightly change \" box_encodings =tf.reshape(\r\n            box_encodings, tf.stack([combined_feature_map_shape[0],\r\n            combined_feature_map_shape[1] *\r\n            combined_feature_map_shape[2] *\r\n            num_predictions_per_location,\r\n            1, self._box_code_size]))\"\r\n\r\nActually i donot understand the reason why reshape tensor with extra \"1\" shape. May be it is a redundant\r\nop. \r\nI have tried way 1 and success to run model in mobile. But still a little slow.  later i will try way 2 to see if it can get a better speed \r\n\r\n "}