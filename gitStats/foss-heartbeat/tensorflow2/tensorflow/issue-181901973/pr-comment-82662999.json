{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/82662999", "pull_request_review_id": 3553109, "id": 82662999, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDgyNjYyOTk5", "diff_hunk": "@@ -301,26 +306,35 @@ def __init__(self, queue, ev_writer, flush_secs):\n     \"\"\"\n     threading.Thread.__init__(self)\n     self.daemon = True\n+    self._stop_flag = False\n     self._queue = queue\n     self._ev_writer = ev_writer\n     self._flush_secs = flush_secs\n     # The first event will be flushed immediately.\n     self._next_event_flush_time = 0\n+    self._fetch_timeout = 1\n \n   def run(self):\n     while True:\n-      event = self._queue.get()\n+      event = self._queue.get(timeout=self._fetch_timeout)\n       try:\n-        self._ev_writer.WriteEvent(event)\n+        if event:\n+          self._ev_writer.WriteEvent(event)\n         # Flush the event writer every so often.\n         now = time.time()\n-        if now > self._next_event_flush_time:\n+        if now > self._next_event_flush_time or self._stop_flag:\n           self._ev_writer.Flush()\n           # Do it again in two minutes.\n           self._next_event_flush_time = now + self._flush_secs\n       finally:\n         self._queue.task_done()\n \n+      if self._stop_flag:\n+        break", "path": "tensorflow/python/summary/summary_iterator.py", "position": null, "original_position": 47, "commit_id": "17ac36d8d88da3a691eda9f6c3d5739fc2888194", "original_commit_id": "65a4bf0c96061c50f9e0da1a5328df21a364c7d3", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "body": "This code has at least one race condition. To avoid corruption and lost records, we should maintain the invariant that all events logged before `stop()` is called are written to the file before `stop()` returns.\n1. Events written before `stop()` is called may or may not be dropped (e.g. `n - 1` events will be dropped if there are `n > 1` elements in the queue when `stop()` is called). We should drain the queue before the thread terminates.\n2. Consider what happens if this thread checks the stop flag and finds it to be `false`,  gets preempted, another thread calls `stop()`, then this thread is scheduled again and calls `self._queue.get()`... which will only block for a second (thanks to `self._fetch_timeout`).\n\nA cleaner option would be to put a sentinel object into the queue, and use that to detect that the writer has stopped, rather than reading the flag. We probably still need the flag to prevent enqueuing after `stop()`, but it will probably need to be protected with a lock, as setting the flag and writing the sentinel on `stop()`; and reading the flag on `write()` ought to be atomic.\n", "created_at": "2016-10-10T18:56:24Z", "updated_at": "2016-10-16T11:02:14Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4860#discussion_r82662999", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4860", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/82662999"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4860#discussion_r82662999"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4860"}}, "body_html": "<p>This code has at least one race condition. To avoid corruption and lost records, we should maintain the invariant that all events logged before <code>stop()</code> is called are written to the file before <code>stop()</code> returns.</p>\n<ol>\n<li>Events written before <code>stop()</code> is called may or may not be dropped (e.g. <code>n - 1</code> events will be dropped if there are <code>n &gt; 1</code> elements in the queue when <code>stop()</code> is called). We should drain the queue before the thread terminates.</li>\n<li>Consider what happens if this thread checks the stop flag and finds it to be <code>false</code>,  gets preempted, another thread calls <code>stop()</code>, then this thread is scheduled again and calls <code>self._queue.get()</code>... which will only block for a second (thanks to <code>self._fetch_timeout</code>).</li>\n</ol>\n<p>A cleaner option would be to put a sentinel object into the queue, and use that to detect that the writer has stopped, rather than reading the flag. We probably still need the flag to prevent enqueuing after <code>stop()</code>, but it will probably need to be protected with a lock, as setting the flag and writing the sentinel on <code>stop()</code>; and reading the flag on <code>write()</code> ought to be atomic.</p>", "body_text": "This code has at least one race condition. To avoid corruption and lost records, we should maintain the invariant that all events logged before stop() is called are written to the file before stop() returns.\n\nEvents written before stop() is called may or may not be dropped (e.g. n - 1 events will be dropped if there are n > 1 elements in the queue when stop() is called). We should drain the queue before the thread terminates.\nConsider what happens if this thread checks the stop flag and finds it to be false,  gets preempted, another thread calls stop(), then this thread is scheduled again and calls self._queue.get()... which will only block for a second (thanks to self._fetch_timeout).\n\nA cleaner option would be to put a sentinel object into the queue, and use that to detect that the writer has stopped, rather than reading the flag. We probably still need the flag to prevent enqueuing after stop(), but it will probably need to be protected with a lock, as setting the flag and writing the sentinel on stop(); and reading the flag on write() ought to be atomic."}