{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22095", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22095/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22095/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22095/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22095", "id": 357262504, "node_id": "MDU6SXNzdWUzNTcyNjI1MDQ=", "number": 22095, "title": "3D convolutions on GPU with large input produces incorrect results on some GPUs", "user": {"login": "gerbenvv", "id": 1511521, "node_id": "MDQ6VXNlcjE1MTE1MjE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1511521?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gerbenvv", "html_url": "https://github.com/gerbenvv", "followers_url": "https://api.github.com/users/gerbenvv/followers", "following_url": "https://api.github.com/users/gerbenvv/following{/other_user}", "gists_url": "https://api.github.com/users/gerbenvv/gists{/gist_id}", "starred_url": "https://api.github.com/users/gerbenvv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gerbenvv/subscriptions", "organizations_url": "https://api.github.com/users/gerbenvv/orgs", "repos_url": "https://api.github.com/users/gerbenvv/repos", "events_url": "https://api.github.com/users/gerbenvv/events{/privacy}", "received_events_url": "https://api.github.com/users/gerbenvv/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-09-05T14:41:12Z", "updated_at": "2018-11-20T19:50:04Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes, see reproduction script below.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04.5 LTS</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary via pip</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.1</li>\n<li><strong>Python version</strong>: 3.6.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: GCC 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.0 / cuDNN 7.2</li>\n<li><strong>GPU model and memory</strong>: GTX 1080 Ti</li>\n<li><strong>Exact command to reproduce</strong>: See script below.</li>\n</ul>\n<pre><code>== cat /etc/issue ===============================================\nLinux gpu01 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux gpu01 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy                    1.14.2\nprotobuf                 3.6.1\ntensorflow-gpu           1.10.1\ntensorflow-tensorboard   1.5.1\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.10.1\ntf.GIT_VERSION = v1.10.1-0-g4dcfddc5d1\ntf.COMPILER_VERSION = v1.10.1-0-g4dcfddc5d1\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda/lib64\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nWed Sep  5 16:19:24 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\n| 23%   38C    P0    64W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 108...  On   | 00000000:05:00.0 Off |                  N/A |\n| 23%   36C    P2    65W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 108...  On   | 00000000:08:00.0 Off |                  N/A |\n| 23%   42C    P0    77W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX 108...  On   | 00000000:09:00.0 Off |                  N/A |\n| 23%   42C    P0    63W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   4  GeForce GTX 108...  On   | 00000000:85:00.0 Off |                  N/A |\n| 23%   35C    P0    63W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   5  GeForce GTX 108...  On   | 00000000:86:00.0 Off |                  N/A |\n| 23%   38C    P0    73W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   6  GeForce GTX 108...  On   | 00000000:89:00.0 Off |                  N/A |\n| 23%   38C    P0    72W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   7  GeForce GTX 108...  On   | 00000000:8A:00.0 Off |                  N/A |\n| 23%   36C    P0    71W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart.so.9.1.85\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart_static.a\n</code></pre>\n<h3>Describe the problem</h3>\n<p>3D convolutions on GPU with large batches fail to calculate the correct result for the last part of the batch. The first entries will be correct, however, after some point the resulting values will be random. This is the case for at least the GTX 1080 Ti and the GeForce GTX 980 Ti gpus. It produces the correct result however on the CPU and at least the K80 GPU.</p>\n<h3>Source code / logs</h3>\n<p>A small reproduction script:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\n\n\nrun_on_gpu = True  # Set to false for the correct result, computed on the CPU.\nbatch_size = 128  # Try out a large batch, that just fits into memory. Small batches work fine.\n\n\n\nrandom_state = np.random.RandomState(42)\n\ninputs = tf.placeholder(tf.float32, (None, 29, 72, 72, 1), 'inputs')\n\ndevice_name = '/gpu:0' if run_on_gpu else '/cpu:0'\n\nwith tf.device(device_name):\n    weights = tf.constant(random_state.randn(3, 3, 3, 1, 32).astype(np.float32))\n    outputs = tf.nn.conv3d(inputs, weights, strides=(1, 1, 1, 1, 1), padding='SAME', dilations=(1, 1, 1, 1, 1))\n    weights = tf.constant(random_state.randn(1, 1, 1, 32, 16).astype(np.float32))\n    outputs = tf.nn.conv3d(outputs, weights, strides=(1, 1, 1, 1, 1), padding='VALID', dilations=(1, 1, 1, 1, 1))\n\nsession = tf.Session()\n\nrandom_inputs = random_state.randn(batch_size, 29, 72, 72, 1).astype(np.float32)\n\na = session.run(outputs, feed_dict={inputs: random_inputs})[-1]\nb = session.run(outputs, feed_dict={inputs: random_inputs[-1:]})[0]\n\n# Should print the same line, twice.\nprint(a.shape, a.ravel()[0])\nprint(b.shape, b.ravel()[0])\n</code></pre>\n<p>This script should print the same line twice.</p>\n<p>Expected result:</p>\n<pre><code>(29, 72, 72, 16) -5.843975\n(29, 72, 72, 16) -5.843975\n</code></pre>\n<p>Actual result:</p>\n<pre><code>(29, 72, 72, 16) -4.591032\n(29, 72, 72, 16) -5.843975\n</code></pre>\n<p>Run on a GeForce GTX 1080 Ti:</p>\n<pre><code>Python 3.6.3\nTensorflow 1.10.1\nNumpy 1.15.1\n\n2018-09-05 15:55:27.172809: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-05 15:55:27.685907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:8a:00.0\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\n2018-09-05 15:55:27.685952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-09-05 15:55:28.161475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-09-05 15:55:28.161524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n2018-09-05 15:55:28.161532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n2018-09-05 15:55:28.161948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10398 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1)\n\n(29, 72, 72, 16) -4.591032\n(29, 72, 72, 16) -5.843975\n</code></pre>\n<p>Run on a GeForce GTX 980 Ti:</p>\n<pre><code>Python 3.6.3\nTensorflow 1.5.1\nNumpy 1.14.2\n\n2018-09-05 16:05:54.557373: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-05 16:05:57.096399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\nname: GeForce GTX 980 Ti major: 5 minor: 2 memoryClockRate(GHz): 1.076\npciBusID: 0000:02:00.0\ntotalMemory: 5.94GiB freeMemory: 5.83GiB\n2018-09-05 16:05:57.096467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:02:00.0, compute capability: 5.2)\n\n(29, 72, 72, 16) -4.591032\n(29, 72, 72, 16) -5.843975\n</code></pre>\n<p>Run on a K80:</p>\n<pre><code>Python 3.6.5\nTensorflow 1.5.1\nNumpy 1.15.0\n\n2018-09-05 14:37:31.279189: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-05 14:37:32.131417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-09-05 14:37:32.131763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:1e.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2018-09-05 14:37:32.131795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\n\n(29, 72, 72, 16) -5.843975\n(29, 72, 72, 16) -5.843975\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see reproduction script below.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.5 LTS\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): Binary via pip\nTensorFlow version (use command below): 1.10.1\nPython version: 3.6.3\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): GCC 5.4.0\nCUDA/cuDNN version: CUDA 9.0 / cuDNN 7.2\nGPU model and memory: GTX 1080 Ti\nExact command to reproduce: See script below.\n\n== cat /etc/issue ===============================================\nLinux gpu01 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux gpu01 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy                    1.14.2\nprotobuf                 3.6.1\ntensorflow-gpu           1.10.1\ntensorflow-tensorboard   1.5.1\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.10.1\ntf.GIT_VERSION = v1.10.1-0-g4dcfddc5d1\ntf.COMPILER_VERSION = v1.10.1-0-g4dcfddc5d1\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda/lib64\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nWed Sep  5 16:19:24 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\n| 23%   38C    P0    64W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 108...  On   | 00000000:05:00.0 Off |                  N/A |\n| 23%   36C    P2    65W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 108...  On   | 00000000:08:00.0 Off |                  N/A |\n| 23%   42C    P0    77W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX 108...  On   | 00000000:09:00.0 Off |                  N/A |\n| 23%   42C    P0    63W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   4  GeForce GTX 108...  On   | 00000000:85:00.0 Off |                  N/A |\n| 23%   35C    P0    63W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   5  GeForce GTX 108...  On   | 00000000:86:00.0 Off |                  N/A |\n| 23%   38C    P0    73W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   6  GeForce GTX 108...  On   | 00000000:89:00.0 Off |                  N/A |\n| 23%   38C    P0    72W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   7  GeForce GTX 108...  On   | 00000000:8A:00.0 Off |                  N/A |\n| 23%   36C    P0    71W / 250W |      1MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart.so.9.1.85\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart_static.a\n\nDescribe the problem\n3D convolutions on GPU with large batches fail to calculate the correct result for the last part of the batch. The first entries will be correct, however, after some point the resulting values will be random. This is the case for at least the GTX 1080 Ti and the GeForce GTX 980 Ti gpus. It produces the correct result however on the CPU and at least the K80 GPU.\nSource code / logs\nA small reproduction script:\nimport tensorflow as tf\nimport numpy as np\n\n\n\nrun_on_gpu = True  # Set to false for the correct result, computed on the CPU.\nbatch_size = 128  # Try out a large batch, that just fits into memory. Small batches work fine.\n\n\n\nrandom_state = np.random.RandomState(42)\n\ninputs = tf.placeholder(tf.float32, (None, 29, 72, 72, 1), 'inputs')\n\ndevice_name = '/gpu:0' if run_on_gpu else '/cpu:0'\n\nwith tf.device(device_name):\n    weights = tf.constant(random_state.randn(3, 3, 3, 1, 32).astype(np.float32))\n    outputs = tf.nn.conv3d(inputs, weights, strides=(1, 1, 1, 1, 1), padding='SAME', dilations=(1, 1, 1, 1, 1))\n    weights = tf.constant(random_state.randn(1, 1, 1, 32, 16).astype(np.float32))\n    outputs = tf.nn.conv3d(outputs, weights, strides=(1, 1, 1, 1, 1), padding='VALID', dilations=(1, 1, 1, 1, 1))\n\nsession = tf.Session()\n\nrandom_inputs = random_state.randn(batch_size, 29, 72, 72, 1).astype(np.float32)\n\na = session.run(outputs, feed_dict={inputs: random_inputs})[-1]\nb = session.run(outputs, feed_dict={inputs: random_inputs[-1:]})[0]\n\n# Should print the same line, twice.\nprint(a.shape, a.ravel()[0])\nprint(b.shape, b.ravel()[0])\n\nThis script should print the same line twice.\nExpected result:\n(29, 72, 72, 16) -5.843975\n(29, 72, 72, 16) -5.843975\n\nActual result:\n(29, 72, 72, 16) -4.591032\n(29, 72, 72, 16) -5.843975\n\nRun on a GeForce GTX 1080 Ti:\nPython 3.6.3\nTensorflow 1.10.1\nNumpy 1.15.1\n\n2018-09-05 15:55:27.172809: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-05 15:55:27.685907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:8a:00.0\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\n2018-09-05 15:55:27.685952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-09-05 15:55:28.161475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-09-05 15:55:28.161524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n2018-09-05 15:55:28.161532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n2018-09-05 15:55:28.161948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10398 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1)\n\n(29, 72, 72, 16) -4.591032\n(29, 72, 72, 16) -5.843975\n\nRun on a GeForce GTX 980 Ti:\nPython 3.6.3\nTensorflow 1.5.1\nNumpy 1.14.2\n\n2018-09-05 16:05:54.557373: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-05 16:05:57.096399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\nname: GeForce GTX 980 Ti major: 5 minor: 2 memoryClockRate(GHz): 1.076\npciBusID: 0000:02:00.0\ntotalMemory: 5.94GiB freeMemory: 5.83GiB\n2018-09-05 16:05:57.096467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:02:00.0, compute capability: 5.2)\n\n(29, 72, 72, 16) -4.591032\n(29, 72, 72, 16) -5.843975\n\nRun on a K80:\nPython 3.6.5\nTensorflow 1.5.1\nNumpy 1.15.0\n\n2018-09-05 14:37:31.279189: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-09-05 14:37:32.131417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-09-05 14:37:32.131763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:1e.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2018-09-05 14:37:32.131795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\n\n(29, 72, 72, 16) -5.843975\n(29, 72, 72, 16) -5.843975", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see reproduction script below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.5 LTS\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Binary via pip\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: GCC 5.4.0\r\n- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.2\r\n- **GPU model and memory**: GTX 1080 Ti\r\n- **Exact command to reproduce**: See script below.\r\n\r\n```\r\n== cat /etc/issue ===============================================\r\nLinux gpu01 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux gpu01 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy                    1.14.2\r\nprotobuf                 3.6.1\r\ntensorflow-gpu           1.10.1\r\ntensorflow-tensorboard   1.5.1\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.1\r\ntf.GIT_VERSION = v1.10.1-0-g4dcfddc5d1\r\ntf.COMPILER_VERSION = v1.10.1-0-g4dcfddc5d1\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Sep  5 16:19:24 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\r\n| 23%   38C    P0    64W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  On   | 00000000:05:00.0 Off |                  N/A |\r\n| 23%   36C    P2    65W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 108...  On   | 00000000:08:00.0 Off |                  N/A |\r\n| 23%   42C    P0    77W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 108...  On   | 00000000:09:00.0 Off |                  N/A |\r\n| 23%   42C    P0    63W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  GeForce GTX 108...  On   | 00000000:85:00.0 Off |                  N/A |\r\n| 23%   35C    P0    63W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  GeForce GTX 108...  On   | 00000000:86:00.0 Off |                  N/A |\r\n| 23%   38C    P0    73W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  GeForce GTX 108...  On   | 00000000:89:00.0 Off |                  N/A |\r\n| 23%   38C    P0    72W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  GeForce GTX 108...  On   | 00000000:8A:00.0 Off |                  N/A |\r\n| 23%   36C    P0    71W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart.so.9.1.85\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart_static.a\r\n```\r\n\r\n### Describe the problem\r\n3D convolutions on GPU with large batches fail to calculate the correct result for the last part of the batch. The first entries will be correct, however, after some point the resulting values will be random. This is the case for at least the GTX 1080 Ti and the GeForce GTX 980 Ti gpus. It produces the correct result however on the CPU and at least the K80 GPU.\r\n\r\n### Source code / logs\r\n\r\nA small reproduction script:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\n\r\nrun_on_gpu = True  # Set to false for the correct result, computed on the CPU.\r\nbatch_size = 128  # Try out a large batch, that just fits into memory. Small batches work fine.\r\n\r\n\r\n\r\nrandom_state = np.random.RandomState(42)\r\n\r\ninputs = tf.placeholder(tf.float32, (None, 29, 72, 72, 1), 'inputs')\r\n\r\ndevice_name = '/gpu:0' if run_on_gpu else '/cpu:0'\r\n\r\nwith tf.device(device_name):\r\n    weights = tf.constant(random_state.randn(3, 3, 3, 1, 32).astype(np.float32))\r\n    outputs = tf.nn.conv3d(inputs, weights, strides=(1, 1, 1, 1, 1), padding='SAME', dilations=(1, 1, 1, 1, 1))\r\n    weights = tf.constant(random_state.randn(1, 1, 1, 32, 16).astype(np.float32))\r\n    outputs = tf.nn.conv3d(outputs, weights, strides=(1, 1, 1, 1, 1), padding='VALID', dilations=(1, 1, 1, 1, 1))\r\n\r\nsession = tf.Session()\r\n\r\nrandom_inputs = random_state.randn(batch_size, 29, 72, 72, 1).astype(np.float32)\r\n\r\na = session.run(outputs, feed_dict={inputs: random_inputs})[-1]\r\nb = session.run(outputs, feed_dict={inputs: random_inputs[-1:]})[0]\r\n\r\n# Should print the same line, twice.\r\nprint(a.shape, a.ravel()[0])\r\nprint(b.shape, b.ravel()[0])\r\n```\r\n\r\nThis script should print the same line twice.\r\n\r\nExpected result:\r\n```\r\n(29, 72, 72, 16) -5.843975\r\n(29, 72, 72, 16) -5.843975\r\n```\r\n\r\nActual result:\r\n```\r\n(29, 72, 72, 16) -4.591032\r\n(29, 72, 72, 16) -5.843975\r\n```\r\n\r\nRun on a GeForce GTX 1080 Ti:\r\n\r\n```\r\nPython 3.6.3\r\nTensorflow 1.10.1\r\nNumpy 1.15.1\r\n\r\n2018-09-05 15:55:27.172809: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-05 15:55:27.685907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:8a:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\r\n2018-09-05 15:55:27.685952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-09-05 15:55:28.161475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-05 15:55:28.161524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \r\n2018-09-05 15:55:28.161532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \r\n2018-09-05 15:55:28.161948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10398 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1)\r\n\r\n(29, 72, 72, 16) -4.591032\r\n(29, 72, 72, 16) -5.843975\r\n```\r\n\r\nRun on a GeForce GTX 980 Ti:\r\n\r\n```\r\nPython 3.6.3\r\nTensorflow 1.5.1\r\nNumpy 1.14.2\r\n\r\n2018-09-05 16:05:54.557373: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-05 16:05:57.096399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\r\nname: GeForce GTX 980 Ti major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 5.94GiB freeMemory: 5.83GiB\r\n2018-09-05 16:05:57.096467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:02:00.0, compute capability: 5.2)\r\n\r\n(29, 72, 72, 16) -4.591032\r\n(29, 72, 72, 16) -5.843975\r\n```\r\n\r\nRun on a K80:\r\n\r\n```\r\nPython 3.6.5\r\nTensorflow 1.5.1\r\nNumpy 1.15.0\r\n\r\n2018-09-05 14:37:31.279189: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-05 14:37:32.131417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-09-05 14:37:32.131763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:1e.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-09-05 14:37:32.131795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\n\r\n(29, 72, 72, 16) -5.843975\r\n(29, 72, 72, 16) -5.843975\r\n```"}