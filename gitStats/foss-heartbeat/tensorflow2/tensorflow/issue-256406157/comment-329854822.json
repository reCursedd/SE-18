{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/329854822", "html_url": "https://github.com/tensorflow/tensorflow/issues/12924#issuecomment-329854822", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12924", "id": 329854822, "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTg1NDgyMg==", "user": {"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-15T17:58:11Z", "updated_at": "2017-09-15T17:58:11Z", "author_association": "NONE", "body_html": "<p>Thanks, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25046619\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/TomorrowIsAnOtherDay\">@TomorrowIsAnOtherDay</a>. I think the interface is working-as-intended. It's probably a bad idea for datasets to automatically pad your data for you out to the desired batch size, as this might have weird effects on your training. I would expect that randomization plus setting some number of epochs is the answer to uniformly using data that doesn't exactly match the batch size.</p>\n<p>This question is better asked on  <a href=\"http://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a> since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!</p>", "body_text": "Thanks, @TomorrowIsAnOtherDay. I think the interface is working-as-intended. It's probably a bad idea for datasets to automatically pad your data for you out to the desired batch size, as this might have weird effects on your training. I would expect that randomization plus setting some number of epochs is the answer to uniformly using data that doesn't exactly match the batch size.\nThis question is better asked on  StackOverflow since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "body": "Thanks, @TomorrowIsAnOtherDay. I think the interface is working-as-intended. It's probably a bad idea for datasets to automatically pad your data for you out to the desired batch size, as this might have weird effects on your training. I would expect that randomization plus setting some number of epochs is the answer to uniformly using data that doesn't exactly match the batch size. \r\n\r\nThis question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"}