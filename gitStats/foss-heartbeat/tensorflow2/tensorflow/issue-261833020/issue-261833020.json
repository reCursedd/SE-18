{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13418", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13418/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13418/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13418/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13418", "id": 261833020, "node_id": "MDU6SXNzdWUyNjE4MzMwMjA=", "number": 13418, "title": "BUG: variable won't update in input_fn (or outside Estimator)", "user": {"login": "facaiy", "id": 1112263, "node_id": "MDQ6VXNlcjExMTIyNjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1112263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/facaiy", "html_url": "https://github.com/facaiy", "followers_url": "https://api.github.com/users/facaiy/followers", "following_url": "https://api.github.com/users/facaiy/following{/other_user}", "gists_url": "https://api.github.com/users/facaiy/gists{/gist_id}", "starred_url": "https://api.github.com/users/facaiy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/facaiy/subscriptions", "organizations_url": "https://api.github.com/users/facaiy/orgs", "repos_url": "https://api.github.com/users/facaiy/repos", "events_url": "https://api.github.com/users/facaiy/events{/privacy}", "received_events_url": "https://api.github.com/users/facaiy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-30T09:46:05Z", "updated_at": "2017-09-30T10:32:50Z", "closed_at": "2017-09-30T10:31:19Z", "author_association": "MEMBER", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Mac 10.11.6</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3.0</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>: NA</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Sometimes we will preprocess our data before feeding them into <code>Estimator</code>. For example, text data will be split or truncated at first, and then we might create a shallow convolution layer for it. However, it seems that those variables, if created, won't update in training.</p>\n<p>I create a tiny code below by using <code>input_fn</code> to clarify my question: variable <code>w</code> seems its initial value after training.</p>\n<h3>Source code / logs</h3>\n<p>code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow <span class=\"pl-k\">import</span> feature_column <span class=\"pl-k\">as</span> fc\n<span class=\"pl-k\">from</span> tensorflow.python.summary <span class=\"pl-k\">import</span> summary\n\ntf.logging.set_verbosity(tf.logging.<span class=\"pl-c1\">DEBUG</span>)\n\n\n<span class=\"pl-c1\">BATCH_SIZE</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">input_fn</span>():\n    x <span class=\"pl-k\">=</span> tf.constant(np.random.randn(<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">4</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n    w <span class=\"pl-k\">=</span> tf.Variable(np.array([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>]).reshape((<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">1</span>)), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test/w<span class=\"pl-pds\">\"</span></span>)\n    summary.scalar(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test/w[0][0]<span class=\"pl-pds\">\"</span></span>, w[<span class=\"pl-c1\">0</span>][<span class=\"pl-c1\">0</span>])\n    summary.scalar(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test/w[1][0]<span class=\"pl-pds\">\"</span></span>, w[<span class=\"pl-c1\">1</span>][<span class=\"pl-c1\">0</span>])\n    summary.scalar(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test/w[2][0]<span class=\"pl-pds\">\"</span></span>, w[<span class=\"pl-c1\">2</span>][<span class=\"pl-c1\">0</span>])\n    summary.scalar(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test/w[3][0]<span class=\"pl-pds\">\"</span></span>, w[<span class=\"pl-c1\">3</span>][<span class=\"pl-c1\">0</span>])\n\n    y <span class=\"pl-k\">=</span> tf.to_int64(tf.matmul(x, w))\n    label <span class=\"pl-k\">=</span> tf.constant(np.random.randint(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">BATCH_SIZE</span>,)))\n\n    <span class=\"pl-k\">return</span> {<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>: y}, label\n\nf <span class=\"pl-k\">=</span> fc.embedding_column(\n        fc.categorical_column_with_hash_bucket(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int64),\n        <span class=\"pl-v\">dimension</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n\ne <span class=\"pl-k\">=</span> tf.estimator.DNNRegressor(\n        <span class=\"pl-v\">feature_columns</span><span class=\"pl-k\">=</span>[f],\n        <span class=\"pl-v\">hidden_units</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>],\n        <span class=\"pl-v\">model_dir</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/tmp/tf/facai/test<span class=\"pl-pds\">\"</span></span>)\n\ne.train(input_fn, <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1000</span>)</pre></div>\n<p>logs:</p>\n<pre><code>~/Downloads \u276f\u276f\u276f python test.py\nINFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tf/facai/test', '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_tf_random_seed': 1, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_save_summary_steps': 100}\nINFO:tensorflow:Summary name test/w[0][0] is illegal; using test/w_0__0_ instead.\nINFO:tensorflow:Summary name test/w[1][0] is illegal; using test/w_1__0_ instead.\nINFO:tensorflow:Summary name test/w[2][0] is illegal; using test/w_2__0_ instead.\nINFO:tensorflow:Summary name test/w[3][0] is illegal; using test/w_3__0_ instead.\nDEBUG:tensorflow:Transforming feature_column _HashedCategoricalColumn(key='y', hash_bucket_size=4, dtype=tf.int64).\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Saving checkpoints for 1 into /tmp/tf/facai/test/model.ckpt.\nINFO:tensorflow:step = 1, loss = 18.9489\nINFO:tensorflow:global_step/sec: 723.222\nINFO:tensorflow:step = 101, loss = 0.187707 (0.138 sec)\nINFO:tensorflow:global_step/sec: 817.997\nINFO:tensorflow:step = 201, loss = 0.0705907 (0.123 sec)\nINFO:tensorflow:global_step/sec: 777.309\nINFO:tensorflow:step = 301, loss = 0.037501 (0.128 sec)\nINFO:tensorflow:global_step/sec: 795.153\nINFO:tensorflow:step = 401, loss = 0.0219456 (0.126 sec)\nINFO:tensorflow:global_step/sec: 810.99\nINFO:tensorflow:step = 501, loss = 0.0132351 (0.123 sec)\nINFO:tensorflow:global_step/sec: 744.186\nINFO:tensorflow:step = 601, loss = 0.00807175 (0.134 sec)\nINFO:tensorflow:global_step/sec: 778.229\nINFO:tensorflow:step = 701, loss = 0.00494827 (0.129 sec)\nINFO:tensorflow:global_step/sec: 760.138\nINFO:tensorflow:step = 801, loss = 0.00304232 (0.131 sec)\nINFO:tensorflow:global_step/sec: 830.641\nINFO:tensorflow:step = 901, loss = 0.00187403 (0.120 sec)\nINFO:tensorflow:Saving checkpoints for 1000 into /tmp/tf/facai/test/model.ckpt.\nINFO:tensorflow:Loss for final step: 0.00116151.\n</code></pre>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1112263/31044707-d92a2ba4-a606-11e7-93c5-457ac8658141.png\"><img width=\"701\" alt=\"screen shot 2017-09-30 at 5 40 29 pm\" src=\"https://user-images.githubusercontent.com/1112263/31044707-d92a2ba4-a606-11e7-93c5-457ac8658141.png\" style=\"max-width:100%;\"></a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac 10.11.6\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.3.0\nPython version: 3.5\nBazel version (if compiling from source):\nCUDA/cuDNN version: NA\nGPU model and memory: NA\nExact command to reproduce:\n\nDescribe the problem\nSometimes we will preprocess our data before feeding them into Estimator. For example, text data will be split or truncated at first, and then we might create a shallow convolution layer for it. However, it seems that those variables, if created, won't update in training.\nI create a tiny code below by using input_fn to clarify my question: variable w seems its initial value after training.\nSource code / logs\ncode:\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import feature_column as fc\nfrom tensorflow.python.summary import summary\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\n\n\nBATCH_SIZE=4\n\n\ndef input_fn():\n    x = tf.constant(np.random.randn(BATCH_SIZE, 4), dtype=tf.float32)\n\n    w = tf.Variable(np.array([1, 2, 3, 4]).reshape((4, 1)), dtype=tf.float32, name=\"test/w\")\n    summary.scalar(\"test/w[0][0]\", w[0][0])\n    summary.scalar(\"test/w[1][0]\", w[1][0])\n    summary.scalar(\"test/w[2][0]\", w[2][0])\n    summary.scalar(\"test/w[3][0]\", w[3][0])\n\n    y = tf.to_int64(tf.matmul(x, w))\n    label = tf.constant(np.random.randint(0, 1, size=(BATCH_SIZE,)))\n\n    return {\"y\": y}, label\n\nf = fc.embedding_column(\n        fc.categorical_column_with_hash_bucket(\"y\", 4, dtype=tf.int64),\n        dimension=2)\n\ne = tf.estimator.DNNRegressor(\n        feature_columns=[f],\n        hidden_units=[2],\n        model_dir=\"/tmp/tf/facai/test\")\n\ne.train(input_fn, steps=1000)\nlogs:\n~/Downloads \u276f\u276f\u276f python test.py\nINFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tf/facai/test', '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_tf_random_seed': 1, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_save_summary_steps': 100}\nINFO:tensorflow:Summary name test/w[0][0] is illegal; using test/w_0__0_ instead.\nINFO:tensorflow:Summary name test/w[1][0] is illegal; using test/w_1__0_ instead.\nINFO:tensorflow:Summary name test/w[2][0] is illegal; using test/w_2__0_ instead.\nINFO:tensorflow:Summary name test/w[3][0] is illegal; using test/w_3__0_ instead.\nDEBUG:tensorflow:Transforming feature_column _HashedCategoricalColumn(key='y', hash_bucket_size=4, dtype=tf.int64).\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Saving checkpoints for 1 into /tmp/tf/facai/test/model.ckpt.\nINFO:tensorflow:step = 1, loss = 18.9489\nINFO:tensorflow:global_step/sec: 723.222\nINFO:tensorflow:step = 101, loss = 0.187707 (0.138 sec)\nINFO:tensorflow:global_step/sec: 817.997\nINFO:tensorflow:step = 201, loss = 0.0705907 (0.123 sec)\nINFO:tensorflow:global_step/sec: 777.309\nINFO:tensorflow:step = 301, loss = 0.037501 (0.128 sec)\nINFO:tensorflow:global_step/sec: 795.153\nINFO:tensorflow:step = 401, loss = 0.0219456 (0.126 sec)\nINFO:tensorflow:global_step/sec: 810.99\nINFO:tensorflow:step = 501, loss = 0.0132351 (0.123 sec)\nINFO:tensorflow:global_step/sec: 744.186\nINFO:tensorflow:step = 601, loss = 0.00807175 (0.134 sec)\nINFO:tensorflow:global_step/sec: 778.229\nINFO:tensorflow:step = 701, loss = 0.00494827 (0.129 sec)\nINFO:tensorflow:global_step/sec: 760.138\nINFO:tensorflow:step = 801, loss = 0.00304232 (0.131 sec)\nINFO:tensorflow:global_step/sec: 830.641\nINFO:tensorflow:step = 901, loss = 0.00187403 (0.120 sec)\nINFO:tensorflow:Saving checkpoints for 1000 into /tmp/tf/facai/test/model.ckpt.\nINFO:tensorflow:Loss for final step: 0.00116151.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac 10.11.6\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\n\r\nSometimes we will preprocess our data before feeding them into `Estimator`. For example, text data will be split or truncated at first, and then we might create a shallow convolution layer for it. However, it seems that those variables, if created, won't update in training.\r\n\r\nI create a tiny code below by using `input_fn` to clarify my question: variable `w` seems its initial value after training.\r\n\r\n\r\n### Source code / logs\r\n\r\ncode:\r\n\r\n```python\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import feature_column as fc\r\nfrom tensorflow.python.summary import summary\r\n\r\ntf.logging.set_verbosity(tf.logging.DEBUG)\r\n\r\n\r\nBATCH_SIZE=4\r\n\r\n\r\ndef input_fn():\r\n    x = tf.constant(np.random.randn(BATCH_SIZE, 4), dtype=tf.float32)\r\n\r\n    w = tf.Variable(np.array([1, 2, 3, 4]).reshape((4, 1)), dtype=tf.float32, name=\"test/w\")\r\n    summary.scalar(\"test/w[0][0]\", w[0][0])\r\n    summary.scalar(\"test/w[1][0]\", w[1][0])\r\n    summary.scalar(\"test/w[2][0]\", w[2][0])\r\n    summary.scalar(\"test/w[3][0]\", w[3][0])\r\n\r\n    y = tf.to_int64(tf.matmul(x, w))\r\n    label = tf.constant(np.random.randint(0, 1, size=(BATCH_SIZE,)))\r\n\r\n    return {\"y\": y}, label\r\n\r\nf = fc.embedding_column(\r\n        fc.categorical_column_with_hash_bucket(\"y\", 4, dtype=tf.int64),\r\n        dimension=2)\r\n\r\ne = tf.estimator.DNNRegressor(\r\n        feature_columns=[f],\r\n        hidden_units=[2],\r\n        model_dir=\"/tmp/tf/facai/test\")\r\n\r\ne.train(input_fn, steps=1000)\r\n```\r\n\r\nlogs:\r\n```\r\n~/Downloads \u276f\u276f\u276f python test.py\r\nINFO:tensorflow:Using default config.\r\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tf/facai/test', '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_tf_random_seed': 1, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_save_summary_steps': 100}\r\nINFO:tensorflow:Summary name test/w[0][0] is illegal; using test/w_0__0_ instead.\r\nINFO:tensorflow:Summary name test/w[1][0] is illegal; using test/w_1__0_ instead.\r\nINFO:tensorflow:Summary name test/w[2][0] is illegal; using test/w_2__0_ instead.\r\nINFO:tensorflow:Summary name test/w[3][0] is illegal; using test/w_3__0_ instead.\r\nDEBUG:tensorflow:Transforming feature_column _HashedCategoricalColumn(key='y', hash_bucket_size=4, dtype=tf.int64).\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Saving checkpoints for 1 into /tmp/tf/facai/test/model.ckpt.\r\nINFO:tensorflow:step = 1, loss = 18.9489\r\nINFO:tensorflow:global_step/sec: 723.222\r\nINFO:tensorflow:step = 101, loss = 0.187707 (0.138 sec)\r\nINFO:tensorflow:global_step/sec: 817.997\r\nINFO:tensorflow:step = 201, loss = 0.0705907 (0.123 sec)\r\nINFO:tensorflow:global_step/sec: 777.309\r\nINFO:tensorflow:step = 301, loss = 0.037501 (0.128 sec)\r\nINFO:tensorflow:global_step/sec: 795.153\r\nINFO:tensorflow:step = 401, loss = 0.0219456 (0.126 sec)\r\nINFO:tensorflow:global_step/sec: 810.99\r\nINFO:tensorflow:step = 501, loss = 0.0132351 (0.123 sec)\r\nINFO:tensorflow:global_step/sec: 744.186\r\nINFO:tensorflow:step = 601, loss = 0.00807175 (0.134 sec)\r\nINFO:tensorflow:global_step/sec: 778.229\r\nINFO:tensorflow:step = 701, loss = 0.00494827 (0.129 sec)\r\nINFO:tensorflow:global_step/sec: 760.138\r\nINFO:tensorflow:step = 801, loss = 0.00304232 (0.131 sec)\r\nINFO:tensorflow:global_step/sec: 830.641\r\nINFO:tensorflow:step = 901, loss = 0.00187403 (0.120 sec)\r\nINFO:tensorflow:Saving checkpoints for 1000 into /tmp/tf/facai/test/model.ckpt.\r\nINFO:tensorflow:Loss for final step: 0.00116151.\r\n```\r\n\r\n<img width=\"701\" alt=\"screen shot 2017-09-30 at 5 40 29 pm\" src=\"https://user-images.githubusercontent.com/1112263/31044707-d92a2ba4-a606-11e7-93c5-457ac8658141.png\">\r\n\r\n\r\n"}