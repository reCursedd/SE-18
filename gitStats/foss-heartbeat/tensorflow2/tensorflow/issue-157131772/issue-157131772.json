{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2531", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2531/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2531/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2531/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2531", "id": 157131772, "node_id": "MDU6SXNzdWUxNTcxMzE3NzI=", "number": 2531, "title": "Running model failed: executing graph using C++ API", "user": {"login": "TianweiXing", "id": 17885178, "node_id": "MDQ6VXNlcjE3ODg1MTc4", "avatar_url": "https://avatars1.githubusercontent.com/u/17885178?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TianweiXing", "html_url": "https://github.com/TianweiXing", "followers_url": "https://api.github.com/users/TianweiXing/followers", "following_url": "https://api.github.com/users/TianweiXing/following{/other_user}", "gists_url": "https://api.github.com/users/TianweiXing/gists{/gist_id}", "starred_url": "https://api.github.com/users/TianweiXing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TianweiXing/subscriptions", "organizations_url": "https://api.github.com/users/TianweiXing/orgs", "repos_url": "https://api.github.com/users/TianweiXing/repos", "events_url": "https://api.github.com/users/TianweiXing/events{/privacy}", "received_events_url": "https://api.github.com/users/TianweiXing/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2016-05-27T05:18:06Z", "updated_at": "2017-08-24T01:38:50Z", "closed_at": "2016-06-22T08:20:14Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I trained a model using Python API, and saved a standalone GraphDef model using freeze_graph.<br>\nAnd then I execute the graph in C++ enviornment</p>\n<p>However, after building the binary file using bazel, it's cannot running correctly:<br>\n<code>E tensorflow/examples/facenet/main.cc:309] Running model failed: Invalid argument: Input 0 of node incept5b/in4_conv1x1_55/batch_norm/cond/ExponentialMovingAverage/AssignMovingAvg_1/Switch was passed float from incept5b/in4_conv1x1_55/batch_norm/cond/incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/variance/ExponentialMovingAverage:0 incompatible with expected float_ref.</code></p>\n<p>Is there any reason for this failure? Does anyone know how to fix this?<br>\nMaybe should add some detailed explanation in C++ API documentation....<br>\nThanks,</p>\n<p>The structure of the graph (in python) can be simplified as: (it's used for face recognition).</p>\n<pre><code>images_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.image_size, FLAGS.image_size, 3), name='input')\n\nphase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')\n\nembeddings = faceRecog.inference_nn4_max_pool_96(images_placeholder, phase_train=phase_train_placeholder)\n\n\n\ndef inference_nn4_max_pool_96(images, phase_train=True):\n\n  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)\n  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')\n  conv2 = _conv(pool1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)\n  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)\n  pool3 = _mpool(conv3,  3, 3, 2, 2, 'SAME')\n\n  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'max', 'incept3a', phase_train=phase_train, use_batch_norm=True)\n  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, 'max', 'incept3b', phase_train=phase_train, use_batch_norm=True)\n  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'max', 'incept3c', phase_train=phase_train, use_batch_norm=True)\n\n  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, 'max', 'incept4a', phase_train=phase_train, use_batch_norm=True)\n  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, 'max', 'incept4b', phase_train=phase_train, use_batch_norm=True)\n  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, 'max', 'incept4c', phase_train=phase_train, use_batch_norm=True)\n  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, 'max', 'incept4d', phase_train=phase_train, use_batch_norm=True)\n  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'max', 'incept4e', phase_train=phase_train, use_batch_norm=True)\n\n  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'max', 'incept5a', phase_train=phase_train, use_batch_norm=True)\n  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'max', 'incept5b', phase_train=phase_train, use_batch_norm=True)\n  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')\n\n  resh1 = tf.reshape(pool6, [-1, 896])\n  affn1 = _affine(resh1, 896, 128)\n  if FLAGS.keep_probability&lt;1.0:\n    affn1 = control_flow_ops.cond(phase_train,\n                                  lambda: tf.nn.dropout(affn1, FLAGS.keep_probability), lambda: affn1)\n  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')\n\n  return norm\n\n</code></pre>\n<p>And in C++, I edit the \"lable_image\" example in tensorflow, and here's the code:</p>\n<pre><code>#include &lt;fstream&gt;\n\n#include \"tensorflow/cc/ops/const_op.h\"\n#include \"tensorflow/cc/ops/image_ops.h\"\n#include \"tensorflow/cc/ops/standard_ops.h\"\n#include \"tensorflow/core/framework/graph.pb.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/graph/default_device.h\"\n#include \"tensorflow/core/graph/graph_def_builder.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/core/threadpool.h\"\n#include \"tensorflow/core/lib/io/path.h\"\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\n#include \"tensorflow/core/platform/init_main.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/public/session.h\"\n#include \"tensorflow/core/util/command_line_flags.h\"\n\n// These are all common classes it's handy to reference with no namespace.\nusing tensorflow::Flag;\nusing tensorflow::Tensor;\nusing tensorflow::Status;\nusing tensorflow::string;\nusing tensorflow::int32;\n\n// Given an image file name, read in the data, try to decode it as an image,\n// resize it to the requested size, and then scale the values as desired.\nStatus ReadTensorFromImageFile(string file_name, const int input_height,\n                               const int input_width, const float input_mean,\n                               const float input_std,\n                               std::vector&lt;Tensor&gt;* out_tensors) {\n  tensorflow::GraphDefBuilder b;\n  string input_name = \"file_reader\";\n  string output_name = \"normalized\";\n  tensorflow::Node* file_reader =\n      tensorflow::ops::ReadFile(tensorflow::ops::Const(file_name, b.opts()),\n                                b.opts().WithName(input_name));\n  // Now try to figure out what kind of file it is and decode it.\n  const int wanted_channels = 3;\n  tensorflow::Node* image_reader;\n  if (tensorflow::StringPiece(file_name).ends_with(\".png\")) {\n    image_reader = tensorflow::ops::DecodePng(\n        file_reader,\n        b.opts().WithAttr(\"channels\", wanted_channels).WithName(\"png_reader\"));\n  } else {\n    // Assume if it's not a PNG then it must be a JPEG.\n    image_reader = tensorflow::ops::DecodeJpeg(\n        file_reader,\n        b.opts().WithAttr(\"channels\", wanted_channels).WithName(\"jpeg_reader\"));\n  }\n  // Now cast the image data to float so we can do normal math on it.\n  tensorflow::Node* float_caster = tensorflow::ops::Cast(\n      image_reader, tensorflow::DT_FLOAT, b.opts().WithName(\"float_caster\"));\n  // The convention for image ops in TensorFlow is that all images are expected\n  // to be in batches, so that they're four-dimensional arrays with indices of\n  // [batch, height, width, channel]. Because we only have a single image, we\n  // have to add a batch dimension of 1 to the start with ExpandDims().\n  tensorflow::Node* dims_expander = tensorflow::ops::ExpandDims(\n      float_caster, tensorflow::ops::Const(0, b.opts()), b.opts());\n  // Bilinearly resize the image to fit the required dimensions.\n  tensorflow::Node* resized = tensorflow::ops::ResizeBilinear(\n      dims_expander, tensorflow::ops::Const({input_height, input_width},\n                                            b.opts().WithName(\"size\")),\n      b.opts());\n  // Subtract the mean and divide by the scale.\n  tensorflow::ops::Div(\n      tensorflow::ops::Sub(\n          resized, tensorflow::ops::Const({input_mean}, b.opts()), b.opts()),\n      tensorflow::ops::Const({input_std}, b.opts()),\n      b.opts().WithName(output_name));\n\n  // This runs the GraphDef network definition that we've just constructed, and\n  // returns the results in the output tensor.\n  tensorflow::GraphDef graph;\n  TF_RETURN_IF_ERROR(b.ToGraphDef(&amp;graph));\n  std::unique_ptr&lt;tensorflow::Session&gt; session(\n      tensorflow::NewSession(tensorflow::SessionOptions()));\n  TF_RETURN_IF_ERROR(session-&gt;Create(graph));\n  TF_RETURN_IF_ERROR(session-&gt;Run({}, {output_name}, {}, out_tensors));\n  return Status::OK();\n}\n\n// Reads a model graph definition from disk, and creates a session object you\n// can use to run it.\nStatus LoadGraph(string graph_file_name,\n                 std::unique_ptr&lt;tensorflow::Session&gt;* session) {\n  tensorflow::GraphDef graph_def;\n  Status load_graph_status =\n      ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &amp;graph_def);\n  if (!load_graph_status.ok()) {\n    return tensorflow::errors::NotFound(\"Failed to load compute graph at '\",\n                                        graph_file_name, \"'\");\n  }\n  session-&gt;reset(tensorflow::NewSession(tensorflow::SessionOptions()));\n  Status session_create_status = (*session)-&gt;Create(graph_def);\n  if (!session_create_status.ok()) {\n    return session_create_status;\n  }\n  return Status::OK();\n}\n\n\nint main(int argc, char* argv[]) {\n  // These are the command-line flags the program can understand.\n  // They define where the graph and input data is located, and what kind of\n  // input the model expects. If you train your own model, or use something\n  // other than GoogLeNet you'll need to update these.\n  string image = \"tensorflow/examples/facenet/data/img.png\";\n // string image = \"tensorflow/examples/label_image/data/grace_hopper.jpg\";\n  string graph =\n      \"tensorflow/examples/facenet/data/\"\n      \"FaceNet.pb\";\n  // not necessary for facenet\n  // string labels =\n  //     \"tensorflow/examples/label_image/data/\"\n  //     \"imagenet_comp_graph_label_strings.txt\";\n  int32 input_width = 96;\n  int32 input_height = 96;\n  int32 input_mean = 0;\n  int32 input_std = 1;\n  string input_layer = \"input\";\n  string output_layer = \"embeddings\";\n  bool self_test = false;\n  string root_dir = \"\";\n  const bool parse_result = tensorflow::ParseFlags(\n      &amp;argc, argv, {Flag(\"image\", &amp;image),                //\n                    Flag(\"graph\", &amp;graph),                //\n                    // Flag(\"labels\", &amp;labels),              //\n                    Flag(\"input_width\", &amp;input_width),    //\n                    Flag(\"input_height\", &amp;input_height),  //\n                    Flag(\"input_mean\", &amp;input_mean),      //\n                    Flag(\"input_std\", &amp;input_std),        //\n                    Flag(\"input_layer\", &amp;input_layer),    //\n                    Flag(\"output_layer\", &amp;output_layer),  //\n                    Flag(\"self_test\", &amp;self_test),        //\n                    Flag(\"root_dir\", &amp;root_dir)});\n  if (!parse_result) {\n    LOG(ERROR) &lt;&lt; \"Error parsing command-line flags.\";\n    return -1;\n  }\n\n  // We need to call this to set up global state for TensorFlow.\n  tensorflow::port::InitMain(argv[0], &amp;argc, &amp;argv);\n  if (argc &gt; 1) {\n    LOG(ERROR) &lt;&lt; \"Unknown argument \" &lt;&lt; argv[1];\n    return -1;\n  }\n\n  // First we load and initialize the model.\n  std::unique_ptr&lt;tensorflow::Session&gt; session;\n  string graph_path = tensorflow::io::JoinPath(root_dir, graph);\n  Status load_graph_status = LoadGraph(graph_path, &amp;session);\n  if (!load_graph_status.ok()) {\n    LOG(ERROR) &lt;&lt; load_graph_status;\n    return -1;\n  }\n\n  // Get the image from disk as a float array of numbers, resized and normalized\n  // to the specifications the main graph expects.\n  std::vector&lt;Tensor&gt; resized_tensors;\n  string image_path = tensorflow::io::JoinPath(root_dir, image);\n  Status read_tensor_status =\n      ReadTensorFromImageFile(image_path, input_height, input_width, input_mean,\n                              input_std, &amp;resized_tensors);\n  if (!read_tensor_status.ok()) {\n    LOG(ERROR) &lt;&lt; read_tensor_status;\n    return -1;\n  }\n  const Tensor&amp; resized_tensor = resized_tensors[0];\n\n  // Actually run the image through the model.\n  std::vector&lt;Tensor&gt; outputs;\n  Status run_status = session-&gt;Run({{\"input\", resized_tensor}},\n                                    {\"embeddings\"}, {}, &amp;outputs);\n                                   // {output_layer}, {}, &amp;outputs);\n  if (!run_status.ok()) {\n    LOG(ERROR) &lt;&lt; \"Running model failed: \" &lt;&lt; run_status;\n    return -1;\n  }\n\n\n  return 0;\n}\n\n</code></pre>\n<p>Thanks!</p>", "body_text": "Hi,\nI trained a model using Python API, and saved a standalone GraphDef model using freeze_graph.\nAnd then I execute the graph in C++ enviornment\nHowever, after building the binary file using bazel, it's cannot running correctly:\nE tensorflow/examples/facenet/main.cc:309] Running model failed: Invalid argument: Input 0 of node incept5b/in4_conv1x1_55/batch_norm/cond/ExponentialMovingAverage/AssignMovingAvg_1/Switch was passed float from incept5b/in4_conv1x1_55/batch_norm/cond/incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/variance/ExponentialMovingAverage:0 incompatible with expected float_ref.\nIs there any reason for this failure? Does anyone know how to fix this?\nMaybe should add some detailed explanation in C++ API documentation....\nThanks,\nThe structure of the graph (in python) can be simplified as: (it's used for face recognition).\nimages_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.image_size, FLAGS.image_size, 3), name='input')\n\nphase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')\n\nembeddings = faceRecog.inference_nn4_max_pool_96(images_placeholder, phase_train=phase_train_placeholder)\n\n\n\ndef inference_nn4_max_pool_96(images, phase_train=True):\n\n  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)\n  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')\n  conv2 = _conv(pool1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)\n  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)\n  pool3 = _mpool(conv3,  3, 3, 2, 2, 'SAME')\n\n  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'max', 'incept3a', phase_train=phase_train, use_batch_norm=True)\n  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, 'max', 'incept3b', phase_train=phase_train, use_batch_norm=True)\n  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'max', 'incept3c', phase_train=phase_train, use_batch_norm=True)\n\n  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, 'max', 'incept4a', phase_train=phase_train, use_batch_norm=True)\n  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, 'max', 'incept4b', phase_train=phase_train, use_batch_norm=True)\n  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, 'max', 'incept4c', phase_train=phase_train, use_batch_norm=True)\n  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, 'max', 'incept4d', phase_train=phase_train, use_batch_norm=True)\n  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'max', 'incept4e', phase_train=phase_train, use_batch_norm=True)\n\n  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'max', 'incept5a', phase_train=phase_train, use_batch_norm=True)\n  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'max', 'incept5b', phase_train=phase_train, use_batch_norm=True)\n  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')\n\n  resh1 = tf.reshape(pool6, [-1, 896])\n  affn1 = _affine(resh1, 896, 128)\n  if FLAGS.keep_probability<1.0:\n    affn1 = control_flow_ops.cond(phase_train,\n                                  lambda: tf.nn.dropout(affn1, FLAGS.keep_probability), lambda: affn1)\n  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')\n\n  return norm\n\n\nAnd in C++, I edit the \"lable_image\" example in tensorflow, and here's the code:\n#include <fstream>\n\n#include \"tensorflow/cc/ops/const_op.h\"\n#include \"tensorflow/cc/ops/image_ops.h\"\n#include \"tensorflow/cc/ops/standard_ops.h\"\n#include \"tensorflow/core/framework/graph.pb.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/graph/default_device.h\"\n#include \"tensorflow/core/graph/graph_def_builder.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/core/threadpool.h\"\n#include \"tensorflow/core/lib/io/path.h\"\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\n#include \"tensorflow/core/platform/init_main.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/public/session.h\"\n#include \"tensorflow/core/util/command_line_flags.h\"\n\n// These are all common classes it's handy to reference with no namespace.\nusing tensorflow::Flag;\nusing tensorflow::Tensor;\nusing tensorflow::Status;\nusing tensorflow::string;\nusing tensorflow::int32;\n\n// Given an image file name, read in the data, try to decode it as an image,\n// resize it to the requested size, and then scale the values as desired.\nStatus ReadTensorFromImageFile(string file_name, const int input_height,\n                               const int input_width, const float input_mean,\n                               const float input_std,\n                               std::vector<Tensor>* out_tensors) {\n  tensorflow::GraphDefBuilder b;\n  string input_name = \"file_reader\";\n  string output_name = \"normalized\";\n  tensorflow::Node* file_reader =\n      tensorflow::ops::ReadFile(tensorflow::ops::Const(file_name, b.opts()),\n                                b.opts().WithName(input_name));\n  // Now try to figure out what kind of file it is and decode it.\n  const int wanted_channels = 3;\n  tensorflow::Node* image_reader;\n  if (tensorflow::StringPiece(file_name).ends_with(\".png\")) {\n    image_reader = tensorflow::ops::DecodePng(\n        file_reader,\n        b.opts().WithAttr(\"channels\", wanted_channels).WithName(\"png_reader\"));\n  } else {\n    // Assume if it's not a PNG then it must be a JPEG.\n    image_reader = tensorflow::ops::DecodeJpeg(\n        file_reader,\n        b.opts().WithAttr(\"channels\", wanted_channels).WithName(\"jpeg_reader\"));\n  }\n  // Now cast the image data to float so we can do normal math on it.\n  tensorflow::Node* float_caster = tensorflow::ops::Cast(\n      image_reader, tensorflow::DT_FLOAT, b.opts().WithName(\"float_caster\"));\n  // The convention for image ops in TensorFlow is that all images are expected\n  // to be in batches, so that they're four-dimensional arrays with indices of\n  // [batch, height, width, channel]. Because we only have a single image, we\n  // have to add a batch dimension of 1 to the start with ExpandDims().\n  tensorflow::Node* dims_expander = tensorflow::ops::ExpandDims(\n      float_caster, tensorflow::ops::Const(0, b.opts()), b.opts());\n  // Bilinearly resize the image to fit the required dimensions.\n  tensorflow::Node* resized = tensorflow::ops::ResizeBilinear(\n      dims_expander, tensorflow::ops::Const({input_height, input_width},\n                                            b.opts().WithName(\"size\")),\n      b.opts());\n  // Subtract the mean and divide by the scale.\n  tensorflow::ops::Div(\n      tensorflow::ops::Sub(\n          resized, tensorflow::ops::Const({input_mean}, b.opts()), b.opts()),\n      tensorflow::ops::Const({input_std}, b.opts()),\n      b.opts().WithName(output_name));\n\n  // This runs the GraphDef network definition that we've just constructed, and\n  // returns the results in the output tensor.\n  tensorflow::GraphDef graph;\n  TF_RETURN_IF_ERROR(b.ToGraphDef(&graph));\n  std::unique_ptr<tensorflow::Session> session(\n      tensorflow::NewSession(tensorflow::SessionOptions()));\n  TF_RETURN_IF_ERROR(session->Create(graph));\n  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));\n  return Status::OK();\n}\n\n// Reads a model graph definition from disk, and creates a session object you\n// can use to run it.\nStatus LoadGraph(string graph_file_name,\n                 std::unique_ptr<tensorflow::Session>* session) {\n  tensorflow::GraphDef graph_def;\n  Status load_graph_status =\n      ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);\n  if (!load_graph_status.ok()) {\n    return tensorflow::errors::NotFound(\"Failed to load compute graph at '\",\n                                        graph_file_name, \"'\");\n  }\n  session->reset(tensorflow::NewSession(tensorflow::SessionOptions()));\n  Status session_create_status = (*session)->Create(graph_def);\n  if (!session_create_status.ok()) {\n    return session_create_status;\n  }\n  return Status::OK();\n}\n\n\nint main(int argc, char* argv[]) {\n  // These are the command-line flags the program can understand.\n  // They define where the graph and input data is located, and what kind of\n  // input the model expects. If you train your own model, or use something\n  // other than GoogLeNet you'll need to update these.\n  string image = \"tensorflow/examples/facenet/data/img.png\";\n // string image = \"tensorflow/examples/label_image/data/grace_hopper.jpg\";\n  string graph =\n      \"tensorflow/examples/facenet/data/\"\n      \"FaceNet.pb\";\n  // not necessary for facenet\n  // string labels =\n  //     \"tensorflow/examples/label_image/data/\"\n  //     \"imagenet_comp_graph_label_strings.txt\";\n  int32 input_width = 96;\n  int32 input_height = 96;\n  int32 input_mean = 0;\n  int32 input_std = 1;\n  string input_layer = \"input\";\n  string output_layer = \"embeddings\";\n  bool self_test = false;\n  string root_dir = \"\";\n  const bool parse_result = tensorflow::ParseFlags(\n      &argc, argv, {Flag(\"image\", &image),                //\n                    Flag(\"graph\", &graph),                //\n                    // Flag(\"labels\", &labels),              //\n                    Flag(\"input_width\", &input_width),    //\n                    Flag(\"input_height\", &input_height),  //\n                    Flag(\"input_mean\", &input_mean),      //\n                    Flag(\"input_std\", &input_std),        //\n                    Flag(\"input_layer\", &input_layer),    //\n                    Flag(\"output_layer\", &output_layer),  //\n                    Flag(\"self_test\", &self_test),        //\n                    Flag(\"root_dir\", &root_dir)});\n  if (!parse_result) {\n    LOG(ERROR) << \"Error parsing command-line flags.\";\n    return -1;\n  }\n\n  // We need to call this to set up global state for TensorFlow.\n  tensorflow::port::InitMain(argv[0], &argc, &argv);\n  if (argc > 1) {\n    LOG(ERROR) << \"Unknown argument \" << argv[1];\n    return -1;\n  }\n\n  // First we load and initialize the model.\n  std::unique_ptr<tensorflow::Session> session;\n  string graph_path = tensorflow::io::JoinPath(root_dir, graph);\n  Status load_graph_status = LoadGraph(graph_path, &session);\n  if (!load_graph_status.ok()) {\n    LOG(ERROR) << load_graph_status;\n    return -1;\n  }\n\n  // Get the image from disk as a float array of numbers, resized and normalized\n  // to the specifications the main graph expects.\n  std::vector<Tensor> resized_tensors;\n  string image_path = tensorflow::io::JoinPath(root_dir, image);\n  Status read_tensor_status =\n      ReadTensorFromImageFile(image_path, input_height, input_width, input_mean,\n                              input_std, &resized_tensors);\n  if (!read_tensor_status.ok()) {\n    LOG(ERROR) << read_tensor_status;\n    return -1;\n  }\n  const Tensor& resized_tensor = resized_tensors[0];\n\n  // Actually run the image through the model.\n  std::vector<Tensor> outputs;\n  Status run_status = session->Run({{\"input\", resized_tensor}},\n                                    {\"embeddings\"}, {}, &outputs);\n                                   // {output_layer}, {}, &outputs);\n  if (!run_status.ok()) {\n    LOG(ERROR) << \"Running model failed: \" << run_status;\n    return -1;\n  }\n\n\n  return 0;\n}\n\n\nThanks!", "body": "Hi,\n\nI trained a model using Python API, and saved a standalone GraphDef model using freeze_graph.\nAnd then I execute the graph in C++ enviornment\n\nHowever, after building the binary file using bazel, it's cannot running correctly:\n`E tensorflow/examples/facenet/main.cc:309] Running model failed: Invalid argument: Input 0 of node incept5b/in4_conv1x1_55/batch_norm/cond/ExponentialMovingAverage/AssignMovingAvg_1/Switch was passed float from incept5b/in4_conv1x1_55/batch_norm/cond/incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/variance/ExponentialMovingAverage:0 incompatible with expected float_ref.`\n\nIs there any reason for this failure? Does anyone know how to fix this?\nMaybe should add some detailed explanation in C++ API documentation....\nThanks,\n\nThe structure of the graph (in python) can be simplified as: (it's used for face recognition).\n\n```\nimages_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.image_size, FLAGS.image_size, 3), name='input')\n\nphase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')\n\nembeddings = faceRecog.inference_nn4_max_pool_96(images_placeholder, phase_train=phase_train_placeholder)\n\n\n\ndef inference_nn4_max_pool_96(images, phase_train=True):\n\n  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)\n  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')\n  conv2 = _conv(pool1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)\n  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)\n  pool3 = _mpool(conv3,  3, 3, 2, 2, 'SAME')\n\n  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'max', 'incept3a', phase_train=phase_train, use_batch_norm=True)\n  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, 'max', 'incept3b', phase_train=phase_train, use_batch_norm=True)\n  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'max', 'incept3c', phase_train=phase_train, use_batch_norm=True)\n\n  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, 'max', 'incept4a', phase_train=phase_train, use_batch_norm=True)\n  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, 'max', 'incept4b', phase_train=phase_train, use_batch_norm=True)\n  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, 'max', 'incept4c', phase_train=phase_train, use_batch_norm=True)\n  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, 'max', 'incept4d', phase_train=phase_train, use_batch_norm=True)\n  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'max', 'incept4e', phase_train=phase_train, use_batch_norm=True)\n\n  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'max', 'incept5a', phase_train=phase_train, use_batch_norm=True)\n  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'max', 'incept5b', phase_train=phase_train, use_batch_norm=True)\n  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')\n\n  resh1 = tf.reshape(pool6, [-1, 896])\n  affn1 = _affine(resh1, 896, 128)\n  if FLAGS.keep_probability<1.0:\n    affn1 = control_flow_ops.cond(phase_train,\n                                  lambda: tf.nn.dropout(affn1, FLAGS.keep_probability), lambda: affn1)\n  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')\n\n  return norm\n\n```\n\nAnd in C++, I edit the \"lable_image\" example in tensorflow, and here's the code:\n\n```\n#include <fstream>\n\n#include \"tensorflow/cc/ops/const_op.h\"\n#include \"tensorflow/cc/ops/image_ops.h\"\n#include \"tensorflow/cc/ops/standard_ops.h\"\n#include \"tensorflow/core/framework/graph.pb.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/graph/default_device.h\"\n#include \"tensorflow/core/graph/graph_def_builder.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/core/threadpool.h\"\n#include \"tensorflow/core/lib/io/path.h\"\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\n#include \"tensorflow/core/platform/init_main.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/public/session.h\"\n#include \"tensorflow/core/util/command_line_flags.h\"\n\n// These are all common classes it's handy to reference with no namespace.\nusing tensorflow::Flag;\nusing tensorflow::Tensor;\nusing tensorflow::Status;\nusing tensorflow::string;\nusing tensorflow::int32;\n\n// Given an image file name, read in the data, try to decode it as an image,\n// resize it to the requested size, and then scale the values as desired.\nStatus ReadTensorFromImageFile(string file_name, const int input_height,\n                               const int input_width, const float input_mean,\n                               const float input_std,\n                               std::vector<Tensor>* out_tensors) {\n  tensorflow::GraphDefBuilder b;\n  string input_name = \"file_reader\";\n  string output_name = \"normalized\";\n  tensorflow::Node* file_reader =\n      tensorflow::ops::ReadFile(tensorflow::ops::Const(file_name, b.opts()),\n                                b.opts().WithName(input_name));\n  // Now try to figure out what kind of file it is and decode it.\n  const int wanted_channels = 3;\n  tensorflow::Node* image_reader;\n  if (tensorflow::StringPiece(file_name).ends_with(\".png\")) {\n    image_reader = tensorflow::ops::DecodePng(\n        file_reader,\n        b.opts().WithAttr(\"channels\", wanted_channels).WithName(\"png_reader\"));\n  } else {\n    // Assume if it's not a PNG then it must be a JPEG.\n    image_reader = tensorflow::ops::DecodeJpeg(\n        file_reader,\n        b.opts().WithAttr(\"channels\", wanted_channels).WithName(\"jpeg_reader\"));\n  }\n  // Now cast the image data to float so we can do normal math on it.\n  tensorflow::Node* float_caster = tensorflow::ops::Cast(\n      image_reader, tensorflow::DT_FLOAT, b.opts().WithName(\"float_caster\"));\n  // The convention for image ops in TensorFlow is that all images are expected\n  // to be in batches, so that they're four-dimensional arrays with indices of\n  // [batch, height, width, channel]. Because we only have a single image, we\n  // have to add a batch dimension of 1 to the start with ExpandDims().\n  tensorflow::Node* dims_expander = tensorflow::ops::ExpandDims(\n      float_caster, tensorflow::ops::Const(0, b.opts()), b.opts());\n  // Bilinearly resize the image to fit the required dimensions.\n  tensorflow::Node* resized = tensorflow::ops::ResizeBilinear(\n      dims_expander, tensorflow::ops::Const({input_height, input_width},\n                                            b.opts().WithName(\"size\")),\n      b.opts());\n  // Subtract the mean and divide by the scale.\n  tensorflow::ops::Div(\n      tensorflow::ops::Sub(\n          resized, tensorflow::ops::Const({input_mean}, b.opts()), b.opts()),\n      tensorflow::ops::Const({input_std}, b.opts()),\n      b.opts().WithName(output_name));\n\n  // This runs the GraphDef network definition that we've just constructed, and\n  // returns the results in the output tensor.\n  tensorflow::GraphDef graph;\n  TF_RETURN_IF_ERROR(b.ToGraphDef(&graph));\n  std::unique_ptr<tensorflow::Session> session(\n      tensorflow::NewSession(tensorflow::SessionOptions()));\n  TF_RETURN_IF_ERROR(session->Create(graph));\n  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));\n  return Status::OK();\n}\n\n// Reads a model graph definition from disk, and creates a session object you\n// can use to run it.\nStatus LoadGraph(string graph_file_name,\n                 std::unique_ptr<tensorflow::Session>* session) {\n  tensorflow::GraphDef graph_def;\n  Status load_graph_status =\n      ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);\n  if (!load_graph_status.ok()) {\n    return tensorflow::errors::NotFound(\"Failed to load compute graph at '\",\n                                        graph_file_name, \"'\");\n  }\n  session->reset(tensorflow::NewSession(tensorflow::SessionOptions()));\n  Status session_create_status = (*session)->Create(graph_def);\n  if (!session_create_status.ok()) {\n    return session_create_status;\n  }\n  return Status::OK();\n}\n\n\nint main(int argc, char* argv[]) {\n  // These are the command-line flags the program can understand.\n  // They define where the graph and input data is located, and what kind of\n  // input the model expects. If you train your own model, or use something\n  // other than GoogLeNet you'll need to update these.\n  string image = \"tensorflow/examples/facenet/data/img.png\";\n // string image = \"tensorflow/examples/label_image/data/grace_hopper.jpg\";\n  string graph =\n      \"tensorflow/examples/facenet/data/\"\n      \"FaceNet.pb\";\n  // not necessary for facenet\n  // string labels =\n  //     \"tensorflow/examples/label_image/data/\"\n  //     \"imagenet_comp_graph_label_strings.txt\";\n  int32 input_width = 96;\n  int32 input_height = 96;\n  int32 input_mean = 0;\n  int32 input_std = 1;\n  string input_layer = \"input\";\n  string output_layer = \"embeddings\";\n  bool self_test = false;\n  string root_dir = \"\";\n  const bool parse_result = tensorflow::ParseFlags(\n      &argc, argv, {Flag(\"image\", &image),                //\n                    Flag(\"graph\", &graph),                //\n                    // Flag(\"labels\", &labels),              //\n                    Flag(\"input_width\", &input_width),    //\n                    Flag(\"input_height\", &input_height),  //\n                    Flag(\"input_mean\", &input_mean),      //\n                    Flag(\"input_std\", &input_std),        //\n                    Flag(\"input_layer\", &input_layer),    //\n                    Flag(\"output_layer\", &output_layer),  //\n                    Flag(\"self_test\", &self_test),        //\n                    Flag(\"root_dir\", &root_dir)});\n  if (!parse_result) {\n    LOG(ERROR) << \"Error parsing command-line flags.\";\n    return -1;\n  }\n\n  // We need to call this to set up global state for TensorFlow.\n  tensorflow::port::InitMain(argv[0], &argc, &argv);\n  if (argc > 1) {\n    LOG(ERROR) << \"Unknown argument \" << argv[1];\n    return -1;\n  }\n\n  // First we load and initialize the model.\n  std::unique_ptr<tensorflow::Session> session;\n  string graph_path = tensorflow::io::JoinPath(root_dir, graph);\n  Status load_graph_status = LoadGraph(graph_path, &session);\n  if (!load_graph_status.ok()) {\n    LOG(ERROR) << load_graph_status;\n    return -1;\n  }\n\n  // Get the image from disk as a float array of numbers, resized and normalized\n  // to the specifications the main graph expects.\n  std::vector<Tensor> resized_tensors;\n  string image_path = tensorflow::io::JoinPath(root_dir, image);\n  Status read_tensor_status =\n      ReadTensorFromImageFile(image_path, input_height, input_width, input_mean,\n                              input_std, &resized_tensors);\n  if (!read_tensor_status.ok()) {\n    LOG(ERROR) << read_tensor_status;\n    return -1;\n  }\n  const Tensor& resized_tensor = resized_tensors[0];\n\n  // Actually run the image through the model.\n  std::vector<Tensor> outputs;\n  Status run_status = session->Run({{\"input\", resized_tensor}},\n                                    {\"embeddings\"}, {}, &outputs);\n                                   // {output_layer}, {}, &outputs);\n  if (!run_status.ok()) {\n    LOG(ERROR) << \"Running model failed: \" << run_status;\n    return -1;\n  }\n\n\n  return 0;\n}\n\n```\n\nThanks!\n"}