{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/150156389", "pull_request_review_id": 75665828, "id": 150156389, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MDE1NjM4OQ==", "diff_hunk": "@@ -0,0 +1,336 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\n+\"\"\"Wrapper optimizer for Elastic Average SGD \"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import math_ops\n+\n+from tensorflow.python.ops import gen_nn_ops\n+from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import variable_scope\n+from tensorflow.python.ops import variables\n+from tensorflow.python.training import optimizer\n+from tensorflow.python.training import session_run_hook\n+from tensorflow.python.ops import state_ops\n+from tensorflow.python.ops import data_flow_ops\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import constant_op\n+\n+\n+class ElasticAverageCustomGetter(object):\n+  \"\"\"Custom_getter class is used to do:\n+  1. Change trainable variables to local collection and place them at worker\n+    device\n+  2. Generate global variables(global center variables)\n+  3. Generate local variables(local center variables) which record the global\n+    variables and place them at worker device\n+  4. Remain global step variable as global variable\n+    Notice that the class should be used with tf.replica_device_setter,\n+    so that the global center variables and global step variable can be placed\n+    at ps device. Besides, use 'tf.get_variable' instead of 'tf.Variable' to\n+    use this custom getter.\n+\n+  For example,\n+  ea_custom_getter = ElasticAverageCustomGetter(worker_device)\n+  with tf.device(\n+    tf.train.replica_device_setter(\n+      worker_device=worker_device,\n+      ps_device=\"/job:ps/cpu:0\",\n+      cluster=cluster)),\n+    tf.variable_scope('',custom_getter=ea_custom_getter):\n+    hid_w = tf.get_variable(\n+      initializer=tf.truncated_normal(\n+          [IMAGE_PIXELS * IMAGE_PIXELS, FLAGS.hidden_units],\n+          stddev=1.0 / IMAGE_PIXELS),\n+      name=\"hid_w\")\n+    hid_b = tf.get_variable(initializer=tf.zeros([FLAGS.hidden_units]),\n+                            name=\"hid_b\")\n+  \"\"\"\n+\n+  def __init__(self, worker_device):\n+    \"\"\"Create a new `ElasticAverageCustomGetter`.\n+\n+    Args:\n+      worker_device: String.  Name of the `worker` job.\n+    \"\"\"\n+    self._worker_device = worker_device\n+\n+  def __call__(self, getter, name, *args, **kwargs):\n+    if name.find('global_step') != -1:\n+      return getter(name, *args, **kwargs)\n+\n+    kwargs['collections'] = [ops.GraphKeys.LOCAL_VARIABLES]\n+    with ops.device(self._worker_device):\n+      local_var = getter(name, *args, **kwargs)\n+\n+    if kwargs['trainable']:\n+      global_center_variable = variables.Variable(\n+        name='%s/%s' %\n+             ('global_center_variable',\n+              name),\n+        initial_value=local_var.initialized_value(),\n+        trainable=False,\n+        collections=[\n+          ops.GraphKeys.GLOBAL_VARIABLES,\n+          'global_center_variable'])\n+\n+      with ops.device(self._worker_device):\n+        local_center_variable = variables.Variable(\n+          name='%s/%s' % ('local_center_variable', name),\n+          initial_value=local_var.initialized_value(),\n+          trainable=False,\n+          collections=[ops.GraphKeys.LOCAL_VARIABLES,\n+                       'local_center_variable'])", "path": "tensorflow/contrib/opt/python/training/elastic_average_optimizer.py", "position": null, "original_position": 99, "commit_id": "632eec0e3064232671de62517a7905242a7e6ecb", "original_commit_id": "77613c5a24863ab7a58022129a1a8715763dabfb", "user": {"login": "jinxin0924", "id": 8096033, "node_id": "MDQ6VXNlcjgwOTYwMzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/8096033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jinxin0924", "html_url": "https://github.com/jinxin0924", "followers_url": "https://api.github.com/users/jinxin0924/followers", "following_url": "https://api.github.com/users/jinxin0924/following{/other_user}", "gists_url": "https://api.github.com/users/jinxin0924/gists{/gist_id}", "starred_url": "https://api.github.com/users/jinxin0924/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jinxin0924/subscriptions", "organizations_url": "https://api.github.com/users/jinxin0924/orgs", "repos_url": "https://api.github.com/users/jinxin0924/repos", "events_url": "https://api.github.com/users/jinxin0924/events{/privacy}", "received_events_url": "https://api.github.com/users/jinxin0924/received_events", "type": "User", "site_admin": false}, "body": "I do not think passing the getter as a constructor to the optimizer will work. The local_var should be used to in forward computation and backward computation. But the global variables will be used in forward computation if the getter is not used before building the model(getter returns the local_var).\r\n", "created_at": "2017-11-10T05:24:19Z", "updated_at": "2017-12-11T05:39:16Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13012#discussion_r150156389", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13012", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/150156389"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13012#discussion_r150156389"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13012"}}, "body_html": "<p>I do not think passing the getter as a constructor to the optimizer will work. The local_var should be used to in forward computation and backward computation. But the global variables will be used in forward computation if the getter is not used before building the model(getter returns the local_var).</p>", "body_text": "I do not think passing the getter as a constructor to the optimizer will work. The local_var should be used to in forward computation and backward computation. But the global variables will be used in forward computation if the getter is not used before building the model(getter returns the local_var).", "in_reply_to_id": 150003462}