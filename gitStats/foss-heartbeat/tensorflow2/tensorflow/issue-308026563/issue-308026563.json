{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17951", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17951/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17951/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17951/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17951", "id": 308026563, "node_id": "MDU6SXNzdWUzMDgwMjY1NjM=", "number": 17951, "title": "Feature request: Create a function that handles errors for tf.train.SessionRunHook()", "user": {"login": "aforslow", "id": 17109848, "node_id": "MDQ6VXNlcjE3MTA5ODQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/17109848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aforslow", "html_url": "https://github.com/aforslow", "followers_url": "https://api.github.com/users/aforslow/followers", "following_url": "https://api.github.com/users/aforslow/following{/other_user}", "gists_url": "https://api.github.com/users/aforslow/gists{/gist_id}", "starred_url": "https://api.github.com/users/aforslow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aforslow/subscriptions", "organizations_url": "https://api.github.com/users/aforslow/orgs", "repos_url": "https://api.github.com/users/aforslow/repos", "events_url": "https://api.github.com/users/aforslow/events{/privacy}", "received_events_url": "https://api.github.com/users/aforslow/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-03-23T13:21:10Z", "updated_at": "2018-08-22T20:46:40Z", "closed_at": "2018-08-22T20:46:40Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 10 Pro 64-bit (10.0, Build 16299)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nBinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.6.0</li>\n<li><strong>Python version</strong>:<br>\n3.6.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>I would like an operation for tf.train.SessionRunHook() that executes when an error is thrown from the sess.run() (it should be able to act upon a single error/multiple errors (in a list)/all errors. The reason I would like this, is because there exists use cases where a hook action should be performed only when an error is raised.</p>\n<p>My current example of this use case is the switch between training and validation loops. I am, in a tf.train.MonitoredTrainingSession() trying to run a training loop and a validation loop that switches between each other. In order to achieve this, I'm using a tf.data.Dataset.iterator that runs in a while loop until a tf.errors.OutOfRangeError is thrown; breaking the while loop and moving on to the next. When this exception is thrown, I would like to perform hook actions, such as saving epoch summaries, print logging on the terminal, etc. My current way of doing this is to write these actions manually in the exception clause, as shown below. It would, however, be cleaner and easier if these actions could be performed in the hooks themselves when an error is thrown.</p>\n<h3>Source code / logs</h3>\n<p>Example code I am using currently:</p>\n<pre><code>import tensorflow as tf\nfrom functools import partial\n\ndef create_reset_metric(metric, scope='reset_metrics', **metric_args):\n    with tf.variable_scope(scope) as scope:\n        metric_op, update_op = metric(**metric_args)\n        vars = tf.contrib.framework.get_variables(\n                scope, collection=tf.GraphKeys.LOCAL_VARIABLES\n            )\n        reset_op = tf.variables_initializer(vars)\n    return metric_op, update_op, reset_op\n\ndataset_train = tf.data.Dataset.range(100)\niterator_train = dataset_train.make_initializable_iterator()\nnext_elem_train = iterator_train.get_next()\nmean_batch_train, mean_update_train, mean_reset_train = create_reset_metric(\n                                                            metric=tf.metrics.mean,\n                                                            scope='reset_metrics_train',\n                                                            values=next_elem_train)\nsummary_train = tf.summary.scalar('train_summary', mean_update_train, collections=['train'])\n\ndataset_test = tf.data.Dataset.range(50)\niterator_test = dataset_test.make_initializable_iterator()\nnext_elem_test = iterator_test.get_next()\nmean_batch_test, mean_update_test, mean_reset_test = create_reset_metric(\n                                                            metric=tf.metrics.mean,\n                                                            scope='reset_metrics_test',\n                                                            values=next_elem_test)\nsummary_test = tf.summary.scalar('test_summary', mean_update_test, collections=['test'])\n\nmerged_train_summary_op = tf.summary.merge_all('train')\nmerged_test_summary_op = tf.summary.merge_all('test')\n\ndef step_fn(fetches, feed_dict, step_context):\n    return step_context.session.run(fetches=fetches, feed_dict=feed_dict)\n\nwith tf.summary.FileWriter('./tmp/train_test_switch') as writer:\n    with tf.train.MonitoredTrainingSession() as sess:\n        epoch_step = 0\n        while not sess.should_stop():\n            sess.run_step_fn(partial(step_fn, iterator_train.initializer, {}))\n            while True:\n                try:\n                    summary_train_, _ = sess.run([merged_train_summary_op, next_elem_train])\n                except tf.errors.OutOfRangeError:\n                    writer.add_summary(summary_train_, epoch_step)\n                    sess.run_step_fn(partial(step_fn, mean_reset_train, {}))\n                    break\n\n            sess.run_step_fn(partial(step_fn, iterator_test.initializer, {}))\n            while True:\n                try:\n                    summary_test_, _ = sess.run([merged_test_summary_op, next_elem_test])\n                except tf.errors.OutOfRangeError:\n                    writer.add_summary(summary_test_, epoch_step)\n                    sess.run_step_fn(partial(step_fn, mean_reset_test, {}))\n                    break\n            print(\"epoch_step:\", epoch_step)\n            epoch_step += 1\n\n</code></pre>\n<p>Example of how I want the <code>tf.train.MonitoredTrainingSession()</code> to look (the beginning is the same as before):</p>\n<pre><code>...\n\nwith tf.summary.FileWriter('./tmp/train_test_switch') as writer:\n    error_catching_hook = ErrorCatchingHook(...)\n    with tf.train.MonitoredTrainingSession(hooks=[error_catching_hook]) as sess:\n        epoch_step = 0\n        while not sess.should_stop():\n            sess.run_step_fn(partial(step_fn, iterator_train.initializer, {}))\n            error_catching_hook.is_training() # Set flag to call correct params when OutOfRangeError\n            while True:\n                try:\n                    summary_train_, _ = sess.run([merged_train_summary_op, next_elem_train])\n                except tf.errors.OutOfRangeError:\n                    # error_catching_hook calls writer.add_summary(...)\n                    # error_catching_hook calls mean_reset_train\n                    break\n\n            sess.run_step_fn(partial(step_fn, iterator_test.initializer, {}))\n            error_catching_hook.is_testing() # Set flag to call correct params when OutOfRangeError\n            while True:\n                try:\n                    summary_test_, _ = sess.run([merged_test_summary_op, next_elem_test])\n                except tf.errors.OutOfRangeError:\n                    # error_catching_hook calls writer.add_summary(...)\n                    # error_catching_hook calls mean_reset_test\n                    break\n            print(\"epoch_step:\", epoch_step)\n            epoch_step += 1\n</code></pre>\n<p>I realize that this might not be the best example of a use case for this, but I hope you get my point, and I'm sure there are other use cases for this.</p>\n<p>After having read my code above, I also hope that this could provide a solution for others trying to gather and summarize epoch-wise data. A common pattern of summarizing train/test data is, after all, to summarize an epoch average after each epoch. This feels like an unnecessarily painful implementation task today, and I hope that this request of mine can at least bring down the pain a little bit. Hopefully, this can lead to a tf.train.EndOfSetHook() or similar, that is only called when a dataset reaches its end!</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 10 Pro 64-bit (10.0, Build 16299)\nTensorFlow installed from (source or binary):\nBinary\nTensorFlow version (use command below):\n1.6.0\nPython version:\n3.6.4\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nI would like an operation for tf.train.SessionRunHook() that executes when an error is thrown from the sess.run() (it should be able to act upon a single error/multiple errors (in a list)/all errors. The reason I would like this, is because there exists use cases where a hook action should be performed only when an error is raised.\nMy current example of this use case is the switch between training and validation loops. I am, in a tf.train.MonitoredTrainingSession() trying to run a training loop and a validation loop that switches between each other. In order to achieve this, I'm using a tf.data.Dataset.iterator that runs in a while loop until a tf.errors.OutOfRangeError is thrown; breaking the while loop and moving on to the next. When this exception is thrown, I would like to perform hook actions, such as saving epoch summaries, print logging on the terminal, etc. My current way of doing this is to write these actions manually in the exception clause, as shown below. It would, however, be cleaner and easier if these actions could be performed in the hooks themselves when an error is thrown.\nSource code / logs\nExample code I am using currently:\nimport tensorflow as tf\nfrom functools import partial\n\ndef create_reset_metric(metric, scope='reset_metrics', **metric_args):\n    with tf.variable_scope(scope) as scope:\n        metric_op, update_op = metric(**metric_args)\n        vars = tf.contrib.framework.get_variables(\n                scope, collection=tf.GraphKeys.LOCAL_VARIABLES\n            )\n        reset_op = tf.variables_initializer(vars)\n    return metric_op, update_op, reset_op\n\ndataset_train = tf.data.Dataset.range(100)\niterator_train = dataset_train.make_initializable_iterator()\nnext_elem_train = iterator_train.get_next()\nmean_batch_train, mean_update_train, mean_reset_train = create_reset_metric(\n                                                            metric=tf.metrics.mean,\n                                                            scope='reset_metrics_train',\n                                                            values=next_elem_train)\nsummary_train = tf.summary.scalar('train_summary', mean_update_train, collections=['train'])\n\ndataset_test = tf.data.Dataset.range(50)\niterator_test = dataset_test.make_initializable_iterator()\nnext_elem_test = iterator_test.get_next()\nmean_batch_test, mean_update_test, mean_reset_test = create_reset_metric(\n                                                            metric=tf.metrics.mean,\n                                                            scope='reset_metrics_test',\n                                                            values=next_elem_test)\nsummary_test = tf.summary.scalar('test_summary', mean_update_test, collections=['test'])\n\nmerged_train_summary_op = tf.summary.merge_all('train')\nmerged_test_summary_op = tf.summary.merge_all('test')\n\ndef step_fn(fetches, feed_dict, step_context):\n    return step_context.session.run(fetches=fetches, feed_dict=feed_dict)\n\nwith tf.summary.FileWriter('./tmp/train_test_switch') as writer:\n    with tf.train.MonitoredTrainingSession() as sess:\n        epoch_step = 0\n        while not sess.should_stop():\n            sess.run_step_fn(partial(step_fn, iterator_train.initializer, {}))\n            while True:\n                try:\n                    summary_train_, _ = sess.run([merged_train_summary_op, next_elem_train])\n                except tf.errors.OutOfRangeError:\n                    writer.add_summary(summary_train_, epoch_step)\n                    sess.run_step_fn(partial(step_fn, mean_reset_train, {}))\n                    break\n\n            sess.run_step_fn(partial(step_fn, iterator_test.initializer, {}))\n            while True:\n                try:\n                    summary_test_, _ = sess.run([merged_test_summary_op, next_elem_test])\n                except tf.errors.OutOfRangeError:\n                    writer.add_summary(summary_test_, epoch_step)\n                    sess.run_step_fn(partial(step_fn, mean_reset_test, {}))\n                    break\n            print(\"epoch_step:\", epoch_step)\n            epoch_step += 1\n\n\nExample of how I want the tf.train.MonitoredTrainingSession() to look (the beginning is the same as before):\n...\n\nwith tf.summary.FileWriter('./tmp/train_test_switch') as writer:\n    error_catching_hook = ErrorCatchingHook(...)\n    with tf.train.MonitoredTrainingSession(hooks=[error_catching_hook]) as sess:\n        epoch_step = 0\n        while not sess.should_stop():\n            sess.run_step_fn(partial(step_fn, iterator_train.initializer, {}))\n            error_catching_hook.is_training() # Set flag to call correct params when OutOfRangeError\n            while True:\n                try:\n                    summary_train_, _ = sess.run([merged_train_summary_op, next_elem_train])\n                except tf.errors.OutOfRangeError:\n                    # error_catching_hook calls writer.add_summary(...)\n                    # error_catching_hook calls mean_reset_train\n                    break\n\n            sess.run_step_fn(partial(step_fn, iterator_test.initializer, {}))\n            error_catching_hook.is_testing() # Set flag to call correct params when OutOfRangeError\n            while True:\n                try:\n                    summary_test_, _ = sess.run([merged_test_summary_op, next_elem_test])\n                except tf.errors.OutOfRangeError:\n                    # error_catching_hook calls writer.add_summary(...)\n                    # error_catching_hook calls mean_reset_test\n                    break\n            print(\"epoch_step:\", epoch_step)\n            epoch_step += 1\n\nI realize that this might not be the best example of a use case for this, but I hope you get my point, and I'm sure there are other use cases for this.\nAfter having read my code above, I also hope that this could provide a solution for others trying to gather and summarize epoch-wise data. A common pattern of summarizing train/test data is, after all, to summarize an epoch average after each epoch. This feels like an unnecessarily painful implementation task today, and I hope that this request of mine can at least bring down the pain a little bit. Hopefully, this can lead to a tf.train.EndOfSetHook() or similar, that is only called when a dataset reaches its end!", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 Pro 64-bit (10.0, Build 16299)\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.6.0\r\n- **Python version**: \r\n3.6.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI would like an operation for tf.train.SessionRunHook() that executes when an error is thrown from the sess.run() (it should be able to act upon a single error/multiple errors (in a list)/all errors. The reason I would like this, is because there exists use cases where a hook action should be performed only when an error is raised.\r\n\r\nMy current example of this use case is the switch between training and validation loops. I am, in a tf.train.MonitoredTrainingSession() trying to run a training loop and a validation loop that switches between each other. In order to achieve this, I'm using a tf.data.Dataset.iterator that runs in a while loop until a tf.errors.OutOfRangeError is thrown; breaking the while loop and moving on to the next. When this exception is thrown, I would like to perform hook actions, such as saving epoch summaries, print logging on the terminal, etc. My current way of doing this is to write these actions manually in the exception clause, as shown below. It would, however, be cleaner and easier if these actions could be performed in the hooks themselves when an error is thrown.\r\n\r\n### Source code / logs\r\nExample code I am using currently:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom functools import partial\r\n\r\ndef create_reset_metric(metric, scope='reset_metrics', **metric_args):\r\n    with tf.variable_scope(scope) as scope:\r\n        metric_op, update_op = metric(**metric_args)\r\n        vars = tf.contrib.framework.get_variables(\r\n                scope, collection=tf.GraphKeys.LOCAL_VARIABLES\r\n            )\r\n        reset_op = tf.variables_initializer(vars)\r\n    return metric_op, update_op, reset_op\r\n\r\ndataset_train = tf.data.Dataset.range(100)\r\niterator_train = dataset_train.make_initializable_iterator()\r\nnext_elem_train = iterator_train.get_next()\r\nmean_batch_train, mean_update_train, mean_reset_train = create_reset_metric(\r\n                                                            metric=tf.metrics.mean,\r\n                                                            scope='reset_metrics_train',\r\n                                                            values=next_elem_train)\r\nsummary_train = tf.summary.scalar('train_summary', mean_update_train, collections=['train'])\r\n\r\ndataset_test = tf.data.Dataset.range(50)\r\niterator_test = dataset_test.make_initializable_iterator()\r\nnext_elem_test = iterator_test.get_next()\r\nmean_batch_test, mean_update_test, mean_reset_test = create_reset_metric(\r\n                                                            metric=tf.metrics.mean,\r\n                                                            scope='reset_metrics_test',\r\n                                                            values=next_elem_test)\r\nsummary_test = tf.summary.scalar('test_summary', mean_update_test, collections=['test'])\r\n\r\nmerged_train_summary_op = tf.summary.merge_all('train')\r\nmerged_test_summary_op = tf.summary.merge_all('test')\r\n\r\ndef step_fn(fetches, feed_dict, step_context):\r\n    return step_context.session.run(fetches=fetches, feed_dict=feed_dict)\r\n\r\nwith tf.summary.FileWriter('./tmp/train_test_switch') as writer:\r\n    with tf.train.MonitoredTrainingSession() as sess:\r\n        epoch_step = 0\r\n        while not sess.should_stop():\r\n            sess.run_step_fn(partial(step_fn, iterator_train.initializer, {}))\r\n            while True:\r\n                try:\r\n                    summary_train_, _ = sess.run([merged_train_summary_op, next_elem_train])\r\n                except tf.errors.OutOfRangeError:\r\n                    writer.add_summary(summary_train_, epoch_step)\r\n                    sess.run_step_fn(partial(step_fn, mean_reset_train, {}))\r\n                    break\r\n\r\n            sess.run_step_fn(partial(step_fn, iterator_test.initializer, {}))\r\n            while True:\r\n                try:\r\n                    summary_test_, _ = sess.run([merged_test_summary_op, next_elem_test])\r\n                except tf.errors.OutOfRangeError:\r\n                    writer.add_summary(summary_test_, epoch_step)\r\n                    sess.run_step_fn(partial(step_fn, mean_reset_test, {}))\r\n                    break\r\n            print(\"epoch_step:\", epoch_step)\r\n            epoch_step += 1\r\n\r\n```\r\n\r\nExample of how I want the `tf.train.MonitoredTrainingSession()` to look (the beginning is the same as before):\r\n\r\n```\r\n...\r\n\r\nwith tf.summary.FileWriter('./tmp/train_test_switch') as writer:\r\n    error_catching_hook = ErrorCatchingHook(...)\r\n    with tf.train.MonitoredTrainingSession(hooks=[error_catching_hook]) as sess:\r\n        epoch_step = 0\r\n        while not sess.should_stop():\r\n            sess.run_step_fn(partial(step_fn, iterator_train.initializer, {}))\r\n            error_catching_hook.is_training() # Set flag to call correct params when OutOfRangeError\r\n            while True:\r\n                try:\r\n                    summary_train_, _ = sess.run([merged_train_summary_op, next_elem_train])\r\n                except tf.errors.OutOfRangeError:\r\n                    # error_catching_hook calls writer.add_summary(...)\r\n                    # error_catching_hook calls mean_reset_train\r\n                    break\r\n\r\n            sess.run_step_fn(partial(step_fn, iterator_test.initializer, {}))\r\n            error_catching_hook.is_testing() # Set flag to call correct params when OutOfRangeError\r\n            while True:\r\n                try:\r\n                    summary_test_, _ = sess.run([merged_test_summary_op, next_elem_test])\r\n                except tf.errors.OutOfRangeError:\r\n                    # error_catching_hook calls writer.add_summary(...)\r\n                    # error_catching_hook calls mean_reset_test\r\n                    break\r\n            print(\"epoch_step:\", epoch_step)\r\n            epoch_step += 1\r\n```\r\n\r\nI realize that this might not be the best example of a use case for this, but I hope you get my point, and I'm sure there are other use cases for this. \r\n\r\nAfter having read my code above, I also hope that this could provide a solution for others trying to gather and summarize epoch-wise data. A common pattern of summarizing train/test data is, after all, to summarize an epoch average after each epoch. This feels like an unnecessarily painful implementation task today, and I hope that this request of mine can at least bring down the pain a little bit. Hopefully, this can lead to a tf.train.EndOfSetHook() or similar, that is only called when a dataset reaches its end!"}