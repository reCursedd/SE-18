{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13935", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13935/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13935/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13935/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/13935", "id": 267877696, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQ4MjgzOTQ5", "number": 13935, "title": "Fix mnist_softmax tutorial: W should be randomly initialized, should \u2026", "user": {"login": "eeandrew", "id": 7982269, "node_id": "MDQ6VXNlcjc5ODIyNjk=", "avatar_url": "https://avatars2.githubusercontent.com/u/7982269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eeandrew", "html_url": "https://github.com/eeandrew", "followers_url": "https://api.github.com/users/eeandrew/followers", "following_url": "https://api.github.com/users/eeandrew/following{/other_user}", "gists_url": "https://api.github.com/users/eeandrew/gists{/gist_id}", "starred_url": "https://api.github.com/users/eeandrew/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eeandrew/subscriptions", "organizations_url": "https://api.github.com/users/eeandrew/orgs", "repos_url": "https://api.github.com/users/eeandrew/repos", "events_url": "https://api.github.com/users/eeandrew/events{/privacy}", "received_events_url": "https://api.github.com/users/eeandrew/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 390482148, "node_id": "MDU6TGFiZWwzOTA0ODIxNDg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20review", "name": "awaiting review", "color": "fef2c0", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-10-24T02:34:41Z", "updated_at": "2017-10-26T00:53:16Z", "closed_at": "2017-10-26T00:53:16Z", "author_association": "NONE", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13935", "html_url": "https://github.com/tensorflow/tensorflow/pull/13935", "diff_url": "https://github.com/tensorflow/tensorflow/pull/13935.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/13935.patch"}, "body_html": "<p>Fix mnist_softmax tutorial: W should be randomly initialized, should not be initialized as zeros. Otherwise, you will get a symmetric NN.</p>\n<pre><code># This is wrong and misleading. W should not initialized as zeros. \n# If you do so, you will get a symmetric network. \nW = tf.Variable(tf.zeros([784, 10]))\n</code></pre>\n<p>Instead, W should be randomly initialized</p>\n<pre><code>W = tf.Variable(tf.random_normal([784, 10]))\n</code></pre>\n<p>Actually, there is another mistake:</p>\n<pre><code># This is not how we use mini-batch in practical environment\nfor _ in range(1000):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n</code></pre>\n<p>Instead, mini-batch should be used as follows:</p>\n<pre><code>for _ in range(1000):\n   for batch in range(550):\n      batch_xs, batch_ys = mnist.train.next_batch(100)\n      sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n</code></pre>\n<p>But maybe for simplicity, we can ignore this mistake</p>", "body_text": "Fix mnist_softmax tutorial: W should be randomly initialized, should not be initialized as zeros. Otherwise, you will get a symmetric NN.\n# This is wrong and misleading. W should not initialized as zeros. \n# If you do so, you will get a symmetric network. \nW = tf.Variable(tf.zeros([784, 10]))\n\nInstead, W should be randomly initialized\nW = tf.Variable(tf.random_normal([784, 10]))\n\nActually, there is another mistake:\n# This is not how we use mini-batch in practical environment\nfor _ in range(1000):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\nInstead, mini-batch should be used as follows:\nfor _ in range(1000):\n   for batch in range(550):\n      batch_xs, batch_ys = mnist.train.next_batch(100)\n      sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\nBut maybe for simplicity, we can ignore this mistake", "body": "Fix mnist_softmax tutorial: W should be randomly initialized, should not be initialized as zeros. Otherwise, you will get a symmetric NN.\r\n```\r\n# This is wrong and misleading. W should not initialized as zeros. \r\n# If you do so, you will get a symmetric network. \r\nW = tf.Variable(tf.zeros([784, 10]))\r\n```\r\nInstead, W should be randomly initialized\r\n```\r\nW = tf.Variable(tf.random_normal([784, 10]))\r\n```\r\nActually, there is another mistake:\r\n```\r\n# This is not how we use mini-batch in practical environment\r\nfor _ in range(1000):\r\n    batch_xs, batch_ys = mnist.train.next_batch(100)\r\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\r\n```\r\nInstead, mini-batch should be used as follows:\r\n```\r\nfor _ in range(1000):\r\n   for batch in range(550):\r\n      batch_xs, batch_ys = mnist.train.next_batch(100)\r\n      sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\r\n```\r\nBut maybe for simplicity, we can ignore this mistake"}