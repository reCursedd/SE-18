{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/79578179", "pull_request_review_id": 717944, "id": 79578179, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc5NTc4MTc5", "diff_hunk": "@@ -119,57 +121,108 @@ bool PortableReadFileToProto(const std::string& file_name,\n tensorflow::Status LoadModel(NSString* file_name, NSString* file_type,\n                              std::unique_ptr<tensorflow::Session>* session) {\n   tensorflow::SessionOptions options;\n-  \n+\n   tensorflow::Session* session_pointer = nullptr;\n-  tensorflow::Status session_status = tensorflow::NewSession(options, &session_pointer);\n+  tensorflow::Status session_status =\n+      tensorflow::NewSession(options, &session_pointer);\n   if (!session_status.ok()) {\n     LOG(ERROR) << \"Could not create TensorFlow Session: \" << session_status;\n     return session_status;\n   }\n   session->reset(session_pointer);\n-  LOG(INFO) << \"Session created.\";\n-  \n+\n   tensorflow::GraphDef tensorflow_graph;\n-  LOG(INFO) << \"Graph created.\";\n-  \n+\n   NSString* model_path = FilePathForResourceName(file_name, file_type);\n   if (!model_path) {\n     LOG(ERROR) << \"Failed to find model proto at\" << [file_name UTF8String]\n                << [file_type UTF8String];\n     return tensorflow::errors::NotFound([file_name UTF8String],\n                                         [file_type UTF8String]);\n   }\n-  const bool read_proto_succeeded = PortableReadFileToProto(\n-    [model_path UTF8String], &tensorflow_graph);\n+  const bool read_proto_succeeded =\n+      PortableReadFileToProto([model_path UTF8String], &tensorflow_graph);\n   if (!read_proto_succeeded) {\n     LOG(ERROR) << \"Failed to load model proto from\" << [model_path UTF8String];\n     return tensorflow::errors::NotFound([model_path UTF8String]);\n   }\n-  \n-  LOG(INFO) << \"Creating session.\";\n+\n   tensorflow::Status create_status = (*session)->Create(tensorflow_graph);\n   if (!create_status.ok()) {\n     LOG(ERROR) << \"Could not create TensorFlow Graph: \" << create_status;\n     return create_status;\n   }\n-  \n+\n+  return tensorflow::Status::OK();\n+}\n+\n+tensorflow::Status LoadMemoryMappedModel(\n+    NSString* file_name, NSString* file_type,\n+    std::unique_ptr<tensorflow::Session>* session,\n+    std::unique_ptr<tensorflow::MemmappedEnv>* memmapped_env) {\n+  NSString* network_path = FilePathForResourceName(file_name, file_type);\n+  memmapped_env->reset(\n+      new tensorflow::MemmappedEnv(tensorflow::Env::Default()));\n+  tensorflow::Status mmap_status =\n+      (memmapped_env->get())->InitializeFromFile([network_path UTF8String]);\n+  if (!mmap_status.ok()) {\n+    LOG(ERROR) << \"MMap failed with \" << mmap_status.error_message();\n+    return mmap_status;\n+  }\n+\n+  tensorflow::GraphDef tensorflow_graph;\n+  tensorflow::Status load_graph_status = ReadBinaryProto(\n+      memmapped_env->get(),\n+      tensorflow::MemmappedFileSystem::kMemmappedPackageDefaultGraphDef,\n+      &tensorflow_graph);\n+  if (!load_graph_status.ok()) {\n+    LOG(ERROR) << \"MMap load graph failed with \"\n+               << load_graph_status.error_message();\n+    return load_graph_status;\n+  }\n+\n+  tensorflow::SessionOptions options;\n+  // Disable optimizations on this graph so that constant folding doesn't\n+  // increase the memory footprint by creating new constant copies of the weight", "path": "tensorflow/contrib/ios_examples/camera/tensorflow_utils.mm", "position": 200, "original_position": 200, "commit_id": "d6f387ac14119a959fab5e87680f79aaa2807978", "original_commit_id": "3908e2d3dc799daac0f756fe6fb0f54a3087c9df", "user": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "body": "This only happens if it's used in a subsequent expression, so in general it's doing the right thing. It would be good to have an option to disable this optimization just for subgraphs that have ImmutableConsts as their source though. I'd also like to get constant folding into optimize_graph as an offline process too.\n", "created_at": "2016-09-20T10:18:35Z", "updated_at": "2016-09-20T10:33:04Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4457#discussion_r79578179", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4457", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/79578179"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4457#discussion_r79578179"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4457"}}, "body_html": "<p>This only happens if it's used in a subsequent expression, so in general it's doing the right thing. It would be good to have an option to disable this optimization just for subgraphs that have ImmutableConsts as their source though. I'd also like to get constant folding into optimize_graph as an offline process too.</p>", "body_text": "This only happens if it's used in a subsequent expression, so in general it's doing the right thing. It would be good to have an option to disable this optimization just for subgraphs that have ImmutableConsts as their source though. I'd also like to get constant folding into optimize_graph as an offline process too.", "in_reply_to_id": 79403802}