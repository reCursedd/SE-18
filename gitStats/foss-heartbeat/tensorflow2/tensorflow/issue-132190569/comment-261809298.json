{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261809298", "html_url": "https://github.com/tensorflow/tensorflow/issues/1021#issuecomment-261809298", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1021", "id": 261809298, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTgwOTI5OA==", "user": {"login": "ulgus", "id": 23620296, "node_id": "MDQ6VXNlcjIzNjIwMjk2", "avatar_url": "https://avatars2.githubusercontent.com/u/23620296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ulgus", "html_url": "https://github.com/ulgus", "followers_url": "https://api.github.com/users/ulgus/followers", "following_url": "https://api.github.com/users/ulgus/following{/other_user}", "gists_url": "https://api.github.com/users/ulgus/gists{/gist_id}", "starred_url": "https://api.github.com/users/ulgus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ulgus/subscriptions", "organizations_url": "https://api.github.com/users/ulgus/orgs", "repos_url": "https://api.github.com/users/ulgus/repos", "events_url": "https://api.github.com/users/ulgus/events{/privacy}", "received_events_url": "https://api.github.com/users/ulgus/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-20T22:01:19Z", "updated_at": "2016-11-21T11:20:15Z", "author_association": "NONE", "body_html": "<p>If I get this code right, the fix works for evaluation purposes only (i.e., computing top-k-error). Is there a way to extract the bottleneck vectors themselves (pool_3:0) in a batched fashion?</p>\n<p>Cmp. this thread, for example: <a href=\"http://stackoverflow.com/questions/35274457/inceptionv3-and-transfer-learning-with-tensorflow/40709836#40709836\" rel=\"nofollow\">http://stackoverflow.com/questions/35274457/inceptionv3-and-transfer-learning-with-tensorflow/40709836#40709836</a></p>\n<p>I tried the solution proposed there (basically setting feed_dict={'ResizeBilinear:0':imgs}, where imgs is an array with, say, 10 stacked images) but it didn't work (\"Cannot feed value of shape (10, 299, 299, 3) for Tensor u'ResizeBilinear:0', which has shape '(1, 299, 299, 3)'\"). I tested with tensorflow v0.10.0 and 0.11.0rc0, and the inception model downloaded from <a href=\"http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\" rel=\"nofollow\">http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz</a>.</p>\n<p>Thanks in advance -</p>", "body_text": "If I get this code right, the fix works for evaluation purposes only (i.e., computing top-k-error). Is there a way to extract the bottleneck vectors themselves (pool_3:0) in a batched fashion?\nCmp. this thread, for example: http://stackoverflow.com/questions/35274457/inceptionv3-and-transfer-learning-with-tensorflow/40709836#40709836\nI tried the solution proposed there (basically setting feed_dict={'ResizeBilinear:0':imgs}, where imgs is an array with, say, 10 stacked images) but it didn't work (\"Cannot feed value of shape (10, 299, 299, 3) for Tensor u'ResizeBilinear:0', which has shape '(1, 299, 299, 3)'\"). I tested with tensorflow v0.10.0 and 0.11.0rc0, and the inception model downloaded from http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz.\nThanks in advance -", "body": "If I get this code right, the fix works for evaluation purposes only (i.e., computing top-k-error). Is there a way to extract the bottleneck vectors themselves (pool_3:0) in a batched fashion?\r\n\r\nCmp. this thread, for example: http://stackoverflow.com/questions/35274457/inceptionv3-and-transfer-learning-with-tensorflow/40709836#40709836\r\n\r\nI tried the solution proposed there (basically setting feed_dict={'ResizeBilinear:0':imgs}, where imgs is an array with, say, 10 stacked images) but it didn't work (\"Cannot feed value of shape (10, 299, 299, 3) for Tensor u'ResizeBilinear:0', which has shape '(1, 299, 299, 3)'\"). I tested with tensorflow v0.10.0 and 0.11.0rc0, and the inception model downloaded from http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz.\r\n\r\nThanks in advance -"}