{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/424890257", "html_url": "https://github.com/tensorflow/tensorflow/issues/22378#issuecomment-424890257", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22378", "id": 424890257, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDg5MDI1Nw==", "user": {"login": "nairouz", "id": 10966954, "node_id": "MDQ6VXNlcjEwOTY2OTU0", "avatar_url": "https://avatars0.githubusercontent.com/u/10966954?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nairouz", "html_url": "https://github.com/nairouz", "followers_url": "https://api.github.com/users/nairouz/followers", "following_url": "https://api.github.com/users/nairouz/following{/other_user}", "gists_url": "https://api.github.com/users/nairouz/gists{/gist_id}", "starred_url": "https://api.github.com/users/nairouz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nairouz/subscriptions", "organizations_url": "https://api.github.com/users/nairouz/orgs", "repos_url": "https://api.github.com/users/nairouz/repos", "events_url": "https://api.github.com/users/nairouz/events{/privacy}", "received_events_url": "https://api.github.com/users/nairouz/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-26T22:29:05Z", "updated_at": "2018-09-26T22:30:50Z", "author_association": "NONE", "body_html": "<p>Actually, I have found a workaround. I can simply wrap the tensor which I want to exclude from the gradient computation with <code>tfe.Variable()</code>.<br>\nThe code would look something like this</p>\n<pre><code>\ndef virtual_adversarial_loss(X, DAE_encoder):\n    r_vadv = tfe.Variable(generate_virtual_adversarial_perturbation(X, DAE_encoder))\n    p = tfe.Variable(DAE_encoder(X))\n    q = DAE_encoder(X+r_vadv)\n    loss = tf.reduce_mean(kl(p, q), axis=0)\n    return tf.identity(loss, name=\"vat_loss\")\n\n</code></pre>\n<p>But obviously, this is not intuitive at all.</p>", "body_text": "Actually, I have found a workaround. I can simply wrap the tensor which I want to exclude from the gradient computation with tfe.Variable().\nThe code would look something like this\n\ndef virtual_adversarial_loss(X, DAE_encoder):\n    r_vadv = tfe.Variable(generate_virtual_adversarial_perturbation(X, DAE_encoder))\n    p = tfe.Variable(DAE_encoder(X))\n    q = DAE_encoder(X+r_vadv)\n    loss = tf.reduce_mean(kl(p, q), axis=0)\n    return tf.identity(loss, name=\"vat_loss\")\n\n\nBut obviously, this is not intuitive at all.", "body": "Actually, I have found a workaround. I can simply wrap the tensor which I want to exclude from the gradient computation with `tfe.Variable()`.\r\nThe code would look something like this\r\n```\r\n\r\ndef virtual_adversarial_loss(X, DAE_encoder):\r\n    r_vadv = tfe.Variable(generate_virtual_adversarial_perturbation(X, DAE_encoder))\r\n    p = tfe.Variable(DAE_encoder(X))\r\n    q = DAE_encoder(X+r_vadv)\r\n    loss = tf.reduce_mean(kl(p, q), axis=0)\r\n    return tf.identity(loss, name=\"vat_loss\")\r\n\r\n```\r\nBut obviously, this is not intuitive at all."}