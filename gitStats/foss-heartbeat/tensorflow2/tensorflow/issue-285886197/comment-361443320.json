{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/361443320", "html_url": "https://github.com/tensorflow/tensorflow/issues/15833#issuecomment-361443320", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15833", "id": 361443320, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTQ0MzMyMA==", "user": {"login": "shoyer", "id": 1217238, "node_id": "MDQ6VXNlcjEyMTcyMzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoyer", "html_url": "https://github.com/shoyer", "followers_url": "https://api.github.com/users/shoyer/followers", "following_url": "https://api.github.com/users/shoyer/following{/other_user}", "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions", "organizations_url": "https://api.github.com/users/shoyer/orgs", "repos_url": "https://api.github.com/users/shoyer/repos", "events_url": "https://api.github.com/users/shoyer/events{/privacy}", "received_events_url": "https://api.github.com/users/shoyer/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-30T01:13:40Z", "updated_at": "2018-01-30T01:13:40Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=14889516\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/LionSR\">@LionSR</a> Can you provide code that reproduces this issue and report the error message you find?</p>\n<p>As a simple example, here how you could modify the Lorenz equation example from the docs to optimize the initial conditions for the ODE:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> matplotlib.pyplot <span class=\"pl-k\">as</span> plt\n\nrho <span class=\"pl-k\">=</span> <span class=\"pl-c1\">28.0</span>\nsigma <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10.0</span>\nbeta <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8.0</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">3.0</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">lorenz_equation</span>(<span class=\"pl-smi\">state</span>, <span class=\"pl-smi\">t</span>):\n  x, y, z <span class=\"pl-k\">=</span> tf.unstack(state)\n  dx <span class=\"pl-k\">=</span> sigma <span class=\"pl-k\">*</span> (y <span class=\"pl-k\">-</span> x)\n  dy <span class=\"pl-k\">=</span> x <span class=\"pl-k\">*</span> (rho <span class=\"pl-k\">-</span> z) <span class=\"pl-k\">-</span> y\n  dz <span class=\"pl-k\">=</span> x <span class=\"pl-k\">*</span> y <span class=\"pl-k\">-</span> beta <span class=\"pl-k\">*</span> z\n  <span class=\"pl-k\">return</span> tf.stack([dx, dy, dz])\n\ntarget <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">20</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float64)\ninit_state <span class=\"pl-k\">=</span> tf.Variable(target)\nt <span class=\"pl-k\">=</span> np.linspace(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0.5</span>, <span class=\"pl-v\">num</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>)\ntensor_state, tensor_info <span class=\"pl-k\">=</span> tf.contrib.integrate.odeint(\n    lorenz_equation, init_state, t, <span class=\"pl-v\">full_output</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\nloss <span class=\"pl-k\">=</span> tf.reduce_sum((tensor_state[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>] <span class=\"pl-k\">-</span> target) <span class=\"pl-k\">**</span> <span class=\"pl-c1\">2</span>)\ntrain_step <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">5e-2</span>).minimize(loss)\n\nsess <span class=\"pl-k\">=</span> tf.Session()\nsess.run(tf.global_variables_initializer())\nlosses <span class=\"pl-k\">=</span> []\ntrajectories <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">100</span>):\n  loss_eval, trajectory, _ <span class=\"pl-k\">=</span> sess.run([loss, tensor_state, train_step])\n  losses.append(loss_eval)\n  trajectories.append(trajectory)\n  <span class=\"pl-k\">if</span> i <span class=\"pl-k\">%</span> <span class=\"pl-c1\">10</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n    <span class=\"pl-c1\">print</span>(loss_eval)</pre></div>\n<p>It doesn't entirely converge (this problem is probably non-convex), but the loss decreases over time. The program prints:</p>\n<pre><code>663.541165873\n4.66117861453\n3.95432178915\n3.5868347332\n3.37596507952\n3.25978177698\n3.19799942176\n3.16602229662\n3.14980148132\n3.14169093144\n</code></pre>", "body_text": "@LionSR Can you provide code that reproduces this issue and report the error message you find?\nAs a simple example, here how you could modify the Lorenz equation example from the docs to optimize the initial conditions for the ODE:\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nrho = 28.0\nsigma = 10.0\nbeta = 8.0/3.0\n\ndef lorenz_equation(state, t):\n  x, y, z = tf.unstack(state)\n  dx = sigma * (y - x)\n  dy = x * (rho - z) - y\n  dz = x * y - beta * z\n  return tf.stack([dx, dy, dz])\n\ntarget = tf.constant([0, 2, 20], dtype=tf.float64)\ninit_state = tf.Variable(target)\nt = np.linspace(0, 0.5, num=100)\ntensor_state, tensor_info = tf.contrib.integrate.odeint(\n    lorenz_equation, init_state, t, full_output=True)\n\nloss = tf.reduce_sum((tensor_state[-1] - target) ** 2)\ntrain_step = tf.train.GradientDescentOptimizer(5e-2).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nlosses = []\ntrajectories = []\nfor i in range(100):\n  loss_eval, trajectory, _ = sess.run([loss, tensor_state, train_step])\n  losses.append(loss_eval)\n  trajectories.append(trajectory)\n  if i % 10 == 0:\n    print(loss_eval)\nIt doesn't entirely converge (this problem is probably non-convex), but the loss decreases over time. The program prints:\n663.541165873\n4.66117861453\n3.95432178915\n3.5868347332\n3.37596507952\n3.25978177698\n3.19799942176\n3.16602229662\n3.14980148132\n3.14169093144", "body": "@LionSR Can you provide code that reproduces this issue and report the error message you find?\r\n\r\nAs a simple example, here how you could modify the Lorenz equation example from the docs to optimize the initial conditions for the ODE:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nrho = 28.0\r\nsigma = 10.0\r\nbeta = 8.0/3.0\r\n\r\ndef lorenz_equation(state, t):\r\n  x, y, z = tf.unstack(state)\r\n  dx = sigma * (y - x)\r\n  dy = x * (rho - z) - y\r\n  dz = x * y - beta * z\r\n  return tf.stack([dx, dy, dz])\r\n\r\ntarget = tf.constant([0, 2, 20], dtype=tf.float64)\r\ninit_state = tf.Variable(target)\r\nt = np.linspace(0, 0.5, num=100)\r\ntensor_state, tensor_info = tf.contrib.integrate.odeint(\r\n    lorenz_equation, init_state, t, full_output=True)\r\n\r\nloss = tf.reduce_sum((tensor_state[-1] - target) ** 2)\r\ntrain_step = tf.train.GradientDescentOptimizer(5e-2).minimize(loss)\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nlosses = []\r\ntrajectories = []\r\nfor i in range(100):\r\n  loss_eval, trajectory, _ = sess.run([loss, tensor_state, train_step])\r\n  losses.append(loss_eval)\r\n  trajectories.append(trajectory)\r\n  if i % 10 == 0:\r\n    print(loss_eval)\r\n```\r\nIt doesn't entirely converge (this problem is probably non-convex), but the loss decreases over time. The program prints:\r\n```\r\n663.541165873\r\n4.66117861453\r\n3.95432178915\r\n3.5868347332\r\n3.37596507952\r\n3.25978177698\r\n3.19799942176\r\n3.16602229662\r\n3.14980148132\r\n3.14169093144\r\n```"}