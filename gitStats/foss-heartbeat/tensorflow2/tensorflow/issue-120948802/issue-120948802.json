{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/443", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/443/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/443/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/443/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/443", "id": 120948802, "node_id": "MDU6SXNzdWUxMjA5NDg4MDI=", "number": 443, "title": "Feature Request: LogSoftmax layer", "user": {"login": "fabiencro", "id": 6006273, "node_id": "MDQ6VXNlcjYwMDYyNzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6006273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fabiencro", "html_url": "https://github.com/fabiencro", "followers_url": "https://api.github.com/users/fabiencro/followers", "following_url": "https://api.github.com/users/fabiencro/following{/other_user}", "gists_url": "https://api.github.com/users/fabiencro/gists{/gist_id}", "starred_url": "https://api.github.com/users/fabiencro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fabiencro/subscriptions", "organizations_url": "https://api.github.com/users/fabiencro/orgs", "repos_url": "https://api.github.com/users/fabiencro/repos", "events_url": "https://api.github.com/users/fabiencro/events{/privacy}", "received_events_url": "https://api.github.com/users/fabiencro/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2015-12-08T07:11:40Z", "updated_at": "2017-02-09T22:37:50Z", "closed_at": "2016-03-30T15:36:48Z", "author_association": "NONE", "body_html": "<p>Torch has a LogSoftmax layer, that does what the name imply: it is the equivalent of a softmax followed by a log. However, I could not find a similar layer in tensorflow.</p>\n<p>LogSoftmax is quite convenient because I am often more interested in log-probabilities (eg for computing a log-likelihood) than in the probabilities themselves.</p>\n<p>Further, I suspect a LogSoftmax can be implemented more efficiently than a Softmax (it should at least saves a log call, if one is interested in the log-probabilities; plus it is less sensitive to underflow/overflows). Indeed Torch documentation indicates it is faster when one need the log-probabilities.</p>\n<p>Would you consider adding such a layer at some point?</p>", "body_text": "Torch has a LogSoftmax layer, that does what the name imply: it is the equivalent of a softmax followed by a log. However, I could not find a similar layer in tensorflow.\nLogSoftmax is quite convenient because I am often more interested in log-probabilities (eg for computing a log-likelihood) than in the probabilities themselves.\nFurther, I suspect a LogSoftmax can be implemented more efficiently than a Softmax (it should at least saves a log call, if one is interested in the log-probabilities; plus it is less sensitive to underflow/overflows). Indeed Torch documentation indicates it is faster when one need the log-probabilities.\nWould you consider adding such a layer at some point?", "body": "Torch has a LogSoftmax layer, that does what the name imply: it is the equivalent of a softmax followed by a log. However, I could not find a similar layer in tensorflow.\n\nLogSoftmax is quite convenient because I am often more interested in log-probabilities (eg for computing a log-likelihood) than in the probabilities themselves. \n\nFurther, I suspect a LogSoftmax can be implemented more efficiently than a Softmax (it should at least saves a log call, if one is interested in the log-probabilities; plus it is less sensitive to underflow/overflows). Indeed Torch documentation indicates it is faster when one need the log-probabilities.\n\nWould you consider adding such a layer at some point?\n"}