{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/267513155", "html_url": "https://github.com/tensorflow/tensorflow/issues/6326#issuecomment-267513155", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6326", "id": 267513155, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NzUxMzE1NQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-16T04:14:07Z", "updated_at": "2016-12-16T04:14:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Some random ideas -- attach to the stuck server with <code>gdb -p ...</code> and do <code>gdb bt</code> to get backtrace to see if it's problem in saver implementation. Provide which version of tensorflow you are using. Try with latest version (12rc1). Try with <code>sharded=True</code> for the Saver since it may try different codepath. Finally you could try fetching the weights manually from parameter server as numpy arrays, maybe that'll expose the problem you have with distributed receiving</p>", "body_text": "Some random ideas -- attach to the stuck server with gdb -p ... and do gdb bt to get backtrace to see if it's problem in saver implementation. Provide which version of tensorflow you are using. Try with latest version (12rc1). Try with sharded=True for the Saver since it may try different codepath. Finally you could try fetching the weights manually from parameter server as numpy arrays, maybe that'll expose the problem you have with distributed receiving", "body": "Some random ideas -- attach to the stuck server with `gdb -p ...` and do `gdb bt` to get backtrace to see if it's problem in saver implementation. Provide which version of tensorflow you are using. Try with latest version (12rc1). Try with `sharded=True` for the Saver since it may try different codepath. Finally you could try fetching the weights manually from parameter server as numpy arrays, maybe that'll expose the problem you have with distributed receiving"}