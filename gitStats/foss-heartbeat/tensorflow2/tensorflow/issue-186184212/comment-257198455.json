{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257198455", "html_url": "https://github.com/tensorflow/tensorflow/issues/5293#issuecomment-257198455", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5293", "id": 257198455, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NzE5ODQ1NQ==", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-31T01:57:24Z", "updated_at": "2016-10-31T01:57:24Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=170179\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jhseu\">@jhseu</a> for comments</p>\n<p>The native format for Spark is parquet, for which you can now get a C++ reader/writer from impala.</p>\n<p>The ORC format does have a C++ reader, but it lacks bloom filters and a variety of compression algorithms. It has been extracted out of the hadoop code as a standalone recently.</p>\n<p>The legacy MR RCFile format is very, very Java dependent and I wouldn't want to support that.</p>", "body_text": "@jhseu for comments\nThe native format for Spark is parquet, for which you can now get a C++ reader/writer from impala.\nThe ORC format does have a C++ reader, but it lacks bloom filters and a variety of compression algorithms. It has been extracted out of the hadoop code as a standalone recently.\nThe legacy MR RCFile format is very, very Java dependent and I wouldn't want to support that.", "body": "@jhseu for comments\n\nThe native format for Spark is parquet, for which you can now get a C++ reader/writer from impala.\n\nThe ORC format does have a C++ reader, but it lacks bloom filters and a variety of compression algorithms. It has been extracted out of the hadoop code as a standalone recently.\n\nThe legacy MR RCFile format is very, very Java dependent and I wouldn't want to support that.\n"}