{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9824", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9824/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9824/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9824/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9824", "id": 227865985, "node_id": "MDU6SXNzdWUyMjc4NjU5ODU=", "number": 9824, "title": "possible bug - LSTMCell and GRUCell have different variable reuse behavior", "user": {"login": "Sycor4x", "id": 17602932, "node_id": "MDQ6VXNlcjE3NjAyOTMy", "avatar_url": "https://avatars3.githubusercontent.com/u/17602932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sycor4x", "html_url": "https://github.com/Sycor4x", "followers_url": "https://api.github.com/users/Sycor4x/followers", "following_url": "https://api.github.com/users/Sycor4x/following{/other_user}", "gists_url": "https://api.github.com/users/Sycor4x/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sycor4x/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sycor4x/subscriptions", "organizations_url": "https://api.github.com/users/Sycor4x/orgs", "repos_url": "https://api.github.com/users/Sycor4x/repos", "events_url": "https://api.github.com/users/Sycor4x/events{/privacy}", "received_events_url": "https://api.github.com/users/Sycor4x/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2017-05-11T03:04:09Z", "updated_at": "2017-06-04T00:31:27Z", "closed_at": "2017-06-04T00:31:27Z", "author_association": "NONE", "body_html": "<p><a href=\"https://github.com/tensorflow/tensorflow/files/999124/tf_env.txt\">tf_env.txt</a></p>\n<h3>System information</h3>\n<p>Capture script output is attached.</p>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes -- see below</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:  OS X 10.12.4</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.1.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>:  NA</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>class ToyModel(object):\n\tdef __init__(self):\n\t\tx = tf.get_variable(\"x\", shape=[10,32,3], initializer=tf.random_uniform_initializer(), trainable=False)\n\t\tcell = tf.contrib.rnn.LSTMCell(3)\n\t\tself.y, _ = tf.nn.dynamic_rnn(cell, inputs=x, dtype=tf.float32)\n\ngraph_context = tf.Graph()\nwith graph_context.as_default():\n\twith tf.name_scope(\"Train\"):\n\t\twith tf.variable_scope(\"Model\", reuse=None):\n\t\t\tm1 = ToyModel()\n\twith tf.name_scope(\"Valid\"):\n\t\twith tf.variable_scope(\"Model\", reuse=True):\n\t\t\tm2 = ToyModel()\n\n\ttf_init = tf.global_variables_initializer()\n\n\t# sv = tf.train.Supervisor(logdir=save_dir)\n\t# with sv.managed_session() as session:\n\tsession = tf.Session(graph=graph_context)\n\twith session as sess:\n\t\tsess.run(tf_init)\n\t\ty1 = m1.y.eval()\n\n\t\ty2 = m2.y.eval()\n\n\t\tprint(y1 == y2)\n\nTraceback (most recent call last):\n  File \"src/minimal_tf.py\", line 30, in &lt;module&gt;\n    m2 = ToyModel()\n  File \"src/minimal_tf.py\", line 21, in __init__\n    self.y, _ = tf.nn.dynamic_rnn(cell, inputs=x, dtype=tf.float32)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 553, in dynamic_rnn\n    dtype=dtype)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 720, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2623, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2456, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2406, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 705, in _time_step\n    (output, new_state) = call_cell()\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 691, in &lt;lambda&gt;\n    call_cell = lambda: cell(input_t, state)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 398, in __call__\n    reuse=self._reuse) as unit_scope:\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\", line 59, in __enter__\n    return next(self.gen)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 93, in _checked_scope\n    \"the argument reuse=True.\" % (scope_name, type(cell).__name__))\nValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'Model/rnn/lstm_cell'; and the cell was not constructed as LSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.\n</code></pre>\n<h3>Describe the problem</h3>\n<p>When cell is an LSTMCell instance, this code raises the the ValueError above, which I believe to be a bug. My expectation is that invoking the second model in a scope with reuse=True will mean that m2 uses the already-existing variables in m1. The error message indicates that this is not happening, apparently because the LSTMCell is not aware of the reuse flag set in m2's scope.</p>\n<p>By contrast, if you swap the LSTMCell for GRUCell, no errors are raised, and the code completes as expected. Indeed, the outputs of y1 and y2 are equal when the graph is evaluated.</p>\n<p>Likewise, if you use the LSTMCell but skip creating m2 at all, y1 can be evaluated without any errors.</p>", "body_text": "tf_env.txt\nSystem information\nCapture script output is attached.\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes -- see below\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):  OS X 10.12.4\nTensorFlow installed from (source or binary): pip\nTensorFlow version (use command below): 1.1.0\nBazel version (if compiling from source): NA\nCUDA/cuDNN version: NA\nGPU model and memory:  NA\nExact command to reproduce:\n\nclass ToyModel(object):\n\tdef __init__(self):\n\t\tx = tf.get_variable(\"x\", shape=[10,32,3], initializer=tf.random_uniform_initializer(), trainable=False)\n\t\tcell = tf.contrib.rnn.LSTMCell(3)\n\t\tself.y, _ = tf.nn.dynamic_rnn(cell, inputs=x, dtype=tf.float32)\n\ngraph_context = tf.Graph()\nwith graph_context.as_default():\n\twith tf.name_scope(\"Train\"):\n\t\twith tf.variable_scope(\"Model\", reuse=None):\n\t\t\tm1 = ToyModel()\n\twith tf.name_scope(\"Valid\"):\n\t\twith tf.variable_scope(\"Model\", reuse=True):\n\t\t\tm2 = ToyModel()\n\n\ttf_init = tf.global_variables_initializer()\n\n\t# sv = tf.train.Supervisor(logdir=save_dir)\n\t# with sv.managed_session() as session:\n\tsession = tf.Session(graph=graph_context)\n\twith session as sess:\n\t\tsess.run(tf_init)\n\t\ty1 = m1.y.eval()\n\n\t\ty2 = m2.y.eval()\n\n\t\tprint(y1 == y2)\n\nTraceback (most recent call last):\n  File \"src/minimal_tf.py\", line 30, in <module>\n    m2 = ToyModel()\n  File \"src/minimal_tf.py\", line 21, in __init__\n    self.y, _ = tf.nn.dynamic_rnn(cell, inputs=x, dtype=tf.float32)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 553, in dynamic_rnn\n    dtype=dtype)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 720, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2623, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2456, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2406, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 705, in _time_step\n    (output, new_state) = call_cell()\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 691, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 398, in __call__\n    reuse=self._reuse) as unit_scope:\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\", line 59, in __enter__\n    return next(self.gen)\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 93, in _checked_scope\n    \"the argument reuse=True.\" % (scope_name, type(cell).__name__))\nValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'Model/rnn/lstm_cell'; and the cell was not constructed as LSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.\n\nDescribe the problem\nWhen cell is an LSTMCell instance, this code raises the the ValueError above, which I believe to be a bug. My expectation is that invoking the second model in a scope with reuse=True will mean that m2 uses the already-existing variables in m1. The error message indicates that this is not happening, apparently because the LSTMCell is not aware of the reuse flag set in m2's scope.\nBy contrast, if you swap the LSTMCell for GRUCell, no errors are raised, and the code completes as expected. Indeed, the outputs of y1 and y2 are equal when the graph is evaluated.\nLikewise, if you use the LSTMCell but skip creating m2 at all, y1 can be evaluated without any errors.", "body": "[tf_env.txt](https://github.com/tensorflow/tensorflow/files/999124/tf_env.txt)\r\n### System information\r\n\r\nCapture script output is attached.\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes -- see below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  OS X 10.12.4\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Bazel version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**:  NA\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nclass ToyModel(object):\r\n\tdef __init__(self):\r\n\t\tx = tf.get_variable(\"x\", shape=[10,32,3], initializer=tf.random_uniform_initializer(), trainable=False)\r\n\t\tcell = tf.contrib.rnn.LSTMCell(3)\r\n\t\tself.y, _ = tf.nn.dynamic_rnn(cell, inputs=x, dtype=tf.float32)\r\n\r\ngraph_context = tf.Graph()\r\nwith graph_context.as_default():\r\n\twith tf.name_scope(\"Train\"):\r\n\t\twith tf.variable_scope(\"Model\", reuse=None):\r\n\t\t\tm1 = ToyModel()\r\n\twith tf.name_scope(\"Valid\"):\r\n\t\twith tf.variable_scope(\"Model\", reuse=True):\r\n\t\t\tm2 = ToyModel()\r\n\r\n\ttf_init = tf.global_variables_initializer()\r\n\r\n\t# sv = tf.train.Supervisor(logdir=save_dir)\r\n\t# with sv.managed_session() as session:\r\n\tsession = tf.Session(graph=graph_context)\r\n\twith session as sess:\r\n\t\tsess.run(tf_init)\r\n\t\ty1 = m1.y.eval()\r\n\r\n\t\ty2 = m2.y.eval()\r\n\r\n\t\tprint(y1 == y2)\r\n\r\nTraceback (most recent call last):\r\n  File \"src/minimal_tf.py\", line 30, in <module>\r\n    m2 = ToyModel()\r\n  File \"src/minimal_tf.py\", line 21, in __init__\r\n    self.y, _ = tf.nn.dynamic_rnn(cell, inputs=x, dtype=tf.float32)\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 553, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 720, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2623, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2456, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2406, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 705, in _time_step\r\n    (output, new_state) = call_cell()\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 691, in <lambda>\r\n    call_cell = lambda: cell(input_t, state)\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 398, in __call__\r\n    reuse=self._reuse) as unit_scope:\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\", line 59, in __enter__\r\n    return next(self.gen)\r\n  File \"/Users/delkind/Desktop/whd/venv/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 93, in _checked_scope\r\n    \"the argument reuse=True.\" % (scope_name, type(cell).__name__))\r\nValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'Model/rnn/lstm_cell'; and the cell was not constructed as LSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.\r\n```\r\n### Describe the problem\r\n\r\nWhen cell is an LSTMCell instance, this code raises the the ValueError above, which I believe to be a bug. My expectation is that invoking the second model in a scope with reuse=True will mean that m2 uses the already-existing variables in m1. The error message indicates that this is not happening, apparently because the LSTMCell is not aware of the reuse flag set in m2's scope.\r\n\r\nBy contrast, if you swap the LSTMCell for GRUCell, no errors are raised, and the code completes as expected. Indeed, the outputs of y1 and y2 are equal when the graph is evaluated.\r\n\r\nLikewise, if you use the LSTMCell but skip creating m2 at all, y1 can be evaluated without any errors."}