{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/315736497", "html_url": "https://github.com/tensorflow/tensorflow/issues/2169#issuecomment-315736497", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2169", "id": 315736497, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTczNjQ5Nw==", "user": {"login": "ThomasWollmann", "id": 6473917, "node_id": "MDQ6VXNlcjY0NzM5MTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/6473917?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ThomasWollmann", "html_url": "https://github.com/ThomasWollmann", "followers_url": "https://api.github.com/users/ThomasWollmann/followers", "following_url": "https://api.github.com/users/ThomasWollmann/following{/other_user}", "gists_url": "https://api.github.com/users/ThomasWollmann/gists{/gist_id}", "starred_url": "https://api.github.com/users/ThomasWollmann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ThomasWollmann/subscriptions", "organizations_url": "https://api.github.com/users/ThomasWollmann/orgs", "repos_url": "https://api.github.com/users/ThomasWollmann/repos", "events_url": "https://api.github.com/users/ThomasWollmann/events{/privacy}", "received_events_url": "https://api.github.com/users/ThomasWollmann/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-17T12:02:40Z", "updated_at": "2017-07-17T12:02:40Z", "author_association": "NONE", "body_html": "<p>I've adapted chahld's version to handle unknown input tensor shape.</p>\n<pre><code>def unpool(pool, ind, ksize=[1, 2, 2, 1], scope='unpool'):\n    \"\"\"\n       Unpooling layer after max_pool_with_argmax.\n       Args:\n           pool:   max pooled output tensor\n           ind:      argmax indices\n           ksize:     ksize is the same as for the pool\n       Return:\n           unpool:    unpooling tensor\n    \"\"\"\n    with tf.variable_scope(scope):\n        input_shape =  tf.shape(pool)\n        output_shape = [input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3]]\n\n        flat_input_size = tf.cumprod(input_shape)[-1]\n        flat_output_shape = tf.stack([output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]])\n\n        pool_ = tf.reshape(pool, tf.stack([flat_input_size]))\n        batch_range = tf.reshape(tf.range(tf.cast(output_shape[0], tf.int64), dtype=ind.dtype), \n                                          shape=tf.stack([input_shape[0], 1, 1, 1]))\n        b = tf.ones_like(ind) * batch_range\n        b = tf.reshape(b, tf.stack([flat_input_size, 1]))\n        ind_ = tf.reshape(ind, tf.stack([flat_input_size, 1]))\n        ind_ = tf.concat([b, ind_], 1)\n\n        ret = tf.scatter_nd(ind_, pool_, shape=tf.cast(flat_output_shape, tf.int64))\n        ret = tf.reshape(ret, tf.stack(output_shape))\n        return ret\n</code></pre>", "body_text": "I've adapted chahld's version to handle unknown input tensor shape.\ndef unpool(pool, ind, ksize=[1, 2, 2, 1], scope='unpool'):\n    \"\"\"\n       Unpooling layer after max_pool_with_argmax.\n       Args:\n           pool:   max pooled output tensor\n           ind:      argmax indices\n           ksize:     ksize is the same as for the pool\n       Return:\n           unpool:    unpooling tensor\n    \"\"\"\n    with tf.variable_scope(scope):\n        input_shape =  tf.shape(pool)\n        output_shape = [input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3]]\n\n        flat_input_size = tf.cumprod(input_shape)[-1]\n        flat_output_shape = tf.stack([output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]])\n\n        pool_ = tf.reshape(pool, tf.stack([flat_input_size]))\n        batch_range = tf.reshape(tf.range(tf.cast(output_shape[0], tf.int64), dtype=ind.dtype), \n                                          shape=tf.stack([input_shape[0], 1, 1, 1]))\n        b = tf.ones_like(ind) * batch_range\n        b = tf.reshape(b, tf.stack([flat_input_size, 1]))\n        ind_ = tf.reshape(ind, tf.stack([flat_input_size, 1]))\n        ind_ = tf.concat([b, ind_], 1)\n\n        ret = tf.scatter_nd(ind_, pool_, shape=tf.cast(flat_output_shape, tf.int64))\n        ret = tf.reshape(ret, tf.stack(output_shape))\n        return ret", "body": "I've adapted chahld's version to handle unknown input tensor shape.\r\n\r\n```\r\ndef unpool(pool, ind, ksize=[1, 2, 2, 1], scope='unpool'):\r\n    \"\"\"\r\n       Unpooling layer after max_pool_with_argmax.\r\n       Args:\r\n           pool:   max pooled output tensor\r\n           ind:      argmax indices\r\n           ksize:     ksize is the same as for the pool\r\n       Return:\r\n           unpool:    unpooling tensor\r\n    \"\"\"\r\n    with tf.variable_scope(scope):\r\n        input_shape =  tf.shape(pool)\r\n        output_shape = [input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3]]\r\n\r\n        flat_input_size = tf.cumprod(input_shape)[-1]\r\n        flat_output_shape = tf.stack([output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]])\r\n\r\n        pool_ = tf.reshape(pool, tf.stack([flat_input_size]))\r\n        batch_range = tf.reshape(tf.range(tf.cast(output_shape[0], tf.int64), dtype=ind.dtype), \r\n                                          shape=tf.stack([input_shape[0], 1, 1, 1]))\r\n        b = tf.ones_like(ind) * batch_range\r\n        b = tf.reshape(b, tf.stack([flat_input_size, 1]))\r\n        ind_ = tf.reshape(ind, tf.stack([flat_input_size, 1]))\r\n        ind_ = tf.concat([b, ind_], 1)\r\n\r\n        ret = tf.scatter_nd(ind_, pool_, shape=tf.cast(flat_output_shape, tf.int64))\r\n        ret = tf.reshape(ret, tf.stack(output_shape))\r\n        return ret\r\n```\r\n"}