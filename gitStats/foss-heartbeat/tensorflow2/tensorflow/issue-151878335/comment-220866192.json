{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/220866192", "html_url": "https://github.com/tensorflow/tensorflow/issues/2169#issuecomment-220866192", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2169", "id": 220866192, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDg2NjE5Mg==", "user": {"login": "daeyun", "id": 1250682, "node_id": "MDQ6VXNlcjEyNTA2ODI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1250682?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daeyun", "html_url": "https://github.com/daeyun", "followers_url": "https://api.github.com/users/daeyun/followers", "following_url": "https://api.github.com/users/daeyun/following{/other_user}", "gists_url": "https://api.github.com/users/daeyun/gists{/gist_id}", "starred_url": "https://api.github.com/users/daeyun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daeyun/subscriptions", "organizations_url": "https://api.github.com/users/daeyun/orgs", "repos_url": "https://api.github.com/users/daeyun/repos", "events_url": "https://api.github.com/users/daeyun/events{/privacy}", "received_events_url": "https://api.github.com/users/daeyun/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-23T00:31:30Z", "updated_at": "2018-03-24T01:20:50Z", "author_association": "CONTRIBUTOR", "body_html": "<p>my implementation using <code>tf.reshape</code> and <code>tf.concat</code></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">unpool</span>(<span class=\"pl-smi\">value</span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>unpool<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>N-dimensional version of the unpooling operation from</span>\n<span class=\"pl-s\">    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]</span>\n<span class=\"pl-s\">    :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> tf.name_scope(name) <span class=\"pl-k\">as</span> scope:\n        sh <span class=\"pl-k\">=</span> value.get_shape().as_list()\n        dim <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(sh[<span class=\"pl-c1\">1</span>:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>])\n        out <span class=\"pl-k\">=</span> (tf.reshape(value, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>] <span class=\"pl-k\">+</span> sh[<span class=\"pl-k\">-</span>dim:]))\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(dim, <span class=\"pl-c1\">0</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>):\n            out <span class=\"pl-k\">=</span> tf.concat([out, tf.zeros_like(out)], i)\n        out_size <span class=\"pl-k\">=</span> [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>] <span class=\"pl-k\">+</span> [s <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span> <span class=\"pl-k\">for</span> s <span class=\"pl-k\">in</span> sh[<span class=\"pl-c1\">1</span>:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]] <span class=\"pl-k\">+</span> [sh[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]]\n        out <span class=\"pl-k\">=</span> tf.reshape(out, out_size, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>scope)\n    <span class=\"pl-k\">return</span> out\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">pool</span>(<span class=\"pl-smi\">value</span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>pool<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Downsampling operation.</span>\n<span class=\"pl-s\">    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]</span>\n<span class=\"pl-s\">    :return: A Tensor of shape [b, d0/2, d1/2, ..., dn/2, ch]</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> tf.name_scope(name) <span class=\"pl-k\">as</span> scope:\n        sh <span class=\"pl-k\">=</span> value.get_shape().as_list()\n        out <span class=\"pl-k\">=</span> value\n        <span class=\"pl-k\">for</span> sh_i <span class=\"pl-k\">in</span> sh[<span class=\"pl-c1\">1</span>:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]:\n            <span class=\"pl-k\">assert</span> sh_i <span class=\"pl-k\">%</span> <span class=\"pl-c1\">2</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(sh[<span class=\"pl-c1\">1</span>:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>])):\n            out <span class=\"pl-k\">=</span> tf.reshape(out, (<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, np.prod(sh[i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">2</span>:])))\n            out <span class=\"pl-k\">=</span> out[:, <span class=\"pl-c1\">0</span>, :]\n        out_size <span class=\"pl-k\">=</span> [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>] <span class=\"pl-k\">+</span> [math.ceil(s <span class=\"pl-k\">/</span> <span class=\"pl-c1\">2</span>) <span class=\"pl-k\">for</span> s <span class=\"pl-k\">in</span> sh[<span class=\"pl-c1\">1</span>:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]] <span class=\"pl-k\">+</span> [sh[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]]\n        out <span class=\"pl-k\">=</span> tf.reshape(out, out_size, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>scope)\n    <span class=\"pl-k\">return</span> out</pre></div>", "body_text": "my implementation using tf.reshape and tf.concat\ndef unpool(value, name='unpool'):\n    \"\"\"N-dimensional version of the unpooling operation from\n    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n\n    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\n    :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\n    \"\"\"\n    with tf.name_scope(name) as scope:\n        sh = value.get_shape().as_list()\n        dim = len(sh[1:-1])\n        out = (tf.reshape(value, [-1] + sh[-dim:]))\n        for i in range(dim, 0, -1):\n            out = tf.concat([out, tf.zeros_like(out)], i)\n        out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\n        out = tf.reshape(out, out_size, name=scope)\n    return out\n\n\ndef pool(value, name='pool'):\n    \"\"\"Downsampling operation.\n    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\n    :return: A Tensor of shape [b, d0/2, d1/2, ..., dn/2, ch]\n    \"\"\"\n    with tf.name_scope(name) as scope:\n        sh = value.get_shape().as_list()\n        out = value\n        for sh_i in sh[1:-1]:\n            assert sh_i % 2 == 0\n        for i in range(len(sh[1:-1])):\n            out = tf.reshape(out, (-1, 2, np.prod(sh[i + 2:])))\n            out = out[:, 0, :]\n        out_size = [-1] + [math.ceil(s / 2) for s in sh[1:-1]] + [sh[-1]]\n        out = tf.reshape(out, out_size, name=scope)\n    return out", "body": "my implementation using `tf.reshape` and `tf.concat`\r\n\r\n``` python\r\ndef unpool(value, name='unpool'):\r\n    \"\"\"N-dimensional version of the unpooling operation from\r\n    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\r\n\r\n    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\r\n    :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\r\n    \"\"\"\r\n    with tf.name_scope(name) as scope:\r\n        sh = value.get_shape().as_list()\r\n        dim = len(sh[1:-1])\r\n        out = (tf.reshape(value, [-1] + sh[-dim:]))\r\n        for i in range(dim, 0, -1):\r\n            out = tf.concat([out, tf.zeros_like(out)], i)\r\n        out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\r\n        out = tf.reshape(out, out_size, name=scope)\r\n    return out\r\n\r\n\r\ndef pool(value, name='pool'):\r\n    \"\"\"Downsampling operation.\r\n    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\r\n    :return: A Tensor of shape [b, d0/2, d1/2, ..., dn/2, ch]\r\n    \"\"\"\r\n    with tf.name_scope(name) as scope:\r\n        sh = value.get_shape().as_list()\r\n        out = value\r\n        for sh_i in sh[1:-1]:\r\n            assert sh_i % 2 == 0\r\n        for i in range(len(sh[1:-1])):\r\n            out = tf.reshape(out, (-1, 2, np.prod(sh[i + 2:])))\r\n            out = out[:, 0, :]\r\n        out_size = [-1] + [math.ceil(s / 2) for s in sh[1:-1]] + [sh[-1]]\r\n        out = tf.reshape(out, out_size, name=scope)\r\n    return out\r\n```\r\n"}