{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/307373111", "html_url": "https://github.com/tensorflow/tensorflow/issues/2169#issuecomment-307373111", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2169", "id": 307373111, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzM3MzExMQ==", "user": {"login": "Pepslee", "id": 13853798, "node_id": "MDQ6VXNlcjEzODUzNzk4", "avatar_url": "https://avatars1.githubusercontent.com/u/13853798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Pepslee", "html_url": "https://github.com/Pepslee", "followers_url": "https://api.github.com/users/Pepslee/followers", "following_url": "https://api.github.com/users/Pepslee/following{/other_user}", "gists_url": "https://api.github.com/users/Pepslee/gists{/gist_id}", "starred_url": "https://api.github.com/users/Pepslee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Pepslee/subscriptions", "organizations_url": "https://api.github.com/users/Pepslee/orgs", "repos_url": "https://api.github.com/users/Pepslee/repos", "events_url": "https://api.github.com/users/Pepslee/events{/privacy}", "received_events_url": "https://api.github.com/users/Pepslee/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-09T12:15:34Z", "updated_at": "2017-06-09T12:15:34Z", "author_association": "NONE", "body_html": "<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">unpool</span>(<span class=\"pl-smi\">pool</span>, <span class=\"pl-smi\">ind</span>, <span class=\"pl-smi\">ksize</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-smi\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>unpool<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">       Unpooling layer after max_pool_with_argmax.</span>\n<span class=\"pl-s\">       Args:</span>\n<span class=\"pl-s\">           updates:   max pooled output tensor</span>\n<span class=\"pl-s\">           mask:      argmax indices</span>\n<span class=\"pl-s\">           ksize:     ksize is the same as for the pool</span>\n<span class=\"pl-s\">       Return:</span>\n<span class=\"pl-s\">           unpool:    unpooling tensor</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> tf.variable_scope(scope):\n        input_shape <span class=\"pl-k\">=</span> pool.get_shape().as_list()\n        output_shape <span class=\"pl-k\">=</span> (input_shape[<span class=\"pl-c1\">0</span>], input_shape[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> ksize[<span class=\"pl-c1\">1</span>], input_shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> ksize[<span class=\"pl-c1\">2</span>], input_shape[<span class=\"pl-c1\">3</span>])\n        pool_ <span class=\"pl-k\">=</span> tf.reshape(pool, [input_shape[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">3</span>]])\n        batch_range <span class=\"pl-k\">=</span> tf.reshape(tf.range(output_shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>ind.dtype), <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[input_shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>])\n        b <span class=\"pl-k\">=</span> tf.ones_like(ind) <span class=\"pl-k\">*</span> batch_range\n        b <span class=\"pl-k\">=</span> tf.reshape(b, [input_shape[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">3</span>], <span class=\"pl-c1\">1</span>])\n        ind_ <span class=\"pl-k\">=</span> tf.reshape(ind, [input_shape[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">3</span>], <span class=\"pl-c1\">1</span>])\n        ind_ <span class=\"pl-k\">=</span> tf.concat(<span class=\"pl-c1\">1</span>, [b, ind_])\n        ref <span class=\"pl-k\">=</span> tf.Variable(tf.zeros([output_shape[<span class=\"pl-c1\">0</span>], output_shape[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> output_shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> output_shape[<span class=\"pl-c1\">3</span>]]))\n        ret <span class=\"pl-k\">=</span> tf.scatter_nd_update(ref, ind_, pool_)\n        ret <span class=\"pl-k\">=</span> tf.reshape(ret, [output_shape[<span class=\"pl-c1\">0</span>], output_shape[<span class=\"pl-c1\">1</span>], output_shape[<span class=\"pl-c1\">2</span>], output_shape[<span class=\"pl-c1\">3</span>]])\n        <span class=\"pl-k\">return</span> ret</pre></div>", "body_text": "def unpool(pool, ind, ksize=[1, 2, 2, 1], scope='unpool'):\n    \"\"\"\n       Unpooling layer after max_pool_with_argmax.\n       Args:\n           updates:   max pooled output tensor\n           mask:      argmax indices\n           ksize:     ksize is the same as for the pool\n       Return:\n           unpool:    unpooling tensor\n    \"\"\"\n    with tf.variable_scope(scope):\n        input_shape = pool.get_shape().as_list()\n        output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])\n        pool_ = tf.reshape(pool, [input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3]])\n        batch_range = tf.reshape(tf.range(output_shape[0], dtype=ind.dtype), shape=[input_shape[0], 1, 1, 1])\n        b = tf.ones_like(ind) * batch_range\n        b = tf.reshape(b, [input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3], 1])\n        ind_ = tf.reshape(ind, [input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3], 1])\n        ind_ = tf.concat(1, [b, ind_])\n        ref = tf.Variable(tf.zeros([output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]))\n        ret = tf.scatter_nd_update(ref, ind_, pool_)\n        ret = tf.reshape(ret, [output_shape[0], output_shape[1], output_shape[2], output_shape[3]])\n        return ret", "body": "\r\n\r\n``` python \r\n\r\ndef unpool(pool, ind, ksize=[1, 2, 2, 1], scope='unpool'):\r\n    \"\"\"\r\n       Unpooling layer after max_pool_with_argmax.\r\n       Args:\r\n           updates:   max pooled output tensor\r\n           mask:      argmax indices\r\n           ksize:     ksize is the same as for the pool\r\n       Return:\r\n           unpool:    unpooling tensor\r\n    \"\"\"\r\n    with tf.variable_scope(scope):\r\n        input_shape = pool.get_shape().as_list()\r\n        output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])\r\n        pool_ = tf.reshape(pool, [input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3]])\r\n        batch_range = tf.reshape(tf.range(output_shape[0], dtype=ind.dtype), shape=[input_shape[0], 1, 1, 1])\r\n        b = tf.ones_like(ind) * batch_range\r\n        b = tf.reshape(b, [input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3], 1])\r\n        ind_ = tf.reshape(ind, [input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3], 1])\r\n        ind_ = tf.concat(1, [b, ind_])\r\n        ref = tf.Variable(tf.zeros([output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]))\r\n        ret = tf.scatter_nd_update(ref, ind_, pool_)\r\n        ret = tf.reshape(ret, [output_shape[0], output_shape[1], output_shape[2], output_shape[3]])\r\n        return ret\r\n```"}