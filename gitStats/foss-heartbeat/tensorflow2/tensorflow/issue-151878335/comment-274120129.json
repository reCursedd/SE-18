{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/274120129", "html_url": "https://github.com/tensorflow/tensorflow/issues/2169#issuecomment-274120129", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2169", "id": 274120129, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NDEyMDEyOQ==", "user": {"login": "Pepslee", "id": 13853798, "node_id": "MDQ6VXNlcjEzODUzNzk4", "avatar_url": "https://avatars1.githubusercontent.com/u/13853798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Pepslee", "html_url": "https://github.com/Pepslee", "followers_url": "https://api.github.com/users/Pepslee/followers", "following_url": "https://api.github.com/users/Pepslee/following{/other_user}", "gists_url": "https://api.github.com/users/Pepslee/gists{/gist_id}", "starred_url": "https://api.github.com/users/Pepslee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Pepslee/subscriptions", "organizations_url": "https://api.github.com/users/Pepslee/orgs", "repos_url": "https://api.github.com/users/Pepslee/repos", "events_url": "https://api.github.com/users/Pepslee/events{/privacy}", "received_events_url": "https://api.github.com/users/Pepslee/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-20T16:47:08Z", "updated_at": "2017-01-20T16:48:43Z", "author_association": "NONE", "body_html": "<p>even faster</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">unravel_argmax</span>(<span class=\"pl-smi\">argmax</span>, <span class=\"pl-smi\">shape</span>):\n    argmax_shape <span class=\"pl-k\">=</span> argmax.get_shape()\n    new_1dim_shape <span class=\"pl-k\">=</span> tf.shape(tf.constant(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[tf.Dimension(<span class=\"pl-c1\">4</span>), argmax_shape[<span class=\"pl-c1\">0</span>]<span class=\"pl-k\">*</span>argmax_shape[<span class=\"pl-c1\">1</span>]<span class=\"pl-k\">*</span>argmax_shape[<span class=\"pl-c1\">2</span>]<span class=\"pl-k\">*</span>argmax_shape[<span class=\"pl-c1\">3</span>]]))\n    batch_shape <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int64, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[argmax_shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>]).get_shape()\n    b <span class=\"pl-k\">=</span> tf.multiply(tf.ones_like(argmax), tf.reshape(tf.range(shape[<span class=\"pl-c1\">0</span>]), batch_shape))\n    y <span class=\"pl-k\">=</span> argmax <span class=\"pl-k\">//</span> (shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> shape[<span class=\"pl-c1\">3</span>])\n    x <span class=\"pl-k\">=</span> argmax <span class=\"pl-k\">%</span> (shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> shape[<span class=\"pl-c1\">3</span>]) <span class=\"pl-k\">//</span> shape[<span class=\"pl-c1\">3</span>]\n    c <span class=\"pl-k\">=</span> tf.ones_like(argmax) <span class=\"pl-k\">*</span> tf.range(shape[<span class=\"pl-c1\">3</span>])\n    pack <span class=\"pl-k\">=</span> tf.stack([b, y, x, c])\n    pack <span class=\"pl-k\">=</span> tf.reshape(pack, new_1dim_shape)\n    pack <span class=\"pl-k\">=</span> tf.transpose(pack)\n    <span class=\"pl-k\">return</span> pack\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">unpool</span>(<span class=\"pl-smi\">updates</span>, <span class=\"pl-smi\">mask</span>, <span class=\"pl-smi\">ksize</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>]):\n    input_shape <span class=\"pl-k\">=</span> updates.get_shape()\n    new_dim_y <span class=\"pl-k\">=</span> input_shape[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> ksize[<span class=\"pl-c1\">1</span>]\n    new_dim_x <span class=\"pl-k\">=</span> input_shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> ksize[<span class=\"pl-c1\">2</span>]\n    output_shape <span class=\"pl-k\">=</span> tf.to_int64((tf.constant(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int64, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[input_shape[<span class=\"pl-c1\">0</span>], new_dim_y, new_dim_x, input_shape[<span class=\"pl-c1\">3</span>]]).get_shape()))\n    indices <span class=\"pl-k\">=</span> unravel_argmax(mask, output_shape)\n    new_1dim_shape <span class=\"pl-k\">=</span> tf.shape(tf.constant(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[input_shape[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> input_shape[<span class=\"pl-c1\">3</span>]]))\n    values <span class=\"pl-k\">=</span> tf.reshape(updates, new_1dim_shape)\n    ret <span class=\"pl-k\">=</span> tf.scatter_nd(indices, values, output_shape)\n    <span class=\"pl-k\">return</span> ret</pre></div>", "body_text": "even faster\ndef unravel_argmax(argmax, shape):\n    argmax_shape = argmax.get_shape()\n    new_1dim_shape = tf.shape(tf.constant(0, shape=[tf.Dimension(4), argmax_shape[0]*argmax_shape[1]*argmax_shape[2]*argmax_shape[3]]))\n    batch_shape = tf.constant(0, dtype=tf.int64, shape=[argmax_shape[0], 1, 1, 1]).get_shape()\n    b = tf.multiply(tf.ones_like(argmax), tf.reshape(tf.range(shape[0]), batch_shape))\n    y = argmax // (shape[2] * shape[3])\n    x = argmax % (shape[2] * shape[3]) // shape[3]\n    c = tf.ones_like(argmax) * tf.range(shape[3])\n    pack = tf.stack([b, y, x, c])\n    pack = tf.reshape(pack, new_1dim_shape)\n    pack = tf.transpose(pack)\n    return pack\n\n\ndef unpool(updates, mask, ksize=[1, 2, 2, 1]):\n    input_shape = updates.get_shape()\n    new_dim_y = input_shape[1] * ksize[1]\n    new_dim_x = input_shape[2] * ksize[2]\n    output_shape = tf.to_int64((tf.constant(0, dtype=tf.int64, shape=[input_shape[0], new_dim_y, new_dim_x, input_shape[3]]).get_shape()))\n    indices = unravel_argmax(mask, output_shape)\n    new_1dim_shape = tf.shape(tf.constant(0, shape=[input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3]]))\n    values = tf.reshape(updates, new_1dim_shape)\n    ret = tf.scatter_nd(indices, values, output_shape)\n    return ret", "body": "even faster\r\n\r\n``` python\r\ndef unravel_argmax(argmax, shape):\r\n    argmax_shape = argmax.get_shape()\r\n    new_1dim_shape = tf.shape(tf.constant(0, shape=[tf.Dimension(4), argmax_shape[0]*argmax_shape[1]*argmax_shape[2]*argmax_shape[3]]))\r\n    batch_shape = tf.constant(0, dtype=tf.int64, shape=[argmax_shape[0], 1, 1, 1]).get_shape()\r\n    b = tf.multiply(tf.ones_like(argmax), tf.reshape(tf.range(shape[0]), batch_shape))\r\n    y = argmax // (shape[2] * shape[3])\r\n    x = argmax % (shape[2] * shape[3]) // shape[3]\r\n    c = tf.ones_like(argmax) * tf.range(shape[3])\r\n    pack = tf.stack([b, y, x, c])\r\n    pack = tf.reshape(pack, new_1dim_shape)\r\n    pack = tf.transpose(pack)\r\n    return pack\r\n\r\n\r\ndef unpool(updates, mask, ksize=[1, 2, 2, 1]):\r\n    input_shape = updates.get_shape()\r\n    new_dim_y = input_shape[1] * ksize[1]\r\n    new_dim_x = input_shape[2] * ksize[2]\r\n    output_shape = tf.to_int64((tf.constant(0, dtype=tf.int64, shape=[input_shape[0], new_dim_y, new_dim_x, input_shape[3]]).get_shape()))\r\n    indices = unravel_argmax(mask, output_shape)\r\n    new_1dim_shape = tf.shape(tf.constant(0, shape=[input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3]]))\r\n    values = tf.reshape(updates, new_1dim_shape)\r\n    ret = tf.scatter_nd(indices, values, output_shape)\r\n    return ret\r\n```"}