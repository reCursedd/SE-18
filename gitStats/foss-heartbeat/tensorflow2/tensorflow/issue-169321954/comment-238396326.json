{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/238396326", "html_url": "https://github.com/tensorflow/tensorflow/issues/3638#issuecomment-238396326", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3638", "id": 238396326, "node_id": "MDEyOklzc3VlQ29tbWVudDIzODM5NjMyNg==", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-08T22:23:04Z", "updated_at": "2016-08-08T22:23:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks!<br>\nI think the checking shouldn't be optional, otherwise users will keep running into problems, so that would rule out option 1.<br>\nOption 2 still blocks ops that depend on gather. I think we should try to avoid this if we can.<br>\nOption 3 sounds good, but a <code>LOG(FATAL)</code> would crash the interpreter that the user might be running TensorFlow in, which isn't very nice. (But maybe this is easy to fix?)</p>\n<p>I've also thought of writing a <code>CheckGather</code> op, which performs the index checking separately from <code>Gather</code>. It could be launched alongside <code>Gather</code> from a Python wrapper.<br>\nThis could either always run on the CPU, or synchronize with the GPU, possibly as an AsyncOpKernel as you've explained.</p>\n<p>Maybe the cleanest option would be to modify <code>Executor</code> slightly to add support for asynchronous error reporting.<br>\nFor example, we could add a <code>Status</code> protected by a mutex to <code>Executor</code> that's specifically designed for asynchronous error reporting. The op's <code>Compute</code> method could then pass the <code>Status</code> into a callback that's executed as part of the CUDA stream. The <code>Executor</code> would then check the <code>Status</code> after it synchronized the computation.<br>\nI'm not sure how useful this change would be for ops other than <code>Gather</code>, though.</p>", "body_text": "Thanks!\nI think the checking shouldn't be optional, otherwise users will keep running into problems, so that would rule out option 1.\nOption 2 still blocks ops that depend on gather. I think we should try to avoid this if we can.\nOption 3 sounds good, but a LOG(FATAL) would crash the interpreter that the user might be running TensorFlow in, which isn't very nice. (But maybe this is easy to fix?)\nI've also thought of writing a CheckGather op, which performs the index checking separately from Gather. It could be launched alongside Gather from a Python wrapper.\nThis could either always run on the CPU, or synchronize with the GPU, possibly as an AsyncOpKernel as you've explained.\nMaybe the cleanest option would be to modify Executor slightly to add support for asynchronous error reporting.\nFor example, we could add a Status protected by a mutex to Executor that's specifically designed for asynchronous error reporting. The op's Compute method could then pass the Status into a callback that's executed as part of the CUDA stream. The Executor would then check the Status after it synchronized the computation.\nI'm not sure how useful this change would be for ops other than Gather, though.", "body": "Thanks!\nI think the checking shouldn't be optional, otherwise users will keep running into problems, so that would rule out option 1.\nOption 2 still blocks ops that depend on gather. I think we should try to avoid this if we can.\nOption 3 sounds good, but a `LOG(FATAL)` would crash the interpreter that the user might be running TensorFlow in, which isn't very nice. (But maybe this is easy to fix?)\n\nI've also thought of writing a `CheckGather` op, which performs the index checking separately from `Gather`. It could be launched alongside `Gather` from a Python wrapper.\nThis could either always run on the CPU, or synchronize with the GPU, possibly as an AsyncOpKernel as you've explained.\n\nMaybe the cleanest option would be to modify `Executor` slightly to add support for asynchronous error reporting.\nFor example, we could add a `Status` protected by a mutex to `Executor` that's specifically designed for asynchronous error reporting. The op's `Compute` method could then pass the `Status` into a callback that's executed as part of the CUDA stream. The `Executor` would then check the `Status` after it synchronized the computation.\nI'm not sure how useful this change would be for ops other than `Gather`, though.\n"}