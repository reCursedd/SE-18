{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/403038713", "html_url": "https://github.com/tensorflow/tensorflow/issues/9091#issuecomment-403038713", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9091", "id": 403038713, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzAzODcxMw==", "user": {"login": "Satcheel", "id": 23453539, "node_id": "MDQ6VXNlcjIzNDUzNTM5", "avatar_url": "https://avatars0.githubusercontent.com/u/23453539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Satcheel", "html_url": "https://github.com/Satcheel", "followers_url": "https://api.github.com/users/Satcheel/followers", "following_url": "https://api.github.com/users/Satcheel/following{/other_user}", "gists_url": "https://api.github.com/users/Satcheel/gists{/gist_id}", "starred_url": "https://api.github.com/users/Satcheel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Satcheel/subscriptions", "organizations_url": "https://api.github.com/users/Satcheel/orgs", "repos_url": "https://api.github.com/users/Satcheel/repos", "events_url": "https://api.github.com/users/Satcheel/events{/privacy}", "received_events_url": "https://api.github.com/users/Satcheel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-06T13:44:59Z", "updated_at": "2018-07-06T13:45:06Z", "author_association": "NONE", "body_html": "<p>I'm getting a similar problem. I'm generating batches manually from different .h5 files.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> sess.as_default():\n\tfull_start <span class=\"pl-k\">=</span> clock()\n\t<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">100</span>):    <span class=\"pl-c\"><span class=\"pl-c\">#</span>epochs</span>\n\t\tstart <span class=\"pl-k\">=</span> clock()\n\t\tbatch_train_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">512</span>\n\t\tbatch_test_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">200</span>\n\t\tstart_train_index <span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n\t\tend_train_index <span class=\"pl-k\">=</span> start_train_index<span class=\"pl-k\">+</span>batch_train_size\n\t\tstart_test_index <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n\t\tend_test_index <span class=\"pl-k\">=</span> start_test_index<span class=\"pl-k\">+</span>batch_test_size\n\t\t<span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">int</span>(ceil(<span class=\"pl-c1\">float</span>(train_len)<span class=\"pl-k\">/</span>batch_train_size))):\t\t\n\t\t\t<span class=\"pl-k\">if</span> start_train_index  <span class=\"pl-k\">&gt;=</span> train_len:\n\t\t\t\tstart_train_index <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n\t\t\t<span class=\"pl-k\">if</span> start_test_index <span class=\"pl-k\">&gt;=</span> test_len:\n\t\t\t\tstart_test_index <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n\t\t\tend_train_index <span class=\"pl-k\">=</span> start_train_index<span class=\"pl-k\">+</span>batch_train_size\n\t\t\tend_test_index <span class=\"pl-k\">=</span> start_test_index <span class=\"pl-k\">+</span> batch_test_size\n\t\t\t<span class=\"pl-k\">if</span> end_train_index <span class=\"pl-k\">&gt;=</span> train_len:\n\t\t\t\tend_train_index <span class=\"pl-k\">=</span> train_len\n\t\t\t<span class=\"pl-k\">if</span> end_test_index <span class=\"pl-k\">&gt;=</span> test_len:\n\t\t\t\tend_test_index <span class=\"pl-k\">=</span> test_len\n\t\t\t<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>epoch:<span class=\"pl-pds\">'</span></span>,i<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/100 batch_num:<span class=\"pl-pds\">'</span></span>,j<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/19<span class=\"pl-pds\">'</span></span>\n\t\t\tx_train,y_train,x_test,y_test <span class=\"pl-k\">=</span> loadData(start_train_index,end_train_index,start_test_index,end_test_index)\n\t\t\tstart_train_index <span class=\"pl-k\">=</span> end_train_index\n\t\t\tstart_test_index <span class=\"pl-k\">=</span> end_test_index\n                        <span class=\"pl-c1\">print</span> x_train.shape,x_test.shape\n\t\t\ttrain_step.run(<span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{X_train: x_train,\n\t                                  labels: y_train})</pre></div>\n<p>loadData function returns padded input features of different videos from .h5 files</p>\n<p>After a few batches</p>\n<pre><code>2018-07-06 18:04:56.278757: W ./tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 7730940928\nKilled\n</code></pre>\n<p>Can someone suggest a way to load batches manually and not exhaust memory<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1411079\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/JonathanRaiman\">@JonathanRaiman</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7760423\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hbb21st\">@hbb21st</a> Please guide me if you solved your error</p>", "body_text": "I'm getting a similar problem. I'm generating batches manually from different .h5 files.\nwith sess.as_default():\n\tfull_start = clock()\n\tfor i in range(100):    #epochs\n\t\tstart = clock()\n\t\tbatch_train_size = 512\n\t\tbatch_test_size = 200\n\t\tstart_train_index =0\n\t\tend_train_index = start_train_index+batch_train_size\n\t\tstart_test_index = 0\n\t\tend_test_index = start_test_index+batch_test_size\n\t\tfor j in range(int(ceil(float(train_len)/batch_train_size))):\t\t\n\t\t\tif start_train_index  >= train_len:\n\t\t\t\tstart_train_index = 0\n\t\t\tif start_test_index >= test_len:\n\t\t\t\tstart_test_index = 0\n\t\t\tend_train_index = start_train_index+batch_train_size\n\t\t\tend_test_index = start_test_index + batch_test_size\n\t\t\tif end_train_index >= train_len:\n\t\t\t\tend_train_index = train_len\n\t\t\tif end_test_index >= test_len:\n\t\t\t\tend_test_index = test_len\n\t\t\tprint 'epoch:',i+1,'/100 batch_num:',j+1,'/19'\n\t\t\tx_train,y_train,x_test,y_test = loadData(start_train_index,end_train_index,start_test_index,end_test_index)\n\t\t\tstart_train_index = end_train_index\n\t\t\tstart_test_index = end_test_index\n                        print x_train.shape,x_test.shape\n\t\t\ttrain_step.run(feed_dict={X_train: x_train,\n\t                                  labels: y_train})\nloadData function returns padded input features of different videos from .h5 files\nAfter a few batches\n2018-07-06 18:04:56.278757: W ./tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 7730940928\nKilled\n\nCan someone suggest a way to load batches manually and not exhaust memory\n@JonathanRaiman @hbb21st Please guide me if you solved your error", "body": "I'm getting a similar problem. I'm generating batches manually from different .h5 files.\r\n```python\r\nwith sess.as_default():\r\n\tfull_start = clock()\r\n\tfor i in range(100):    #epochs\r\n\t\tstart = clock()\r\n\t\tbatch_train_size = 512\r\n\t\tbatch_test_size = 200\r\n\t\tstart_train_index =0\r\n\t\tend_train_index = start_train_index+batch_train_size\r\n\t\tstart_test_index = 0\r\n\t\tend_test_index = start_test_index+batch_test_size\r\n\t\tfor j in range(int(ceil(float(train_len)/batch_train_size))):\t\t\r\n\t\t\tif start_train_index  >= train_len:\r\n\t\t\t\tstart_train_index = 0\r\n\t\t\tif start_test_index >= test_len:\r\n\t\t\t\tstart_test_index = 0\r\n\t\t\tend_train_index = start_train_index+batch_train_size\r\n\t\t\tend_test_index = start_test_index + batch_test_size\r\n\t\t\tif end_train_index >= train_len:\r\n\t\t\t\tend_train_index = train_len\r\n\t\t\tif end_test_index >= test_len:\r\n\t\t\t\tend_test_index = test_len\r\n\t\t\tprint 'epoch:',i+1,'/100 batch_num:',j+1,'/19'\r\n\t\t\tx_train,y_train,x_test,y_test = loadData(start_train_index,end_train_index,start_test_index,end_test_index)\r\n\t\t\tstart_train_index = end_train_index\r\n\t\t\tstart_test_index = end_test_index\r\n                        print x_train.shape,x_test.shape\r\n\t\t\ttrain_step.run(feed_dict={X_train: x_train,\r\n\t                                  labels: y_train})\r\n```\r\nloadData function returns padded input features of different videos from .h5 files\r\n\r\nAfter a few batches \r\n```\r\n2018-07-06 18:04:56.278757: W ./tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 7730940928\r\nKilled\r\n```\r\nCan someone suggest a way to load batches manually and not exhaust memory \r\n@JonathanRaiman @hbb21st Please guide me if you solved your error"}