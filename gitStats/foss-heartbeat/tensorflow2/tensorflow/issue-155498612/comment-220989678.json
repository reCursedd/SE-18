{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/220989678", "html_url": "https://github.com/tensorflow/tensorflow/issues/2416#issuecomment-220989678", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2416", "id": 220989678, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDk4OTY3OA==", "user": {"login": "erickrf", "id": 294483, "node_id": "MDQ6VXNlcjI5NDQ4Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/294483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erickrf", "html_url": "https://github.com/erickrf", "followers_url": "https://api.github.com/users/erickrf/followers", "following_url": "https://api.github.com/users/erickrf/following{/other_user}", "gists_url": "https://api.github.com/users/erickrf/gists{/gist_id}", "starred_url": "https://api.github.com/users/erickrf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erickrf/subscriptions", "organizations_url": "https://api.github.com/users/erickrf/orgs", "repos_url": "https://api.github.com/users/erickrf/repos", "events_url": "https://api.github.com/users/erickrf/events{/privacy}", "received_events_url": "https://api.github.com/users/erickrf/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-23T14:04:56Z", "updated_at": "2016-05-23T14:04:56Z", "author_association": "NONE", "body_html": "<p>My problem seems to be related to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116428689\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/152\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/152/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/152\">#152</a>. I tried to set <code>CUDA_VISIBLE_DEVICES=1</code>, as indicated in that issue, since I'm using a shared server. This made python (but not ipython) work with a simple statement after <code>-c</code>, but the interactive shell still results in a segfault:</p>\n<pre><code>$ CUDA_VISIBLE_DEVICES=1 python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\n</code></pre>\n<pre><code>$ CUDA_VISIBLE_DEVICES=1 python \nPython 2.7.11 |Anaconda 4.0.0 (64-bit)| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n&gt;&gt;&gt; import tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n&gt;&gt;&gt; sess = tf.InteractiveSession()\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\nterminate called after throwing an instance of 'std::system_error'\n  what():  Resource temporarily unavailable\nAborted (core dumped)\n</code></pre>\n<p>Any suggestions about what might be wrong?</p>", "body_text": "My problem seems to be related to #152. I tried to set CUDA_VISIBLE_DEVICES=1, as indicated in that issue, since I'm using a shared server. This made python (but not ipython) work with a simple statement after -c, but the interactive shell still results in a segfault:\n$ CUDA_VISIBLE_DEVICES=1 python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\n\n$ CUDA_VISIBLE_DEVICES=1 python \nPython 2.7.11 |Anaconda 4.0.0 (64-bit)| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n>>> import tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n>>> sess = tf.InteractiveSession()\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\nterminate called after throwing an instance of 'std::system_error'\n  what():  Resource temporarily unavailable\nAborted (core dumped)\n\nAny suggestions about what might be wrong?", "body": "My problem seems to be related to #152. I tried to set `CUDA_VISIBLE_DEVICES=1`, as indicated in that issue, since I'm using a shared server. This made python (but not ipython) work with a simple statement after `-c`, but the interactive shell still results in a segfault:\n\n```\n$ CUDA_VISIBLE_DEVICES=1 python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\n```\n\n```\n$ CUDA_VISIBLE_DEVICES=1 python \nPython 2.7.11 |Anaconda 4.0.0 (64-bit)| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n>>> import tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n>>> sess = tf.InteractiveSession()\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\nterminate called after throwing an instance of 'std::system_error'\n  what():  Resource temporarily unavailable\nAborted (core dumped)\n```\n\nAny suggestions about what might be wrong?\n"}