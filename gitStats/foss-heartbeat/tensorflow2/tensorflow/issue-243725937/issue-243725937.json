{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11581", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11581/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11581/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11581/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/11581", "id": 243725937, "node_id": "MDExOlB1bGxSZXF1ZXN0MTMxMDk0NjYw", "number": 11581, "title": "Model average replicas optimizer", "user": {"login": "abenmao", "id": 29789552, "node_id": "MDQ6VXNlcjI5Nzg5NTUy", "avatar_url": "https://avatars0.githubusercontent.com/u/29789552?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abenmao", "html_url": "https://github.com/abenmao", "followers_url": "https://api.github.com/users/abenmao/followers", "following_url": "https://api.github.com/users/abenmao/following{/other_user}", "gists_url": "https://api.github.com/users/abenmao/gists{/gist_id}", "starred_url": "https://api.github.com/users/abenmao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abenmao/subscriptions", "organizations_url": "https://api.github.com/users/abenmao/orgs", "repos_url": "https://api.github.com/users/abenmao/repos", "events_url": "https://api.github.com/users/abenmao/events{/privacy}", "received_events_url": "https://api.github.com/users/abenmao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}, {"id": 474725938, "node_id": "MDU6TGFiZWw0NzQ3MjU5Mzg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stalled", "name": "stalled", "color": "d4c5f9", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 36, "created_at": "2017-07-18T13:59:11Z", "updated_at": "2018-05-30T08:36:04Z", "closed_at": "2017-11-15T06:12:59Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11581", "html_url": "https://github.com/tensorflow/tensorflow/pull/11581", "diff_url": "https://github.com/tensorflow/tensorflow/pull/11581.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/11581.patch"}, "body_html": "<p>We have implemented a new replicas_optimizer \"ModelAverageOptimizer\" to reduce cross-node communication cost. It is mentioned in the following issue:</p>\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"233783549\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/10449\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/10449/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/10449\">#10449</a></p>\n<h1>Model Average</h1>\n<p>In a typical synchronous training environment (N-replica synchronous training), gradients will be averaged each step, and then applied to the variables, after that replicas can fetch the new variables and continue. However, in a model-average training environment, model parameters will be averaged every 'ma_intervals' steps. In the interval between two \"average operation\", each worker trained its local model, there are no data transfer at all between workers or ps, which can significantly accerlate parallel training.</p>\n<p>Reference:  <a href=\"https://arxiv.org/pdf/1410.7455v8.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1410.7455v8.pdf</a></p>\n<h2>BMUF</h2>\n<p>Reference:  <a href=\"http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/0005880.pdf\" rel=\"nofollow\">http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/0005880.pdf</a></p>\n<p>BMUF brings in 'Momentum' and can also work with a Nesterov momentum scheme on the based of Model Average method.</p>\n<p>block_momentum_rate: It brings in the historical blockwise gradients. The block momentum is usually set according to the number of workers: block_momentum = 1.0 - 1.0/num_of_workers. The default value is 0.0. When using default value, the naive ModelAverage method is applied, the original learning rate of local optimizer should be multiply by num_of_workers. While when the value is (0.0,1.0), the BMUF method is applied, the learning rate of local optimizer can be unchanged.</p>\n<p>use_Nesterov: means the Nesterov-style momentum update is applied on the block level. The default value is true. This can accelerate training with non-zero block_momentum_rate.</p>\n<p>block_learning_rate: block_learning_rate is always 1.0 or slightly higher than 1.0.</p>\n<div class=\"highlight highlight-source-python\"><pre>  <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>,\n               <span class=\"pl-smi\">replicas_to_aggregate</span>,                                                                 \n               <span class=\"pl-smi\">ma_intervals</span>,\n               <span class=\"pl-smi\">total_num_replicas</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n               <span class=\"pl-smi\">block_momentum_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0</span>,\n               <span class=\"pl-smi\">use_Nesterov</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n               <span class=\"pl-smi\">block_learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Construct a model_average optimizer.</span></pre></div>\n<h1>Result</h1>\n<p>We have benchmarked it on several in-house models, the results showed a good convergence speedup and training-data processing almostly reaches linear speedup.</p>\n<table>\n<thead>\n<tr>\n<th>device config (GPU M40)</th>\n<th>convergence speed-up</th>\n<th>computation speed-up</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>4 GPUs within 2 nodes</td>\n<td>3.4</td>\n<td>3.9</td>\n</tr>\n<tr>\n<td>8 GPUs within 4 nodes</td>\n<td>5.7</td>\n<td>7.5</td>\n</tr>\n<tr>\n<td>16 GPUs within 8 nodes</td>\n<td>9.2</td>\n<td>14.6</td>\n</tr>\n</tbody>\n</table>\n<p>Also\uff0cwe made a experiment with ResNet on cifar10 (baseline code is from: <a href=\"https://github.com/tensorflow/models/tree/master/resnet\">https://github.com/tensorflow/models/tree/master/resnet</a>):</p>\n<table>\n<thead>\n<tr>\n<th>device config (GPU P100)</th>\n<th>convergence speed-up</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2 GPUs within 1 nodes</td>\n<td>2.03</td>\n</tr>\n<tr>\n<td>4 GPUs within 1 nodes</td>\n<td>3.67</td>\n</tr>\n<tr>\n<td>8 GPUs within 1 nodes</td>\n<td>6.57</td>\n</tr>\n</tbody>\n</table>\n<h1>API</h1>\n<p>By now, it is implemented as a tensorflow API using Python\uff0c doesn't have to change the core/distributed runtime code.</p>\n<div class=\"highlight highlight-source-python\"><pre>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create any optimizer to update the variables, say a simple SGD:</span>\n  opt <span class=\"pl-k\">=</span> GradientDescentOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>)\n             \n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a ModelAverageOptimizer to update the global variables:</span>\n  ma <span class=\"pl-k\">=</span> tf.contrib.model_average.ModelAverageOptimizer(<span class=\"pl-v\">replicas_to_aggregate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">50</span>, \n                                                      <span class=\"pl-v\">ma_intervals</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>)\n             \n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> create the hook which handles model average operations.</span>\n  ma_replicas_hook <span class=\"pl-k\">=</span> ma.make_ma_run_hook()\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> And also, create the hook which handles initialization and queues.</span>\n  ma_hook <span class=\"pl-k\">=</span> ma.make_session_run_hook(is_chief)</pre></div>\n<p>Thanks.</p>", "body_text": "We have implemented a new replicas_optimizer \"ModelAverageOptimizer\" to reduce cross-node communication cost. It is mentioned in the following issue:\n#10449\nModel Average\nIn a typical synchronous training environment (N-replica synchronous training), gradients will be averaged each step, and then applied to the variables, after that replicas can fetch the new variables and continue. However, in a model-average training environment, model parameters will be averaged every 'ma_intervals' steps. In the interval between two \"average operation\", each worker trained its local model, there are no data transfer at all between workers or ps, which can significantly accerlate parallel training.\nReference:  https://arxiv.org/pdf/1410.7455v8.pdf\nBMUF\nReference:  http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/0005880.pdf\nBMUF brings in 'Momentum' and can also work with a Nesterov momentum scheme on the based of Model Average method.\nblock_momentum_rate: It brings in the historical blockwise gradients. The block momentum is usually set according to the number of workers: block_momentum = 1.0 - 1.0/num_of_workers. The default value is 0.0. When using default value, the naive ModelAverage method is applied, the original learning rate of local optimizer should be multiply by num_of_workers. While when the value is (0.0,1.0), the BMUF method is applied, the learning rate of local optimizer can be unchanged.\nuse_Nesterov: means the Nesterov-style momentum update is applied on the block level. The default value is true. This can accelerate training with non-zero block_momentum_rate.\nblock_learning_rate: block_learning_rate is always 1.0 or slightly higher than 1.0.\n  def __init__(self,\n               replicas_to_aggregate,                                                                 \n               ma_intervals,\n               total_num_replicas=None,\n               block_momentum_rate=0.0,\n               use_Nesterov=True,\n               block_learning_rate=1.0):\n    \"\"\"Construct a model_average optimizer.\nResult\nWe have benchmarked it on several in-house models, the results showed a good convergence speedup and training-data processing almostly reaches linear speedup.\n\n\n\ndevice config (GPU M40)\nconvergence speed-up\ncomputation speed-up\n\n\n\n\n4 GPUs within 2 nodes\n3.4\n3.9\n\n\n8 GPUs within 4 nodes\n5.7\n7.5\n\n\n16 GPUs within 8 nodes\n9.2\n14.6\n\n\n\nAlso\uff0cwe made a experiment with ResNet on cifar10 (baseline code is from: https://github.com/tensorflow/models/tree/master/resnet):\n\n\n\ndevice config (GPU P100)\nconvergence speed-up\n\n\n\n\n2 GPUs within 1 nodes\n2.03\n\n\n4 GPUs within 1 nodes\n3.67\n\n\n8 GPUs within 1 nodes\n6.57\n\n\n\nAPI\nBy now, it is implemented as a tensorflow API using Python\uff0c doesn't have to change the core/distributed runtime code.\n  # Create any optimizer to update the variables, say a simple SGD:\n  opt = GradientDescentOptimizer(learning_rate=0.1)\n             \n  # Create a ModelAverageOptimizer to update the global variables:\n  ma = tf.contrib.model_average.ModelAverageOptimizer(replicas_to_aggregate=50, \n                                                      ma_intervals=100)\n             \n  # create the hook which handles model average operations.\n  ma_replicas_hook = ma.make_ma_run_hook()\n  # And also, create the hook which handles initialization and queues.\n  ma_hook = ma.make_session_run_hook(is_chief)\nThanks.", "body": "We have implemented a new replicas_optimizer \"ModelAverageOptimizer\" to reduce cross-node communication cost. It is mentioned in the following issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/10449\r\n\r\n# Model Average\r\n\r\nIn a typical synchronous training environment (N-replica synchronous training), gradients will be averaged each step, and then applied to the variables, after that replicas can fetch the new variables and continue. However, in a model-average training environment, model parameters will be averaged every 'ma_intervals' steps. In the interval between two \"average operation\", each worker trained its local model, there are no data transfer at all between workers or ps, which can significantly accerlate parallel training.\r\n\r\nReference:  https://arxiv.org/pdf/1410.7455v8.pdf\r\n\r\n\r\n## BMUF\r\n\r\nReference:  http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/0005880.pdf\r\n\r\nBMUF brings in 'Momentum' and can also work with a Nesterov momentum scheme on the based of Model Average method.\r\n\r\nblock\\_momentum\\_rate: It brings in the historical blockwise gradients. The block momentum is usually set according to the number of workers: block\\_momentum = 1.0 - 1.0/num_of_workers. The default value is 0.0. When using default value, the naive ModelAverage method is applied, the original learning rate of local optimizer should be multiply by num_of_workers. While when the value is (0.0,1.0), the BMUF method is applied, the learning rate of local optimizer can be unchanged.\r\n\r\nuse\\_Nesterov: means the Nesterov-style momentum update is applied on the block level. The default value is true. This can accelerate training with non-zero block_momentum_rate.\r\n\r\nblock\\_learning\\_rate: block\\_learning\\_rate is always 1.0 or slightly higher than 1.0.\r\n\r\n```python             \r\n  def __init__(self,\r\n               replicas_to_aggregate,                                                                 \r\n               ma_intervals,\r\n               total_num_replicas=None,\r\n               block_momentum_rate=0.0,\r\n               use_Nesterov=True,\r\n               block_learning_rate=1.0):\r\n    \"\"\"Construct a model_average optimizer.\r\n```\r\n\r\n# Result\r\nWe have benchmarked it on several in-house models, the results showed a good convergence speedup and training-data processing almostly reaches linear speedup.\r\n\r\n| device config (GPU M40)\t| convergence speed-up | computation speed-up |\r\n|---|---|---|\r\n|4 GPUs within 2 nodes|3.4|3.9|\r\n|8 GPUs within 4 nodes|5.7|7.5|\r\n|16 GPUs within 8 nodes|9.2|14.6|\r\n\r\nAlso\uff0cwe made a experiment with ResNet on cifar10 (baseline code is from: https://github.com/tensorflow/models/tree/master/resnet):\r\n\r\n| device config (GPU P100)\t| convergence speed-up |\r\n|---|---|\r\n|2 GPUs within 1 nodes|2.03|\r\n|4 GPUs within 1 nodes|3.67|\r\n|8 GPUs within 1 nodes|6.57|\r\n\r\n# API\r\nBy now, it is implemented as a tensorflow API using Python\uff0c doesn't have to change the core/distributed runtime code.\r\n\r\n\r\n```python  \r\n  # Create any optimizer to update the variables, say a simple SGD:\r\n  opt = GradientDescentOptimizer(learning_rate=0.1)\r\n             \r\n  # Create a ModelAverageOptimizer to update the global variables:\r\n  ma = tf.contrib.model_average.ModelAverageOptimizer(replicas_to_aggregate=50, \r\n                                                      ma_intervals=100)\r\n             \r\n  # create the hook which handles model average operations.\r\n  ma_replicas_hook = ma.make_ma_run_hook()\r\n  # And also, create the hook which handles initialization and queues.\r\n  ma_hook = ma.make_session_run_hook(is_chief)\r\n```\r\n  \r\n\r\nThanks."}