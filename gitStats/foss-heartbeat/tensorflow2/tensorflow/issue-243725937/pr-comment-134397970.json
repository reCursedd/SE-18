{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/134397970", "pull_request_review_id": 57682256, "id": 134397970, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNDM5Nzk3MA==", "diff_hunk": "@@ -0,0 +1,581 @@\n+# 2017 Contrib.\n+# ==============================================================================\n+\n+\"\"\"Synchronize replicas for model average training.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import time\n+\n+from tensorflow.core.framework import types_pb2\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import data_flow_ops\n+from tensorflow.python.ops import init_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import state_ops\n+from tensorflow.python.ops import variables\n+from tensorflow.python.ops import variable_scope\n+from tensorflow.python.platform import tf_logging as logging\n+from tensorflow.python.training import queue_runner\n+from tensorflow.python.training import session_manager\n+from tensorflow.python.training import session_run_hook\n+\n+class ModelAverageOptimizer(object):\n+  \"\"\"Class to synchronize, aggregate model params.\n+\n+  In a typical synchronous training environment (N-replica synchronous training)\n+  , gradients will be averaged each step, and then applying them to the\n+  variables in one shot, after which replicas can fetch the new variables and\n+  continue. In a model average training environment, model variables will be\n+  averaged (or with momentum) every 'ma_intervals' steps, and then fetch the new\n+  variables and continue training in local worker. In the interval between two\n+  \"average operation\", there are no data transfer at all, which can accerlate\n+  training.\n+\n+  The following accumulators/queue are created:\n+  <empty line>\n+  * N `model-variable accumulators`, one per variable for train model. local\n+  variables are pushed to them and the chief worker will wait until enough\n+  variables are collected and then average them. The accumulator will drop all\n+  stale variables (more details in the accumulator op).\n+  * 1 `token` queue where the optimizer pushes the new global_step value after\n+    all variables are updated.\n+\n+  The following local variable is created:\n+  * `sync_rep_local_step`, one per replica. Compared against the global_step in\n+    each accumulator to check for staleness of the variables.\n+\n+  The optimizer adds nodes to the graph to collect local variables and pause\n+  the trainers until variables are updated.\n+  For the Parameter Server job:\n+  <empty line>\n+  1. An accumulator is created for each variable, and each replica pushes the\n+     local variables into the accumulators.\n+  2. Each accumulator averages once enough variables (replicas_to_aggregate)\n+     have been accumulated.\n+  3. apply the averaged variables to global variables.\n+  4. Only after all variables have been updated, increment the global step.\n+  5. Only after step 4, pushes `global_step` in the `token_queue`, once for\n+     each worker replica. The workers can now fetch the global step, use it to\n+     update its local_step variable and start the next batch.\n+\n+  For the replicas:\n+  <empty line>\n+  1. Start a training block: fetch variables, finish \"ma_intervals\" steps\n+     training.\n+  2. Once current training block has been finished, push local variables into\n+     accumulators. Each accumulator will check the staleness and drop the\n+     stale ones.\n+  3. After pushing all the variables, dequeue an updated value of global_step\n+     from the token queue and record that step to its local_step variable. Note\n+     that this is effectively a barrier.\n+  4. fetch new variables, Start the next block.\n+\n+  ### Usage\n+\n+  ```python\n+  # Create any optimizer to update the variables, say a simple SGD:\n+  opt = GradientDescentOptimizer(learning_rate=0.1)\n+\n+  # Create a ModelAverageOptimizer to update the global variables:\n+  # Note that if you want to have 2 backup replicas, you can change\n+  # total_num_replicas=52 and make sure this number matches how many physical\n+  # replicas you started in your job.\n+  ma = tf.contrib.model_average.ModelAverageOptimizer(replicas_to_aggregate=50,", "path": "tensorflow/contrib/opt/python/training/model_average_optimizer.py", "position": 210, "original_position": 88, "commit_id": "86498c37a589fe38a9464b15b2f39b1576b8cbec", "original_commit_id": "9f7b2fe99e5d63ae14f03d0ab02bbe3839d6021a", "user": {"login": "abenmao", "id": 29789552, "node_id": "MDQ6VXNlcjI5Nzg5NTUy", "avatar_url": "https://avatars0.githubusercontent.com/u/29789552?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abenmao", "html_url": "https://github.com/abenmao", "followers_url": "https://api.github.com/users/abenmao/followers", "following_url": "https://api.github.com/users/abenmao/following{/other_user}", "gists_url": "https://api.github.com/users/abenmao/gists{/gist_id}", "starred_url": "https://api.github.com/users/abenmao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abenmao/subscriptions", "organizations_url": "https://api.github.com/users/abenmao/orgs", "repos_url": "https://api.github.com/users/abenmao/repos", "events_url": "https://api.github.com/users/abenmao/events{/privacy}", "received_events_url": "https://api.github.com/users/abenmao/received_events", "type": "User", "site_admin": false}, "body": "We don't wrapper ModelAverageOptimizer as an actual TensorFlow Optimizer because we think it's unnatural to implement compute_gradients and apply_gradients Functions for model average. ", "created_at": "2017-08-22T06:57:08Z", "updated_at": "2017-09-28T04:17:13Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11581#discussion_r134397970", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11581", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/134397970"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11581#discussion_r134397970"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11581"}}, "body_html": "<p>We don't wrapper ModelAverageOptimizer as an actual TensorFlow Optimizer because we think it's unnatural to implement compute_gradients and apply_gradients Functions for model average.</p>", "body_text": "We don't wrapper ModelAverageOptimizer as an actual TensorFlow Optimizer because we think it's unnatural to implement compute_gradients and apply_gradients Functions for model average.", "in_reply_to_id": 133040354}