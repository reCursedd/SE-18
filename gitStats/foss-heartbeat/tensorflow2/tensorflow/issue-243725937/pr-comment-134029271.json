{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/134029271", "pull_request_review_id": 57282131, "id": 134029271, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNDAyOTI3MQ==", "diff_hunk": "@@ -0,0 +1,145 @@\n+# 2017 Contrib.\n+# ==============================================================================\n+\"\"\"Tests for model_average_optimizer.py.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import numpy as np\n+import portpicker\n+\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import variables\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.platform import test\n+from tensorflow.python.training import server_lib\n+from tensorflow.python.training import training\n+from tensorflow.contrib.opt.python.training import model_average_optimizer\n+\n+\n+def create_local_cluster(num_workers, num_ps, protocol=\"grpc\"):\n+  \"\"\"Create local GRPC servers and return them.\"\"\"\n+  worker_ports = [portpicker.pick_unused_port() for _ in range(num_workers)]\n+  ps_ports = [portpicker.pick_unused_port() for _ in range(num_ps)]\n+  cluster_dict = {\n+      \"worker\": [\"localhost:%s\" % port for port in worker_ports],\n+      \"ps\": [\"localhost:%s\" % port for port in ps_ports]\n+  }\n+  cs = server_lib.ClusterSpec(cluster_dict)\n+\n+  workers = [\n+      server_lib.Server(\n+          cs, job_name=\"worker\", protocol=protocol, task_index=ix, start=True)\n+      for ix in range(num_workers)\n+  ]\n+  ps_servers = [\n+      server_lib.Server(\n+          cs, job_name=\"ps\", protocol=protocol, task_index=ix, start=True)\n+      for ix in range(num_ps)\n+  ]\n+\n+  return workers, ps_servers\n+\n+\n+# Creates the workers and return their sessions, graphs, train_ops.\n+def get_workers(num_workers, replicas_to_aggregate, workers):\n+  sessions = []\n+  graphs = []\n+  train_ops = []\n+  for worker_id in range(num_workers):\n+    graph = ops.Graph()\n+    is_chief = (worker_id == 0)\n+    with graph.as_default():\n+      with ops.device(model_average_optimizer.model_average_device_setter(\n+          worker_device=\"/job:worker/task:%d/gpu:%d\" % (worker_id, worker_id))):\n+        k = variables.Variable(0.0, name=\"k\")\n+        if is_chief:\n+          xs = np.linspace(-0.5, 0.49, 100)\n+        else:\n+          xs = np.linspace(-1.0, 0.99, 100)\n+        ys = 42.0 * xs\n+        x = ops.convert_to_tensor(xs, np.float32)\n+        y = ops.convert_to_tensor(ys, np.float32)\n+\n+        y_hat = math_ops.multiply(k, x, name=\"y_hat\")\n+        sse = math_ops.reduce_sum((y - y_hat) * (y - y_hat), name=\"sse\")\n+        opt = training.GradientDescentOptimizer(learning_rate=0.02)\n+        train_op = opt.minimize(sse)\n+        ma = model_average_optimizer.ModelAverageOptimizer(\n+            replicas_to_aggregate, 1)\n+        ma_hook = ma.make_ma_run_hook()\n+        ma_replicas_hook = ma.make_session_run_hook(is_chief,\n+                                                    num_tokens=num_workers)\n+\n+      # Creates MonitoredSession\n+      session = training.MonitoredTrainingSession(\n+          master=workers[worker_id].target,\n+          is_chief=is_chief,\n+          hooks=[ma_replicas_hook, ma_hook])\n+\n+    sessions.append(session)\n+    graphs.append(graph)\n+    train_ops.append(train_op)\n+\n+  return sessions, graphs, train_ops\n+\n+\n+class ModelAverageOptimizerTest(test.TestCase):\n+  def _run(self, train_op, sess):\n+    sess.run(train_op)\n+\n+  def test2Workers(self):\n+    num_workers = 2\n+    replicas_to_aggregate = 2\n+    num_ps = 1\n+    workers, _ = create_local_cluster(num_workers=num_workers, num_ps=num_ps)\n+\n+    # Creates and returns all the workers.\n+    sessions, graphs, train_ops = get_workers(num_workers,\n+                                              replicas_to_aggregate, workers)\n+    var_0 = graphs[0].get_tensor_by_name(\"k:0\")\n+    var_1 = graphs[1].get_tensor_by_name(\"k:0\")\n+    var_g = graphs[0].get_tensor_by_name(\"modelAverage_g0:0\")\n+\n+    self.assertAllEqual(0.0, sessions[0]._tf_sess().run(var_0))\n+\n+    # We have initial tokens in the queue so we can call this one by one. After\n+    # the first step, this will no longer work as there will be no more extra\n+    # tokens in the queue.\n+    sessions[0].run(train_ops[0])\n+    sessions[1].run(train_ops[1])\n+\n+    sessions[0].run(train_ops[0])\n+    sessions[1].run(train_ops[1])\n+    # Will just use session 1 to verify all the variables later.\n+    a = 14.00279999\n+    b = 56.56562805\n+    ma = (a+b)/2.0\n+    self.assertAllClose(ma, sessions[0]._tf_sess().run(var_0))\n+    self.assertAllClose(ma, sessions[1]._tf_sess().run(var_1))\n+    self.assertAllClose(ma, sessions[0]._tf_sess().run(var_g))\n+\n+  _cluster_spec = server_lib.ClusterSpec({\n+      \"ps\": [\"ps0:2222\", \"ps1:2222\"],\n+      \"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]\n+  })\n+\n+  def testPS2TasksWithClusterSpecClass(self):\n+    with ops.device(\n+        model_average_optimizer.model_average_device_setter(\n+            cluster=self._cluster_spec)):", "path": "tensorflow/contrib/opt/python/training/model_average_optimizer_test.py", "position": null, "original_position": 131, "commit_id": "86498c37a589fe38a9464b15b2f39b1576b8cbec", "original_commit_id": "4bb973323e87b2a442dcedd710fe3f14106d6182", "user": {"login": "ry", "id": 80, "node_id": "MDQ6VXNlcjgw", "avatar_url": "https://avatars1.githubusercontent.com/u/80?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ry", "html_url": "https://github.com/ry", "followers_url": "https://api.github.com/users/ry/followers", "following_url": "https://api.github.com/users/ry/following{/other_user}", "gists_url": "https://api.github.com/users/ry/gists{/gist_id}", "starred_url": "https://api.github.com/users/ry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ry/subscriptions", "organizations_url": "https://api.github.com/users/ry/orgs", "repos_url": "https://api.github.com/users/ry/repos", "events_url": "https://api.github.com/users/ry/events{/privacy}", "received_events_url": "https://api.github.com/users/ry/received_events", "type": "User", "site_admin": false}, "body": "missing `ps_tasks` argument.", "created_at": "2017-08-18T18:43:53Z", "updated_at": "2017-09-28T04:17:13Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11581#discussion_r134029271", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11581", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/134029271"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11581#discussion_r134029271"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11581"}}, "body_html": "<p>missing <code>ps_tasks</code> argument.</p>", "body_text": "missing ps_tasks argument."}