{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/323904511", "html_url": "https://github.com/tensorflow/tensorflow/pull/11581#issuecomment-323904511", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11581", "id": 323904511, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzkwNDUxMQ==", "user": {"login": "zhouh", "id": 7070361, "node_id": "MDQ6VXNlcjcwNzAzNjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/7070361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhouh", "html_url": "https://github.com/zhouh", "followers_url": "https://api.github.com/users/zhouh/followers", "following_url": "https://api.github.com/users/zhouh/following{/other_user}", "gists_url": "https://api.github.com/users/zhouh/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhouh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhouh/subscriptions", "organizations_url": "https://api.github.com/users/zhouh/orgs", "repos_url": "https://api.github.com/users/zhouh/repos", "events_url": "https://api.github.com/users/zhouh/events{/privacy}", "received_events_url": "https://api.github.com/users/zhouh/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-22T02:49:27Z", "updated_at": "2017-08-22T02:54:05Z", "author_association": "NONE", "body_html": "<p>Thank you for your contribution. I have been using your code to accelerate my in-house neural machine translation system, but I find it does not converge. The loss stoped at 4.5, which should be 1.5 instead. Do you have any general idea for the issue? Here is my code.</p>\n<p>`</p>\n<p>def distributed_run(self, server, cluster, num_workers, gpu_options):</p>\n<pre><code>    # begin model average distributed training\n\n    if self.job_name == 'ps':\n        server.join()\n    elif self.job_name == 'worker':\n        is_chief = (self.task_index == 0)\n\n        with tf.device(device_setter.model_average_device_setter(\n                worker_device=\"/job:worker/task:%d/gpu:%d\" %\n                        (self.task_index, self.gpu_id), cluster=cluster)):\n\n\n            # Create model template function\n            model_template_builder = tf.make_template(\"\", self.seq2seqmodel.build, create_scope_now_=False)\n            source_ids, source_seq_length, target_ids, target_seq_length = self._build_input_fields()\n\n            seq2seq_info = model_template_builder(source_ids, source_seq_length, target_ids, target_seq_length)\n            loss = seq2seq_info.loss\n\n            loss = tf.reduce_mean(loss)\n\n            train_op, global_steps_tensor = create_train_op(self.opt_params, loss)\n\n            if self.do_evaluation and is_chief:\n                tf.logging.info(\"Building evaluate model\")\n                self.dev_evaluate_helper.build((source_ids, source_seq_length))\n\n            ma = model_average.ModelAverageOptimizer(4, 10)\n\n\n    # build the distributed operation\n    config = tf.ConfigProto(gpu_options=gpu_options)\n    config.log_device_placement = False\n    config.allow_soft_placement = True\n\n    ma_hook = ma.make_ma_run_hook()\n    ma_replicas_hook = ma.make_session_run_hook(is_chief)\n\n\n    save_checkpoints_steps = self.training_options['save_checkpoints_steps']\n    max_train_epochs = self.training_options['train_epochs']\n    max_train_steps = self.training_options['train_steps']\n    display_steps = self.training_options['display_steps']\n\n\n    #\n    #\n    #\n    # if is_chief:\n    #     merged_summary = tf.summary.merge_all()\n    #     summary_writer = tf.summary.FileWriter(os.path.join(self.output_dir, \"events\"), self.sess.graph)\n    #\n\n    self.distributed_sess = tf.train.MonitoredTrainingSession(master=server.target,\n                                             is_chief=is_chief,\n                                             checkpoint_dir=self.output_dir,\n                                             save_checkpoint_secs=save_checkpoints_steps,\n                                             save_summaries_steps=display_steps,\n                                             hooks=[ma_replicas_hook, ma_hook],\n                                             config=config)\n\n    train_data = TrainTextIterator(self.training_options['train_sources'],\n                                   self.training_options['train_targets'],\n                                   self.vocab_source,\n                                   self.vocab_target,\n                                   maxlen_src=self.training_options[\"source_max_seq_len\"],\n                                   maxlen_trg=self.training_options[\"target_max_seq_len\"],\n                                   batch_size=self.training_options['batch_size'])\n\n\n    # not need saver now\n    # saver = tf.train.Saver()\n    # model_out = os.path.join(self.output_dir, \"model-ckpt\")\n\n    # for the distributed training process, the MonitoredTrainingSession\n    # can help initialization and restore automatically\n    #\n    # # reload\n    # checkpoint_path = tf.train.latest_checkpoint()\n    # if checkpoint_path:\n    #     tf.logging.info(\"reloading models...\")\n    #     saver.restore(self.sess, checkpoint_path)\n    # else:\n    #     tf.logging.info(\"initializing model parameters...\")\n    #     self.sess.run(tf.global_variables_initializer())\n    # dump model details \"model_analysis.txt\"\n    #\n    # if  is_chief:\n    #     dump_model_analysis(self.output_dir)\n    #\n\n    # self.sess.graph.finalize()\n\n    estop = False\n    ud_accumulate = 0.\n\n    for eidx in range(max_train_epochs):\n\n        tf.logging.info(\"Epooch: %d\" % eidx)\n\n        if self.distributed_sess.should_stop():\n            break\n\n        for (x, lengths_x), (y, lengths_y) in train_data:\n            ud_start = time.time()\n            # update\n\n\n            _, global_step, training_loss \\\n                = self.distributed_sess.run([train_op, global_steps_tensor, loss],\n                                feed_dict={source_ids:x, source_seq_length:lengths_x,\n                                           target_ids:y, target_seq_length:lengths_y})\n            ud_accumulate += time.time() - ud_start\n\n            # display training loss\n            if global_step % display_steps == 0 and is_chief:\n                tf.logging.info(\"Epoch %d  Update %d\\tLoss=%f   UD %f s/update\" \\\n                                % (eidx, global_step, training_loss,\n                                   ud_accumulate / display_steps))\n                # summary_writer.add_summary(summary, global_step)\n                ud_accumulate = 0.\n\n            # greedy inference for developing\n            if global_step % save_checkpoints_steps == 0 and is_chief:\n            # if  is_chief:\n\n                tf.logging.info(\"Saving models... global step=%d\" % global_step)\n                # saver.save(self.sess, model_out, global_step=global_step)\n                # evaluate model with BLEU score\n                if self.do_evaluation and self.eval_options[\"start_eval_at\"] &lt;= global_step:\n                    tf.logging.info(\"Evaluating with BLEU score......\")\n                    eval_start_time = time.time()\n                    samples, bleu = self.dev_evaluate_helper.evaluate(self.sess,\n                                                                      global_step)\n                    tf.logging.info(\"Evaluating DEVSET: BLEU=%f  GlobalStep=%s   UD %.2f\"\n                                    % (bleu, global_step, time.time()-eval_start_time))\n                    for idx, (s, p) in enumerate(zip(*samples)):\n                        tf.logging.info(\"Sample%d Source: %s\" % (idx, s))\n                        tf.logging.info(\"Sample%d Prediction: %s\\n\" % (idx, p))\n            if global_step &gt; max_train_steps:\n                estop = True\n                break\n        if estop:\n            tf.logging.info(\"Trained maximum steps: %d\" % max_train_steps)\n            break\n    #saver.save(self.sess, model_out, global_step=global_step)\n</code></pre>\n<p>`</p>", "body_text": "Thank you for your contribution. I have been using your code to accelerate my in-house neural machine translation system, but I find it does not converge. The loss stoped at 4.5, which should be 1.5 instead. Do you have any general idea for the issue? Here is my code.\n`\ndef distributed_run(self, server, cluster, num_workers, gpu_options):\n    # begin model average distributed training\n\n    if self.job_name == 'ps':\n        server.join()\n    elif self.job_name == 'worker':\n        is_chief = (self.task_index == 0)\n\n        with tf.device(device_setter.model_average_device_setter(\n                worker_device=\"/job:worker/task:%d/gpu:%d\" %\n                        (self.task_index, self.gpu_id), cluster=cluster)):\n\n\n            # Create model template function\n            model_template_builder = tf.make_template(\"\", self.seq2seqmodel.build, create_scope_now_=False)\n            source_ids, source_seq_length, target_ids, target_seq_length = self._build_input_fields()\n\n            seq2seq_info = model_template_builder(source_ids, source_seq_length, target_ids, target_seq_length)\n            loss = seq2seq_info.loss\n\n            loss = tf.reduce_mean(loss)\n\n            train_op, global_steps_tensor = create_train_op(self.opt_params, loss)\n\n            if self.do_evaluation and is_chief:\n                tf.logging.info(\"Building evaluate model\")\n                self.dev_evaluate_helper.build((source_ids, source_seq_length))\n\n            ma = model_average.ModelAverageOptimizer(4, 10)\n\n\n    # build the distributed operation\n    config = tf.ConfigProto(gpu_options=gpu_options)\n    config.log_device_placement = False\n    config.allow_soft_placement = True\n\n    ma_hook = ma.make_ma_run_hook()\n    ma_replicas_hook = ma.make_session_run_hook(is_chief)\n\n\n    save_checkpoints_steps = self.training_options['save_checkpoints_steps']\n    max_train_epochs = self.training_options['train_epochs']\n    max_train_steps = self.training_options['train_steps']\n    display_steps = self.training_options['display_steps']\n\n\n    #\n    #\n    #\n    # if is_chief:\n    #     merged_summary = tf.summary.merge_all()\n    #     summary_writer = tf.summary.FileWriter(os.path.join(self.output_dir, \"events\"), self.sess.graph)\n    #\n\n    self.distributed_sess = tf.train.MonitoredTrainingSession(master=server.target,\n                                             is_chief=is_chief,\n                                             checkpoint_dir=self.output_dir,\n                                             save_checkpoint_secs=save_checkpoints_steps,\n                                             save_summaries_steps=display_steps,\n                                             hooks=[ma_replicas_hook, ma_hook],\n                                             config=config)\n\n    train_data = TrainTextIterator(self.training_options['train_sources'],\n                                   self.training_options['train_targets'],\n                                   self.vocab_source,\n                                   self.vocab_target,\n                                   maxlen_src=self.training_options[\"source_max_seq_len\"],\n                                   maxlen_trg=self.training_options[\"target_max_seq_len\"],\n                                   batch_size=self.training_options['batch_size'])\n\n\n    # not need saver now\n    # saver = tf.train.Saver()\n    # model_out = os.path.join(self.output_dir, \"model-ckpt\")\n\n    # for the distributed training process, the MonitoredTrainingSession\n    # can help initialization and restore automatically\n    #\n    # # reload\n    # checkpoint_path = tf.train.latest_checkpoint()\n    # if checkpoint_path:\n    #     tf.logging.info(\"reloading models...\")\n    #     saver.restore(self.sess, checkpoint_path)\n    # else:\n    #     tf.logging.info(\"initializing model parameters...\")\n    #     self.sess.run(tf.global_variables_initializer())\n    # dump model details \"model_analysis.txt\"\n    #\n    # if  is_chief:\n    #     dump_model_analysis(self.output_dir)\n    #\n\n    # self.sess.graph.finalize()\n\n    estop = False\n    ud_accumulate = 0.\n\n    for eidx in range(max_train_epochs):\n\n        tf.logging.info(\"Epooch: %d\" % eidx)\n\n        if self.distributed_sess.should_stop():\n            break\n\n        for (x, lengths_x), (y, lengths_y) in train_data:\n            ud_start = time.time()\n            # update\n\n\n            _, global_step, training_loss \\\n                = self.distributed_sess.run([train_op, global_steps_tensor, loss],\n                                feed_dict={source_ids:x, source_seq_length:lengths_x,\n                                           target_ids:y, target_seq_length:lengths_y})\n            ud_accumulate += time.time() - ud_start\n\n            # display training loss\n            if global_step % display_steps == 0 and is_chief:\n                tf.logging.info(\"Epoch %d  Update %d\\tLoss=%f   UD %f s/update\" \\\n                                % (eidx, global_step, training_loss,\n                                   ud_accumulate / display_steps))\n                # summary_writer.add_summary(summary, global_step)\n                ud_accumulate = 0.\n\n            # greedy inference for developing\n            if global_step % save_checkpoints_steps == 0 and is_chief:\n            # if  is_chief:\n\n                tf.logging.info(\"Saving models... global step=%d\" % global_step)\n                # saver.save(self.sess, model_out, global_step=global_step)\n                # evaluate model with BLEU score\n                if self.do_evaluation and self.eval_options[\"start_eval_at\"] <= global_step:\n                    tf.logging.info(\"Evaluating with BLEU score......\")\n                    eval_start_time = time.time()\n                    samples, bleu = self.dev_evaluate_helper.evaluate(self.sess,\n                                                                      global_step)\n                    tf.logging.info(\"Evaluating DEVSET: BLEU=%f  GlobalStep=%s   UD %.2f\"\n                                    % (bleu, global_step, time.time()-eval_start_time))\n                    for idx, (s, p) in enumerate(zip(*samples)):\n                        tf.logging.info(\"Sample%d Source: %s\" % (idx, s))\n                        tf.logging.info(\"Sample%d Prediction: %s\\n\" % (idx, p))\n            if global_step > max_train_steps:\n                estop = True\n                break\n        if estop:\n            tf.logging.info(\"Trained maximum steps: %d\" % max_train_steps)\n            break\n    #saver.save(self.sess, model_out, global_step=global_step)\n\n`", "body": "Thank you for your contribution. I have been using your code to accelerate my in-house neural machine translation system, but I find it does not converge. The loss stoped at 4.5, which should be 1.5 instead. Do you have any general idea for the issue? Here is my code.\r\n\r\n`\r\n\r\n\r\n def distributed_run(self, server, cluster, num_workers, gpu_options):\r\n\r\n        # begin model average distributed training\r\n\r\n        if self.job_name == 'ps':\r\n            server.join()\r\n        elif self.job_name == 'worker':\r\n            is_chief = (self.task_index == 0)\r\n\r\n            with tf.device(device_setter.model_average_device_setter(\r\n                    worker_device=\"/job:worker/task:%d/gpu:%d\" %\r\n                            (self.task_index, self.gpu_id), cluster=cluster)):\r\n\r\n\r\n                # Create model template function\r\n                model_template_builder = tf.make_template(\"\", self.seq2seqmodel.build, create_scope_now_=False)\r\n                source_ids, source_seq_length, target_ids, target_seq_length = self._build_input_fields()\r\n\r\n                seq2seq_info = model_template_builder(source_ids, source_seq_length, target_ids, target_seq_length)\r\n                loss = seq2seq_info.loss\r\n\r\n                loss = tf.reduce_mean(loss)\r\n\r\n                train_op, global_steps_tensor = create_train_op(self.opt_params, loss)\r\n\r\n                if self.do_evaluation and is_chief:\r\n                    tf.logging.info(\"Building evaluate model\")\r\n                    self.dev_evaluate_helper.build((source_ids, source_seq_length))\r\n\r\n                ma = model_average.ModelAverageOptimizer(4, 10)\r\n\r\n\r\n        # build the distributed operation\r\n        config = tf.ConfigProto(gpu_options=gpu_options)\r\n        config.log_device_placement = False\r\n        config.allow_soft_placement = True\r\n\r\n        ma_hook = ma.make_ma_run_hook()\r\n        ma_replicas_hook = ma.make_session_run_hook(is_chief)\r\n\r\n\r\n        save_checkpoints_steps = self.training_options['save_checkpoints_steps']\r\n        max_train_epochs = self.training_options['train_epochs']\r\n        max_train_steps = self.training_options['train_steps']\r\n        display_steps = self.training_options['display_steps']\r\n\r\n\r\n        #\r\n        #\r\n        #\r\n        # if is_chief:\r\n        #     merged_summary = tf.summary.merge_all()\r\n        #     summary_writer = tf.summary.FileWriter(os.path.join(self.output_dir, \"events\"), self.sess.graph)\r\n        #\r\n\r\n        self.distributed_sess = tf.train.MonitoredTrainingSession(master=server.target,\r\n                                                 is_chief=is_chief,\r\n                                                 checkpoint_dir=self.output_dir,\r\n                                                 save_checkpoint_secs=save_checkpoints_steps,\r\n                                                 save_summaries_steps=display_steps,\r\n                                                 hooks=[ma_replicas_hook, ma_hook],\r\n                                                 config=config)\r\n\r\n        train_data = TrainTextIterator(self.training_options['train_sources'],\r\n                                       self.training_options['train_targets'],\r\n                                       self.vocab_source,\r\n                                       self.vocab_target,\r\n                                       maxlen_src=self.training_options[\"source_max_seq_len\"],\r\n                                       maxlen_trg=self.training_options[\"target_max_seq_len\"],\r\n                                       batch_size=self.training_options['batch_size'])\r\n\r\n\r\n        # not need saver now\r\n        # saver = tf.train.Saver()\r\n        # model_out = os.path.join(self.output_dir, \"model-ckpt\")\r\n\r\n        # for the distributed training process, the MonitoredTrainingSession\r\n        # can help initialization and restore automatically\r\n        #\r\n        # # reload\r\n        # checkpoint_path = tf.train.latest_checkpoint()\r\n        # if checkpoint_path:\r\n        #     tf.logging.info(\"reloading models...\")\r\n        #     saver.restore(self.sess, checkpoint_path)\r\n        # else:\r\n        #     tf.logging.info(\"initializing model parameters...\")\r\n        #     self.sess.run(tf.global_variables_initializer())\r\n        # dump model details \"model_analysis.txt\"\r\n        #\r\n        # if  is_chief:\r\n        #     dump_model_analysis(self.output_dir)\r\n        #\r\n\r\n        # self.sess.graph.finalize()\r\n\r\n        estop = False\r\n        ud_accumulate = 0.\r\n\r\n        for eidx in range(max_train_epochs):\r\n\r\n            tf.logging.info(\"Epooch: %d\" % eidx)\r\n\r\n            if self.distributed_sess.should_stop():\r\n                break\r\n\r\n            for (x, lengths_x), (y, lengths_y) in train_data:\r\n                ud_start = time.time()\r\n                # update\r\n\r\n\r\n                _, global_step, training_loss \\\r\n                    = self.distributed_sess.run([train_op, global_steps_tensor, loss],\r\n                                    feed_dict={source_ids:x, source_seq_length:lengths_x,\r\n                                               target_ids:y, target_seq_length:lengths_y})\r\n                ud_accumulate += time.time() - ud_start\r\n\r\n                # display training loss\r\n                if global_step % display_steps == 0 and is_chief:\r\n                    tf.logging.info(\"Epoch %d  Update %d\\tLoss=%f   UD %f s/update\" \\\r\n                                    % (eidx, global_step, training_loss,\r\n                                       ud_accumulate / display_steps))\r\n                    # summary_writer.add_summary(summary, global_step)\r\n                    ud_accumulate = 0.\r\n\r\n                # greedy inference for developing\r\n                if global_step % save_checkpoints_steps == 0 and is_chief:\r\n                # if  is_chief:\r\n\r\n                    tf.logging.info(\"Saving models... global step=%d\" % global_step)\r\n                    # saver.save(self.sess, model_out, global_step=global_step)\r\n                    # evaluate model with BLEU score\r\n                    if self.do_evaluation and self.eval_options[\"start_eval_at\"] <= global_step:\r\n                        tf.logging.info(\"Evaluating with BLEU score......\")\r\n                        eval_start_time = time.time()\r\n                        samples, bleu = self.dev_evaluate_helper.evaluate(self.sess,\r\n                                                                          global_step)\r\n                        tf.logging.info(\"Evaluating DEVSET: BLEU=%f  GlobalStep=%s   UD %.2f\"\r\n                                        % (bleu, global_step, time.time()-eval_start_time))\r\n                        for idx, (s, p) in enumerate(zip(*samples)):\r\n                            tf.logging.info(\"Sample%d Source: %s\" % (idx, s))\r\n                            tf.logging.info(\"Sample%d Prediction: %s\\n\" % (idx, p))\r\n                if global_step > max_train_steps:\r\n                    estop = True\r\n                    break\r\n            if estop:\r\n                tf.logging.info(\"Trained maximum steps: %d\" % max_train_steps)\r\n                break\r\n        #saver.save(self.sess, model_out, global_step=global_step)\r\n`"}