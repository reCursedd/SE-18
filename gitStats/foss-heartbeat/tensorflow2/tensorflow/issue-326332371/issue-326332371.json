{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19546", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19546/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19546/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19546/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19546", "id": 326332371, "node_id": "MDU6SXNzdWUzMjYzMzIzNzE=", "number": 19546, "title": "Estimator API for DQN?", "user": {"login": "daogiang993", "id": 16729921, "node_id": "MDQ6VXNlcjE2NzI5OTIx", "avatar_url": "https://avatars0.githubusercontent.com/u/16729921?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daogiang993", "html_url": "https://github.com/daogiang993", "followers_url": "https://api.github.com/users/daogiang993/followers", "following_url": "https://api.github.com/users/daogiang993/following{/other_user}", "gists_url": "https://api.github.com/users/daogiang993/gists{/gist_id}", "starred_url": "https://api.github.com/users/daogiang993/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daogiang993/subscriptions", "organizations_url": "https://api.github.com/users/daogiang993/orgs", "repos_url": "https://api.github.com/users/daogiang993/repos", "events_url": "https://api.github.com/users/daogiang993/events{/privacy}", "received_events_url": "https://api.github.com/users/daogiang993/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-24T23:32:29Z", "updated_at": "2018-06-26T10:38:23Z", "closed_at": "2018-06-26T10:38:23Z", "author_association": "NONE", "body_html": "<p>Hello,<br>\nThis is my first time using Estimator API. I'm trying to use Estimator to train a DQN on multiple GPUs. Here is my code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">from</span> constants <span class=\"pl-k\">import</span> <span class=\"pl-k\">*</span>\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Net</span>:\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">n_state</span>, <span class=\"pl-smi\">n_action</span>, <span class=\"pl-smi\">dueling</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-smi\">grad_clip</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>, <span class=\"pl-smi\">double_q</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>):\n        <span class=\"pl-c1\">self</span>.n_state <span class=\"pl-k\">=</span> n_state\n        <span class=\"pl-c1\">self</span>.n_action <span class=\"pl-k\">=</span> n_action\n        <span class=\"pl-c1\">self</span>.dueling <span class=\"pl-k\">=</span> dueling\n        <span class=\"pl-c1\">self</span>.grad_clip <span class=\"pl-k\">=</span> grad_clip\n        <span class=\"pl-c1\">self</span>.double_q <span class=\"pl-k\">=</span> double_q\n\n        params <span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>lr<span class=\"pl-pds\">'</span></span>:<span class=\"pl-c1\">LR_NN</span>,\n                 <span class=\"pl-s\"><span class=\"pl-pds\">'</span>eps<span class=\"pl-pds\">'</span></span>:<span class=\"pl-c1\">1e-3</span>,\n                 <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gamma<span class=\"pl-pds\">'</span></span>:<span class=\"pl-c1\">DISCOUNT_FACTOR</span>,\n                 <span class=\"pl-s\"><span class=\"pl-pds\">'</span>double_q<span class=\"pl-pds\">'</span></span>:double_q,\n                 <span class=\"pl-s\"><span class=\"pl-pds\">'</span>grad_clip<span class=\"pl-pds\">'</span></span>:grad_clip,\n                 <span class=\"pl-s\"><span class=\"pl-pds\">'</span>n_action<span class=\"pl-pds\">'</span></span>:n_action}\n\n        <span class=\"pl-c1\">self</span>.model <span class=\"pl-k\">=</span> tf.estimator.Estimator(<span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>tf.contrib.estimator.replicate_model_fn(<span class=\"pl-c1\">self</span>._model_fn), <span class=\"pl-v\">params</span><span class=\"pl-k\">=</span>params)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_inference</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">state_in</span>, <span class=\"pl-smi\">scope_name</span>, <span class=\"pl-smi\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n        <span class=\"pl-k\">with</span> tf.variable_scope(scope_name, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse):\n            h1 <span class=\"pl-k\">=</span> tf.layers.conv2d(state_in, <span class=\"pl-c1\">CONV1_SIZE</span>, <span class=\"pl-c1\">CONV1_KERNEL</span>, <span class=\"pl-c1\">CONV1_STRIDE</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu, <span class=\"pl-v\">kernel_initializer</span><span class=\"pl-k\">=</span>tf.contrib.layers.variance_scaling_initializer(<span class=\"pl-c1\">2.0</span>))\n            h2 <span class=\"pl-k\">=</span> tf.layers.conv2d(h1, <span class=\"pl-c1\">CONV2_SIZE</span>, <span class=\"pl-c1\">CONV2_KERNEL</span>, <span class=\"pl-c1\">CONV2_STRIDE</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu, <span class=\"pl-v\">kernel_initializer</span><span class=\"pl-k\">=</span>tf.contrib.layers.variance_scaling_initializer(<span class=\"pl-c1\">2.0</span>))\n            h3 <span class=\"pl-k\">=</span> tf.layers.conv2d(h2, <span class=\"pl-c1\">CONV3_SIZE</span>, <span class=\"pl-c1\">CONV3_KERNEL</span>, <span class=\"pl-c1\">CONV3_STRIDE</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu, <span class=\"pl-v\">kernel_initializer</span><span class=\"pl-k\">=</span>tf.contrib.layers.variance_scaling_initializer(<span class=\"pl-c1\">2.0</span>))\n            h4 <span class=\"pl-k\">=</span> tf.layers.dense(tf.layers.flatten(h3), <span class=\"pl-c1\">256</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu, <span class=\"pl-v\">kernel_initializer</span><span class=\"pl-k\">=</span>tf.contrib.layers.variance_scaling_initializer(<span class=\"pl-c1\">2.0</span>))\n            <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.dueling:\n                V <span class=\"pl-k\">=</span> tf.layers.dense(h4, <span class=\"pl-c1\">1</span>)\n                A <span class=\"pl-k\">=</span> tf.layers.dense(h4, <span class=\"pl-c1\">self</span>.n_action)\n                Q <span class=\"pl-k\">=</span> A <span class=\"pl-k\">+</span> V <span class=\"pl-k\">-</span> tf.reduce_mean(A, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keepdims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n            <span class=\"pl-k\">else</span>:\n                Q <span class=\"pl-k\">=</span> tf.layers.dense(h4, <span class=\"pl-c1\">self</span>.n_action)\n        <span class=\"pl-k\">return</span> Q\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_model_fn</span>(<span class=\"pl-smi\">inp</span>, <span class=\"pl-smi\">mode</span>, <span class=\"pl-smi\">params</span>):\n        s <span class=\"pl-k\">=</span> inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>s<span class=\"pl-pds\">'</span></span>]\n        a <span class=\"pl-k\">=</span> inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>]\n        r <span class=\"pl-k\">=</span> inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>r<span class=\"pl-pds\">'</span></span>]\n        ns <span class=\"pl-k\">=</span> inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>ns<span class=\"pl-pds\">'</span></span>]\n        d <span class=\"pl-k\">=</span> inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>d<span class=\"pl-pds\">'</span></span>]\n\n        online_Q <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._inference(s, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>online<span class=\"pl-pds\">'</span></span>)\n        target_Q <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._inference(ns, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>target<span class=\"pl-pds\">'</span></span>)\n        next_online_Q <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._inference(ns, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>online<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n        <span class=\"pl-k\">if</span> params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>double_q<span class=\"pl-pds\">'</span></span>]:\n            best <span class=\"pl-k\">=</span> tf.reduce_sum(target_Q<span class=\"pl-k\">*</span>tf.one_hot(tf.argmax(next_online_Q, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>), params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>n_action<span class=\"pl-pds\">'</span></span>]), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keepdims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n        <span class=\"pl-k\">else</span>:\n            best <span class=\"pl-k\">=</span> tf.reduce_max(target_Q, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keepdims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n        target <span class=\"pl-k\">=</span> r <span class=\"pl-k\">+</span> (<span class=\"pl-c1\">1.0</span> <span class=\"pl-k\">-</span> d)<span class=\"pl-k\">*</span>params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>gamma<span class=\"pl-pds\">'</span></span>]<span class=\"pl-k\">*</span>tf.stop_gradient(best)\n        pred <span class=\"pl-k\">=</span> tf.reduce_sum(online_Q<span class=\"pl-k\">*</span>tf.one_hot(a, params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>n_action<span class=\"pl-pds\">'</span></span>]), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keepdims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n        loss <span class=\"pl-k\">=</span> tf.losses.huber_loss(target, pred, <span class=\"pl-v\">reduction</span><span class=\"pl-k\">=</span>tf.losses.Reduction.<span class=\"pl-c1\">MEAN</span>)\n\n        optimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>lr<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">epsilon</span><span class=\"pl-k\">=</span>params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>eps<span class=\"pl-pds\">'</span></span>])\n        optimizer <span class=\"pl-k\">=</span> tf.contrib.estimator.TowerOptimizer(optimizer)\n\n        <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>:\n            <span class=\"pl-k\">if</span> params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>grad_clip<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n                grads <span class=\"pl-k\">=</span> optimizer.compute_gradients(loss)\n                <span class=\"pl-k\">for</span> i, (grad, var) <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(grads):\n                    <span class=\"pl-k\">if</span> grad <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n                        grads[i] <span class=\"pl-k\">=</span> (tf.clip_by_norm(grad, params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>grad_clip<span class=\"pl-pds\">'</span></span>]), var)\n                optimizer_op <span class=\"pl-k\">=</span> optimizer.apply_gradients(grads)\n            <span class=\"pl-k\">else</span>:\n                optimizer_op <span class=\"pl-k\">=</span> optimizer.minimize(loss)\n\n            <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>optimizer_op)\n        <span class=\"pl-k\">elif</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">PREDICT</span>:\n            pred_action <span class=\"pl-k\">=</span> tf.argmax(online_Q)\n            <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">predictions</span><span class=\"pl-k\">=</span>pred_action)\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    sess <span class=\"pl-k\">=</span> tf.InteractiveSession()\n    nn <span class=\"pl-k\">=</span> Net(<span class=\"pl-v\">n_state</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">84</span>,<span class=\"pl-c1\">84</span>,<span class=\"pl-c1\">4</span>), <span class=\"pl-v\">n_action</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n    sess.run(tf.global_variables_initializer())\n    s <span class=\"pl-k\">=</span> np.random.rand(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">84</span>, <span class=\"pl-c1\">84</span>, <span class=\"pl-c1\">4</span>)\n    ns <span class=\"pl-k\">=</span> np.random.rand(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">84</span>, <span class=\"pl-c1\">84</span>, <span class=\"pl-c1\">4</span>)\n    a <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">4</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>)\n    r <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">30</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>).reshape(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>)\n    d <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">2</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>).reshape(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>)\n    inp <span class=\"pl-k\">=</span> {}\n    inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>s<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> np.array(s)\n    inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> np.array(a)\n    inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>r<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> np.array(r)\n    inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>ns<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> np.array(ns)\n    inp[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>d<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> np.array(d)\n\n    input_f <span class=\"pl-k\">=</span> tf.estimator.inputs.numpy_input_fn(<span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>inp, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    nn.model.train(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>input_f, <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)</pre></div>\n<p>The output/error when running the last (final) line:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">INFO</span>:tensorflow:Calling model_fn.\n<span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">7</span><span class=\"pl-k\">-</span><span class=\"pl-ii\">1a67111ae305</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n<span class=\"pl-ii\">----</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">1</span> nn.model.train(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>input_f, <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>estimator.py <span class=\"pl-k\">in</span> train(<span class=\"pl-c1\">self</span>, input_fn, hooks, steps, max_steps, saving_listeners)\n    <span class=\"pl-c1\">361</span> \n    <span class=\"pl-c1\">362</span>       saving_listeners <span class=\"pl-k\">=</span> _check_listeners_type(saving_listeners)\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">363</span>       loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._train_model(input_fn, hooks, saving_listeners)\n    <span class=\"pl-c1\">364</span>       logging.info(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Loss for final step: <span class=\"pl-c1\">%s</span>.<span class=\"pl-pds\">'</span></span>, loss)\n    <span class=\"pl-c1\">365</span>       <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>estimator.py <span class=\"pl-k\">in</span> _train_model(<span class=\"pl-c1\">self</span>, input_fn, hooks, saving_listeners)\n   <span class=\"pl-c1\">1053</span>       <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>._train_model_distributed(input_fn, hooks, saving_listeners)\n   <span class=\"pl-c1\">1054</span>     <span class=\"pl-k\">else</span>:\n<span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">1055</span>       <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>._train_model_default(input_fn, hooks, saving_listeners)\n   <span class=\"pl-c1\">1056</span> \n   <span class=\"pl-c1\">1057</span>   <span class=\"pl-k\">def</span> <span class=\"pl-en\">_train_model_default</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input_fn</span>, <span class=\"pl-smi\">hooks</span>, <span class=\"pl-smi\">saving_listeners</span>):\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>estimator.py <span class=\"pl-k\">in</span> _train_model_default(<span class=\"pl-c1\">self</span>, input_fn, hooks, saving_listeners)\n   <span class=\"pl-c1\">1066</span>       worker_hooks.extend(input_hooks)\n   <span class=\"pl-c1\">1067</span>       estimator_spec <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._call_model_fn(\n<span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">1068</span>           features, labels, model_fn_lib.ModeKeys.<span class=\"pl-c1\">TRAIN</span>, <span class=\"pl-c1\">self</span>.config)\n   <span class=\"pl-c1\">1069</span>       <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>._train_with_estimator_spec(estimator_spec, worker_hooks,\n   <span class=\"pl-c1\">1070</span>                                              hooks, global_step_tensor,\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>estimator.py <span class=\"pl-k\">in</span> _call_model_fn(<span class=\"pl-c1\">self</span>, features, labels, mode, config)\n   <span class=\"pl-c1\">1041</span> \n   <span class=\"pl-c1\">1042</span>     logging.info(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Calling model_fn.<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">1043</span>     <span class=\"pl-v\">model_fn_results</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._model_fn(<span class=\"pl-v\">features</span><span class=\"pl-k\">=</span>features, <span class=\"pl-k\">**</span>kwargs)\n   <span class=\"pl-c1\">1044</span>     logging.info(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Done calling model_fn.<span class=\"pl-pds\">'</span></span>)\n   <span class=\"pl-c1\">1045</span> \n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>contrib<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>replicate_model_fn.py <span class=\"pl-k\">in</span> replicated_model_fn(features, labels, mode, params, config)\n    <span class=\"pl-c1\">238</span>         <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config,\n    <span class=\"pl-c1\">239</span>         <span class=\"pl-v\">devices</span><span class=\"pl-k\">=</span>devices,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">240</span>         <span class=\"pl-v\">local_ps_devices</span><span class=\"pl-k\">=</span>ps_devices)\n    <span class=\"pl-c1\">241</span> \n    <span class=\"pl-c1\">242</span>     <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> model_fn_lib.ModeKeys.<span class=\"pl-c1\">TRAIN</span>:\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>contrib<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>replicate_model_fn.py <span class=\"pl-k\">in</span> _get_loss_towers(model_fn, mode, features, labels, params, config, devices, local_ps_devices, loss_reduction, name_scope_pattern)\n    <span class=\"pl-c1\">522</span>   tower_specs <span class=\"pl-k\">=</span> []\n    <span class=\"pl-c1\">523</span> \n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">524</span>   model_fn_args <span class=\"pl-k\">=</span> util.fn_args(model_fn)\n    <span class=\"pl-c1\">525</span>   optional_params <span class=\"pl-k\">=</span> {}\n    <span class=\"pl-c1\">526</span>   <span class=\"pl-k\">if</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>params<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">in</span> model_fn_args:\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>estimator<span class=\"pl-k\">/</span>util.py <span class=\"pl-k\">in</span> fn_args(fn)\n     <span class=\"pl-c1\">60</span>     args <span class=\"pl-k\">=</span> tf_inspect.getfullargspec(fn).args\n     <span class=\"pl-c1\">61</span>     <span class=\"pl-k\">if</span> _is_bounded_method(fn):\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">62</span>       args.remove(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>self<span class=\"pl-pds\">'</span></span>)\n     <span class=\"pl-c1\">63</span>   <span class=\"pl-k\">return</span> <span class=\"pl-c1\">tuple</span>(args)\n     <span class=\"pl-c1\">64</span> \n\n<span class=\"pl-c1\">ValueError</span>: <span class=\"pl-c1\">list</span>.remove(x): x <span class=\"pl-k\">not</span> <span class=\"pl-k\">in</span> <span class=\"pl-c1\">list</span></pre></div>\n<p>Any idea where the error happens?</p>", "body_text": "Hello,\nThis is my first time using Estimator API. I'm trying to use Estimator to train a DQN on multiple GPUs. Here is my code:\nimport tensorflow as tf\nimport numpy as np\nfrom constants import *\n\nclass Net:\n    def __init__(self, n_state, n_action, dueling=False, grad_clip=10, double_q=True):\n        self.n_state = n_state\n        self.n_action = n_action\n        self.dueling = dueling\n        self.grad_clip = grad_clip\n        self.double_q = double_q\n\n        params ={'lr':LR_NN,\n                 'eps':1e-3,\n                 'gamma':DISCOUNT_FACTOR,\n                 'double_q':double_q,\n                 'grad_clip':grad_clip,\n                 'n_action':n_action}\n\n        self.model = tf.estimator.Estimator(model_fn=tf.contrib.estimator.replicate_model_fn(self._model_fn), params=params)\n\n    def _inference(self, state_in, scope_name, reuse=None):\n        with tf.variable_scope(scope_name, reuse=reuse):\n            h1 = tf.layers.conv2d(state_in, CONV1_SIZE, CONV1_KERNEL, CONV1_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))\n            h2 = tf.layers.conv2d(h1, CONV2_SIZE, CONV2_KERNEL, CONV2_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))\n            h3 = tf.layers.conv2d(h2, CONV3_SIZE, CONV3_KERNEL, CONV3_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))\n            h4 = tf.layers.dense(tf.layers.flatten(h3), 256, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))\n            if self.dueling:\n                V = tf.layers.dense(h4, 1)\n                A = tf.layers.dense(h4, self.n_action)\n                Q = A + V - tf.reduce_mean(A, 1, keepdims=True)\n            else:\n                Q = tf.layers.dense(h4, self.n_action)\n        return Q\n\n    def _model_fn(inp, mode, params):\n        s = inp['s']\n        a = inp['a']\n        r = inp['r']\n        ns = inp['ns']\n        d = inp['d']\n\n        online_Q = self._inference(s, 'online')\n        target_Q = self._inference(ns, 'target')\n        next_online_Q = self._inference(ns, 'online', reuse=True)\n\n        if params['double_q']:\n            best = tf.reduce_sum(target_Q*tf.one_hot(tf.argmax(next_online_Q, axis=1), params['n_action']), axis=1, keepdims=True)\n        else:\n            best = tf.reduce_max(target_Q, axis=1, keepdims=True)\n        target = r + (1.0 - d)*params['gamma']*tf.stop_gradient(best)\n        pred = tf.reduce_sum(online_Q*tf.one_hot(a, params['n_action']), axis=1, keepdims=True)\n\n        loss = tf.losses.huber_loss(target, pred, reduction=tf.losses.Reduction.MEAN)\n\n        optimizer = tf.train.AdamOptimizer(params['lr'], epsilon=params['eps'])\n        optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n\n        if mode == tf.estimator.ModeKeys.TRAIN:\n            if params['grad_clip'] is not None:\n                grads = optimizer.compute_gradients(loss)\n                for i, (grad, var) in enumerate(grads):\n                    if grad is not None:\n                        grads[i] = (tf.clip_by_norm(grad, params['grad_clip']), var)\n                optimizer_op = optimizer.apply_gradients(grads)\n            else:\n                optimizer_op = optimizer.minimize(loss)\n\n            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=optimizer_op)\n        elif mode == tf.estimator.ModeKeys.PREDICT:\n            pred_action = tf.argmax(online_Q)\n            return tf.estimator.EstimatorSpec(mode=mode, predictions=pred_action)\n\nif __name__ == '__main__':\n    sess = tf.InteractiveSession()\n    nn = Net(n_state=(84,84,4), n_action=4)\n    sess.run(tf.global_variables_initializer())\n    s = np.random.rand(32, 84, 84, 4)\n    ns = np.random.rand(32, 84, 84, 4)\n    a = np.random.randint(4, size=32)\n    r = np.random.randint(30, size=32).reshape(-1,1)\n    d = np.random.randint(2, size=32).reshape(-1,1)\n    inp = {}\n    inp['s'] = np.array(s)\n    inp['a'] = np.array(a)\n    inp['r'] = np.array(r)\n    inp['ns'] = np.array(ns)\n    inp['d'] = np.array(d)\n\n    input_f = tf.estimator.inputs.numpy_input_fn(x=inp, batch_size=32, shuffle=False)\n    nn.model.train(input_fn=input_f, steps=1)\nThe output/error when running the last (final) line:\nINFO:tensorflow:Calling model_fn.\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-7-1a67111ae305> in <module>()\n----> 1 nn.model.train(input_fn=input_f, steps=1)\n\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    361 \n    362       saving_listeners = _check_listeners_type(saving_listeners)\n--> 363       loss = self._train_model(input_fn, hooks, saving_listeners)\n    364       logging.info('Loss for final step: %s.', loss)\n    365       return self\n\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1053       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1054     else:\n-> 1055       return self._train_model_default(input_fn, hooks, saving_listeners)\n   1056 \n   1057   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\n   1066       worker_hooks.extend(input_hooks)\n   1067       estimator_spec = self._call_model_fn(\n-> 1068           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n   1069       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n   1070                                              hooks, global_step_tensor,\n\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\n   1041 \n   1042     logging.info('Calling model_fn.')\n-> 1043     model_fn_results = self._model_fn(features=features, **kwargs)\n   1044     logging.info('Done calling model_fn.')\n   1045 \n\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py in replicated_model_fn(features, labels, mode, params, config)\n    238         config=config,\n    239         devices=devices,\n--> 240         local_ps_devices=ps_devices)\n    241 \n    242     if mode == model_fn_lib.ModeKeys.TRAIN:\n\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py in _get_loss_towers(model_fn, mode, features, labels, params, config, devices, local_ps_devices, loss_reduction, name_scope_pattern)\n    522   tower_specs = []\n    523 \n--> 524   model_fn_args = util.fn_args(model_fn)\n    525   optional_params = {}\n    526   if 'params' in model_fn_args:\n\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/util.py in fn_args(fn)\n     60     args = tf_inspect.getfullargspec(fn).args\n     61     if _is_bounded_method(fn):\n---> 62       args.remove('self')\n     63   return tuple(args)\n     64 \n\nValueError: list.remove(x): x not in list\nAny idea where the error happens?", "body": "Hello,\r\nThis is my first time using Estimator API. I'm trying to use Estimator to train a DQN on multiple GPUs. Here is my code:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom constants import *\r\n\r\nclass Net:\r\n    def __init__(self, n_state, n_action, dueling=False, grad_clip=10, double_q=True):\r\n        self.n_state = n_state\r\n        self.n_action = n_action\r\n        self.dueling = dueling\r\n        self.grad_clip = grad_clip\r\n        self.double_q = double_q\r\n\r\n        params ={'lr':LR_NN,\r\n                 'eps':1e-3,\r\n                 'gamma':DISCOUNT_FACTOR,\r\n                 'double_q':double_q,\r\n                 'grad_clip':grad_clip,\r\n                 'n_action':n_action}\r\n\r\n        self.model = tf.estimator.Estimator(model_fn=tf.contrib.estimator.replicate_model_fn(self._model_fn), params=params)\r\n\r\n    def _inference(self, state_in, scope_name, reuse=None):\r\n        with tf.variable_scope(scope_name, reuse=reuse):\r\n            h1 = tf.layers.conv2d(state_in, CONV1_SIZE, CONV1_KERNEL, CONV1_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))\r\n            h2 = tf.layers.conv2d(h1, CONV2_SIZE, CONV2_KERNEL, CONV2_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))\r\n            h3 = tf.layers.conv2d(h2, CONV3_SIZE, CONV3_KERNEL, CONV3_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))\r\n            h4 = tf.layers.dense(tf.layers.flatten(h3), 256, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))\r\n            if self.dueling:\r\n                V = tf.layers.dense(h4, 1)\r\n                A = tf.layers.dense(h4, self.n_action)\r\n                Q = A + V - tf.reduce_mean(A, 1, keepdims=True)\r\n            else:\r\n                Q = tf.layers.dense(h4, self.n_action)\r\n        return Q\r\n\r\n    def _model_fn(inp, mode, params):\r\n        s = inp['s']\r\n        a = inp['a']\r\n        r = inp['r']\r\n        ns = inp['ns']\r\n        d = inp['d']\r\n\r\n        online_Q = self._inference(s, 'online')\r\n        target_Q = self._inference(ns, 'target')\r\n        next_online_Q = self._inference(ns, 'online', reuse=True)\r\n\r\n        if params['double_q']:\r\n            best = tf.reduce_sum(target_Q*tf.one_hot(tf.argmax(next_online_Q, axis=1), params['n_action']), axis=1, keepdims=True)\r\n        else:\r\n            best = tf.reduce_max(target_Q, axis=1, keepdims=True)\r\n        target = r + (1.0 - d)*params['gamma']*tf.stop_gradient(best)\r\n        pred = tf.reduce_sum(online_Q*tf.one_hot(a, params['n_action']), axis=1, keepdims=True)\r\n\r\n        loss = tf.losses.huber_loss(target, pred, reduction=tf.losses.Reduction.MEAN)\r\n\r\n        optimizer = tf.train.AdamOptimizer(params['lr'], epsilon=params['eps'])\r\n        optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\r\n\r\n        if mode == tf.estimator.ModeKeys.TRAIN:\r\n            if params['grad_clip'] is not None:\r\n                grads = optimizer.compute_gradients(loss)\r\n                for i, (grad, var) in enumerate(grads):\r\n                    if grad is not None:\r\n                        grads[i] = (tf.clip_by_norm(grad, params['grad_clip']), var)\r\n                optimizer_op = optimizer.apply_gradients(grads)\r\n            else:\r\n                optimizer_op = optimizer.minimize(loss)\r\n\r\n            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=optimizer_op)\r\n        elif mode == tf.estimator.ModeKeys.PREDICT:\r\n            pred_action = tf.argmax(online_Q)\r\n            return tf.estimator.EstimatorSpec(mode=mode, predictions=pred_action)\r\n\r\nif __name__ == '__main__':\r\n    sess = tf.InteractiveSession()\r\n    nn = Net(n_state=(84,84,4), n_action=4)\r\n    sess.run(tf.global_variables_initializer())\r\n    s = np.random.rand(32, 84, 84, 4)\r\n    ns = np.random.rand(32, 84, 84, 4)\r\n    a = np.random.randint(4, size=32)\r\n    r = np.random.randint(30, size=32).reshape(-1,1)\r\n    d = np.random.randint(2, size=32).reshape(-1,1)\r\n    inp = {}\r\n    inp['s'] = np.array(s)\r\n    inp['a'] = np.array(a)\r\n    inp['r'] = np.array(r)\r\n    inp['ns'] = np.array(ns)\r\n    inp['d'] = np.array(d)\r\n\r\n    input_f = tf.estimator.inputs.numpy_input_fn(x=inp, batch_size=32, shuffle=False)\r\n    nn.model.train(input_fn=input_f, steps=1)\r\n```\r\n\r\nThe output/error when running the last (final) line:\r\n```python\r\nINFO:tensorflow:Calling model_fn.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-7-1a67111ae305> in <module>()\r\n----> 1 nn.model.train(input_fn=input_f, steps=1)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    361 \r\n    362       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 363       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    364       logging.info('Loss for final step: %s.', loss)\r\n    365       return self\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1053       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1054     else:\r\n-> 1055       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n   1056 \r\n   1057   def _train_model_default(self, input_fn, hooks, saving_listeners):\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\r\n   1066       worker_hooks.extend(input_hooks)\r\n   1067       estimator_spec = self._call_model_fn(\r\n-> 1068           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n   1069       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\r\n   1070                                              hooks, global_step_tensor,\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\r\n   1041 \r\n   1042     logging.info('Calling model_fn.')\r\n-> 1043     model_fn_results = self._model_fn(features=features, **kwargs)\r\n   1044     logging.info('Done calling model_fn.')\r\n   1045 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py in replicated_model_fn(features, labels, mode, params, config)\r\n    238         config=config,\r\n    239         devices=devices,\r\n--> 240         local_ps_devices=ps_devices)\r\n    241 \r\n    242     if mode == model_fn_lib.ModeKeys.TRAIN:\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py in _get_loss_towers(model_fn, mode, features, labels, params, config, devices, local_ps_devices, loss_reduction, name_scope_pattern)\r\n    522   tower_specs = []\r\n    523 \r\n--> 524   model_fn_args = util.fn_args(model_fn)\r\n    525   optional_params = {}\r\n    526   if 'params' in model_fn_args:\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/util.py in fn_args(fn)\r\n     60     args = tf_inspect.getfullargspec(fn).args\r\n     61     if _is_bounded_method(fn):\r\n---> 62       args.remove('self')\r\n     63   return tuple(args)\r\n     64 \r\n\r\nValueError: list.remove(x): x not in list\r\n```\r\n\r\nAny idea where the error happens?"}