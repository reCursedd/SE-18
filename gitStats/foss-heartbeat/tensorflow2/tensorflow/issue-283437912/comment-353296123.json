{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/353296123", "html_url": "https://github.com/tensorflow/tensorflow/issues/15497#issuecomment-353296123", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15497", "id": 353296123, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MzI5NjEyMw==", "user": {"login": "selcouthlyBlue", "id": 13268675, "node_id": "MDQ6VXNlcjEzMjY4Njc1", "avatar_url": "https://avatars2.githubusercontent.com/u/13268675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/selcouthlyBlue", "html_url": "https://github.com/selcouthlyBlue", "followers_url": "https://api.github.com/users/selcouthlyBlue/followers", "following_url": "https://api.github.com/users/selcouthlyBlue/following{/other_user}", "gists_url": "https://api.github.com/users/selcouthlyBlue/gists{/gist_id}", "starred_url": "https://api.github.com/users/selcouthlyBlue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/selcouthlyBlue/subscriptions", "organizations_url": "https://api.github.com/users/selcouthlyBlue/orgs", "repos_url": "https://api.github.com/users/selcouthlyBlue/repos", "events_url": "https://api.github.com/users/selcouthlyBlue/events{/privacy}", "received_events_url": "https://api.github.com/users/selcouthlyBlue/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-21T09:01:56Z", "updated_at": "2017-12-21T10:08:45Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Until I know what <code>num_frequency_blocks</code> is for in contrib.rnn.GridLSTMCell, I'm going to use tf.contrib.grid_rnn. I'm doing a learning test on tf.contrib.grid_rnn 's grid_rnn_cell that involves what the core rnn accepts using these cells. Here's what I got so far:</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib.grid_rnn.python.ops import grid_rnn_cell\n\n\ndef reshape_to_rnn_dims(tensor, shape):\n    reshaped_tensor = tf.reshape(tensor, shape)\n    split_tensor = tf.split(reshaped_tensor, shape[1], 1)\n    return split_tensor\n\n\nclass GridLSTMCellTest(tf.test.TestCase):\n    def setUp(self):\n        self.num_features = 1\n        self.time_steps = 1\n        self.batch_size = 1\n        tf.reset_default_graph()\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\n        self.cell = grid_rnn_cell.Grid1LSTMCell(num_units=8)\n\n    def test_simple_grid_rnn(self):\n        self.input_layer = reshape_to_rnn_dims(self.input_layer, [-1, self.num_features * self.time_steps])\n        tf.nn.static_rnn(self.cell, self.input_layer, dtype=tf.float32)\n\n    def test_dynamic_grid_rnn(self):\n        tf.nn.dynamic_rnn(self.cell, self.input_layer, dtype=tf.float32)\n\n\nclass BidirectionalGridRNNCellTest(tf.test.TestCase):\n    def setUp(self):\n        self.num_features = 1\n        self.time_steps = 1\n        self.batch_size = 1\n        tf.reset_default_graph()\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\n        self.cell_fw = grid_rnn_cell.Grid1LSTMCell(num_units=8)\n        self.cell_bw = grid_rnn_cell.Grid1LSTMCell(num_units=8)\n\n    def test_simple_bidirectional_grid_rnn(self):\n        self.input_layer = reshape_to_rnn_dims(self.input_layer, [-1, self.num_features * self.time_steps])\n        tf.nn.static_bidirectional_rnn(self.cell_fw, self.cell_fw, self.input_layer, dtype=tf.float32)\n\n    def test_bidirectional_dynamic_grid_rnn(self):\n        tf.nn.bidirectional_dynamic_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)\n\n\nif __name__ == '__main__':\n    tf.test.main()\n\n</code></pre>", "body_text": "Until I know what num_frequency_blocks is for in contrib.rnn.GridLSTMCell, I'm going to use tf.contrib.grid_rnn. I'm doing a learning test on tf.contrib.grid_rnn 's grid_rnn_cell that involves what the core rnn accepts using these cells. Here's what I got so far:\nimport tensorflow as tf\nfrom tensorflow.contrib.grid_rnn.python.ops import grid_rnn_cell\n\n\ndef reshape_to_rnn_dims(tensor, shape):\n    reshaped_tensor = tf.reshape(tensor, shape)\n    split_tensor = tf.split(reshaped_tensor, shape[1], 1)\n    return split_tensor\n\n\nclass GridLSTMCellTest(tf.test.TestCase):\n    def setUp(self):\n        self.num_features = 1\n        self.time_steps = 1\n        self.batch_size = 1\n        tf.reset_default_graph()\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\n        self.cell = grid_rnn_cell.Grid1LSTMCell(num_units=8)\n\n    def test_simple_grid_rnn(self):\n        self.input_layer = reshape_to_rnn_dims(self.input_layer, [-1, self.num_features * self.time_steps])\n        tf.nn.static_rnn(self.cell, self.input_layer, dtype=tf.float32)\n\n    def test_dynamic_grid_rnn(self):\n        tf.nn.dynamic_rnn(self.cell, self.input_layer, dtype=tf.float32)\n\n\nclass BidirectionalGridRNNCellTest(tf.test.TestCase):\n    def setUp(self):\n        self.num_features = 1\n        self.time_steps = 1\n        self.batch_size = 1\n        tf.reset_default_graph()\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\n        self.cell_fw = grid_rnn_cell.Grid1LSTMCell(num_units=8)\n        self.cell_bw = grid_rnn_cell.Grid1LSTMCell(num_units=8)\n\n    def test_simple_bidirectional_grid_rnn(self):\n        self.input_layer = reshape_to_rnn_dims(self.input_layer, [-1, self.num_features * self.time_steps])\n        tf.nn.static_bidirectional_rnn(self.cell_fw, self.cell_fw, self.input_layer, dtype=tf.float32)\n\n    def test_bidirectional_dynamic_grid_rnn(self):\n        tf.nn.bidirectional_dynamic_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)\n\n\nif __name__ == '__main__':\n    tf.test.main()", "body": "Until I know what `num_frequency_blocks` is for in contrib.rnn.GridLSTMCell, I'm going to use tf.contrib.grid_rnn. I'm doing a learning test on tf.contrib.grid_rnn 's grid_rnn_cell that involves what the core rnn accepts using these cells. Here's what I got so far:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.grid_rnn.python.ops import grid_rnn_cell\r\n\r\n\r\ndef reshape_to_rnn_dims(tensor, shape):\r\n    reshaped_tensor = tf.reshape(tensor, shape)\r\n    split_tensor = tf.split(reshaped_tensor, shape[1], 1)\r\n    return split_tensor\r\n\r\n\r\nclass GridLSTMCellTest(tf.test.TestCase):\r\n    def setUp(self):\r\n        self.num_features = 1\r\n        self.time_steps = 1\r\n        self.batch_size = 1\r\n        tf.reset_default_graph()\r\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\r\n        self.cell = grid_rnn_cell.Grid1LSTMCell(num_units=8)\r\n\r\n    def test_simple_grid_rnn(self):\r\n        self.input_layer = reshape_to_rnn_dims(self.input_layer, [-1, self.num_features * self.time_steps])\r\n        tf.nn.static_rnn(self.cell, self.input_layer, dtype=tf.float32)\r\n\r\n    def test_dynamic_grid_rnn(self):\r\n        tf.nn.dynamic_rnn(self.cell, self.input_layer, dtype=tf.float32)\r\n\r\n\r\nclass BidirectionalGridRNNCellTest(tf.test.TestCase):\r\n    def setUp(self):\r\n        self.num_features = 1\r\n        self.time_steps = 1\r\n        self.batch_size = 1\r\n        tf.reset_default_graph()\r\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\r\n        self.cell_fw = grid_rnn_cell.Grid1LSTMCell(num_units=8)\r\n        self.cell_bw = grid_rnn_cell.Grid1LSTMCell(num_units=8)\r\n\r\n    def test_simple_bidirectional_grid_rnn(self):\r\n        self.input_layer = reshape_to_rnn_dims(self.input_layer, [-1, self.num_features * self.time_steps])\r\n        tf.nn.static_bidirectional_rnn(self.cell_fw, self.cell_fw, self.input_layer, dtype=tf.float32)\r\n\r\n    def test_bidirectional_dynamic_grid_rnn(self):\r\n        tf.nn.bidirectional_dynamic_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.test.main()\r\n\r\n```"}