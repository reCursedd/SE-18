{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18904", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18904/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18904/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18904/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18904", "id": 318089431, "node_id": "MDU6SXNzdWUzMTgwODk0MzE=", "number": 18904, "title": "Relevant fluctuations in activations depending on batch size, at test time", "user": {"login": "noky", "id": 1211827, "node_id": "MDQ6VXNlcjEyMTE4Mjc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1211827?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noky", "html_url": "https://github.com/noky", "followers_url": "https://api.github.com/users/noky/followers", "following_url": "https://api.github.com/users/noky/following{/other_user}", "gists_url": "https://api.github.com/users/noky/gists{/gist_id}", "starred_url": "https://api.github.com/users/noky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noky/subscriptions", "organizations_url": "https://api.github.com/users/noky/orgs", "repos_url": "https://api.github.com/users/noky/repos", "events_url": "https://api.github.com/users/noky/events{/privacy}", "received_events_url": "https://api.github.com/users/noky/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-04-26T15:45:15Z", "updated_at": "2018-04-27T09:40:29Z", "closed_at": "2018-04-27T09:40:29Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Y</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.3.0-rc2-20-g0787eee 1.3.0</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX 1080 8GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm using the slim implementation of resnet-v1-50 . The logits seem to change depending on the test batch_size used.</p>\n<p>I would expect some instability due to parallelism mechanisms on GPU, but I found out this behavior after the model's accuracy changed when batch_size changed. Thus, some fluctuations might be so big that they change predictions, which is not irrelevant.</p>\n<p>If this is not a bug, is there a way to prevent this / what is the recommended way to evaluate our models?</p>\n<h3>Source code / logs</h3>\n<p>I attach source code that tests this scenario. It was tested on tf version 1.3 .<br>\nto run: python test_batch_size.py --batch_size=1</p>\n<p>It prints the logits for the first frame of the batch. It saves the frame so you can be sure it's the very same frame. It loads all the weights from a checkpoint, and batchnorm is disabled with is_training=False.</p>\n<p>please vary the batch_size argument, and see that the activations change.<br>\n<a href=\"https://www.dropbox.com/s/ns9j84t02zifdaa/test_batch_size.zip?dl=0\" rel=\"nofollow\">https://www.dropbox.com/s/ns9j84t02zifdaa/test_batch_size.zip?dl=0</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0\nPython version: 3.5.2\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 8.0\nGPU model and memory: GeForce GTX 1080 8GB\nExact command to reproduce:\n\nDescribe the problem\nI'm using the slim implementation of resnet-v1-50 . The logits seem to change depending on the test batch_size used.\nI would expect some instability due to parallelism mechanisms on GPU, but I found out this behavior after the model's accuracy changed when batch_size changed. Thus, some fluctuations might be so big that they change predictions, which is not irrelevant.\nIf this is not a bug, is there a way to prevent this / what is the recommended way to evaluate our models?\nSource code / logs\nI attach source code that tests this scenario. It was tested on tf version 1.3 .\nto run: python test_batch_size.py --batch_size=1\nIt prints the logits for the first frame of the batch. It saves the frame so you can be sure it's the very same frame. It loads all the weights from a checkpoint, and batchnorm is disabled with is_training=False.\nplease vary the batch_size argument, and see that the activations change.\nhttps://www.dropbox.com/s/ns9j84t02zifdaa/test_batch_size.zip?dl=0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: \r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GeForce GTX 1080 8GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm using the slim implementation of resnet-v1-50 . The logits seem to change depending on the test batch_size used.\r\n\r\nI would expect some instability due to parallelism mechanisms on GPU, but I found out this behavior after the model's accuracy changed when batch_size changed. Thus, some fluctuations might be so big that they change predictions, which is not irrelevant.\r\n\r\nIf this is not a bug, is there a way to prevent this / what is the recommended way to evaluate our models?\r\n\r\n### Source code / logs\r\nI attach source code that tests this scenario. It was tested on tf version 1.3 .\r\nto run: python test_batch_size.py --batch_size=1\r\n\r\nIt prints the logits for the first frame of the batch. It saves the frame so you can be sure it's the very same frame. It loads all the weights from a checkpoint, and batchnorm is disabled with is_training=False.\r\n\r\nplease vary the batch_size argument, and see that the activations change.\r\nhttps://www.dropbox.com/s/ns9j84t02zifdaa/test_batch_size.zip?dl=0"}