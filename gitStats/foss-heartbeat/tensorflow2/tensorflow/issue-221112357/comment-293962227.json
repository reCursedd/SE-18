{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/293962227", "html_url": "https://github.com/tensorflow/tensorflow/issues/9150#issuecomment-293962227", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9150", "id": 293962227, "node_id": "MDEyOklzc3VlQ29tbWVudDI5Mzk2MjIyNw==", "user": {"login": "eaplatanios", "id": 1294940, "node_id": "MDQ6VXNlcjEyOTQ5NDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1294940?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eaplatanios", "html_url": "https://github.com/eaplatanios", "followers_url": "https://api.github.com/users/eaplatanios/followers", "following_url": "https://api.github.com/users/eaplatanios/following{/other_user}", "gists_url": "https://api.github.com/users/eaplatanios/gists{/gist_id}", "starred_url": "https://api.github.com/users/eaplatanios/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eaplatanios/subscriptions", "organizations_url": "https://api.github.com/users/eaplatanios/orgs", "repos_url": "https://api.github.com/users/eaplatanios/repos", "events_url": "https://api.github.com/users/eaplatanios/events{/privacy}", "received_events_url": "https://api.github.com/users/eaplatanios/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-13T17:05:52Z", "updated_at": "2017-04-13T17:06:26Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5061\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alextp\">@alextp</a> As long as I create a DirectByteBuffer on the Scala side, the GC will be able to deallocate its underlying buffer. Furthermore, as long as a reference to that DirectByteBuffer exists on the Scala side, the GC will not deallocate it and the C side will be able to use it (e.g., when you call session.run). So I think there would be no memory leakage since the GC will take care of that buffer. The only occasion where there might be an issue if the GC deallocates it and then the C library tries to use it. This should not happen though unless the C library tries to reuse the tensor you pass in session.run, after that function returns. Does that sound reasonable?</p>\n<p>It only means that we leave memory management to the GC on the Scala side, rather than to the TensorFlow native library.</p>", "body_text": "@alextp As long as I create a DirectByteBuffer on the Scala side, the GC will be able to deallocate its underlying buffer. Furthermore, as long as a reference to that DirectByteBuffer exists on the Scala side, the GC will not deallocate it and the C side will be able to use it (e.g., when you call session.run). So I think there would be no memory leakage since the GC will take care of that buffer. The only occasion where there might be an issue if the GC deallocates it and then the C library tries to use it. This should not happen though unless the C library tries to reuse the tensor you pass in session.run, after that function returns. Does that sound reasonable?\nIt only means that we leave memory management to the GC on the Scala side, rather than to the TensorFlow native library.", "body": "@alextp As long as I create a DirectByteBuffer on the Scala side, the GC will be able to deallocate its underlying buffer. Furthermore, as long as a reference to that DirectByteBuffer exists on the Scala side, the GC will not deallocate it and the C side will be able to use it (e.g., when you call session.run). So I think there would be no memory leakage since the GC will take care of that buffer. The only occasion where there might be an issue if the GC deallocates it and then the C library tries to use it. This should not happen though unless the C library tries to reuse the tensor you pass in session.run, after that function returns. Does that sound reasonable?\r\n\r\nIt only means that we leave memory management to the GC on the Scala side, rather than to the TensorFlow native library."}