{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294976456", "html_url": "https://github.com/tensorflow/tensorflow/issues/9150#issuecomment-294976456", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9150", "id": 294976456, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDk3NjQ1Ng==", "user": {"login": "eaplatanios", "id": 1294940, "node_id": "MDQ6VXNlcjEyOTQ5NDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1294940?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eaplatanios", "html_url": "https://github.com/eaplatanios", "followers_url": "https://api.github.com/users/eaplatanios/followers", "following_url": "https://api.github.com/users/eaplatanios/following{/other_user}", "gists_url": "https://api.github.com/users/eaplatanios/gists{/gist_id}", "starred_url": "https://api.github.com/users/eaplatanios/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eaplatanios/subscriptions", "organizations_url": "https://api.github.com/users/eaplatanios/orgs", "repos_url": "https://api.github.com/users/eaplatanios/repos", "events_url": "https://api.github.com/users/eaplatanios/events{/privacy}", "received_events_url": "https://api.github.com/users/eaplatanios/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-18T20:45:24Z", "updated_at": "2017-04-18T20:45:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have worked out all the core parts except for the fetching tensors from sessions. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5061\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alextp\">@alextp</a> you mentioned that if I can trigger unrefing of the scala object when TF calls the destructor and trigger unrefing of the Tensor when scala is done with the byte buffer all will be well I think. I have managed the first part, but I have some confusion regarding the second. I currently have no way of unrefing the TF tensor when Scala is done with the byte buffer, but I'm not sure if that's necessary. The C API documentation for session.run says this:</p>\n<blockquote>\n<p>On success, the tensors corresponding to outputs[0,noutputs-1] are placed in<br>\noutput_values[]. Ownership of the elements of output_values[] is transferred<br>\nto the caller, which must eventually call TF_DeleteTensor on them.</p>\n</blockquote>\n<p>Does this mean that the TensorFlow native library is guaranteed to not use that tensor again? Because in that case, I could return a pointer to the underlying byte buffer, along with it's size and let the garbage collector delete the byte buffer when it's done using it. Is there anything else that TF_DeleteTensor deletes other than that byte buffer? And if so, could I delete that data manually without deleting the buffer?</p>\n<p>Looking at the Python API implementation, I think this is the relevant piece of code:</p>\n<div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-c\"><span class=\"pl-c\">//</span> 4. We now own the fetched tensors, so set up a safe container to</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">//</span> delete them when we exit this scope.</span>\n  Safe_TF_TensorVector tf_outputs_safe;\n  <span class=\"pl-k\">for</span> (<span class=\"pl-k\">const</span> <span class=\"pl-k\">auto</span>&amp; output : outputs) {\n    tf_outputs_safe.<span class=\"pl-c1\">emplace_back</span>(<span class=\"pl-c1\">make_safe</span>(output));\n  }\n\n  <span class=\"pl-c\"><span class=\"pl-c\">//</span> 5. Convert the fetched tensors into numpy ndarrays. Store them in a safe</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">//</span> container so that we do not leak</span>\n  Safe_PyObjectVector py_outputs_safe;\n  <span class=\"pl-k\">for</span> (<span class=\"pl-c1\">size_t</span> i = <span class=\"pl-c1\">0</span>; i &lt; output_names.size(); ++i) {\n    PyObject* py_array;\n    s = <span class=\"pl-c1\">TF_Tensor_to_PyObject</span>(<span class=\"pl-c1\">std::move</span>(tf_outputs_safe[i]), &amp;py_array);\n    <span class=\"pl-k\">if</span> (!s.<span class=\"pl-c1\">ok</span>()) {\n      <span class=\"pl-c1\">Set_TF_Status_from_Status</span>(out_status, s);\n      <span class=\"pl-k\">return</span>;\n    }\n    py_outputs_safe.<span class=\"pl-c1\">emplace_back</span>(<span class=\"pl-c1\">make_safe</span>(py_array));\n  }\n\n  <span class=\"pl-c\"><span class=\"pl-c\">//</span> 6. If we reach this point, we have successfully built a list of objects</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">//</span> so we can release them from the safe container.</span>\n  <span class=\"pl-k\">for</span> (<span class=\"pl-k\">auto</span>&amp; output : py_outputs_safe) {\n    out_values-&gt;<span class=\"pl-c1\">push_back</span>(output.<span class=\"pl-c1\">release</span>());\n  }</pre></div>\n<p>and the <code>make_safe</code> function creates a unique_ptr that calls TF_DeleteTensor when unreferenced. My question is whether there is a way to avoid that call entirely and let the garbage collector deallocate the underlying byte array when necessary.</p>\n<p>I hope this makes sense.</p>", "body_text": "I have worked out all the core parts except for the fetching tensors from sessions. @alextp you mentioned that if I can trigger unrefing of the scala object when TF calls the destructor and trigger unrefing of the Tensor when scala is done with the byte buffer all will be well I think. I have managed the first part, but I have some confusion regarding the second. I currently have no way of unrefing the TF tensor when Scala is done with the byte buffer, but I'm not sure if that's necessary. The C API documentation for session.run says this:\n\nOn success, the tensors corresponding to outputs[0,noutputs-1] are placed in\noutput_values[]. Ownership of the elements of output_values[] is transferred\nto the caller, which must eventually call TF_DeleteTensor on them.\n\nDoes this mean that the TensorFlow native library is guaranteed to not use that tensor again? Because in that case, I could return a pointer to the underlying byte buffer, along with it's size and let the garbage collector delete the byte buffer when it's done using it. Is there anything else that TF_DeleteTensor deletes other than that byte buffer? And if so, could I delete that data manually without deleting the buffer?\nLooking at the Python API implementation, I think this is the relevant piece of code:\n  // 4. We now own the fetched tensors, so set up a safe container to\n  // delete them when we exit this scope.\n  Safe_TF_TensorVector tf_outputs_safe;\n  for (const auto& output : outputs) {\n    tf_outputs_safe.emplace_back(make_safe(output));\n  }\n\n  // 5. Convert the fetched tensors into numpy ndarrays. Store them in a safe\n  // container so that we do not leak\n  Safe_PyObjectVector py_outputs_safe;\n  for (size_t i = 0; i < output_names.size(); ++i) {\n    PyObject* py_array;\n    s = TF_Tensor_to_PyObject(std::move(tf_outputs_safe[i]), &py_array);\n    if (!s.ok()) {\n      Set_TF_Status_from_Status(out_status, s);\n      return;\n    }\n    py_outputs_safe.emplace_back(make_safe(py_array));\n  }\n\n  // 6. If we reach this point, we have successfully built a list of objects\n  // so we can release them from the safe container.\n  for (auto& output : py_outputs_safe) {\n    out_values->push_back(output.release());\n  }\nand the make_safe function creates a unique_ptr that calls TF_DeleteTensor when unreferenced. My question is whether there is a way to avoid that call entirely and let the garbage collector deallocate the underlying byte array when necessary.\nI hope this makes sense.", "body": "I have worked out all the core parts except for the fetching tensors from sessions. @alextp you mentioned that if I can trigger unrefing of the scala object when TF calls the destructor and trigger unrefing of the Tensor when scala is done with the byte buffer all will be well I think. I have managed the first part, but I have some confusion regarding the second. I currently have no way of unrefing the TF tensor when Scala is done with the byte buffer, but I'm not sure if that's necessary. The C API documentation for session.run says this:\r\n\r\n> On success, the tensors corresponding to outputs[0,noutputs-1] are placed in\r\n> output_values[]. Ownership of the elements of output_values[] is transferred\r\n> to the caller, which must eventually call TF_DeleteTensor on them.\r\n\r\nDoes this mean that the TensorFlow native library is guaranteed to not use that tensor again? Because in that case, I could return a pointer to the underlying byte buffer, along with it's size and let the garbage collector delete the byte buffer when it's done using it. Is there anything else that TF_DeleteTensor deletes other than that byte buffer? And if so, could I delete that data manually without deleting the buffer?\r\n\r\nLooking at the Python API implementation, I think this is the relevant piece of code:\r\n\r\n```cpp\r\n  // 4. We now own the fetched tensors, so set up a safe container to\r\n  // delete them when we exit this scope.\r\n  Safe_TF_TensorVector tf_outputs_safe;\r\n  for (const auto& output : outputs) {\r\n    tf_outputs_safe.emplace_back(make_safe(output));\r\n  }\r\n\r\n  // 5. Convert the fetched tensors into numpy ndarrays. Store them in a safe\r\n  // container so that we do not leak\r\n  Safe_PyObjectVector py_outputs_safe;\r\n  for (size_t i = 0; i < output_names.size(); ++i) {\r\n    PyObject* py_array;\r\n    s = TF_Tensor_to_PyObject(std::move(tf_outputs_safe[i]), &py_array);\r\n    if (!s.ok()) {\r\n      Set_TF_Status_from_Status(out_status, s);\r\n      return;\r\n    }\r\n    py_outputs_safe.emplace_back(make_safe(py_array));\r\n  }\r\n\r\n  // 6. If we reach this point, we have successfully built a list of objects\r\n  // so we can release them from the safe container.\r\n  for (auto& output : py_outputs_safe) {\r\n    out_values->push_back(output.release());\r\n  }\r\n```\r\n\r\nand the `make_safe` function creates a unique_ptr that calls TF_DeleteTensor when unreferenced. My question is whether there is a way to avoid that call entirely and let the garbage collector deallocate the underlying byte array when necessary.\r\n\r\nI hope this makes sense."}