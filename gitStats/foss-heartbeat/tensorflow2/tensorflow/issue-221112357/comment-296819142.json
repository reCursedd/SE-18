{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/296819142", "html_url": "https://github.com/tensorflow/tensorflow/issues/9150#issuecomment-296819142", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9150", "id": 296819142, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NjgxOTE0Mg==", "user": {"login": "eaplatanios", "id": 1294940, "node_id": "MDQ6VXNlcjEyOTQ5NDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1294940?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eaplatanios", "html_url": "https://github.com/eaplatanios", "followers_url": "https://api.github.com/users/eaplatanios/followers", "following_url": "https://api.github.com/users/eaplatanios/following{/other_user}", "gists_url": "https://api.github.com/users/eaplatanios/gists{/gist_id}", "starred_url": "https://api.github.com/users/eaplatanios/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eaplatanios/subscriptions", "organizations_url": "https://api.github.com/users/eaplatanios/orgs", "repos_url": "https://api.github.com/users/eaplatanios/repos", "events_url": "https://api.github.com/users/eaplatanios/events{/privacy}", "received_events_url": "https://api.github.com/users/eaplatanios/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-24T20:53:30Z", "updated_at": "2017-04-24T20:53:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I see. I hadn't gotten to that part yet. And yes, you're right; the experimental flag has been removed or I simply remembered wrong. In that case, my question is whether I can add gradient computation code on top of the TF_NewWhile/TF_FinishWhile methods. I was planning to replicate the way in which gradients are computed in Python, but is that possible or does that also require adding inputs to ops after constructing them? Thanks!</p>", "body_text": "I see. I hadn't gotten to that part yet. And yes, you're right; the experimental flag has been removed or I simply remembered wrong. In that case, my question is whether I can add gradient computation code on top of the TF_NewWhile/TF_FinishWhile methods. I was planning to replicate the way in which gradients are computed in Python, but is that possible or does that also require adding inputs to ops after constructing them? Thanks!", "body": "I see. I hadn't gotten to that part yet. And yes, you're right; the experimental flag has been removed or I simply remembered wrong. In that case, my question is whether I can add gradient computation code on top of the TF_NewWhile/TF_FinishWhile methods. I was planning to replicate the way in which gradients are computed in Python, but is that possible or does that also require adding inputs to ops after constructing them? Thanks!"}