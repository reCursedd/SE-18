{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/410171380", "html_url": "https://github.com/tensorflow/tensorflow/issues/13164#issuecomment-410171380", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13164", "id": 410171380, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDE3MTM4MA==", "user": {"login": "unrealwill", "id": 11304248, "node_id": "MDQ6VXNlcjExMzA0MjQ4", "avatar_url": "https://avatars0.githubusercontent.com/u/11304248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/unrealwill", "html_url": "https://github.com/unrealwill", "followers_url": "https://api.github.com/users/unrealwill/followers", "following_url": "https://api.github.com/users/unrealwill/following{/other_user}", "gists_url": "https://api.github.com/users/unrealwill/gists{/gist_id}", "starred_url": "https://api.github.com/users/unrealwill/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/unrealwill/subscriptions", "organizations_url": "https://api.github.com/users/unrealwill/orgs", "repos_url": "https://api.github.com/users/unrealwill/repos", "events_url": "https://api.github.com/users/unrealwill/events{/privacy}", "received_events_url": "https://api.github.com/users/unrealwill/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-03T07:36:05Z", "updated_at": "2018-08-03T07:36:34Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1112263\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/facaiy\">@facaiy</a> : Are you sure ? It's quite strange, if so it's error prone, currently I have used two different ugly ways to hack_it to get it to work on GPU.<br>\nI can either<br>\n<code>tf.squeeze( tf.gather_nd( tf.expand_dims(tab,1),tf.expand_dims(ind,1) )</code><br>\nor<br>\n<code>tf.cast( tf.gather( tf.cast(tab,tf.int64 ), ind ), tf.int32 )</code><br>\nIn either way they are both way more efficient, than a copy to cpu, the gather on cpu followed by a copy back to gpu, which happens if you let tensorflow the liberty of choosing where to place ops.</p>", "body_text": "@facaiy : Are you sure ? It's quite strange, if so it's error prone, currently I have used two different ugly ways to hack_it to get it to work on GPU.\nI can either\ntf.squeeze( tf.gather_nd( tf.expand_dims(tab,1),tf.expand_dims(ind,1) )\nor\ntf.cast( tf.gather( tf.cast(tab,tf.int64 ), ind ), tf.int32 )\nIn either way they are both way more efficient, than a copy to cpu, the gather on cpu followed by a copy back to gpu, which happens if you let tensorflow the liberty of choosing where to place ops.", "body": "@facaiy : Are you sure ? It's quite strange, if so it's error prone, currently I have used two different ugly ways to hack_it to get it to work on GPU.\r\nI can either \r\n`tf.squeeze( tf.gather_nd( tf.expand_dims(tab,1),tf.expand_dims(ind,1) )`\r\nor\r\n`tf.cast( tf.gather( tf.cast(tab,tf.int64 ), ind ), tf.int32 )`\r\nIn either way they are both way more efficient, than a copy to cpu, the gather on cpu followed by a copy back to gpu, which happens if you let tensorflow the liberty of choosing where to place ops."}