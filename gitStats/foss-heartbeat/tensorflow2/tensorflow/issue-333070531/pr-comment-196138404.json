{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/196138404", "pull_request_review_id": 129635263, "id": 196138404, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjEzODQwNA==", "diff_hunk": "@@ -0,0 +1,992 @@\n+{\n+  \"nbformat\": 4,\n+  \"nbformat_minor\": 0,\n+  \"metadata\": {\n+    \"colab\": {\n+      \"name\": \"NMT with Attention.ipynb\",\n+      \"version\": \"0.3.2\",\n+      \"views\": {},\n+      \"default_view\": {},\n+      \"provenance\": [\n+        {\n+          \"file_id\": \"1C4fpM7_7IL8ZzF7Gc5abywqQjeQNS2-U\",\n+          \"timestamp\": 1527858391290\n+        },\n+        {\n+          \"file_id\": \"1pExo6aUuw0S6MISFWoinfJv0Ftm9V4qv\",\n+          \"timestamp\": 1527776041613\n+        }\n+      ],\n+      \"private_outputs\": true,\n+      \"collapsed_sections\": []\n+    },\n+    \"kernelspec\": {\n+      \"name\": \"python3\",\n+      \"display_name\": \"Python 3\"\n+    },\n+    \"accelerator\": \"GPU\"\n+  },\n+  \"cells\": [\n+    {\n+      \"metadata\": {\n+        \"id\": \"AOpGoE2T-YXS\",\n+        \"colab_type\": \"text\"\n+      },\n+      \"cell_type\": \"markdown\",\n+      \"source\": [\n+        \"##### Copyright 2018 The TensorFlow Authors.\\n\",\n+        \"\\n\",\n+        \"Licensed under the Apache License, Version 2.0 (the \\\"License\\\").\\n\",\n+        \"\\n\",\n+        \"# Neural Machine Translation with Attention\\n\",\n+        \"\\n\",\n+        \"This notebook trains a sequence to sequence (seq2seq) model for Spanish to English translation using [tf.keras](https://www.tensorflow.org/programmers_guide/keras) and [eager execution](https://www.tensorflow.org/programmers_guide/eager). This is an advanced example for readers with prior background in sequence to sequence models.\\n\",\n+        \"\\n\",\n+        \"Here's an example output you'll see after running this notebook. After training the model, we'll translate the Spanish sentence \\\"\u00bftodavia estan en casa?\\\", and we'll see the output \\\"are you still at home ?\\\". \\n\",\n+        \"\\n\",\n+        \"The translation quality is reasonable for a toy example, but what's even cooler is the attention plot that will be generated:\\n\",\n+        \"\\n\",\n+        \"This shows which parts of the input sentence the model is attending to while translating. \\n\",\n+        \"\\n\",\n+        \"![alt text](https://tensorflow.org/images/spanish-english.png)\\n\",\n+        \"\\n\",\n+        \"\\n\",\n+        \"Ballpark, this example will take approximately 10 mintues to run on a single P100 GPU.\\n\",\n+        \"\\n\",\n+        \"This notebook requires Tensorflow version >= 1.9\"\n+      ]\n+    },\n+    {\n+      \"metadata\": {\n+        \"id\": \"tnxXKDjq3jEL\",\n+        \"colab_type\": \"code\",\n+        \"colab\": {\n+          \"autoexec\": {\n+            \"startup\": false,\n+            \"wait_interval\": 0\n+          }\n+        }\n+      },\n+      \"cell_type\": \"code\",\n+      \"source\": [\n+        \"# Import TensorFlow and enable eager execution\\n\",\n+        \"import tensorflow as tf\\n\",\n+        \"import tensorflow.contrib.eager as tfe\\n\",\n+        \"tf.enable_eager_execution()\\n\",\n+        \"\\n\",\n+        \"# We'll generate plots of attention in order to see which parts of a sentence\\n\",\n+        \"# our model focuses on during translation\\n\",\n+        \"import matplotlib.pyplot as plt\\n\",\n+        \"\\n\",\n+        \"# Scikit-learn includes many handy utilities\\n\",\n+        \"from sklearn.model_selection import train_test_split\\n\",\n+        \"\\n\",\n+        \"import unicodedata\\n\",\n+        \"import re\\n\",\n+        \"import numpy as np\\n\",\n+        \"import os\\n\",\n+        \"import time\"\n+      ],\n+      \"execution_count\": 0,\n+      \"outputs\": []\n+    },\n+    {\n+      \"metadata\": {\n+        \"id\": \"wfodePkj3jEa\",\n+        \"colab_type\": \"text\"\n+      },\n+      \"cell_type\": \"markdown\",\n+      \"source\": [\n+        \"## Download and prepare the dataset\\n\",\n+        \"\\n\",\n+        \"We'll use a dataset helpfully provided by http://www.manythings.org/anki/. This contains language translation pairs, in this format:\\n\",\n+        \"\\n\",\n+        \"```\\n\",\n+        \"May I borrow this book?\\t\u00bfPuedo tomar prestado este libro?\\n\",\n+        \"```\\n\",\n+        \"\\n\",\n+        \"There are a variety of such datasets you can explore. This notebook will download and use the English-Spanish dataset. \\n\",\n+        \"\\n\",\n+        \"We've hosted a copy on Google Cloud for convenience. Alternatively, you can download and use a similar dataset (like English -> German) from http://www.manythings.org/anki/ and use it instead without changing any other code.\\n\",\n+        \"\\n\",\n+        \"After we've downloaded it, here are the steps we'll use to prepare the data:\\n\",\n+        \"\\n\",\n+        \"* Add a start and end token to each sentence\\n\",\n+        \"* Clean the sentences by removing special characters\\n\",\n+        \"* Create a word index and reverse word index (dictionaries mapping from word -> id and id -> word)\\n\",\n+        \"* Pad each sentence to a maximum length\"\n+      ]\n+    },\n+    {\n+      \"metadata\": {\n+        \"id\": \"kRVATYOgJs1b\",\n+        \"colab_type\": \"code\",\n+        \"colab\": {\n+          \"autoexec\": {\n+            \"startup\": false,\n+            \"wait_interval\": 0\n+          }\n+        }\n+      },\n+      \"cell_type\": \"code\",\n+      \"source\": [\n+        \"# Download the file\\n\",\n+        \"path_to_zip = tf.keras.utils.get_file(\\n\",\n+        \"    'spa-eng.zip', origin='http://download.tensorflow.org/data/spa-eng.zip', \\n\",\n+        \"    extract=True)\\n\",\n+        \"\\n\",\n+        \"path_to_file = os.path.dirname(path_to_zip)+\\\"/spa-eng/spa.txt\\\"\"\n+      ],\n+      \"execution_count\": 0,\n+      \"outputs\": []\n+    },\n+    {\n+      \"metadata\": {\n+        \"id\": \"DzIS_cRu3jEb\",\n+        \"colab_type\": \"code\",\n+        \"colab\": {\n+          \"autoexec\": {\n+            \"startup\": false,\n+            \"wait_interval\": 0\n+          }\n+        }\n+      },\n+      \"cell_type\": \"code\",\n+      \"source\": [\n+        \"# Converts the unicode file to ascii\\n\",\n+        \"def unicode_to_ascii(s):\\n\",\n+        \"    return ''.join(c for c in unicodedata.normalize('NFD', s)\\n\",\n+        \"        if unicodedata.category(c) != 'Mn')\"\n+      ],\n+      \"execution_count\": 0,\n+      \"outputs\": []\n+    },\n+    {\n+      \"metadata\": {\n+        \"id\": \"rd0jw-eC3jEh\",\n+        \"colab_type\": \"code\",\n+        \"colab\": {\n+          \"autoexec\": {\n+            \"startup\": false,\n+            \"wait_interval\": 0\n+          }\n+        }\n+      },\n+      \"cell_type\": \"code\",\n+      \"source\": [\n+        \"def preprocess_sentence(w):\\n\",\n+        \"    w = unicode_to_ascii(w.lower().strip())\\n\",\n+        \"    \\n\",\n+        \"    # creating a space between a word and the punctuation following it\\n\",\n+        \"    # eg: \\\"he is a boy.\\\" => \\\"he is a boy .\\\" \\n\",\n+        \"    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\\n\",\n+        \"    w = re.sub(r\\\"([?.!,\u00bf])\\\", r\\\" \\\\1 \\\", w)\\n\",\n+        \"    w = re.sub(r'[\\\" \\\"]+', \\\" \\\", w)\\n\",\n+        \"    \\n\",\n+        \"    # replacing everything with space except (a-z, A-Z, \\\".\\\", \\\"?\\\", \\\"!\\\", \\\",\\\")\\n\",\n+        \"    w = re.sub(r\\\"[^a-zA-Z?.!,\u00bf]+\\\", \\\" \\\", w)\\n\",\n+        \"    \\n\",\n+        \"    w = w.rstrip().strip()\\n\",\n+        \"    \\n\",\n+        \"    # adding a start and an end token to the sentence\\n\",\n+        \"    # so that the model know when to start and stop predicting.\\n\",\n+        \"    w = '<start> ' + w + ' <end>'\\n\",\n+        \"    return w\"\n+      ],\n+      \"execution_count\": 0,\n+      \"outputs\": []\n+    },\n+    {\n+      \"metadata\": {\n+        \"id\": \"OHn4Dct23jEm\",\n+        \"colab_type\": \"code\",\n+        \"colab\": {\n+          \"autoexec\": {\n+            \"startup\": false,\n+            \"wait_interval\": 0\n+          }\n+        }\n+      },\n+      \"cell_type\": \"code\",\n+      \"source\": [\n+        \"# first we remove the pronumciations\\n\",", "path": "tensorflow/contrib/eager/python/examples/nmt_with_attention/NMT_with_Attention.ipynb", "position": null, "original_position": 212, "commit_id": "ce74f7362ee5161976f7c30777b88637be1d02b5", "original_commit_id": "4e0e0750b0cb6ba922503b8e543c378ea0ee937b", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "body": "pronunciations", "created_at": "2018-06-18T16:14:53Z", "updated_at": "2018-06-18T19:59:58Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20084#discussion_r196138404", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20084", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/196138404"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20084#discussion_r196138404"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20084"}}, "body_html": "<p>pronunciations</p>", "body_text": "pronunciations"}