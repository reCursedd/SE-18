{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/354709724", "html_url": "https://github.com/tensorflow/tensorflow/issues/11182#issuecomment-354709724", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11182", "id": 354709724, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDcwOTcyNA==", "user": {"login": "jeffxtang", "id": 535090, "node_id": "MDQ6VXNlcjUzNTA5MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/535090?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeffxtang", "html_url": "https://github.com/jeffxtang", "followers_url": "https://api.github.com/users/jeffxtang/followers", "following_url": "https://api.github.com/users/jeffxtang/following{/other_user}", "gists_url": "https://api.github.com/users/jeffxtang/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeffxtang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeffxtang/subscriptions", "organizations_url": "https://api.github.com/users/jeffxtang/orgs", "repos_url": "https://api.github.com/users/jeffxtang/repos", "events_url": "https://api.github.com/users/jeffxtang/events{/privacy}", "received_events_url": "https://api.github.com/users/jeffxtang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-02T06:38:35Z", "updated_at": "2018-01-02T06:38:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Anyone having the low accuracy problem on iOS? I use <code>transform_graph</code> on a retrain model (based on Inception v3) and <code>label_image</code> works fine on the quantized model <code>transform_dog_retrained.pb</code> (same accuracy as with the pre-transformed model <code>dog_retrained.pb</code>), but the iOS app gives bad recognition results. The iOS app gives the same results as <code>label_image</code> when using the retrained (but before transformed) model <code>dog_retrained.pb</code>.</p>\n<p>Commands to retrain, transform, and call label_image are as follows:</p>\n<pre><code>python tensorflow/examples/image_retraining/retrain.py   \\\n--model_dir=/tf_files/inception-v3   \\\n--output_graph=/tf_files/retrained_models/dog_retrained.pb   \\\n--output_labels=/tf_files/retrained_models/dog_retrained_labels.txt   \\\n--image_dir ~/Downloads/dog_images   \\\n--bottleneck_dir=/tf_files/dogs_bottleneck\n</code></pre>\n<pre><code>bazel-bin/tensorflow/tools/graph_transforms/transform_graph  \\\n --in_graph=/tf_files/retrained_models/dog_retrained.pb   \\\n--out_graph=/tf_files/retrained_models/transform_dog_retrained.pb   \\\n--inputs='Mul'   --outputs='final_result'   \\\n--transforms='\n  add_default_attributes\n  strip_unused_nodes(type=float, shape=\"1,299,299,3\")\n  fold_constants(ignore_errors=true)\n  fold_batch_norms\n  fold_old_batch_norms\n  quantize_weights\n  strip_unused_nodes\n  sort_by_execution_order'\n</code></pre>\n<pre><code>bazel-bin/tensorflow/examples/label_image/label_image \\\n--graph=/tf_files/retrained_models/transform_dog_retrained.pb \\\n--image=/tf_files/lab.jpg --input_layer=Mul --output_layer=final_result \\\n--labels=/tf_files/retrained_models/dog_retrained_labels.txt\n</code></pre>\n<p>Anyone has any idea how to fix the iOS issue? Btw, if I use the older <code>bazel build tensorflow/python/tools:strip_unused</code> then <code>python tensorflow/tools/quantization/quantize_graph.py</code>, the quantized model generated this way has good results (same accuracy as <code>label_image</code>) on iOS. But I hope to use the new <code>transform_graph</code> method instead of the old way.</p>\n<p>What's the right way to use <code>transform_graph</code> so the generated model works on iOS with about the same accuracy as using<code>label_image</code>?</p>\n<p>Thanks!</p>", "body_text": "Anyone having the low accuracy problem on iOS? I use transform_graph on a retrain model (based on Inception v3) and label_image works fine on the quantized model transform_dog_retrained.pb (same accuracy as with the pre-transformed model dog_retrained.pb), but the iOS app gives bad recognition results. The iOS app gives the same results as label_image when using the retrained (but before transformed) model dog_retrained.pb.\nCommands to retrain, transform, and call label_image are as follows:\npython tensorflow/examples/image_retraining/retrain.py   \\\n--model_dir=/tf_files/inception-v3   \\\n--output_graph=/tf_files/retrained_models/dog_retrained.pb   \\\n--output_labels=/tf_files/retrained_models/dog_retrained_labels.txt   \\\n--image_dir ~/Downloads/dog_images   \\\n--bottleneck_dir=/tf_files/dogs_bottleneck\n\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph  \\\n --in_graph=/tf_files/retrained_models/dog_retrained.pb   \\\n--out_graph=/tf_files/retrained_models/transform_dog_retrained.pb   \\\n--inputs='Mul'   --outputs='final_result'   \\\n--transforms='\n  add_default_attributes\n  strip_unused_nodes(type=float, shape=\"1,299,299,3\")\n  fold_constants(ignore_errors=true)\n  fold_batch_norms\n  fold_old_batch_norms\n  quantize_weights\n  strip_unused_nodes\n  sort_by_execution_order'\n\nbazel-bin/tensorflow/examples/label_image/label_image \\\n--graph=/tf_files/retrained_models/transform_dog_retrained.pb \\\n--image=/tf_files/lab.jpg --input_layer=Mul --output_layer=final_result \\\n--labels=/tf_files/retrained_models/dog_retrained_labels.txt\n\nAnyone has any idea how to fix the iOS issue? Btw, if I use the older bazel build tensorflow/python/tools:strip_unused then python tensorflow/tools/quantization/quantize_graph.py, the quantized model generated this way has good results (same accuracy as label_image) on iOS. But I hope to use the new transform_graph method instead of the old way.\nWhat's the right way to use transform_graph so the generated model works on iOS with about the same accuracy as usinglabel_image?\nThanks!", "body": "Anyone having the low accuracy problem on iOS? I use `transform_graph` on a retrain model (based on Inception v3) and `label_image` works fine on the quantized model `transform_dog_retrained.pb` (same accuracy as with the pre-transformed model `dog_retrained.pb`), but the iOS app gives bad recognition results. The iOS app gives the same results as `label_image` when using the retrained (but before transformed) model `dog_retrained.pb`.\r\n\r\nCommands to retrain, transform, and call label_image are as follows:\r\n\r\n```\r\npython tensorflow/examples/image_retraining/retrain.py   \\\r\n--model_dir=/tf_files/inception-v3   \\\r\n--output_graph=/tf_files/retrained_models/dog_retrained.pb   \\\r\n--output_labels=/tf_files/retrained_models/dog_retrained_labels.txt   \\\r\n--image_dir ~/Downloads/dog_images   \\\r\n--bottleneck_dir=/tf_files/dogs_bottleneck\r\n```\r\n\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph  \\\r\n --in_graph=/tf_files/retrained_models/dog_retrained.pb   \\\r\n--out_graph=/tf_files/retrained_models/transform_dog_retrained.pb   \\\r\n--inputs='Mul'   --outputs='final_result'   \\\r\n--transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=float, shape=\"1,299,299,3\")\r\n  fold_constants(ignore_errors=true)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  strip_unused_nodes\r\n  sort_by_execution_order'\r\n```\r\n```\r\nbazel-bin/tensorflow/examples/label_image/label_image \\\r\n--graph=/tf_files/retrained_models/transform_dog_retrained.pb \\\r\n--image=/tf_files/lab.jpg --input_layer=Mul --output_layer=final_result \\\r\n--labels=/tf_files/retrained_models/dog_retrained_labels.txt\r\n```\r\n\r\nAnyone has any idea how to fix the iOS issue? Btw, if I use the older `bazel build tensorflow/python/tools:strip_unused` then `python tensorflow/tools/quantization/quantize_graph.py`, the quantized model generated this way has good results (same accuracy as `label_image`) on iOS. But I hope to use the new `transform_graph` method instead of the old way.\r\n\r\nWhat's the right way to use `transform_graph` so the generated model works on iOS with about the same accuracy as using`label_image`?\r\n\r\nThanks!"}