{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/359974649", "html_url": "https://github.com/tensorflow/tensorflow/issues/13622#issuecomment-359974649", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13622", "id": 359974649, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTk3NDY0OQ==", "user": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-24T00:04:16Z", "updated_at": "2018-01-24T00:04:16Z", "author_association": "MEMBER", "body_html": "<p>We have introduced new CudnnLSTM layers after TF1.5 which manages the variables for you. Please try that out.<br>\nAlso, note that the code doesn't show how train_ops are created.</p>\n<div class=\"highlight highlight-source-python\"><pre>    lstm_para_size <span class=\"pl-k\">=</span> lstm.params_size()\n    lstm_para <span class=\"pl-k\">=</span> tf.Variable(tf.random_uniform([lstm_para_size]), <span class=\"pl-v\">validate_shape</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>lstm_para<span class=\"pl-pds\">'</span></span>)\n\n    state_c <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[num_layer, <span class=\"pl-c1\">1</span>, num_unit]), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    state_h <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[num_layer, <span class=\"pl-c1\">1</span>, num_unit]), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n    lstm_output, lstm_h, lstm_c <span class=\"pl-k\">=</span> lstm(<span class=\"pl-v\">input_data</span><span class=\"pl-k\">=</span>x1, <span class=\"pl-v\">input_h</span><span class=\"pl-k\">=</span>state_h, <span class=\"pl-v\">input_c</span><span class=\"pl-k\">=</span>state_c, <span class=\"pl-v\">params</span><span class=\"pl-k\">=</span>lstm_para)</pre></div>\n<p>If you're just doing inference, does \"1\" show up in one step or persists after one step? I suspect with your input it happens that the ground truth output is 1 for certain step.</p>", "body_text": "We have introduced new CudnnLSTM layers after TF1.5 which manages the variables for you. Please try that out.\nAlso, note that the code doesn't show how train_ops are created.\n    lstm_para_size = lstm.params_size()\n    lstm_para = tf.Variable(tf.random_uniform([lstm_para_size]), validate_shape=False, name='lstm_para')\n\n    state_c = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\n    state_h = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\n\n    lstm_output, lstm_h, lstm_c = lstm(input_data=x1, input_h=state_h, input_c=state_c, params=lstm_para)\nIf you're just doing inference, does \"1\" show up in one step or persists after one step? I suspect with your input it happens that the ground truth output is 1 for certain step.", "body": "We have introduced new CudnnLSTM layers after TF1.5 which manages the variables for you. Please try that out.\r\nAlso, note that the code doesn't show how train_ops are created.\r\n```py\r\n    lstm_para_size = lstm.params_size()\r\n    lstm_para = tf.Variable(tf.random_uniform([lstm_para_size]), validate_shape=False, name='lstm_para')\r\n\r\n    state_c = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\r\n    state_h = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\r\n\r\n    lstm_output, lstm_h, lstm_c = lstm(input_data=x1, input_h=state_h, input_c=state_c, params=lstm_para)\r\n```\r\n\r\nIf you're just doing inference, does \"1\" show up in one step or persists after one step? I suspect with your input it happens that the ground truth output is 1 for certain step."}