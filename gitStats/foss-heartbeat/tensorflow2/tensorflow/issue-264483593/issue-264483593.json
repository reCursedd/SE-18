{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13622", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13622/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13622/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13622/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13622", "id": 264483593, "node_id": "MDU6SXNzdWUyNjQ0ODM1OTM=", "number": 13622, "title": "CudnnLSTM returns all Ones(1) after the 10th sequence ", "user": {"login": "josephlau", "id": 3964684, "node_id": "MDQ6VXNlcjM5NjQ2ODQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/3964684?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josephlau", "html_url": "https://github.com/josephlau", "followers_url": "https://api.github.com/users/josephlau/followers", "following_url": "https://api.github.com/users/josephlau/following{/other_user}", "gists_url": "https://api.github.com/users/josephlau/gists{/gist_id}", "starred_url": "https://api.github.com/users/josephlau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josephlau/subscriptions", "organizations_url": "https://api.github.com/users/josephlau/orgs", "repos_url": "https://api.github.com/users/josephlau/repos", "events_url": "https://api.github.com/users/josephlau/events{/privacy}", "received_events_url": "https://api.github.com/users/josephlau/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2017-10-11T07:30:44Z", "updated_at": "2018-02-07T23:25:33Z", "closed_at": "2018-02-07T23:25:32Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: v1.3.0-rc1-1486-g752dcb6 1.3.0</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/6.0</li>\n<li><strong>GPU model and memory</strong>: GTX1050Ti</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I tried to use CudnnLSTM to speed up the training, but found it only returns one after the 10th step, following code generate the output.</p>\n<h3>Source code / logs</h3>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib.cudnn_rnn import CudnnLSTM\nimport numpy as np\n\n\nnp.set_printoptions(linewidth=240, edgeitems=6)\n# Reset default graph\ntf.reset_default_graph()\n\nnum_layer = 5\nnum_unit = 256\ninput_size = 400\nseq_lenght = 20\n\nwith tf.device('/gpu:0'):\n    x = tf.random_uniform([seq_lenght, input_size], maxval=1, dtype=tf.float32)\n    x1 = tf.expand_dims(x, 1)\n    lstm = CudnnLSTM(num_layers=num_layer, num_units=num_unit, input_size=input_size,\n                 input_mode='linear_input',\n                 direction='unidirectional')\n\n    # CudnnLSTM parameter\n    lstm_para_size = lstm.params_size()\n    lstm_para = tf.Variable(tf.random_uniform([lstm_para_size]), validate_shape=False, name='lstm_para')\n\n    state_c = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\n    state_h = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\n\n    lstm_output, lstm_h, lstm_c = lstm(input_data=x1, input_h=state_h, input_c=state_c, params=lstm_para)\n\n# Variable initializing op\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\ncudnn_output = sess.run(lstm_output)\nprint(cudnn_output)\n</code></pre>\n<p>###LSTM output<br>\n[[[ 0.76159418  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418 ...,  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418]]</p>\n<p>[[ 0.96402758  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758 ...,  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758]]</p>\n<p>[[ 0.99505478  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478 ...,  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478]]</p>\n<p>[[ 0.99932933  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933 ...,  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933]]</p>\n<p>[[ 0.99990922  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922 ...,  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922]]</p>\n<p>[[ 0.99998772  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772 ...,  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772]]</p>\n<p>...,<br>\n[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]</p>\n<p>[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]</p>\n<p>[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]</p>\n<p>[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]</p>\n<p>[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]</p>\n<p>[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]]</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.3\nPython version: 3.5\nBazel version (if compiling from source): v1.3.0-rc1-1486-g752dcb6 1.3.0\nCUDA/cuDNN version: 8.0/6.0\nGPU model and memory: GTX1050Ti\nExact command to reproduce:\n\nDescribe the problem\nI tried to use CudnnLSTM to speed up the training, but found it only returns one after the 10th step, following code generate the output.\nSource code / logs\nimport tensorflow as tf\nfrom tensorflow.contrib.cudnn_rnn import CudnnLSTM\nimport numpy as np\n\n\nnp.set_printoptions(linewidth=240, edgeitems=6)\n# Reset default graph\ntf.reset_default_graph()\n\nnum_layer = 5\nnum_unit = 256\ninput_size = 400\nseq_lenght = 20\n\nwith tf.device('/gpu:0'):\n    x = tf.random_uniform([seq_lenght, input_size], maxval=1, dtype=tf.float32)\n    x1 = tf.expand_dims(x, 1)\n    lstm = CudnnLSTM(num_layers=num_layer, num_units=num_unit, input_size=input_size,\n                 input_mode='linear_input',\n                 direction='unidirectional')\n\n    # CudnnLSTM parameter\n    lstm_para_size = lstm.params_size()\n    lstm_para = tf.Variable(tf.random_uniform([lstm_para_size]), validate_shape=False, name='lstm_para')\n\n    state_c = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\n    state_h = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\n\n    lstm_output, lstm_h, lstm_c = lstm(input_data=x1, input_h=state_h, input_c=state_c, params=lstm_para)\n\n# Variable initializing op\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\ncudnn_output = sess.run(lstm_output)\nprint(cudnn_output)\n\n###LSTM output\n[[[ 0.76159418  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418 ...,  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418]]\n[[ 0.96402758  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758 ...,  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758]]\n[[ 0.99505478  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478 ...,  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478]]\n[[ 0.99932933  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933 ...,  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933]]\n[[ 0.99990922  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922 ...,  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922]]\n[[ 0.99998772  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772 ...,  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772]]\n...,\n[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\n[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\n[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\n[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\n[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\n[[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: v1.3.0-rc1-1486-g752dcb6 1.3.0\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: GTX1050Ti\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI tried to use CudnnLSTM to speed up the training, but found it only returns one after the 10th step, following code generate the output.\r\n\r\n### Source code / logs\r\n    import tensorflow as tf\r\n    from tensorflow.contrib.cudnn_rnn import CudnnLSTM\r\n    import numpy as np\r\n\r\n\r\n    np.set_printoptions(linewidth=240, edgeitems=6)\r\n    # Reset default graph\r\n    tf.reset_default_graph()\r\n\r\n    num_layer = 5\r\n    num_unit = 256\r\n    input_size = 400\r\n    seq_lenght = 20\r\n\r\n    with tf.device('/gpu:0'):\r\n        x = tf.random_uniform([seq_lenght, input_size], maxval=1, dtype=tf.float32)\r\n        x1 = tf.expand_dims(x, 1)\r\n        lstm = CudnnLSTM(num_layers=num_layer, num_units=num_unit, input_size=input_size,\r\n                     input_mode='linear_input',\r\n                     direction='unidirectional')\r\n\r\n        # CudnnLSTM parameter\r\n        lstm_para_size = lstm.params_size()\r\n        lstm_para = tf.Variable(tf.random_uniform([lstm_para_size]), validate_shape=False, name='lstm_para')\r\n\r\n        state_c = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\r\n        state_h = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)\r\n\r\n        lstm_output, lstm_h, lstm_c = lstm(input_data=x1, input_h=state_h, input_c=state_c, params=lstm_para)\r\n\r\n    # Variable initializing op\r\n    init = tf.global_variables_initializer()\r\n\r\n    with tf.Session() as sess:\r\n        sess.run(init)\r\n    cudnn_output = sess.run(lstm_output)\r\n    print(cudnn_output)\r\n\r\n###LSTM output\r\n[[[ 0.76159418  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418 ...,  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418]]\r\n\r\n [[ 0.96402758  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758 ...,  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758]]\r\n\r\n [[ 0.99505478  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478 ...,  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478]]\r\n\r\n [[ 0.99932933  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933 ...,  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933]]\r\n\r\n [[ 0.99990922  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922 ...,  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922]]\r\n\r\n [[ 0.99998772  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772 ...,  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772]]\r\n\r\n ..., \r\n [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\r\n\r\n [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\r\n\r\n [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\r\n\r\n [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\r\n\r\n [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]\r\n\r\n [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]]"}