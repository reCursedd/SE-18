{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/239964184", "html_url": "https://github.com/tensorflow/tensorflow/issues/3579#issuecomment-239964184", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3579", "id": 239964184, "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTk2NDE4NA==", "user": {"login": "arjunsesh", "id": 5135454, "node_id": "MDQ6VXNlcjUxMzU0NTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/5135454?v=4", "gravatar_id": "", "url": "https://api.github.com/users/arjunsesh", "html_url": "https://github.com/arjunsesh", "followers_url": "https://api.github.com/users/arjunsesh/followers", "following_url": "https://api.github.com/users/arjunsesh/following{/other_user}", "gists_url": "https://api.github.com/users/arjunsesh/gists{/gist_id}", "starred_url": "https://api.github.com/users/arjunsesh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/arjunsesh/subscriptions", "organizations_url": "https://api.github.com/users/arjunsesh/orgs", "repos_url": "https://api.github.com/users/arjunsesh/repos", "events_url": "https://api.github.com/users/arjunsesh/events{/privacy}", "received_events_url": "https://api.github.com/users/arjunsesh/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-15T23:54:41Z", "updated_at": "2016-08-16T00:07:27Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16907534\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rmlarsen\">@rmlarsen</a> It seems like you misunderstood what I was pointing out - I understand that the dimensions of the <em>output</em> are (N+1) x N for both batch_self_adjoint_eig and self_adjoint_eig since it is packing both the eigenvectors and values together. I was pointing out that the batch_self_adjoint_eig function is currently modifying the shape of the <em>input</em> tensor to become (N+1) x N for no reason at all. Take a look at the example above that I posted for more clarity, and thanks for your help.</p>", "body_text": "@rmlarsen It seems like you misunderstood what I was pointing out - I understand that the dimensions of the output are (N+1) x N for both batch_self_adjoint_eig and self_adjoint_eig since it is packing both the eigenvectors and values together. I was pointing out that the batch_self_adjoint_eig function is currently modifying the shape of the input tensor to become (N+1) x N for no reason at all. Take a look at the example above that I posted for more clarity, and thanks for your help.", "body": "@rmlarsen It seems like you misunderstood what I was pointing out - I understand that the dimensions of the _output_ are (N+1) x N for both batch_self_adjoint_eig and self_adjoint_eig since it is packing both the eigenvectors and values together. I was pointing out that the batch_self_adjoint_eig function is currently modifying the shape of the _input_ tensor to become (N+1) x N for no reason at all. Take a look at the example above that I posted for more clarity, and thanks for your help. \n"}