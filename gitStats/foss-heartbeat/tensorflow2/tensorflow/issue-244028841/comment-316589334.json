{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/316589334", "html_url": "https://github.com/tensorflow/tensorflow/issues/11605#issuecomment-316589334", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11605", "id": 316589334, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjU4OTMzNA==", "user": {"login": "jakiechris", "id": 12059735, "node_id": "MDQ6VXNlcjEyMDU5NzM1", "avatar_url": "https://avatars2.githubusercontent.com/u/12059735?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakiechris", "html_url": "https://github.com/jakiechris", "followers_url": "https://api.github.com/users/jakiechris/followers", "following_url": "https://api.github.com/users/jakiechris/following{/other_user}", "gists_url": "https://api.github.com/users/jakiechris/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakiechris/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakiechris/subscriptions", "organizations_url": "https://api.github.com/users/jakiechris/orgs", "repos_url": "https://api.github.com/users/jakiechris/repos", "events_url": "https://api.github.com/users/jakiechris/events{/privacy}", "received_events_url": "https://api.github.com/users/jakiechris/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-20T03:52:42Z", "updated_at": "2017-07-20T03:52:42Z", "author_association": "NONE", "body_html": "<p>print_selective_registration_header.py result:</p>\n<p>#ifndef OPS_TO_REGISTER<br>\n#define OPS_TO_REGISTER<br>\nconstexpr inline bool ShouldRegisterOp(const char op[]) {<br>\nreturn false<br>\n|| (strcmp(op, \"ArgMax\") == 0)<br>\n|| (strcmp(op, \"BiasAdd\") == 0)<br>\n|| (strcmp(op, \"Const\") == 0)<br>\n|| (strcmp(op, \"Conv2D\") == 0)<br>\n|| (strcmp(op, \"ExpandDims\") == 0)<br>\n|| (strcmp(op, \"Identity\") == 0)<br>\n|| (strcmp(op, \"MatMul\") == 0)<br>\n|| (strcmp(op, \"MaxPool\") == 0)<br>\n|| (strcmp(op, \"NoOp\") == 0)<br>\n|| (strcmp(op, \"Placeholder\") == 0)<br>\n|| (strcmp(op, \"Relu\") == 0)<br>\n|| (strcmp(op, \"Reshape\") == 0)<br>\n|| (strcmp(op, \"Squeeze\") == 0)<br>\n|| (strcmp(op, \"StridedSlice\") == 0)<br>\n|| (strcmp(op, \"_Recv\") == 0)<br>\n|| (strcmp(op, \"_Send\") == 0)<br>\n;<br>\n}<br>\n#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)</p>\n<pre><code>namespace {\n  constexpr const char* skip(const char* x) {\n    return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;\n  }\n\n  constexpr bool isequal(const char* x, const char* y) {\n    return (*skip(x) &amp;&amp; *skip(y))\n               ? (*skip(x) == *skip(y) &amp;&amp; isequal(skip(x) + 1, skip(y) + 1))\n               : (!*skip(x) &amp;&amp; !*skip(y));\n  }\n\n  template&lt;int N&gt;\n  struct find_in {\n    static constexpr bool f(const char* x, const char* const y[N]) {\n      return isequal(x, y[0]) || find_in&lt;N - 1&gt;::f(x, y + 1);\n    }\n  };\n\n  template&lt;&gt;\n  struct find_in&lt;0&gt; {\n    static constexpr bool f(const char* x, const char* const y[]) {\n      return false;\n    }\n  };\n}  // end namespace\nconstexpr const char* kNecessaryOpKernelClasses[] = {\n</code></pre>\n<p>\"ArgMaxOp&lt;CPUDevice, float&gt;\",<br>\n\"BiasOp&lt;CPUDevice, float&gt;\",<br>\n\"ConstantOp\",<br>\n\"Conv2DOp&lt;CPUDevice, float&gt;\",<br>\n\"ExpandDimsOp\",<br>\n\"IdentityOp\",<br>\n\"MatMulOp&lt;CPUDevice, float, false &gt;\",<br>\n\"MaxPoolingOp&lt;CPUDevice, float&gt;\",<br>\n\"NoOp\",<br>\n\"PlaceholderOp\",<br>\n\"ReluOp&lt;CPUDevice, float&gt;\",<br>\n\"ReshapeOp\",<br>\n\"SqueezeOp\",<br>\n\"StridedSliceOp&lt;CPUDevice, float&gt;\",<br>\n\"RecvOp\",<br>\n\"SendOp\",<br>\n};<br>\n#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in&lt;sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)&gt;::f(clz, kNecessaryOpKernelClasses))</p>\n<p>#define SHOULD_REGISTER_OP_GRADIENT false<br>\n#endif</p>", "body_text": "print_selective_registration_header.py result:\n#ifndef OPS_TO_REGISTER\n#define OPS_TO_REGISTER\nconstexpr inline bool ShouldRegisterOp(const char op[]) {\nreturn false\n|| (strcmp(op, \"ArgMax\") == 0)\n|| (strcmp(op, \"BiasAdd\") == 0)\n|| (strcmp(op, \"Const\") == 0)\n|| (strcmp(op, \"Conv2D\") == 0)\n|| (strcmp(op, \"ExpandDims\") == 0)\n|| (strcmp(op, \"Identity\") == 0)\n|| (strcmp(op, \"MatMul\") == 0)\n|| (strcmp(op, \"MaxPool\") == 0)\n|| (strcmp(op, \"NoOp\") == 0)\n|| (strcmp(op, \"Placeholder\") == 0)\n|| (strcmp(op, \"Relu\") == 0)\n|| (strcmp(op, \"Reshape\") == 0)\n|| (strcmp(op, \"Squeeze\") == 0)\n|| (strcmp(op, \"StridedSlice\") == 0)\n|| (strcmp(op, \"_Recv\") == 0)\n|| (strcmp(op, \"_Send\") == 0)\n;\n}\n#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)\nnamespace {\n  constexpr const char* skip(const char* x) {\n    return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;\n  }\n\n  constexpr bool isequal(const char* x, const char* y) {\n    return (*skip(x) && *skip(y))\n               ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))\n               : (!*skip(x) && !*skip(y));\n  }\n\n  template<int N>\n  struct find_in {\n    static constexpr bool f(const char* x, const char* const y[N]) {\n      return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);\n    }\n  };\n\n  template<>\n  struct find_in<0> {\n    static constexpr bool f(const char* x, const char* const y[]) {\n      return false;\n    }\n  };\n}  // end namespace\nconstexpr const char* kNecessaryOpKernelClasses[] = {\n\n\"ArgMaxOp<CPUDevice, float>\",\n\"BiasOp<CPUDevice, float>\",\n\"ConstantOp\",\n\"Conv2DOp<CPUDevice, float>\",\n\"ExpandDimsOp\",\n\"IdentityOp\",\n\"MatMulOp<CPUDevice, float, false >\",\n\"MaxPoolingOp<CPUDevice, float>\",\n\"NoOp\",\n\"PlaceholderOp\",\n\"ReluOp<CPUDevice, float>\",\n\"ReshapeOp\",\n\"SqueezeOp\",\n\"StridedSliceOp<CPUDevice, float>\",\n\"RecvOp\",\n\"SendOp\",\n};\n#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))\n#define SHOULD_REGISTER_OP_GRADIENT false\n#endif", "body": "print_selective_registration_header.py result:\r\n\r\n\r\n#ifndef OPS_TO_REGISTER\r\n#define OPS_TO_REGISTER\r\nconstexpr inline bool ShouldRegisterOp(const char op[]) {\r\n  return false\r\n     || (strcmp(op, \"ArgMax\") == 0)\r\n     || (strcmp(op, \"BiasAdd\") == 0)\r\n     || (strcmp(op, \"Const\") == 0)\r\n     || (strcmp(op, \"Conv2D\") == 0)\r\n     || (strcmp(op, \"ExpandDims\") == 0)\r\n     || (strcmp(op, \"Identity\") == 0)\r\n     || (strcmp(op, \"MatMul\") == 0)\r\n     || (strcmp(op, \"MaxPool\") == 0)\r\n     || (strcmp(op, \"NoOp\") == 0)\r\n     || (strcmp(op, \"Placeholder\") == 0)\r\n     || (strcmp(op, \"Relu\") == 0)\r\n     || (strcmp(op, \"Reshape\") == 0)\r\n     || (strcmp(op, \"Squeeze\") == 0)\r\n     || (strcmp(op, \"StridedSlice\") == 0)\r\n     || (strcmp(op, \"_Recv\") == 0)\r\n     || (strcmp(op, \"_Send\") == 0)\r\n  ;\r\n}\r\n#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)\r\n\r\n\r\n    namespace {\r\n      constexpr const char* skip(const char* x) {\r\n        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;\r\n      }\r\n\r\n      constexpr bool isequal(const char* x, const char* y) {\r\n        return (*skip(x) && *skip(y))\r\n                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))\r\n                   : (!*skip(x) && !*skip(y));\r\n      }\r\n\r\n      template<int N>\r\n      struct find_in {\r\n        static constexpr bool f(const char* x, const char* const y[N]) {\r\n          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);\r\n        }\r\n      };\r\n\r\n      template<>\r\n      struct find_in<0> {\r\n        static constexpr bool f(const char* x, const char* const y[]) {\r\n          return false;\r\n        }\r\n      };\r\n    }  // end namespace\r\n    constexpr const char* kNecessaryOpKernelClasses[] = {\r\n\"ArgMaxOp<CPUDevice, float>\",\r\n\"BiasOp<CPUDevice, float>\",\r\n\"ConstantOp\",\r\n\"Conv2DOp<CPUDevice, float>\",\r\n\"ExpandDimsOp\",\r\n\"IdentityOp\",\r\n\"MatMulOp<CPUDevice, float, false >\",\r\n\"MaxPoolingOp<CPUDevice, float>\",\r\n\"NoOp\",\r\n\"PlaceholderOp\",\r\n\"ReluOp<CPUDevice, float>\",\r\n\"ReshapeOp\",\r\n\"SqueezeOp\",\r\n\"StridedSliceOp<CPUDevice, float>\",\r\n\"RecvOp\",\r\n\"SendOp\",\r\n};\r\n#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))\r\n\r\n#define SHOULD_REGISTER_OP_GRADIENT false\r\n#endif"}