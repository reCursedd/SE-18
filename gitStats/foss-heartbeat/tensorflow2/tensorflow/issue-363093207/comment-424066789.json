{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/424066789", "html_url": "https://github.com/tensorflow/tensorflow/issues/22479#issuecomment-424066789", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22479", "id": 424066789, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDA2Njc4OQ==", "user": {"login": "nairouz", "id": 10966954, "node_id": "MDQ6VXNlcjEwOTY2OTU0", "avatar_url": "https://avatars0.githubusercontent.com/u/10966954?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nairouz", "html_url": "https://github.com/nairouz", "followers_url": "https://api.github.com/users/nairouz/followers", "following_url": "https://api.github.com/users/nairouz/following{/other_user}", "gists_url": "https://api.github.com/users/nairouz/gists{/gist_id}", "starred_url": "https://api.github.com/users/nairouz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nairouz/subscriptions", "organizations_url": "https://api.github.com/users/nairouz/orgs", "repos_url": "https://api.github.com/users/nairouz/repos", "events_url": "https://api.github.com/users/nairouz/events{/privacy}", "received_events_url": "https://api.github.com/users/nairouz/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-24T17:56:43Z", "updated_at": "2018-09-24T17:57:29Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=42785357\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ymodak\">@ymodak</a> thank you for the response. I have created a second model as suggested in the similar thread.<br>\nUnfortunately, it is not working. Please note that in <a href=\"url\">https://github.com/keras-team/keras/issues/8909</a>, the user mentioned that <code>the  model.summary() shows that the layer has been removed</code>. For me, it is not the case.</p>\n<p>Here is the code. Check it out.</p>\n<pre><code>import tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.backend as K\nimport numpy as np\nfrom tensorflow.keras.layers import Dense, Input, Layer\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(20,), name=\"input\")\nhidden = Dense(100, activation='relu')(input_tensor)\nout = Dense(10, activation='relu', name=\"out\")(hidden)\n\nmodel = Model(inputs=input_tensor, outputs=out)\nmodel.compile(loss=\"mse\", optimizer=tf.train.AdamOptimizer(learning_rate=0.001))\n\nmodel.summary()\nmodel.layers.pop()\nmodel.summary()\n\nhidden = Dense(120, activation='relu')(model.layers[-1].output)\nout = Dense(5, activation='softmax')(hidden)\nmodel2 = Model(input_tensor, out)\n\nmodel2.summary()\n</code></pre>", "body_text": "@ymodak thank you for the response. I have created a second model as suggested in the similar thread.\nUnfortunately, it is not working. Please note that in https://github.com/keras-team/keras/issues/8909, the user mentioned that the  model.summary() shows that the layer has been removed. For me, it is not the case.\nHere is the code. Check it out.\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.backend as K\nimport numpy as np\nfrom tensorflow.keras.layers import Dense, Input, Layer\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(20,), name=\"input\")\nhidden = Dense(100, activation='relu')(input_tensor)\nout = Dense(10, activation='relu', name=\"out\")(hidden)\n\nmodel = Model(inputs=input_tensor, outputs=out)\nmodel.compile(loss=\"mse\", optimizer=tf.train.AdamOptimizer(learning_rate=0.001))\n\nmodel.summary()\nmodel.layers.pop()\nmodel.summary()\n\nhidden = Dense(120, activation='relu')(model.layers[-1].output)\nout = Dense(5, activation='softmax')(hidden)\nmodel2 = Model(input_tensor, out)\n\nmodel2.summary()", "body": "@ymodak thank you for the response. I have created a second model as suggested in the similar thread. \r\nUnfortunately, it is not working. Please note that in [https://github.com/keras-team/keras/issues/8909](url), the user mentioned that `the  model.summary() shows that the layer has been removed`. For me, it is not the case.\r\n\r\nHere is the code. Check it out.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\nimport tensorflow.keras.backend as K\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import Dense, Input, Layer\r\nfrom tensorflow.keras.models import Model\r\n\r\ninput_tensor = Input(shape=(20,), name=\"input\")\r\nhidden = Dense(100, activation='relu')(input_tensor)\r\nout = Dense(10, activation='relu', name=\"out\")(hidden)\r\n\r\nmodel = Model(inputs=input_tensor, outputs=out)\r\nmodel.compile(loss=\"mse\", optimizer=tf.train.AdamOptimizer(learning_rate=0.001))\r\n\r\nmodel.summary()\r\nmodel.layers.pop()\r\nmodel.summary()\r\n\r\nhidden = Dense(120, activation='relu')(model.layers[-1].output)\r\nout = Dense(5, activation='softmax')(hidden)\r\nmodel2 = Model(input_tensor, out)\r\n\r\nmodel2.summary()\r\n```\r\n\r\n"}