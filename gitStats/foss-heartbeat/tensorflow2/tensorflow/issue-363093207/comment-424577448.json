{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/424577448", "html_url": "https://github.com/tensorflow/tensorflow/issues/22479#issuecomment-424577448", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22479", "id": 424577448, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDU3NzQ0OA==", "user": {"login": "yanboliang", "id": 1962026, "node_id": "MDQ6VXNlcjE5NjIwMjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/1962026?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yanboliang", "html_url": "https://github.com/yanboliang", "followers_url": "https://api.github.com/users/yanboliang/followers", "following_url": "https://api.github.com/users/yanboliang/following{/other_user}", "gists_url": "https://api.github.com/users/yanboliang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yanboliang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yanboliang/subscriptions", "organizations_url": "https://api.github.com/users/yanboliang/orgs", "repos_url": "https://api.github.com/users/yanboliang/repos", "events_url": "https://api.github.com/users/yanboliang/events{/privacy}", "received_events_url": "https://api.github.com/users/yanboliang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-26T04:02:49Z", "updated_at": "2018-09-26T04:02:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10966954\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nairouz\">@nairouz</a><br>\nThere are two issues in your code:</p>\n<ul>\n<li>You can't use <code>model.layers.pop()</code> to remove the last layer in the model. In <code>tf.keras</code>, <code>model.layers</code> will return a shallow copy version of the layers list, so actually you don't remove that layer, just remove the layer in the return value.</li>\n<li>If you want to remove the last dense layer and add your own one, you should use <code>hidden = Dense(120, activation='relu')(model.layers[-2].output)</code>. <code>model.layers[-1].output</code> means the last layer's output which is the final output, so in your code, you actually didn't remove any layers.</li>\n</ul>\n<p>Thanks.</p>", "body_text": "@nairouz\nThere are two issues in your code:\n\nYou can't use model.layers.pop() to remove the last layer in the model. In tf.keras, model.layers will return a shallow copy version of the layers list, so actually you don't remove that layer, just remove the layer in the return value.\nIf you want to remove the last dense layer and add your own one, you should use hidden = Dense(120, activation='relu')(model.layers[-2].output). model.layers[-1].output means the last layer's output which is the final output, so in your code, you actually didn't remove any layers.\n\nThanks.", "body": "@nairouz \r\nThere are two issues in your code:\r\n* You can't use ```model.layers.pop()``` to remove the last layer in the model. In ```tf.keras```, ```model.layers``` will return a shallow copy version of the layers list, so actually you don't remove that layer, just remove the layer in the return value.\r\n* If you want to remove the last dense layer and add your own one, you should use ```hidden = Dense(120, activation='relu')(model.layers[-2].output)```. ```model.layers[-1].output``` means the last layer's output which is the final output, so in your code, you actually didn't remove any layers.\r\n\r\nThanks."}