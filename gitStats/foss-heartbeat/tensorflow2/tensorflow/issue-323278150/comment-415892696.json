{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/415892696", "html_url": "https://github.com/tensorflow/tensorflow/issues/19295#issuecomment-415892696", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19295", "id": 415892696, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTg5MjY5Ng==", "user": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-24T21:54:43Z", "updated_at": "2018-08-24T21:54:43Z", "author_association": "MEMBER", "body_html": "<p>There are two options here:</p>\n<ol>\n<li>\n<p>Warm start the keras model by calling <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights\" rel=\"nofollow\">model.load_weights</a> -- this will now work with hdf5 or checkpoints. Then, model_to_estimator. For cases where you want to reuse a keras architecture (which is what I think you are saying, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1710528\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bhack\">@bhack</a> ), you can wrap the model building in a function to build a new model with the same architecture for each new set of weights.</p>\n</li>\n<li>\n<p>Build the Keras model in an Estimator's model_fn, and use the outputs of the keras model to feed into an Estimator Head or an EstimatorSpec directly. An example of this strategy is the <a href=\"https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L102\">Official MNIST</a>, and another with Head briefly here:</p>\n</li>\n</ol>\n<pre><code>def model_fn(features, labels, mode):\n  model = tf.keras.Sequential([\n      tf.keras.layers.Dense(64),\n      tf.keras.layers.Dense(40, activation=tf.nn.softmax)\n  ])\n  \n  logits = model(features)\n  return tf.contrib.estimator.multi_class_head(...).create_estimator_spec(\n      mode=mode, features=features, labels=labels, logits=logits, optimizer=tf.train.AdamOptimizer())\n\n</code></pre>\n<p>Using that model_fn in an Estimator will then allow you to use the Estimator API as-is with warm start settings.</p>\n<p>Will either of those work for the use cases above? If yes, and you're willing to share a little more-- which do you prefer, and why?</p>", "body_text": "There are two options here:\n\n\nWarm start the keras model by calling model.load_weights -- this will now work with hdf5 or checkpoints. Then, model_to_estimator. For cases where you want to reuse a keras architecture (which is what I think you are saying, @bhack ), you can wrap the model building in a function to build a new model with the same architecture for each new set of weights.\n\n\nBuild the Keras model in an Estimator's model_fn, and use the outputs of the keras model to feed into an Estimator Head or an EstimatorSpec directly. An example of this strategy is the Official MNIST, and another with Head briefly here:\n\n\ndef model_fn(features, labels, mode):\n  model = tf.keras.Sequential([\n      tf.keras.layers.Dense(64),\n      tf.keras.layers.Dense(40, activation=tf.nn.softmax)\n  ])\n  \n  logits = model(features)\n  return tf.contrib.estimator.multi_class_head(...).create_estimator_spec(\n      mode=mode, features=features, labels=labels, logits=logits, optimizer=tf.train.AdamOptimizer())\n\n\nUsing that model_fn in an Estimator will then allow you to use the Estimator API as-is with warm start settings.\nWill either of those work for the use cases above? If yes, and you're willing to share a little more-- which do you prefer, and why?", "body": "There are two options here:\r\n\r\n1. Warm start the keras model by calling [model.load_weights](https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights) -- this will now work with hdf5 or checkpoints. Then, model_to_estimator. For cases where you want to reuse a keras architecture (which is what I think you are saying, @bhack ), you can wrap the model building in a function to build a new model with the same architecture for each new set of weights.\r\n\r\n2. Build the Keras model in an Estimator's model_fn, and use the outputs of the keras model to feed into an Estimator Head or an EstimatorSpec directly. An example of this strategy is the [Official MNIST](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L102), and another with Head briefly here:\r\n\r\n```\r\ndef model_fn(features, labels, mode):\r\n  model = tf.keras.Sequential([\r\n      tf.keras.layers.Dense(64),\r\n      tf.keras.layers.Dense(40, activation=tf.nn.softmax)\r\n  ])\r\n  \r\n  logits = model(features)\r\n  return tf.contrib.estimator.multi_class_head(...).create_estimator_spec(\r\n      mode=mode, features=features, labels=labels, logits=logits, optimizer=tf.train.AdamOptimizer())\r\n\r\n```\r\nUsing that model_fn in an Estimator will then allow you to use the Estimator API as-is with warm start settings.\r\n\r\nWill either of those work for the use cases above? If yes, and you're willing to share a little more-- which do you prefer, and why?"}