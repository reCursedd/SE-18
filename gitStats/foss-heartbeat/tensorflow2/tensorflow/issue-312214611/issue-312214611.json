{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18311", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18311/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18311/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18311/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18311", "id": 312214611, "node_id": "MDU6SXNzdWUzMTIyMTQ2MTE=", "number": 18311, "title": "[Feature request] unsquashing unsorted_segment_x", "user": {"login": "roya0045", "id": 12854129, "node_id": "MDQ6VXNlcjEyODU0MTI5", "avatar_url": "https://avatars1.githubusercontent.com/u/12854129?v=4", "gravatar_id": "", "url": "https://api.github.com/users/roya0045", "html_url": "https://github.com/roya0045", "followers_url": "https://api.github.com/users/roya0045/followers", "following_url": "https://api.github.com/users/roya0045/following{/other_user}", "gists_url": "https://api.github.com/users/roya0045/gists{/gist_id}", "starred_url": "https://api.github.com/users/roya0045/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/roya0045/subscriptions", "organizations_url": "https://api.github.com/users/roya0045/orgs", "repos_url": "https://api.github.com/users/roya0045/repos", "events_url": "https://api.github.com/users/roya0045/events{/privacy}", "received_events_url": "https://api.github.com/users/roya0045/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-04-07T15:06:11Z", "updated_at": "2018-11-14T19:16:58Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Have I written custom code? No<br>\nOS Platform and Distribution? Win10<br>\nTensorFlow installed from? pip<br>\nTensorFlow version? 1.7<br>\nBazel version? N/A<br>\nCUDA/cuDNN version? N/A<br>\nGPU model and memory? N/A<br>\nExact command to reproduce: unsorted_segment_sum</p>\n<h3>Describe the problem</h3>\n<p>Let's say you have 3 sequences of 12 values (shape (3,12)) with 5 segments and you have an input of shape (None,12,3) transposed to (3,12,None)<br>\nusing any function with unsorted_segement_x the output will be (5,None).</p>\n<p>Would it be possible to have a function that does the same but still keep the first dimention.<br>\nSomething equivalent to:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">input</span>.shape<span class=\"pl-k\">==</span>(<span class=\"pl-c1\">None</span>,<span class=\"pl-c1\">12</span>,<span class=\"pl-c1\">3</span>)\nsegment.shape<span class=\"pl-k\">==</span>(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">12</span>)\n\noutputs<span class=\"pl-k\">=</span>[]\n<span class=\"pl-k\">for</span> ix, val <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(tf.unstack(<span class=\"pl-c1\">input</span>)):\n    ouputs.append(tf.unsorted_segment_sum(val,sequence[ix],<span class=\"pl-c1\">5</span>)\n<span class=\"pl-v\">output</span><span class=\"pl-k\">=</span>tf.stack(outputs)\noutput.shape<span class=\"pl-k\">==</span>(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">5</span>,<span class=\"pl-c1\">None</span>)</pre></div>\n<p>The use of such a thing would be to iterate over a weighted input and without having to loop over the data or using reshape. I think this should be somewhat straightforward to implement; not concatenate together all the sequences for the superior dimensions and use \"keep_dims\" similar to reduce_sum to trigger that behaviour.</p>", "body_text": "Have I written custom code? No\nOS Platform and Distribution? Win10\nTensorFlow installed from? pip\nTensorFlow version? 1.7\nBazel version? N/A\nCUDA/cuDNN version? N/A\nGPU model and memory? N/A\nExact command to reproduce: unsorted_segment_sum\nDescribe the problem\nLet's say you have 3 sequences of 12 values (shape (3,12)) with 5 segments and you have an input of shape (None,12,3) transposed to (3,12,None)\nusing any function with unsorted_segement_x the output will be (5,None).\nWould it be possible to have a function that does the same but still keep the first dimention.\nSomething equivalent to:\ninput.shape==(None,12,3)\nsegment.shape==(3,12)\n\noutputs=[]\nfor ix, val in enumerate(tf.unstack(input)):\n    ouputs.append(tf.unsorted_segment_sum(val,sequence[ix],5)\noutput=tf.stack(outputs)\noutput.shape==(3,5,None)\nThe use of such a thing would be to iterate over a weighted input and without having to loop over the data or using reshape. I think this should be somewhat straightforward to implement; not concatenate together all the sequences for the superior dimensions and use \"keep_dims\" similar to reduce_sum to trigger that behaviour.", "body": "Have I written custom code? No\r\nOS Platform and Distribution? Win10\r\nTensorFlow installed from? pip\r\nTensorFlow version? 1.7\r\nBazel version? N/A\r\nCUDA/cuDNN version? N/A\r\nGPU model and memory? N/A\r\nExact command to reproduce: unsorted_segment_sum\r\n\r\n### Describe the problem\r\nLet's say you have 3 sequences of 12 values (shape (3,12)) with 5 segments and you have an input of shape (None,12,3) transposed to (3,12,None)\r\nusing any function with unsorted_segement_x the output will be (5,None).\r\n\r\nWould it be possible to have a function that does the same but still keep the first dimention.\r\nSomething equivalent to:\r\n```python\r\ninput.shape==(None,12,3)\r\nsegment.shape==(3,12)\r\n\r\noutputs=[]\r\nfor ix, val in enumerate(tf.unstack(input)):\r\n    ouputs.append(tf.unsorted_segment_sum(val,sequence[ix],5)\r\noutput=tf.stack(outputs)\r\noutput.shape==(3,5,None)\r\n```\r\nThe use of such a thing would be to iterate over a weighted input and without having to loop over the data or using reshape. I think this should be somewhat straightforward to implement; not concatenate together all the sequences for the superior dimensions and use \"keep_dims\" similar to reduce_sum to trigger that behaviour.\r\n\r\n\r\n\r\n"}