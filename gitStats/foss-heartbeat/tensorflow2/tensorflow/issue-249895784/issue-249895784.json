{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12252", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12252/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12252/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12252/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12252", "id": 249895784, "node_id": "MDU6SXNzdWUyNDk4OTU3ODQ=", "number": 12252, "title": "Cannot use mean_absolute_error", "user": {"login": "jmlipman", "id": 3540650, "node_id": "MDQ6VXNlcjM1NDA2NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/3540650?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jmlipman", "html_url": "https://github.com/jmlipman", "followers_url": "https://api.github.com/users/jmlipman/followers", "following_url": "https://api.github.com/users/jmlipman/following{/other_user}", "gists_url": "https://api.github.com/users/jmlipman/gists{/gist_id}", "starred_url": "https://api.github.com/users/jmlipman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jmlipman/subscriptions", "organizations_url": "https://api.github.com/users/jmlipman/orgs", "repos_url": "https://api.github.com/users/jmlipman/repos", "events_url": "https://api.github.com/users/jmlipman/events{/privacy}", "received_events_url": "https://api.github.com/users/jmlipman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-13T20:07:41Z", "updated_at": "2018-04-13T14:29:00Z", "closed_at": "2017-08-14T18:51:31Z", "author_association": "NONE", "body_html": "<p>I made a very simple neural network on tf and I wanted to use mean absolute error loss function, however I got this error right after I created the optimizer:</p>\n<p>No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [...] and loss Tensor(...)</p>\n<p>This is what I did:</p>\n<pre><code>cost = tf.metrics.mean_absolute_error(pred, y)[0]\noptimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)\n</code></pre>\n<p>I tried another loss function and it worked. In fact, I read that it's difficult to provide a gradient when the absolute value is involved, but I did exactly the same in Keras and it works. In fact, I also did the following (which is basically the mean absolute error) and it works as well!</p>\n<pre><code>cost = tf.reduce_mean(tf.abs(tf.subtract(pred, y)))\noptimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)\n</code></pre>\n<p>Why the function doesn't work?</p>\n<p>JM.</p>", "body_text": "I made a very simple neural network on tf and I wanted to use mean absolute error loss function, however I got this error right after I created the optimizer:\nNo gradients provided for any variable, check your graph for ops that do not support gradients, between variables [...] and loss Tensor(...)\nThis is what I did:\ncost = tf.metrics.mean_absolute_error(pred, y)[0]\noptimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)\n\nI tried another loss function and it worked. In fact, I read that it's difficult to provide a gradient when the absolute value is involved, but I did exactly the same in Keras and it works. In fact, I also did the following (which is basically the mean absolute error) and it works as well!\ncost = tf.reduce_mean(tf.abs(tf.subtract(pred, y)))\noptimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)\n\nWhy the function doesn't work?\nJM.", "body": "I made a very simple neural network on tf and I wanted to use mean absolute error loss function, however I got this error right after I created the optimizer:\r\n\r\nNo gradients provided for any variable, check your graph for ops that do not support gradients, between variables [...] and loss Tensor(...)\r\n\r\nThis is what I did:\r\n```\r\ncost = tf.metrics.mean_absolute_error(pred, y)[0]\r\noptimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)\r\n```\r\n\r\nI tried another loss function and it worked. In fact, I read that it's difficult to provide a gradient when the absolute value is involved, but I did exactly the same in Keras and it works. In fact, I also did the following (which is basically the mean absolute error) and it works as well!\r\n\r\n```\r\ncost = tf.reduce_mean(tf.abs(tf.subtract(pred, y)))\r\noptimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)\r\n```\r\n\r\nWhy the function doesn't work?\r\n\r\nJM.\r\n"}