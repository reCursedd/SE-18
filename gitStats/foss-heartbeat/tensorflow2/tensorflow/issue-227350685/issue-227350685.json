{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9793", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9793/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9793/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9793/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9793", "id": 227350685, "node_id": "MDU6SXNzdWUyMjczNTA2ODU=", "number": 9793, "title": "is model ready when Fine-tuning in distributed case", "user": {"login": "passerbydj", "id": 20178426, "node_id": "MDQ6VXNlcjIwMTc4NDI2", "avatar_url": "https://avatars1.githubusercontent.com/u/20178426?v=4", "gravatar_id": "", "url": "https://api.github.com/users/passerbydj", "html_url": "https://github.com/passerbydj", "followers_url": "https://api.github.com/users/passerbydj/followers", "following_url": "https://api.github.com/users/passerbydj/following{/other_user}", "gists_url": "https://api.github.com/users/passerbydj/gists{/gist_id}", "starred_url": "https://api.github.com/users/passerbydj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/passerbydj/subscriptions", "organizations_url": "https://api.github.com/users/passerbydj/orgs", "repos_url": "https://api.github.com/users/passerbydj/repos", "events_url": "https://api.github.com/users/passerbydj/events{/privacy}", "received_events_url": "https://api.github.com/users/passerbydj/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-05-09T12:34:15Z", "updated_at": "2018-01-02T06:50:46Z", "closed_at": "2017-05-09T15:45:54Z", "author_association": "NONE", "body_html": "<p>When we finetune a model on a different task, only a part of vars in the model are restored from the pretrained task and others are left as initial values.<br>\nAs many docs recommends(<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim\">page1</a> <a href=\"https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py\">page2</a>), when training with a local graph, we restore the pretrained model <strong>after</strong> running the global init op(call restoring in \"init_fn\" if MonitoredSession or supervisor is included).<br>\nBut in the distributed case, does global init op make \"model_ready\" returns true before the restoring-model called? other non-chief nodes will use the \"not ready\" values.</p>", "body_text": "When we finetune a model on a different task, only a part of vars in the model are restored from the pretrained task and others are left as initial values.\nAs many docs recommends(page1 page2), when training with a local graph, we restore the pretrained model after running the global init op(call restoring in \"init_fn\" if MonitoredSession or supervisor is included).\nBut in the distributed case, does global init op make \"model_ready\" returns true before the restoring-model called? other non-chief nodes will use the \"not ready\" values.", "body": "When we finetune a model on a different task, only a part of vars in the model are restored from the pretrained task and others are left as initial values.\r\nAs many docs recommends([page1](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) [page2](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py)), when training with a local graph, we restore the pretrained model **after** running the global init op(call restoring in \"init_fn\" if MonitoredSession or supervisor is included).\r\nBut in the distributed case, does global init op make \"model_ready\" returns true before the restoring-model called? other non-chief nodes will use the \"not ready\" values. \r\n\r\n"}