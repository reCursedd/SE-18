{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11002", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11002/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11002/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11002/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11002", "id": 238025067, "node_id": "MDU6SXNzdWUyMzgwMjUwNjc=", "number": 11002, "title": "`TF_AddGradients` incorrectly reports `Add` has no gradient ", "user": {"login": "malmaud", "id": 987837, "node_id": "MDQ6VXNlcjk4NzgzNw==", "avatar_url": "https://avatars1.githubusercontent.com/u/987837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/malmaud", "html_url": "https://github.com/malmaud", "followers_url": "https://api.github.com/users/malmaud/followers", "following_url": "https://api.github.com/users/malmaud/following{/other_user}", "gists_url": "https://api.github.com/users/malmaud/gists{/gist_id}", "starred_url": "https://api.github.com/users/malmaud/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/malmaud/subscriptions", "organizations_url": "https://api.github.com/users/malmaud/orgs", "repos_url": "https://api.github.com/users/malmaud/repos", "events_url": "https://api.github.com/users/malmaud/events{/privacy}", "received_events_url": "https://api.github.com/users/malmaud/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-06-23T02:35:56Z", "updated_at": "2017-06-23T19:51:58Z", "closed_at": "2017-06-23T19:51:58Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<p>OS X with a CPU libtensorflow.so built off master (<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/2336cdf7f00434c24f1eb394f255d7de071bdc08/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/2336cdf7f00434c24f1eb394f255d7de071bdc08\"><tt>2336cdf</tt></a>)</p>\n<h3>Describe the problem</h3>\n<p><code>TF_AddGradients</code> reports</p>\n<pre><code>No gradient defined for op: Add. Please see https://www.tensorflow.org/code/tensorflow/cc/gradients/README.md for instructions on how to add C++ gradients.\n</code></pre>\n<p>when asked to compute dz/dx for z=x+y (see code example).</p>\n<p>and yet <code>Add</code> has a <a href=\"https://github.com/tensorflow/tensorflow/blob/2336cdf7f00434c24f1eb394f255d7de071bdc08/tensorflow/core/ops/math_grad.cc#L372\">registered gradient</a>. <code>Mul</code> also doesn't work, although gradients of other operations (like <code>Sin</code>) do work.</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-c\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>c_api.h<span class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">void</span> <span class=\"pl-en\">check_status</span>(TF_Status* status) {\n  <span class=\"pl-k\">auto</span> code = <span class=\"pl-c1\">TF_GetCode</span>(status);\n  <span class=\"pl-k\">if</span> (code != TF_OK) {\n    cout&lt;&lt;<span class=\"pl-c1\">TF_Message</span>(status)&lt;&lt;endl;\n    <span class=\"pl-c1\">exit</span>(<span class=\"pl-c1\">0</span>);\n  }\n}\n\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>() {\n  <span class=\"pl-k\">auto</span> graph = <span class=\"pl-c1\">TF_NewGraph</span>();\n  <span class=\"pl-k\">auto</span> x_desc = <span class=\"pl-c1\">TF_NewOperation</span>(graph, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Placeholder<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x<span class=\"pl-pds\">\"</span></span>);\n  <span class=\"pl-c1\">TF_SetAttrType</span>(x_desc, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>dtype<span class=\"pl-pds\">\"</span></span>, TF_FLOAT);\n  <span class=\"pl-k\">auto</span> status = <span class=\"pl-c1\">TF_NewStatus</span>();\n  <span class=\"pl-k\">auto</span> x = <span class=\"pl-c1\">TF_FinishOperation</span>(x_desc, status);\n  <span class=\"pl-k\">auto</span> y_desc = <span class=\"pl-c1\">TF_NewOperation</span>(graph, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Placeholder<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>y<span class=\"pl-pds\">\"</span></span>);\n  <span class=\"pl-c1\">TF_SetAttrType</span>(y_desc, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>dtype<span class=\"pl-pds\">\"</span></span>, TF_FLOAT);\n  <span class=\"pl-k\">auto</span> y = <span class=\"pl-c1\">TF_FinishOperation</span>(y_desc, status);\n  <span class=\"pl-k\">auto</span> z_desc = <span class=\"pl-c1\">TF_NewOperation</span>(graph, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Add<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>z<span class=\"pl-pds\">\"</span></span>);\n  <span class=\"pl-c1\">TF_AddInput</span>(z_desc, {x, <span class=\"pl-c1\">0</span>});\n  <span class=\"pl-c1\">TF_AddInput</span>(z_desc, {y, <span class=\"pl-c1\">0</span>});\n  <span class=\"pl-k\">auto</span> z = <span class=\"pl-c1\">TF_FinishOperation</span>(z_desc, status);\n  TF_Output output = {z, <span class=\"pl-c1\">0</span>};\n  TF_Output input = {x, <span class=\"pl-c1\">0</span>};\n  TF_Output grad;\n  <span class=\"pl-c1\">TF_AddGradients</span>(graph, &amp;output, <span class=\"pl-c1\">1</span>, &amp;input, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">NULL</span>, status, &amp;grad);\n  <span class=\"pl-c1\">check_status</span>(status);\n  <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}\n</pre></div>", "body_text": "System information\nOS X with a CPU libtensorflow.so built off master (2336cdf)\nDescribe the problem\nTF_AddGradients reports\nNo gradient defined for op: Add. Please see https://www.tensorflow.org/code/tensorflow/cc/gradients/README.md for instructions on how to add C++ gradients.\n\nwhen asked to compute dz/dx for z=x+y (see code example).\nand yet Add has a registered gradient. Mul also doesn't work, although gradients of other operations (like Sin) do work.\nSource code / logs\n#include \"c_api.h\"\n\nvoid check_status(TF_Status* status) {\n  auto code = TF_GetCode(status);\n  if (code != TF_OK) {\n    cout<<TF_Message(status)<<endl;\n    exit(0);\n  }\n}\n\nint main() {\n  auto graph = TF_NewGraph();\n  auto x_desc = TF_NewOperation(graph, \"Placeholder\", \"x\");\n  TF_SetAttrType(x_desc, \"dtype\", TF_FLOAT);\n  auto status = TF_NewStatus();\n  auto x = TF_FinishOperation(x_desc, status);\n  auto y_desc = TF_NewOperation(graph, \"Placeholder\", \"y\");\n  TF_SetAttrType(y_desc, \"dtype\", TF_FLOAT);\n  auto y = TF_FinishOperation(y_desc, status);\n  auto z_desc = TF_NewOperation(graph, \"Add\", \"z\");\n  TF_AddInput(z_desc, {x, 0});\n  TF_AddInput(z_desc, {y, 0});\n  auto z = TF_FinishOperation(z_desc, status);\n  TF_Output output = {z, 0};\n  TF_Output input = {x, 0};\n  TF_Output grad;\n  TF_AddGradients(graph, &output, 1, &input, 1, NULL, status, &grad);\n  check_status(status);\n  return 0;\n}", "body": "### System information\r\n\r\nOS X with a CPU libtensorflow.so built off master (2336cdf)\r\n\r\n### Describe the problem\r\n\r\n`TF_AddGradients` reports \r\n\r\n```\r\nNo gradient defined for op: Add. Please see https://www.tensorflow.org/code/tensorflow/cc/gradients/README.md for instructions on how to add C++ gradients.\r\n```\r\n\r\nwhen asked to compute dz/dx for z=x+y (see code example). \r\n\r\nand yet `Add` has a [registered gradient](https://github.com/tensorflow/tensorflow/blob/2336cdf7f00434c24f1eb394f255d7de071bdc08/tensorflow/core/ops/math_grad.cc#L372). `Mul` also doesn't work, although gradients of other operations (like `Sin`) do work. \r\n\r\n\r\n### Source code / logs\r\n\r\n```c\r\n#include \"c_api.h\"\r\n\r\nvoid check_status(TF_Status* status) {\r\n  auto code = TF_GetCode(status);\r\n  if (code != TF_OK) {\r\n    cout<<TF_Message(status)<<endl;\r\n    exit(0);\r\n  }\r\n}\r\n\r\nint main() {\r\n  auto graph = TF_NewGraph();\r\n  auto x_desc = TF_NewOperation(graph, \"Placeholder\", \"x\");\r\n  TF_SetAttrType(x_desc, \"dtype\", TF_FLOAT);\r\n  auto status = TF_NewStatus();\r\n  auto x = TF_FinishOperation(x_desc, status);\r\n  auto y_desc = TF_NewOperation(graph, \"Placeholder\", \"y\");\r\n  TF_SetAttrType(y_desc, \"dtype\", TF_FLOAT);\r\n  auto y = TF_FinishOperation(y_desc, status);\r\n  auto z_desc = TF_NewOperation(graph, \"Add\", \"z\");\r\n  TF_AddInput(z_desc, {x, 0});\r\n  TF_AddInput(z_desc, {y, 0});\r\n  auto z = TF_FinishOperation(z_desc, status);\r\n  TF_Output output = {z, 0};\r\n  TF_Output input = {x, 0};\r\n  TF_Output grad;\r\n  TF_AddGradients(graph, &output, 1, &input, 1, NULL, status, &grad);\r\n  check_status(status);\r\n  return 0;\r\n}\r\n\r\n```"}