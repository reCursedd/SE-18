{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/196819777", "pull_request_review_id": 130444243, "id": 196819777, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjgxOTc3Nw==", "diff_hunk": "@@ -318,186 +123,694 @@ tensorflow::Status BuildNodeMap(\n }\n \n }  // namespace\n+\n+// Function to get calibration from ResourceMgr and put them into nodedef.\n tensorflow::Status ConvertCalibGraphToInferGraph(\n-    const tensorflow::GraphDef& graph_def, tensorflow::GraphDef* infer_graph) {\n+    const tensorflow::GraphDef& graph_def, tensorflow::GraphDef* infer_graph,\n+    bool is_dyn_op) {\n   VLOG(0) << \"Starting Calib Conversion\";\n-  tensorflow::Graph graph(tensorflow::OpRegistry::Global());\n-  TF_RETURN_IF_ERROR(tensorflow::ConvertGraphDefToGraph(\n-      tensorflow::GraphConstructorOptions(), graph_def, &graph));\n-  //  get calib nodes\n-  std::vector<tensorflow::Node*> calib_nodes;\n-  std::vector<tensorflow::Node*> topo_order;\n-  tensorflow::GetPostOrder(graph, &topo_order);\n-  for (auto rit = topo_order.rbegin(); rit != topo_order.rend(); ++rit) {\n-    auto node = *rit;\n-    if (node->type_string() == \"TRTCalibOp\") {\n-      VLOG(1) << \"Found Calib Node \" << node->name();\n-      calib_nodes.push_back(node);\n-    }\n+  infer_graph->CopyFrom(graph_def);\n+  auto trt_rm = TRTResourceManager::instance();\n+  auto calib_rm = trt_rm->getManager(\"TRTCalibration\");\n+  int num_nodes = infer_graph->node_size();\n+  if (!is_dyn_op) {\n+    LOG(WARNING) << \"Construction of static int8 engine is not implemented \"\n+                    \"yet!. Dynamic engine will be constructed\";\n   }\n-  VLOG(0) << \"Num Calib nodes in graph= \" << calib_nodes.size();\n-  if (calib_nodes.size() == 0)\n-    return tensorflow::errors::FailedPrecondition(\n-        \"Graph doesn't contain any calibration nodes!.\"\n-        \" Please generate calibration graph and run calibration first\");\n-  for (auto n : calib_nodes) {\n-    TF_RETURN_IF_ERROR(\n-        tensorrt::convert::ConvertCalibrationNodeToEngineNode(graph, n));\n+  for (int i = 0; i < num_nodes; ++i) {\n+    auto n = infer_graph->mutable_node(i);\n+    if (n->op() == \"TRTEngineOp\") {\n+      VLOG(1) << \"Processing \" << n->name();\n+      string container_name = n->attr().at(\"segment_funcdef_name\").s();\n+      TRTCalibrationResource* cres = nullptr;\n+      auto status = calib_rm->Lookup(container_name, \"Calibrator\", &cres);\n+      if (!status.ok()) {\n+        LOG(ERROR) << \"Could not get Calibration information. Did you run with \"\n+                      \"calibration data?\";\n+        return tensorflow::errors::FailedPrecondition(\n+            \"Need to run graph with calibration data first!\");\n+      }\n+      if (cres->calibrator_) {\n+        cres->calibrator_->setDone();\n+        cres->thr_->join();\n+        const auto& calibration_table =\n+            cres->calibrator_->getCalibrationTableAsString();\n+        if (!calibration_table.size()) {\n+          LOG(ERROR) << \"Calibration table is empty\";\n+          return tensorflow::errors::Unknown(\n+              \"Calibration table is missing. This shouldn't have happened!\");\n+        }\n+        n->mutable_attr()->at(\"calibration_data\").set_s(calibration_table);\n+      } else {\n+        LOG(ERROR) << \"Can't get TRTCalibrator from resource manager!\";\n+        return tensorflow::errors::Unknown(\n+            \"Can't get TRTCalibrator from resource manager!\");\n+      }\n+      cres->Unref();\n+    }\n   }\n-  graph.ToGraphDef(infer_graph);\n   return tensorflow::Status::OK();\n }\n \n+// Entry function from Python.\n tensorflow::Status ConvertGraphDefToTensorRT(\n     const tensorflow::GraphDef& graph_def,\n     const std::vector<string>& output_names, size_t max_batch_size,\n     size_t max_workspace_size_bytes, tensorflow::GraphDef* new_graph_def,\n-    int precision_mode = FP32MODE, int minimum_segment_size = 3) {\n+    int precision_mode, int minimum_segment_size, bool is_dyn_op,\n+    int max_cached_engines, std::vector<int> cached_engine_batches) {\n   // optimization pass\n   tensorflow::grappler::GrapplerItem item;\n   item.fetch = output_names;\n   item.graph = graph_def;\n-\n+  // grappler requires a virtual cluster with a proper GPU device\n+  // in order to calculate flops>0 or fails with FATAL\n+  // We add numbers from a Pascal card here to have flops>0\n   tensorflow::DeviceProperties device_properties;\n   device_properties.set_type(\"GPU\");\n   device_properties.mutable_environment()->insert({\"architecture\", \"6\"});\n-  tensorflow::grappler::Cluster* cluster =\n-      new tensorflow::grappler::VirtualCluster({{\"/GPU:0\", device_properties}});\n+  device_properties.set_num_cores(3584);\n+  device_properties.set_frequency(1531);\n+  std::unique_ptr<tensorflow::grappler::Cluster> cluster(\n+      new tensorflow::grappler::VirtualCluster(\n+          {{\"/GPU:0\", device_properties}}));\n \n   // single machine\n   int num_cpu_cores = tensorflow::grappler::GetNumAvailableLogicalCPUCores();\n   int num_gpus = tensorflow::grappler::GetNumAvailableGPUs();\n   VLOG(2) << \"cpu_cores: \" << num_cpu_cores;\n   VLOG(2) << \"gpus: \" << num_gpus;\n   tensorflow::RewriterConfig rw_cfg;\n+  // use only const folding and layout for the time being since new optimizers\n+  // break the graph for us\n+  rw_cfg.add_optimizers(\"constfold\");\n+  rw_cfg.add_optimizers(\"layout\");\n+  rw_cfg.set_meta_optimizer_iterations(tensorflow::RewriterConfig::ONE);\n   tensorflow::grappler::MetaOptimizer meta_opt(nullptr, rw_cfg);\n   tensorflow::GraphDef gdef;\n-  TF_RETURN_IF_ERROR(meta_opt.Optimize(cluster, item, &gdef));\n+  TF_RETURN_IF_ERROR(meta_opt.Optimize(cluster.get(), item, &gdef));\n   item.graph = gdef;\n \n   // AJ refactoring shape inference through grappler/GraphProperties.\n   tensorflow::grappler::GraphProperties static_graph_properties(item);\n   TF_RETURN_IF_ERROR(static_graph_properties.InferStatically(true));\n   // Build full graph\n-\n-  return ConvertAfterShapes(gdef, output_names, max_batch_size,\n-                            max_workspace_size_bytes, new_graph_def,\n-                            precision_mode, minimum_segment_size,\n-                            static_graph_properties, nullptr);\n+  ConversionParams cp;\n+  cp.input_graph_def = &gdef;\n+  cp.output_names = &output_names;\n+  cp.max_batch_size = max_batch_size;\n+  cp.output_graph_def = new_graph_def;\n+  cp.precision_mode = precision_mode;\n+  cp.is_dyn_op = is_dyn_op;\n+  cp.max_cached_engines = max_cached_engines;\n+  cp.cached_engine_batches = cached_engine_batches;\n+  cp.minimum_segment_size = minimum_segment_size;\n+  cp.graph_properties = &static_graph_properties;\n+  cp.max_workspace_size_bytes = max_workspace_size_bytes;\n+  if (VLOG_IS_ON(5)) {\n+    std::fstream f;\n+    f.open(\"TRTConversionInput.pb\",\n+           std::fstream::out | std::fstream::binary | std::fstream::trunc);\n+    f << gdef.SerializeAsString();\n+    f.close();\n+  }\n+  return ConvertAfterShapes(cp);\n }\n \n-tensorflow::Status ConvertAfterShapes(\n-    const tensorflow::GraphDef& gdef, const std::vector<string>& output_names,\n-    size_t max_batch_size, size_t max_workspace_size_bytes,\n-    tensorflow::GraphDef* new_graph_def, int precision_mode,\n-    int minimum_segment_size,\n+// Function to get subsegment information structure.\n+EngineInfo GetEngineInfo(\n+    const tensorflow::Graph* g,\n     const tensorflow::grappler::GraphProperties& graph_properties,\n-    const tensorflow::grappler::Cluster* cluster) {\n-  // Segment the graph into subgraphs that can be converted to TensorRT\n-  tensorflow::tensorrt::segment::SegmentOptions segment_options;\n+    const std::set<string>& segment_nodes,\n+    const std::unordered_map<string, tensorflow::Node*>& node_map,\n+    const std::vector<tensorflow::Node*>& reverse_topo_order) {", "path": "tensorflow/contrib/tensorrt/convert/convert_graph.cc", "position": null, "original_position": 463, "commit_id": "4631936e61651101932073197c08b600006530a3", "original_commit_id": "520384df634f64cb6d803884f5f0c9462a6ef9fd", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "As discussed, this is really reverse_topo_order.", "created_at": "2018-06-20T15:08:40Z", "updated_at": "2018-06-21T22:23:15Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19871#discussion_r196819777", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19871", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/196819777"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19871#discussion_r196819777"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19871"}}, "body_html": "<p>As discussed, this is really reverse_topo_order.</p>", "body_text": "As discussed, this is really reverse_topo_order.", "in_reply_to_id": 196565662}