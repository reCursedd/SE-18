{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/195785181", "pull_request_review_id": 128899486, "id": 195785181, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NTc4NTE4MQ==", "diff_hunk": "@@ -692,16 +714,67 @@ tensorflow::Status ConvertAfterShapes(ConversionParams& params) {\n           cuda_device_id = cuda_gpu_id.value();\n         }\n         tensorflow::GPUOptions gpuoptions;\n-        // we need to us PM here since in python path there is no way to get\n-        // to allocators\n-        auto pm = tensorflow::ProcessState::singleton();\n         // this should be instantiated by now\n         auto dev_allocator = pm->GetGPUAllocator(gpuoptions, tf_gpu_id, 1);\n         VLOG(1) << \"Got an allocator for device tf_device=\" << tf_gpu_id.value()\n                 << \" cuda device= \" << cuda_device_id << \" at \"\n                 << dev_allocator;\n         alloc.reset(new TRTDeviceAllocator(dev_allocator));\n       }\n+    } else {\n+      int found_device = 0;\n+      bool try_gpu_ids = true;\n+      auto checkDeviceId = [](int tfid) -> int {\n+        tensorflow::TfGpuId tf_gpu_id(tfid);\n+        CudaGpuId cuda_gpu_id;\n+        Status s = GpuIdManager::TfToCudaGpuId(tf_gpu_id, &cuda_gpu_id);\n+        if (s.ok()) {\n+          VLOG(1) << \"Found TF GPU \" << tf_gpu_id.value() << \" at cuda device \"\n+                  << cuda_gpu_id.value();\n+          return cuda_gpu_id.value();\n+        }\n+        VLOG(2) << \"TF GPU with id \" << tfid << \" do not exist \" << s;\n+        return -1;\n+      };\n+      // if device is set, try to find the device. Might be a problem for multi\n+      // host case but TensorRT do not support multi host setups yet.\n+      if (!engine.device.empty()) {\n+        auto res = str_util::Split(engine.device, \":\");", "path": "tensorflow/contrib/tensorrt/convert/convert_graph.cc", "position": null, "original_position": 130, "commit_id": "4631936e61651101932073197c08b600006530a3", "original_commit_id": "99d2d13592a78d2eac5b90fced60a2cd562bed85", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "Please use [DeviceNameUtils::ParseFullName](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/device_name_utils.h#L89)", "created_at": "2018-06-15T15:56:13Z", "updated_at": "2018-06-21T22:23:15Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19871#discussion_r195785181", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19871", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/195785181"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19871#discussion_r195785181"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19871"}}, "body_html": "<p>Please use <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/device_name_utils.h#L89\">DeviceNameUtils::ParseFullName</a></p>", "body_text": "Please use DeviceNameUtils::ParseFullName"}