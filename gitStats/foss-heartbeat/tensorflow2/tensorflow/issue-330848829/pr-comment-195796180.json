{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/195796180", "pull_request_review_id": 129236463, "id": 195796180, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NTc5NjE4MA==", "diff_hunk": "@@ -417,87 +639,160 @@ tensorflow::Status ConvertAfterShapes(\n   std::unordered_map<string, tensorflow::Node*> node_map;\n   TF_RETURN_IF_ERROR(BuildNodeMap(graph, &node_map));\n   std::unordered_map<string, std::pair<int, string>> output_edge_map;\n-  int count = 0;\n   float total_num_nodes_in_segments = 0.;\n-  for (auto s : segments) {\n+  std::vector<EngineInfo> engine_segments;\n+  engine_segments.reserve(segments.size());\n+  std::vector<tensorflow::Node*> topo_order;\n+  tensorflow::GetPostOrder(graph, &topo_order);\n+  size_t total_engine_size = 0;\n+  std::vector<size_t> engine_sizes;\n+  for (size_t t = 0; t < segments.size(); t++) {\n+    auto& s = segments.at(t);\n+    engine_segments.emplace_back(GetEngineInfo(&graph, *params.graph_properties,\n+                                               s.first, node_map, topo_order));\n+    auto& curr_engine = engine_segments.back();\n+    curr_engine.precision_mode = params.precision_mode;\n+    engine_sizes.push_back(curr_engine.segment_graph_def.ByteSizeLong());\n+    curr_engine.engine_type =\n+        (params.is_dyn_op || params.precision_mode == INT8MODE\n+             ? EngineInfo::EngineType::TRTDynamic\n+             : EngineInfo::EngineType::TRTStatic);\n+    curr_engine.cached_engine_batches = params.cached_engine_batches;\n+    curr_engine.maximum_cached_engines = params.max_cached_engines;\n+    total_engine_size += engine_sizes.back();\n     total_num_nodes_in_segments += s.first.size();\n-  }\n-  // We create the map here since cluster may not be available in all cases.\n-  std::map<string, tensorflow::Device*> name_to_device_map;\n-  if (cluster) {\n-    // TODO(aaroey): consider using DeviceSet::FindDeviceByName(), as in a\n-    // distributed environment, devices from different workers can have same\n-    // short name.\n-    for (const auto dm : cluster->GetDeviceSet()->devices()) {\n-      name_to_device_map[dm->name()] = dm;\n+    StrAppend(&curr_engine.engine_name, \"my_trt_op_\", t);\n+    RegisterSegmentFunctionToFunctionLibrary(\n+        &graph, curr_engine.segment_graph_def, curr_engine.engine_name);\n+    if (VLOG_IS_ON(8)) {\n+      string fname = curr_engine.engine_name;\n+      StrAppend(&fname, \".pb\");\n+      std::fstream f;\n+      f.open(fname.c_str(), std::fstream::out | std::fstream::binary);\n+      f << engine_segments.at(t).segment_graph_def.SerializeAsString();\n+      f.close();\n     }\n   }\n-  for (const auto& segment_nodes_and_device : segments) {\n-    const std::set<string>& subgraph_node_names =\n-        segment_nodes_and_device.first;\n-    std::set<int> subgraph_node_ids;\n-    size_t max_mem_per_engine =\n-        max_workspace_size_bytes *\n-        ((float)subgraph_node_names.size() / total_num_nodes_in_segments);\n-    std::stringstream oss;\n-    for (const string& node_name : subgraph_node_names) {\n-      oss << \" \" << node_name;\n-      subgraph_node_ids.insert(node_map.at(node_name)->id());\n-    }\n-    VLOG(1) << \"Subgraph nodes at device \" << segment_nodes_and_device.second\n-            << \" : \" << oss.str();\n-    auto target_device =\n-        name_to_device_map.find(segment_nodes_and_device.second);\n-    std::shared_ptr<nvinfer1::IGpuAllocator> allocator(0);\n-\n+  std::vector<tensorflow::NodeDef*> trt_nodes;\n+  trt_nodes.reserve(engine_segments.size());\n+  int old_cuda_device = 0;\n+  auto err = cudaGetDevice(&old_cuda_device);\n+  if (err != cudaSuccess) {\n+    LOG(ERROR) << \"Couldn't get current device error is \"\n+               << cudaGetErrorString(err);\n+  }\n+  VLOG(1) << \"Current cuda device is \" << old_cuda_device;\n+  for (int i = 0; i < engine_segments.size(); ++i) {\n+    auto trt_node = new tensorflow::NodeDef;\n+    trt_nodes.push_back(trt_node);\n+    auto& engine = engine_segments.at(i);\n+    // Partition the workspace size by the average of node ratio and segment\n+    // graphdef size\n+    engine.max_workspace_size_bytes =\n+        params.max_workspace_size_bytes *\n+        (engine_sizes.at(i) / total_engine_size +\n+         segments.at(i).first.size() / total_num_nodes_in_segments) /\n+        2.0;\n+    std::shared_ptr<nvinfer1::IGpuAllocator> alloc;\n     int cuda_device_id = 0;\n-    if (target_device != name_to_device_map.end()) {\n-      tensorflow::TfGpuId tf_gpu_id(target_device->second->parsed_name().id);\n-      CudaGpuId cuda_gpu_id;\n-      Status s = GpuIdManager::TfToCudaGpuId(tf_gpu_id, &cuda_gpu_id);\n-      if (!s.ok()) {\n-        LOG(ERROR)\n-            << \"Cuda device identification failed, using device 0. Error= \"\n-            << s;\n-      } else {\n-        cuda_device_id = cuda_gpu_id.value();\n+    // we need to us PM here since in python path there is no way to get\n+    // to allocators\n+    auto pm = tensorflow::ProcessState::singleton();\n+    if (params.cluster) {  // get allocator\n+      const auto device =\n+          params.cluster->GetDeviceSet()->FindDeviceByName(engine.device);", "path": "tensorflow/contrib/tensorrt/convert/convert_graph.cc", "position": null, "original_position": 957, "commit_id": "4631936e61651101932073197c08b600006530a3", "original_commit_id": "99d2d13592a78d2eac5b90fced60a2cd562bed85", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "Please make sure GetDeviceSet() is not null before using.", "created_at": "2018-06-15T16:25:39Z", "updated_at": "2018-06-21T22:23:15Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19871#discussion_r195796180", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19871", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/195796180"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19871#discussion_r195796180"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19871"}}, "body_html": "<p>Please make sure GetDeviceSet() is not null before using.</p>", "body_text": "Please make sure GetDeviceSet() is not null before using."}