{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/195846437", "pull_request_review_id": 129298115, "id": 195846437, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NTg0NjQzNw==", "diff_hunk": "@@ -692,16 +714,67 @@ tensorflow::Status ConvertAfterShapes(ConversionParams& params) {\n           cuda_device_id = cuda_gpu_id.value();\n         }\n         tensorflow::GPUOptions gpuoptions;\n-        // we need to us PM here since in python path there is no way to get\n-        // to allocators\n-        auto pm = tensorflow::ProcessState::singleton();\n         // this should be instantiated by now\n         auto dev_allocator = pm->GetGPUAllocator(gpuoptions, tf_gpu_id, 1);\n         VLOG(1) << \"Got an allocator for device tf_device=\" << tf_gpu_id.value()\n                 << \" cuda device= \" << cuda_device_id << \" at \"\n                 << dev_allocator;\n         alloc.reset(new TRTDeviceAllocator(dev_allocator));\n       }\n+    } else {\n+      int found_device = 0;\n+      bool try_gpu_ids = true;\n+      auto checkDeviceId = [](int tfid) -> int {\n+        tensorflow::TfGpuId tf_gpu_id(tfid);\n+        CudaGpuId cuda_gpu_id;\n+        Status s = GpuIdManager::TfToCudaGpuId(tf_gpu_id, &cuda_gpu_id);\n+        if (s.ok()) {\n+          VLOG(1) << \"Found TF GPU \" << tf_gpu_id.value() << \" at cuda device \"\n+                  << cuda_gpu_id.value();\n+          return cuda_gpu_id.value();\n+        }\n+        VLOG(2) << \"TF GPU with id \" << tfid << \" do not exist \" << s;\n+        return -1;\n+      };\n+      // if device is set, try to find the device. Might be a problem for multi\n+      // host case but TensorRT do not support multi host setups yet.\n+      if (!engine.device.empty()) {\n+        auto res = str_util::Split(engine.device, \":\");\n+        if (res.size() > 0) {\n+          tensorflow::StringPiece s(res.back());\n+          tensorflow::str_util::RemoveWhitespaceContext(&s);\n+          uint64 dev_id = 0;\n+          if (str_util::ConsumeLeadingDigits(&s, &dev_id)) {\n+            found_device = dev_id;\n+            cuda_device_id = checkDeviceId(found_device);\n+            if (cuda_device_id >= 0) try_gpu_ids = false;\n+          }\n+        }\n+      }\n+      if (try_gpu_ids) {\n+        while (found_device < 100) {\n+          cuda_device_id = checkDeviceId(found_device);\n+          if (cuda_device_id >= 0) {\n+            break;\n+          }\n+          found_device++;\n+        }\n+      }\n+      if (found_device == 100) {\n+        LOG(ERROR) << \" Can't find a GPU device to work with. Please \"\n+                      \"instantiate a session to initialize devices\";\n+        return tensorflow::errors::NotFound(\n+            \"Can't find a GPU device to work with\");\n+      }\n+      LOG(WARNING)\n+          << \"Can't determine the device constructing an allocator at device \"\n+          << found_device;\n+      tensorflow::GPUOptions gpuoptions;", "path": "tensorflow/contrib/tensorrt/convert/convert_graph.cc", "position": null, "original_position": 160, "commit_id": "4631936e61651101932073197c08b600006530a3", "original_commit_id": "99d2d13592a78d2eac5b90fced60a2cd562bed85", "user": {"login": "samikama", "id": 10539540, "node_id": "MDQ6VXNlcjEwNTM5NTQw", "avatar_url": "https://avatars0.githubusercontent.com/u/10539540?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samikama", "html_url": "https://github.com/samikama", "followers_url": "https://api.github.com/users/samikama/followers", "following_url": "https://api.github.com/users/samikama/following{/other_user}", "gists_url": "https://api.github.com/users/samikama/gists{/gist_id}", "starred_url": "https://api.github.com/users/samikama/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samikama/subscriptions", "organizations_url": "https://api.github.com/users/samikama/orgs", "repos_url": "https://api.github.com/users/samikama/repos", "events_url": "https://api.github.com/users/samikama/events{/privacy}", "received_events_url": "https://api.github.com/users/samikama/received_events", "type": "User", "site_admin": false}, "body": ">Also, GetGPUAllocator accepts a TfGpuId whose value is NOT the device id, \r\n\r\nI doubt it since device is choosen by querying the GpuIdManager::TfToCudaGpuId(tf_gpu_id, &cuda_gpu_id); and process manager uses the same function to map between tf and cuda gpu ids.\r\n\r\n>And, with the cluster problem in OptimizeGraph() fixed, I think we don't need this path any more as we can always get the device.\r\n\r\nIs this available right now?\r\n", "created_at": "2018-06-15T19:55:02Z", "updated_at": "2018-06-21T22:23:15Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19871#discussion_r195846437", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19871", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/195846437"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19871#discussion_r195846437"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19871"}}, "body_html": "<blockquote>\n<p>Also, GetGPUAllocator accepts a TfGpuId whose value is NOT the device id,</p>\n</blockquote>\n<p>I doubt it since device is choosen by querying the GpuIdManager::TfToCudaGpuId(tf_gpu_id, &amp;cuda_gpu_id); and process manager uses the same function to map between tf and cuda gpu ids.</p>\n<blockquote>\n<p>And, with the cluster problem in OptimizeGraph() fixed, I think we don't need this path any more as we can always get the device.</p>\n</blockquote>\n<p>Is this available right now?</p>", "body_text": "Also, GetGPUAllocator accepts a TfGpuId whose value is NOT the device id,\n\nI doubt it since device is choosen by querying the GpuIdManager::TfToCudaGpuId(tf_gpu_id, &cuda_gpu_id); and process manager uses the same function to map between tf and cuda gpu ids.\n\nAnd, with the cluster problem in OptimizeGraph() fixed, I think we don't need this path any more as we can always get the device.\n\nIs this available right now?", "in_reply_to_id": 195787798}