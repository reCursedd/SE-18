{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/411604897", "html_url": "https://github.com/tensorflow/tensorflow/issues/21476#issuecomment-411604897", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21476", "id": 411604897, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTYwNDg5Nw==", "user": {"login": "baluyotraf", "id": 7478783, "node_id": "MDQ6VXNlcjc0Nzg3ODM=", "avatar_url": "https://avatars1.githubusercontent.com/u/7478783?v=4", "gravatar_id": "", "url": "https://api.github.com/users/baluyotraf", "html_url": "https://github.com/baluyotraf", "followers_url": "https://api.github.com/users/baluyotraf/followers", "following_url": "https://api.github.com/users/baluyotraf/following{/other_user}", "gists_url": "https://api.github.com/users/baluyotraf/gists{/gist_id}", "starred_url": "https://api.github.com/users/baluyotraf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/baluyotraf/subscriptions", "organizations_url": "https://api.github.com/users/baluyotraf/orgs", "repos_url": "https://api.github.com/users/baluyotraf/repos", "events_url": "https://api.github.com/users/baluyotraf/events{/privacy}", "received_events_url": "https://api.github.com/users/baluyotraf/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-09T01:11:09Z", "updated_at": "2018-08-09T01:16:50Z", "author_association": "NONE", "body_html": "<p>I'm using the low level tensorflow API. As recommended I create 3 graphs for training, evaluation, and inference and I'm using the Dataset APIs to load my data.</p>\n<p>If we are working with model inputs with similar lengths or dimension, you can do this.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> x and y are uniformly sized numpy arrays</span>\ndataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices((x, y), <span class=\"pl-c1\">...</span>)\ndataset <span class=\"pl-k\">=</span> dataset.map(<span class=\"pl-c1\">...</span>)\ndataset <span class=\"pl-k\">=</span> dataset.padded_batch(<span class=\"pl-c1\">...</span>)\niterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\ninputs <span class=\"pl-k\">=</span> iterator.get_next()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> training graph</span>\ncreate_training_graph(inputs)</pre></div>\n<p>For inference, you can simply remove y and replace x with a placeholder so you can give the data to the network as feed dict.</p>\n<p>When working with data with difference input lengths (text, and other sequences), most of the issues posted here that I've seen recommend to use generators</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Creating a generator since sequence lengths are different</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">data_generator</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>):\n    <span class=\"pl-c1\">...</span>\n\ndataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_generator(data_generator(x, y), <span class=\"pl-c1\">...</span>)\ndataset <span class=\"pl-k\">=</span> dataset.map(<span class=\"pl-c1\">...</span>)\ndataset <span class=\"pl-k\">=</span> dataset.padded_batch(<span class=\"pl-c1\">...</span>)\niterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\ninputs <span class=\"pl-k\">=</span> iterator.get_next()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> training graph</span>\ncreate_training_graph(inputs)</pre></div>\n<p>In this case, how do we try to add the placeholders in order to perform inference without making a large changes in the dataset pre-processing?</p>", "body_text": "I'm using the low level tensorflow API. As recommended I create 3 graphs for training, evaluation, and inference and I'm using the Dataset APIs to load my data.\nIf we are working with model inputs with similar lengths or dimension, you can do this.\n# x and y are uniformly sized numpy arrays\ndataset = tf.data.Dataset.from_tensor_slices((x, y), ...)\ndataset = dataset.map(...)\ndataset = dataset.padded_batch(...)\niterator = dataset.make_one_shot_iterator()\ninputs = iterator.get_next()\n\n# training graph\ncreate_training_graph(inputs)\nFor inference, you can simply remove y and replace x with a placeholder so you can give the data to the network as feed dict.\nWhen working with data with difference input lengths (text, and other sequences), most of the issues posted here that I've seen recommend to use generators\n# Creating a generator since sequence lengths are different\ndef data_generator(x, y):\n    ...\n\ndataset = tf.data.Dataset.from_generator(data_generator(x, y), ...)\ndataset = dataset.map(...)\ndataset = dataset.padded_batch(...)\niterator = dataset.make_one_shot_iterator()\ninputs = iterator.get_next()\n\n# training graph\ncreate_training_graph(inputs)\nIn this case, how do we try to add the placeholders in order to perform inference without making a large changes in the dataset pre-processing?", "body": "I'm using the low level tensorflow API. As recommended I create 3 graphs for training, evaluation, and inference and I'm using the Dataset APIs to load my data.\r\n\r\nIf we are working with model inputs with similar lengths or dimension, you can do this.\r\n\r\n```python\r\n# x and y are uniformly sized numpy arrays\r\ndataset = tf.data.Dataset.from_tensor_slices((x, y), ...)\r\ndataset = dataset.map(...)\r\ndataset = dataset.padded_batch(...)\r\niterator = dataset.make_one_shot_iterator()\r\ninputs = iterator.get_next()\r\n\r\n# training graph\r\ncreate_training_graph(inputs)\r\n```\r\n\r\nFor inference, you can simply remove y and replace x with a placeholder so you can give the data to the network as feed dict.\r\n\r\nWhen working with data with difference input lengths (text, and other sequences), most of the issues posted here that I've seen recommend to use generators\r\n\r\n```python\r\n# Creating a generator since sequence lengths are different\r\ndef data_generator(x, y):\r\n    ...\r\n\r\ndataset = tf.data.Dataset.from_generator(data_generator(x, y), ...)\r\ndataset = dataset.map(...)\r\ndataset = dataset.padded_batch(...)\r\niterator = dataset.make_one_shot_iterator()\r\ninputs = iterator.get_next()\r\n\r\n# training graph\r\ncreate_training_graph(inputs)\r\n```\r\n\r\nIn this case, how do we try to add the placeholders in order to perform inference without making a large changes in the dataset pre-processing?"}