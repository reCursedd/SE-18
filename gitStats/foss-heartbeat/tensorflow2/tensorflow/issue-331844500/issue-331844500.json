{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19969", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19969/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19969/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19969/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19969", "id": 331844500, "node_id": "MDU6SXNzdWUzMzE4NDQ1MDA=", "number": 19969, "title": "Is there a way to load a TF graph just once, and run it multiple times?", "user": {"login": "sekharvth", "id": 37143160, "node_id": "MDQ6VXNlcjM3MTQzMTYw", "avatar_url": "https://avatars3.githubusercontent.com/u/37143160?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sekharvth", "html_url": "https://github.com/sekharvth", "followers_url": "https://api.github.com/users/sekharvth/followers", "following_url": "https://api.github.com/users/sekharvth/following{/other_user}", "gists_url": "https://api.github.com/users/sekharvth/gists{/gist_id}", "starred_url": "https://api.github.com/users/sekharvth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sekharvth/subscriptions", "organizations_url": "https://api.github.com/users/sekharvth/orgs", "repos_url": "https://api.github.com/users/sekharvth/repos", "events_url": "https://api.github.com/users/sekharvth/events{/privacy}", "received_events_url": "https://api.github.com/users/sekharvth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-06-13T05:15:07Z", "updated_at": "2018-10-13T11:41:10Z", "closed_at": "2018-10-13T11:41:10Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n</ul>\n<p>Yes</p>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n</ul>\n<p>Windows 10 Home, running TF on Colab and on VM on GCP.</p>\n<ul>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n</ul>\n<p>Binary</p>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n</ul>\n<p>1.8.0</p>\n<ul>\n<li><strong>Python version</strong>:</li>\n</ul>\n<p>3.6.5</p>\n<ul>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: Tesla K80, 12 GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I have a TF model that was saved with the tf.train.Saver class, and so I have the .meta file, the data-00000-of-00001 file, the index file and the checkpoint file.</p>\n<p>I use it for inference like this :</p>\n<pre><code>    graph_num = tf.Graph()\n    with graph_num.as_default():\n        sess = tf.Session()\n        with sess.as_default():\n\n            new_saver = tf.train.import_meta_graph('{}.meta'.format(model_path), clear_devices=True)\n            new_saver.restore(sess, ('{}'.format(model_path)))\n            sess.run(tf.tables_initializer())\n\n            arr_placeholder = graph_num.get_operation_by_name('arr_placeholder/inp_array').outputs[0]\n            str_placeholder = graph_num.get_operation_by_name('str_placeholder/inp_string').outputs[0]\n            dropout_keep_prob = graph_num.get_operation_by_name('dropout_keep_prob/keep_prob').outputs[0]\n\n            logis = graph_num.get_tensor_by_name('logits/preds/BiasAdd:0')\n\n            def model_api(input_data):\n                # ...preprocessing the input_data...\n\n                a = sess.run(tf.nn.softmax(logis),\n                             feed_dict={\n                                 arr_placeholder:\n                                     np.array(list_of_primary_inputs).reshape(len(list_of_primary_inputs), 142),\n                                 dropout_keep_prob: 1.0, str_placeholder: input_string\n                             })\n\n                return a\n</code></pre>\n<p>So far so good, but then I call the function like this:</p>\n<pre><code>tf.reset_default_graph()\nresult = model_api(test_input_data)\n</code></pre>\n<p>and each time I call it, it gives me different results for the same test data.</p>\n<p>But when I instantiate the graph again and then call the function, it gives me the same numbers.</p>\n<p>This behaviour is rather odd, and I don't want to re load the graph every time I want to pass in a new instance(s).</p>\n<p>I can't use a for loop within the session, because the instances to be predicted come in real time, and so I have to use a function that supports arguments.</p>\n<p>I saw this post too : <a href=\"https://stackoverflow.com/questions/42124000/reuse-graph-and-use-it-multiple-times\" rel=\"nofollow\">https://stackoverflow.com/questions/42124000/reuse-graph-and-use-it-multiple-times</a> but that wasn't helping my case.</p>\n<p>I tried freezing the graph ( converting the existing meta graph into .pb ) but that too was giving me an error with one of the lookup tables that I have. And that is filed as a separate issue on GitHub, and unfortunately the workaround mentioned there didn't work for me. That issue is still open : <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"216501380\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8665\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8665/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/8665\">#8665</a></p>\n<p>I have even set tf.set_random_seed to a constant value while training, and tried doing the same to the inference part as well, but to no avail.</p>\n<p>So right now I'm at my wits end.</p>\n<p>I have asked this question on SO ( <a href=\"https://stackoverflow.com/questions/50812641/load-a-tensorflow-graph-once-and-use-it-multiple-times\" rel=\"nofollow\">https://stackoverflow.com/questions/50812641/load-a-tensorflow-graph-once-and-use-it-multiple-times</a> ) too, but that hasn't been helpful.</p>\n<p>Why does it give me different results each time? And is there a way to load the graph once, and then keep running new instances without running into this issue of inconsistent outputs?</p>\n<p>I couldn't find such a query while researching on this topic, so if there is currently no way to load a graph and run it multiple times all the while producing consistent outputs, can this be considered a feature request?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nYes\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n\nWindows 10 Home, running TF on Colab and on VM on GCP.\n\nTensorFlow installed from (source or binary):\n\nBinary\n\nTensorFlow version (use command below):\n\n1.8.0\n\nPython version:\n\n3.6.5\n\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: Tesla K80, 12 GB\nExact command to reproduce:\n\nDescribe the problem\nI have a TF model that was saved with the tf.train.Saver class, and so I have the .meta file, the data-00000-of-00001 file, the index file and the checkpoint file.\nI use it for inference like this :\n    graph_num = tf.Graph()\n    with graph_num.as_default():\n        sess = tf.Session()\n        with sess.as_default():\n\n            new_saver = tf.train.import_meta_graph('{}.meta'.format(model_path), clear_devices=True)\n            new_saver.restore(sess, ('{}'.format(model_path)))\n            sess.run(tf.tables_initializer())\n\n            arr_placeholder = graph_num.get_operation_by_name('arr_placeholder/inp_array').outputs[0]\n            str_placeholder = graph_num.get_operation_by_name('str_placeholder/inp_string').outputs[0]\n            dropout_keep_prob = graph_num.get_operation_by_name('dropout_keep_prob/keep_prob').outputs[0]\n\n            logis = graph_num.get_tensor_by_name('logits/preds/BiasAdd:0')\n\n            def model_api(input_data):\n                # ...preprocessing the input_data...\n\n                a = sess.run(tf.nn.softmax(logis),\n                             feed_dict={\n                                 arr_placeholder:\n                                     np.array(list_of_primary_inputs).reshape(len(list_of_primary_inputs), 142),\n                                 dropout_keep_prob: 1.0, str_placeholder: input_string\n                             })\n\n                return a\n\nSo far so good, but then I call the function like this:\ntf.reset_default_graph()\nresult = model_api(test_input_data)\n\nand each time I call it, it gives me different results for the same test data.\nBut when I instantiate the graph again and then call the function, it gives me the same numbers.\nThis behaviour is rather odd, and I don't want to re load the graph every time I want to pass in a new instance(s).\nI can't use a for loop within the session, because the instances to be predicted come in real time, and so I have to use a function that supports arguments.\nI saw this post too : https://stackoverflow.com/questions/42124000/reuse-graph-and-use-it-multiple-times but that wasn't helping my case.\nI tried freezing the graph ( converting the existing meta graph into .pb ) but that too was giving me an error with one of the lookup tables that I have. And that is filed as a separate issue on GitHub, and unfortunately the workaround mentioned there didn't work for me. That issue is still open : #8665\nI have even set tf.set_random_seed to a constant value while training, and tried doing the same to the inference part as well, but to no avail.\nSo right now I'm at my wits end.\nI have asked this question on SO ( https://stackoverflow.com/questions/50812641/load-a-tensorflow-graph-once-and-use-it-multiple-times ) too, but that hasn't been helpful.\nWhy does it give me different results each time? And is there a way to load the graph once, and then keep running new instances without running into this issue of inconsistent outputs?\nI couldn't find such a query while researching on this topic, so if there is currently no way to load a graph and run it multiple times all the while producing consistent outputs, can this be considered a feature request?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\n\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nWindows 10 Home, running TF on Colab and on VM on GCP.\r\n\r\n- **TensorFlow installed from (source or binary)**: \r\n\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n\r\n1.8.0\r\n- **Python version**: \r\n\r\n3.6.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: Tesla K80, 12 GB\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\n\r\nI have a TF model that was saved with the tf.train.Saver class, and so I have the .meta file, the data-00000-of-00001 file, the index file and the checkpoint file.\r\n\r\nI use it for inference like this :\r\n\r\n```\r\n    graph_num = tf.Graph()\r\n    with graph_num.as_default():\r\n        sess = tf.Session()\r\n        with sess.as_default():\r\n\r\n            new_saver = tf.train.import_meta_graph('{}.meta'.format(model_path), clear_devices=True)\r\n            new_saver.restore(sess, ('{}'.format(model_path)))\r\n            sess.run(tf.tables_initializer())\r\n\r\n            arr_placeholder = graph_num.get_operation_by_name('arr_placeholder/inp_array').outputs[0]\r\n            str_placeholder = graph_num.get_operation_by_name('str_placeholder/inp_string').outputs[0]\r\n            dropout_keep_prob = graph_num.get_operation_by_name('dropout_keep_prob/keep_prob').outputs[0]\r\n\r\n            logis = graph_num.get_tensor_by_name('logits/preds/BiasAdd:0')\r\n\r\n            def model_api(input_data):\r\n                # ...preprocessing the input_data...\r\n\r\n                a = sess.run(tf.nn.softmax(logis),\r\n                             feed_dict={\r\n                                 arr_placeholder:\r\n                                     np.array(list_of_primary_inputs).reshape(len(list_of_primary_inputs), 142),\r\n                                 dropout_keep_prob: 1.0, str_placeholder: input_string\r\n                             })\r\n\r\n                return a\r\n```\r\n\r\nSo far so good, but then I call the function like this: \r\n\r\n```\r\ntf.reset_default_graph()\r\nresult = model_api(test_input_data)\r\n```\r\nand each time I call it, it gives me different results for the same test data.\r\n\r\nBut when I instantiate the graph again and then call the function, it gives me the same numbers.\r\n\r\nThis behaviour is rather odd, and I don't want to re load the graph every time I want to pass in a new instance(s).\r\n\r\nI can't use a for loop within the session, because the instances to be predicted come in real time, and so I have to use a function that supports arguments.\r\n\r\nI saw this post too : https://stackoverflow.com/questions/42124000/reuse-graph-and-use-it-multiple-times but that wasn't helping my case.\r\n\r\nI tried freezing the graph ( converting the existing meta graph into .pb ) but that too was giving me an error with one of the lookup tables that I have. And that is filed as a separate issue on GitHub, and unfortunately the workaround mentioned there didn't work for me. That issue is still open : https://github.com/tensorflow/tensorflow/issues/8665\r\n\r\nI have even set tf.set_random_seed to a constant value while training, and tried doing the same to the inference part as well, but to no avail.\r\n\r\nSo right now I'm at my wits end.\r\n\r\n\r\nI have asked this question on SO ( https://stackoverflow.com/questions/50812641/load-a-tensorflow-graph-once-and-use-it-multiple-times ) too, but that hasn't been helpful.\r\n\r\nWhy does it give me different results each time? And is there a way to load the graph once, and then keep running new instances without running into this issue of inconsistent outputs?\r\n\r\nI couldn't find such a query while researching on this topic, so if there is currently no way to load a graph and run it multiple times all the while producing consistent outputs, can this be considered a feature request?\r\n\r\n"}