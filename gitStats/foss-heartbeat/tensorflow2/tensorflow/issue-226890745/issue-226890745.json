{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9742", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9742/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9742/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9742/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9742", "id": 226890745, "node_id": "MDU6SXNzdWUyMjY4OTA3NDU=", "number": 9742, "title": "Optimized compiled Tensorflow uses almost 2x more memory than non-optimized binary", "user": {"login": "sirfz", "id": 4741099, "node_id": "MDQ6VXNlcjQ3NDEwOTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/4741099?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sirfz", "html_url": "https://github.com/sirfz", "followers_url": "https://api.github.com/users/sirfz/followers", "following_url": "https://api.github.com/users/sirfz/following{/other_user}", "gists_url": "https://api.github.com/users/sirfz/gists{/gist_id}", "starred_url": "https://api.github.com/users/sirfz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sirfz/subscriptions", "organizations_url": "https://api.github.com/users/sirfz/orgs", "repos_url": "https://api.github.com/users/sirfz/repos", "events_url": "https://api.github.com/users/sirfz/events{/privacy}", "received_events_url": "https://api.github.com/users/sirfz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2017-05-07T20:20:30Z", "updated_at": "2017-06-05T16:23:17Z", "closed_at": "2017-06-05T16:23:17Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Both</li>\n<li><strong>TensorFlow version (use command below)</strong>: ('v1.0.0-65-g4763edf-dirty', '1.0.1') (compiled at the same git commit of the binary version)</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.4.5</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A (CPU only)</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> pdb\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">get_layer</span>(<span class=\"pl-smi\">input_size</span>, <span class=\"pl-smi\">output_size</span>, <span class=\"pl-smi\">name</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> W_val is loaded from a file using numpy.load</span>\n    W_val <span class=\"pl-k\">=</span> np.random.normal(<span class=\"pl-v\">scale</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(input_size, output_size)).astype(np.float32)\n    W <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>W_<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(name), <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(input_size, output_size),\n                        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span>W_val, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32),\n                        <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    b <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>b_<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(name), <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(output_size,),\n                        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32),\n                        <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    <span class=\"pl-k\">return</span> W, b\n\nsessions <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">3</span>):\n    g <span class=\"pl-k\">=</span> tf.Graph()\n    <span class=\"pl-k\">with</span> g.as_default():\n        W1, b1 <span class=\"pl-k\">=</span> get_layer(<span class=\"pl-c1\">158238</span>, <span class=\"pl-c1\">900</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1<span class=\"pl-pds\">'</span></span>)\n        W2, b2 <span class=\"pl-k\">=</span> get_layer(<span class=\"pl-c1\">900</span>, <span class=\"pl-c1\">1000</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>2<span class=\"pl-pds\">'</span></span>)\n        W3, b3 <span class=\"pl-k\">=</span> get_layer(<span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>3<span class=\"pl-pds\">'</span></span>)\n\n        init <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n    session <span class=\"pl-k\">=</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>g)\n    session.run(init)\n    <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Loaded <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(i)\n    sessions.append(session)\n\npdb.set_trace()</pre></div>\n<h3>Describe the problem</h3>\n<p>After running the code snippet under the non-optimized binary Tensorflow installation, the used memory is ~6GB. However, when the same snippet is run with Tensorflow compiled with <code>-c opt --copt=-march=native</code> directives, the memory usage is ~11GB (1.8x larger).</p>\n<p>Note that there's no memory-usage difference when I use <code>tf.truncated_normal(stddev=0.1...)</code> instead of <code>tf.constant_initializer</code> with a numpy array.</p>\n<p>Not sure if this is a bug, or a side-effect of the optimized version or if there's something I can do to optimize memory usage?</p>\n<h3>Source code / logs</h3>\n<p>I can attach chrome traces if necessary.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): Both\nTensorFlow version (use command below): ('v1.0.0-65-g4763edf-dirty', '1.0.1') (compiled at the same git commit of the binary version)\nBazel version (if compiling from source): 0.4.5\nCUDA/cuDNN version: N/A (CPU only)\nGPU model and memory: N/A\nExact command to reproduce:\n\nimport pdb\nimport numpy as np\nimport tensorflow as tf\n\ndef get_layer(input_size, output_size, name):\n    # W_val is loaded from a file using numpy.load\n    W_val = np.random.normal(scale=0.1, size=(input_size, output_size)).astype(np.float32)\n    W = tf.get_variable(name='W_{}'.format(name), shape=(input_size, output_size),\n                        initializer=tf.constant_initializer(value=W_val, dtype=tf.float32),\n                        dtype=tf.float32)\n    b = tf.get_variable(name='b_{}'.format(name), shape=(output_size,),\n                        initializer=tf.constant_initializer(value=0.1, dtype=tf.float32),\n                        dtype=tf.float32)\n    return W, b\n\nsessions = []\nfor i in range(3):\n    g = tf.Graph()\n    with g.as_default():\n        W1, b1 = get_layer(158238, 900, '1')\n        W2, b2 = get_layer(900, 1000, '2')\n        W3, b3 = get_layer(1000, 1, '3')\n\n        init = tf.global_variables_initializer()\n    session = tf.Session(graph=g)\n    session.run(init)\n    print 'Loaded {}'.format(i)\n    sessions.append(session)\n\npdb.set_trace()\nDescribe the problem\nAfter running the code snippet under the non-optimized binary Tensorflow installation, the used memory is ~6GB. However, when the same snippet is run with Tensorflow compiled with -c opt --copt=-march=native directives, the memory usage is ~11GB (1.8x larger).\nNote that there's no memory-usage difference when I use tf.truncated_normal(stddev=0.1...) instead of tf.constant_initializer with a numpy array.\nNot sure if this is a bug, or a side-effect of the optimized version or if there's something I can do to optimize memory usage?\nSource code / logs\nI can attach chrome traces if necessary.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Both\r\n- **TensorFlow version (use command below)**: ('v1.0.0-65-g4763edf-dirty', '1.0.1') (compiled at the same git commit of the binary version)\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: N/A (CPU only)\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\nimport pdb\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef get_layer(input_size, output_size, name):\r\n    # W_val is loaded from a file using numpy.load\r\n    W_val = np.random.normal(scale=0.1, size=(input_size, output_size)).astype(np.float32)\r\n    W = tf.get_variable(name='W_{}'.format(name), shape=(input_size, output_size),\r\n                        initializer=tf.constant_initializer(value=W_val, dtype=tf.float32),\r\n                        dtype=tf.float32)\r\n    b = tf.get_variable(name='b_{}'.format(name), shape=(output_size,),\r\n                        initializer=tf.constant_initializer(value=0.1, dtype=tf.float32),\r\n                        dtype=tf.float32)\r\n    return W, b\r\n\r\nsessions = []\r\nfor i in range(3):\r\n    g = tf.Graph()\r\n    with g.as_default():\r\n        W1, b1 = get_layer(158238, 900, '1')\r\n        W2, b2 = get_layer(900, 1000, '2')\r\n        W3, b3 = get_layer(1000, 1, '3')\r\n\r\n        init = tf.global_variables_initializer()\r\n    session = tf.Session(graph=g)\r\n    session.run(init)\r\n    print 'Loaded {}'.format(i)\r\n    sessions.append(session)\r\n\r\npdb.set_trace()\r\n```\r\n\r\n### Describe the problem\r\nAfter running the code snippet under the non-optimized binary Tensorflow installation, the used memory is ~6GB. However, when the same snippet is run with Tensorflow compiled with `-c opt --copt=-march=native` directives, the memory usage is ~11GB (1.8x larger).\r\n\r\nNote that there's no memory-usage difference when I use `tf.truncated_normal(stddev=0.1...)` instead of `tf.constant_initializer` with a numpy array.\r\n\r\nNot sure if this is a bug, or a side-effect of the optimized version or if there's something I can do to optimize memory usage?\r\n\r\n### Source code / logs\r\nI can attach chrome traces if necessary."}