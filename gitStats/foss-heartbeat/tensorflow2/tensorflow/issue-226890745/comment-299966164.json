{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299966164", "html_url": "https://github.com/tensorflow/tensorflow/issues/9742#issuecomment-299966164", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9742", "id": 299966164, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTk2NjE2NA==", "user": {"login": "sirfz", "id": 4741099, "node_id": "MDQ6VXNlcjQ3NDEwOTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/4741099?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sirfz", "html_url": "https://github.com/sirfz", "followers_url": "https://api.github.com/users/sirfz/followers", "following_url": "https://api.github.com/users/sirfz/following{/other_user}", "gists_url": "https://api.github.com/users/sirfz/gists{/gist_id}", "starred_url": "https://api.github.com/users/sirfz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sirfz/subscriptions", "organizations_url": "https://api.github.com/users/sirfz/orgs", "repos_url": "https://api.github.com/users/sirfz/repos", "events_url": "https://api.github.com/users/sirfz/events{/privacy}", "received_events_url": "https://api.github.com/users/sirfz/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-08T19:27:38Z", "updated_at": "2017-05-08T19:27:38Z", "author_association": "NONE", "body_html": "<p>I ran the profiler tool against the pip version and the compiled version. First, here's the printed messages for each:</p>\n<h3>Pip version</h3>\n<pre><code>~# LD_PRELOAD=\"/usr/lib/libtcmalloc.so.4\" HEAPPROFILE=/root/tf_profile python test.py\nStarting tracking the heap\nStarting tracking the heap\ntcmalloc: large alloc 1139318784 bytes == 0x4326000 @  0x7fa0319cfd1b 0x7fa02fa7835c 0x7fa02faafe73 0x7fa02fab2b19 0x7fa02fb2b1e8 0x7f9fdef7ece5 0x7f9fdefc1c00 0x4cada2 0x4c9d8f 0x4c2765 0x4c2509 0x4f1def 0x4ec652 0x4eae31 0x49e14a 0x7fa0313d7830 0x49d9d9 (nil)\nDumping heap profile to /root/tf_profile.0001.heap (1387 MB allocated cumulatively, 1105 MB currently in use)\nDumping heap profile to /root/tf_profile.0002.heap (1649 MB currently in use)\nDumping heap profile to /root/tf_profile.0003.heap (3016 MB allocated cumulatively, 1649 MB currently in use)\nDumping heap profile to /root/tf_profile.0004.heap (2192 MB currently in use)\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nDumping heap profile to /root/tf_profile.0005.heap (4676 MB allocated cumulatively, 1657 MB currently in use)\nDumping heap profile to /root/tf_profile.0006.heap (5769 MB allocated cumulatively, 1657 MB currently in use)\nDumping heap profile to /root/tf_profile.0007.heap (Exiting, 561 MB in use)\n</code></pre>\n<h3>Compiled version</h3>\n<pre><code>~# LD_PRELOAD=\"/usr/lib/libtcmalloc.so.4\" HEAPPROFILE=/root/tf_profile python test.py\nStarting tracking the heap\nStarting tracking the heap\ntcmalloc: large alloc 1139318784 bytes == 0x3c70000 @  0x7f4c16a35d1b 0x7f4c14ade35c 0x7f4c14b15e73 0x7f4c14b18b19 0x7f4c14b911e8 0x7f4bc3fd4ce5 0x7f4bc4017c00 0x4cada2 0x4c9d8f 0x4c2765 0x4c2509 0x4f1def 0x4ec652 0x4eae31 0x49e14a 0x7f4c1643d830 0x49d9d9 (nil)\nDumping heap profile to /root/tf_profile.0001.heap (1390 MB allocated cumulatively, 1105 MB currently in use)\nDumping heap profile to /root/tf_profile.0002.heap (1649 MB currently in use)\nDumping heap profile to /root/tf_profile.0003.heap (3020 MB allocated cumulatively, 1649 MB currently in use)\nDumping heap profile to /root/tf_profile.0004.heap (2192 MB currently in use)\nDumping heap profile to /root/tf_profile.0005.heap (4680 MB allocated cumulatively, 1657 MB currently in use)\nDumping heap profile to /root/tf_profile.0006.heap (5777 MB allocated cumulatively, 2754 MB currently in use)\nDumping heap profile to /root/tf_profile.0007.heap (6867 MB allocated cumulatively, 2751 MB currently in use)\nDumping heap profile to /root/tf_profile.0008.heap (7960 MB allocated cumulatively, 2751 MB currently in use)\nDumping heap profile to /root/tf_profile.0009.heap (Exiting, 561 MB in use)\n</code></pre>\n<p>Up until heap 4 in both cases, memory usage is the same and both graphs (generated by <code>google-pprof</code> tool) are exactly the same based on a quick look.</p>\n<p>At heap 5, the memory usage is still the same but in the compiled version's case I see some parallelization in the graph where there are 2 nodes with ~540MB each instead of 1 node with 1090MB in the pip version's case.</p>\n<p>Heap 6 is where the memory usage doubles in the compiled version's case. In the pip version there's 1 big unnamed node with 1637.6MB. However, in the compiled version there are 3 nodes with ~500MB each (<code>initcmath</code> + 2 other unnamed nodes) + a fourth large node called <code>tensorflow PartialRunSetupRequest MergePartialFromCodedStream</code> with 1093.8MB usage. I didn't see this particular node in any of the heap files of the pip-version. I can attach a screenshot but it becomes unreadable when I zoom out enough to view the whole thing. Let me know if you'd like me to attach the heap files.</p>\n<p>In heap 7 of the compiled version, that same node appears with double the memory as well (2183.7MB).</p>\n<p>I used a simplified version of my original snippet to generate the heap files:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">get_layer</span>(<span class=\"pl-smi\">input_size</span>, <span class=\"pl-smi\">output_size</span>, <span class=\"pl-smi\">name</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> supposedly loaded from a saved file</span>\n    W_val <span class=\"pl-k\">=</span> np.random.normal(<span class=\"pl-v\">scale</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(input_size, output_size)).astype(np.float32)\n    W <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>W_<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(name), <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(input_size, output_size),\n                        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span>W_val, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32),\n                        <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    b <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>b_<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(name), <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(output_size,),\n                        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32),\n                        <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    <span class=\"pl-k\">return</span> W, b\n\ng <span class=\"pl-k\">=</span> tf.Graph()\n<span class=\"pl-k\">with</span> g.as_default():\n    W1, b1 <span class=\"pl-k\">=</span> get_layer(<span class=\"pl-c1\">158238</span>, <span class=\"pl-c1\">900</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1<span class=\"pl-pds\">'</span></span>)\n    W2, b2 <span class=\"pl-k\">=</span> get_layer(<span class=\"pl-c1\">900</span>, <span class=\"pl-c1\">1000</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>2<span class=\"pl-pds\">'</span></span>)\n    W3, b3 <span class=\"pl-k\">=</span> get_layer(<span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>3<span class=\"pl-pds\">'</span></span>)\n    init <span class=\"pl-k\">=</span> tf.global_variables_initializer()\nsession <span class=\"pl-k\">=</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>g)\nsession.run(init)\nsession.close()</pre></div>", "body_text": "I ran the profiler tool against the pip version and the compiled version. First, here's the printed messages for each:\nPip version\n~# LD_PRELOAD=\"/usr/lib/libtcmalloc.so.4\" HEAPPROFILE=/root/tf_profile python test.py\nStarting tracking the heap\nStarting tracking the heap\ntcmalloc: large alloc 1139318784 bytes == 0x4326000 @  0x7fa0319cfd1b 0x7fa02fa7835c 0x7fa02faafe73 0x7fa02fab2b19 0x7fa02fb2b1e8 0x7f9fdef7ece5 0x7f9fdefc1c00 0x4cada2 0x4c9d8f 0x4c2765 0x4c2509 0x4f1def 0x4ec652 0x4eae31 0x49e14a 0x7fa0313d7830 0x49d9d9 (nil)\nDumping heap profile to /root/tf_profile.0001.heap (1387 MB allocated cumulatively, 1105 MB currently in use)\nDumping heap profile to /root/tf_profile.0002.heap (1649 MB currently in use)\nDumping heap profile to /root/tf_profile.0003.heap (3016 MB allocated cumulatively, 1649 MB currently in use)\nDumping heap profile to /root/tf_profile.0004.heap (2192 MB currently in use)\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nDumping heap profile to /root/tf_profile.0005.heap (4676 MB allocated cumulatively, 1657 MB currently in use)\nDumping heap profile to /root/tf_profile.0006.heap (5769 MB allocated cumulatively, 1657 MB currently in use)\nDumping heap profile to /root/tf_profile.0007.heap (Exiting, 561 MB in use)\n\nCompiled version\n~# LD_PRELOAD=\"/usr/lib/libtcmalloc.so.4\" HEAPPROFILE=/root/tf_profile python test.py\nStarting tracking the heap\nStarting tracking the heap\ntcmalloc: large alloc 1139318784 bytes == 0x3c70000 @  0x7f4c16a35d1b 0x7f4c14ade35c 0x7f4c14b15e73 0x7f4c14b18b19 0x7f4c14b911e8 0x7f4bc3fd4ce5 0x7f4bc4017c00 0x4cada2 0x4c9d8f 0x4c2765 0x4c2509 0x4f1def 0x4ec652 0x4eae31 0x49e14a 0x7f4c1643d830 0x49d9d9 (nil)\nDumping heap profile to /root/tf_profile.0001.heap (1390 MB allocated cumulatively, 1105 MB currently in use)\nDumping heap profile to /root/tf_profile.0002.heap (1649 MB currently in use)\nDumping heap profile to /root/tf_profile.0003.heap (3020 MB allocated cumulatively, 1649 MB currently in use)\nDumping heap profile to /root/tf_profile.0004.heap (2192 MB currently in use)\nDumping heap profile to /root/tf_profile.0005.heap (4680 MB allocated cumulatively, 1657 MB currently in use)\nDumping heap profile to /root/tf_profile.0006.heap (5777 MB allocated cumulatively, 2754 MB currently in use)\nDumping heap profile to /root/tf_profile.0007.heap (6867 MB allocated cumulatively, 2751 MB currently in use)\nDumping heap profile to /root/tf_profile.0008.heap (7960 MB allocated cumulatively, 2751 MB currently in use)\nDumping heap profile to /root/tf_profile.0009.heap (Exiting, 561 MB in use)\n\nUp until heap 4 in both cases, memory usage is the same and both graphs (generated by google-pprof tool) are exactly the same based on a quick look.\nAt heap 5, the memory usage is still the same but in the compiled version's case I see some parallelization in the graph where there are 2 nodes with ~540MB each instead of 1 node with 1090MB in the pip version's case.\nHeap 6 is where the memory usage doubles in the compiled version's case. In the pip version there's 1 big unnamed node with 1637.6MB. However, in the compiled version there are 3 nodes with ~500MB each (initcmath + 2 other unnamed nodes) + a fourth large node called tensorflow PartialRunSetupRequest MergePartialFromCodedStream with 1093.8MB usage. I didn't see this particular node in any of the heap files of the pip-version. I can attach a screenshot but it becomes unreadable when I zoom out enough to view the whole thing. Let me know if you'd like me to attach the heap files.\nIn heap 7 of the compiled version, that same node appears with double the memory as well (2183.7MB).\nI used a simplified version of my original snippet to generate the heap files:\nimport numpy as np\nimport tensorflow as tf\n\ndef get_layer(input_size, output_size, name):\n    # supposedly loaded from a saved file\n    W_val = np.random.normal(scale=0.1, size=(input_size, output_size)).astype(np.float32)\n    W = tf.get_variable(name='W_{}'.format(name), shape=(input_size, output_size),\n                        initializer=tf.constant_initializer(value=W_val, dtype=tf.float32),\n                        dtype=tf.float32)\n    b = tf.get_variable(name='b_{}'.format(name), shape=(output_size,),\n                        initializer=tf.constant_initializer(value=0.1, dtype=tf.float32),\n                        dtype=tf.float32)\n    return W, b\n\ng = tf.Graph()\nwith g.as_default():\n    W1, b1 = get_layer(158238, 900, '1')\n    W2, b2 = get_layer(900, 1000, '2')\n    W3, b3 = get_layer(1000, 1, '3')\n    init = tf.global_variables_initializer()\nsession = tf.Session(graph=g)\nsession.run(init)\nsession.close()", "body": "I ran the profiler tool against the pip version and the compiled version. First, here's the printed messages for each:\r\n\r\n### Pip version\r\n```\r\n~# LD_PRELOAD=\"/usr/lib/libtcmalloc.so.4\" HEAPPROFILE=/root/tf_profile python test.py\r\nStarting tracking the heap\r\nStarting tracking the heap\r\ntcmalloc: large alloc 1139318784 bytes == 0x4326000 @  0x7fa0319cfd1b 0x7fa02fa7835c 0x7fa02faafe73 0x7fa02fab2b19 0x7fa02fb2b1e8 0x7f9fdef7ece5 0x7f9fdefc1c00 0x4cada2 0x4c9d8f 0x4c2765 0x4c2509 0x4f1def 0x4ec652 0x4eae31 0x49e14a 0x7fa0313d7830 0x49d9d9 (nil)\r\nDumping heap profile to /root/tf_profile.0001.heap (1387 MB allocated cumulatively, 1105 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0002.heap (1649 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0003.heap (3016 MB allocated cumulatively, 1649 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0004.heap (2192 MB currently in use)\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nDumping heap profile to /root/tf_profile.0005.heap (4676 MB allocated cumulatively, 1657 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0006.heap (5769 MB allocated cumulatively, 1657 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0007.heap (Exiting, 561 MB in use)\r\n```\r\n\r\n### Compiled version\r\n```\r\n~# LD_PRELOAD=\"/usr/lib/libtcmalloc.so.4\" HEAPPROFILE=/root/tf_profile python test.py\r\nStarting tracking the heap\r\nStarting tracking the heap\r\ntcmalloc: large alloc 1139318784 bytes == 0x3c70000 @  0x7f4c16a35d1b 0x7f4c14ade35c 0x7f4c14b15e73 0x7f4c14b18b19 0x7f4c14b911e8 0x7f4bc3fd4ce5 0x7f4bc4017c00 0x4cada2 0x4c9d8f 0x4c2765 0x4c2509 0x4f1def 0x4ec652 0x4eae31 0x49e14a 0x7f4c1643d830 0x49d9d9 (nil)\r\nDumping heap profile to /root/tf_profile.0001.heap (1390 MB allocated cumulatively, 1105 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0002.heap (1649 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0003.heap (3020 MB allocated cumulatively, 1649 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0004.heap (2192 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0005.heap (4680 MB allocated cumulatively, 1657 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0006.heap (5777 MB allocated cumulatively, 2754 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0007.heap (6867 MB allocated cumulatively, 2751 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0008.heap (7960 MB allocated cumulatively, 2751 MB currently in use)\r\nDumping heap profile to /root/tf_profile.0009.heap (Exiting, 561 MB in use)\r\n```\r\nUp until heap 4 in both cases, memory usage is the same and both graphs (generated by `google-pprof` tool) are exactly the same based on a quick look.\r\n\r\nAt heap 5, the memory usage is still the same but in the compiled version's case I see some parallelization in the graph where there are 2 nodes with ~540MB each instead of 1 node with 1090MB in the pip version's case.\r\n\r\nHeap 6 is where the memory usage doubles in the compiled version's case. In the pip version there's 1 big unnamed node with 1637.6MB. However, in the compiled version there are 3 nodes with ~500MB each (`initcmath` + 2 other unnamed nodes) + a fourth large node called `tensorflow PartialRunSetupRequest MergePartialFromCodedStream` with 1093.8MB usage. I didn't see this particular node in any of the heap files of the pip-version. I can attach a screenshot but it becomes unreadable when I zoom out enough to view the whole thing. Let me know if you'd like me to attach the heap files.\r\n\r\nIn heap 7 of the compiled version, that same node appears with double the memory as well (2183.7MB).\r\n\r\nI used a simplified version of my original snippet to generate the heap files:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef get_layer(input_size, output_size, name):\r\n    # supposedly loaded from a saved file\r\n    W_val = np.random.normal(scale=0.1, size=(input_size, output_size)).astype(np.float32)\r\n    W = tf.get_variable(name='W_{}'.format(name), shape=(input_size, output_size),\r\n                        initializer=tf.constant_initializer(value=W_val, dtype=tf.float32),\r\n                        dtype=tf.float32)\r\n    b = tf.get_variable(name='b_{}'.format(name), shape=(output_size,),\r\n                        initializer=tf.constant_initializer(value=0.1, dtype=tf.float32),\r\n                        dtype=tf.float32)\r\n    return W, b\r\n\r\ng = tf.Graph()\r\nwith g.as_default():\r\n    W1, b1 = get_layer(158238, 900, '1')\r\n    W2, b2 = get_layer(900, 1000, '2')\r\n    W3, b3 = get_layer(1000, 1, '3')\r\n    init = tf.global_variables_initializer()\r\nsession = tf.Session(graph=g)\r\nsession.run(init)\r\nsession.close()\r\n```\r\n\r\n"}