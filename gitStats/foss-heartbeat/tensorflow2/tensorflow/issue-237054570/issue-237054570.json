{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10838", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10838/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10838/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10838/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10838", "id": 237054570, "node_id": "MDU6SXNzdWUyMzcwNTQ1NzA=", "number": 10838, "title": "Compiling TensorFlow gives 3k lines of warnings!", "user": {"login": "Iolaum", "id": 14947634, "node_id": "MDQ6VXNlcjE0OTQ3NjM0", "avatar_url": "https://avatars2.githubusercontent.com/u/14947634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Iolaum", "html_url": "https://github.com/Iolaum", "followers_url": "https://api.github.com/users/Iolaum/followers", "following_url": "https://api.github.com/users/Iolaum/following{/other_user}", "gists_url": "https://api.github.com/users/Iolaum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Iolaum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Iolaum/subscriptions", "organizations_url": "https://api.github.com/users/Iolaum/orgs", "repos_url": "https://api.github.com/users/Iolaum/repos", "events_url": "https://api.github.com/users/Iolaum/events{/privacy}", "received_events_url": "https://api.github.com/users/Iolaum/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173351, "node_id": "MDU6TGFiZWw0NzMxNzMzNTE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-06-19T23:48:39Z", "updated_at": "2017-08-25T18:17:30Z", "closed_at": "2017-08-25T18:17:30Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04.2 (4.8 kernel)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Compiling TF from Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.2.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.5.1</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 8.0, CuDNN 5.1</li>\n<li><strong>GPU model and memory</strong>: 1050Ti 4GB (Notebook version) (Intel i5-7300hq CPU)</li>\n<li><strong>Exact command to reproduce</strong>: Compiling from source <a href=\"https://www.tensorflow.org/install/install_sources\" rel=\"nofollow\">following documentation</a>.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I compiled tensorflow from source. The process finished successfully and the binary managed to install and run successfully. What seems strange is that during the process I got ~3k lines of warnings. I am linking to them at the end of the issue. I am wondering if that's expected behavior or indication of a (small or <em>not_so_small</em>?) problem.</p>\n<p>One thing that may affect this is bazel installation. I followed <a href=\"https://bazel.build/versions/master/docs/install.html\" rel=\"nofollow\">Bazel Installation Instructions</a> and used the recommended apt method. This led to me running into <a href=\"https://github.com/tensorflow/tensorflow/issues/8092\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8092/hovercard\">this</a> issue. Installing openjdk-8-jdk on top of the ibm-java80-jdk as suggested in a <a href=\"https://github.com/tensorflow/tensorflow/issues/8092#issuecomment-304957009\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8092/hovercard\">comment</a> solves the problem (although I am not sure how much technical debt this solution caries, which may have manifested in some of the warnings produced during compilation).</p>\n<h3>Source code / logs</h3>\n<p><strong>Configuration Script options:</strong></p>\n<pre lang=\"{shell}\"><code>$ ./configure\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\nFound possible Python library paths:\n  /usr/local/lib/python3.5/dist-packages\n  /usr/lib/python3/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]\n/usr/local/lib/python3.5/dist-packages\nDo you wish to build TensorFlow with MKL support? [y/N] y\nMKL support will be enabled for TensorFlow\nDo you wish to download MKL LIB from the web? [Y/n] y\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nDo you wish to use jemalloc as the malloc implementation? [Y/n] y\njemalloc enabled\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] n\nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] n\nNo XLA JIT support will be enabled for TensorFlow\nDo you wish to build TensorFlow with VERBS support? [y/N] n\nNo VERBS support will be enabled for TensorFlow\nDo you wish to build TensorFlow with OpenCL support? [y/N] n\nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N] n\nnvcc will be used as CUDA compiler\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nPlease specify the cuDNN version you want to use. [Leave empty to use system default]: 5\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: 6.1\n........\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\nConfiguration finished\n</code></pre>\n<p><a href=\"https://github.com/Iolaum/CompileTF/blob/master/CompilationOutput.txt\">Console output of compilation command</a><br>\nBecause the output is too big to be placed within the issue I 've put it in it's own repository.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.2 (4.8 kernel)\nTensorFlow installed from (source or binary): Compiling TF from Source\nTensorFlow version (use command below): 1.2.0\nBazel version (if compiling from source): 0.5.1\nCUDA/cuDNN version: CUDA 8.0, CuDNN 5.1\nGPU model and memory: 1050Ti 4GB (Notebook version) (Intel i5-7300hq CPU)\nExact command to reproduce: Compiling from source following documentation.\n\nDescribe the problem\nI compiled tensorflow from source. The process finished successfully and the binary managed to install and run successfully. What seems strange is that during the process I got ~3k lines of warnings. I am linking to them at the end of the issue. I am wondering if that's expected behavior or indication of a (small or not_so_small?) problem.\nOne thing that may affect this is bazel installation. I followed Bazel Installation Instructions and used the recommended apt method. This led to me running into this issue. Installing openjdk-8-jdk on top of the ibm-java80-jdk as suggested in a comment solves the problem (although I am not sure how much technical debt this solution caries, which may have manifested in some of the warnings produced during compilation).\nSource code / logs\nConfiguration Script options:\n$ ./configure\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\nFound possible Python library paths:\n  /usr/local/lib/python3.5/dist-packages\n  /usr/lib/python3/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]\n/usr/local/lib/python3.5/dist-packages\nDo you wish to build TensorFlow with MKL support? [y/N] y\nMKL support will be enabled for TensorFlow\nDo you wish to download MKL LIB from the web? [Y/n] y\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nDo you wish to use jemalloc as the malloc implementation? [Y/n] y\njemalloc enabled\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] n\nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] n\nNo XLA JIT support will be enabled for TensorFlow\nDo you wish to build TensorFlow with VERBS support? [y/N] n\nNo VERBS support will be enabled for TensorFlow\nDo you wish to build TensorFlow with OpenCL support? [y/N] n\nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N] n\nnvcc will be used as CUDA compiler\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nPlease specify the cuDNN version you want to use. [Leave empty to use system default]: 5\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: 6.1\n........\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\nConfiguration finished\n\nConsole output of compilation command\nBecause the output is too big to be placed within the issue I 've put it in it's own repository.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2 (4.8 kernel)\r\n- **TensorFlow installed from (source or binary)**: Compiling TF from Source\r\n- **TensorFlow version (use command below)**: 1.2.0\r\n- **Bazel version (if compiling from source)**: 0.5.1\r\n- **CUDA/cuDNN version**: CUDA 8.0, CuDNN 5.1\r\n- **GPU model and memory**: 1050Ti 4GB (Notebook version) (Intel i5-7300hq CPU)\r\n- **Exact command to reproduce**: Compiling from source [following documentation](https://www.tensorflow.org/install/install_sources).\r\n\r\n### Describe the problem\r\nI compiled tensorflow from source. The process finished successfully and the binary managed to install and run successfully. What seems strange is that during the process I got ~3k lines of warnings. I am linking to them at the end of the issue. I am wondering if that's expected behavior or indication of a (small or _not_so_small_?) problem.\r\n\r\nOne thing that may affect this is bazel installation. I followed [Bazel Installation Instructions](https://bazel.build/versions/master/docs/install.html) and used the recommended apt method. This led to me running into [this](https://github.com/tensorflow/tensorflow/issues/8092) issue. Installing openjdk-8-jdk on top of the ibm-java80-jdk as suggested in a [comment](https://github.com/tensorflow/tensorflow/issues/8092#issuecomment-304957009) solves the problem (although I am not sure how much technical debt this solution caries, which may have manifested in some of the warnings produced during compilation).\r\n\r\n### Source code / logs\r\n**Configuration Script options:**\r\n```{shell}\r\n$ ./configure\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\nFound possible Python library paths:\r\n  /usr/local/lib/python3.5/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]\r\n/usr/local/lib/python3.5/dist-packages\r\nDo you wish to build TensorFlow with MKL support? [y/N] y\r\nMKL support will be enabled for TensorFlow\r\nDo you wish to download MKL LIB from the web? [Y/n] y\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\nDo you wish to use jemalloc as the malloc implementation? [Y/n] y\r\njemalloc enabled\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] n\r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] n\r\nNo XLA JIT support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with VERBS support? [y/N] n\r\nNo VERBS support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] n\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nDo you want to use clang as CUDA compiler? [y/N] n\r\nnvcc will be used as CUDA compiler\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nPlease specify the cuDNN version you want to use. [Leave empty to use system default]: 5\r\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.1\r\n........\r\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\r\nConfiguration finished\r\n```\r\n[Console output of compilation command](https://github.com/Iolaum/CompileTF/blob/master/CompilationOutput.txt)\r\nBecause the output is too big to be placed within the issue I 've put it in it's own repository."}