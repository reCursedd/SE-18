{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14085", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14085/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14085/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14085/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14085", "id": 269514534, "node_id": "MDU6SXNzdWUyNjk1MTQ1MzQ=", "number": 14085, "title": "How can I run a Tensorflow file on GPUs? Error: Cannot assign a device for operation 'eval_step'", "user": {"login": "Ellie68", "id": 30722660, "node_id": "MDQ6VXNlcjMwNzIyNjYw", "avatar_url": "https://avatars1.githubusercontent.com/u/30722660?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ellie68", "html_url": "https://github.com/Ellie68", "followers_url": "https://api.github.com/users/Ellie68/followers", "following_url": "https://api.github.com/users/Ellie68/following{/other_user}", "gists_url": "https://api.github.com/users/Ellie68/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ellie68/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ellie68/subscriptions", "organizations_url": "https://api.github.com/users/Ellie68/orgs", "repos_url": "https://api.github.com/users/Ellie68/repos", "events_url": "https://api.github.com/users/Ellie68/events{/privacy}", "received_events_url": "https://api.github.com/users/Ellie68/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-10-30T08:21:45Z", "updated_at": "2018-02-28T02:29:48Z", "closed_at": "2017-11-06T19:59:25Z", "author_association": "NONE", "body_html": "<p>Do you have any idea how can I run <a href=\"https://github.com/pudae/tensorflow-densenet/blob/master/eval_image_classifier.py\">\"eval_image_classifier.py\"</a> on GPUs? Should I change any functions or do any modifications? Or whether there exist any other specific functions for evaluation on GPUs?</p>\n<p>I can already run <a href=\"https://github.com/pudae/tensorflow-densenet/blob/master/train_image_classifier.py\">\"train_image_classifier.py\"</a> on GPUs because of having the associated flag for switching between CPU and GPU:</p>\n<pre><code>tf.app.flags.DEFINE_boolean('clone_on_cpu', False,\n                        'Use CPUs to deploy clones.')\n</code></pre>\n<p>I did try to add the same line to <code>eval_image_classifier.py</code>, but it had no effect. I'm using Python 2.7.13 and Tensorflow 1.3.0 .</p>\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport math\nimport tensorflow as tf\nfrom deployment import model_deploy\nfrom datasets import dataset_factory\nfrom nets import nets_factory\nfrom preprocessing import preprocessing_factory\nslim = tf.contrib.slim\n\n\ntf.app.flags.DEFINE_integer(\n    'batch_size', 32, 'The number of samples in each batch.')\n\ntf.app.flags.DEFINE_integer(\n    'max_num_batches', None,\n    'Max number of batches to evaluate by default use all.')\n\ntf.app.flags.DEFINE_string(\n    'master', '', 'The address of the TensorFlow master to use.')\n\ntf.app.flags.DEFINE_string(\n    'checkpoint_path', '...',\n    'The directory where the model was written to or an absolute path to a '\n    'checkpoint file.')\n\ntf.app.flags.DEFINE_string(\n    'eval_dir', '...',\n    'Directory where the results are saved to.')\n\ntf.app.flags.DEFINE_integer('num_clones', 1,\n                            'Number of model clones to deploy.')\n\ntf.app.flags.DEFINE_boolean('clone_on_cpu', False,\n                            'Use CPUs to deploy clones.')\n\ntf.app.flags.DEFINE_integer('worker_replicas', 1, 'Number of worker replicas.')\n\ntf.app.flags.DEFINE_integer(\n    'num_readers', 4,\n    'The number of parallel readers that read data from the dataset.')\n\ntf.app.flags.DEFINE_integer(\n    'num_ps_tasks', 0,\n    'The number of parameter servers. If the value is 0, then the parameters '\n    'are handled locally by the worker.')\n\n\ntf.app.flags.DEFINE_integer(\n    'num_preprocessing_threads', 4,\n    'The number of threads used to create the batches.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_name', '...', 'The name of the dataset to load.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_split_name', 'validation', 'The name of the train/test split.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_dir', '...', \n    'The directory where the dataset files are stored.')\n\ntf.app.flags.DEFINE_integer(\n    'labels_offset', 0,\n    'An offset for the labels in the dataset. This flag is primarily used to '\n    'evaluate the VGG and ResNet architectures which do not use a background '\n    'class for the ImageNet dataset.')\n\ntf.app.flags.DEFINE_string(\n    'model_name', 'densenet161', 'The name of the architecture to evaluate.')\n\ntf.app.flags.DEFINE_string(\n    'preprocessing_name', None, 'The name of the preprocessing to use. If left '\n    'as `None`, then the model_name flag is used.')\n\ntf.app.flags.DEFINE_float(\n    'moving_average_decay', None,\n    'The decay to use for the moving average.'\n    'If left as None, then moving averages are not used.')\n\ntf.app.flags.DEFINE_integer(\n    'eval_image_size', None, 'Eval image size')\n\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n  if not FLAGS.dataset_dir:\n    raise ValueError('You must supply the dataset directory with --dataset_dir')\n    \n    #######################\n    # Config model_deploy #\n    #######################\n  tf.logging.set_verbosity(tf.logging.INFO)\n  with tf.Graph().as_default():\n      \n    deploy_config = model_deploy.DeploymentConfig(\n      num_clones=FLAGS.num_clones,\n      clone_on_cpu=FLAGS.clone_on_cpu,\n      #replica_id=FLAGS.task,\n      num_replicas=FLAGS.worker_replicas,\n      num_ps_tasks=FLAGS.num_ps_tasks)\n      \n    # Create global_step\n    with tf.device(deploy_config.variables_device()):\n      tf_global_step = slim.create_global_step()\n    ######################\n    # Select the dataset #\n    ######################\n    dataset = dataset_factory.get_dataset(\n        FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\n\n    ####################\n    # Select the model #\n    ####################\n    network_fn = nets_factory.get_network_fn(\n        FLAGS.model_name,\n        num_classes=(dataset.num_classes - FLAGS.labels_offset),\n        is_training=False)\n\n    ##############################################################\n    # Create a dataset provider that loads data from the dataset #\n    ##############################################################\n    with tf.device(deploy_config.inputs_device()):\n        provider = slim.dataset_data_provider.DatasetDataProvider(\n            dataset,\n            num_readers=FLAGS.num_readers,\n            shuffle=False,\n            common_queue_capacity=2 * FLAGS.batch_size,\n            common_queue_min=FLAGS.batch_size)\n        [image, label] = provider.get(['image', 'label'])\n        label -= FLAGS.labels_offset\n\n    #####################################\n    # Select the preprocessing function #\n    #####################################\n    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\n    image_preprocessing_fn = preprocessing_factory.get_preprocessing(\n        preprocessing_name,\n        is_training=False)\n\n    eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\n\n    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)\n\n    images, labels = tf.train.batch(\n        [image, label],\n        batch_size=FLAGS.batch_size,\n        num_threads=FLAGS.num_preprocessing_threads,\n        capacity=5 * FLAGS.batch_size)\n    batch_queue = slim.prefetch_queue.prefetch_queue(\n        [images, labels], capacity=2 * deploy_config.num_clones)\n    ####################\n    # Define the model #\n    ####################\n    def clone_fn(batch_queue):\n      \"\"\"Allows data parallelism by creating multiple clones of network_fn.\"\"\"\n      with tf.device(deploy_config.inputs_device()):\n        images, labels = batch_queue.dequeue()\n      logits, end_points = network_fn(images)\n      logits = tf.squeeze(logits)\n\n      #############################\n      # Specify the loss function #\n      #############################\n      if 'AuxLogits' in end_points:\n        tf.losses.mean_squared_error(\n            predictions=end_points['AuxLogits'], labels=labels, weights=0.4, scope='aux_loss')\n      tf.losses.mean_squared_error(\n          predictions=logits, labels=labels, weights=1.0)\n      return end_points\n\n    #clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])\n    #first_clone_scope = deploy_config.clone_scope(0)\n    ####################\n    # Define the model #\n    ####################\n    logits, _ = network_fn(images)\n\n    if FLAGS.moving_average_decay:\n      variable_averages = tf.train.ExponentialMovingAverage(\n          FLAGS.moving_average_decay, tf_global_step)\n      variables_to_restore = variable_averages.variables_to_restore(\n          slim.get_model_variables())\n      variables_to_restore[tf_global_step.op.name] = tf_global_step\n    else:\n      variables_to_restore = slim.get_variables_to_restore()\n\n    logits = tf.squeeze(logits)\n\n    # Define the metrics:\n    predictions = logits\n\n    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n        'Accuracy': tf.metrics.root_mean_squared_error(predictions, labels),\n        'Recall_5': slim.metrics.streaming_recall(\n            logits, labels),\n    })\n\n    # Print the summaries to screen.\n    print_ops = []\n    summary_ops = []\n    for name, value in names_to_values.items():\n      summary_name = 'eval/%s' % name\n      op = tf.summary.scalar(summary_name, value, collections=[])\n      op = tf.Print(op, [value], summary_name)\n      summary_ops.append(op)\n      print_ops.append(tf.Print(value, [value], summary_name))\n      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n\n    # TODO(sguada) use num_epochs=1\n    if FLAGS.max_num_batches:\n      num_batches = FLAGS.max_num_batches\n    else:\n      # This ensures that we make a single pass over all of the data.\n      num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\n\n    if tf.gfile.IsDirectory(FLAGS.checkpoint_path):\n        if tf.train.latest_checkpoint(FLAGS.checkpoint_path):\n            checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\n        else:\n            checkpoint_path = FLAGS.checkpoint_path\n\n    eval_interval_secs = 6\n    \n    tf.logging.info('Evaluating %s' % checkpoint_path)\n\n    slim.evaluation.evaluation_loop(\n        master=FLAGS.master,\n        checkpoint_dir=checkpoint_path,\n        logdir=FLAGS.eval_dir,\n        num_evals=num_batches,\n        eval_op=list(names_to_updates.values()) + print_ops,\n        variables_to_restore=variables_to_restore,\n        eval_interval_secs = eval_interval_secs )\nif __name__ == '__main__':\n  tf.app.run()\n</code></pre>\n<p>I tried to use some code like Tensorflow tutorial as well:</p>\n<pre><code># Creates a graph.\nwith tf.device('/gpu:2'):\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\n# Creates a session with allow_soft_placement and log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(\n         allow_soft_placement=True, log_device_placement=True))\n# Runs the op.\nprint(sess.run(c))\n</code></pre>\n<p>I modified the code in this way:</p>\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport tensorflow as tf\n\nfrom datasets import dataset_factory\nfrom nets import nets_factory\nfrom preprocessing import preprocessing_factory\n\nslim = tf.contrib.slim\n\ntf.app.flags.DEFINE_integer(\n    'batch_size', 32, 'The number of samples in each batch.')\n\ntf.app.flags.DEFINE_integer(\n    'max_num_batches', None,\n    'Max number of batches to evaluate by default use all.')\n\ntf.app.flags.DEFINE_string(\n    'master', '', 'The address of the TensorFlow master to use.')\n\ntf.app.flags.DEFINE_string(\n    'checkpoint_path', '...',\n    'The directory where the model was written to or an absolute path to a '\n    'checkpoint file.')\n\ntf.app.flags.DEFINE_string(\n    'eval_dir', '...',\n    'Directory where the results are saved to.')\n\ntf.app.flags.DEFINE_integer(\n    'num_preprocessing_threads', 4,\n    'The number of threads used to create the batches.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_name', '...', 'The name of the dataset to load.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_split_name', 'validation', 'The name of the train/test split.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_dir', '...', \n    'The directory where the dataset files are stored.')\n\ntf.app.flags.DEFINE_integer(\n    'labels_offset', 0,\n    'An offset for the labels in the dataset. This flag is primarily used to '\n    'evaluate the VGG and ResNet architectures which do not use a background '\n    'class for the ImageNet dataset.')\n\ntf.app.flags.DEFINE_string(\n    'model_name', 'densenet161', 'The name of the architecture to evaluate.')\n\ntf.app.flags.DEFINE_string(\n    'preprocessing_name', None, 'The name of the preprocessing to use. If left '\n    'as `None`, then the model_name flag is used.')\n\ntf.app.flags.DEFINE_float(\n    'moving_average_decay', None,\n    'The decay to use for the moving average.'\n    'If left as None, then moving averages are not used.')\n\ntf.app.flags.DEFINE_integer(\n    'eval_image_size', None, 'Eval image size')\n\nFLAGS = tf.app.flags.FLAGS\n\n# Initialize all global and local variables\ninit = tf.group(tf.global_variables_initializer(),\n                   tf.local_variables_initializer())\n\ndef main(_):\n  if not FLAGS.dataset_dir:\n    raise ValueError('You must supply the dataset directory with --dataset_dir')\n\n  tf.logging.set_verbosity(tf.logging.INFO)\n  \n  sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n                                          log_device_placement=True))\n  \n  with tf.Graph().as_default(), tf.device('/gpu:0'):\n      \n    sess.run(init)\n    tf_global_step = slim.get_or_create_global_step()\n\n    ######################\n    # Select the dataset #\n    ######################\n    dataset = dataset_factory.get_dataset(\n        FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\n\n    ####################\n    # Select the model #\n    ####################\n    network_fn = nets_factory.get_network_fn(\n        FLAGS.model_name,\n        num_classes=(dataset.num_classes - FLAGS.labels_offset),\n        is_training=False)\n\n    ##############################################################\n    # Create a dataset provider that loads data from the dataset #\n    ##############################################################\n    provider = slim.dataset_data_provider.DatasetDataProvider(\n        dataset,\n        shuffle=False,\n        common_queue_capacity=2 * FLAGS.batch_size,\n        common_queue_min=FLAGS.batch_size)\n    [image, label] = provider.get(['image', 'label'])\n    label -= FLAGS.labels_offset\n\n    #####################################\n    # Select the preprocessing function #\n    #####################################\n    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\n    image_preprocessing_fn = preprocessing_factory.get_preprocessing(\n        preprocessing_name,\n        is_training=False)\n\n    eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\n\n    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)\n\n    images, labels = tf.train.batch(\n        [image, label],\n        batch_size=FLAGS.batch_size,\n        num_threads=FLAGS.num_preprocessing_threads,\n        capacity=5 * FLAGS.batch_size)\n\n    ####################\n    # Define the model #\n    ####################\n    logits, _ = network_fn(images)\n\n    if FLAGS.moving_average_decay:\n      variable_averages = tf.train.ExponentialMovingAverage(\n          FLAGS.moving_average_decay, tf_global_step)\n      variables_to_restore = variable_averages.variables_to_restore(\n          slim.get_model_variables())\n      variables_to_restore[tf_global_step.op.name] = tf_global_step\n    else:\n      variables_to_restore = slim.get_variables_to_restore()\n\n    logits = tf.squeeze(logits)\n\n    # Define the metrics:\n    predictions = logits\n\n    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n        'Accuracy': tf.metrics.root_mean_squared_error(predictions, labels),\n        'Recall_5': slim.metrics.streaming_recall(\n            logits, labels),\n    })\n\n    # Print the summaries to screen.\n    print_ops = []\n    summary_ops = []\n    for name, value in names_to_values.items():\n      summary_name = 'eval/%s' % name\n      op = tf.summary.scalar(summary_name, value, collections=[])\n      op = tf.Print(op, [value], summary_name)\n      summary_ops.append(op)\n      print_ops.append(tf.Print(value, [value], summary_name))\n      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n      \n    # TODO(sguada) use num_epochs=1\n    if FLAGS.max_num_batches:\n      num_batches = FLAGS.max_num_batches\n    else:\n      # This ensures that we make a single pass over all of the data.\n      num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\n\n    if tf.gfile.IsDirectory(FLAGS.checkpoint_path):\n        if tf.train.latest_checkpoint(FLAGS.checkpoint_path):\n            checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\n        else:\n            checkpoint_path = FLAGS.checkpoint_path\n\n    #print(checkpoint_path)\n    eval_interval_secs = 6\n    \n    tf.logging.info('Evaluating %s' % checkpoint_path)\n\n    slim.evaluation.evaluation_loop(\n        master=FLAGS.master,\n        checkpoint_dir=checkpoint_path,\n        logdir=FLAGS.eval_dir,\n        num_evals=num_batches,\n        eval_op=list(names_to_updates.values()) + print_ops,\n        variables_to_restore=variables_to_restore,\n        eval_interval_secs = eval_interval_secs )\n\n\nif __name__ == '__main__':\n  tf.app.run()\n</code></pre>\n<p>When I run this code, I face this error:</p>\n<pre><code>    Traceback (most recent call last):\n  File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 210, in &lt;module&gt;\n    tf.app.run()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 206, in main\n    eval_interval_secs = 60 )\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py\", line 296, in evaluation_loo\np\n    timeout=timeout)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py\", line 447, in evalua\nte_repeatedly\n    session_creator=session_creator, hooks=hooks) as session:\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 668, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 490, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 842, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 847, in _create_session\n    return self._sess_creator.create_session()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 551, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 425, in create_session\n    init_fn=self._scaffold.init_fn)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py\", line 273, in prepare_session\n    config=config)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py\", line 189, in _restore_checkpoin\nt\n    saver.restore(sess, checkpoint_filename_with_path)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1560, in restore\n    {self.saver_def.filename_tensor_name: save_path})\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'eval_step': Could not satisfy explicit device s\npecification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nConst: GPU CPU \nAssignAdd: CPU \nVariableV2: CPU \nIdentity: GPU CPU \nAssign: CPU \nIsVariableInitialized: CPU \n\t [[Node: eval_step = VariableV2[_class=[\"loc:@eval_step\"], container=\"\", dtype=DT_INT64, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]\n()]]\n\nCaused by op u'eval_step', defined at:\n  File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 210, in &lt;module&gt;\n    tf.app.run()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 206, in main\n    eval_interval_secs = 60 )\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py\", line 296, in evaluation_loo\np\n    timeout=timeout)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py\", line 410, in evalua\nte_repeatedly\n    eval_step = get_or_create_eval_step()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/evaluation.py\", line 57, in _get_or_create_eval_step\n    collections=[ops.GraphKeys.LOCAL_VARIABLES, ops.GraphKeys.EVAL_STEP])\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 367, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\n    use_resource=use_resource)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 725, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\n    expected_shape=expected_shape)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 283, in _init_from_args\n    name=name)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 131, in variable_op_v2\n    shared_name=shared_name)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 682, in _variable_v2\n    name=name)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'eval_step': Could not satisfy explicit device specification '\n/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nConst: GPU CPU \nAssignAdd: CPU \nVariableV2: CPU \nIdentity: GPU CPU \nAssign: CPU \nIsVariableInitialized: CPU \n\t [[Node: eval_step = VariableV2[_class=[\"loc:@eval_step\"], container=\"\", dtype=DT_INT64, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]\n()]]\n\nERROR:tensorflow:==================================\nObject was never used (type &lt;class 'tensorflow.python.framework.ops.Tensor'&gt;):\n&lt;tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string&gt;\nIf you want to mark it as used call its \"mark_used()\" method.\n</code></pre>", "body_text": "Do you have any idea how can I run \"eval_image_classifier.py\" on GPUs? Should I change any functions or do any modifications? Or whether there exist any other specific functions for evaluation on GPUs?\nI can already run \"train_image_classifier.py\" on GPUs because of having the associated flag for switching between CPU and GPU:\ntf.app.flags.DEFINE_boolean('clone_on_cpu', False,\n                        'Use CPUs to deploy clones.')\n\nI did try to add the same line to eval_image_classifier.py, but it had no effect. I'm using Python 2.7.13 and Tensorflow 1.3.0 .\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport math\nimport tensorflow as tf\nfrom deployment import model_deploy\nfrom datasets import dataset_factory\nfrom nets import nets_factory\nfrom preprocessing import preprocessing_factory\nslim = tf.contrib.slim\n\n\ntf.app.flags.DEFINE_integer(\n    'batch_size', 32, 'The number of samples in each batch.')\n\ntf.app.flags.DEFINE_integer(\n    'max_num_batches', None,\n    'Max number of batches to evaluate by default use all.')\n\ntf.app.flags.DEFINE_string(\n    'master', '', 'The address of the TensorFlow master to use.')\n\ntf.app.flags.DEFINE_string(\n    'checkpoint_path', '...',\n    'The directory where the model was written to or an absolute path to a '\n    'checkpoint file.')\n\ntf.app.flags.DEFINE_string(\n    'eval_dir', '...',\n    'Directory where the results are saved to.')\n\ntf.app.flags.DEFINE_integer('num_clones', 1,\n                            'Number of model clones to deploy.')\n\ntf.app.flags.DEFINE_boolean('clone_on_cpu', False,\n                            'Use CPUs to deploy clones.')\n\ntf.app.flags.DEFINE_integer('worker_replicas', 1, 'Number of worker replicas.')\n\ntf.app.flags.DEFINE_integer(\n    'num_readers', 4,\n    'The number of parallel readers that read data from the dataset.')\n\ntf.app.flags.DEFINE_integer(\n    'num_ps_tasks', 0,\n    'The number of parameter servers. If the value is 0, then the parameters '\n    'are handled locally by the worker.')\n\n\ntf.app.flags.DEFINE_integer(\n    'num_preprocessing_threads', 4,\n    'The number of threads used to create the batches.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_name', '...', 'The name of the dataset to load.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_split_name', 'validation', 'The name of the train/test split.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_dir', '...', \n    'The directory where the dataset files are stored.')\n\ntf.app.flags.DEFINE_integer(\n    'labels_offset', 0,\n    'An offset for the labels in the dataset. This flag is primarily used to '\n    'evaluate the VGG and ResNet architectures which do not use a background '\n    'class for the ImageNet dataset.')\n\ntf.app.flags.DEFINE_string(\n    'model_name', 'densenet161', 'The name of the architecture to evaluate.')\n\ntf.app.flags.DEFINE_string(\n    'preprocessing_name', None, 'The name of the preprocessing to use. If left '\n    'as `None`, then the model_name flag is used.')\n\ntf.app.flags.DEFINE_float(\n    'moving_average_decay', None,\n    'The decay to use for the moving average.'\n    'If left as None, then moving averages are not used.')\n\ntf.app.flags.DEFINE_integer(\n    'eval_image_size', None, 'Eval image size')\n\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n  if not FLAGS.dataset_dir:\n    raise ValueError('You must supply the dataset directory with --dataset_dir')\n    \n    #######################\n    # Config model_deploy #\n    #######################\n  tf.logging.set_verbosity(tf.logging.INFO)\n  with tf.Graph().as_default():\n      \n    deploy_config = model_deploy.DeploymentConfig(\n      num_clones=FLAGS.num_clones,\n      clone_on_cpu=FLAGS.clone_on_cpu,\n      #replica_id=FLAGS.task,\n      num_replicas=FLAGS.worker_replicas,\n      num_ps_tasks=FLAGS.num_ps_tasks)\n      \n    # Create global_step\n    with tf.device(deploy_config.variables_device()):\n      tf_global_step = slim.create_global_step()\n    ######################\n    # Select the dataset #\n    ######################\n    dataset = dataset_factory.get_dataset(\n        FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\n\n    ####################\n    # Select the model #\n    ####################\n    network_fn = nets_factory.get_network_fn(\n        FLAGS.model_name,\n        num_classes=(dataset.num_classes - FLAGS.labels_offset),\n        is_training=False)\n\n    ##############################################################\n    # Create a dataset provider that loads data from the dataset #\n    ##############################################################\n    with tf.device(deploy_config.inputs_device()):\n        provider = slim.dataset_data_provider.DatasetDataProvider(\n            dataset,\n            num_readers=FLAGS.num_readers,\n            shuffle=False,\n            common_queue_capacity=2 * FLAGS.batch_size,\n            common_queue_min=FLAGS.batch_size)\n        [image, label] = provider.get(['image', 'label'])\n        label -= FLAGS.labels_offset\n\n    #####################################\n    # Select the preprocessing function #\n    #####################################\n    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\n    image_preprocessing_fn = preprocessing_factory.get_preprocessing(\n        preprocessing_name,\n        is_training=False)\n\n    eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\n\n    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)\n\n    images, labels = tf.train.batch(\n        [image, label],\n        batch_size=FLAGS.batch_size,\n        num_threads=FLAGS.num_preprocessing_threads,\n        capacity=5 * FLAGS.batch_size)\n    batch_queue = slim.prefetch_queue.prefetch_queue(\n        [images, labels], capacity=2 * deploy_config.num_clones)\n    ####################\n    # Define the model #\n    ####################\n    def clone_fn(batch_queue):\n      \"\"\"Allows data parallelism by creating multiple clones of network_fn.\"\"\"\n      with tf.device(deploy_config.inputs_device()):\n        images, labels = batch_queue.dequeue()\n      logits, end_points = network_fn(images)\n      logits = tf.squeeze(logits)\n\n      #############################\n      # Specify the loss function #\n      #############################\n      if 'AuxLogits' in end_points:\n        tf.losses.mean_squared_error(\n            predictions=end_points['AuxLogits'], labels=labels, weights=0.4, scope='aux_loss')\n      tf.losses.mean_squared_error(\n          predictions=logits, labels=labels, weights=1.0)\n      return end_points\n\n    #clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])\n    #first_clone_scope = deploy_config.clone_scope(0)\n    ####################\n    # Define the model #\n    ####################\n    logits, _ = network_fn(images)\n\n    if FLAGS.moving_average_decay:\n      variable_averages = tf.train.ExponentialMovingAverage(\n          FLAGS.moving_average_decay, tf_global_step)\n      variables_to_restore = variable_averages.variables_to_restore(\n          slim.get_model_variables())\n      variables_to_restore[tf_global_step.op.name] = tf_global_step\n    else:\n      variables_to_restore = slim.get_variables_to_restore()\n\n    logits = tf.squeeze(logits)\n\n    # Define the metrics:\n    predictions = logits\n\n    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n        'Accuracy': tf.metrics.root_mean_squared_error(predictions, labels),\n        'Recall_5': slim.metrics.streaming_recall(\n            logits, labels),\n    })\n\n    # Print the summaries to screen.\n    print_ops = []\n    summary_ops = []\n    for name, value in names_to_values.items():\n      summary_name = 'eval/%s' % name\n      op = tf.summary.scalar(summary_name, value, collections=[])\n      op = tf.Print(op, [value], summary_name)\n      summary_ops.append(op)\n      print_ops.append(tf.Print(value, [value], summary_name))\n      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n\n    # TODO(sguada) use num_epochs=1\n    if FLAGS.max_num_batches:\n      num_batches = FLAGS.max_num_batches\n    else:\n      # This ensures that we make a single pass over all of the data.\n      num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\n\n    if tf.gfile.IsDirectory(FLAGS.checkpoint_path):\n        if tf.train.latest_checkpoint(FLAGS.checkpoint_path):\n            checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\n        else:\n            checkpoint_path = FLAGS.checkpoint_path\n\n    eval_interval_secs = 6\n    \n    tf.logging.info('Evaluating %s' % checkpoint_path)\n\n    slim.evaluation.evaluation_loop(\n        master=FLAGS.master,\n        checkpoint_dir=checkpoint_path,\n        logdir=FLAGS.eval_dir,\n        num_evals=num_batches,\n        eval_op=list(names_to_updates.values()) + print_ops,\n        variables_to_restore=variables_to_restore,\n        eval_interval_secs = eval_interval_secs )\nif __name__ == '__main__':\n  tf.app.run()\n\nI tried to use some code like Tensorflow tutorial as well:\n# Creates a graph.\nwith tf.device('/gpu:2'):\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\n# Creates a session with allow_soft_placement and log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(\n         allow_soft_placement=True, log_device_placement=True))\n# Runs the op.\nprint(sess.run(c))\n\nI modified the code in this way:\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport tensorflow as tf\n\nfrom datasets import dataset_factory\nfrom nets import nets_factory\nfrom preprocessing import preprocessing_factory\n\nslim = tf.contrib.slim\n\ntf.app.flags.DEFINE_integer(\n    'batch_size', 32, 'The number of samples in each batch.')\n\ntf.app.flags.DEFINE_integer(\n    'max_num_batches', None,\n    'Max number of batches to evaluate by default use all.')\n\ntf.app.flags.DEFINE_string(\n    'master', '', 'The address of the TensorFlow master to use.')\n\ntf.app.flags.DEFINE_string(\n    'checkpoint_path', '...',\n    'The directory where the model was written to or an absolute path to a '\n    'checkpoint file.')\n\ntf.app.flags.DEFINE_string(\n    'eval_dir', '...',\n    'Directory where the results are saved to.')\n\ntf.app.flags.DEFINE_integer(\n    'num_preprocessing_threads', 4,\n    'The number of threads used to create the batches.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_name', '...', 'The name of the dataset to load.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_split_name', 'validation', 'The name of the train/test split.')\n\ntf.app.flags.DEFINE_string(\n    'dataset_dir', '...', \n    'The directory where the dataset files are stored.')\n\ntf.app.flags.DEFINE_integer(\n    'labels_offset', 0,\n    'An offset for the labels in the dataset. This flag is primarily used to '\n    'evaluate the VGG and ResNet architectures which do not use a background '\n    'class for the ImageNet dataset.')\n\ntf.app.flags.DEFINE_string(\n    'model_name', 'densenet161', 'The name of the architecture to evaluate.')\n\ntf.app.flags.DEFINE_string(\n    'preprocessing_name', None, 'The name of the preprocessing to use. If left '\n    'as `None`, then the model_name flag is used.')\n\ntf.app.flags.DEFINE_float(\n    'moving_average_decay', None,\n    'The decay to use for the moving average.'\n    'If left as None, then moving averages are not used.')\n\ntf.app.flags.DEFINE_integer(\n    'eval_image_size', None, 'Eval image size')\n\nFLAGS = tf.app.flags.FLAGS\n\n# Initialize all global and local variables\ninit = tf.group(tf.global_variables_initializer(),\n                   tf.local_variables_initializer())\n\ndef main(_):\n  if not FLAGS.dataset_dir:\n    raise ValueError('You must supply the dataset directory with --dataset_dir')\n\n  tf.logging.set_verbosity(tf.logging.INFO)\n  \n  sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n                                          log_device_placement=True))\n  \n  with tf.Graph().as_default(), tf.device('/gpu:0'):\n      \n    sess.run(init)\n    tf_global_step = slim.get_or_create_global_step()\n\n    ######################\n    # Select the dataset #\n    ######################\n    dataset = dataset_factory.get_dataset(\n        FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\n\n    ####################\n    # Select the model #\n    ####################\n    network_fn = nets_factory.get_network_fn(\n        FLAGS.model_name,\n        num_classes=(dataset.num_classes - FLAGS.labels_offset),\n        is_training=False)\n\n    ##############################################################\n    # Create a dataset provider that loads data from the dataset #\n    ##############################################################\n    provider = slim.dataset_data_provider.DatasetDataProvider(\n        dataset,\n        shuffle=False,\n        common_queue_capacity=2 * FLAGS.batch_size,\n        common_queue_min=FLAGS.batch_size)\n    [image, label] = provider.get(['image', 'label'])\n    label -= FLAGS.labels_offset\n\n    #####################################\n    # Select the preprocessing function #\n    #####################################\n    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\n    image_preprocessing_fn = preprocessing_factory.get_preprocessing(\n        preprocessing_name,\n        is_training=False)\n\n    eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\n\n    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)\n\n    images, labels = tf.train.batch(\n        [image, label],\n        batch_size=FLAGS.batch_size,\n        num_threads=FLAGS.num_preprocessing_threads,\n        capacity=5 * FLAGS.batch_size)\n\n    ####################\n    # Define the model #\n    ####################\n    logits, _ = network_fn(images)\n\n    if FLAGS.moving_average_decay:\n      variable_averages = tf.train.ExponentialMovingAverage(\n          FLAGS.moving_average_decay, tf_global_step)\n      variables_to_restore = variable_averages.variables_to_restore(\n          slim.get_model_variables())\n      variables_to_restore[tf_global_step.op.name] = tf_global_step\n    else:\n      variables_to_restore = slim.get_variables_to_restore()\n\n    logits = tf.squeeze(logits)\n\n    # Define the metrics:\n    predictions = logits\n\n    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n        'Accuracy': tf.metrics.root_mean_squared_error(predictions, labels),\n        'Recall_5': slim.metrics.streaming_recall(\n            logits, labels),\n    })\n\n    # Print the summaries to screen.\n    print_ops = []\n    summary_ops = []\n    for name, value in names_to_values.items():\n      summary_name = 'eval/%s' % name\n      op = tf.summary.scalar(summary_name, value, collections=[])\n      op = tf.Print(op, [value], summary_name)\n      summary_ops.append(op)\n      print_ops.append(tf.Print(value, [value], summary_name))\n      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n      \n    # TODO(sguada) use num_epochs=1\n    if FLAGS.max_num_batches:\n      num_batches = FLAGS.max_num_batches\n    else:\n      # This ensures that we make a single pass over all of the data.\n      num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\n\n    if tf.gfile.IsDirectory(FLAGS.checkpoint_path):\n        if tf.train.latest_checkpoint(FLAGS.checkpoint_path):\n            checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\n        else:\n            checkpoint_path = FLAGS.checkpoint_path\n\n    #print(checkpoint_path)\n    eval_interval_secs = 6\n    \n    tf.logging.info('Evaluating %s' % checkpoint_path)\n\n    slim.evaluation.evaluation_loop(\n        master=FLAGS.master,\n        checkpoint_dir=checkpoint_path,\n        logdir=FLAGS.eval_dir,\n        num_evals=num_batches,\n        eval_op=list(names_to_updates.values()) + print_ops,\n        variables_to_restore=variables_to_restore,\n        eval_interval_secs = eval_interval_secs )\n\n\nif __name__ == '__main__':\n  tf.app.run()\n\nWhen I run this code, I face this error:\n    Traceback (most recent call last):\n  File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 210, in <module>\n    tf.app.run()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 206, in main\n    eval_interval_secs = 60 )\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py\", line 296, in evaluation_loo\np\n    timeout=timeout)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py\", line 447, in evalua\nte_repeatedly\n    session_creator=session_creator, hooks=hooks) as session:\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 668, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 490, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 842, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 847, in _create_session\n    return self._sess_creator.create_session()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 551, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 425, in create_session\n    init_fn=self._scaffold.init_fn)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py\", line 273, in prepare_session\n    config=config)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py\", line 189, in _restore_checkpoin\nt\n    saver.restore(sess, checkpoint_filename_with_path)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1560, in restore\n    {self.saver_def.filename_tensor_name: save_path})\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'eval_step': Could not satisfy explicit device s\npecification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nConst: GPU CPU \nAssignAdd: CPU \nVariableV2: CPU \nIdentity: GPU CPU \nAssign: CPU \nIsVariableInitialized: CPU \n\t [[Node: eval_step = VariableV2[_class=[\"loc:@eval_step\"], container=\"\", dtype=DT_INT64, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]\n()]]\n\nCaused by op u'eval_step', defined at:\n  File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 210, in <module>\n    tf.app.run()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 206, in main\n    eval_interval_secs = 60 )\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py\", line 296, in evaluation_loo\np\n    timeout=timeout)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py\", line 410, in evalua\nte_repeatedly\n    eval_step = get_or_create_eval_step()\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/evaluation.py\", line 57, in _get_or_create_eval_step\n    collections=[ops.GraphKeys.LOCAL_VARIABLES, ops.GraphKeys.EVAL_STEP])\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 367, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\n    use_resource=use_resource)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 725, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\n    expected_shape=expected_shape)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 283, in _init_from_args\n    name=name)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 131, in variable_op_v2\n    shared_name=shared_name)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 682, in _variable_v2\n    name=name)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'eval_step': Could not satisfy explicit device specification '\n/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nConst: GPU CPU \nAssignAdd: CPU \nVariableV2: CPU \nIdentity: GPU CPU \nAssign: CPU \nIsVariableInitialized: CPU \n\t [[Node: eval_step = VariableV2[_class=[\"loc:@eval_step\"], container=\"\", dtype=DT_INT64, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]\n()]]\n\nERROR:tensorflow:==================================\nObject was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):\n<tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string>\nIf you want to mark it as used call its \"mark_used()\" method.", "body": "Do you have any idea how can I run [\"eval_image_classifier.py\"][1] on GPUs? Should I change any functions or do any modifications? Or whether there exist any other specific functions for evaluation on GPUs?\r\n\r\nI can already run [\"train_image_classifier.py\"][2] on GPUs because of having the associated flag for switching between CPU and GPU:\r\n\r\n    tf.app.flags.DEFINE_boolean('clone_on_cpu', False,\r\n                            'Use CPUs to deploy clones.')\r\n\r\n\r\nI did try to add the same line to `eval_image_classifier.py`, but it had no effect. I'm using Python 2.7.13 and Tensorflow 1.3.0 .\r\n\r\n    from __future__ import absolute_import\r\n    from __future__ import division\r\n    from __future__ import print_function\r\n    import math\r\n    import tensorflow as tf\r\n    from deployment import model_deploy\r\n    from datasets import dataset_factory\r\n    from nets import nets_factory\r\n    from preprocessing import preprocessing_factory\r\n    slim = tf.contrib.slim\r\n    \r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'batch_size', 32, 'The number of samples in each batch.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'max_num_batches', None,\r\n        'Max number of batches to evaluate by default use all.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'master', '', 'The address of the TensorFlow master to use.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'checkpoint_path', '...',\r\n        'The directory where the model was written to or an absolute path to a '\r\n        'checkpoint file.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'eval_dir', '...',\r\n        'Directory where the results are saved to.')\r\n    \r\n    tf.app.flags.DEFINE_integer('num_clones', 1,\r\n                                'Number of model clones to deploy.')\r\n    \r\n    tf.app.flags.DEFINE_boolean('clone_on_cpu', False,\r\n                                'Use CPUs to deploy clones.')\r\n    \r\n    tf.app.flags.DEFINE_integer('worker_replicas', 1, 'Number of worker replicas.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'num_readers', 4,\r\n        'The number of parallel readers that read data from the dataset.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'num_ps_tasks', 0,\r\n        'The number of parameter servers. If the value is 0, then the parameters '\r\n        'are handled locally by the worker.')\r\n    \r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'num_preprocessing_threads', 4,\r\n        'The number of threads used to create the batches.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'dataset_name', '...', 'The name of the dataset to load.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'dataset_split_name', 'validation', 'The name of the train/test split.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'dataset_dir', '...', \r\n        'The directory where the dataset files are stored.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'labels_offset', 0,\r\n        'An offset for the labels in the dataset. This flag is primarily used to '\r\n        'evaluate the VGG and ResNet architectures which do not use a background '\r\n        'class for the ImageNet dataset.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'model_name', 'densenet161', 'The name of the architecture to evaluate.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'preprocessing_name', None, 'The name of the preprocessing to use. If left '\r\n        'as `None`, then the model_name flag is used.')\r\n    \r\n    tf.app.flags.DEFINE_float(\r\n        'moving_average_decay', None,\r\n        'The decay to use for the moving average.'\r\n        'If left as None, then moving averages are not used.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'eval_image_size', None, 'Eval image size')\r\n    \r\n    FLAGS = tf.app.flags.FLAGS\r\n    \r\n    \r\n    def main(_):\r\n      if not FLAGS.dataset_dir:\r\n        raise ValueError('You must supply the dataset directory with --dataset_dir')\r\n        \r\n        #######################\r\n        # Config model_deploy #\r\n        #######################\r\n      tf.logging.set_verbosity(tf.logging.INFO)\r\n      with tf.Graph().as_default():\r\n          \r\n        deploy_config = model_deploy.DeploymentConfig(\r\n          num_clones=FLAGS.num_clones,\r\n          clone_on_cpu=FLAGS.clone_on_cpu,\r\n          #replica_id=FLAGS.task,\r\n          num_replicas=FLAGS.worker_replicas,\r\n          num_ps_tasks=FLAGS.num_ps_tasks)\r\n          \r\n        # Create global_step\r\n        with tf.device(deploy_config.variables_device()):\r\n          tf_global_step = slim.create_global_step()\r\n        ######################\r\n        # Select the dataset #\r\n        ######################\r\n        dataset = dataset_factory.get_dataset(\r\n            FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\r\n    \r\n        ####################\r\n        # Select the model #\r\n        ####################\r\n        network_fn = nets_factory.get_network_fn(\r\n            FLAGS.model_name,\r\n            num_classes=(dataset.num_classes - FLAGS.labels_offset),\r\n            is_training=False)\r\n    \r\n        ##############################################################\r\n        # Create a dataset provider that loads data from the dataset #\r\n        ##############################################################\r\n        with tf.device(deploy_config.inputs_device()):\r\n            provider = slim.dataset_data_provider.DatasetDataProvider(\r\n                dataset,\r\n                num_readers=FLAGS.num_readers,\r\n                shuffle=False,\r\n                common_queue_capacity=2 * FLAGS.batch_size,\r\n                common_queue_min=FLAGS.batch_size)\r\n            [image, label] = provider.get(['image', 'label'])\r\n            label -= FLAGS.labels_offset\r\n    \r\n        #####################################\r\n        # Select the preprocessing function #\r\n        #####################################\r\n        preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\r\n        image_preprocessing_fn = preprocessing_factory.get_preprocessing(\r\n            preprocessing_name,\r\n            is_training=False)\r\n    \r\n        eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\r\n    \r\n        image = image_preprocessing_fn(image, eval_image_size, eval_image_size)\r\n    \r\n        images, labels = tf.train.batch(\r\n            [image, label],\r\n            batch_size=FLAGS.batch_size,\r\n            num_threads=FLAGS.num_preprocessing_threads,\r\n            capacity=5 * FLAGS.batch_size)\r\n        batch_queue = slim.prefetch_queue.prefetch_queue(\r\n            [images, labels], capacity=2 * deploy_config.num_clones)\r\n        ####################\r\n        # Define the model #\r\n        ####################\r\n        def clone_fn(batch_queue):\r\n          \"\"\"Allows data parallelism by creating multiple clones of network_fn.\"\"\"\r\n          with tf.device(deploy_config.inputs_device()):\r\n            images, labels = batch_queue.dequeue()\r\n          logits, end_points = network_fn(images)\r\n          logits = tf.squeeze(logits)\r\n    \r\n          #############################\r\n          # Specify the loss function #\r\n          #############################\r\n          if 'AuxLogits' in end_points:\r\n            tf.losses.mean_squared_error(\r\n                predictions=end_points['AuxLogits'], labels=labels, weights=0.4, scope='aux_loss')\r\n          tf.losses.mean_squared_error(\r\n              predictions=logits, labels=labels, weights=1.0)\r\n          return end_points\r\n    \r\n        #clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])\r\n        #first_clone_scope = deploy_config.clone_scope(0)\r\n        ####################\r\n        # Define the model #\r\n        ####################\r\n        logits, _ = network_fn(images)\r\n    \r\n        if FLAGS.moving_average_decay:\r\n          variable_averages = tf.train.ExponentialMovingAverage(\r\n              FLAGS.moving_average_decay, tf_global_step)\r\n          variables_to_restore = variable_averages.variables_to_restore(\r\n              slim.get_model_variables())\r\n          variables_to_restore[tf_global_step.op.name] = tf_global_step\r\n        else:\r\n          variables_to_restore = slim.get_variables_to_restore()\r\n    \r\n        logits = tf.squeeze(logits)\r\n    \r\n        # Define the metrics:\r\n        predictions = logits\r\n    \r\n        names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\r\n            'Accuracy': tf.metrics.root_mean_squared_error(predictions, labels),\r\n            'Recall_5': slim.metrics.streaming_recall(\r\n                logits, labels),\r\n        })\r\n    \r\n        # Print the summaries to screen.\r\n        print_ops = []\r\n        summary_ops = []\r\n        for name, value in names_to_values.items():\r\n          summary_name = 'eval/%s' % name\r\n          op = tf.summary.scalar(summary_name, value, collections=[])\r\n          op = tf.Print(op, [value], summary_name)\r\n          summary_ops.append(op)\r\n          print_ops.append(tf.Print(value, [value], summary_name))\r\n          tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\r\n    \r\n        # TODO(sguada) use num_epochs=1\r\n        if FLAGS.max_num_batches:\r\n          num_batches = FLAGS.max_num_batches\r\n        else:\r\n          # This ensures that we make a single pass over all of the data.\r\n          num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\r\n    \r\n        if tf.gfile.IsDirectory(FLAGS.checkpoint_path):\r\n            if tf.train.latest_checkpoint(FLAGS.checkpoint_path):\r\n                checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\r\n            else:\r\n                checkpoint_path = FLAGS.checkpoint_path\r\n    \r\n        eval_interval_secs = 6\r\n        \r\n        tf.logging.info('Evaluating %s' % checkpoint_path)\r\n    \r\n        slim.evaluation.evaluation_loop(\r\n            master=FLAGS.master,\r\n            checkpoint_dir=checkpoint_path,\r\n            logdir=FLAGS.eval_dir,\r\n            num_evals=num_batches,\r\n            eval_op=list(names_to_updates.values()) + print_ops,\r\n            variables_to_restore=variables_to_restore,\r\n            eval_interval_secs = eval_interval_secs )\r\n    if __name__ == '__main__':\r\n      tf.app.run()\r\n\r\nI tried to use some code like Tensorflow tutorial as well:\r\n    \r\n    # Creates a graph.\r\n    with tf.device('/gpu:2'):\r\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\n    c = tf.matmul(a, b)\r\n    # Creates a session with allow_soft_placement and log_device_placement set to True.\r\n    sess = tf.Session(config=tf.ConfigProto(\r\n             allow_soft_placement=True, log_device_placement=True))\r\n    # Runs the op.\r\n    print(sess.run(c))\r\n\r\nI modified the code in this way:\r\n\r\n    \r\n    from __future__ import absolute_import\r\n    from __future__ import division\r\n    from __future__ import print_function\r\n    \r\n    import math\r\n    import tensorflow as tf\r\n    \r\n    from datasets import dataset_factory\r\n    from nets import nets_factory\r\n    from preprocessing import preprocessing_factory\r\n    \r\n    slim = tf.contrib.slim\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'batch_size', 32, 'The number of samples in each batch.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'max_num_batches', None,\r\n        'Max number of batches to evaluate by default use all.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'master', '', 'The address of the TensorFlow master to use.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'checkpoint_path', '...',\r\n        'The directory where the model was written to or an absolute path to a '\r\n        'checkpoint file.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'eval_dir', '...',\r\n        'Directory where the results are saved to.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'num_preprocessing_threads', 4,\r\n        'The number of threads used to create the batches.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'dataset_name', '...', 'The name of the dataset to load.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'dataset_split_name', 'validation', 'The name of the train/test split.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'dataset_dir', '...', \r\n        'The directory where the dataset files are stored.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'labels_offset', 0,\r\n        'An offset for the labels in the dataset. This flag is primarily used to '\r\n        'evaluate the VGG and ResNet architectures which do not use a background '\r\n        'class for the ImageNet dataset.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'model_name', 'densenet161', 'The name of the architecture to evaluate.')\r\n    \r\n    tf.app.flags.DEFINE_string(\r\n        'preprocessing_name', None, 'The name of the preprocessing to use. If left '\r\n        'as `None`, then the model_name flag is used.')\r\n    \r\n    tf.app.flags.DEFINE_float(\r\n        'moving_average_decay', None,\r\n        'The decay to use for the moving average.'\r\n        'If left as None, then moving averages are not used.')\r\n    \r\n    tf.app.flags.DEFINE_integer(\r\n        'eval_image_size', None, 'Eval image size')\r\n    \r\n    FLAGS = tf.app.flags.FLAGS\r\n    \r\n    # Initialize all global and local variables\r\n    init = tf.group(tf.global_variables_initializer(),\r\n                       tf.local_variables_initializer())\r\n    \r\n    def main(_):\r\n      if not FLAGS.dataset_dir:\r\n        raise ValueError('You must supply the dataset directory with --dataset_dir')\r\n    \r\n      tf.logging.set_verbosity(tf.logging.INFO)\r\n      \r\n      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\r\n                                              log_device_placement=True))\r\n      \r\n      with tf.Graph().as_default(), tf.device('/gpu:0'):\r\n          \r\n        sess.run(init)\r\n        tf_global_step = slim.get_or_create_global_step()\r\n    \r\n        ######################\r\n        # Select the dataset #\r\n        ######################\r\n        dataset = dataset_factory.get_dataset(\r\n            FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\r\n    \r\n        ####################\r\n        # Select the model #\r\n        ####################\r\n        network_fn = nets_factory.get_network_fn(\r\n            FLAGS.model_name,\r\n            num_classes=(dataset.num_classes - FLAGS.labels_offset),\r\n            is_training=False)\r\n    \r\n        ##############################################################\r\n        # Create a dataset provider that loads data from the dataset #\r\n        ##############################################################\r\n        provider = slim.dataset_data_provider.DatasetDataProvider(\r\n            dataset,\r\n            shuffle=False,\r\n            common_queue_capacity=2 * FLAGS.batch_size,\r\n            common_queue_min=FLAGS.batch_size)\r\n        [image, label] = provider.get(['image', 'label'])\r\n        label -= FLAGS.labels_offset\r\n    \r\n        #####################################\r\n        # Select the preprocessing function #\r\n        #####################################\r\n        preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\r\n        image_preprocessing_fn = preprocessing_factory.get_preprocessing(\r\n            preprocessing_name,\r\n            is_training=False)\r\n    \r\n        eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\r\n    \r\n        image = image_preprocessing_fn(image, eval_image_size, eval_image_size)\r\n    \r\n        images, labels = tf.train.batch(\r\n            [image, label],\r\n            batch_size=FLAGS.batch_size,\r\n            num_threads=FLAGS.num_preprocessing_threads,\r\n            capacity=5 * FLAGS.batch_size)\r\n    \r\n        ####################\r\n        # Define the model #\r\n        ####################\r\n        logits, _ = network_fn(images)\r\n    \r\n        if FLAGS.moving_average_decay:\r\n          variable_averages = tf.train.ExponentialMovingAverage(\r\n              FLAGS.moving_average_decay, tf_global_step)\r\n          variables_to_restore = variable_averages.variables_to_restore(\r\n              slim.get_model_variables())\r\n          variables_to_restore[tf_global_step.op.name] = tf_global_step\r\n        else:\r\n          variables_to_restore = slim.get_variables_to_restore()\r\n    \r\n        logits = tf.squeeze(logits)\r\n    \r\n        # Define the metrics:\r\n        predictions = logits\r\n\r\n        names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\r\n            'Accuracy': tf.metrics.root_mean_squared_error(predictions, labels),\r\n            'Recall_5': slim.metrics.streaming_recall(\r\n                logits, labels),\r\n        })\r\n    \r\n        # Print the summaries to screen.\r\n        print_ops = []\r\n        summary_ops = []\r\n        for name, value in names_to_values.items():\r\n          summary_name = 'eval/%s' % name\r\n          op = tf.summary.scalar(summary_name, value, collections=[])\r\n          op = tf.Print(op, [value], summary_name)\r\n          summary_ops.append(op)\r\n          print_ops.append(tf.Print(value, [value], summary_name))\r\n          tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\r\n          \r\n        # TODO(sguada) use num_epochs=1\r\n        if FLAGS.max_num_batches:\r\n          num_batches = FLAGS.max_num_batches\r\n        else:\r\n          # This ensures that we make a single pass over all of the data.\r\n          num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\r\n    \r\n        if tf.gfile.IsDirectory(FLAGS.checkpoint_path):\r\n            if tf.train.latest_checkpoint(FLAGS.checkpoint_path):\r\n                checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\r\n            else:\r\n                checkpoint_path = FLAGS.checkpoint_path\r\n    \r\n        #print(checkpoint_path)\r\n        eval_interval_secs = 6\r\n        \r\n        tf.logging.info('Evaluating %s' % checkpoint_path)\r\n    \r\n        slim.evaluation.evaluation_loop(\r\n            master=FLAGS.master,\r\n            checkpoint_dir=checkpoint_path,\r\n            logdir=FLAGS.eval_dir,\r\n            num_evals=num_batches,\r\n            eval_op=list(names_to_updates.values()) + print_ops,\r\n            variables_to_restore=variables_to_restore,\r\n            eval_interval_secs = eval_interval_secs )\r\n    \r\n    \r\n    if __name__ == '__main__':\r\n      tf.app.run()\r\n\r\nWhen I run this code, I face this error:\r\n\r\n        Traceback (most recent call last):\r\n      File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 210, in <module>\r\n        tf.app.run()\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n        _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n      File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 206, in main\r\n        eval_interval_secs = 60 )\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py\", line 296, in evaluation_loo\r\n    p\r\n        timeout=timeout)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py\", line 447, in evalua\r\n    te_repeatedly\r\n        session_creator=session_creator, hooks=hooks) as session:\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 668, in __init__\r\n        stop_grace_period_secs=stop_grace_period_secs)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 490, in __init__\r\n        self._sess = _RecoverableSession(self._coordinated_creator)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 842, in __init__\r\n        _WrappedSession.__init__(self, self._create_session())\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 847, in _create_session\r\n        return self._sess_creator.create_session()\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 551, in create_session\r\n        self.tf_sess = self._session_creator.create_session()\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 425, in create_session\r\n        init_fn=self._scaffold.init_fn)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py\", line 273, in prepare_session\r\n        config=config)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py\", line 189, in _restore_checkpoin\r\n    t\r\n        saver.restore(sess, checkpoint_filename_with_path)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1560, in restore\r\n        {self.saver_def.filename_tensor_name: save_path})\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n        run_metadata_ptr)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\r\n        feed_dict_tensor, options, run_metadata)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n        options, run_metadata)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n        raise type(e)(node_def, op, message)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'eval_step': Could not satisfy explicit device s\r\n    pecification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\n    Colocation Debug Info:\r\n    Colocation group had the following types and devices: \r\n    Const: GPU CPU \r\n    AssignAdd: CPU \r\n    VariableV2: CPU \r\n    Identity: GPU CPU \r\n    Assign: CPU \r\n    IsVariableInitialized: CPU \r\n    \t [[Node: eval_step = VariableV2[_class=[\"loc:@eval_step\"], container=\"\", dtype=DT_INT64, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]\r\n    ()]]\r\n    \r\n    Caused by op u'eval_step', defined at:\r\n      File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 210, in <module>\r\n        tf.app.run()\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n        _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n      File \"/home/zgholami/test1/GZ_Project/GZ_DenseNet_TF-slim/eval_image_classifier.py\", line 206, in main\r\n        eval_interval_secs = 60 )\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py\", line 296, in evaluation_loo\r\n    p\r\n        timeout=timeout)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py\", line 410, in evalua\r\n    te_repeatedly\r\n        eval_step = get_or_create_eval_step()\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/training/evaluation.py\", line 57, in _get_or_create_eval_step\r\n        collections=[ops.GraphKeys.LOCAL_VARIABLES, ops.GraphKeys.EVAL_STEP])\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\r\n        use_resource=use_resource, custom_getter=custom_getter)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\r\n        use_resource=use_resource, custom_getter=custom_getter)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 367, in get_variable\r\n        validate_shape=validate_shape, use_resource=use_resource)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\r\n        use_resource=use_resource)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 725, in _get_single_variable\r\n        validate_shape=validate_shape)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\r\n        expected_shape=expected_shape)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 283, in _init_from_args\r\n        name=name)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 131, in variable_op_v2\r\n        shared_name=shared_name)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 682, in _variable_v2\r\n        name=name)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n        op_def=op_def)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\r\n        original_op=self._default_original_op, op_def=op_def)\r\n      File \"/group/pawsey0245/zgholami/pyml/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\r\n        self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n    \r\n    InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'eval_step': Could not satisfy explicit device specification '\r\n    /device:GPU:0' because no supported kernel for GPU devices is available.\r\n    Colocation Debug Info:\r\n    Colocation group had the following types and devices: \r\n    Const: GPU CPU \r\n    AssignAdd: CPU \r\n    VariableV2: CPU \r\n    Identity: GPU CPU \r\n    Assign: CPU \r\n    IsVariableInitialized: CPU \r\n    \t [[Node: eval_step = VariableV2[_class=[\"loc:@eval_step\"], container=\"\", dtype=DT_INT64, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]\r\n    ()]]\r\n    \r\n    ERROR:tensorflow:==================================\r\n    Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):\r\n    <tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string>\r\n    If you want to mark it as used call its \"mark_used()\" method.\r\n\r\n  [1]: https://github.com/pudae/tensorflow-densenet/blob/master/eval_image_classifier.py\r\n  [2]: https://github.com/pudae/tensorflow-densenet/blob/master/train_image_classifier.py\r\n"}