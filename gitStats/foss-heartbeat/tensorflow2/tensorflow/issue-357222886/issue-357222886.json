{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22092", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22092/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22092/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22092/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22092", "id": 357222886, "node_id": "MDU6SXNzdWUzNTcyMjI4ODY=", "number": 22092, "title": "TF Record, Example, and SeqeunceExample inconsistency(?) / Documentation request", "user": {"login": "SumNeuron", "id": 22868585, "node_id": "MDQ6VXNlcjIyODY4NTg1", "avatar_url": "https://avatars3.githubusercontent.com/u/22868585?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SumNeuron", "html_url": "https://github.com/SumNeuron", "followers_url": "https://api.github.com/users/SumNeuron/followers", "following_url": "https://api.github.com/users/SumNeuron/following{/other_user}", "gists_url": "https://api.github.com/users/SumNeuron/gists{/gist_id}", "starred_url": "https://api.github.com/users/SumNeuron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SumNeuron/subscriptions", "organizations_url": "https://api.github.com/users/SumNeuron/orgs", "repos_url": "https://api.github.com/users/SumNeuron/repos", "events_url": "https://api.github.com/users/SumNeuron/events{/privacy}", "received_events_url": "https://api.github.com/users/SumNeuron/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "lamberta", "id": 43051, "node_id": "MDQ6VXNlcjQzMDUx", "avatar_url": "https://avatars2.githubusercontent.com/u/43051?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lamberta", "html_url": "https://github.com/lamberta", "followers_url": "https://api.github.com/users/lamberta/followers", "following_url": "https://api.github.com/users/lamberta/following{/other_user}", "gists_url": "https://api.github.com/users/lamberta/gists{/gist_id}", "starred_url": "https://api.github.com/users/lamberta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lamberta/subscriptions", "organizations_url": "https://api.github.com/users/lamberta/orgs", "repos_url": "https://api.github.com/users/lamberta/repos", "events_url": "https://api.github.com/users/lamberta/events{/privacy}", "received_events_url": "https://api.github.com/users/lamberta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "lamberta", "id": 43051, "node_id": "MDQ6VXNlcjQzMDUx", "avatar_url": "https://avatars2.githubusercontent.com/u/43051?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lamberta", "html_url": "https://github.com/lamberta", "followers_url": "https://api.github.com/users/lamberta/followers", "following_url": "https://api.github.com/users/lamberta/following{/other_user}", "gists_url": "https://api.github.com/users/lamberta/gists{/gist_id}", "starred_url": "https://api.github.com/users/lamberta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lamberta/subscriptions", "organizations_url": "https://api.github.com/users/lamberta/orgs", "repos_url": "https://api.github.com/users/lamberta/repos", "events_url": "https://api.github.com/users/lamberta/events{/privacy}", "received_events_url": "https://api.github.com/users/lamberta/received_events", "type": "User", "site_admin": false}, {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, {"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}, {"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-09-05T13:12:16Z", "updated_at": "2018-11-14T09:05:25Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I have posted 2 stack overflow questions regarding TF Records and (Sequence)Examples.<br>\nI even had a bounty on one.<br>\nDespite only receiving up-votes. Neither received any support.<br>\nBoth had an associated Colab document to assist.</p>\n<p>The questions where</p>\n<ol>\n<li>\n<p>[Store images as byte strings or per channel?]<a href=\"https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel\" rel=\"nofollow\">https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel</a>)</p>\n</li>\n<li>\n<p><a href=\"https://stackoverflow.com/questions/52064866/tensorflow-1-10-tfrecorddataset-recovering-tfrecords\" rel=\"nofollow\">Recovering TF Records</a></p>\n</li>\n</ol>\n<p>With the corresponding colabs</p>\n<p><a href=\"https://colab.research.google.com/drive/1HUGoXfgxp0A_0eSdaCzutOkFvnYZ-egv\" rel=\"nofollow\">Colab 1</a><br>\n<a href=\"https://colab.research.google.com/drive/1M10tbHih5eJ8LiApJSKKpNM79IconYJX\" rel=\"nofollow\">Colab 2</a></p>\n<p>I am creating an issue as I am struggling to see the consistency in the behavior between tf Records, Example, SequenceExample, Feature, Features, FeatureList, FeatureLists, FixLenFeature, FixLenSequenceFeature, and VarLenFeature.</p>\n<p>In this <a href=\"https://colab.research.google.com/drive/1M10tbHih5eJ8LiApJSKKpNM79IconYJX\" rel=\"nofollow\">Colab</a></p>\n<p>I survey 10 ways of encoding an array / array of arrays.</p>\n<ul>\n<li>Example: Int64 feature (int array)</li>\n<li>Example: Float feature (float array)</li>\n<li>Example: Bytes feature (int array dumped to byte string)</li>\n<li>SequenceExample: Int64 feature list (array of int arrays)</li>\n<li>SequenceExample: Float feature list (array of float arrays)</li>\n<li>SequenceExample: Bytes feature list (array of int arrays dumped to byte strings)</li>\n<li>Example: Bytes feature (array of int arrays all of which is dumped to byte string)</li>\n<li>SequenceExample: Bytes feature list (array of int arrays dumped to byte strings)</li>\n<li>SequenceExample: Bytes feature list (array of int arrays all of which is dumped to byte string)</li>\n<li>SequenceExample: Bytes feature list (array of int arrays, where each int is dumped to byte string)</li>\n</ul>\n<p>In short, with the exception of 8, I was able to 'recover' (write to tf.record and read back the data). However, it should be noted that for methods 7 and 10, the retrieved array is flattened.</p>\n<p>Further, when I state 'recover' I mean that of course that the feature is wrapped in an addition array. e.g. shape (3, ) becomes (1, 3).</p>\n<p>As most tutorials of TF Record, Example and SequenceExample are just a rehashing of the one example provided in the TF Docs (for a movie recommender system, although code is provided for images).</p>\n<p>I think it would be beneficial for a \"style guide\" of sorts, given that one can their data in a myriad of ways. (e.g. are byte strings superior to float feature lists? should one break their image / sequence down per channel? why is there FixLenSeqeuenceFeature but no VarLenSequenceFeature?, if Example and SequenceExample are meant to contain a single data record, why are the only options List based features?)</p>\n<p>I would be happy to contribute to more documentation / examples if I knew the answer to these questions. However, to my unexperienced eyes the mismatch between converting data into a (Sequence)Example and extracting it out from a Record is bewildering.</p>\n<hr>\n<p>TensorFlow Butler requested information:</p>\n<p>Have I written custom code: yes, see linked colabs and S.O. posts.<br>\nOS Platform and Distribution: N/a (irrelevant, but Ubuntu 16.04LTS / macOS High Sierra)<br>\nTensorFlow installed from: (irrelevant, but conda / Colab's V.M.)<br>\nTensorFlow version: 1.10<br>\nBazel version: N/a<br>\nCUDA/cuDNN version: N/a (irrelevant but latest / Colab's V.M.'s)<br>\nGPU model and memory: N/a (irrelevant, but NVIDIA Titan X / NVIDIA Titan V / Colab's GPU)<br>\nExact command to reproduce: see linked to code<br>\nMobile device: N/a  (irrelevant)</p>\n<p>This is more of a \"meta\" question regarding the structuring of Example / SequenceExample, the correspondingly needed Feature, Features, FeatureList, FeatureLists, etc and the parsing equivalents FixedLenFeature, VariableLenFeature, FixedLenSequenceFeature.</p>\n<p>More specifically:</p>\n<ul>\n<li>\n<p>a request for more documentation</p>\n</li>\n<li>\n<p>a request for \"best\" practices recording encoding of rank 2+ tensors</p>\n<ul>\n<li>e.g. if I have a sequence in an <em>numpy.ndarray</em> with <em>n</em> channels should I \"dump\" (call <em>.tostring()</em>) on the entire sequence and store in a BytesFeature in an Example? or split each channel up into a Float/Int Feature (or dump to BytesFeature) in an Example / SequenceExample.</li>\n</ul>\n</li>\n<li>\n<p>a request for \"best\" practices as to why ever use Example, when it seems that the \"context features\" are equivalent and then if sequence features are needed later it is easier to adapt? (i.e. the difference between context features in sequence example and normal features of example rather than just calling context features \"meta-data\" of the sequences)</p>\n</li>\n<li>\n<p>a request for \"best' practices for recording rank 0 tensors (as they have to be wrapped into a feature list, so should similarly typed features be concatenated together)</p>\n</li>\n<li>\n<p>a request for elucidating why sometimes decoding a bytes array losses the rank from which it was encoded (see linked colab)</p>\n</li>\n<li>\n<p>a request for a mid-tier api at the feature level e.g. remove the need for the user to define how a feature should be encoded as a record and then decoded  (parsed) from a serialized record. I have a conceptual prototype that I can include here or in another colab if interested.</p>\n</li>\n</ul>\n<p>etc, etc</p>", "body_text": "I have posted 2 stack overflow questions regarding TF Records and (Sequence)Examples.\nI even had a bounty on one.\nDespite only receiving up-votes. Neither received any support.\nBoth had an associated Colab document to assist.\nThe questions where\n\n\n[Store images as byte strings or per channel?]https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel)\n\n\nRecovering TF Records\n\n\nWith the corresponding colabs\nColab 1\nColab 2\nI am creating an issue as I am struggling to see the consistency in the behavior between tf Records, Example, SequenceExample, Feature, Features, FeatureList, FeatureLists, FixLenFeature, FixLenSequenceFeature, and VarLenFeature.\nIn this Colab\nI survey 10 ways of encoding an array / array of arrays.\n\nExample: Int64 feature (int array)\nExample: Float feature (float array)\nExample: Bytes feature (int array dumped to byte string)\nSequenceExample: Int64 feature list (array of int arrays)\nSequenceExample: Float feature list (array of float arrays)\nSequenceExample: Bytes feature list (array of int arrays dumped to byte strings)\nExample: Bytes feature (array of int arrays all of which is dumped to byte string)\nSequenceExample: Bytes feature list (array of int arrays dumped to byte strings)\nSequenceExample: Bytes feature list (array of int arrays all of which is dumped to byte string)\nSequenceExample: Bytes feature list (array of int arrays, where each int is dumped to byte string)\n\nIn short, with the exception of 8, I was able to 'recover' (write to tf.record and read back the data). However, it should be noted that for methods 7 and 10, the retrieved array is flattened.\nFurther, when I state 'recover' I mean that of course that the feature is wrapped in an addition array. e.g. shape (3, ) becomes (1, 3).\nAs most tutorials of TF Record, Example and SequenceExample are just a rehashing of the one example provided in the TF Docs (for a movie recommender system, although code is provided for images).\nI think it would be beneficial for a \"style guide\" of sorts, given that one can their data in a myriad of ways. (e.g. are byte strings superior to float feature lists? should one break their image / sequence down per channel? why is there FixLenSeqeuenceFeature but no VarLenSequenceFeature?, if Example and SequenceExample are meant to contain a single data record, why are the only options List based features?)\nI would be happy to contribute to more documentation / examples if I knew the answer to these questions. However, to my unexperienced eyes the mismatch between converting data into a (Sequence)Example and extracting it out from a Record is bewildering.\n\nTensorFlow Butler requested information:\nHave I written custom code: yes, see linked colabs and S.O. posts.\nOS Platform and Distribution: N/a (irrelevant, but Ubuntu 16.04LTS / macOS High Sierra)\nTensorFlow installed from: (irrelevant, but conda / Colab's V.M.)\nTensorFlow version: 1.10\nBazel version: N/a\nCUDA/cuDNN version: N/a (irrelevant but latest / Colab's V.M.'s)\nGPU model and memory: N/a (irrelevant, but NVIDIA Titan X / NVIDIA Titan V / Colab's GPU)\nExact command to reproduce: see linked to code\nMobile device: N/a  (irrelevant)\nThis is more of a \"meta\" question regarding the structuring of Example / SequenceExample, the correspondingly needed Feature, Features, FeatureList, FeatureLists, etc and the parsing equivalents FixedLenFeature, VariableLenFeature, FixedLenSequenceFeature.\nMore specifically:\n\n\na request for more documentation\n\n\na request for \"best\" practices recording encoding of rank 2+ tensors\n\ne.g. if I have a sequence in an numpy.ndarray with n channels should I \"dump\" (call .tostring()) on the entire sequence and store in a BytesFeature in an Example? or split each channel up into a Float/Int Feature (or dump to BytesFeature) in an Example / SequenceExample.\n\n\n\na request for \"best\" practices as to why ever use Example, when it seems that the \"context features\" are equivalent and then if sequence features are needed later it is easier to adapt? (i.e. the difference between context features in sequence example and normal features of example rather than just calling context features \"meta-data\" of the sequences)\n\n\na request for \"best' practices for recording rank 0 tensors (as they have to be wrapped into a feature list, so should similarly typed features be concatenated together)\n\n\na request for elucidating why sometimes decoding a bytes array losses the rank from which it was encoded (see linked colab)\n\n\na request for a mid-tier api at the feature level e.g. remove the need for the user to define how a feature should be encoded as a record and then decoded  (parsed) from a serialized record. I have a conceptual prototype that I can include here or in another colab if interested.\n\n\netc, etc", "body": "I have posted 2 stack overflow questions regarding TF Records and (Sequence)Examples.\r\nI even had a bounty on one. \r\nDespite only receiving up-votes. Neither received any support.\r\nBoth had an associated Colab document to assist.\r\n\r\nThe questions where\r\n\r\n1. [Store images as byte strings or per channel?]https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel)\r\n\r\n2. [Recovering TF Records](https://stackoverflow.com/questions/52064866/tensorflow-1-10-tfrecorddataset-recovering-tfrecords)\r\n\r\nWith the corresponding colabs\r\n\r\n[Colab 1](https://colab.research.google.com/drive/1HUGoXfgxp0A_0eSdaCzutOkFvnYZ-egv)\r\n[Colab 2](https://colab.research.google.com/drive/1M10tbHih5eJ8LiApJSKKpNM79IconYJX)\r\n\r\n\r\nI am creating an issue as I am struggling to see the consistency in the behavior between tf Records, Example, SequenceExample, Feature, Features, FeatureList, FeatureLists, FixLenFeature, FixLenSequenceFeature, and VarLenFeature.\r\n\r\nIn this [Colab](https://colab.research.google.com/drive/1M10tbHih5eJ8LiApJSKKpNM79IconYJX)\r\n\r\nI survey 10 ways of encoding an array / array of arrays.\r\n\r\n-    Example: Int64 feature (int array)\r\n-    Example: Float feature (float array)\r\n-    Example: Bytes feature (int array dumped to byte string)\r\n-    SequenceExample: Int64 feature list (array of int arrays)\r\n-    SequenceExample: Float feature list (array of float arrays)\r\n-    SequenceExample: Bytes feature list (array of int arrays dumped to byte strings)\r\n-    Example: Bytes feature (array of int arrays all of which is dumped to byte string)\r\n-    SequenceExample: Bytes feature list (array of int arrays dumped to byte strings)\r\n-    SequenceExample: Bytes feature list (array of int arrays all of which is dumped to byte string)\r\n-    SequenceExample: Bytes feature list (array of int arrays, where each int is dumped to byte string)\r\n\r\nIn short, with the exception of 8, I was able to 'recover' (write to tf.record and read back the data). However, it should be noted that for methods 7 and 10, the retrieved array is flattened.\r\n\r\nFurther, when I state 'recover' I mean that of course that the feature is wrapped in an addition array. e.g. shape (3, ) becomes (1, 3).\r\n\r\n\r\nAs most tutorials of TF Record, Example and SequenceExample are just a rehashing of the one example provided in the TF Docs (for a movie recommender system, although code is provided for images). \r\n\r\nI think it would be beneficial for a \"style guide\" of sorts, given that one can their data in a myriad of ways. (e.g. are byte strings superior to float feature lists? should one break their image / sequence down per channel? why is there FixLenSeqeuenceFeature but no VarLenSequenceFeature?, if Example and SequenceExample are meant to contain a single data record, why are the only options List based features?)\r\n\r\nI would be happy to contribute to more documentation / examples if I knew the answer to these questions. However, to my unexperienced eyes the mismatch between converting data into a (Sequence)Example and extracting it out from a Record is bewildering.\r\n\r\n\r\n\r\n-------\r\n\r\nTensorFlow Butler requested information:\r\n\r\nHave I written custom code: yes, see linked colabs and S.O. posts.\r\nOS Platform and Distribution: N/a (irrelevant, but Ubuntu 16.04LTS / macOS High Sierra)\r\nTensorFlow installed from: (irrelevant, but conda / Colab's V.M.)\r\nTensorFlow version: 1.10\r\nBazel version: N/a\r\nCUDA/cuDNN version: N/a (irrelevant but latest / Colab's V.M.'s)\r\nGPU model and memory: N/a (irrelevant, but NVIDIA Titan X / NVIDIA Titan V / Colab's GPU)\r\nExact command to reproduce: see linked to code\r\nMobile device: N/a  (irrelevant) \r\n\r\n\r\nThis is more of a \"meta\" question regarding the structuring of Example / SequenceExample, the correspondingly needed Feature, Features, FeatureList, FeatureLists, etc and the parsing equivalents FixedLenFeature, VariableLenFeature, FixedLenSequenceFeature.\r\n\r\nMore specifically:\r\n\r\n- a request for more documentation\r\n- a request for \"best\" practices recording encoding of rank 2+ tensors\r\n\r\n   +  e.g. if I have a sequence in an _numpy.ndarray_ with _n_ channels should I \"dump\" (call _.tostring()_) on the entire sequence and store in a BytesFeature in an Example? or split each channel up into a Float/Int Feature (or dump to BytesFeature) in an Example / SequenceExample. \r\n\r\n-  a request for \"best\" practices as to why ever use Example, when it seems that the \"context features\" are equivalent and then if sequence features are needed later it is easier to adapt? (i.e. the difference between context features in sequence example and normal features of example rather than just calling context features \"meta-data\" of the sequences)\r\n\r\n- a request for \"best' practices for recording rank 0 tensors (as they have to be wrapped into a feature list, so should similarly typed features be concatenated together)\r\n\r\n- a request for elucidating why sometimes decoding a bytes array losses the rank from which it was encoded (see linked colab)\r\n\r\n- a request for a mid-tier api at the feature level e.g. remove the need for the user to define how a feature should be encoded as a record and then decoded  (parsed) from a serialized record. I have a conceptual prototype that I can include here or in another colab if interested. \r\n\r\netc, etc\r\n"}