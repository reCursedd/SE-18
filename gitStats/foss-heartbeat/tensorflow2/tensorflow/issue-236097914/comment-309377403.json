{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/309377403", "html_url": "https://github.com/tensorflow/tensorflow/issues/10723#issuecomment-309377403", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10723", "id": 309377403, "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTM3NzQwMw==", "user": {"login": "GD06", "id": 13307515, "node_id": "MDQ6VXNlcjEzMzA3NTE1", "avatar_url": "https://avatars2.githubusercontent.com/u/13307515?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GD06", "html_url": "https://github.com/GD06", "followers_url": "https://api.github.com/users/GD06/followers", "following_url": "https://api.github.com/users/GD06/following{/other_user}", "gists_url": "https://api.github.com/users/GD06/gists{/gist_id}", "starred_url": "https://api.github.com/users/GD06/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GD06/subscriptions", "organizations_url": "https://api.github.com/users/GD06/orgs", "repos_url": "https://api.github.com/users/GD06/repos", "events_url": "https://api.github.com/users/GD06/events{/privacy}", "received_events_url": "https://api.github.com/users/GD06/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-19T08:46:44Z", "updated_at": "2017-06-19T08:46:44Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23486130\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tfboyd\">@tfboyd</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1381301\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ppwwyyxx\">@ppwwyyxx</a><br>\nHi Toby &amp; Yuxin,</p>\n<p>Thanks a lot for your patient explanation. I performed the multiGPU tests for three argument sets and the results are shown as the following tables:<br>\nThe abbreviations for the parameter sets are as followed:</p>\n<ol>\n<li>replicated_gpu_nccl: <code>variable_update=replicated local_parameter_device=gpu use_nccl=True</code></li>\n<li>parameter_server_gpu: <code>variable_update=parameter_server local_parameter_device=cpu use_nccl=False</code></li>\n<li>parameter_server_gpu_nccl: <code>variable_update=parameter_server local_parameter_device=gpu use_nccl=True</code></li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Number of GPUs</th>\n<th>replicated_gpu_nccl</th>\n<th>parameter_server_cpu</th>\n<th>parameter_server_gpu_nccl</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>82.31</td>\n<td>76.53</td>\n<td>83.14</td>\n</tr>\n<tr>\n<td>2</td>\n<td>154.59</td>\n<td>140.35</td>\n<td>155.53</td>\n</tr>\n<tr>\n<td>3</td>\n<td>214.84</td>\n<td>219.67</td>\n<td>212.39</td>\n</tr>\n<tr>\n<td>4</td>\n<td>280.17</td>\n<td>276.82</td>\n<td>266.04</td>\n</tr>\n<tr>\n<td>5</td>\n<td>338.93</td>\n<td>302.22</td>\n<td>267.23</td>\n</tr>\n<tr>\n<td>6</td>\n<td>405.59</td>\n<td>370.58</td>\n<td>275.08</td>\n</tr>\n<tr>\n<td>7</td>\n<td>470.66</td>\n<td>410.25</td>\n<td>273.08</td>\n</tr>\n<tr>\n<td>8</td>\n<td>517.31</td>\n<td>373.5</td>\n<td>308.48</td>\n</tr>\n</tbody>\n</table>\n<p>From the table presented above, I would like to conclude that the parameter set used in the second column is the best practice for my system and platform. Do the results in the second column achieve the expected speedup of VGG16 on 8 GPUs?</p>\n<p>Thank you again for your helpful suggestions! I am still a little confused about two modes for variable_update. What's the difference between \"replicated\" and \"parameter_server\"? Comparing with the second column and the fourth column of the table above, these two modes result in significant performance difference even both of them use GPU as local parameter device and reduce parameters through NCCL. Can anyone help me?</p>\n<p>Thanks,<br>\nXinfeng</p>", "body_text": "@tfboyd @ppwwyyxx\nHi Toby & Yuxin,\nThanks a lot for your patient explanation. I performed the multiGPU tests for three argument sets and the results are shown as the following tables:\nThe abbreviations for the parameter sets are as followed:\n\nreplicated_gpu_nccl: variable_update=replicated local_parameter_device=gpu use_nccl=True\nparameter_server_gpu: variable_update=parameter_server local_parameter_device=cpu use_nccl=False\nparameter_server_gpu_nccl: variable_update=parameter_server local_parameter_device=gpu use_nccl=True\n\n\n\n\nNumber of GPUs\nreplicated_gpu_nccl\nparameter_server_cpu\nparameter_server_gpu_nccl\n\n\n\n\n1\n82.31\n76.53\n83.14\n\n\n2\n154.59\n140.35\n155.53\n\n\n3\n214.84\n219.67\n212.39\n\n\n4\n280.17\n276.82\n266.04\n\n\n5\n338.93\n302.22\n267.23\n\n\n6\n405.59\n370.58\n275.08\n\n\n7\n470.66\n410.25\n273.08\n\n\n8\n517.31\n373.5\n308.48\n\n\n\nFrom the table presented above, I would like to conclude that the parameter set used in the second column is the best practice for my system and platform. Do the results in the second column achieve the expected speedup of VGG16 on 8 GPUs?\nThank you again for your helpful suggestions! I am still a little confused about two modes for variable_update. What's the difference between \"replicated\" and \"parameter_server\"? Comparing with the second column and the fourth column of the table above, these two modes result in significant performance difference even both of them use GPU as local parameter device and reduce parameters through NCCL. Can anyone help me?\nThanks,\nXinfeng", "body": "@tfboyd @ppwwyyxx \r\nHi Toby & Yuxin,\r\n\r\nThanks a lot for your patient explanation. I performed the multiGPU tests for three argument sets and the results are shown as the following tables:\r\nThe abbreviations for the parameter sets are as followed:\r\n1. replicated_gpu_nccl: ```variable_update=replicated local_parameter_device=gpu use_nccl=True```\r\n2. parameter_server_gpu: ```variable_update=parameter_server local_parameter_device=cpu use_nccl=False```\r\n3. parameter_server_gpu_nccl: ```variable_update=parameter_server local_parameter_device=gpu use_nccl=True```\r\n\r\n| Number of GPUs | replicated_gpu_nccl | parameter_server_cpu | parameter_server_gpu_nccl |\r\n|----------------|---------------------|----------------------|---------------------------|\r\n| 1              | 82.31               | 76.53                | 83.14                     |\r\n| 2              | 154.59              | 140.35               | 155.53                    |\r\n| 3              | 214.84              | 219.67               | 212.39                    |\r\n| 4              | 280.17              | 276.82               | 266.04                    |\r\n| 5              | 338.93              | 302.22               | 267.23                    |\r\n| 6              | 405.59              | 370.58               | 275.08                    |\r\n| 7              | 470.66              | 410.25               | 273.08                    |\r\n| 8              | 517.31              | 373.5                | 308.48                    |\r\n\r\nFrom the table presented above, I would like to conclude that the parameter set used in the second column is the best practice for my system and platform. Do the results in the second column achieve the expected speedup of VGG16 on 8 GPUs? \r\n\r\nThank you again for your helpful suggestions! I am still a little confused about two modes for variable_update. What's the difference between \"replicated\" and \"parameter_server\"? Comparing with the second column and the fourth column of the table above, these two modes result in significant performance difference even both of them use GPU as local parameter device and reduce parameters through NCCL. Can anyone help me?\r\n\r\nThanks,\r\nXinfeng"}