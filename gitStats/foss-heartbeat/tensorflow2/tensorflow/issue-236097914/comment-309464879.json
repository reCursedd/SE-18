{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/309464879", "html_url": "https://github.com/tensorflow/tensorflow/issues/10723#issuecomment-309464879", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10723", "id": 309464879, "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTQ2NDg3OQ==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-19T14:54:12Z", "updated_at": "2017-06-19T14:54:12Z", "author_association": "MEMBER", "body_html": "<p>First, I am really excited that having the benchmarks public helped us to have a reference point to figure this out (maybe a pat on the back but it justifies the time and money we spend running these tests).  Second, I am glad you were able to try multiple configurations and we have another semi-reference point that most likely M40s and decently connected Titan X (maxwells) likely behave like a DGX-1.</p>\n<p>My attempt (others have already given possibly better answers and I will add a few links).</p>\n<ul>\n<li>The <a href=\"https://www.tensorflow.org/performance/performance_models\" rel=\"nofollow\">high performance models</a> page explains variable management better than I can.</li>\n<li><a href=\"https://github.com/NVIDIA/nccl\">NCCL</a> home page</li>\n</ul>\n<p>One of your configs did not do what you might have expected:</p>\n<pre><code>parameter_server_gpu_nccl: variable_update=parameter_server local_parameter_device=gpu use_nccl=True\n</code></pre>\n<p>In the above config what happened was the variables were <strong>spread across the 8 GPUs</strong> and NCCL was not involved.  NCCL is only a valid option if you set parameter_server=replicated and local_ps_device=gpu.  The settings can be confusing and we do not do any or very many checks because it is a tool and there are so many options.</p>\n<p>Deeply understanding the differences is beyond me.  We had a long internal thread discussing why variable_update=parameter_server and local_parameter_device=cpu is faster on DGX-1 for inception and resnet.  For my level of understanding it seems that the more parameters there are the more likely NCCL will be the better option.  I also know VGG16 does not scale very well in distributed mode (across servers), which is also an indication.</p>\n<p>I am sorry I cannot provide you a deeper technical explanation.  I would rather say I do not know than make something up.  :-)</p>", "body_text": "First, I am really excited that having the benchmarks public helped us to have a reference point to figure this out (maybe a pat on the back but it justifies the time and money we spend running these tests).  Second, I am glad you were able to try multiple configurations and we have another semi-reference point that most likely M40s and decently connected Titan X (maxwells) likely behave like a DGX-1.\nMy attempt (others have already given possibly better answers and I will add a few links).\n\nThe high performance models page explains variable management better than I can.\nNCCL home page\n\nOne of your configs did not do what you might have expected:\nparameter_server_gpu_nccl: variable_update=parameter_server local_parameter_device=gpu use_nccl=True\n\nIn the above config what happened was the variables were spread across the 8 GPUs and NCCL was not involved.  NCCL is only a valid option if you set parameter_server=replicated and local_ps_device=gpu.  The settings can be confusing and we do not do any or very many checks because it is a tool and there are so many options.\nDeeply understanding the differences is beyond me.  We had a long internal thread discussing why variable_update=parameter_server and local_parameter_device=cpu is faster on DGX-1 for inception and resnet.  For my level of understanding it seems that the more parameters there are the more likely NCCL will be the better option.  I also know VGG16 does not scale very well in distributed mode (across servers), which is also an indication.\nI am sorry I cannot provide you a deeper technical explanation.  I would rather say I do not know than make something up.  :-)", "body": "First, I am really excited that having the benchmarks public helped us to have a reference point to figure this out (maybe a pat on the back but it justifies the time and money we spend running these tests).  Second, I am glad you were able to try multiple configurations and we have another semi-reference point that most likely M40s and decently connected Titan X (maxwells) likely behave like a DGX-1.  \r\n\r\nMy attempt (others have already given possibly better answers and I will add a few links).  \r\n\r\n- The [high performance models](https://www.tensorflow.org/performance/performance_models) page explains variable management better than I can.\r\n- [NCCL](https://github.com/NVIDIA/nccl) home page\r\n\r\nOne of your configs did not do what you might have expected:\r\n```\r\nparameter_server_gpu_nccl: variable_update=parameter_server local_parameter_device=gpu use_nccl=True\r\n```\r\n\r\nIn the above config what happened was the variables were **spread across the 8 GPUs** and NCCL was not involved.  NCCL is only a valid option if you set parameter_server=replicated and local_ps_device=gpu.  The settings can be confusing and we do not do any or very many checks because it is a tool and there are so many options.  \r\n\r\nDeeply understanding the differences is beyond me.  We had a long internal thread discussing why variable_update=parameter_server and local_parameter_device=cpu is faster on DGX-1 for inception and resnet.  For my level of understanding it seems that the more parameters there are the more likely NCCL will be the better option.  I also know VGG16 does not scale very well in distributed mode (across servers), which is also an indication.  \r\n\r\nI am sorry I cannot provide you a deeper technical explanation.  I would rather say I do not know than make something up.  :-)\r\n\r\n\r\n\r\n"}