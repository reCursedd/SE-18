{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302259929", "html_url": "https://github.com/tensorflow/tensorflow/issues/9926#issuecomment-302259929", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9926", "id": 302259929, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjI1OTkyOQ==", "user": {"login": "alsrgv", "id": 16640218, "node_id": "MDQ6VXNlcjE2NjQwMjE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16640218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alsrgv", "html_url": "https://github.com/alsrgv", "followers_url": "https://api.github.com/users/alsrgv/followers", "following_url": "https://api.github.com/users/alsrgv/following{/other_user}", "gists_url": "https://api.github.com/users/alsrgv/gists{/gist_id}", "starred_url": "https://api.github.com/users/alsrgv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alsrgv/subscriptions", "organizations_url": "https://api.github.com/users/alsrgv/orgs", "repos_url": "https://api.github.com/users/alsrgv/repos", "events_url": "https://api.github.com/users/alsrgv/events{/privacy}", "received_events_url": "https://api.github.com/users/alsrgv/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-17T23:34:19Z", "updated_at": "2017-05-17T23:54:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I feel I'm facing similar situation.  When trying to run two-node set up, I see following errors.</p>\n<p>On first (chief) worker:</p>\n<pre><code>...\n2017-05-17 22:43:09.680866: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\n2017-05-17 22:43:30.237809: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:30.237851: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\n2017-05-17 22:43:30.239249: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\n2017-05-17 22:43:30.239955: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:31.592456: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n...\n2017-05-17 22:44:30.982164: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:worker/replica:0/task:0/cpu:0;5e9e196185e311cc;/job:ps/replica:0/task:0/cpu:0;edge_15063_Mul_145;0:0;141115178875244276 error message: Step 141115178875244276\n</code></pre>\n<p>On first parameter server:</p>\n<pre><code>2017-05-17 22:42:51.775275: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\n2017-05-17 22:43:13.055682: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\n2017-05-17 22:43:30.239808: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:35.198098: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:35.198150: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\n2017-05-17 22:43:35.198926: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:44:29.948398: F tensorflow/contrib/verbs/rdma.cc:130] Check failed: wc_[i].status == IBV_WC_SUCCESS Failed status \ntransport retry counter exceeded 12 738900624 129\n</code></pre>\n<p>On second worker:</p>\n<pre><code>...\n2017-05-17 22:43:29.731111: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\n2017-05-17 22:43:29.733157: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\n2017-05-17 22:43:29.734459: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\n2017-05-17 22:43:30.234363: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:31.588210: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:35.194635: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n...\n2017-05-17 22:44:30.979018: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:worker/replica:0/task:1/cpu:0;47caf76f804b2108;/job:ps/replica:0/task:1/cpu:0;edge_16166_Mul_85;0:0;117997835881656439 error message: Step 117997835881656439\n</code></pre>\n<p>On second parameter server:</p>\n<pre><code>2017-05-17 22:43:26.510171: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:331] Started server with target: grpc://localhost:31254\n2017-05-17 22:43:26.510230: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\n2017-05-17 22:43:31.588367: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:31.588410: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\n2017-05-17 22:43:31.589394: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:31.589446: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\n2017-05-17 22:43:35.195517: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:44:29.981975: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:ps/replica:0/task:1/cpu:0;e73d8038df027221;/job:worker/replica:0/task:0/gpu:0;edge_17945_group_deps_2/NoOp_1;0:0;141115178875244276 error message: Dequeue operation was cancelled\n\t [[Node: fifo_queue_DequeueMany = QueueDequeueManyV2[component_types=[DT_BOOL], timeout_ms=-1, _device=\"/job:ps/replica:0/task:1/cpu:0\"](fifo_queue, fifo_queue_DequeueMany/n)]]\n</code></pre>\n<p><code>ibv_devinfo</code> on first machine:</p>\n<pre><code>hca_id:\tmlx5_1\n\ttransport:\t\t\tInfiniBand (0)\n\tfw_ver:\t\t\t\t14.14.2320\n\tnode_guid:\t\t\t248a:0703:004c:2719\n\tsys_image_guid:\t\t\t248a:0703:004c:2718\n\tvendor_id:\t\t\t0x02c9\n\tvendor_part_id:\t\t\t4117\n\thw_ver:\t\t\t\t0x0\n\tboard_id:\t\t\tDEL2420110034\n\tphys_port_cnt:\t\t\t1\n\tDevice ports:\n\t\tport:\t1\n\t\t\tstate:\t\t\tPORT_DOWN (1)\n\t\t\tmax_mtu:\t\t4096 (5)\n\t\t\tactive_mtu:\t\t1024 (3)\n\t\t\tsm_lid:\t\t\t0\n\t\t\tport_lid:\t\t0\n\t\t\tport_lmc:\t\t0x00\n\t\t\tlink_layer:\t\tEthernet\n\nhca_id:\tmlx5_0\n\ttransport:\t\t\tInfiniBand (0)\n\tfw_ver:\t\t\t\t14.14.2320\n\tnode_guid:\t\t\t248a:0703:004c:2718\n\tsys_image_guid:\t\t\t248a:0703:004c:2718\n\tvendor_id:\t\t\t0x02c9\n\tvendor_part_id:\t\t\t4117\n\thw_ver:\t\t\t\t0x0\n\tboard_id:\t\t\tDEL2420110034\n\tphys_port_cnt:\t\t\t1\n\tDevice ports:\n\t\tport:\t1\n\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n\t\t\tmax_mtu:\t\t4096 (5)\n\t\t\tactive_mtu:\t\t1024 (3)\n\t\t\tsm_lid:\t\t\t0\n\t\t\tport_lid:\t\t0\n\t\t\tport_lmc:\t\t0x00\n\t\t\tlink_layer:\t\tEthernet\n</code></pre>\n<p><code>ibv_devinfo</code> on second machine:</p>\n<pre><code>hca_id:\tmlx5_1\n\ttransport:\t\t\tInfiniBand (0)\n\tfw_ver:\t\t\t\t14.14.2320\n\tnode_guid:\t\t\t248a:0703:004c:25f9\n\tsys_image_guid:\t\t\t248a:0703:004c:25f8\n\tvendor_id:\t\t\t0x02c9\n\tvendor_part_id:\t\t\t4117\n\thw_ver:\t\t\t\t0x0\n\tboard_id:\t\t\tDEL2420110034\n\tphys_port_cnt:\t\t\t1\n\tDevice ports:\n\t\tport:\t1\n\t\t\tstate:\t\t\tPORT_DOWN (1)\n\t\t\tmax_mtu:\t\t4096 (5)\n\t\t\tactive_mtu:\t\t1024 (3)\n\t\t\tsm_lid:\t\t\t0\n\t\t\tport_lid:\t\t0\n\t\t\tport_lmc:\t\t0x00\n\t\t\tlink_layer:\t\tEthernet\n\nhca_id:\tmlx5_0\n\ttransport:\t\t\tInfiniBand (0)\n\tfw_ver:\t\t\t\t14.14.2320\n\tnode_guid:\t\t\t248a:0703:004c:25f8\n\tsys_image_guid:\t\t\t248a:0703:004c:25f8\n\tvendor_id:\t\t\t0x02c9\n\tvendor_part_id:\t\t\t4117\n\thw_ver:\t\t\t\t0x0\n\tboard_id:\t\t\tDEL2420110034\n\tphys_port_cnt:\t\t\t1\n\tDevice ports:\n\t\tport:\t1\n\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n\t\t\tmax_mtu:\t\t4096 (5)\n\t\t\tactive_mtu:\t\t1024 (3)\n\t\t\tsm_lid:\t\t\t0\n\t\t\tport_lid:\t\t0\n\t\t\tport_lmc:\t\t0x00\n\t\t\tlink_layer:\t\tEthernet\n</code></pre>\n<p>As you may notice, first port in the list is DOWN.  To work around that, I made modification suggested by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=22419555\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bkovalev\">@bkovalev</a> in the <code>verbs</code> to open device like this:</p>\n<pre><code>ibv_context* open_default_device() {\n  ibv_device** dev_list;\n  ibv_device* ib_dev;\n  int num_devices;\n  dev_list = ibv_get_device_list(&amp;num_devices);\n  CHECK(dev_list) &lt;&lt; \"No InfiniBand device found\";\n  ib_dev = dev_list[num_devices - 1];  /// THIS IS MODIFICATION\n  CHECK(ib_dev) &lt;&lt; \"No InfiniBand device found\";\n  ibv_context* context = ibv_open_device(ib_dev);\n  CHECK(context) &lt;&lt; \"Open context failed for \" &lt;&lt; ibv_get_device_name(ib_dev);\n  return context;\n}\n</code></pre>\n<p>Any suggestions?</p>", "body_text": "I feel I'm facing similar situation.  When trying to run two-node set up, I see following errors.\nOn first (chief) worker:\n...\n2017-05-17 22:43:09.680866: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\n2017-05-17 22:43:30.237809: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:30.237851: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\n2017-05-17 22:43:30.239249: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\n2017-05-17 22:43:30.239955: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:31.592456: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n...\n2017-05-17 22:44:30.982164: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:worker/replica:0/task:0/cpu:0;5e9e196185e311cc;/job:ps/replica:0/task:0/cpu:0;edge_15063_Mul_145;0:0;141115178875244276 error message: Step 141115178875244276\n\nOn first parameter server:\n2017-05-17 22:42:51.775275: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\n2017-05-17 22:43:13.055682: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\n2017-05-17 22:43:30.239808: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:35.198098: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:35.198150: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\n2017-05-17 22:43:35.198926: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:44:29.948398: F tensorflow/contrib/verbs/rdma.cc:130] Check failed: wc_[i].status == IBV_WC_SUCCESS Failed status \ntransport retry counter exceeded 12 738900624 129\n\nOn second worker:\n...\n2017-05-17 22:43:29.731111: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\n2017-05-17 22:43:29.733157: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\n2017-05-17 22:43:29.734459: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\n2017-05-17 22:43:30.234363: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:31.588210: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:35.194635: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n...\n2017-05-17 22:44:30.979018: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:worker/replica:0/task:1/cpu:0;47caf76f804b2108;/job:ps/replica:0/task:1/cpu:0;edge_16166_Mul_85;0:0;117997835881656439 error message: Step 117997835881656439\n\nOn second parameter server:\n2017-05-17 22:43:26.510171: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:331] Started server with target: grpc://localhost:31254\n2017-05-17 22:43:26.510230: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\n2017-05-17 22:43:31.588367: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:31.588410: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\n2017-05-17 22:43:31.589394: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:43:31.589446: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\n2017-05-17 22:43:35.195517: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\n2017-05-17 22:44:29.981975: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:ps/replica:0/task:1/cpu:0;e73d8038df027221;/job:worker/replica:0/task:0/gpu:0;edge_17945_group_deps_2/NoOp_1;0:0;141115178875244276 error message: Dequeue operation was cancelled\n\t [[Node: fifo_queue_DequeueMany = QueueDequeueManyV2[component_types=[DT_BOOL], timeout_ms=-1, _device=\"/job:ps/replica:0/task:1/cpu:0\"](fifo_queue, fifo_queue_DequeueMany/n)]]\n\nibv_devinfo on first machine:\nhca_id:\tmlx5_1\n\ttransport:\t\t\tInfiniBand (0)\n\tfw_ver:\t\t\t\t14.14.2320\n\tnode_guid:\t\t\t248a:0703:004c:2719\n\tsys_image_guid:\t\t\t248a:0703:004c:2718\n\tvendor_id:\t\t\t0x02c9\n\tvendor_part_id:\t\t\t4117\n\thw_ver:\t\t\t\t0x0\n\tboard_id:\t\t\tDEL2420110034\n\tphys_port_cnt:\t\t\t1\n\tDevice ports:\n\t\tport:\t1\n\t\t\tstate:\t\t\tPORT_DOWN (1)\n\t\t\tmax_mtu:\t\t4096 (5)\n\t\t\tactive_mtu:\t\t1024 (3)\n\t\t\tsm_lid:\t\t\t0\n\t\t\tport_lid:\t\t0\n\t\t\tport_lmc:\t\t0x00\n\t\t\tlink_layer:\t\tEthernet\n\nhca_id:\tmlx5_0\n\ttransport:\t\t\tInfiniBand (0)\n\tfw_ver:\t\t\t\t14.14.2320\n\tnode_guid:\t\t\t248a:0703:004c:2718\n\tsys_image_guid:\t\t\t248a:0703:004c:2718\n\tvendor_id:\t\t\t0x02c9\n\tvendor_part_id:\t\t\t4117\n\thw_ver:\t\t\t\t0x0\n\tboard_id:\t\t\tDEL2420110034\n\tphys_port_cnt:\t\t\t1\n\tDevice ports:\n\t\tport:\t1\n\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n\t\t\tmax_mtu:\t\t4096 (5)\n\t\t\tactive_mtu:\t\t1024 (3)\n\t\t\tsm_lid:\t\t\t0\n\t\t\tport_lid:\t\t0\n\t\t\tport_lmc:\t\t0x00\n\t\t\tlink_layer:\t\tEthernet\n\nibv_devinfo on second machine:\nhca_id:\tmlx5_1\n\ttransport:\t\t\tInfiniBand (0)\n\tfw_ver:\t\t\t\t14.14.2320\n\tnode_guid:\t\t\t248a:0703:004c:25f9\n\tsys_image_guid:\t\t\t248a:0703:004c:25f8\n\tvendor_id:\t\t\t0x02c9\n\tvendor_part_id:\t\t\t4117\n\thw_ver:\t\t\t\t0x0\n\tboard_id:\t\t\tDEL2420110034\n\tphys_port_cnt:\t\t\t1\n\tDevice ports:\n\t\tport:\t1\n\t\t\tstate:\t\t\tPORT_DOWN (1)\n\t\t\tmax_mtu:\t\t4096 (5)\n\t\t\tactive_mtu:\t\t1024 (3)\n\t\t\tsm_lid:\t\t\t0\n\t\t\tport_lid:\t\t0\n\t\t\tport_lmc:\t\t0x00\n\t\t\tlink_layer:\t\tEthernet\n\nhca_id:\tmlx5_0\n\ttransport:\t\t\tInfiniBand (0)\n\tfw_ver:\t\t\t\t14.14.2320\n\tnode_guid:\t\t\t248a:0703:004c:25f8\n\tsys_image_guid:\t\t\t248a:0703:004c:25f8\n\tvendor_id:\t\t\t0x02c9\n\tvendor_part_id:\t\t\t4117\n\thw_ver:\t\t\t\t0x0\n\tboard_id:\t\t\tDEL2420110034\n\tphys_port_cnt:\t\t\t1\n\tDevice ports:\n\t\tport:\t1\n\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n\t\t\tmax_mtu:\t\t4096 (5)\n\t\t\tactive_mtu:\t\t1024 (3)\n\t\t\tsm_lid:\t\t\t0\n\t\t\tport_lid:\t\t0\n\t\t\tport_lmc:\t\t0x00\n\t\t\tlink_layer:\t\tEthernet\n\nAs you may notice, first port in the list is DOWN.  To work around that, I made modification suggested by @bkovalev in the verbs to open device like this:\nibv_context* open_default_device() {\n  ibv_device** dev_list;\n  ibv_device* ib_dev;\n  int num_devices;\n  dev_list = ibv_get_device_list(&num_devices);\n  CHECK(dev_list) << \"No InfiniBand device found\";\n  ib_dev = dev_list[num_devices - 1];  /// THIS IS MODIFICATION\n  CHECK(ib_dev) << \"No InfiniBand device found\";\n  ibv_context* context = ibv_open_device(ib_dev);\n  CHECK(context) << \"Open context failed for \" << ibv_get_device_name(ib_dev);\n  return context;\n}\n\nAny suggestions?", "body": "I feel I'm facing similar situation.  When trying to run two-node set up, I see following errors.\r\n\r\nOn first (chief) worker:\r\n```\r\n...\r\n2017-05-17 22:43:09.680866: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\r\n2017-05-17 22:43:30.237809: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:43:30.237851: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\r\n2017-05-17 22:43:30.239249: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\r\n2017-05-17 22:43:30.239955: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:43:31.592456: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n...\r\n2017-05-17 22:44:30.982164: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:worker/replica:0/task:0/cpu:0;5e9e196185e311cc;/job:ps/replica:0/task:0/cpu:0;edge_15063_Mul_145;0:0;141115178875244276 error message: Step 141115178875244276\r\n```\r\n\r\nOn first parameter server:\r\n```\r\n2017-05-17 22:42:51.775275: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\r\n2017-05-17 22:43:13.055682: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\r\n2017-05-17 22:43:30.239808: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:43:35.198098: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:43:35.198150: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\r\n2017-05-17 22:43:35.198926: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:44:29.948398: F tensorflow/contrib/verbs/rdma.cc:130] Check failed: wc_[i].status == IBV_WC_SUCCESS Failed status \r\ntransport retry counter exceeded 12 738900624 129\r\n```\r\n\r\nOn second worker:\r\n```\r\n...\r\n2017-05-17 22:43:29.731111: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\r\n2017-05-17 22:43:29.733157: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:1\r\n2017-05-17 22:43:29.734459: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\r\n2017-05-17 22:43:30.234363: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:43:31.588210: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:43:35.194635: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n...\r\n2017-05-17 22:44:30.979018: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:worker/replica:0/task:1/cpu:0;47caf76f804b2108;/job:ps/replica:0/task:1/cpu:0;edge_16166_Mul_85;0:0;117997835881656439 error message: Step 117997835881656439\r\n```\r\n\r\nOn second parameter server:\r\n```\r\n2017-05-17 22:43:26.510171: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:331] Started server with target: grpc://localhost:31254\r\n2017-05-17 22:43:26.510230: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:1\r\n2017-05-17 22:43:31.588367: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:43:31.588410: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\r\n2017-05-17 22:43:31.589394: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:43:31.589446: I tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:ps/replica:0/task:0\r\n2017-05-17 22:43:35.195517: I tensorflow/contrib/verbs/rdma.cc:519] channel already connected\r\n2017-05-17 22:44:29.981975: F tensorflow/contrib/verbs/rdma.cc:679] Check failed: status.ok() RecvLocalAsync was not ok, key/job:ps/replica:0/task:1/cpu:0;e73d8038df027221;/job:worker/replica:0/task:0/gpu:0;edge_17945_group_deps_2/NoOp_1;0:0;141115178875244276 error message: Dequeue operation was cancelled\r\n\t [[Node: fifo_queue_DequeueMany = QueueDequeueManyV2[component_types=[DT_BOOL], timeout_ms=-1, _device=\"/job:ps/replica:0/task:1/cpu:0\"](fifo_queue, fifo_queue_DequeueMany/n)]]\r\n```\r\n\r\n`ibv_devinfo` on first machine:\r\n```\r\nhca_id:\tmlx5_1\r\n\ttransport:\t\t\tInfiniBand (0)\r\n\tfw_ver:\t\t\t\t14.14.2320\r\n\tnode_guid:\t\t\t248a:0703:004c:2719\r\n\tsys_image_guid:\t\t\t248a:0703:004c:2718\r\n\tvendor_id:\t\t\t0x02c9\r\n\tvendor_part_id:\t\t\t4117\r\n\thw_ver:\t\t\t\t0x0\r\n\tboard_id:\t\t\tDEL2420110034\r\n\tphys_port_cnt:\t\t\t1\r\n\tDevice ports:\r\n\t\tport:\t1\r\n\t\t\tstate:\t\t\tPORT_DOWN (1)\r\n\t\t\tmax_mtu:\t\t4096 (5)\r\n\t\t\tactive_mtu:\t\t1024 (3)\r\n\t\t\tsm_lid:\t\t\t0\r\n\t\t\tport_lid:\t\t0\r\n\t\t\tport_lmc:\t\t0x00\r\n\t\t\tlink_layer:\t\tEthernet\r\n\r\nhca_id:\tmlx5_0\r\n\ttransport:\t\t\tInfiniBand (0)\r\n\tfw_ver:\t\t\t\t14.14.2320\r\n\tnode_guid:\t\t\t248a:0703:004c:2718\r\n\tsys_image_guid:\t\t\t248a:0703:004c:2718\r\n\tvendor_id:\t\t\t0x02c9\r\n\tvendor_part_id:\t\t\t4117\r\n\thw_ver:\t\t\t\t0x0\r\n\tboard_id:\t\t\tDEL2420110034\r\n\tphys_port_cnt:\t\t\t1\r\n\tDevice ports:\r\n\t\tport:\t1\r\n\t\t\tstate:\t\t\tPORT_ACTIVE (4)\r\n\t\t\tmax_mtu:\t\t4096 (5)\r\n\t\t\tactive_mtu:\t\t1024 (3)\r\n\t\t\tsm_lid:\t\t\t0\r\n\t\t\tport_lid:\t\t0\r\n\t\t\tport_lmc:\t\t0x00\r\n\t\t\tlink_layer:\t\tEthernet\r\n```\r\n\r\n`ibv_devinfo` on second machine:\r\n```\r\nhca_id:\tmlx5_1\r\n\ttransport:\t\t\tInfiniBand (0)\r\n\tfw_ver:\t\t\t\t14.14.2320\r\n\tnode_guid:\t\t\t248a:0703:004c:25f9\r\n\tsys_image_guid:\t\t\t248a:0703:004c:25f8\r\n\tvendor_id:\t\t\t0x02c9\r\n\tvendor_part_id:\t\t\t4117\r\n\thw_ver:\t\t\t\t0x0\r\n\tboard_id:\t\t\tDEL2420110034\r\n\tphys_port_cnt:\t\t\t1\r\n\tDevice ports:\r\n\t\tport:\t1\r\n\t\t\tstate:\t\t\tPORT_DOWN (1)\r\n\t\t\tmax_mtu:\t\t4096 (5)\r\n\t\t\tactive_mtu:\t\t1024 (3)\r\n\t\t\tsm_lid:\t\t\t0\r\n\t\t\tport_lid:\t\t0\r\n\t\t\tport_lmc:\t\t0x00\r\n\t\t\tlink_layer:\t\tEthernet\r\n\r\nhca_id:\tmlx5_0\r\n\ttransport:\t\t\tInfiniBand (0)\r\n\tfw_ver:\t\t\t\t14.14.2320\r\n\tnode_guid:\t\t\t248a:0703:004c:25f8\r\n\tsys_image_guid:\t\t\t248a:0703:004c:25f8\r\n\tvendor_id:\t\t\t0x02c9\r\n\tvendor_part_id:\t\t\t4117\r\n\thw_ver:\t\t\t\t0x0\r\n\tboard_id:\t\t\tDEL2420110034\r\n\tphys_port_cnt:\t\t\t1\r\n\tDevice ports:\r\n\t\tport:\t1\r\n\t\t\tstate:\t\t\tPORT_ACTIVE (4)\r\n\t\t\tmax_mtu:\t\t4096 (5)\r\n\t\t\tactive_mtu:\t\t1024 (3)\r\n\t\t\tsm_lid:\t\t\t0\r\n\t\t\tport_lid:\t\t0\r\n\t\t\tport_lmc:\t\t0x00\r\n\t\t\tlink_layer:\t\tEthernet\r\n```\r\n\r\nAs you may notice, first port in the list is DOWN.  To work around that, I made modification suggested by @bkovalev in the `verbs` to open device like this:\r\n```\r\nibv_context* open_default_device() {\r\n  ibv_device** dev_list;\r\n  ibv_device* ib_dev;\r\n  int num_devices;\r\n  dev_list = ibv_get_device_list(&num_devices);\r\n  CHECK(dev_list) << \"No InfiniBand device found\";\r\n  ib_dev = dev_list[num_devices - 1];  /// THIS IS MODIFICATION\r\n  CHECK(ib_dev) << \"No InfiniBand device found\";\r\n  ibv_context* context = ibv_open_device(ib_dev);\r\n  CHECK(context) << \"Open context failed for \" << ibv_get_device_name(ib_dev);\r\n  return context;\r\n}\r\n```\r\n\r\nAny suggestions?"}