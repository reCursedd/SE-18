{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/413622631", "html_url": "https://github.com/tensorflow/tensorflow/issues/19840#issuecomment-413622631", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19840", "id": 413622631, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzYyMjYzMQ==", "user": {"login": "noahstier", "id": 7936971, "node_id": "MDQ6VXNlcjc5MzY5NzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/7936971?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noahstier", "html_url": "https://github.com/noahstier", "followers_url": "https://api.github.com/users/noahstier/followers", "following_url": "https://api.github.com/users/noahstier/following{/other_user}", "gists_url": "https://api.github.com/users/noahstier/gists{/gist_id}", "starred_url": "https://api.github.com/users/noahstier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noahstier/subscriptions", "organizations_url": "https://api.github.com/users/noahstier/orgs", "repos_url": "https://api.github.com/users/noahstier/repos", "events_url": "https://api.github.com/users/noahstier/events{/privacy}", "received_events_url": "https://api.github.com/users/noahstier/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-16T17:25:51Z", "updated_at": "2018-08-16T20:26:46Z", "author_association": "NONE", "body_html": "<p>I'm getting the same error, not related to tf-serving. Just building tensorflow with</p>\n<pre><code>bazel build \\\n  --config=opt \\\n  --config=cuda \\\n  --config=mkl \\\n  //tensorflow/tools/pip_package:build_pip_package\n</code></pre>\n<p>specs:</p>\n<ul>\n<li>Bazel 0.15.2</li>\n<li>Python 3.5.5</li>\n<li>TensorFlow 1.9 and 1.10 (tried both, same result)</li>\n<li>Ubuntu 16.04</li>\n<li>gcc 5.4.0</li>\n<li>cuda 9.2</li>\n<li>with and without --config=monolithic (tried both)</li>\n</ul>\n<p>Error after successful build:</p>\n<pre><code>In [4]: import tensorflow.contrib\n---------------------------------------------------------------------------\nNotFoundError                             Traceback (most recent call last)\n&lt;ipython-input-4-9ce6c8f43c36&gt; in &lt;module&gt;()\n----&gt; 1 import tensorflow.contrib\n...\nNotFoundError: ~/miniconda3/envs/35/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/_lstm_ops.so: undefined symbol: _ZN15stream_executor6Stream12ThenBlasGemmENS_4blas9TransposeES2_yyyfRKNS_12DeviceMemoryIfEEiS6_ifPS4_i\n</code></pre>\n<p>Not sure if this is relevant but I get this warning when the tensorflow build starts:<br>\n<code>WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.</code></p>\n<p>Edit: I found that I only get this error when building with TensorRT support. I'm using TensorRT 4.0.1.6-1+cuda9.2</p>\n<p>Edit: Problem solved by install pycuda with <code>pip install pycuda</code> before importing tensorflow.contrib</p>", "body_text": "I'm getting the same error, not related to tf-serving. Just building tensorflow with\nbazel build \\\n  --config=opt \\\n  --config=cuda \\\n  --config=mkl \\\n  //tensorflow/tools/pip_package:build_pip_package\n\nspecs:\n\nBazel 0.15.2\nPython 3.5.5\nTensorFlow 1.9 and 1.10 (tried both, same result)\nUbuntu 16.04\ngcc 5.4.0\ncuda 9.2\nwith and without --config=monolithic (tried both)\n\nError after successful build:\nIn [4]: import tensorflow.contrib\n---------------------------------------------------------------------------\nNotFoundError                             Traceback (most recent call last)\n<ipython-input-4-9ce6c8f43c36> in <module>()\n----> 1 import tensorflow.contrib\n...\nNotFoundError: ~/miniconda3/envs/35/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/_lstm_ops.so: undefined symbol: _ZN15stream_executor6Stream12ThenBlasGemmENS_4blas9TransposeES2_yyyfRKNS_12DeviceMemoryIfEEiS6_ifPS4_i\n\nNot sure if this is relevant but I get this warning when the tensorflow build starts:\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\nEdit: I found that I only get this error when building with TensorRT support. I'm using TensorRT 4.0.1.6-1+cuda9.2\nEdit: Problem solved by install pycuda with pip install pycuda before importing tensorflow.contrib", "body": "I'm getting the same error, not related to tf-serving. Just building tensorflow with\r\n```\r\nbazel build \\\r\n  --config=opt \\\r\n  --config=cuda \\\r\n  --config=mkl \\\r\n  //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nspecs:\r\n- Bazel 0.15.2\r\n- Python 3.5.5\r\n- TensorFlow 1.9 and 1.10 (tried both, same result)\r\n- Ubuntu 16.04\r\n- gcc 5.4.0\r\n- cuda 9.2\r\n- with and without --config=monolithic (tried both)\r\n\r\nError after successful build:\r\n```\r\nIn [4]: import tensorflow.contrib\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-4-9ce6c8f43c36> in <module>()\r\n----> 1 import tensorflow.contrib\r\n...\r\nNotFoundError: ~/miniconda3/envs/35/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/_lstm_ops.so: undefined symbol: _ZN15stream_executor6Stream12ThenBlasGemmENS_4blas9TransposeES2_yyyfRKNS_12DeviceMemoryIfEEiS6_ifPS4_i\r\n```\r\n\r\n\r\nNot sure if this is relevant but I get this warning when the tensorflow build starts:\r\n`WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.`\r\n\r\n\r\n\r\nEdit: I found that I only get this error when building with TensorRT support. I'm using TensorRT 4.0.1.6-1+cuda9.2\r\n\r\nEdit: Problem solved by install pycuda with `pip install pycuda` before importing tensorflow.contrib"}