{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16298", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16298/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16298/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16298/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16298", "id": 290592641, "node_id": "MDU6SXNzdWUyOTA1OTI2NDE=", "number": 16298, "title": "Bug of tf.data.TFRecordDataset? or my codes wrong?", "user": {"login": "ybsave", "id": 26417094, "node_id": "MDQ6VXNlcjI2NDE3MDk0", "avatar_url": "https://avatars0.githubusercontent.com/u/26417094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ybsave", "html_url": "https://github.com/ybsave", "followers_url": "https://api.github.com/users/ybsave/followers", "following_url": "https://api.github.com/users/ybsave/following{/other_user}", "gists_url": "https://api.github.com/users/ybsave/gists{/gist_id}", "starred_url": "https://api.github.com/users/ybsave/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ybsave/subscriptions", "organizations_url": "https://api.github.com/users/ybsave/orgs", "repos_url": "https://api.github.com/users/ybsave/repos", "events_url": "https://api.github.com/users/ybsave/events{/privacy}", "received_events_url": "https://api.github.com/users/ybsave/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-22T19:48:46Z", "updated_at": "2018-01-23T22:48:02Z", "closed_at": "2018-01-23T22:48:02Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:  Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:  binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:  1.4</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/6.0</li>\n<li><strong>GPU model and memory</strong>: Nvidia Quadro K4000</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>I tested to write dynamic numbers of variables into tfrecord. But when I use the tf.data.TFRecordDataset to read VarLenFeature, the program crashes. However, if I do not use dataset, but just tf.python_io.tf_record_iterator. The program works without problem. I wonder whether this is a bug of tf.data.TFRecordDataset, or there is something wrong in my codes?</p>\n<p>My writing codes are</p>\n<pre><code>def test_write():\n  writer = tf.python_io.TFRecordWriter('test.tfrecord')\n\n  for i in range(3):\n    val_list = []\n    for j in range(i+1):\n      val_list.append(i+j)\n    feature_dict = {\n      'val': tf.train.Feature(int64_list=tf.train.Int64List(value=val_list)),\n    }\n\n    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n    writer.write(example.SerializeToString())\n\n  writer.close()\n</code></pre>\n<p>The reading codes using tf.data.TFRecordDataset and causing error are</p>\n<pre><code>def parse_test(example):\n  features = {\n\t'val': tf.VarLenFeature(dtype=tf.int64)\n  }\n  parsed_features = tf.parse_single_example(example, features)\n\n  return parsed_features\n\ndef test_read():\n  dataset = tf.data.TFRecordDataset(['test.tfrecord'])\n  dataset = dataset.map(parse_test)\n  dataset = dataset.batch(1)\n\n  iterator = dataset.make_one_shot_iterator()\n  feature_dict =  iterator.get_next()\n\n  with tf.Session() as sess:\n\tfor _ in range(3):\n\t  curr_dict = sess.run(feature_dict)\n\t  print([curr_dict['val']])\n</code></pre>\n<p>The error message is:</p>\n<pre><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt; to Tensor. Contents: SparseTensor(indices=Tensor(\"ParseSingleExample/Slice_Indices_val:0\", shape=(?, 1), dtype=int64), values=Tensor(\"ParseSingleExample/ParseExample/ParseExample:1\", shape=(?,), dtype=int64), dense_shape=Tensor(\"ParseSingleExample/Squeeze_Shape_val:0\", shape=(1,), dtype=int64)). Consider casting elements to a supported type.\n</code></pre>\n<p>The successful reading codes without using tf.data.TFRecordDataset are as below</p>\n<pre><code>def test_read2():\n  with tf.Session() as sess:\n\tfor serialized_example in tf.python_io.tf_record_iterator('test.tfrecord'):\n\t  features = tf.parse_single_example(serialized_example,\n\t\tfeatures={\n\t\t  'val': tf.VarLenFeature(dtype=tf.int64),\n\t\t}\n\t  )\n\n\t  temp = features['val']\n\n\t  values = sess.run(temp)\n\t  print(values)\n</code></pre>\n<p>This code successfully print out</p>\n<pre><code>SparseTensorValue(indices=array([[0]], dtype=int64), values=array([0], dtype=int64), dense_shape=array([1], dtype=int64))\nSparseTensorValue(indices=array([[0],\n\t   [1]], dtype=int64), values=array([1, 2], dtype=int64), dense_shape=array([2], dtype=int64))\nSparseTensorValue(indices=array([[0],\n\t   [1],\n\t   [2]], dtype=int64), values=array([2, 3, 4], dtype=int64), dense_shape=array([3], dtype=int64))\n</code></pre>\n<p>However, I am still hoping to use the dataset structure to deal with the VarLenFeature. Is there anything wrong with my reading codes or there is a bug in tf.data.TFRecordDataset? Thank you.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10\nTensorFlow installed from (source or binary):  binary\nTensorFlow version (use command below):  1.4\nPython version: 3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 8.0/6.0\nGPU model and memory: Nvidia Quadro K4000\nExact command to reproduce:\n\nI tested to write dynamic numbers of variables into tfrecord. But when I use the tf.data.TFRecordDataset to read VarLenFeature, the program crashes. However, if I do not use dataset, but just tf.python_io.tf_record_iterator. The program works without problem. I wonder whether this is a bug of tf.data.TFRecordDataset, or there is something wrong in my codes?\nMy writing codes are\ndef test_write():\n  writer = tf.python_io.TFRecordWriter('test.tfrecord')\n\n  for i in range(3):\n    val_list = []\n    for j in range(i+1):\n      val_list.append(i+j)\n    feature_dict = {\n      'val': tf.train.Feature(int64_list=tf.train.Int64List(value=val_list)),\n    }\n\n    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n    writer.write(example.SerializeToString())\n\n  writer.close()\n\nThe reading codes using tf.data.TFRecordDataset and causing error are\ndef parse_test(example):\n  features = {\n\t'val': tf.VarLenFeature(dtype=tf.int64)\n  }\n  parsed_features = tf.parse_single_example(example, features)\n\n  return parsed_features\n\ndef test_read():\n  dataset = tf.data.TFRecordDataset(['test.tfrecord'])\n  dataset = dataset.map(parse_test)\n  dataset = dataset.batch(1)\n\n  iterator = dataset.make_one_shot_iterator()\n  feature_dict =  iterator.get_next()\n\n  with tf.Session() as sess:\n\tfor _ in range(3):\n\t  curr_dict = sess.run(feature_dict)\n\t  print([curr_dict['val']])\n\nThe error message is:\nTypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"ParseSingleExample/Slice_Indices_val:0\", shape=(?, 1), dtype=int64), values=Tensor(\"ParseSingleExample/ParseExample/ParseExample:1\", shape=(?,), dtype=int64), dense_shape=Tensor(\"ParseSingleExample/Squeeze_Shape_val:0\", shape=(1,), dtype=int64)). Consider casting elements to a supported type.\n\nThe successful reading codes without using tf.data.TFRecordDataset are as below\ndef test_read2():\n  with tf.Session() as sess:\n\tfor serialized_example in tf.python_io.tf_record_iterator('test.tfrecord'):\n\t  features = tf.parse_single_example(serialized_example,\n\t\tfeatures={\n\t\t  'val': tf.VarLenFeature(dtype=tf.int64),\n\t\t}\n\t  )\n\n\t  temp = features['val']\n\n\t  values = sess.run(temp)\n\t  print(values)\n\nThis code successfully print out\nSparseTensorValue(indices=array([[0]], dtype=int64), values=array([0], dtype=int64), dense_shape=array([1], dtype=int64))\nSparseTensorValue(indices=array([[0],\n\t   [1]], dtype=int64), values=array([1, 2], dtype=int64), dense_shape=array([2], dtype=int64))\nSparseTensorValue(indices=array([[0],\n\t   [1],\n\t   [2]], dtype=int64), values=array([2, 3, 4], dtype=int64), dense_shape=array([3], dtype=int64))\n\nHowever, I am still hoping to use the dataset structure to deal with the VarLenFeature. Is there anything wrong with my reading codes or there is a bug in tf.data.TFRecordDataset? Thank you.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Windows 10\r\n- **TensorFlow installed from (source or binary)**:  binary\r\n- **TensorFlow version (use command below)**:  1.4\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: Nvidia Quadro K4000\r\n- **Exact command to reproduce**: \r\n\r\n\r\nI tested to write dynamic numbers of variables into tfrecord. But when I use the tf.data.TFRecordDataset to read VarLenFeature, the program crashes. However, if I do not use dataset, but just tf.python_io.tf_record_iterator. The program works without problem. I wonder whether this is a bug of tf.data.TFRecordDataset, or there is something wrong in my codes?\r\n\r\nMy writing codes are \r\n\r\n    def test_write():\r\n      writer = tf.python_io.TFRecordWriter('test.tfrecord')\r\n\r\n      for i in range(3):\r\n        val_list = []\r\n        for j in range(i+1):\r\n          val_list.append(i+j)\r\n        feature_dict = {\r\n          'val': tf.train.Feature(int64_list=tf.train.Int64List(value=val_list)),\r\n        }\r\n    \r\n        example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\r\n        writer.write(example.SerializeToString())\r\n\r\n      writer.close()\r\n\r\nThe reading codes using tf.data.TFRecordDataset and causing error are\r\n\r\n\tdef parse_test(example):\r\n\t  features = {\r\n\t\t'val': tf.VarLenFeature(dtype=tf.int64)\r\n\t  }\r\n\t  parsed_features = tf.parse_single_example(example, features)\r\n\r\n\t  return parsed_features\r\n\r\n\tdef test_read():\r\n\t  dataset = tf.data.TFRecordDataset(['test.tfrecord'])\r\n\t  dataset = dataset.map(parse_test)\r\n\t  dataset = dataset.batch(1)\r\n\r\n\t  iterator = dataset.make_one_shot_iterator()\r\n\t  feature_dict =  iterator.get_next()\r\n\r\n\t  with tf.Session() as sess:\r\n\t\tfor _ in range(3):\r\n\t\t  curr_dict = sess.run(feature_dict)\r\n\t\t  print([curr_dict['val']])\r\n\r\nThe error message is:\r\n\r\n\tTypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"ParseSingleExample/Slice_Indices_val:0\", shape=(?, 1), dtype=int64), values=Tensor(\"ParseSingleExample/ParseExample/ParseExample:1\", shape=(?,), dtype=int64), dense_shape=Tensor(\"ParseSingleExample/Squeeze_Shape_val:0\", shape=(1,), dtype=int64)). Consider casting elements to a supported type.\r\n\r\n\r\n The successful reading codes without using tf.data.TFRecordDataset are as below\r\n\r\n\tdef test_read2():\r\n\t  with tf.Session() as sess:\r\n\t\tfor serialized_example in tf.python_io.tf_record_iterator('test.tfrecord'):\r\n\t\t  features = tf.parse_single_example(serialized_example,\r\n\t\t\tfeatures={\r\n\t\t\t  'val': tf.VarLenFeature(dtype=tf.int64),\r\n\t\t\t}\r\n\t\t  )\r\n\r\n\t\t  temp = features['val']\r\n\r\n\t\t  values = sess.run(temp)\r\n\t\t  print(values)\r\n\r\nThis code successfully print out\r\n\r\n\tSparseTensorValue(indices=array([[0]], dtype=int64), values=array([0], dtype=int64), dense_shape=array([1], dtype=int64))\r\n\tSparseTensorValue(indices=array([[0],\r\n\t\t   [1]], dtype=int64), values=array([1, 2], dtype=int64), dense_shape=array([2], dtype=int64))\r\n\tSparseTensorValue(indices=array([[0],\r\n\t\t   [1],\r\n\t\t   [2]], dtype=int64), values=array([2, 3, 4], dtype=int64), dense_shape=array([3], dtype=int64))\r\n\r\nHowever, I am still hoping to use the dataset structure to deal with the VarLenFeature. Is there anything wrong with my reading codes or there is a bug in tf.data.TFRecordDataset? Thank you.\r\n\r\n"}