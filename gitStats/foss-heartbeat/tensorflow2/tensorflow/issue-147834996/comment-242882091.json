{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/242882091", "html_url": "https://github.com/tensorflow/tensorflow/issues/1888#issuecomment-242882091", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1888", "id": 242882091, "node_id": "MDEyOklzc3VlQ29tbWVudDI0Mjg4MjA5MQ==", "user": {"login": "gibiansky", "id": 1865411, "node_id": "MDQ6VXNlcjE4NjU0MTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1865411?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gibiansky", "html_url": "https://github.com/gibiansky", "followers_url": "https://api.github.com/users/gibiansky/followers", "following_url": "https://api.github.com/users/gibiansky/following{/other_user}", "gists_url": "https://api.github.com/users/gibiansky/gists{/gist_id}", "starred_url": "https://api.github.com/users/gibiansky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gibiansky/subscriptions", "organizations_url": "https://api.github.com/users/gibiansky/orgs", "repos_url": "https://api.github.com/users/gibiansky/repos", "events_url": "https://api.github.com/users/gibiansky/events{/privacy}", "received_events_url": "https://api.github.com/users/gibiansky/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-27T00:16:07Z", "updated_at": "2016-08-27T00:16:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thank you! Yes, sadly if you look at the code behind <code>ExecutorForDevice</code>, it eventually calls <a href=\"https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/stream_executor/cuda/cuda_platform.cc#L149\"><code>GetUncachedExecutor</code></a>; this creates a new <code>CUDAExecutor</code> and calls <code>Init</code>; in turn, that calls <code>CUDADriver::GetDevice</code>, which then calls <code>cuDeviceGet</code>, which is the low-level call that I believe actually creates the context.</p>\n<p>It seems like in this case StreamExecutor is doing everything right \u2013 when you call <code>ExecutorForDevice</code>, it <em>should</em> allocate a context and prepare for running things on the device, since you're about to run things on the device! (That's what executors do, presumably.) However, the mistake is in Tensorflow core -- Tensorflow shouldn't be asking for the stream executors in the first place.</p>", "body_text": "Thank you! Yes, sadly if you look at the code behind ExecutorForDevice, it eventually calls GetUncachedExecutor; this creates a new CUDAExecutor and calls Init; in turn, that calls CUDADriver::GetDevice, which then calls cuDeviceGet, which is the low-level call that I believe actually creates the context.\nIt seems like in this case StreamExecutor is doing everything right \u2013 when you call ExecutorForDevice, it should allocate a context and prepare for running things on the device, since you're about to run things on the device! (That's what executors do, presumably.) However, the mistake is in Tensorflow core -- Tensorflow shouldn't be asking for the stream executors in the first place.", "body": "Thank you! Yes, sadly if you look at the code behind `ExecutorForDevice`, it eventually calls [`GetUncachedExecutor`](https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/stream_executor/cuda/cuda_platform.cc#L149); this creates a new `CUDAExecutor` and calls `Init`; in turn, that calls `CUDADriver::GetDevice`, which then calls `cuDeviceGet`, which is the low-level call that I believe actually creates the context.\n\nIt seems like in this case StreamExecutor is doing everything right \u2013 when you call `ExecutorForDevice`, it _should_ allocate a context and prepare for running things on the device, since you're about to run things on the device! (That's what executors do, presumably.) However, the mistake is in Tensorflow core -- Tensorflow shouldn't be asking for the stream executors in the first place.\n"}