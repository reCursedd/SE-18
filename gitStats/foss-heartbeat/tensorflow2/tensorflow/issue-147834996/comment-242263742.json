{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/242263742", "html_url": "https://github.com/tensorflow/tensorflow/issues/1888#issuecomment-242263742", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1888", "id": 242263742, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MjI2Mzc0Mg==", "user": {"login": "gibiansky", "id": 1865411, "node_id": "MDQ6VXNlcjE4NjU0MTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1865411?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gibiansky", "html_url": "https://github.com/gibiansky", "followers_url": "https://api.github.com/users/gibiansky/followers", "following_url": "https://api.github.com/users/gibiansky/following{/other_user}", "gists_url": "https://api.github.com/users/gibiansky/gists{/gist_id}", "starred_url": "https://api.github.com/users/gibiansky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gibiansky/subscriptions", "organizations_url": "https://api.github.com/users/gibiansky/orgs", "repos_url": "https://api.github.com/users/gibiansky/repos", "events_url": "https://api.github.com/users/gibiansky/events{/privacy}", "received_events_url": "https://api.github.com/users/gibiansky/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-25T02:19:17Z", "updated_at": "2016-08-25T02:20:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a> Yes! This would be perfect! (In fact, I started implementing <em>literally</em> the same thing today, in the same manner.)</p>\n<p>Minor questions:</p>\n<ul>\n<li>Shouldn't that be part of ConfigProto not GPUOptions? (GPUOptions seems like it is settings that affect a single GPU, while ConfigProto has settings related to many GPUs, for example device_count)</li>\n<li>Why pass <code>visible_gpu_devices</code> as a string, rather than as a <code>repeated int</code>?</li>\n<li>To confirm: this interacts fluidly with <code>CUDA_VISIBLE_DEVICES</code>. For example, if, on an 8-GPU system, <code>CUDA_VISIBLE_DEVICES=5,2,0,6</code>, and you set <code>visible_gpu_devices=0,3</code>, Tensorflow will end up running on GPUs 5 and 6.</li>\n<li>Does this change also mean that, since the GPU info is stored in the <code>Session</code>, <code>Session.close()</code> can now actually deallocate the GPU and destroy the context? If that's the case that would be <em>awesome</em>. (If you look right now, <code>nvidia-smi</code> will show that even after <code>Session.close()</code>, the GPU contexts still exist and thus you cannot launch more processes that use them.)</li>\n</ul>\n<p>The most important thing is that when <code>visible_gpu_devices</code> is used, the contexts are <em>not</em> created on all visible devices \u2013 not just that memory is not allocated on them, but that they are completely uninitialized, so that other concurrently running Tensorflow processes can use them.</p>", "body_text": "@vrv Yes! This would be perfect! (In fact, I started implementing literally the same thing today, in the same manner.)\nMinor questions:\n\nShouldn't that be part of ConfigProto not GPUOptions? (GPUOptions seems like it is settings that affect a single GPU, while ConfigProto has settings related to many GPUs, for example device_count)\nWhy pass visible_gpu_devices as a string, rather than as a repeated int?\nTo confirm: this interacts fluidly with CUDA_VISIBLE_DEVICES. For example, if, on an 8-GPU system, CUDA_VISIBLE_DEVICES=5,2,0,6, and you set visible_gpu_devices=0,3, Tensorflow will end up running on GPUs 5 and 6.\nDoes this change also mean that, since the GPU info is stored in the Session, Session.close() can now actually deallocate the GPU and destroy the context? If that's the case that would be awesome. (If you look right now, nvidia-smi will show that even after Session.close(), the GPU contexts still exist and thus you cannot launch more processes that use them.)\n\nThe most important thing is that when visible_gpu_devices is used, the contexts are not created on all visible devices \u2013 not just that memory is not allocated on them, but that they are completely uninitialized, so that other concurrently running Tensorflow processes can use them.", "body": "@vrv Yes! This would be perfect! (In fact, I started implementing _literally_ the same thing today, in the same manner.)\n\nMinor questions:\n- Shouldn't that be part of ConfigProto not GPUOptions? (GPUOptions seems like it is settings that affect a single GPU, while ConfigProto has settings related to many GPUs, for example device_count)\n- Why pass `visible_gpu_devices` as a string, rather than as a `repeated int`?\n- To confirm: this interacts fluidly with `CUDA_VISIBLE_DEVICES`. For example, if, on an 8-GPU system, `CUDA_VISIBLE_DEVICES=5,2,0,6`, and you set `visible_gpu_devices=0,3`, Tensorflow will end up running on GPUs 5 and 6.\n- Does this change also mean that, since the GPU info is stored in the `Session`, `Session.close()` can now actually deallocate the GPU and destroy the context? If that's the case that would be _awesome_. (If you look right now, `nvidia-smi` will show that even after `Session.close()`, the GPU contexts still exist and thus you cannot launch more processes that use them.)\n\nThe most important thing is that when `visible_gpu_devices` is used, the contexts are _not_ created on all visible devices \u2013 not just that memory is not allocated on them, but that they are completely uninitialized, so that other concurrently running Tensorflow processes can use them.\n"}