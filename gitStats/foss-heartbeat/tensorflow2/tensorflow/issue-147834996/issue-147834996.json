{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1888", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1888/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1888/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1888/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1888", "id": 147834996, "node_id": "MDU6SXNzdWUxNDc4MzQ5OTY=", "number": 1888, "title": "Feature request: Ability to specify some GPUs and ignore all others", "user": {"login": "rdipietro", "id": 5150559, "node_id": "MDQ6VXNlcjUxNTA1NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5150559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdipietro", "html_url": "https://github.com/rdipietro", "followers_url": "https://api.github.com/users/rdipietro/followers", "following_url": "https://api.github.com/users/rdipietro/following{/other_user}", "gists_url": "https://api.github.com/users/rdipietro/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdipietro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdipietro/subscriptions", "organizations_url": "https://api.github.com/users/rdipietro/orgs", "repos_url": "https://api.github.com/users/rdipietro/repos", "events_url": "https://api.github.com/users/rdipietro/events{/privacy}", "received_events_url": "https://api.github.com/users/rdipietro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 40, "created_at": "2016-04-12T18:26:31Z", "updated_at": "2018-03-15T03:10:57Z", "closed_at": "2016-09-06T18:19:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Right now, to specify a particular GPU, I do something like this:</p>\n<pre><code>gpu = 0\navailable_devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')\nos.environ['CUDA_VISIBLE_DEVICES'] = available_devices[gpu]\n</code></pre>\n<p>after which TensorFlow will only allocate resources on the first GPU device. It would be nice to include a native way to do this.</p>\n<p>Side note: There isn't much documentation (any?) on <code>device_count</code>, so I'm not sure if it's meant to handle this. Either way, I have experimented with the <code>device_count</code>, but with no luck: if I use <code>device_count = {'GPU': 1}</code>, TensorFlow still allocates memory on all available GPUs.</p>", "body_text": "Right now, to specify a particular GPU, I do something like this:\ngpu = 0\navailable_devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')\nos.environ['CUDA_VISIBLE_DEVICES'] = available_devices[gpu]\n\nafter which TensorFlow will only allocate resources on the first GPU device. It would be nice to include a native way to do this.\nSide note: There isn't much documentation (any?) on device_count, so I'm not sure if it's meant to handle this. Either way, I have experimented with the device_count, but with no luck: if I use device_count = {'GPU': 1}, TensorFlow still allocates memory on all available GPUs.", "body": "Right now, to specify a particular GPU, I do something like this:\n\n```\ngpu = 0\navailable_devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')\nos.environ['CUDA_VISIBLE_DEVICES'] = available_devices[gpu]\n```\n\nafter which TensorFlow will only allocate resources on the first GPU device. It would be nice to include a native way to do this.\n\nSide note: There isn't much documentation (any?) on `device_count`, so I'm not sure if it's meant to handle this. Either way, I have experimented with the `device_count`, but with no luck: if I use `device_count = {'GPU': 1}`, TensorFlow still allocates memory on all available GPUs.\n"}