{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3635", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3635/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3635/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3635/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/3635", "id": 169266278, "node_id": "MDExOlB1bGxSZXF1ZXN0ODAwMDIyOTc=", "number": 3635, "title": "Fixed inconsistency of outputs collection", "user": {"login": "Egor-Krivov", "id": 5444879, "node_id": "MDQ6VXNlcjU0NDQ4Nzk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5444879?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Egor-Krivov", "html_url": "https://github.com/Egor-Krivov", "followers_url": "https://api.github.com/users/Egor-Krivov/followers", "following_url": "https://api.github.com/users/Egor-Krivov/following{/other_user}", "gists_url": "https://api.github.com/users/Egor-Krivov/gists{/gist_id}", "starred_url": "https://api.github.com/users/Egor-Krivov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Egor-Krivov/subscriptions", "organizations_url": "https://api.github.com/users/Egor-Krivov/orgs", "repos_url": "https://api.github.com/users/Egor-Krivov/repos", "events_url": "https://api.github.com/users/Egor-Krivov/events{/privacy}", "received_events_url": "https://api.github.com/users/Egor-Krivov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 419840263, "node_id": "MDU6TGFiZWw0MTk4NDAyNjM=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20testing%20(then%20merge)", "name": "awaiting testing (then merge)", "color": "c2e0c6", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2016-08-04T00:41:15Z", "updated_at": "2016-08-23T19:22:50Z", "closed_at": "2016-08-23T19:22:50Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3635", "html_url": "https://github.com/tensorflow/tensorflow/pull/3635", "diff_url": "https://github.com/tensorflow/tensorflow/pull/3635.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/3635.patch"}, "body_html": "<p>Because naming logic for utils.collect_named_outputs in max_pool2d and convolution2d is different, collection is getting filled with inconsistent names.<br>\ncode to reproduce:</p>\n<pre><code>graph = tf.Graph()\n\nnode_collection = 'nodes'\nwith graph.as_default():\n    x = tf.placeholder(tf.float32, (1, 20, 20, 3))\n\n    with tf.name_scope('name_scope'):\n        conv = tf.contrib.layers.conv2d(\n            x, num_outputs=8, kernel_size=4,\n            scope='conv', outputs_collections=node_collection)\n        max_pool = tf.contrib.layers.max_pool2d(\n                conv, kernel_size=2, stride=2, scope='max_pool',\n                outputs_collections=node_collection)\n\nprint([nt.name for nt in graph.get_collection(node_collection)])\n=============================================\n['conv', 'name_scope/max_pool']\n</code></pre>\n<p>Expected output is ['name_scope/conv', 'name_scope/max_pool'].</p>\n<p>It is also important for those who use tf.name_scope to distinguish processing of different inputs with the same layer, like in siamese neural network. Currently, they will get identical names.<br>\nCode to reproduce:</p>\n<pre><code>graph = tf.Graph()\n\nnode_collection = 'nodes'\nwith graph.as_default():\n  input_a = tf.placeholder(tf.float32, (1, 20, 20, 3))\n  input_b = tf.placeholder(tf.float32, (1, 20, 20, 3))\n  with tf.variable_scope('feature_extractor') as vs:\n    for name_scope, inputs in [('a', input_a), ('b', input_b)]:\n      with tf.name_scope(name_scope):\n        conv = tf.contrib.layers.conv2d(\n          inputs, num_outputs=8, kernel_size=4,\n          scope='conv', outputs_collections=node_collection)\n        max_pool = tf.contrib.layers.max_pool2d(\n          conv, kernel_size=2, stride=2, scope='max_pool',\n          outputs_collections=node_collection)\n      vs.reuse_variables()\n\nprint([nt.name for nt in graph.get_collection(node_collection)])\n=============================================\n['feature_extractor/conv', 'feature_extractor/a/max_pool', 'feature_extractor/conv', 'feature_extractor/b/max_pool']\n</code></pre>", "body_text": "Because naming logic for utils.collect_named_outputs in max_pool2d and convolution2d is different, collection is getting filled with inconsistent names.\ncode to reproduce:\ngraph = tf.Graph()\n\nnode_collection = 'nodes'\nwith graph.as_default():\n    x = tf.placeholder(tf.float32, (1, 20, 20, 3))\n\n    with tf.name_scope('name_scope'):\n        conv = tf.contrib.layers.conv2d(\n            x, num_outputs=8, kernel_size=4,\n            scope='conv', outputs_collections=node_collection)\n        max_pool = tf.contrib.layers.max_pool2d(\n                conv, kernel_size=2, stride=2, scope='max_pool',\n                outputs_collections=node_collection)\n\nprint([nt.name for nt in graph.get_collection(node_collection)])\n=============================================\n['conv', 'name_scope/max_pool']\n\nExpected output is ['name_scope/conv', 'name_scope/max_pool'].\nIt is also important for those who use tf.name_scope to distinguish processing of different inputs with the same layer, like in siamese neural network. Currently, they will get identical names.\nCode to reproduce:\ngraph = tf.Graph()\n\nnode_collection = 'nodes'\nwith graph.as_default():\n  input_a = tf.placeholder(tf.float32, (1, 20, 20, 3))\n  input_b = tf.placeholder(tf.float32, (1, 20, 20, 3))\n  with tf.variable_scope('feature_extractor') as vs:\n    for name_scope, inputs in [('a', input_a), ('b', input_b)]:\n      with tf.name_scope(name_scope):\n        conv = tf.contrib.layers.conv2d(\n          inputs, num_outputs=8, kernel_size=4,\n          scope='conv', outputs_collections=node_collection)\n        max_pool = tf.contrib.layers.max_pool2d(\n          conv, kernel_size=2, stride=2, scope='max_pool',\n          outputs_collections=node_collection)\n      vs.reuse_variables()\n\nprint([nt.name for nt in graph.get_collection(node_collection)])\n=============================================\n['feature_extractor/conv', 'feature_extractor/a/max_pool', 'feature_extractor/conv', 'feature_extractor/b/max_pool']", "body": "Because naming logic for utils.collect_named_outputs in max_pool2d and convolution2d is different, collection is getting filled with inconsistent names.\ncode to reproduce:\n\n```\ngraph = tf.Graph()\n\nnode_collection = 'nodes'\nwith graph.as_default():\n    x = tf.placeholder(tf.float32, (1, 20, 20, 3))\n\n    with tf.name_scope('name_scope'):\n        conv = tf.contrib.layers.conv2d(\n            x, num_outputs=8, kernel_size=4,\n            scope='conv', outputs_collections=node_collection)\n        max_pool = tf.contrib.layers.max_pool2d(\n                conv, kernel_size=2, stride=2, scope='max_pool',\n                outputs_collections=node_collection)\n\nprint([nt.name for nt in graph.get_collection(node_collection)])\n=============================================\n['conv', 'name_scope/max_pool']\n```\n\nExpected output is ['name_scope/conv', 'name_scope/max_pool'].\n\nIt is also important for those who use tf.name_scope to distinguish processing of different inputs with the same layer, like in siamese neural network. Currently, they will get identical names.\nCode to reproduce:\n\n```\ngraph = tf.Graph()\n\nnode_collection = 'nodes'\nwith graph.as_default():\n  input_a = tf.placeholder(tf.float32, (1, 20, 20, 3))\n  input_b = tf.placeholder(tf.float32, (1, 20, 20, 3))\n  with tf.variable_scope('feature_extractor') as vs:\n    for name_scope, inputs in [('a', input_a), ('b', input_b)]:\n      with tf.name_scope(name_scope):\n        conv = tf.contrib.layers.conv2d(\n          inputs, num_outputs=8, kernel_size=4,\n          scope='conv', outputs_collections=node_collection)\n        max_pool = tf.contrib.layers.max_pool2d(\n          conv, kernel_size=2, stride=2, scope='max_pool',\n          outputs_collections=node_collection)\n      vs.reuse_variables()\n\nprint([nt.name for nt in graph.get_collection(node_collection)])\n=============================================\n['feature_extractor/conv', 'feature_extractor/a/max_pool', 'feature_extractor/conv', 'feature_extractor/b/max_pool']\n```\n"}