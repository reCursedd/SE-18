{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15120", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15120/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15120/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15120/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15120", "id": 279295889, "node_id": "MDU6SXNzdWUyNzkyOTU4ODk=", "number": 15120, "title": "[Feature Request] Please make Estimator.export_savedmodel support input types other than tf.Example", "user": {"login": "snnn", "id": 856316, "node_id": "MDQ6VXNlcjg1NjMxNg==", "avatar_url": "https://avatars3.githubusercontent.com/u/856316?v=4", "gravatar_id": "", "url": "https://api.github.com/users/snnn", "html_url": "https://github.com/snnn", "followers_url": "https://api.github.com/users/snnn/followers", "following_url": "https://api.github.com/users/snnn/following{/other_user}", "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}", "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/snnn/subscriptions", "organizations_url": "https://api.github.com/users/snnn/orgs", "repos_url": "https://api.github.com/users/snnn/repos", "events_url": "https://api.github.com/users/snnn/events{/privacy}", "received_events_url": "https://api.github.com/users/snnn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-05T09:03:56Z", "updated_at": "2017-12-05T11:05:09Z", "closed_at": "2017-12-05T10:37:47Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nbinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.4.1</li>\n<li><strong>Python version</strong>:<br>\n3.5.3</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nNone</li>\n<li><strong>GPU model and memory</strong>:<br>\nNone</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I have a model,  I want to export it into SavedModel format by using tf.estimator API, because I'm using this API for training. Unfortunately,tf.estimator.export.build_raw_serving_input_receiver_fn and tf.saved_model.signature_def_utils.classification_signature_def require the input features must be encoded in tf.Example format.</p>\n<p>In order to use the \"export_savedmodel\" function for exporting, when writing a custom model_fn for Estimator, I must populate the export_outputs element of the tf.estimator.EstimatorSpec return value.  Each output value must be an ExportOutput object such as tf.estimator.export.ClassificationOutput, tf.estimator.export.RegressionOutput, or tf.estimator.export.PredictOutput. Those three output types only support tf.Example as the input.</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">if</span> (classes <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>\n        <span class=\"pl-k\">and</span> <span class=\"pl-k\">not</span> (<span class=\"pl-c1\">isinstance</span>(classes, ops.Tensor)\n                 <span class=\"pl-k\">and</span> dtypes.as_dtype(classes.dtype) <span class=\"pl-k\">==</span> dtypes.string)):\n      <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Classification classes must be a string Tensor; <span class=\"pl-pds\">'</span></span>\n                       <span class=\"pl-s\"><span class=\"pl-pds\">'</span>got <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(classes))</pre></div>\n<p>Because they will use signature_def_utils.classification_signature_def(or predict_signature_def,...) to build the signature.</p>\n<p>Though I may build a new output type by myself, it doesn't.<br>\nAs the comment in tensorflow\\python\\estimator\\export\\export.py:build_all_signature_defs stated:<br>\n\"the call to is_valid_signature here should not remove anything else.\"<br>\nIf you really want to remove it, please show me a warning.</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Convolutional Neural Network Estimator for MNIST, built with tf.layers.<span class=\"pl-pds\">\"\"\"</span></span>\n\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n\n<span class=\"pl-k\">import</span> argparse\n<span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> sys\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nparser <span class=\"pl-k\">=</span> argparse.ArgumentParser()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Basic model parameters.</span>\nparser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--batch_size<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>,\n                    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Number of images to process in a batch<span class=\"pl-pds\">'</span></span>)\n\nparser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--model_dir<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>/tmp/mnist_model<span class=\"pl-pds\">'</span></span>,\n                    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>The directory where the model will be stored.<span class=\"pl-pds\">'</span></span>)\n\n\nparser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--data_format<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n    <span class=\"pl-v\">choices</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_first<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_last<span class=\"pl-pds\">'</span></span>],\n    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>A flag to override the data format used in the model. channels_first <span class=\"pl-pds\">'</span></span>\n         <span class=\"pl-s\"><span class=\"pl-pds\">'</span>provides a performance boost on GPU but is not always compatible <span class=\"pl-pds\">'</span></span>\n         <span class=\"pl-s\"><span class=\"pl-pds\">'</span>with CPU. If left unspecified, the data format will be chosen <span class=\"pl-pds\">'</span></span>\n         <span class=\"pl-s\"><span class=\"pl-pds\">'</span>automatically based on whether TensorFlow was built for CPU or GPU.<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c1\">_NUM_IMAGES</span> <span class=\"pl-k\">=</span> {\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>train<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">50000</span>,\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>validation<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">10000</span>,\n}\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">mnist_model</span>(<span class=\"pl-smi\">inputs</span>, <span class=\"pl-smi\">mode</span>, <span class=\"pl-smi\">data_format</span>):\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Takes the MNIST inputs and mode and outputs a tensor of logits.<span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Input Layer</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Reshape X to 4-D tensor: [batch_size, width, height, channels]</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> MNIST images are 28x28 pixels, and have one color channel</span>\n  inputs <span class=\"pl-k\">=</span> tf.reshape(inputs, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>])\n\n  <span class=\"pl-k\">if</span> data_format <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n    data_format <span class=\"pl-k\">=</span> (<span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_first<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">if</span> tf.test.is_built_with_cuda() <span class=\"pl-k\">else</span>\n                   <span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_last<span class=\"pl-pds\">'</span></span>)\n\n  <span class=\"pl-k\">if</span> data_format <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_first<span class=\"pl-pds\">'</span></span>:\n    inputs <span class=\"pl-k\">=</span> tf.transpose(inputs, [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>])\n\n  conv1 <span class=\"pl-k\">=</span> tf.layers.conv2d(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>inputs,\n      <span class=\"pl-v\">filters</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>,\n      <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>],\n      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu,\n      <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n\n\n  pool1 <span class=\"pl-k\">=</span> tf.layers.max_pooling2d(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>conv1, <span class=\"pl-v\">pool_size</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>], <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>,\n                                  <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n\n\n  conv2 <span class=\"pl-k\">=</span> tf.layers.conv2d(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>pool1,\n      <span class=\"pl-v\">filters</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">64</span>,\n      <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>],\n      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu,\n      <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n\n  pool2 <span class=\"pl-k\">=</span> tf.layers.max_pooling2d(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>conv2, <span class=\"pl-v\">pool_size</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>], <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>,\n                                  <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n\n\n  pool2_flat <span class=\"pl-k\">=</span> tf.reshape(pool2, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">7</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">7</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">64</span>])\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Dense Layer</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Densely connected layer with 1024 neurons</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Input Tensor Shape: [batch_size, 7 * 7 * 64]</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Output Tensor Shape: [batch_size, 1024]</span>\n  dense <span class=\"pl-k\">=</span> tf.layers.dense(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>pool2_flat, <span class=\"pl-v\">units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1024</span>,\n                          <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu)\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add dropout operation; 0.6 probability that element will be kept</span>\n  dropout <span class=\"pl-k\">=</span> tf.layers.dropout(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>dense, <span class=\"pl-v\">rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.4</span>, <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span>(mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>))\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Logits layer</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Input Tensor Shape: [batch_size, 1024]</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Output Tensor Shape: [batch_size, 10]</span>\n  logits <span class=\"pl-k\">=</span> tf.layers.dense(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>dropout, <span class=\"pl-v\">units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)\n  <span class=\"pl-k\">return</span> logits\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">mnist_model_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>, <span class=\"pl-smi\">params</span>):\n  <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(features,<span class=\"pl-c1\">dict</span>):\n    features <span class=\"pl-k\">=</span> features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>image_raw<span class=\"pl-pds\">'</span></span>]\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Model function for MNIST.<span class=\"pl-pds\">\"\"\"</span></span>\n  logits <span class=\"pl-k\">=</span> mnist_model(features, mode, params[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>data_format<span class=\"pl-pds\">'</span></span>])\n\n  predictions <span class=\"pl-k\">=</span> {\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>classes<span class=\"pl-pds\">'</span></span>: tf.argmax(<span class=\"pl-v\">input</span><span class=\"pl-k\">=</span>logits, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>),\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>probabilities<span class=\"pl-pds\">'</span></span>: tf.nn.softmax(logits, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>softmax_tensor<span class=\"pl-pds\">'</span></span>)\n  }\n\n  <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">PREDICT</span>:\n    <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">predictions</span><span class=\"pl-k\">=</span>predictions,\n                                      <span class=\"pl-v\">export_outputs</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>class<span class=\"pl-pds\">'</span></span>: tf.estimator.export.ClassificationOutput(<span class=\"pl-v\">classes</span><span class=\"pl-k\">=</span>tf.as_string(predictions[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>classes<span class=\"pl-pds\">'</span></span>]))})  \n\n  loss <span class=\"pl-k\">=</span> tf.losses.softmax_cross_entropy(<span class=\"pl-v\">onehot_labels</span><span class=\"pl-k\">=</span>labels, <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>logits)\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Configure the training op</span>\n  <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>:\n    optimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-4</span>)\n    train_op <span class=\"pl-k\">=</span> optimizer.minimize(loss, tf.train.get_or_create_global_step())\n  <span class=\"pl-k\">else</span>:\n    train_op <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n  accuracy <span class=\"pl-k\">=</span> tf.metrics.accuracy(tf.argmax(labels, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>), predictions[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>classes<span class=\"pl-pds\">'</span></span>])\n  metrics <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>: accuracy}\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a tensor named train_accuracy for logging purposes</span>\n  tf.identity(accuracy[<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>train_accuracy<span class=\"pl-pds\">'</span></span>)\n  tf.summary.scalar(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>train_accuracy<span class=\"pl-pds\">'</span></span>, accuracy[<span class=\"pl-c1\">1</span>])\n\n  <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode,\n      <span class=\"pl-v\">predictions</span><span class=\"pl-k\">=</span>predictions,\n      <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss,\n      <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>train_op,\n      <span class=\"pl-v\">eval_metric_ops</span><span class=\"pl-k\">=</span>metrics)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">unused_argv</span>):\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create the Estimator</span>\n  mnist_classifier <span class=\"pl-k\">=</span> tf.estimator.Estimator(<span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>mnist_model_fn, <span class=\"pl-v\">model_dir</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.model_dir,\n      <span class=\"pl-v\">params</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>data_format<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">FLAGS</span>.data_format})\n  image <span class=\"pl-k\">=</span> tf.placeholder(tf.float32,[<span class=\"pl-c1\">None</span>])\n  mnist_classifier.export_savedmodel(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>bb<span class=\"pl-pds\">\"</span></span>, tf.estimator.export.build_raw_serving_input_receiver_fn({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>image_raw<span class=\"pl-pds\">\"</span></span>:image}))  \n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n  tf.logging.set_verbosity(tf.logging.<span class=\"pl-c1\">INFO</span>)\n  <span class=\"pl-c1\">FLAGS</span>, unparsed <span class=\"pl-k\">=</span> parser.parse_known_args()\n  tf.app.run(<span class=\"pl-v\">main</span><span class=\"pl-k\">=</span>main, <span class=\"pl-v\">argv</span><span class=\"pl-k\">=</span>[sys.argv[<span class=\"pl-c1\">0</span>]] <span class=\"pl-k\">+</span> unparsed)</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 10\nTensorFlow installed from (source or binary):\nbinary\nTensorFlow version (use command below):\n1.4.1\nPython version:\n3.5.3\nCUDA/cuDNN version:\nNone\nGPU model and memory:\nNone\nExact command to reproduce:\n\nDescribe the problem\nI have a model,  I want to export it into SavedModel format by using tf.estimator API, because I'm using this API for training. Unfortunately,tf.estimator.export.build_raw_serving_input_receiver_fn and tf.saved_model.signature_def_utils.classification_signature_def require the input features must be encoded in tf.Example format.\nIn order to use the \"export_savedmodel\" function for exporting, when writing a custom model_fn for Estimator, I must populate the export_outputs element of the tf.estimator.EstimatorSpec return value.  Each output value must be an ExportOutput object such as tf.estimator.export.ClassificationOutput, tf.estimator.export.RegressionOutput, or tf.estimator.export.PredictOutput. Those three output types only support tf.Example as the input.\n    if (classes is not None\n        and not (isinstance(classes, ops.Tensor)\n                 and dtypes.as_dtype(classes.dtype) == dtypes.string)):\n      raise ValueError('Classification classes must be a string Tensor; '\n                       'got {}'.format(classes))\nBecause they will use signature_def_utils.classification_signature_def(or predict_signature_def,...) to build the signature.\nThough I may build a new output type by myself, it doesn't.\nAs the comment in tensorflow\\python\\estimator\\export\\export.py:build_all_signature_defs stated:\n\"the call to is_valid_signature here should not remove anything else.\"\nIf you really want to remove it, please show me a warning.\nSource code / logs\n\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport os\nimport sys\n\nimport tensorflow as tf\n\nparser = argparse.ArgumentParser()\n\n# Basic model parameters.\nparser.add_argument('--batch_size', type=int, default=100,\n                    help='Number of images to process in a batch')\n\nparser.add_argument('--model_dir', type=str, default='/tmp/mnist_model',\n                    help='The directory where the model will be stored.')\n\n\nparser.add_argument('--data_format', type=str, default=None,\n    choices=['channels_first', 'channels_last'],\n    help='A flag to override the data format used in the model. channels_first '\n         'provides a performance boost on GPU but is not always compatible '\n         'with CPU. If left unspecified, the data format will be chosen '\n         'automatically based on whether TensorFlow was built for CPU or GPU.')\n\n_NUM_IMAGES = {\n    'train': 50000,\n    'validation': 10000,\n}\n\ndef mnist_model(inputs, mode, data_format):\n  \"\"\"Takes the MNIST inputs and mode and outputs a tensor of logits.\"\"\"\n  # Input Layer\n  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n  # MNIST images are 28x28 pixels, and have one color channel\n  inputs = tf.reshape(inputs, [-1, 28, 28, 1])\n\n  if data_format is None:\n    data_format = ('channels_first' if tf.test.is_built_with_cuda() else\n                   'channels_last')\n\n  if data_format == 'channels_first':\n    inputs = tf.transpose(inputs, [0, 3, 1, 2])\n\n  conv1 = tf.layers.conv2d(inputs=inputs,\n      filters=32,\n      kernel_size=[5, 5],\n      padding='same',\n      activation=tf.nn.relu,\n      data_format=data_format)\n\n\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2,\n                                  data_format=data_format)\n\n\n  conv2 = tf.layers.conv2d(inputs=pool1,\n      filters=64,\n      kernel_size=[5, 5],\n      padding='same',\n      activation=tf.nn.relu,\n      data_format=data_format)\n\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2,\n                                  data_format=data_format)\n\n\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\n  # Dense Layer\n  # Densely connected layer with 1024 neurons\n  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n  # Output Tensor Shape: [batch_size, 1024]\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024,\n                          activation=tf.nn.relu)\n\n  # Add dropout operation; 0.6 probability that element will be kept\n  dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=(mode == tf.estimator.ModeKeys.TRAIN))\n\n  # Logits layer\n  # Input Tensor Shape: [batch_size, 1024]\n  # Output Tensor Shape: [batch_size, 10]\n  logits = tf.layers.dense(inputs=dropout, units=10)\n  return logits\n\n\ndef mnist_model_fn(features, labels, mode, params):\n  if isinstance(features,dict):\n    features = features['image_raw']\n  \"\"\"Model function for MNIST.\"\"\"\n  logits = mnist_model(features, mode, params['data_format'])\n\n  predictions = {\n      'classes': tf.argmax(input=logits, axis=1),\n      'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n  }\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n                                      export_outputs={'class': tf.estimator.export.ClassificationOutput(classes=tf.as_string(predictions['classes']))})  \n\n  loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n\n  # Configure the training op\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n    train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())\n  else:\n    train_op = None\n\n  accuracy = tf.metrics.accuracy(tf.argmax(labels, axis=1), predictions['classes'])\n  metrics = {'accuracy': accuracy}\n\n  # Create a tensor named train_accuracy for logging purposes\n  tf.identity(accuracy[1], name='train_accuracy')\n  tf.summary.scalar('train_accuracy', accuracy[1])\n\n  return tf.estimator.EstimatorSpec(mode=mode,\n      predictions=predictions,\n      loss=loss,\n      train_op=train_op,\n      eval_metric_ops=metrics)\n\ndef main(unused_argv):\n  # Create the Estimator\n  mnist_classifier = tf.estimator.Estimator(model_fn=mnist_model_fn, model_dir=FLAGS.model_dir,\n      params={'data_format': FLAGS.data_format})\n  image = tf.placeholder(tf.float32,[None])\n  mnist_classifier.export_savedmodel(\"bb\", tf.estimator.export.build_raw_serving_input_receiver_fn({\"image_raw\":image}))  \n\nif __name__ == '__main__':\n  tf.logging.set_verbosity(tf.logging.INFO)\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.4.1\r\n- **Python version**: \r\n3.5.3\r\n- **CUDA/cuDNN version**:\r\nNone\r\n- **GPU model and memory**:\r\nNone\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI have a model,  I want to export it into SavedModel format by using tf.estimator API, because I'm using this API for training. Unfortunately,tf.estimator.export.build_raw_serving_input_receiver_fn and tf.saved_model.signature_def_utils.classification_signature_def require the input features must be encoded in tf.Example format.\r\n\r\nIn order to use the \"export_savedmodel\" function for exporting, when writing a custom model_fn for Estimator, I must populate the export_outputs element of the tf.estimator.EstimatorSpec return value.  Each output value must be an ExportOutput object such as tf.estimator.export.ClassificationOutput, tf.estimator.export.RegressionOutput, or tf.estimator.export.PredictOutput. Those three output types only support tf.Example as the input. \r\n\r\n```python\r\n    if (classes is not None\r\n        and not (isinstance(classes, ops.Tensor)\r\n                 and dtypes.as_dtype(classes.dtype) == dtypes.string)):\r\n      raise ValueError('Classification classes must be a string Tensor; '\r\n                       'got {}'.format(classes))\r\n```\r\n\r\nBecause they will use signature_def_utils.classification_signature_def(or predict_signature_def,...) to build the signature.\r\n\r\nThough I may build a new output type by myself, it doesn't. \r\nAs the comment in tensorflow\\python\\estimator\\export\\export.py:build_all_signature_defs stated:\r\n\"the call to is_valid_signature here should not remove anything else.\"\r\nIf you really want to remove it, please show me a warning.\r\n\r\n### Source code / logs\r\n```python\r\n\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport os\r\nimport sys\r\n\r\nimport tensorflow as tf\r\n\r\nparser = argparse.ArgumentParser()\r\n\r\n# Basic model parameters.\r\nparser.add_argument('--batch_size', type=int, default=100,\r\n                    help='Number of images to process in a batch')\r\n\r\nparser.add_argument('--model_dir', type=str, default='/tmp/mnist_model',\r\n                    help='The directory where the model will be stored.')\r\n\r\n\r\nparser.add_argument('--data_format', type=str, default=None,\r\n    choices=['channels_first', 'channels_last'],\r\n    help='A flag to override the data format used in the model. channels_first '\r\n         'provides a performance boost on GPU but is not always compatible '\r\n         'with CPU. If left unspecified, the data format will be chosen '\r\n         'automatically based on whether TensorFlow was built for CPU or GPU.')\r\n\r\n_NUM_IMAGES = {\r\n    'train': 50000,\r\n    'validation': 10000,\r\n}\r\n\r\ndef mnist_model(inputs, mode, data_format):\r\n  \"\"\"Takes the MNIST inputs and mode and outputs a tensor of logits.\"\"\"\r\n  # Input Layer\r\n  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\r\n  # MNIST images are 28x28 pixels, and have one color channel\r\n  inputs = tf.reshape(inputs, [-1, 28, 28, 1])\r\n\r\n  if data_format is None:\r\n    data_format = ('channels_first' if tf.test.is_built_with_cuda() else\r\n                   'channels_last')\r\n\r\n  if data_format == 'channels_first':\r\n    inputs = tf.transpose(inputs, [0, 3, 1, 2])\r\n\r\n  conv1 = tf.layers.conv2d(inputs=inputs,\r\n      filters=32,\r\n      kernel_size=[5, 5],\r\n      padding='same',\r\n      activation=tf.nn.relu,\r\n      data_format=data_format)\r\n\r\n\r\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2,\r\n                                  data_format=data_format)\r\n\r\n\r\n  conv2 = tf.layers.conv2d(inputs=pool1,\r\n      filters=64,\r\n      kernel_size=[5, 5],\r\n      padding='same',\r\n      activation=tf.nn.relu,\r\n      data_format=data_format)\r\n\r\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2,\r\n                                  data_format=data_format)\r\n\r\n\r\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\r\n\r\n  # Dense Layer\r\n  # Densely connected layer with 1024 neurons\r\n  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\r\n  # Output Tensor Shape: [batch_size, 1024]\r\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024,\r\n                          activation=tf.nn.relu)\r\n\r\n  # Add dropout operation; 0.6 probability that element will be kept\r\n  dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n\r\n  # Logits layer\r\n  # Input Tensor Shape: [batch_size, 1024]\r\n  # Output Tensor Shape: [batch_size, 10]\r\n  logits = tf.layers.dense(inputs=dropout, units=10)\r\n  return logits\r\n\r\n\r\ndef mnist_model_fn(features, labels, mode, params):\r\n  if isinstance(features,dict):\r\n    features = features['image_raw']\r\n  \"\"\"Model function for MNIST.\"\"\"\r\n  logits = mnist_model(features, mode, params['data_format'])\r\n\r\n  predictions = {\r\n      'classes': tf.argmax(input=logits, axis=1),\r\n      'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\r\n  }\r\n\r\n  if mode == tf.estimator.ModeKeys.PREDICT:\r\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\r\n                                      export_outputs={'class': tf.estimator.export.ClassificationOutput(classes=tf.as_string(predictions['classes']))})  \r\n\r\n  loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\r\n\r\n  # Configure the training op\r\n  if mode == tf.estimator.ModeKeys.TRAIN:\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\r\n    train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())\r\n  else:\r\n    train_op = None\r\n\r\n  accuracy = tf.metrics.accuracy(tf.argmax(labels, axis=1), predictions['classes'])\r\n  metrics = {'accuracy': accuracy}\r\n\r\n  # Create a tensor named train_accuracy for logging purposes\r\n  tf.identity(accuracy[1], name='train_accuracy')\r\n  tf.summary.scalar('train_accuracy', accuracy[1])\r\n\r\n  return tf.estimator.EstimatorSpec(mode=mode,\r\n      predictions=predictions,\r\n      loss=loss,\r\n      train_op=train_op,\r\n      eval_metric_ops=metrics)\r\n\r\ndef main(unused_argv):\r\n  # Create the Estimator\r\n  mnist_classifier = tf.estimator.Estimator(model_fn=mnist_model_fn, model_dir=FLAGS.model_dir,\r\n      params={'data_format': FLAGS.data_format})\r\n  image = tf.placeholder(tf.float32,[None])\r\n  mnist_classifier.export_savedmodel(\"bb\", tf.estimator.export.build_raw_serving_input_receiver_fn({\"image_raw\":image}))  \r\n\r\nif __name__ == '__main__':\r\n  tf.logging.set_verbosity(tf.logging.INFO)\r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n```"}