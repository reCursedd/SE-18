{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/166009191", "html_url": "https://github.com/tensorflow/tensorflow/pull/544#issuecomment-166009191", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/544", "id": 166009191, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NjAwOTE5MQ==", "user": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-19T17:40:29Z", "updated_at": "2015-12-19T17:40:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/20723e2b3d58cc48b2a302f7ea9806c8a75fd18f/tensorflow/python/ops/nn.py#L631\">tensorflow/tensorflow/python/ops/nn.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 631\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/20723e2b3d58cc48b2a302f7ea9806c8a75fd18f\">20723e2</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L631\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"631\"></td>\n          <td id=\"LC631\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> all_w <span class=\"pl-k\">=</span> embedding_ops.embedding_lookup( </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>nce_weights / bias are used as input to the nce_loss higher-level function, which also, under the hood, calls embedding_lookup, so the same property is required.</p>\n<p>I thought our placement algorithm was supposed to ensure that the variable would not be placed on GPU if all consumers can only be placed on CPU, so hopefully we can dig in later to figure out how to solve this more generally.</p>\n<p>We also have a bug internally to add a self-test to word2vec_basic.py so we could catch this earlier.</p>\n<p>I'll take a closer look at this on Monday -- thanks for fixing this.</p>", "body_text": "tensorflow/tensorflow/python/ops/nn.py\n    \n    \n         Line 631\n      in\n      20723e2\n    \n    \n    \n    \n\n        \n          \n           all_w = embedding_ops.embedding_lookup( \n        \n    \n  \n\n\nnce_weights / bias are used as input to the nce_loss higher-level function, which also, under the hood, calls embedding_lookup, so the same property is required.\nI thought our placement algorithm was supposed to ensure that the variable would not be placed on GPU if all consumers can only be placed on CPU, so hopefully we can dig in later to figure out how to solve this more generally.\nWe also have a bug internally to add a self-test to word2vec_basic.py so we could catch this earlier.\nI'll take a closer look at this on Monday -- thanks for fixing this.", "body": "https://github.com/tensorflow/tensorflow/blob/20723e2b3d58cc48b2a302f7ea9806c8a75fd18f/tensorflow/python/ops/nn.py#L631 \n\nnce_weights / bias are used as input to the nce_loss higher-level function, which also, under the hood, calls embedding_lookup, so the same property is required.\n\nI thought our placement algorithm was supposed to ensure that the variable would not be placed on GPU if all consumers can only be placed on CPU, so hopefully we can dig in later to figure out how to solve this more generally.\n\nWe also have a bug internally to add a self-test to word2vec_basic.py so we could catch this earlier.\n\nI'll take a closer look at this on Monday -- thanks for fixing this.\n"}