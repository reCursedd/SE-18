{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/311585164", "html_url": "https://github.com/tensorflow/tensorflow/issues/4018#issuecomment-311585164", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4018", "id": 311585164, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTU4NTE2NA==", "user": {"login": "cnschn", "id": 1759343, "node_id": "MDQ6VXNlcjE3NTkzNDM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1759343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cnschn", "html_url": "https://github.com/cnschn", "followers_url": "https://api.github.com/users/cnschn/followers", "following_url": "https://api.github.com/users/cnschn/following{/other_user}", "gists_url": "https://api.github.com/users/cnschn/gists{/gist_id}", "starred_url": "https://api.github.com/users/cnschn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cnschn/subscriptions", "organizations_url": "https://api.github.com/users/cnschn/orgs", "repos_url": "https://api.github.com/users/cnschn/repos", "events_url": "https://api.github.com/users/cnschn/events{/privacy}", "received_events_url": "https://api.github.com/users/cnschn/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-28T07:53:59Z", "updated_at": "2017-06-28T07:53:59Z", "author_association": "NONE", "body_html": "<p>I'm having the same issue as @fcahoon and will try to add some more information on what the problem is.</p>\n<p>I'm on Debian 8 (Jessie), cuda toolkit 7.5 and cudNN 5.1. The cuda toolkit was, however, not installed using the installer from Nvidia, but via the system package manager (in my case from the jessie-backports repo, in @fcahoon's case using the .deb packages directly downloaded from Nvidia). This places all cuda libraries in standard system locations as shown above instead of bunching them together in, e.g. <code>/usr/local/cuda/</code>.</p>\n<p>Now, trying to build tf from source (I cloned the git repo and checked out tag <code>v1.2.0</code>), the <code>./configure</code> script asks for the cuda toolkit location:</p>\n<pre><code>[...]\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N] N\nnvcc will be used as CUDA compiler\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5\nPlease specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\n</code></pre>\n<p>but there is no \"installation location\" to speak of, and the build would not really need any, as <code>#include &lt;cuda.h&gt;</code> and <code>-lcuda</code> work just fine without any path specifications (all files being in standard locations).</p>\n<p>The exact command to reproduce is thus just <code>./configure</code> on a system with cuda installed from the <code>.deb</code> packages.</p>", "body_text": "I'm having the same issue as @fcahoon and will try to add some more information on what the problem is.\nI'm on Debian 8 (Jessie), cuda toolkit 7.5 and cudNN 5.1. The cuda toolkit was, however, not installed using the installer from Nvidia, but via the system package manager (in my case from the jessie-backports repo, in @fcahoon's case using the .deb packages directly downloaded from Nvidia). This places all cuda libraries in standard system locations as shown above instead of bunching them together in, e.g. /usr/local/cuda/.\nNow, trying to build tf from source (I cloned the git repo and checked out tag v1.2.0), the ./configure script asks for the cuda toolkit location:\n[...]\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N] N\nnvcc will be used as CUDA compiler\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5\nPlease specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\n\nbut there is no \"installation location\" to speak of, and the build would not really need any, as #include <cuda.h> and -lcuda work just fine without any path specifications (all files being in standard locations).\nThe exact command to reproduce is thus just ./configure on a system with cuda installed from the .deb packages.", "body": "I'm having the same issue as @fcahoon and will try to add some more information on what the problem is.\r\n\r\nI'm on Debian 8 (Jessie), cuda toolkit 7.5 and cudNN 5.1. The cuda toolkit was, however, not installed using the installer from Nvidia, but via the system package manager (in my case from the jessie-backports repo, in @fcahoon's case using the .deb packages directly downloaded from Nvidia). This places all cuda libraries in standard system locations as shown above instead of bunching them together in, e.g. `/usr/local/cuda/`.\r\n\r\nNow, trying to build tf from source (I cloned the git repo and checked out tag `v1.2.0`), the `./configure` script asks for the cuda toolkit location:\r\n\r\n```\r\n[...]\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nDo you want to use clang as CUDA compiler? [y/N] N\r\nnvcc will be used as CUDA compiler\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5\r\nPlease specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\n```\r\n\r\nbut there is no \"installation location\" to speak of, and the build would not really need any, as `#include <cuda.h>` and `-lcuda` work just fine without any path specifications (all files being in standard locations).\r\n\r\nThe exact command to reproduce is thus just `./configure` on a system with cuda installed from the `.deb` packages."}