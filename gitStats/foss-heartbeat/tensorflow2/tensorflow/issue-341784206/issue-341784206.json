{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20871", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20871/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20871/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20871/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20871", "id": 341784206, "node_id": "MDU6SXNzdWUzNDE3ODQyMDY=", "number": 20871, "title": "TFLite -- Converting the trained pb file into tflite failed predictions on android", "user": {"login": "longchr123", "id": 15262666, "node_id": "MDQ6VXNlcjE1MjYyNjY2", "avatar_url": "https://avatars0.githubusercontent.com/u/15262666?v=4", "gravatar_id": "", "url": "https://api.github.com/users/longchr123", "html_url": "https://github.com/longchr123", "followers_url": "https://api.github.com/users/longchr123/followers", "following_url": "https://api.github.com/users/longchr123/following{/other_user}", "gists_url": "https://api.github.com/users/longchr123/gists{/gist_id}", "starred_url": "https://api.github.com/users/longchr123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/longchr123/subscriptions", "organizations_url": "https://api.github.com/users/longchr123/orgs", "repos_url": "https://api.github.com/users/longchr123/repos", "events_url": "https://api.github.com/users/longchr123/events{/privacy}", "received_events_url": "https://api.github.com/users/longchr123/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "shashishekhar", "id": 1162712, "node_id": "MDQ6VXNlcjExNjI3MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashishekhar", "html_url": "https://github.com/shashishekhar", "followers_url": "https://api.github.com/users/shashishekhar/followers", "following_url": "https://api.github.com/users/shashishekhar/following{/other_user}", "gists_url": "https://api.github.com/users/shashishekhar/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashishekhar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashishekhar/subscriptions", "organizations_url": "https://api.github.com/users/shashishekhar/orgs", "repos_url": "https://api.github.com/users/shashishekhar/repos", "events_url": "https://api.github.com/users/shashishekhar/events{/privacy}", "received_events_url": "https://api.github.com/users/shashishekhar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shashishekhar", "id": 1162712, "node_id": "MDQ6VXNlcjExNjI3MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashishekhar", "html_url": "https://github.com/shashishekhar", "followers_url": "https://api.github.com/users/shashishekhar/followers", "following_url": "https://api.github.com/users/shashishekhar/following{/other_user}", "gists_url": "https://api.github.com/users/shashishekhar/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashishekhar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashishekhar/subscriptions", "organizations_url": "https://api.github.com/users/shashishekhar/orgs", "repos_url": "https://api.github.com/users/shashishekhar/repos", "events_url": "https://api.github.com/users/shashishekhar/events{/privacy}", "received_events_url": "https://api.github.com/users/shashishekhar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-07-17T06:36:14Z", "updated_at": "2018-08-13T01:34:44Z", "closed_at": "2018-08-13T01:34:44Z", "author_association": "NONE", "body_html": "<p><strong>Question description\uff1a</strong></p>\n<h4>training a pb file, and then convert to tflite file, i use python testing pb file is correct ,but after into tflite file on android testing is wrong, I think this problem should be related to BN(tf.nn.batch_normalization),because when i remove BN get results of android and python are all the same, but with BN is different, the BN is tflite support,and the input data are the same, I don't know why?</h4>\n<hr>\n<p><strong>Test Demo:</strong></p>\n<pre><code>def save_to_pb(sess):\n    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, ['out'])\n    with tf.gfile.FastGFile(MODEL_DIR + 'expert-graph.pb', mode='wb') as f:\n        f.write(constant_graph.SerializeToString())\n\ndef read_data(session):\n    image_name = '182133.jpg'\n    TEST_IMAGINE_PATH = '/home/leve/lcr/ClelebA/Celebra_crop_20w+_w128_dataset/images/test_100/'\n    image = cv.imread(TEST_IMAGINE_PATH + image_name)\n    image = tf.reshape(image, [128, 128, 3])\n    image = image.eval(session=session)\n    image = image[np.newaxis, :]\n    return image\n\ndef batch_norm_lite(x, train=True, bn_decay=0.5,epsilon = 0.001,name='bn'):\n    is_training = tf.convert_to_tensor(train,dtype='bool',name='is_training')\n    x_shape = x.get_shape()\n    params_shape = x_shape[-1:]\n    axis = list(range(len(x_shape) - 1))\n    beta = tf.get_variable(name+'_beta', params_shape, initializer=tf.zeros_initializer())\n    gamma = tf.get_variable(name+'_gamma', params_shape, initializer=tf.ones_initializer())\n    moving_mean = tf.get_variable(name+'_moving_mean', params_shape, initializer=tf.zeros_initializer(), trainable=False)\n    moving_variance = tf.get_variable(name+'_moving_variance', params_shape, initializer=tf.ones_initializer(), trainable=False)\n    mean, variance = tf.nn.moments(x, axis)\n    update_moving_mean = moving_averages.assign_moving_average(moving_mean, mean, bn_decay)\n    update_moving_variance = moving_averages.assign_moving_average(moving_variance, variance, bn_decay)\n    tf.add_to_collection(name+'_update_moving_mean', update_moving_mean)\n    tf.add_to_collection(name+'_update_moving_variance', update_moving_variance)\n    mean, variance = control_flow_ops.cond(\n        is_training, lambda: (mean, variance),\n        lambda: (moving_mean, moving_variance))\n\n    return tf.nn.batch_normalization(x, mean, variance, beta, gamma, epsilon,name=name)\n\ndef train_model():\n    img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 128, 128, 3))\n    b = tf.Variable(tf.truncated_normal((1, 128, 128, 3), seed=1),name='w1')\n    y_real = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\n    val = tf.add(img, b)\n    val = batch_norm_lite(val)\n    out = tf.identity(val, name=\"out\")\n    MSE = tf.reduce_mean(tf.square(y_real - out), name='mse')\n    train_step = tf.train.GradientDescentOptimizer(0.9).minimize(MSE)\n    saver = tf.train.Saver(max_to_keep=10)\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n    config = tf.ConfigProto()\n    config.gpu_options.per_process_gpu_memory_fraction = 0.1\n    config.gpu_options.allow_growth = True\n    with tf.Session() as sess:\n        sess.run(tf.initialize_all_variables())\n        for epoch in range(100):\n            sess.run(train_step,feed_dict={img:read_data(sess)})\n            if epoch % 20 == 0:\n                save_path = saver.save(sess, MODEL_DIR + MODEL_NAME, global_step=epoch + 1)\n            print('step = ' + str(epoch))\n        save_to_pb(sess)\ntrain_model()\n</code></pre>\n<hr>\n<h4>run upper  code and get pb file, when you test pb file with python you maybe get a result like this:</h4>\n<p>39.09046 45.927864 84.797905 45.952957 62.701195 68.00796 41.789146 80.99372 81.67459 81.2203....</p>\n<h4>then run this command to create tflite file:</h4>\n<pre><code>bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/path/expert-graph.pb --output_file=/path/expert-graph.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shape=1,128,128,3 --input_array=img --output_array=out --inference_type=FLOAT --input_data_type=FLOAT --allow_custom_ops\n</code></pre>\n<h4>you will get expert-graph.tflite,then use tflite file to android,will get result like this:</h4>\n<p>49.392387\uff0c 42.290344\uff0c135.30707\uff0c 7.7764254 \uff0c 125.98051\uff0c79.317825 \uff0c157.29184 \uff0c107.58522 \uff0c 283.46997 \uff0c36.103508....</p>\n<h4>Android and python have the same input data,but the result is different,if i remove BN and train, that's ok,but BN is very important,i can remove it ,i don't know how to solve it,this question has been around me for a long time,please help solve it, if don't use TF Lite, what should i do?Thanks</h4>\n<hr>\n<h3>System information</h3>\n<p>Linux Ubuntu 16.04:<br>\nTensorFlow installed from source:<br>\nTensorFlow version 1.8.0:<br>\nPython version:3.6:<br>\nBazel version 0.11.1:<br>\nGCC/Compiler version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10) :<br>\nCUDA/cuDNN 9.0/7.0.5:<br>\nGPU 1060-6G:</p>", "body_text": "Question description\uff1a\ntraining a pb file, and then convert to tflite file, i use python testing pb file is correct ,but after into tflite file on android testing is wrong, I think this problem should be related to BN(tf.nn.batch_normalization),because when i remove BN get results of android and python are all the same, but with BN is different, the BN is tflite support,and the input data are the same, I don't know why?\n\nTest Demo:\ndef save_to_pb(sess):\n    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, ['out'])\n    with tf.gfile.FastGFile(MODEL_DIR + 'expert-graph.pb', mode='wb') as f:\n        f.write(constant_graph.SerializeToString())\n\ndef read_data(session):\n    image_name = '182133.jpg'\n    TEST_IMAGINE_PATH = '/home/leve/lcr/ClelebA/Celebra_crop_20w+_w128_dataset/images/test_100/'\n    image = cv.imread(TEST_IMAGINE_PATH + image_name)\n    image = tf.reshape(image, [128, 128, 3])\n    image = image.eval(session=session)\n    image = image[np.newaxis, :]\n    return image\n\ndef batch_norm_lite(x, train=True, bn_decay=0.5,epsilon = 0.001,name='bn'):\n    is_training = tf.convert_to_tensor(train,dtype='bool',name='is_training')\n    x_shape = x.get_shape()\n    params_shape = x_shape[-1:]\n    axis = list(range(len(x_shape) - 1))\n    beta = tf.get_variable(name+'_beta', params_shape, initializer=tf.zeros_initializer())\n    gamma = tf.get_variable(name+'_gamma', params_shape, initializer=tf.ones_initializer())\n    moving_mean = tf.get_variable(name+'_moving_mean', params_shape, initializer=tf.zeros_initializer(), trainable=False)\n    moving_variance = tf.get_variable(name+'_moving_variance', params_shape, initializer=tf.ones_initializer(), trainable=False)\n    mean, variance = tf.nn.moments(x, axis)\n    update_moving_mean = moving_averages.assign_moving_average(moving_mean, mean, bn_decay)\n    update_moving_variance = moving_averages.assign_moving_average(moving_variance, variance, bn_decay)\n    tf.add_to_collection(name+'_update_moving_mean', update_moving_mean)\n    tf.add_to_collection(name+'_update_moving_variance', update_moving_variance)\n    mean, variance = control_flow_ops.cond(\n        is_training, lambda: (mean, variance),\n        lambda: (moving_mean, moving_variance))\n\n    return tf.nn.batch_normalization(x, mean, variance, beta, gamma, epsilon,name=name)\n\ndef train_model():\n    img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 128, 128, 3))\n    b = tf.Variable(tf.truncated_normal((1, 128, 128, 3), seed=1),name='w1')\n    y_real = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\n    val = tf.add(img, b)\n    val = batch_norm_lite(val)\n    out = tf.identity(val, name=\"out\")\n    MSE = tf.reduce_mean(tf.square(y_real - out), name='mse')\n    train_step = tf.train.GradientDescentOptimizer(0.9).minimize(MSE)\n    saver = tf.train.Saver(max_to_keep=10)\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n    config = tf.ConfigProto()\n    config.gpu_options.per_process_gpu_memory_fraction = 0.1\n    config.gpu_options.allow_growth = True\n    with tf.Session() as sess:\n        sess.run(tf.initialize_all_variables())\n        for epoch in range(100):\n            sess.run(train_step,feed_dict={img:read_data(sess)})\n            if epoch % 20 == 0:\n                save_path = saver.save(sess, MODEL_DIR + MODEL_NAME, global_step=epoch + 1)\n            print('step = ' + str(epoch))\n        save_to_pb(sess)\ntrain_model()\n\n\nrun upper  code and get pb file, when you test pb file with python you maybe get a result like this:\n39.09046 45.927864 84.797905 45.952957 62.701195 68.00796 41.789146 80.99372 81.67459 81.2203....\nthen run this command to create tflite file:\nbazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/path/expert-graph.pb --output_file=/path/expert-graph.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shape=1,128,128,3 --input_array=img --output_array=out --inference_type=FLOAT --input_data_type=FLOAT --allow_custom_ops\n\nyou will get expert-graph.tflite,then use tflite file to android,will get result like this:\n49.392387\uff0c 42.290344\uff0c135.30707\uff0c 7.7764254 \uff0c 125.98051\uff0c79.317825 \uff0c157.29184 \uff0c107.58522 \uff0c 283.46997 \uff0c36.103508....\nAndroid and python have the same input data,but the result is different,if i remove BN and train, that's ok,but BN is very important,i can remove it ,i don't know how to solve it,this question has been around me for a long time,please help solve it, if don't use TF Lite, what should i do?Thanks\n\nSystem information\nLinux Ubuntu 16.04:\nTensorFlow installed from source:\nTensorFlow version 1.8.0:\nPython version:3.6:\nBazel version 0.11.1:\nGCC/Compiler version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10) :\nCUDA/cuDNN 9.0/7.0.5:\nGPU 1060-6G:", "body": "**Question description\uff1a**\r\n####  training a pb file, and then convert to tflite file, i use python testing pb file is correct ,but after into tflite file on android testing is wrong, I think this problem should be related to BN(tf.nn.batch_normalization),because when i remove BN get results of android and python are all the same, but with BN is different, the BN is tflite support,and the input data are the same, I don't know why?\r\n------------------------------------\r\n\r\n**Test Demo:**\r\n```\r\ndef save_to_pb(sess):\r\n    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, ['out'])\r\n    with tf.gfile.FastGFile(MODEL_DIR + 'expert-graph.pb', mode='wb') as f:\r\n        f.write(constant_graph.SerializeToString())\r\n\r\ndef read_data(session):\r\n    image_name = '182133.jpg'\r\n    TEST_IMAGINE_PATH = '/home/leve/lcr/ClelebA/Celebra_crop_20w+_w128_dataset/images/test_100/'\r\n    image = cv.imread(TEST_IMAGINE_PATH + image_name)\r\n    image = tf.reshape(image, [128, 128, 3])\r\n    image = image.eval(session=session)\r\n    image = image[np.newaxis, :]\r\n    return image\r\n\r\ndef batch_norm_lite(x, train=True, bn_decay=0.5,epsilon = 0.001,name='bn'):\r\n    is_training = tf.convert_to_tensor(train,dtype='bool',name='is_training')\r\n    x_shape = x.get_shape()\r\n    params_shape = x_shape[-1:]\r\n    axis = list(range(len(x_shape) - 1))\r\n    beta = tf.get_variable(name+'_beta', params_shape, initializer=tf.zeros_initializer())\r\n    gamma = tf.get_variable(name+'_gamma', params_shape, initializer=tf.ones_initializer())\r\n    moving_mean = tf.get_variable(name+'_moving_mean', params_shape, initializer=tf.zeros_initializer(), trainable=False)\r\n    moving_variance = tf.get_variable(name+'_moving_variance', params_shape, initializer=tf.ones_initializer(), trainable=False)\r\n    mean, variance = tf.nn.moments(x, axis)\r\n    update_moving_mean = moving_averages.assign_moving_average(moving_mean, mean, bn_decay)\r\n    update_moving_variance = moving_averages.assign_moving_average(moving_variance, variance, bn_decay)\r\n    tf.add_to_collection(name+'_update_moving_mean', update_moving_mean)\r\n    tf.add_to_collection(name+'_update_moving_variance', update_moving_variance)\r\n    mean, variance = control_flow_ops.cond(\r\n        is_training, lambda: (mean, variance),\r\n        lambda: (moving_mean, moving_variance))\r\n\r\n    return tf.nn.batch_normalization(x, mean, variance, beta, gamma, epsilon,name=name)\r\n\r\ndef train_model():\r\n    img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 128, 128, 3))\r\n    b = tf.Variable(tf.truncated_normal((1, 128, 128, 3), seed=1),name='w1')\r\n    y_real = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\r\n    val = tf.add(img, b)\r\n    val = batch_norm_lite(val)\r\n    out = tf.identity(val, name=\"out\")\r\n    MSE = tf.reduce_mean(tf.square(y_real - out), name='mse')\r\n    train_step = tf.train.GradientDescentOptimizer(0.9).minimize(MSE)\r\n    saver = tf.train.Saver(max_to_keep=10)\r\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.per_process_gpu_memory_fraction = 0.1\r\n    config.gpu_options.allow_growth = True\r\n    with tf.Session() as sess:\r\n        sess.run(tf.initialize_all_variables())\r\n        for epoch in range(100):\r\n            sess.run(train_step,feed_dict={img:read_data(sess)})\r\n            if epoch % 20 == 0:\r\n                save_path = saver.save(sess, MODEL_DIR + MODEL_NAME, global_step=epoch + 1)\r\n            print('step = ' + str(epoch))\r\n        save_to_pb(sess)\r\ntrain_model()\r\n```\r\n-------------------------\r\n\r\n#### run upper  code and get pb file, when you test pb file with python you maybe get a result like this:\r\n39.09046 45.927864 84.797905 45.952957 62.701195 68.00796 41.789146 80.99372 81.67459 81.2203....\r\n\r\n#### then run this command to create tflite file:\r\n```\r\nbazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/path/expert-graph.pb --output_file=/path/expert-graph.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shape=1,128,128,3 --input_array=img --output_array=out --inference_type=FLOAT --input_data_type=FLOAT --allow_custom_ops\r\n```\r\n\r\n#### you will get expert-graph.tflite,then use tflite file to android,will get result like this:\r\n49.392387\uff0c 42.290344\uff0c135.30707\uff0c 7.7764254 \uff0c 125.98051\uff0c79.317825 \uff0c157.29184 \uff0c107.58522 \uff0c 283.46997 \uff0c36.103508....\r\n\r\n#### Android and python have the same input data,but the result is different,if i remove BN and train, that's ok,but BN is very important,i can remove it ,i don't know how to solve it,this question has been around me for a long time,please help solve it, if don't use TF Lite, what should i do?Thanks\r\n------------------------\r\n\r\n### System information\r\nLinux Ubuntu 16.04:\r\nTensorFlow installed from source:\r\nTensorFlow version 1.8.0:\r\nPython version:3.6:\r\nBazel version 0.11.1:\r\nGCC/Compiler version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10) :\r\nCUDA/cuDNN 9.0/7.0.5:\r\nGPU 1060-6G:"}