{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23422", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23422/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23422/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23422/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23422", "id": 376295081, "node_id": "MDU6SXNzdWUzNzYyOTUwODE=", "number": 23422, "title": "a  confused problem about placeholder", "user": {"login": "sanlb", "id": 18899321, "node_id": "MDQ6VXNlcjE4ODk5MzIx", "avatar_url": "https://avatars0.githubusercontent.com/u/18899321?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sanlb", "html_url": "https://github.com/sanlb", "followers_url": "https://api.github.com/users/sanlb/followers", "following_url": "https://api.github.com/users/sanlb/following{/other_user}", "gists_url": "https://api.github.com/users/sanlb/gists{/gist_id}", "starred_url": "https://api.github.com/users/sanlb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sanlb/subscriptions", "organizations_url": "https://api.github.com/users/sanlb/orgs", "repos_url": "https://api.github.com/users/sanlb/repos", "events_url": "https://api.github.com/users/sanlb/events{/privacy}", "received_events_url": "https://api.github.com/users/sanlb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-11-01T08:14:15Z", "updated_at": "2018-11-23T18:37:26Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04</li>\n<li>TensorFlow installed from (source or binary):from pycharm(+anaconda)</li>\n<li>TensorFlow version (use command below):1.9</li>\n<li>Python version:3.6</li>\n<li>CUDA/cuDNN version:8.0/5.1</li>\n<li>GPU model and memory:1060/6g</li>\n</ul>\n<p>I want to  give values of lr and beta1 to adam with placeholder but there is an error'You must feed a value for placeholder tensor 'm' with dtype float'. it's confused because when i fix the beta1=0.5, the lr can deliver to the adam, once i want to deliver lr and beta1 to adam there will be error.</p>\n<p>`def build_training_pi_graph(x, y, ul_x, lr, unsup_weight, m):<br>\nglobal_step = tf.get_variable(<br>\nname=\"global_step\",<br>\nshape=[],<br>\ndtype=tf.float32,<br>\ninitializer=tf.constant_initializer(0.0),<br>\ntrainable=False,<br>\n)</p>\n<pre><code>z_label1 = PiModels.call(x)\nz_label2 = PiModels.call(x)\n\nz_unlabeled1 = PiModels.call(ul_x)\nz_unlabeled2 = PiModels.call(ul_x)\nwith tf.variable_scope(tf.get_variable_scope(), reuse=True):\n    ce = tf.losses.softmax_cross_entropy(z_label1, y)\n    ul_loss = tf.losses.mean_squared_error(z_label1, z_label2)\n    l_loss = tf.losses.mean_squared_error(z_unlabeled1, z_unlabeled2)\n    loss = ce + unsup_weight * (ul_loss + l_loss)\n\nopt = tf.train.AdamOptimizer(learning_rate=lr, beta1=m, beta2=0.999)\ntvars = tf.trainable_variables()\ngrads_and_vars = opt.compute_gradients(loss, tvars)\ntrain_op = opt.apply_gradients(grads_and_vars, global_step=global_step)\n\nreturn loss, train_op, global_step`\n</code></pre>\n<p>`def main():<br>\nwith tf.Graph().as_default() as g:</p>\n<pre><code>    with tf.device(\"/cpu:0\"):\n        train_labeled_iterator = inputs(batch_size=batch_size,\n                                train=True,\n                                validation=validation,\n                                shuffle=True, num_epochs=num_epochs+1000)\n        train_x, train_y, label_index = train_labeled_iterator.get_next()\n\n        train_unlabeled_iterator = unlabeled_inputs(batch_size=ul_batch_size,\n                                    validation=validation,\n                                     shuffle=True,num_epochs=num_epochs)\n        ul_x, _, unlabel_index = train_unlabeled_iterator.get_next()\n\n        validation_iterator = inputs(batch_size=eval_batch_size,\n                                                      train=True,\n                                                      validation=True,\n                                                      shuffle=True)\n        val_x, val_y, _ = validation_iterator.get_next()\n\n        itest_iterator = inputs(batch_size=eval_batch_size,\n                                                    train=False,\n                                                    validation=validation,\n                                                    shuffle=True)\n        test_x, test_y, _= itest_iterator.get_next()\n\n    with tf.device(device):\n        lr = tf.placeholder(tf.float32, shape=[], name='learning_rate')\n        unsupervised_weight = tf.placeholder(tf.float32, shape=[], name='unsupervised_weight')\n        m = tf.placeholder(tf.float32, shape=[], name='m')\n        with tf.variable_scope('CNN', reuse=tf.AUTO_REUSE):\n            loss, train_op, global_step = build_training_pi_graph(train_x, train_y, ul_x, lr, unsupervised_weight, m)\n\n        init_op = tf.global_variables_initializer()\n\n    with tf.Session().as_default() as sess:\n        sess.run(init_op)\n        for ep in range(num_epochs):\n\n            sum_loss = 0\n\n            feed_dict = {lr: 0.001, unsupervised_weight: 0.5, m: 0.5}\n\n            start = time.time()\n            for i in range(num_iter_per_epoch):\n                batch_loss, _, _ = sess.run([loss, train_op, global_step], feed_dict=feed_dict)\n                sum_loss += batch_loss\n            end = time.time()\n            print('epoch:', ep, 'epoch train loss:', sum_loss / num_iter_per_epoch, 'epoch train time:',\n                  end - start)\n</code></pre>\n<p>main()`</p>\n<p><strong>Other info / logs</strong><br>\nTraceback (most recent call last):<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1292, in _do_call<br>\nreturn fn(*args)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1277, in _run_fn<br>\noptions, feed_dict, fetch_list, target_list, run_metadata)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1367, in _call_tf_sessionrun<br>\nrun_metadata)<br>\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'm' with dtype float<br>\n[[{{node m}} = Placeholder<a href=\"\">dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"</a>]]</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 172, in <br>\nmain()<br>\nFile \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 157, in main<br>\nsess.run(init_op)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 887, in run<br>\nrun_metadata_ptr)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1110, in _run<br>\nfeed_dict_tensor, options, run_metadata)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run<br>\nrun_metadata)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1308, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'm' with dtype float<br>\n[[{{node m}} = Placeholder<a href=\"\">dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"</a>]]</p>\n<p>Caused by op 'm', defined at:<br>\nFile \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 172, in <br>\nmain()<br>\nFile \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 146, in main<br>\nm = tf.placeholder(tf.float32, shape=[], name='m')<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1745, in placeholder<br>\nreturn gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5020, in placeholder<br>\n\"Placeholder\", dtype=dtype, shape=shape, name=name)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func<br>\nreturn func(*args, **kwargs)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op<br>\nop_def=op_def)<br>\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in <strong>init</strong><br>\nself._traceback = tf_stack.extract_stack()</p>\n<p>InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'm' with dtype float<br>\n[[{{node m}} = Placeholder<a href=\"\">dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"</a>]]</p>\n<p>any help, thanks</p>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\nTensorFlow installed from (source or binary):from pycharm(+anaconda)\nTensorFlow version (use command below):1.9\nPython version:3.6\nCUDA/cuDNN version:8.0/5.1\nGPU model and memory:1060/6g\n\nI want to  give values of lr and beta1 to adam with placeholder but there is an error'You must feed a value for placeholder tensor 'm' with dtype float'. it's confused because when i fix the beta1=0.5, the lr can deliver to the adam, once i want to deliver lr and beta1 to adam there will be error.\n`def build_training_pi_graph(x, y, ul_x, lr, unsup_weight, m):\nglobal_step = tf.get_variable(\nname=\"global_step\",\nshape=[],\ndtype=tf.float32,\ninitializer=tf.constant_initializer(0.0),\ntrainable=False,\n)\nz_label1 = PiModels.call(x)\nz_label2 = PiModels.call(x)\n\nz_unlabeled1 = PiModels.call(ul_x)\nz_unlabeled2 = PiModels.call(ul_x)\nwith tf.variable_scope(tf.get_variable_scope(), reuse=True):\n    ce = tf.losses.softmax_cross_entropy(z_label1, y)\n    ul_loss = tf.losses.mean_squared_error(z_label1, z_label2)\n    l_loss = tf.losses.mean_squared_error(z_unlabeled1, z_unlabeled2)\n    loss = ce + unsup_weight * (ul_loss + l_loss)\n\nopt = tf.train.AdamOptimizer(learning_rate=lr, beta1=m, beta2=0.999)\ntvars = tf.trainable_variables()\ngrads_and_vars = opt.compute_gradients(loss, tvars)\ntrain_op = opt.apply_gradients(grads_and_vars, global_step=global_step)\n\nreturn loss, train_op, global_step`\n\n`def main():\nwith tf.Graph().as_default() as g:\n    with tf.device(\"/cpu:0\"):\n        train_labeled_iterator = inputs(batch_size=batch_size,\n                                train=True,\n                                validation=validation,\n                                shuffle=True, num_epochs=num_epochs+1000)\n        train_x, train_y, label_index = train_labeled_iterator.get_next()\n\n        train_unlabeled_iterator = unlabeled_inputs(batch_size=ul_batch_size,\n                                    validation=validation,\n                                     shuffle=True,num_epochs=num_epochs)\n        ul_x, _, unlabel_index = train_unlabeled_iterator.get_next()\n\n        validation_iterator = inputs(batch_size=eval_batch_size,\n                                                      train=True,\n                                                      validation=True,\n                                                      shuffle=True)\n        val_x, val_y, _ = validation_iterator.get_next()\n\n        itest_iterator = inputs(batch_size=eval_batch_size,\n                                                    train=False,\n                                                    validation=validation,\n                                                    shuffle=True)\n        test_x, test_y, _= itest_iterator.get_next()\n\n    with tf.device(device):\n        lr = tf.placeholder(tf.float32, shape=[], name='learning_rate')\n        unsupervised_weight = tf.placeholder(tf.float32, shape=[], name='unsupervised_weight')\n        m = tf.placeholder(tf.float32, shape=[], name='m')\n        with tf.variable_scope('CNN', reuse=tf.AUTO_REUSE):\n            loss, train_op, global_step = build_training_pi_graph(train_x, train_y, ul_x, lr, unsupervised_weight, m)\n\n        init_op = tf.global_variables_initializer()\n\n    with tf.Session().as_default() as sess:\n        sess.run(init_op)\n        for ep in range(num_epochs):\n\n            sum_loss = 0\n\n            feed_dict = {lr: 0.001, unsupervised_weight: 0.5, m: 0.5}\n\n            start = time.time()\n            for i in range(num_iter_per_epoch):\n                batch_loss, _, _ = sess.run([loss, train_op, global_step], feed_dict=feed_dict)\n                sum_loss += batch_loss\n            end = time.time()\n            print('epoch:', ep, 'epoch train loss:', sum_loss / num_iter_per_epoch, 'epoch train time:',\n                  end - start)\n\nmain()`\nOther info / logs\nTraceback (most recent call last):\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1292, in _do_call\nreturn fn(*args)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1277, in _run_fn\noptions, feed_dict, fetch_list, target_list, run_metadata)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1367, in _call_tf_sessionrun\nrun_metadata)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'm' with dtype float\n[[{{node m}} = Placeholderdtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 172, in \nmain()\nFile \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 157, in main\nsess.run(init_op)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 887, in run\nrun_metadata_ptr)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\nfeed_dict_tensor, options, run_metadata)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\nrun_metadata)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1308, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'm' with dtype float\n[[{{node m}} = Placeholderdtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]]\nCaused by op 'm', defined at:\nFile \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 172, in \nmain()\nFile \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 146, in main\nm = tf.placeholder(tf.float32, shape=[], name='m')\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1745, in placeholder\nreturn gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5020, in placeholder\n\"Placeholder\", dtype=dtype, shape=shape, name=name)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\nreturn func(*args, **kwargs)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\nop_def=op_def)\nFile \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in init\nself._traceback = tf_stack.extract_stack()\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'm' with dtype float\n[[{{node m}} = Placeholderdtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]]\nany help, thanks", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):from pycharm(+anaconda)\r\n- TensorFlow version (use command below):1.9\r\n- Python version:3.6\r\n- CUDA/cuDNN version:8.0/5.1\r\n- GPU model and memory:1060/6g\r\n\r\n\r\nI want to  give values of lr and beta1 to adam with placeholder but there is an error'You must feed a value for placeholder tensor 'm' with dtype float'. it's confused because when i fix the beta1=0.5, the lr can deliver to the adam, once i want to deliver lr and beta1 to adam there will be error. \r\n\r\n`def build_training_pi_graph(x, y, ul_x, lr, unsup_weight, m):\r\n    global_step = tf.get_variable(\r\n        name=\"global_step\",\r\n        shape=[],\r\n        dtype=tf.float32,\r\n        initializer=tf.constant_initializer(0.0),\r\n        trainable=False,\r\n    )\r\n\r\n    z_label1 = PiModels.call(x)\r\n    z_label2 = PiModels.call(x)\r\n\r\n    z_unlabeled1 = PiModels.call(ul_x)\r\n    z_unlabeled2 = PiModels.call(ul_x)\r\n    with tf.variable_scope(tf.get_variable_scope(), reuse=True):\r\n        ce = tf.losses.softmax_cross_entropy(z_label1, y)\r\n        ul_loss = tf.losses.mean_squared_error(z_label1, z_label2)\r\n        l_loss = tf.losses.mean_squared_error(z_unlabeled1, z_unlabeled2)\r\n        loss = ce + unsup_weight * (ul_loss + l_loss)\r\n\r\n    opt = tf.train.AdamOptimizer(learning_rate=lr, beta1=m, beta2=0.999)\r\n    tvars = tf.trainable_variables()\r\n    grads_and_vars = opt.compute_gradients(loss, tvars)\r\n    train_op = opt.apply_gradients(grads_and_vars, global_step=global_step)\r\n\r\n    return loss, train_op, global_step`\r\n`def main():\r\n    with tf.Graph().as_default() as g:\r\n\r\n        with tf.device(\"/cpu:0\"):\r\n            train_labeled_iterator = inputs(batch_size=batch_size,\r\n                                    train=True,\r\n                                    validation=validation,\r\n                                    shuffle=True, num_epochs=num_epochs+1000)\r\n            train_x, train_y, label_index = train_labeled_iterator.get_next()\r\n\r\n            train_unlabeled_iterator = unlabeled_inputs(batch_size=ul_batch_size,\r\n                                        validation=validation,\r\n                                         shuffle=True,num_epochs=num_epochs)\r\n            ul_x, _, unlabel_index = train_unlabeled_iterator.get_next()\r\n\r\n            validation_iterator = inputs(batch_size=eval_batch_size,\r\n                                                          train=True,\r\n                                                          validation=True,\r\n                                                          shuffle=True)\r\n            val_x, val_y, _ = validation_iterator.get_next()\r\n\r\n            itest_iterator = inputs(batch_size=eval_batch_size,\r\n                                                        train=False,\r\n                                                        validation=validation,\r\n                                                        shuffle=True)\r\n            test_x, test_y, _= itest_iterator.get_next()\r\n\r\n        with tf.device(device):\r\n            lr = tf.placeholder(tf.float32, shape=[], name='learning_rate')\r\n            unsupervised_weight = tf.placeholder(tf.float32, shape=[], name='unsupervised_weight')\r\n            m = tf.placeholder(tf.float32, shape=[], name='m')\r\n            with tf.variable_scope('CNN', reuse=tf.AUTO_REUSE):\r\n                loss, train_op, global_step = build_training_pi_graph(train_x, train_y, ul_x, lr, unsupervised_weight, m)\r\n\r\n            init_op = tf.global_variables_initializer()\r\n\r\n        with tf.Session().as_default() as sess:\r\n            sess.run(init_op)\r\n            for ep in range(num_epochs):\r\n\r\n                sum_loss = 0\r\n\r\n                feed_dict = {lr: 0.001, unsupervised_weight: 0.5, m: 0.5}\r\n\r\n                start = time.time()\r\n                for i in range(num_iter_per_epoch):\r\n                    batch_loss, _, _ = sess.run([loss, train_op, global_step], feed_dict=feed_dict)\r\n                    sum_loss += batch_loss\r\n                end = time.time()\r\n                print('epoch:', ep, 'epoch train loss:', sum_loss / num_iter_per_epoch, 'epoch train time:',\r\n                      end - start)\r\n\r\nmain()`\r\n\r\n**Other info / logs**\r\nTraceback (most recent call last):\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1277, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1367, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'm' with dtype float\r\n\t [[{{node m}} = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 172, in <module>\r\n    main()\r\n  File \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 157, in main\r\n    sess.run(init_op)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'm' with dtype float\r\n\t [[{{node m}} = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nCaused by op 'm', defined at:\r\n  File \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 172, in <module>\r\n    main()\r\n  File \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 146, in main\r\n    m = tf.placeholder(tf.float32, shape=[], name='m')\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1745, in placeholder\r\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5020, in placeholder\r\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'm' with dtype float\r\n\t [[{{node m}} = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nany help, thanks"}