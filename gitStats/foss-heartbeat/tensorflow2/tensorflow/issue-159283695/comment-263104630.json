{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263104630", "html_url": "https://github.com/tensorflow/tensorflow/issues/2740#issuecomment-263104630", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2740", "id": 263104630, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MzEwNDYzMA==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-27T06:16:25Z", "updated_at": "2016-11-27T06:18:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>On latest tensorflow, the <code>with tf.name_scope(None)</code> hack still introduces variables with duplicated scope name:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">f</span>():\n    v <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>W<span class=\"pl-pds\">'</span></span>, [<span class=\"pl-c1\">1</span>])\n    v <span class=\"pl-k\">=</span> v <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-c1\">None</span>):\n        ema <span class=\"pl-k\">=</span> tf.train.ExponentialMovingAverage(<span class=\"pl-v\">decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.9</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>EMA<span class=\"pl-pds\">'</span></span>)\n        emaop <span class=\"pl-k\">=</span> ema.apply([v])\n        average_v <span class=\"pl-k\">=</span> ema.average(v)\n\n<span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>scope<span class=\"pl-pds\">'</span></span>):\n    f()\n<span class=\"pl-c1\">print</span>([k.name <span class=\"pl-k\">for</span> k <span class=\"pl-k\">in</span> tf.global_variables()])</pre></div>\n<p>will print:</p>\n<pre><code>[u'scope/W:0', u'scope/add/EMA:0', u'scope/scope/add/EMA/biased:0', \nu'scope/scope/add/EMA/local_step:0']\n</code></pre>", "body_text": "On latest tensorflow, the with tf.name_scope(None) hack still introduces variables with duplicated scope name:\ndef f():\n    v = tf.get_variable('W', [1])\n    v = v + 1\n    with tf.name_scope(None):\n        ema = tf.train.ExponentialMovingAverage(decay=0.9, name='EMA')\n        emaop = ema.apply([v])\n        average_v = ema.average(v)\n\nwith tf.variable_scope('scope'):\n    f()\nprint([k.name for k in tf.global_variables()])\nwill print:\n[u'scope/W:0', u'scope/add/EMA:0', u'scope/scope/add/EMA/biased:0', \nu'scope/scope/add/EMA/local_step:0']", "body": "On latest tensorflow, the `with tf.name_scope(None)` hack still introduces variables with duplicated scope name:\r\n```python\r\ndef f():\r\n    v = tf.get_variable('W', [1])\r\n    v = v + 1\r\n    with tf.name_scope(None):\r\n        ema = tf.train.ExponentialMovingAverage(decay=0.9, name='EMA')\r\n        emaop = ema.apply([v])\r\n        average_v = ema.average(v)\r\n\r\nwith tf.variable_scope('scope'):\r\n    f()\r\nprint([k.name for k in tf.global_variables()])\r\n```\r\nwill print:\r\n```\r\n[u'scope/W:0', u'scope/add/EMA:0', u'scope/scope/add/EMA/biased:0', \r\nu'scope/scope/add/EMA/local_step:0']\r\n```"}