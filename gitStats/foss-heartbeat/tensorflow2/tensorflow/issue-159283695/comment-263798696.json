{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263798696", "html_url": "https://github.com/tensorflow/tensorflow/issues/2740#issuecomment-263798696", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2740", "id": 263798696, "node_id": "MDEyOklzc3VlQ29tbWVudDI2Mzc5ODY5Ng==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-30T07:00:23Z", "updated_at": "2016-11-30T07:06:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The recently-introduced new variables in EMA also brings error when using with reuse=True.<br>\nThe example below seems like a common pattern in batch normalization. It works before, but now:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">f</span>(<span class=\"pl-smi\">v</span>):\n    ema <span class=\"pl-k\">=</span> tf.train.ExponentialMovingAverage(<span class=\"pl-c1\">0.9</span>)\n    vema <span class=\"pl-k\">=</span> ema.apply([v])\n    <span class=\"pl-k\">return</span> vema\n\n<span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>s<span class=\"pl-pds\">'</span></span>):\n    v1 <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>W<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[])\n    v1 <span class=\"pl-k\">=</span> v1 <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n    f(v1)\n<span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>s<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>):\n    v2 <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>W<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[])\n    v2 <span class=\"pl-k\">=</span> v2 <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n    f(v2)</pre></div>\n<pre><code>ValueError: Variable s/s_1/s_1/add/ExponentialMovingAverage/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\n</code></pre>", "body_text": "The recently-introduced new variables in EMA also brings error when using with reuse=True.\nThe example below seems like a common pattern in batch normalization. It works before, but now:\ndef f(v):\n    ema = tf.train.ExponentialMovingAverage(0.9)\n    vema = ema.apply([v])\n    return vema\n\nwith tf.variable_scope('s'):\n    v1 = tf.get_variable('W', shape=[])\n    v1 = v1 + 1\n    f(v1)\nwith tf.variable_scope('s', reuse=True):\n    v2 = tf.get_variable('W', shape=[])\n    v2 = v2 + 1\n    f(v2)\nValueError: Variable s/s_1/s_1/add/ExponentialMovingAverage/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?", "body": "The recently-introduced new variables in EMA also brings error when using with reuse=True.\r\nThe example below seems like a common pattern in batch normalization. It works before, but now:\r\n```python\r\ndef f(v):\r\n    ema = tf.train.ExponentialMovingAverage(0.9)\r\n    vema = ema.apply([v])\r\n    return vema\r\n\r\nwith tf.variable_scope('s'):\r\n    v1 = tf.get_variable('W', shape=[])\r\n    v1 = v1 + 1\r\n    f(v1)\r\nwith tf.variable_scope('s', reuse=True):\r\n    v2 = tf.get_variable('W', shape=[])\r\n    v2 = v2 + 1\r\n    f(v2)\r\n```\r\n```\r\nValueError: Variable s/s_1/s_1/add/ExponentialMovingAverage/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\r\n```"}