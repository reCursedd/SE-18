{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/416217528", "html_url": "https://github.com/tensorflow/tensorflow/issues/9832#issuecomment-416217528", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9832", "id": 416217528, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNjIxNzUyOA==", "user": {"login": "weiwancheng", "id": 13504420, "node_id": "MDQ6VXNlcjEzNTA0NDIw", "avatar_url": "https://avatars0.githubusercontent.com/u/13504420?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiwancheng", "html_url": "https://github.com/weiwancheng", "followers_url": "https://api.github.com/users/weiwancheng/followers", "following_url": "https://api.github.com/users/weiwancheng/following{/other_user}", "gists_url": "https://api.github.com/users/weiwancheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiwancheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiwancheng/subscriptions", "organizations_url": "https://api.github.com/users/weiwancheng/orgs", "repos_url": "https://api.github.com/users/weiwancheng/repos", "events_url": "https://api.github.com/users/weiwancheng/events{/privacy}", "received_events_url": "https://api.github.com/users/weiwancheng/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-27T12:57:31Z", "updated_at": "2018-08-27T12:57:31Z", "author_association": "NONE", "body_html": "<p>it seems that beam search not end with the symbol, because I have some the same sentence with beam search. I set the end_token, but it seems not work.<br>\nI used this api:</p>\n<pre><code>inference_decoder = BeamSearchDecoder(\ncell=self.decoder_cell,\nembedding=embed_and_input_proj,\nstart_tokens=start_tokens,\nend_token=end_token,\ninitial_state=self.decoder_initial_state,\nbeam_width=self.beam_width,\noutput_layer=self.decoder_output_projection,\n)\n\n self.decoder_outputs_decode,_ ,_= (seq2seq.dynamic_decode\n(\n                    decoder=inference_decoder,\n                    output_time_major=self.time_major,\n                    maximum_iterations=max_decode_step,\n                    swap_memory=True,\n                    scope=decoder_scope ))\n</code></pre>\n<p>The results are as follows:<br>\nsentence1\uff1a.....eos unk unk unk unk unk<br>\nsentence2\uff1a.....eos eos unk unk unk<br>\nsentence3\uff1a.....eos eos unk unk unk<br>\nsentence4\uff1a....eos eos unk unk unk<br>\nsentence5 ....eos eos eos eos eos unk unk unk<br>\nabove, sentence4 is same as sentence5.</p>\n<p>this problem worried me, who can help me? thanks.</p>", "body_text": "it seems that beam search not end with the symbol, because I have some the same sentence with beam search. I set the end_token, but it seems not work.\nI used this api:\ninference_decoder = BeamSearchDecoder(\ncell=self.decoder_cell,\nembedding=embed_and_input_proj,\nstart_tokens=start_tokens,\nend_token=end_token,\ninitial_state=self.decoder_initial_state,\nbeam_width=self.beam_width,\noutput_layer=self.decoder_output_projection,\n)\n\n self.decoder_outputs_decode,_ ,_= (seq2seq.dynamic_decode\n(\n                    decoder=inference_decoder,\n                    output_time_major=self.time_major,\n                    maximum_iterations=max_decode_step,\n                    swap_memory=True,\n                    scope=decoder_scope ))\n\nThe results are as follows:\nsentence1\uff1a.....eos unk unk unk unk unk\nsentence2\uff1a.....eos eos unk unk unk\nsentence3\uff1a.....eos eos unk unk unk\nsentence4\uff1a....eos eos unk unk unk\nsentence5 ....eos eos eos eos eos unk unk unk\nabove, sentence4 is same as sentence5.\nthis problem worried me, who can help me? thanks.", "body": "it seems that beam search not end with the symbol, because I have some the same sentence with beam search. I set the end_token, but it seems not work.\r\nI used this api:\r\n```\r\ninference_decoder = BeamSearchDecoder(\r\ncell=self.decoder_cell,\r\nembedding=embed_and_input_proj,\r\nstart_tokens=start_tokens,\r\nend_token=end_token,\r\ninitial_state=self.decoder_initial_state,\r\nbeam_width=self.beam_width,\r\noutput_layer=self.decoder_output_projection,\r\n)\r\n\r\n self.decoder_outputs_decode,_ ,_= (seq2seq.dynamic_decode\r\n(\r\n                    decoder=inference_decoder,\r\n                    output_time_major=self.time_major,\r\n                    maximum_iterations=max_decode_step,\r\n                    swap_memory=True,\r\n                    scope=decoder_scope ))\r\n```\r\nThe results are as follows:\r\nsentence1\uff1a.....eos unk unk unk unk unk\r\nsentence2\uff1a.....eos eos unk unk unk\r\nsentence3\uff1a.....eos eos unk unk unk\r\nsentence4\uff1a....eos eos unk unk unk\r\nsentence5 ....eos eos eos eos eos unk unk unk\r\nabove, sentence4 is same as sentence5. \r\n\r\nthis problem worried me, who can help me? thanks."}