{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/334327961", "html_url": "https://github.com/tensorflow/tensorflow/issues/9832#issuecomment-334327961", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9832", "id": 334327961, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDMyNzk2MQ==", "user": {"login": "untrix", "id": 1545368, "node_id": "MDQ6VXNlcjE1NDUzNjg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1545368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/untrix", "html_url": "https://github.com/untrix", "followers_url": "https://api.github.com/users/untrix/followers", "following_url": "https://api.github.com/users/untrix/following{/other_user}", "gists_url": "https://api.github.com/users/untrix/gists{/gist_id}", "starred_url": "https://api.github.com/users/untrix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/untrix/subscriptions", "organizations_url": "https://api.github.com/users/untrix/orgs", "repos_url": "https://api.github.com/users/untrix/repos", "events_url": "https://api.github.com/users/untrix/events{/privacy}", "received_events_url": "https://api.github.com/users/untrix/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-05T00:39:27Z", "updated_at": "2017-10-05T00:41:58Z", "author_association": "NONE", "body_html": "<p>Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> ! I see the documentation in the master branch on github but the text hasn't yet shown up in the online documentation yet (for master branch). I hope it will show up soon. Just one additional point regarding the following text in the doc-string:<br>\n<code>   - The initial state created with</code>zero_state<code>above contains a</code>cell_state<code> value containing properly tiled final state from the encoder.</code><br>\nIt is not always the case that the decoder-initial-state is equal to the encoder-final-state, hence it probably makes sense to add the following type of clarification:<br>\n<code>Ensure that the decoder-initial-state is tiled to size batch_size*beam_width using @{tf.contrib.seq2seq.tile_batch} (NOT tf.tile).</code> If one were using zero-state to create the decoder-initial-state then the current doc-string is complete, however that's not true in every case.<br>\nFor e.g. in my case for e.g. the encoder is a CNN - not an RNN - and the decoder-init-state is generated by a dedicated MLP (as in <a href=\"https://arxiv.org/abs/1502.03044\" rel=\"nofollow\">this</a> paper) - not final state of an encoder.</p>\n<p>Best</p>", "body_text": "Thanks @ebrevdo ! I see the documentation in the master branch on github but the text hasn't yet shown up in the online documentation yet (for master branch). I hope it will show up soon. Just one additional point regarding the following text in the doc-string:\n   - The initial state created withzero_stateabove contains acell_state value containing properly tiled final state from the encoder.\nIt is not always the case that the decoder-initial-state is equal to the encoder-final-state, hence it probably makes sense to add the following type of clarification:\nEnsure that the decoder-initial-state is tiled to size batch_size*beam_width using @{tf.contrib.seq2seq.tile_batch} (NOT tf.tile). If one were using zero-state to create the decoder-initial-state then the current doc-string is complete, however that's not true in every case.\nFor e.g. in my case for e.g. the encoder is a CNN - not an RNN - and the decoder-init-state is generated by a dedicated MLP (as in this paper) - not final state of an encoder.\nBest", "body": "Thanks @ebrevdo ! I see the documentation in the master branch on github but the text hasn't yet shown up in the online documentation yet (for master branch). I hope it will show up soon. Just one additional point regarding the following text in the doc-string:\r\n`    - The initial state created with `zero_state` above contains a\r\n      `cell_state` value containing properly tiled final state from the\r\n      encoder.`\r\nIt is not always the case that the decoder-initial-state is equal to the encoder-final-state, hence it probably makes sense to add the following type of clarification: \r\n`Ensure that the decoder-initial-state is tiled to size batch_size*beam_width using @{tf.contrib.seq2seq.tile_batch} (NOT tf.tile).` If one were using zero-state to create the decoder-initial-state then the current doc-string is complete, however that's not true in every case.\r\nFor e.g. in my case for e.g. the encoder is a CNN - not an RNN - and the decoder-init-state is generated by a dedicated MLP (as in [this](https://arxiv.org/abs/1502.03044) paper) - not final state of an encoder.\r\n\r\nBest"}