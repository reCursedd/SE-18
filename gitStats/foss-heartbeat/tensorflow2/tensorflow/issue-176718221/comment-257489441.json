{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257489441", "html_url": "https://github.com/tensorflow/tensorflow/issues/4361#issuecomment-257489441", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4361", "id": 257489441, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NzQ4OTQ0MQ==", "user": {"login": "wookayin", "id": 1009873, "node_id": "MDQ6VXNlcjEwMDk4NzM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1009873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wookayin", "html_url": "https://github.com/wookayin", "followers_url": "https://api.github.com/users/wookayin/followers", "following_url": "https://api.github.com/users/wookayin/following{/other_user}", "gists_url": "https://api.github.com/users/wookayin/gists{/gist_id}", "starred_url": "https://api.github.com/users/wookayin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wookayin/subscriptions", "organizations_url": "https://api.github.com/users/wookayin/orgs", "repos_url": "https://api.github.com/users/wookayin/repos", "events_url": "https://api.github.com/users/wookayin/events{/privacy}", "received_events_url": "https://api.github.com/users/wookayin/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-01T05:03:25Z", "updated_at": "2016-11-01T05:03:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>For (2), I agree with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2537736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bsautermeister\">@bsautermeister</a> because as I believe adding dependences on <code>train_op</code> looks sound. For some reasons, one may compute loss value (i.e. forward-prop) for validation datapoints; but with dependences on <code>loss</code> batch-normalization statistics are also taken from validation set.</p>\n<p>For (3), do we need to share the BN parameters for <code>bn_train</code> and <code>bn_inference</code>? (in the original code different BN variables like beta, gamma are present for those two)</p>\n<div class=\"highlight highlight-source-diff\"><pre> def batch_norm_layer(x, train_phase, scope_bn):\n   bn_train = batch_norm(x, decay=0.999, center=True, scale=True,\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>  updates_collections=None, is_training=True)</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>  updates_collections=None, is_training=True, scope=scope_bn)</span>\n   bn_inference = batch_norm(x, decay=0.999, center=True, scale=True,\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>  updates_collections=None, is_training=False)</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>  updates_collections=None, is_training=False, scope=scope_bn, reuse=True)</span>\n   bn = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\n   return bn</pre></div>\n<p>NOTE: I simply ignored the invalid moving average/variance update in the code for simplicity.</p>", "body_text": "For (2), I agree with @bsautermeister because as I believe adding dependences on train_op looks sound. For some reasons, one may compute loss value (i.e. forward-prop) for validation datapoints; but with dependences on loss batch-normalization statistics are also taken from validation set.\nFor (3), do we need to share the BN parameters for bn_train and bn_inference? (in the original code different BN variables like beta, gamma are present for those two)\n def batch_norm_layer(x, train_phase, scope_bn):\n   bn_train = batch_norm(x, decay=0.999, center=True, scale=True,\n-  updates_collections=None, is_training=True)\n+  updates_collections=None, is_training=True, scope=scope_bn)\n   bn_inference = batch_norm(x, decay=0.999, center=True, scale=True,\n-  updates_collections=None, is_training=False)\n+  updates_collections=None, is_training=False, scope=scope_bn, reuse=True)\n   bn = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\n   return bn\nNOTE: I simply ignored the invalid moving average/variance update in the code for simplicity.", "body": "For (2), I agree with @bsautermeister because as I believe adding dependences on `train_op` looks sound. For some reasons, one may compute loss value (i.e. forward-prop) for validation datapoints; but with dependences on `loss` batch-normalization statistics are also taken from validation set.\n\nFor (3), do we need to share the BN parameters for `bn_train` and `bn_inference`? (in the original code different BN variables like beta, gamma are present for those two)\n\n``` diff\n def batch_norm_layer(x, train_phase, scope_bn):\n   bn_train = batch_norm(x, decay=0.999, center=True, scale=True,\n-  updates_collections=None, is_training=True)\n+  updates_collections=None, is_training=True, scope=scope_bn)\n   bn_inference = batch_norm(x, decay=0.999, center=True, scale=True,\n-  updates_collections=None, is_training=False)\n+  updates_collections=None, is_training=False, scope=scope_bn, reuse=True)\n   bn = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\n   return bn\n```\n\nNOTE: I simply ignored the invalid moving average/variance update in the code for simplicity.\n"}