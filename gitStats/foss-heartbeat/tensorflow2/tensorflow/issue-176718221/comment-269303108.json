{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269303108", "html_url": "https://github.com/tensorflow/tensorflow/issues/4361#issuecomment-269303108", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4361", "id": 269303108, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTMwMzEwOA==", "user": {"login": "RuiShu", "id": 7140902, "node_id": "MDQ6VXNlcjcxNDA5MDI=", "avatar_url": "https://avatars1.githubusercontent.com/u/7140902?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RuiShu", "html_url": "https://github.com/RuiShu", "followers_url": "https://api.github.com/users/RuiShu/followers", "following_url": "https://api.github.com/users/RuiShu/following{/other_user}", "gists_url": "https://api.github.com/users/RuiShu/gists{/gist_id}", "starred_url": "https://api.github.com/users/RuiShu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RuiShu/subscriptions", "organizations_url": "https://api.github.com/users/RuiShu/orgs", "repos_url": "https://api.github.com/users/RuiShu/repos", "events_url": "https://api.github.com/users/RuiShu/events{/privacy}", "received_events_url": "https://api.github.com/users/RuiShu/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-27T09:51:03Z", "updated_at": "2016-12-27T09:52:37Z", "author_association": "NONE", "body_html": "<p>I noticed that the docs haven't been updated yet. Would it be useful if the docs instead said:</p>\n<div class=\"highlight highlight-source-python\"><pre>update_ops <span class=\"pl-k\">=</span> tf.get_collection(tf.GraphKeys.<span class=\"pl-c1\">UPDATE_OPS</span>)\n<span class=\"pl-k\">with</span> tf.control_dependencies(update_ops):\n    train_step <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">0.01</span>).minimize(total_loss)</pre></div>\n<p>As for proper reuse across multiple data streams, it looks like a shareable version is still <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/normalization.py#L200\">in the works</a>.</p>\n<p>As an aside, to the best of my understanding, the notion of a shareable BN layer should be treated with some care. Depending on the use-case, I think there should be an option to distinguish sharing of the moving averages from the sharing of the beta/gamma parameters <a href=\"https://arxiv.org/pdf/1603.09025v4.pdf\" rel=\"nofollow\">as noted here</a>.</p>", "body_text": "I noticed that the docs haven't been updated yet. Would it be useful if the docs instead said:\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nwith tf.control_dependencies(update_ops):\n    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(total_loss)\nAs for proper reuse across multiple data streams, it looks like a shareable version is still in the works.\nAs an aside, to the best of my understanding, the notion of a shareable BN layer should be treated with some care. Depending on the use-case, I think there should be an option to distinguish sharing of the moving averages from the sharing of the beta/gamma parameters as noted here.", "body": "I noticed that the docs haven't been updated yet. Would it be useful if the docs instead said:\r\n```python\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(total_loss)\r\n```\r\n\r\nAs for proper reuse across multiple data streams, it looks like a shareable version is still [in the works](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/normalization.py#L200). \r\n\r\nAs an aside, to the best of my understanding, the notion of a shareable BN layer should be treated with some care. Depending on the use-case, I think there should be an option to distinguish sharing of the moving averages from the sharing of the beta/gamma parameters [as noted here](https://arxiv.org/pdf/1603.09025v4.pdf)."}