{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/396115670", "html_url": "https://github.com/tensorflow/tensorflow/issues/18102#issuecomment-396115670", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18102", "id": 396115670, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjExNTY3MA==", "user": {"login": "droidicus", "id": 6981482, "node_id": "MDQ6VXNlcjY5ODE0ODI=", "avatar_url": "https://avatars2.githubusercontent.com/u/6981482?v=4", "gravatar_id": "", "url": "https://api.github.com/users/droidicus", "html_url": "https://github.com/droidicus", "followers_url": "https://api.github.com/users/droidicus/followers", "following_url": "https://api.github.com/users/droidicus/following{/other_user}", "gists_url": "https://api.github.com/users/droidicus/gists{/gist_id}", "starred_url": "https://api.github.com/users/droidicus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/droidicus/subscriptions", "organizations_url": "https://api.github.com/users/droidicus/orgs", "repos_url": "https://api.github.com/users/droidicus/repos", "events_url": "https://api.github.com/users/droidicus/events{/privacy}", "received_events_url": "https://api.github.com/users/droidicus/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-11T03:54:42Z", "updated_at": "2018-06-11T03:54:42Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=607207\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rjpower\">@rjpower</a> I understand the need for all tensors in the XLA compiled graph to have static shapes, and in this case all tensors do have static shapes.</p>\n<p>For instance, printing the dataset before calling the make_one_shot_iterator:<br>\n<code>&lt;_RestructuredDataset shapes: ((1024, 10, 10), (1024, 10)), types: (tf.float32, tf.float32)&gt;</code></p>\n<p>The 'features' tensor prior to the LSTM layer:<br>\n<code>Tensor(\"InfeedQueue/dequeue:0\", shape=(128, 10, 10), dtype=float32, device=/device:TPU_REPLICATED_CORE:0)</code></p>\n<p>And the 'predictions' tensor  after the LSTM layer:<br>\n<code>Tensor(\"lstm/TensorArrayReadV3:0\", shape=(128, 10), dtype=float32)</code></p>\n<p>That being said, it looks like the changes in TF 1.9 will work for this use-case as well.</p>", "body_text": "@rjpower I understand the need for all tensors in the XLA compiled graph to have static shapes, and in this case all tensors do have static shapes.\nFor instance, printing the dataset before calling the make_one_shot_iterator:\n<_RestructuredDataset shapes: ((1024, 10, 10), (1024, 10)), types: (tf.float32, tf.float32)>\nThe 'features' tensor prior to the LSTM layer:\nTensor(\"InfeedQueue/dequeue:0\", shape=(128, 10, 10), dtype=float32, device=/device:TPU_REPLICATED_CORE:0)\nAnd the 'predictions' tensor  after the LSTM layer:\nTensor(\"lstm/TensorArrayReadV3:0\", shape=(128, 10), dtype=float32)\nThat being said, it looks like the changes in TF 1.9 will work for this use-case as well.", "body": "@rjpower I understand the need for all tensors in the XLA compiled graph to have static shapes, and in this case all tensors do have static shapes.\r\n\r\nFor instance, printing the dataset before calling the make_one_shot_iterator:\r\n``` <_RestructuredDataset shapes: ((1024, 10, 10), (1024, 10)), types: (tf.float32, tf.float32)> ```\r\n\r\nThe 'features' tensor prior to the LSTM layer:\r\n``` Tensor(\"InfeedQueue/dequeue:0\", shape=(128, 10, 10), dtype=float32, device=/device:TPU_REPLICATED_CORE:0) ```\r\n\r\nAnd the 'predictions' tensor  after the LSTM layer:\r\n``` Tensor(\"lstm/TensorArrayReadV3:0\", shape=(128, 10), dtype=float32) ```\r\n\r\nThat being said, it looks like the changes in TF 1.9 will work for this use-case as well."}