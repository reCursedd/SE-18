{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23126", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23126/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23126/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23126/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23126", "id": 372196092, "node_id": "MDU6SXNzdWUzNzIxOTYwOTI=", "number": 23126, "title": "Tensorflow - Disaccording TF METRICS (Accuracy, Precision, Recall)", "user": {"login": "lucadigiammarino", "id": 16779908, "node_id": "MDQ6VXNlcjE2Nzc5OTA4", "avatar_url": "https://avatars1.githubusercontent.com/u/16779908?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucadigiammarino", "html_url": "https://github.com/lucadigiammarino", "followers_url": "https://api.github.com/users/lucadigiammarino/followers", "following_url": "https://api.github.com/users/lucadigiammarino/following{/other_user}", "gists_url": "https://api.github.com/users/lucadigiammarino/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucadigiammarino/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucadigiammarino/subscriptions", "organizations_url": "https://api.github.com/users/lucadigiammarino/orgs", "repos_url": "https://api.github.com/users/lucadigiammarino/repos", "events_url": "https://api.github.com/users/lucadigiammarino/events{/privacy}", "received_events_url": "https://api.github.com/users/lucadigiammarino/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-10-20T10:10:50Z", "updated_at": "2018-11-06T18:56:30Z", "closed_at": "2018-11-06T18:39:55Z", "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.4</li>\n<li>TensorFlow installed from (source or binary): source</li>\n<li>TensorFlow version (use command below): 1.10.1</li>\n<li>Python version: 2.7</li>\n<li>GCC/Compiler version (if compiling from source): 5.4.0</li>\n<li>CUDA/cuDNN version: release 7.5</li>\n<li>GPU model and memory: Tesla K80 - 11.17GiB</li>\n<li>Bazel version: N/A</li>\n<li>Exact command to reproduce: N/A</li>\n<li>Mobile device: N/A</li>\n</ul>\n<p>I am working with a CNN for an instrument recognition problem, using <strong>IRMAS</strong> dataset.</p>\n<p>The <strong>IRMAS</strong> dataset has a clear <strong>training</strong> set, based only on singular instruments, therefore each instrument (guitar, violin, etc) has its own directory with multiple samples (<em>multi-classification</em>). The <strong>testing</strong> set, differently, contains polyphonic music, therefore multiple classes of instruments may appear in the same song (<em>multi-classification</em>, <em>multi-label</em>).</p>\n<p>This is the final part of my network with the prediction and loss calculation, I am using the <code>Estimator API</code>.</p>\n<pre><code>### previous part of network is omitted\n\n# logits layer\nlogits = tf.layers.dense(inputs=dropout, units=labels.shape[1])\n\nprint('Shape Logits:', logits.shape)\n   \n\npredictions = {\n    \"classes\": tf.argmax(input=logits, axis=1),\n    \"probabilities\": tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(labels, tf.float32), logits=tf.cast(logits, tf.float32), name=\"sigmoid_tensor\")\n}\n\nif mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\nloss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels, logits=logits)\n\nif mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n    #optimizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.96)\n    train_op = optimizer.minimize(\n                              loss=loss,\n                              global_step=tf.train.get_global_step())\n    logging_hook = tf.train.LoggingTensorHook({\"loss\" : loss}, every_n_iter=10)\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, training_hooks = [logging_hook])\n\neval_metric_ops = {\n    \"accuracy\": tf.metrics.accuracy(\n    labels=tf.argmax(input=labels, axis=1),\n    predictions=predictions[\"classes\"]),\n\n    \"recall\": tf.metrics.recall(\n    labels=tf.argmax(input=labels, axis=1),\n    predictions=predictions[\"classes\"]),\n\n    \"precision\": tf.metrics.precision(\n    labels=tf.argmax(input=labels, axis=1),\n    predictions=predictions[\"classes\"])\n}\n</code></pre>\n<p>After few epochs, the training process seems to work since the loss goes down quite smoothly. However, the tensorflow metrics needed to evaluate the model does not seem to agree.</p>\n<p>These are my results on the evaluation set (15% of the training set):</p>\n<p><code>{'recall': 0.9989496, 'accuracy': 0.40656063, 'global_step': 1428, 'precision': 0.95004994, 'loss': 0.2432195}</code></p>\n<p>These are the results obtained from the testing set:</p>\n<p><code>{'recall': 0.9981618, 'accuracy': 0.26530612, 'global_step': 1428, 'precision': 0.96533334, 'loss': 0.46097097}</code></p>\n<p>In my opinion, the accuracy value seems to be the only right, since decreases in the testing set, which is composed by polyphonic music rather than singular instruments. I don't understand why I get these results for precision and recall, they should be lower compared to the accuracy I get.</p>\n<p>I've tried to display the FP, FN, TN and TP and they seem to be in accord with precision and recall. In fact, by computing the accuracy with them I got around 0.97 (too high for this classification problem).</p>\n<p>My question is why the metrics of tensorflow are so in disaccord? I could not find any useful information in the documentation.</p>\n<p>Thank you in advance</p>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.4\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.10.1\nPython version: 2.7\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: release 7.5\nGPU model and memory: Tesla K80 - 11.17GiB\nBazel version: N/A\nExact command to reproduce: N/A\nMobile device: N/A\n\nI am working with a CNN for an instrument recognition problem, using IRMAS dataset.\nThe IRMAS dataset has a clear training set, based only on singular instruments, therefore each instrument (guitar, violin, etc) has its own directory with multiple samples (multi-classification). The testing set, differently, contains polyphonic music, therefore multiple classes of instruments may appear in the same song (multi-classification, multi-label).\nThis is the final part of my network with the prediction and loss calculation, I am using the Estimator API.\n### previous part of network is omitted\n\n# logits layer\nlogits = tf.layers.dense(inputs=dropout, units=labels.shape[1])\n\nprint('Shape Logits:', logits.shape)\n   \n\npredictions = {\n    \"classes\": tf.argmax(input=logits, axis=1),\n    \"probabilities\": tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(labels, tf.float32), logits=tf.cast(logits, tf.float32), name=\"sigmoid_tensor\")\n}\n\nif mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\nloss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels, logits=logits)\n\nif mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n    #optimizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.96)\n    train_op = optimizer.minimize(\n                              loss=loss,\n                              global_step=tf.train.get_global_step())\n    logging_hook = tf.train.LoggingTensorHook({\"loss\" : loss}, every_n_iter=10)\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, training_hooks = [logging_hook])\n\neval_metric_ops = {\n    \"accuracy\": tf.metrics.accuracy(\n    labels=tf.argmax(input=labels, axis=1),\n    predictions=predictions[\"classes\"]),\n\n    \"recall\": tf.metrics.recall(\n    labels=tf.argmax(input=labels, axis=1),\n    predictions=predictions[\"classes\"]),\n\n    \"precision\": tf.metrics.precision(\n    labels=tf.argmax(input=labels, axis=1),\n    predictions=predictions[\"classes\"])\n}\n\nAfter few epochs, the training process seems to work since the loss goes down quite smoothly. However, the tensorflow metrics needed to evaluate the model does not seem to agree.\nThese are my results on the evaluation set (15% of the training set):\n{'recall': 0.9989496, 'accuracy': 0.40656063, 'global_step': 1428, 'precision': 0.95004994, 'loss': 0.2432195}\nThese are the results obtained from the testing set:\n{'recall': 0.9981618, 'accuracy': 0.26530612, 'global_step': 1428, 'precision': 0.96533334, 'loss': 0.46097097}\nIn my opinion, the accuracy value seems to be the only right, since decreases in the testing set, which is composed by polyphonic music rather than singular instruments. I don't understand why I get these results for precision and recall, they should be lower compared to the accuracy I get.\nI've tried to display the FP, FN, TN and TP and they seem to be in accord with precision and recall. In fact, by computing the accuracy with them I got around 0.97 (too high for this classification problem).\nMy question is why the metrics of tensorflow are so in disaccord? I could not find any useful information in the documentation.\nThank you in advance", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.4\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.10.1\r\n- Python version: 2.7\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: release 7.5\r\n- GPU model and memory: Tesla K80 - 11.17GiB\r\n- Bazel version: N/A\r\n- Exact command to reproduce: N/A\r\n- Mobile device: N/A\r\n\r\nI am working with a CNN for an instrument recognition problem, using **IRMAS** dataset. \r\n\r\nThe **IRMAS** dataset has a clear **training** set, based only on singular instruments, therefore each instrument (guitar, violin, etc) has its own directory with multiple samples (*multi-classification*). The **testing** set, differently, contains polyphonic music, therefore multiple classes of instruments may appear in the same song (*multi-classification*, *multi-label*).\r\n\r\nThis is the final part of my network with the prediction and loss calculation, I am using the `Estimator API`.\r\n\r\n    \r\n\r\n    ### previous part of network is omitted\r\n    \r\n    # logits layer\r\n    logits = tf.layers.dense(inputs=dropout, units=labels.shape[1])\r\n\r\n    print('Shape Logits:', logits.shape)\r\n       \r\n   \r\n    predictions = {\r\n        \"classes\": tf.argmax(input=logits, axis=1),\r\n        \"probabilities\": tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(labels, tf.float32), logits=tf.cast(logits, tf.float32), name=\"sigmoid_tensor\")\r\n    }\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels, logits=logits)\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n        #optimizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.96)\r\n        train_op = optimizer.minimize(\r\n                                  loss=loss,\r\n                                  global_step=tf.train.get_global_step())\r\n        logging_hook = tf.train.LoggingTensorHook({\"loss\" : loss}, every_n_iter=10)\r\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, training_hooks = [logging_hook])\r\n\r\n    eval_metric_ops = {\r\n        \"accuracy\": tf.metrics.accuracy(\r\n        labels=tf.argmax(input=labels, axis=1),\r\n        predictions=predictions[\"classes\"]),\r\n\r\n        \"recall\": tf.metrics.recall(\r\n        labels=tf.argmax(input=labels, axis=1),\r\n        predictions=predictions[\"classes\"]),\r\n\r\n        \"precision\": tf.metrics.precision(\r\n        labels=tf.argmax(input=labels, axis=1),\r\n        predictions=predictions[\"classes\"])\r\n    }\r\n\r\n\r\nAfter few epochs, the training process seems to work since the loss goes down quite smoothly. However, the tensorflow metrics needed to evaluate the model does not seem to agree.\r\n\r\nThese are my results on the evaluation set (15% of the training set):\r\n\r\n`{'recall': 0.9989496, 'accuracy': 0.40656063, 'global_step': 1428, 'precision': 0.95004994, 'loss': 0.2432195}`\r\n\r\nThese are the results obtained from the testing set:\r\n\r\n`{'recall': 0.9981618, 'accuracy': 0.26530612, 'global_step': 1428, 'precision': 0.96533334, 'loss': 0.46097097}`\r\n\r\nIn my opinion, the accuracy value seems to be the only right, since decreases in the testing set, which is composed by polyphonic music rather than singular instruments. I don't understand why I get these results for precision and recall, they should be lower compared to the accuracy I get. \r\n\r\nI've tried to display the FP, FN, TN and TP and they seem to be in accord with precision and recall. In fact, by computing the accuracy with them I got around 0.97 (too high for this classification problem).\r\n\r\nMy question is why the metrics of tensorflow are so in disaccord? I could not find any useful information in the documentation.\r\n\r\nThank you in advance\r\n"}