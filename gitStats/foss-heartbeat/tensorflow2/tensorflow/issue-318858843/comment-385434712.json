{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385434712", "html_url": "https://github.com/tensorflow/tensorflow/issues/18979#issuecomment-385434712", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18979", "id": 385434712, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTQzNDcxMg==", "user": {"login": "bjacob", "id": 79535, "node_id": "MDQ6VXNlcjc5NTM1", "avatar_url": "https://avatars1.githubusercontent.com/u/79535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjacob", "html_url": "https://github.com/bjacob", "followers_url": "https://api.github.com/users/bjacob/followers", "following_url": "https://api.github.com/users/bjacob/following{/other_user}", "gists_url": "https://api.github.com/users/bjacob/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjacob/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjacob/subscriptions", "organizations_url": "https://api.github.com/users/bjacob/orgs", "repos_url": "https://api.github.com/users/bjacob/repos", "events_url": "https://api.github.com/users/bjacob/events{/privacy}", "received_events_url": "https://api.github.com/users/bjacob/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-30T15:30:00Z", "updated_at": "2018-04-30T15:30:00Z", "author_association": "NONE", "body_html": "<p>The flag,</p>\n<p><code>--output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold</code></p>\n<p>is asking toco to cut this graph at this point, i.e. immediately after the Conv2D op, before the subsequent BiasAdd, ReLU6... and FakeQuantWithMinMaxVars.</p>\n<p>The resulting cropped graph thus does not have anymore the required min-max info for the output node.</p>\n<p>Passing arbitrary --input_arrays , --output_arrays to cut graphs is fine, as long as the required granularity of the graph is preserved. When quantizing (--inference_type=QUANTIZED_UINT8), that required granularity is whichever granularity FakeQuant nodes are inserted at, e.g. typically whole fused layers (Conv2D+BiasAdd+Relu6).</p>\n<p>Try this instead:</p>\n<pre><code>--output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/act_quant/FakeQuantWithMinMaxVars\n</code></pre>", "body_text": "The flag,\n--output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold\nis asking toco to cut this graph at this point, i.e. immediately after the Conv2D op, before the subsequent BiasAdd, ReLU6... and FakeQuantWithMinMaxVars.\nThe resulting cropped graph thus does not have anymore the required min-max info for the output node.\nPassing arbitrary --input_arrays , --output_arrays to cut graphs is fine, as long as the required granularity of the graph is preserved. When quantizing (--inference_type=QUANTIZED_UINT8), that required granularity is whichever granularity FakeQuant nodes are inserted at, e.g. typically whole fused layers (Conv2D+BiasAdd+Relu6).\nTry this instead:\n--output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/act_quant/FakeQuantWithMinMaxVars", "body": "The flag,\r\n\r\n```--output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold```\r\n\r\nis asking toco to cut this graph at this point, i.e. immediately after the Conv2D op, before the subsequent BiasAdd, ReLU6... and FakeQuantWithMinMaxVars.\r\n\r\nThe resulting cropped graph thus does not have anymore the required min-max info for the output node.\r\n\r\nPassing arbitrary --input_arrays , --output_arrays to cut graphs is fine, as long as the required granularity of the graph is preserved. When quantizing (--inference_type=QUANTIZED_UINT8), that required granularity is whichever granularity FakeQuant nodes are inserted at, e.g. typically whole fused layers (Conv2D+BiasAdd+Relu6).\r\n\r\nTry this instead:\r\n\r\n```\r\n--output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/act_quant/FakeQuantWithMinMaxVars\r\n```"}