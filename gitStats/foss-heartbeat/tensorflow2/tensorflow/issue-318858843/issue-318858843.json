{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18979", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18979/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18979/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18979/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18979", "id": 318858843, "node_id": "MDU6SXNzdWUzMTg4NTg4NDM=", "number": 18979, "title": "TOCO converter requires min/max information for taking output from intermediate nodes?", "user": {"login": "liquidscience", "id": 8677795, "node_id": "MDQ6VXNlcjg2Nzc3OTU=", "avatar_url": "https://avatars3.githubusercontent.com/u/8677795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liquidscience", "html_url": "https://github.com/liquidscience", "followers_url": "https://api.github.com/users/liquidscience/followers", "following_url": "https://api.github.com/users/liquidscience/following{/other_user}", "gists_url": "https://api.github.com/users/liquidscience/gists{/gist_id}", "starred_url": "https://api.github.com/users/liquidscience/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liquidscience/subscriptions", "organizations_url": "https://api.github.com/users/liquidscience/orgs", "repos_url": "https://api.github.com/users/liquidscience/repos", "events_url": "https://api.github.com/users/liquidscience/events{/privacy}", "received_events_url": "https://api.github.com/users/liquidscience/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-04-30T11:24:48Z", "updated_at": "2018-05-30T17:53:27Z", "closed_at": "2018-05-30T17:53:27Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:No.</li>\n<li><strong>TensorFlow version (use command below)</strong>:v1.7.0-3-g024aecf414 1.7.0</li>\n<li><strong>Python version</strong>: 3.5.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>:N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:N/A</li>\n<li><strong>CUDA/cuDNN version</strong>:9.0</li>\n<li><strong>GPU model and memory</strong>:Nvidia 840M</li>\n<li><strong>Exact command to reproduce</strong>:N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I have a quantized mobilenet downloaded from the official repository(<a href=\"https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md\">here</a>) , I want to collect output from the last pointwise convolutional layer of the network and run on a mobile.</p>\n<p>The quantized frozen model contains additional fc,softmax etc layers that are of no use for my application.</p>\n<p>To convert my quantized and frozen graph to specified input &amp; output i run the below command</p>\n<pre><code>toco \\\n  --input_file=mobilenet_v1_1.0_224_quant_frozen.pb \\\n  --output_file=corrected_mobilenet_v1_1.0_224_frozen.tflite \\\n  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\n  --inference_type=QUANTIZED_UINT8 \\\n  --input_shape=\"1,224,224,3\" \\\n  --input_array=input \\\n  --output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold \\\n  --std_value=127.5 --mean_value=127.5\n</code></pre>\n<p>and receive the following output from the converter</p>\n<pre><code>WARNING:tensorflow:From /home/sam/.virtualenvs/tf6/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse the retry module or similar alternatives.\n2018-04-30 16:31:24.735099: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 598 operators, 889 arrays (0 quantized)\n2018-04-30 16:31:24.753483: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 571 operators, 851 arrays (0 quantized)\n2018-04-30 16:31:24.773414: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 571 operators, 851 arrays (0 quantized)\n2018-04-30 16:31:25.122835: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 54 operators, 109 arrays (1 quantized)\n2018-04-30 16:31:25.123855: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 54 operators, 109 arrays (1 quantized)\n2018-04-30 16:31:25.124206: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 28 operators, 83 arrays (1 quantized)\n2018-04-30 16:31:25.124569: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 28 operators, 83 arrays (1 quantized)\n2018-04-30 16:31:25.155063: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:169] Array MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold does not have MinMax information, and is not a constant array. Cannot proceed with quantization.\nAborted (core dumped)\n</code></pre>\n<p>Why does this quantized graph requires min max information for intermediate nodes when it can resolve the final nodes correctly without additional min/max information?</p>\n<p>I also tried manually giving default min/max information but i suffer a huge performance drop if i do this.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\nTensorFlow installed from (source or binary):No.\nTensorFlow version (use command below):v1.7.0-3-g024aecf414 1.7.0\nPython version: 3.5.4\nBazel version (if compiling from source):N/A\nGCC/Compiler version (if compiling from source):N/A\nCUDA/cuDNN version:9.0\nGPU model and memory:Nvidia 840M\nExact command to reproduce:N/A\n\nDescribe the problem\nI have a quantized mobilenet downloaded from the official repository(here) , I want to collect output from the last pointwise convolutional layer of the network and run on a mobile.\nThe quantized frozen model contains additional fc,softmax etc layers that are of no use for my application.\nTo convert my quantized and frozen graph to specified input & output i run the below command\ntoco \\\n  --input_file=mobilenet_v1_1.0_224_quant_frozen.pb \\\n  --output_file=corrected_mobilenet_v1_1.0_224_frozen.tflite \\\n  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\n  --inference_type=QUANTIZED_UINT8 \\\n  --input_shape=\"1,224,224,3\" \\\n  --input_array=input \\\n  --output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold \\\n  --std_value=127.5 --mean_value=127.5\n\nand receive the following output from the converter\nWARNING:tensorflow:From /home/sam/.virtualenvs/tf6/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse the retry module or similar alternatives.\n2018-04-30 16:31:24.735099: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 598 operators, 889 arrays (0 quantized)\n2018-04-30 16:31:24.753483: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 571 operators, 851 arrays (0 quantized)\n2018-04-30 16:31:24.773414: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 571 operators, 851 arrays (0 quantized)\n2018-04-30 16:31:25.122835: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 54 operators, 109 arrays (1 quantized)\n2018-04-30 16:31:25.123855: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 54 operators, 109 arrays (1 quantized)\n2018-04-30 16:31:25.124206: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 28 operators, 83 arrays (1 quantized)\n2018-04-30 16:31:25.124569: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 28 operators, 83 arrays (1 quantized)\n2018-04-30 16:31:25.155063: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:169] Array MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold does not have MinMax information, and is not a constant array. Cannot proceed with quantization.\nAborted (core dumped)\n\nWhy does this quantized graph requires min max information for intermediate nodes when it can resolve the final nodes correctly without additional min/max information?\nI also tried manually giving default min/max information but i suffer a huge performance drop if i do this.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:No.\r\n- **TensorFlow version (use command below)**:v1.7.0-3-g024aecf414 1.7.0\r\n- **Python version**: 3.5.4\r\n- **Bazel version (if compiling from source)**:N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **CUDA/cuDNN version**:9.0\r\n- **GPU model and memory**:Nvidia 840M\r\n- **Exact command to reproduce**:N/A\r\n\r\n### Describe the problem\r\nI have a quantized mobilenet downloaded from the official repository([here](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md)) , I want to collect output from the last pointwise convolutional layer of the network and run on a mobile.\r\n\r\nThe quantized frozen model contains additional fc,softmax etc layers that are of no use for my application.\r\n\r\nTo convert my quantized and frozen graph to specified input & output i run the below command\r\n```\r\ntoco \\\r\n  --input_file=mobilenet_v1_1.0_224_quant_frozen.pb \\\r\n  --output_file=corrected_mobilenet_v1_1.0_224_frozen.tflite \\\r\n  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --input_shape=\"1,224,224,3\" \\\r\n  --input_array=input \\\r\n  --output_array=MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold \\\r\n  --std_value=127.5 --mean_value=127.5\r\n```\r\nand receive the following output from the converter\r\n```\r\nWARNING:tensorflow:From /home/sam/.virtualenvs/tf6/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\n2018-04-30 16:31:24.735099: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 598 operators, 889 arrays (0 quantized)\r\n2018-04-30 16:31:24.753483: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 571 operators, 851 arrays (0 quantized)\r\n2018-04-30 16:31:24.773414: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 571 operators, 851 arrays (0 quantized)\r\n2018-04-30 16:31:25.122835: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 54 operators, 109 arrays (1 quantized)\r\n2018-04-30 16:31:25.123855: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 54 operators, 109 arrays (1 quantized)\r\n2018-04-30 16:31:25.124206: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 28 operators, 83 arrays (1 quantized)\r\n2018-04-30 16:31:25.124569: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 28 operators, 83 arrays (1 quantized)\r\n2018-04-30 16:31:25.155063: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:169] Array MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_Fold does not have MinMax information, and is not a constant array. Cannot proceed with quantization.\r\nAborted (core dumped)\r\n```\r\n\r\nWhy does this quantized graph requires min max information for intermediate nodes when it can resolve the final nodes correctly without additional min/max information?\r\n\r\nI also tried manually giving default min/max information but i suffer a huge performance drop if i do this.\r\n\r\n\r\n\r\n\r\n"}