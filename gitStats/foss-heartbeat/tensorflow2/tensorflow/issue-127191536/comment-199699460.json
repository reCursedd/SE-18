{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/199699460", "html_url": "https://github.com/tensorflow/tensorflow/issues/800#issuecomment-199699460", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/800", "id": 199699460, "node_id": "MDEyOklzc3VlQ29tbWVudDE5OTY5OTQ2MA==", "user": {"login": "HellMood", "id": 7863989, "node_id": "MDQ6VXNlcjc4NjM5ODk=", "avatar_url": "https://avatars2.githubusercontent.com/u/7863989?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HellMood", "html_url": "https://github.com/HellMood", "followers_url": "https://api.github.com/users/HellMood/followers", "following_url": "https://api.github.com/users/HellMood/following{/other_user}", "gists_url": "https://api.github.com/users/HellMood/gists{/gist_id}", "starred_url": "https://api.github.com/users/HellMood/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HellMood/subscriptions", "organizations_url": "https://api.github.com/users/HellMood/orgs", "repos_url": "https://api.github.com/users/HellMood/repos", "events_url": "https://api.github.com/users/HellMood/events{/privacy}", "received_events_url": "https://api.github.com/users/HellMood/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-22T08:28:01Z", "updated_at": "2016-03-22T08:28:01Z", "author_association": "NONE", "body_html": "<p>I used the normal learning rates (and parameters) from the standard CIFAR10 models. My way of successfully combating this problem was actually kind of working around it : Since i work with very suspicious and paradox data (difficult and human labeled), sometimes, due to contradicting information, there is a sequence of learning examples generating very high errors. So i simply reduced the batch size to not stack these errors too high, and in case of failure (see above) i simply switched back to an \"OK\" model before that point.</p>\n<p>I'd suggest you check (evaluate) your models once before and then after the loss jump. Chances are high, that the model after the loss jump is unusable.</p>", "body_text": "I used the normal learning rates (and parameters) from the standard CIFAR10 models. My way of successfully combating this problem was actually kind of working around it : Since i work with very suspicious and paradox data (difficult and human labeled), sometimes, due to contradicting information, there is a sequence of learning examples generating very high errors. So i simply reduced the batch size to not stack these errors too high, and in case of failure (see above) i simply switched back to an \"OK\" model before that point.\nI'd suggest you check (evaluate) your models once before and then after the loss jump. Chances are high, that the model after the loss jump is unusable.", "body": "I used the normal learning rates (and parameters) from the standard CIFAR10 models. My way of successfully combating this problem was actually kind of working around it : Since i work with very suspicious and paradox data (difficult and human labeled), sometimes, due to contradicting information, there is a sequence of learning examples generating very high errors. So i simply reduced the batch size to not stack these errors too high, and in case of failure (see above) i simply switched back to an \"OK\" model before that point.\n\nI'd suggest you check (evaluate) your models once before and then after the loss jump. Chances are high, that the model after the loss jump is unusable.\n"}