{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290854757", "html_url": "https://github.com/tensorflow/tensorflow/issues/8858#issuecomment-290854757", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8858", "id": 290854757, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDg1NDc1Nw==", "user": {"login": "surmenok", "id": 2715382, "node_id": "MDQ6VXNlcjI3MTUzODI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2715382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/surmenok", "html_url": "https://github.com/surmenok", "followers_url": "https://api.github.com/users/surmenok/followers", "following_url": "https://api.github.com/users/surmenok/following{/other_user}", "gists_url": "https://api.github.com/users/surmenok/gists{/gist_id}", "starred_url": "https://api.github.com/users/surmenok/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/surmenok/subscriptions", "organizations_url": "https://api.github.com/users/surmenok/orgs", "repos_url": "https://api.github.com/users/surmenok/repos", "events_url": "https://api.github.com/users/surmenok/events{/privacy}", "received_events_url": "https://api.github.com/users/surmenok/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-31T23:04:25Z", "updated_at": "2017-03-31T23:04:25Z", "author_association": "NONE", "body_html": "<p>I simplified the code a bit more. This is the minimal failing code I could get:</p>\n<pre><code>from __future__ import print_function\nimport tensorflow as tf\n\ndef train_model(run_number):\n    graph = tf.Graph()\n    \n    with graph.as_default():\n        tf_dataset = tf.Variable(tf.truncated_normal([input_dimension, 1000]))\n        weights0 = tf.Variable(tf.truncated_normal([1000, 10000]))\n        result = tf.matmul(tf_dataset, weights0)\n    \n    with tf.Session(graph=graph) as session:\n        tf.global_variables_initializer().run()\n\n        print('Before computation')\n        session.run(result)\n\ninput_dimension = 10000\n\nfor i in range(100):\n    print(\"Run #{}\".format(i))\n    train_model(i)\n</code></pre>\n<p>The function creates 2 variables using tf.truncated_normal for initialization, then multiplies these variables. The function is called 100 times sequentially.<br>\nSeems like the bug is related to memory, because size of TensorFlow variables impacts behavior of the program. Behavior with different values of input_dimension variable (it changes size of one of TensorFlow variables used in computation):</p>\n<pre><code>1000 - works fine\n2000 - reboots the machine on 61st execution\n3000 - reboots the machine on 12th execution\n4000 - reboots the machine on 21st execution\n5000 - reboots the machine on 4th execution\n10000 - reboots the machine on 3rd execution\n25000 - reboots the machine on 2nd execution\n29000 - reboots the machine on 9th execution\n29500 - reboots the machine on 19th execution\n29900 - reboots the machine on 10th execution\n30000 - reboots the machine on 30th execution\n40000 - works fine\n50000 - works fine\n100000 - works fine\n500000 - OOM on 1st execution:\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 18.63GiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:993] Resource exhausted: OOM when allocating tensor with shape[500000,10000]\n</code></pre>\n<p>It's not deterministic. For some time it was working fine with values up to 4260, but then it started failing for values as low as 2000.<br>\nInteresting that it works well with higher values like 40000.</p>\n<p>If I change the program to run the train_model function only once and run the program (executing 'python test.py' in a terminal window) multiple times, it also crashes the machine after a few runs.</p>", "body_text": "I simplified the code a bit more. This is the minimal failing code I could get:\nfrom __future__ import print_function\nimport tensorflow as tf\n\ndef train_model(run_number):\n    graph = tf.Graph()\n    \n    with graph.as_default():\n        tf_dataset = tf.Variable(tf.truncated_normal([input_dimension, 1000]))\n        weights0 = tf.Variable(tf.truncated_normal([1000, 10000]))\n        result = tf.matmul(tf_dataset, weights0)\n    \n    with tf.Session(graph=graph) as session:\n        tf.global_variables_initializer().run()\n\n        print('Before computation')\n        session.run(result)\n\ninput_dimension = 10000\n\nfor i in range(100):\n    print(\"Run #{}\".format(i))\n    train_model(i)\n\nThe function creates 2 variables using tf.truncated_normal for initialization, then multiplies these variables. The function is called 100 times sequentially.\nSeems like the bug is related to memory, because size of TensorFlow variables impacts behavior of the program. Behavior with different values of input_dimension variable (it changes size of one of TensorFlow variables used in computation):\n1000 - works fine\n2000 - reboots the machine on 61st execution\n3000 - reboots the machine on 12th execution\n4000 - reboots the machine on 21st execution\n5000 - reboots the machine on 4th execution\n10000 - reboots the machine on 3rd execution\n25000 - reboots the machine on 2nd execution\n29000 - reboots the machine on 9th execution\n29500 - reboots the machine on 19th execution\n29900 - reboots the machine on 10th execution\n30000 - reboots the machine on 30th execution\n40000 - works fine\n50000 - works fine\n100000 - works fine\n500000 - OOM on 1st execution:\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 18.63GiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:993] Resource exhausted: OOM when allocating tensor with shape[500000,10000]\n\nIt's not deterministic. For some time it was working fine with values up to 4260, but then it started failing for values as low as 2000.\nInteresting that it works well with higher values like 40000.\nIf I change the program to run the train_model function only once and run the program (executing 'python test.py' in a terminal window) multiple times, it also crashes the machine after a few runs.", "body": "I simplified the code a bit more. This is the minimal failing code I could get:\r\n\r\n```\r\nfrom __future__ import print_function\r\nimport tensorflow as tf\r\n\r\ndef train_model(run_number):\r\n    graph = tf.Graph()\r\n    \r\n    with graph.as_default():\r\n        tf_dataset = tf.Variable(tf.truncated_normal([input_dimension, 1000]))\r\n        weights0 = tf.Variable(tf.truncated_normal([1000, 10000]))\r\n        result = tf.matmul(tf_dataset, weights0)\r\n    \r\n    with tf.Session(graph=graph) as session:\r\n        tf.global_variables_initializer().run()\r\n\r\n        print('Before computation')\r\n        session.run(result)\r\n\r\ninput_dimension = 10000\r\n\r\nfor i in range(100):\r\n    print(\"Run #{}\".format(i))\r\n    train_model(i)\r\n```\r\n\r\nThe function creates 2 variables using tf.truncated_normal for initialization, then multiplies these variables. The function is called 100 times sequentially.\r\nSeems like the bug is related to memory, because size of TensorFlow variables impacts behavior of the program. Behavior with different values of input_dimension variable (it changes size of one of TensorFlow variables used in computation):\r\n\r\n```\r\n1000 - works fine\r\n2000 - reboots the machine on 61st execution\r\n3000 - reboots the machine on 12th execution\r\n4000 - reboots the machine on 21st execution\r\n5000 - reboots the machine on 4th execution\r\n10000 - reboots the machine on 3rd execution\r\n25000 - reboots the machine on 2nd execution\r\n29000 - reboots the machine on 9th execution\r\n29500 - reboots the machine on 19th execution\r\n29900 - reboots the machine on 10th execution\r\n30000 - reboots the machine on 30th execution\r\n40000 - works fine\r\n50000 - works fine\r\n100000 - works fine\r\n500000 - OOM on 1st execution:\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 18.63GiB.  See logs for memory state.\r\nW tensorflow/core/framework/op_kernel.cc:993] Resource exhausted: OOM when allocating tensor with shape[500000,10000]\r\n```\r\n\r\nIt's not deterministic. For some time it was working fine with values up to 4260, but then it started failing for values as low as 2000.\r\nInteresting that it works well with higher values like 40000.\r\n\r\nIf I change the program to run the train_model function only once and run the program (executing 'python test.py' in a terminal window) multiple times, it also crashes the machine after a few runs.\r\n\r\n\r\n"}