{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8858", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8858/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8858/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8858/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8858", "id": 218384967, "node_id": "MDU6SXNzdWUyMTgzODQ5Njc=", "number": 8858, "title": "Machine restarts when running TensorFlow with GPU", "user": {"login": "surmenok", "id": 2715382, "node_id": "MDQ6VXNlcjI3MTUzODI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2715382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/surmenok", "html_url": "https://github.com/surmenok", "followers_url": "https://api.github.com/users/surmenok/followers", "following_url": "https://api.github.com/users/surmenok/following{/other_user}", "gists_url": "https://api.github.com/users/surmenok/gists{/gist_id}", "starred_url": "https://api.github.com/users/surmenok/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/surmenok/subscriptions", "organizations_url": "https://api.github.com/users/surmenok/orgs", "repos_url": "https://api.github.com/users/surmenok/repos", "events_url": "https://api.github.com/users/surmenok/events{/privacy}", "received_events_url": "https://api.github.com/users/surmenok/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 50, "created_at": "2017-03-31T03:01:06Z", "updated_at": "2018-11-23T04:02:06Z", "closed_at": "2017-05-22T20:51:30Z", "author_association": "NONE", "body_html": "<p>A simple Python program which runs a few TensorFlow computations consequently crashes when running on GPU.</p>\n<p>Code:</p>\n<pre><code>from __future__ import print_function\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.client import timeline\n\ndef train_model(run_number):\n    image_size = 28\n    num_labels = 10\n    batch_size = 16\n    layer1_neuron_count = 16384\n\n    graph = tf.Graph()\n    \n    with graph.as_default():\n        tf_valid_dataset = tf.constant(valid_dataset)\n\n        # Variables.\n        weights0 = tf.Variable(\n            tf.truncated_normal([image_size * image_size, layer1_neuron_count]))\n        biases0 = tf.Variable(tf.zeros([layer1_neuron_count]))\n\n        weights1 = tf.Variable(\n            tf.truncated_normal([layer1_neuron_count, num_labels]))\n        biases1 = tf.Variable(tf.zeros([num_labels]))\n\n        valid_layer0 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights0) + biases0)\n        valid_prediction = tf.matmul(valid_layer0, weights1) + biases1\n    \n    with tf.Session(graph=graph) as session:\n        tf.global_variables_initializer().run()\n\n        print('Validation')\n        \n        session.run(valid_prediction)\n            \n        print('Validation done')\n\nvalid_dataset = np.random.uniform(-1, 1, (10000, 784)).astype(dtype=np.float32)\nvalid_labels = np.random.uniform(0, 1, (10000, 10)).astype(dtype=np.float32)\n\nfor i in range(10):\n    print(\"Run #{}\".format(i))\n    train_model(i)\n</code></pre>\n<p>It should run the same computation 10 times, recreating a graph and a session every time.<br>\nWorks fine when I run it on CPU. When running on GPU, it fails on running computation for 2nd, 3rd or 4th session.</p>\n<p>Console output:</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nRun #0\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: GeForce GTX 980 Ti\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:01:00.0\nTotal memory: 5.93GiB\nFree memory: 5.83GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nValidation\nValidation done\nRun #1\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nValidation\nValidation done\nRun #2\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nValidation\nValidation done\nRun #3\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nValidation\n</code></pre>\n<p>Then the machine just restarts.<br>\nThere are no relevant messages in syslog before the restart.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p><a href=\"http://stackoverflow.com/questions/39122984/system-auto-reboot-when-tensorflow-model-is-too-large\" rel=\"nofollow\">http://stackoverflow.com/questions/39122984/system-auto-reboot-when-tensorflow-model-is-too-large</a><br>\n<a href=\"http://stackoverflow.com/questions/41237115/computer-restarts-with-large-mini-batches-in-tensorflow\" rel=\"nofollow\">http://stackoverflow.com/questions/41237115/computer-restarts-with-large-mini-batches-in-tensorflow</a></p>\n<p>When running other TensorFlow programs, I noticed that sometimes such crashes happen when I use large tensors. Issues above seem to be related, at least symptoms are similar.</p>\n<h3>Environment info</h3>\n<p>GPU: GeForce GTX 980 Ti<br>\nOperating System: Ubuntu 16.04.2 LTS</p>\n<p>Installed version of CUDA and cuDNN: CUDA 8.0.61, cuDNN 7.5<br>\nOutput of <code>ls -l /usr/local/cuda/lib64/libcud*</code>:</p>\n<p><code>-rw-r--r-- 1 root root   556000 Mar 30 18:05 /usr/local/cuda/lib64/libcudadevrt.a lrwxrwxrwx 1 root root       16 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0 lrwxrwxrwx 1 root root       19 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.61 -rwxr-xr-x 1 root root   415432 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so.8.0.61 -rw-r--r-- 1 root root   775162 Mar 30 18:05 /usr/local/cuda/lib64/libcudart_static.a lrwxrwxrwx 1 root root       13 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so -&gt; libcudnn.so.5 lrwxrwxrwx 1 root root       18 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.1.10 -rwxr-xr-x 1 root root 84163560 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so.5.1.10 -rw-r--r-- 1 root root 70364814 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn_static.a</code></p>\n<p>TensorFlow:</p>\n<ol>\n<li>\"pip install tensorflow-gpu\". Version 1.0.1</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>:</li>\n</ol>\n<p><code>I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally 1.0.1</code></p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>Tried to reinstall Ubuntu/CUDA/cuDNN/TensorFlow, didn't help.</p>", "body_text": "A simple Python program which runs a few TensorFlow computations consequently crashes when running on GPU.\nCode:\nfrom __future__ import print_function\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.client import timeline\n\ndef train_model(run_number):\n    image_size = 28\n    num_labels = 10\n    batch_size = 16\n    layer1_neuron_count = 16384\n\n    graph = tf.Graph()\n    \n    with graph.as_default():\n        tf_valid_dataset = tf.constant(valid_dataset)\n\n        # Variables.\n        weights0 = tf.Variable(\n            tf.truncated_normal([image_size * image_size, layer1_neuron_count]))\n        biases0 = tf.Variable(tf.zeros([layer1_neuron_count]))\n\n        weights1 = tf.Variable(\n            tf.truncated_normal([layer1_neuron_count, num_labels]))\n        biases1 = tf.Variable(tf.zeros([num_labels]))\n\n        valid_layer0 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights0) + biases0)\n        valid_prediction = tf.matmul(valid_layer0, weights1) + biases1\n    \n    with tf.Session(graph=graph) as session:\n        tf.global_variables_initializer().run()\n\n        print('Validation')\n        \n        session.run(valid_prediction)\n            \n        print('Validation done')\n\nvalid_dataset = np.random.uniform(-1, 1, (10000, 784)).astype(dtype=np.float32)\nvalid_labels = np.random.uniform(0, 1, (10000, 10)).astype(dtype=np.float32)\n\nfor i in range(10):\n    print(\"Run #{}\".format(i))\n    train_model(i)\n\nIt should run the same computation 10 times, recreating a graph and a session every time.\nWorks fine when I run it on CPU. When running on GPU, it fails on running computation for 2nd, 3rd or 4th session.\nConsole output:\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nRun #0\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: GeForce GTX 980 Ti\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:01:00.0\nTotal memory: 5.93GiB\nFree memory: 5.83GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nValidation\nValidation done\nRun #1\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nValidation\nValidation done\nRun #2\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nValidation\nValidation done\nRun #3\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nValidation\n\nThen the machine just restarts.\nThere are no relevant messages in syslog before the restart.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nhttp://stackoverflow.com/questions/39122984/system-auto-reboot-when-tensorflow-model-is-too-large\nhttp://stackoverflow.com/questions/41237115/computer-restarts-with-large-mini-batches-in-tensorflow\nWhen running other TensorFlow programs, I noticed that sometimes such crashes happen when I use large tensors. Issues above seem to be related, at least symptoms are similar.\nEnvironment info\nGPU: GeForce GTX 980 Ti\nOperating System: Ubuntu 16.04.2 LTS\nInstalled version of CUDA and cuDNN: CUDA 8.0.61, cuDNN 7.5\nOutput of ls -l /usr/local/cuda/lib64/libcud*:\n-rw-r--r-- 1 root root   556000 Mar 30 18:05 /usr/local/cuda/lib64/libcudadevrt.a lrwxrwxrwx 1 root root       16 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0 lrwxrwxrwx 1 root root       19 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61 -rwxr-xr-x 1 root root   415432 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so.8.0.61 -rw-r--r-- 1 root root   775162 Mar 30 18:05 /usr/local/cuda/lib64/libcudart_static.a lrwxrwxrwx 1 root root       13 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5 lrwxrwxrwx 1 root root       18 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10 -rwxr-xr-x 1 root root 84163560 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so.5.1.10 -rw-r--r-- 1 root root 70364814 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn_static.a\nTensorFlow:\n\n\"pip install tensorflow-gpu\". Version 1.0.1\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\":\n\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally 1.0.1\nWhat other attempted solutions have you tried?\nTried to reinstall Ubuntu/CUDA/cuDNN/TensorFlow, didn't help.", "body": "A simple Python program which runs a few TensorFlow computations consequently crashes when running on GPU.\r\n\r\nCode:\r\n\r\n```\r\nfrom __future__ import print_function\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import timeline\r\n\r\ndef train_model(run_number):\r\n    image_size = 28\r\n    num_labels = 10\r\n    batch_size = 16\r\n    layer1_neuron_count = 16384\r\n\r\n    graph = tf.Graph()\r\n    \r\n    with graph.as_default():\r\n        tf_valid_dataset = tf.constant(valid_dataset)\r\n\r\n        # Variables.\r\n        weights0 = tf.Variable(\r\n            tf.truncated_normal([image_size * image_size, layer1_neuron_count]))\r\n        biases0 = tf.Variable(tf.zeros([layer1_neuron_count]))\r\n\r\n        weights1 = tf.Variable(\r\n            tf.truncated_normal([layer1_neuron_count, num_labels]))\r\n        biases1 = tf.Variable(tf.zeros([num_labels]))\r\n\r\n        valid_layer0 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights0) + biases0)\r\n        valid_prediction = tf.matmul(valid_layer0, weights1) + biases1\r\n    \r\n    with tf.Session(graph=graph) as session:\r\n        tf.global_variables_initializer().run()\r\n\r\n        print('Validation')\r\n        \r\n        session.run(valid_prediction)\r\n            \r\n        print('Validation done')\r\n\r\nvalid_dataset = np.random.uniform(-1, 1, (10000, 784)).astype(dtype=np.float32)\r\nvalid_labels = np.random.uniform(0, 1, (10000, 10)).astype(dtype=np.float32)\r\n\r\nfor i in range(10):\r\n    print(\"Run #{}\".format(i))\r\n    train_model(i)\r\n```\r\n\r\nIt should run the same computation 10 times, recreating a graph and a session every time. \r\nWorks fine when I run it on CPU. When running on GPU, it fails on running computation for 2nd, 3rd or 4th session.\r\n\r\nConsole output:\r\n\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nRun #0\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\r\nname: GeForce GTX 980 Ti\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\r\npciBusID 0000:01:00.0\r\nTotal memory: 5.93GiB\r\nFree memory: 5.83GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\r\nValidation\r\nValidation done\r\nRun #1\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\r\nValidation\r\nValidation done\r\nRun #2\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\r\nValidation\r\nValidation done\r\nRun #3\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\r\nValidation\r\n```\r\n\r\nThen the machine just restarts.\r\nThere are no relevant messages in syslog before the restart.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttp://stackoverflow.com/questions/39122984/system-auto-reboot-when-tensorflow-model-is-too-large\r\nhttp://stackoverflow.com/questions/41237115/computer-restarts-with-large-mini-batches-in-tensorflow\r\n\r\nWhen running other TensorFlow programs, I noticed that sometimes such crashes happen when I use large tensors. Issues above seem to be related, at least symptoms are similar.\r\n\r\n\r\n### Environment info\r\nGPU: GeForce GTX 980 Ti\r\nOperating System: Ubuntu 16.04.2 LTS\r\n\r\nInstalled version of CUDA and cuDNN: CUDA 8.0.61, cuDNN 7.5\r\nOutput of `ls -l /usr/local/cuda/lib64/libcud*`:\r\n\r\n`-rw-r--r-- 1 root root   556000 Mar 30 18:05 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n-rwxr-xr-x 1 root root   415432 Mar 30 18:05 /usr/local/cuda/lib64/libcudart.so.8.0.61\r\n-rw-r--r-- 1 root root   775162 Mar 30 18:05 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       18 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10\r\n-rwxr-xr-x 1 root root 84163560 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn.so.5.1.10\r\n-rw-r--r-- 1 root root 70364814 Mar 30 19:42 /usr/local/cuda/lib64/libcudnn_static.a`\r\n\r\nTensorFlow:\r\n1. \"pip install tensorflow-gpu\". Version 1.0.1\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:\r\n\r\n`I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n1.0.1`\r\n\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nTried to reinstall Ubuntu/CUDA/cuDNN/TensorFlow, didn't help.\r\n\r\n"}