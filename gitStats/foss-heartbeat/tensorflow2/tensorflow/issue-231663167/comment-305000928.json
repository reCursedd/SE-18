{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/305000928", "html_url": "https://github.com/tensorflow/tensorflow/issues/10222#issuecomment-305000928", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10222", "id": 305000928, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNTAwMDkyOA==", "user": {"login": "hunsteve", "id": 15277286, "node_id": "MDQ6VXNlcjE1Mjc3Mjg2", "avatar_url": "https://avatars0.githubusercontent.com/u/15277286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hunsteve", "html_url": "https://github.com/hunsteve", "followers_url": "https://api.github.com/users/hunsteve/followers", "following_url": "https://api.github.com/users/hunsteve/following{/other_user}", "gists_url": "https://api.github.com/users/hunsteve/gists{/gist_id}", "starred_url": "https://api.github.com/users/hunsteve/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hunsteve/subscriptions", "organizations_url": "https://api.github.com/users/hunsteve/orgs", "repos_url": "https://api.github.com/users/hunsteve/repos", "events_url": "https://api.github.com/users/hunsteve/events{/privacy}", "received_events_url": "https://api.github.com/users/hunsteve/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-30T20:38:14Z", "updated_at": "2017-05-30T20:38:14Z", "author_association": "NONE", "body_html": "<p>Determinism option sounds great. Until then a notice in the docs would be nice, saying that the reduction ops might be non-deterministic.</p>\n<p>Currently this behavior does not cause serious problems to us. The way it came up was a test, where we tried to numerically compare the outputs and gradients of our implementation of a method with the reference implementation of that method in tensorflow. We got suprised when the reference implementation was not consistent even with itself in our test.</p>\n<p>Shortly after submitting this issue, we found this article: <a href=\"https://www.twosigma.com/insights/a-workaround-for-non-determinism-in-tensorflow\" rel=\"nofollow\">https://www.twosigma.com/insights/a-workaround-for-non-determinism-in-tensorflow</a></p>", "body_text": "Determinism option sounds great. Until then a notice in the docs would be nice, saying that the reduction ops might be non-deterministic.\nCurrently this behavior does not cause serious problems to us. The way it came up was a test, where we tried to numerically compare the outputs and gradients of our implementation of a method with the reference implementation of that method in tensorflow. We got suprised when the reference implementation was not consistent even with itself in our test.\nShortly after submitting this issue, we found this article: https://www.twosigma.com/insights/a-workaround-for-non-determinism-in-tensorflow", "body": "Determinism option sounds great. Until then a notice in the docs would be nice, saying that the reduction ops might be non-deterministic.\r\n\r\nCurrently this behavior does not cause serious problems to us. The way it came up was a test, where we tried to numerically compare the outputs and gradients of our implementation of a method with the reference implementation of that method in tensorflow. We got suprised when the reference implementation was not consistent even with itself in our test.\r\n\r\nShortly after submitting this issue, we found this article: https://www.twosigma.com/insights/a-workaround-for-non-determinism-in-tensorflow"}