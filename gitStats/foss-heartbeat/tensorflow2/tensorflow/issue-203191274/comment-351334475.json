{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/351334475", "html_url": "https://github.com/tensorflow/tensorflow/issues/7068#issuecomment-351334475", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7068", "id": 351334475, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MTMzNDQ3NQ==", "user": {"login": "albertz", "id": 59132, "node_id": "MDQ6VXNlcjU5MTMy", "avatar_url": "https://avatars0.githubusercontent.com/u/59132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albertz", "html_url": "https://github.com/albertz", "followers_url": "https://api.github.com/users/albertz/followers", "following_url": "https://api.github.com/users/albertz/following{/other_user}", "gists_url": "https://api.github.com/users/albertz/gists{/gist_id}", "starred_url": "https://api.github.com/users/albertz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albertz/subscriptions", "organizations_url": "https://api.github.com/users/albertz/orgs", "repos_url": "https://api.github.com/users/albertz/repos", "events_url": "https://api.github.com/users/albertz/events{/privacy}", "received_events_url": "https://api.github.com/users/albertz/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-13T09:31:18Z", "updated_at": "2017-12-13T09:31:18Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1836815\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/shoeffner\">@shoeffner</a> Your scripts assume that there are enough available nodes in the SGE cluster, right? So if there are not enough, I guess it would break? Have you thought about queuing it all together, so that when it gets scheduled, you will get all the requested amount of nodes and resources? I'm currently looking into this. I think this probably can be done via the SGE parallel environment mechanism (see manpage sge_pe). I have seen OpenMPI setups using this <code>-pe</code> option.</p>", "body_text": "@shoeffner Your scripts assume that there are enough available nodes in the SGE cluster, right? So if there are not enough, I guess it would break? Have you thought about queuing it all together, so that when it gets scheduled, you will get all the requested amount of nodes and resources? I'm currently looking into this. I think this probably can be done via the SGE parallel environment mechanism (see manpage sge_pe). I have seen OpenMPI setups using this -pe option.", "body": "@shoeffner Your scripts assume that there are enough available nodes in the SGE cluster, right? So if there are not enough, I guess it would break? Have you thought about queuing it all together, so that when it gets scheduled, you will get all the requested amount of nodes and resources? I'm currently looking into this. I think this probably can be done via the SGE parallel environment mechanism (see manpage sge_pe). I have seen OpenMPI setups using this `-pe` option."}