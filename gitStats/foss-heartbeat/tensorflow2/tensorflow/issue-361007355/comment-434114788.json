{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/434114788", "html_url": "https://github.com/tensorflow/tensorflow/issues/22322#issuecomment-434114788", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22322", "id": 434114788, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNDExNDc4OA==", "user": {"login": "Sergio0694", "id": 10199417, "node_id": "MDQ6VXNlcjEwMTk5NDE3", "avatar_url": "https://avatars3.githubusercontent.com/u/10199417?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sergio0694", "html_url": "https://github.com/Sergio0694", "followers_url": "https://api.github.com/users/Sergio0694/followers", "following_url": "https://api.github.com/users/Sergio0694/following{/other_user}", "gists_url": "https://api.github.com/users/Sergio0694/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sergio0694/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sergio0694/subscriptions", "organizations_url": "https://api.github.com/users/Sergio0694/orgs", "repos_url": "https://api.github.com/users/Sergio0694/repos", "events_url": "https://api.github.com/users/Sergio0694/events{/privacy}", "received_events_url": "https://api.github.com/users/Sergio0694/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-29T23:13:07Z", "updated_at": "2018-10-29T23:13:07Z", "author_association": "NONE", "body_html": "<p>I'll add more info on the issue here, following a conversation with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4855538\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/arnaldog12\">@arnaldog12</a> about this.</p>\n<ul>\n<li>I'm using TF from Python, but I have a few custom GPU ops that I need to compile and use in my graph.</li>\n<li>Right now I'm working on Ubuntu, and I managed to compile the various ops without issues, following the docs. The thing is that I'd like to distribute my trained network to users on possibly other platforms (eg. Windows), so they'd need to be able to compile those GPU ops there as well. I'd love to see feature parity with Linux/MacOS on this, ie. the ability to compile custom GPU ops with TF <em>installed from binary</em>. I wouldn't want every user to have to build the whole TF package from scratch.</li>\n<li>Being able to build the custom GPU op along with TF (so when installed from source) would still be a valid alternative at least for now (better than nothing). Unfortunately, none of the two approaches seem to work at the moment.</li>\n</ul>\n<p>As for the error logs, <a href=\"https://gist.github.com/Sergio0694/3f379c9007fa2abd588dac5be0fe996e\">this</a> is the error log when trying to build the GPU op with Bazel on Windows (with TF r1.11) following <a href=\"https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_bazel_tensorflow_source_installation\" rel=\"nofollow\">these docs</a> and replacing <code>.so</code> with <code>.dll</code>. As mentioned in the first post, building a GPU op fails, and building a CPU op works, but fails to load when calling <code>tf.load_op_library</code>. Made these attempts just in case, I realize this is probably just not supported on Windows yet.</p>\n<p><strong>My actual question</strong>: would it be possible to get a variant of <a href=\"https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation\" rel=\"nofollow\">this bash script</a> (with the <a href=\"https://www.tensorflow.org/extend/adding_an_op#gpu_support\" rel=\"nofollow\">two additional lines</a> to enable GPU support) to build a custom GPU op for TF on Windows, with TF installed from binary? Is it just a matter of coming up with the right build commands and setting up the environment/compiler properly, or is this just not possible on Windows as of now for some reason?</p>\n<p>Thanks! <g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>", "body_text": "I'll add more info on the issue here, following a conversation with @arnaldog12 about this.\n\nI'm using TF from Python, but I have a few custom GPU ops that I need to compile and use in my graph.\nRight now I'm working on Ubuntu, and I managed to compile the various ops without issues, following the docs. The thing is that I'd like to distribute my trained network to users on possibly other platforms (eg. Windows), so they'd need to be able to compile those GPU ops there as well. I'd love to see feature parity with Linux/MacOS on this, ie. the ability to compile custom GPU ops with TF installed from binary. I wouldn't want every user to have to build the whole TF package from scratch.\nBeing able to build the custom GPU op along with TF (so when installed from source) would still be a valid alternative at least for now (better than nothing). Unfortunately, none of the two approaches seem to work at the moment.\n\nAs for the error logs, this is the error log when trying to build the GPU op with Bazel on Windows (with TF r1.11) following these docs and replacing .so with .dll. As mentioned in the first post, building a GPU op fails, and building a CPU op works, but fails to load when calling tf.load_op_library. Made these attempts just in case, I realize this is probably just not supported on Windows yet.\nMy actual question: would it be possible to get a variant of this bash script (with the two additional lines to enable GPU support) to build a custom GPU op for TF on Windows, with TF installed from binary? Is it just a matter of coming up with the right build commands and setting up the environment/compiler properly, or is this just not possible on Windows as of now for some reason?\nThanks! \ud83d\ude04", "body": "I'll add more info on the issue here, following a conversation with @arnaldog12 about this.\r\n\r\n- I'm using TF from Python, but I have a few custom GPU ops that I need to compile and use in my graph.\r\n- Right now I'm working on Ubuntu, and I managed to compile the various ops without issues, following the docs. The thing is that I'd like to distribute my trained network to users on possibly other platforms (eg. Windows), so they'd need to be able to compile those GPU ops there as well. I'd love to see feature parity with Linux/MacOS on this, ie. the ability to compile custom GPU ops with TF _installed from binary_. I wouldn't want every user to have to build the whole TF package from scratch.\r\n- Being able to build the custom GPU op along with TF (so when installed from source) would still be a valid alternative at least for now (better than nothing). Unfortunately, none of the two approaches seem to work at the moment.\r\n\r\nAs for the error logs, [this](https://gist.github.com/Sergio0694/3f379c9007fa2abd588dac5be0fe996e) is the error log when trying to build the GPU op with Bazel on Windows (with TF r1.11) following [these docs](https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_bazel_tensorflow_source_installation) and replacing `.so` with `.dll`. As mentioned in the first post, building a GPU op fails, and building a CPU op works, but fails to load when calling `tf.load_op_library`. Made these attempts just in case, I realize this is probably just not supported on Windows yet.\r\n\r\n**My actual question**: would it be possible to get a variant of [this bash script](https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation) (with the [two additional lines](https://www.tensorflow.org/extend/adding_an_op#gpu_support) to enable GPU support) to build a custom GPU op for TF on Windows, with TF installed from binary? Is it just a matter of coming up with the right build commands and setting up the environment/compiler properly, or is this just not possible on Windows as of now for some reason?\r\n\r\nThanks! \ud83d\ude04\r\n"}