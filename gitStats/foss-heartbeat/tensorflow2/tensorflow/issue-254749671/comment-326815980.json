{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/326815980", "html_url": "https://github.com/tensorflow/tensorflow/issues/12758#issuecomment-326815980", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12758", "id": 326815980, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjgxNTk4MA==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-03T16:42:34Z", "updated_at": "2017-09-03T19:27:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is a fairly vague feature request since there are so many hyper-parameter optimization methods. The most commonly\u00a0used one is the learning rate optimization. You launch several runs in parallel, with different learning rates in increments of 1.5, and see which one works better</p>\n<p>At Google 1.5 years ago there were a few hyper-parameter optimizers implemented for TensorFlow, and I can't recall any of them being too practical. Couple of issues I remember</p>\n<ol>\n<li>\n<p>to run hyper-parameter candidates in parallel needs extra infrastructure setup. Imagine your model trains with 50 replicas to train, a hyper-parameter optimizer needs to launch x copies of 50 replicas.</p>\n</li>\n<li>\n<p>hyper-parameter optimizers tend to have their own hyper-parameters that they are sensitive too. For instance, you have to decide how long to train your model with new parameters. Shrinking the learning rate is known to increase accuracy in short term, but will harm performance in the long term. So setting the number of epochs too small will point your search in the wrong direction, while setting it too large will take too long to be practical.</p>\n</li>\n</ol>\n<p>I think it would make sense to request a specific hyper-parameter optimizer that works well for a specific application -- ie, maybe a specific algorithm that is known to achieve good results on for standard image recognition tasks.</p>", "body_text": "This is a fairly vague feature request since there are so many hyper-parameter optimization methods. The most commonly\u00a0used one is the learning rate optimization. You launch several runs in parallel, with different learning rates in increments of 1.5, and see which one works better\nAt Google 1.5 years ago there were a few hyper-parameter optimizers implemented for TensorFlow, and I can't recall any of them being too practical. Couple of issues I remember\n\n\nto run hyper-parameter candidates in parallel needs extra infrastructure setup. Imagine your model trains with 50 replicas to train, a hyper-parameter optimizer needs to launch x copies of 50 replicas.\n\n\nhyper-parameter optimizers tend to have their own hyper-parameters that they are sensitive too. For instance, you have to decide how long to train your model with new parameters. Shrinking the learning rate is known to increase accuracy in short term, but will harm performance in the long term. So setting the number of epochs too small will point your search in the wrong direction, while setting it too large will take too long to be practical.\n\n\nI think it would make sense to request a specific hyper-parameter optimizer that works well for a specific application -- ie, maybe a specific algorithm that is known to achieve good results on for standard image recognition tasks.", "body": "This is a fairly vague feature request since there are so many hyper-parameter optimization methods. The most commonly\u00a0used one is the learning rate optimization. You launch several runs in parallel, with different learning rates in increments of 1.5, and see which one works better\r\n\r\nAt Google 1.5 years ago there were a few hyper-parameter optimizers implemented for TensorFlow, and I can't recall any of them being too practical. Couple of issues I remember\r\n\r\n1. to run hyper-parameter candidates in parallel needs extra infrastructure setup. Imagine your model trains with 50 replicas to train, a hyper-parameter optimizer needs to launch x copies of 50 replicas.\r\n\r\n2. hyper-parameter optimizers tend to have their own hyper-parameters that they are sensitive too. For instance, you have to decide how long to train your model with new parameters. Shrinking the learning rate is known to increase accuracy in short term, but will harm performance in the long term. So setting the number of epochs too small will point your search in the wrong direction, while setting it too large will take too long to be practical.\r\n\r\nI think it would make sense to request a specific hyper-parameter optimizer that works well for a specific application -- ie, maybe a specific algorithm that is known to achieve good results on for standard image recognition tasks."}