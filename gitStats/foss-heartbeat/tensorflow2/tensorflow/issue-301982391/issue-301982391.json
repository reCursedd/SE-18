{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17395", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17395/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17395/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17395/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/17395", "id": 301982391, "node_id": "MDExOlB1bGxSZXF1ZXN0MTcyNjU4MTgz", "number": 17395, "title": "add AdaMax optimizer", "user": {"login": "facaiy", "id": 1112263, "node_id": "MDQ6VXNlcjExMTIyNjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1112263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/facaiy", "html_url": "https://github.com/facaiy", "followers_url": "https://api.github.com/users/facaiy/followers", "following_url": "https://api.github.com/users/facaiy/following{/other_user}", "gists_url": "https://api.github.com/users/facaiy/gists{/gist_id}", "starred_url": "https://api.github.com/users/facaiy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/facaiy/subscriptions", "organizations_url": "https://api.github.com/users/facaiy/orgs", "repos_url": "https://api.github.com/users/facaiy/repos", "events_url": "https://api.github.com/users/facaiy/events{/privacy}", "received_events_url": "https://api.github.com/users/facaiy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 419840263, "node_id": "MDU6TGFiZWw0MTk4NDAyNjM=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20testing%20(then%20merge)", "name": "awaiting testing (then merge)", "color": "c2e0c6", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "annarev", "id": 22060313, "node_id": "MDQ6VXNlcjIyMDYwMzEz", "avatar_url": "https://avatars0.githubusercontent.com/u/22060313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/annarev", "html_url": "https://github.com/annarev", "followers_url": "https://api.github.com/users/annarev/followers", "following_url": "https://api.github.com/users/annarev/following{/other_user}", "gists_url": "https://api.github.com/users/annarev/gists{/gist_id}", "starred_url": "https://api.github.com/users/annarev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/annarev/subscriptions", "organizations_url": "https://api.github.com/users/annarev/orgs", "repos_url": "https://api.github.com/users/annarev/repos", "events_url": "https://api.github.com/users/annarev/events{/privacy}", "received_events_url": "https://api.github.com/users/annarev/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "annarev", "id": 22060313, "node_id": "MDQ6VXNlcjIyMDYwMzEz", "avatar_url": "https://avatars0.githubusercontent.com/u/22060313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/annarev", "html_url": "https://github.com/annarev", "followers_url": "https://api.github.com/users/annarev/followers", "following_url": "https://api.github.com/users/annarev/following{/other_user}", "gists_url": "https://api.github.com/users/annarev/gists{/gist_id}", "starred_url": "https://api.github.com/users/annarev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/annarev/subscriptions", "organizations_url": "https://api.github.com/users/annarev/orgs", "repos_url": "https://api.github.com/users/annarev/repos", "events_url": "https://api.github.com/users/annarev/events{/privacy}", "received_events_url": "https://api.github.com/users/annarev/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 21, "created_at": "2018-03-03T09:04:21Z", "updated_at": "2018-04-17T23:48:17Z", "closed_at": "2018-04-17T19:54:31Z", "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17395", "html_url": "https://github.com/tensorflow/tensorflow/pull/17395", "diff_url": "https://github.com/tensorflow/tensorflow/pull/17395.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/17395.patch"}, "body_html": "<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #17104.\">Fix</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"298064004\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/17104\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/17104/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/17104\">#17104</a>. The PR implements the AdaMax optimizer: <a href=\"https://arxiv.org/pdf/1412.6980v8.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1412.6980v8.pdf</a></p>\n<p>Please pay attention to three points when reviewing:</p>\n<ol>\n<li>To avoid division by zero, we add <code>epsilon</code> for <code>v_t</code>, which is slightly different from original paper section 7.1. And we explained the change in the document.</li>\n<li>Contrast to the sparse implementation of <a href=\"https://www.tensorflow.org/versions/master/api_docs/python/tf/train/AdamOptimizer\" rel=\"nofollow\"><code>tf.train.AdamOptimizer</code></a>, the AdaMaxOptimizer only updates variable slices and corresponding <code>m_t</code>, <code>v_t</code> terms when that part of the variable was used in the forward pass.</li>\n<li>Because AdaMax is quite similar with Adam, we refactor the Adam code in c++ side to reuse its route. Not sure whether the solution sounds good.</li>\n</ol>\n<p>The PR is still very rudimentary implementation, any feedback/review would be appreciated.</p>", "body_text": "Fix #17104. The PR implements the AdaMax optimizer: https://arxiv.org/pdf/1412.6980v8.pdf\nPlease pay attention to three points when reviewing:\n\nTo avoid division by zero, we add epsilon for v_t, which is slightly different from original paper section 7.1. And we explained the change in the document.\nContrast to the sparse implementation of tf.train.AdamOptimizer, the AdaMaxOptimizer only updates variable slices and corresponding m_t, v_t terms when that part of the variable was used in the forward pass.\nBecause AdaMax is quite similar with Adam, we refactor the Adam code in c++ side to reuse its route. Not sure whether the solution sounds good.\n\nThe PR is still very rudimentary implementation, any feedback/review would be appreciated.", "body": "Fix #17104. The PR implements the AdaMax optimizer: https://arxiv.org/pdf/1412.6980v8.pdf\r\n\r\nPlease pay attention to three points when reviewing:\r\n1. To avoid division by zero, we add `epsilon` for `v_t`, which is slightly different from original paper section 7.1. And we explained the change in the document.\r\n2. Contrast to the sparse implementation of [`tf.train.AdamOptimizer`](https://www.tensorflow.org/versions/master/api_docs/python/tf/train/AdamOptimizer), the AdaMaxOptimizer only updates variable slices and corresponding `m_t`, `v_t` terms when that part of the variable was used in the forward pass.\r\n3. Because AdaMax is quite similar with Adam, we refactor the Adam code in c++ side to reuse its route. Not sure whether the solution sounds good.\r\n\r\nThe PR is still very rudimentary implementation, any feedback/review would be appreciated."}