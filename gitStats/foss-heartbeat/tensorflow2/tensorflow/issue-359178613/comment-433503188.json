{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/433503188", "html_url": "https://github.com/tensorflow/tensorflow/issues/22216#issuecomment-433503188", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22216", "id": 433503188, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzUwMzE4OA==", "user": {"login": "vishalsubbiah", "id": 3079888, "node_id": "MDQ6VXNlcjMwNzk4ODg=", "avatar_url": "https://avatars3.githubusercontent.com/u/3079888?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishalsubbiah", "html_url": "https://github.com/vishalsubbiah", "followers_url": "https://api.github.com/users/vishalsubbiah/followers", "following_url": "https://api.github.com/users/vishalsubbiah/following{/other_user}", "gists_url": "https://api.github.com/users/vishalsubbiah/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishalsubbiah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishalsubbiah/subscriptions", "organizations_url": "https://api.github.com/users/vishalsubbiah/orgs", "repos_url": "https://api.github.com/users/vishalsubbiah/repos", "events_url": "https://api.github.com/users/vishalsubbiah/events{/privacy}", "received_events_url": "https://api.github.com/users/vishalsubbiah/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-26T18:32:59Z", "updated_at": "2018-10-26T18:34:32Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1990079\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/smit-hinsu\">@smit-hinsu</a>, thanks for the response, but this issues seems independent of how I invoke XLA, since the other ways suggested, would keep it on the cpu device instead of the xla_cpu device which kind of hides the problem but doesn't solve it for my use case. Ideally I would want the entire graph to run on xla_cpu(currently the only way it seems to work, is by moving the while loop to the cpu). I am not running on a distributed system, so the concerns raised in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"302531161\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/17458\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/17458/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/17458\">#17458</a> may not be applicable here.</p>\n<p>I don't think this has been fixed, so could you reopen this issue and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"357442068\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/22102\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/22102/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/22102\">#22102</a></p>", "body_text": "@smit-hinsu, thanks for the response, but this issues seems independent of how I invoke XLA, since the other ways suggested, would keep it on the cpu device instead of the xla_cpu device which kind of hides the problem but doesn't solve it for my use case. Ideally I would want the entire graph to run on xla_cpu(currently the only way it seems to work, is by moving the while loop to the cpu). I am not running on a distributed system, so the concerns raised in #17458 may not be applicable here.\nI don't think this has been fixed, so could you reopen this issue and #22102", "body": "@smit-hinsu, thanks for the response, but this issues seems independent of how I invoke XLA, since the other ways suggested, would keep it on the cpu device instead of the xla_cpu device which kind of hides the problem but doesn't solve it for my use case. Ideally I would want the entire graph to run on xla_cpu(currently the only way it seems to work, is by moving the while loop to the cpu). I am not running on a distributed system, so the concerns raised in #17458 may not be applicable here.  \r\n \r\nI don't think this has been fixed, so could you reopen this issue and #22102"}