{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/424441726", "html_url": "https://github.com/tensorflow/tensorflow/issues/22216#issuecomment-424441726", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22216", "id": 424441726, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDQ0MTcyNg==", "user": {"login": "vishalsubbiah", "id": 3079888, "node_id": "MDQ6VXNlcjMwNzk4ODg=", "avatar_url": "https://avatars3.githubusercontent.com/u/3079888?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishalsubbiah", "html_url": "https://github.com/vishalsubbiah", "followers_url": "https://api.github.com/users/vishalsubbiah/followers", "following_url": "https://api.github.com/users/vishalsubbiah/following{/other_user}", "gists_url": "https://api.github.com/users/vishalsubbiah/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishalsubbiah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishalsubbiah/subscriptions", "organizations_url": "https://api.github.com/users/vishalsubbiah/orgs", "repos_url": "https://api.github.com/users/vishalsubbiah/repos", "events_url": "https://api.github.com/users/vishalsubbiah/events{/privacy}", "received_events_url": "https://api.github.com/users/vishalsubbiah/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-25T17:58:27Z", "updated_at": "2018-09-25T17:58:27Z", "author_association": "NONE", "body_html": "<p>This is the input for the code<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2416432/input.txt\">input.txt</a></p>\n<p>The code is:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport os\nimport argparse\nfrom tensorflow.python.estimator import run_config\nfrom tensorflow.python.ops.rnn import _transpose_batch_time\nfrom tensorflow.python.training import training\n\nBATCH_SIZE = 64\nSEQ_LENGTH = 32\nNUM_BATCHES = 1\n\ndef file_to_input_data(file, seq_length):\n    \"\"\"\n    Reads file, divides into train, validation, test sets and returns the\n    corresponding input source arrays\n    \"\"\"\n    with open(file, 'r') as f:\n        data = f.read()\n\n    char_array = np.array(list(data))\n    char_list, mapped_array = np.unique(char_array, return_inverse=True)\n\n    char_map = {c: i for i, c in enumerate(char_list)}\n    indices_char = {i: c for i, c in enumerate(char_list)}\n\n    num_unique_chars = char_list.shape[0]\n    dataset_size = mapped_array.shape[0]\n\n    # create the partitions\n    val_start = int(0.7 * dataset_size)\n    test_start = int(0.8 * dataset_size)\n    train_data, val_data, test_data = np.array_split(mapped_array,\n                                                     [val_start, test_start])\n\n    # truncate into multiple of seq length\n    def _truncate(x):\n        return x[:(x.shape[0] // seq_length) * seq_length]\n\n    return {\n        \"train\": _truncate(train_data),\n        \"val\": _truncate(val_data),\n        \"test\": _truncate(test_data),\n        \"vocab_size\": num_unique_chars,\n        \"char_map\": char_map,\n        \"indices_char\": indices_char\n    }\n\ndef shifted(x, value=0):\n    '''\n    returns target for a given linear sequence, x\n    '''\n    print(x.shape)\n\n    return np.append(x[1:],0)#np.pad(x[:-1], (1, 0), \"constant\", constant_values=value)\n\n\ndef data_from_file(file, seq_length):\n    \"\"\"Takes params, file, converts to one hot numpy arrays\n    and returns x, y, and vocab_size\"\"\"\n    text = open(file).read()[:10000] # for debugging\n    print(\"Corpus len:\", len(text))\n    chars = sorted(list(set(text)))\n    vocab_size = len(chars)\n    print('total chars:', len(chars))\n    char_indices = dict((c, i) for i, c in enumerate(chars))\n    indices_char = dict((i, c) for i, c in enumerate(chars))\n    sentences = []\n    next_chars = []\n    for i in range(0, len(text)-seq_length, 2):\n        sentences.append(text[i:i+seq_length]) #\"the cat in the ha\"\n        next_chars.append(text[i+seq_length])     #\"t\"\n    print(\"Vectorization...\")\n    x = np.zeros((len(sentences), seq_length, vocab_size), dtype=np.float32)\n    y = np.zeros((len(sentences), vocab_size), dtype=np.float32)\n    for i, sentence in enumerate(sentences):\n        for t, char in enumerate(sentence):\n            x[i, t, char_indices[char]] = 1\n        y[i, char_indices[next_chars[i]]] = 1\n    return {'x':x, 'y':y, 'vocab_size':vocab_size,'indices_char':indices_char,'char_indices':char_indices,'text':text}\n\n\ndef input_fn(params, mode):\n    batch_size = params.get('batch_size', BATCH_SIZE)\n    seq_length = params.get('seq_length', SEQ_LENGTH)\n    char_indices = params.get('char_indices', None)\n    num_classes = params.get('num_classes', None)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        x = params.get('x', None)#[:32000]  #[:batch_size*NUM_BATCHES]\n        #print(\"X SHAPE\", x.shape)\n        y = params.get('y', None) #size: (4984, 57) for 10,000 char sample\n        repeat_count = None\n    elif mode == tf.estimator.ModeKeys.EVAL:\n        data_source = params.get('val_data', None)\n        repeat_count = 1\n    elif mode == tf.estimator.ModeKeys.PREDICT:\n        sentence = params.get('seed_text')\n        char_indices = params.get('char_indices')\n\n\n        x = np.zeros((len(sentence)//seq_length, seq_length, num_classes), dtype=np.float32)\n        for t, char in enumerate(sentence):\n            x[0, t, char_indices[char]] = 1\n\n\n        #print(\"X SHAPE: \", x.shape)\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(1))\n        return ds\n\n    assert x is not None, \"Must supply the data\"\n\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\n    ds = ds.repeat(repeat_count)\n    ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n\n    return ds\n\n\ndef lstm_model_fn(features, labels, mode, params):\n    \"\"\" Basic RNN that uses LSTM Cells\n    features = input_tensors: one-hot tensors encoding the chars\n    mode: instance of tf.estimator.ModeKeys (e.g. ModeKeys.TRAIN)\n    rnn_type = GRU, LSTM, BasicRNN\n    params: dict specifying [learning_rate, seq_length, hidden_units]\"\"\"\n\n    with tf.device(\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"):\n        with tf.variable_scope(\"test_rnn\", use_resource=True):\n            num_classes = params.get(\"num_classes\")\n            batch_size = params.get('batch_size', BATCH_SIZE)\n            state_size = params.get(\"state_size\", 128)\n            seq_length = params.get(\"seq_length\", SEQ_LENGTH)\n\n        #     labels = tf.Print(labels, [labels, tf.shape(labels), \"LABELS SHAPE\"])\n\n            # input tensors need to be [batch_size x sentence_size x vocab_size]\n            #lstm_cell = tf.nn.rnn_cell.LSTMCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)#tf.nn.rnn_cell.BasicLSTMCell(state_size)\n            lstm_cell = tf.nn.rnn_cell.BasicRNNCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)\n            initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n            logits = None\n            predictions = None\n\n            if mode != tf.estimator.ModeKeys.PREDICT:\n                inputs=features\n                outputs,final_state=tf.contrib.recurrent.functional_rnn(cell=lstm_cell,\n                            inputs=inputs,initial_state=initial_state,scope=\"func\",\n                            sequence_length=seq_length,\n                            dtype= tf.float32)\n                #outputs = outputs_ta#.stack()\n\n                #outputs = _transpose_batch_time(outputs)\n        #         outputs = tf.Print(outputs, [outputs, tf.shape(outputs), \"outputs SHAPE\"])\n                with tf.variable_scope(\"rnn_final\",use_resource=True): #to allow prediction to call same function\n                    logits = tf.layers.dense(\n                        outputs, num_classes, name=\"final_layer\") #tf.reshape(outputs, [-1 , state_size])\n\n                logit_loss = logits[:,-1,:] #(64, 57) gets the prediction from the whole sequence\n                logit_loss = tf.reshape(logit_loss, (batch_size, num_classes))\n\n\n                predictions = tf.argmax(logits, axis=1,name=\"predictions\")\n\n            elif mode == tf.estimator.ModeKeys.PREDICT:\n                seed_length = len(params.get('seed_text'))\n                target_length = params.get('target_length')\n                inputs = features\n\n                outputs_ta,final_state=tf.contrib.recurrent.functional_rnn(lstm_cell,inputs,initial_state=initial_state,scope=\"func\")\n                predictions = outputs_ta.stack()\n\n                predictions = tf.Print(predictions, [predictions[90], \"PREDICTIONS\"])\n                return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n            loss = tf.reduce_mean(\n                    tf.nn.softmax_cross_entropy_with_logits(\n                    logits=logit_loss, labels=labels)) #tf.reshape(labels, [-1]))\n\n            optimizer = tf.train.MomentumOptimizer(learning_rate=0.15, momentum=0.97)\n\n            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n\n            if mode == tf.estimator.ModeKeys.TRAIN:\n                return tf.estimator.EstimatorSpec(\n                    mode=mode, loss=loss, train_op=train_op)\n            elif mode == tf.estimator.ModeKeys.EVAL:\n                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=metrics)\n\nif __name__ == \"__main__\":\n    tf.logging.set_verbosity(tf.logging.INFO)\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--train_file',\n        type=str,\n        default=os.path.expanduser(\"./input.txt\"),\n        help='where pre-processed data is stored')\n    parser.add_argument(\n        '--mode',\n        type=str,\n        default='train',\n        help='train, eval, or predict')\n    parser.add_argument(\n        '--num_states', type=int, default=128, help='size of each rnn layer')\n    parser.add_argument(\n        '--seed_text', type=str, default=\"The Volsces have much corn; take\", help='seed for prediction mode')\n    parser.add_argument(\n        '--target_length', type=int, default=100, help='the output length of your given prediction')\n    parser.add_argument(\n        '--seq_length', type=int, default=SEQ_LENGTH, help='number of unrolled time steps')\n    parser.add_argument(\n        '--num_steps', type=int, default=10, help='number of training steps')\n    parser.add_argument(\n        '--batch_size', type=int, default=BATCH_SIZE, help=\"samples per batch\")\n    args = parser.parse_args()\n\n    data = data_from_file(args.train_file, seq_length=args.seq_length)\n\n    classifier = tf.estimator.Estimator(\n        model_fn=lstm_model_fn,\n        params={\n            'num_classes': data[\"vocab_size\"],\n            'state_size': args.num_states,\n            'batch_size': args.batch_size,\n            'seq_length': args.seq_length,\n            'x': data[\"x\"],\n            'y': data['y'],\n            'char_indices': data[\"char_indices\"],\n            'seed_text': args.seed_text,\n            'target_length': args.target_length,\n        },\n        config=run_config.RunConfig(\n            save_summary_steps=10,\n            save_checkpoints_steps=100,\n            model_dir=\"./model\"))\n\n    classifier.train(input_fn, steps=args.num_steps)\n</code></pre>\n<p>this is the stacktrace of the error:</p>\n<pre><code>2018-09-25 10:54:39.604560: E tensorflow/core/common_runtime/executor.cc:697] Executor failed to create kernel. Not found: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\n  device='CPU'; dtype in [DT_BOOL]\n  device='CPU'; dtype in [DT_INT64]\n  device='CPU'; dtype in [DT_INT32]\n  device='CPU'; dtype in [DT_STRING]\n  device='CPU'; dtype in [DT_HALF]\n  device='CPU'; dtype in [DT_DOUBLE]\n  device='CPU'; dtype in [DT_FLOAT]\n\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\nTraceback (most recent call last):\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\n    return fn(*args)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\n  device='CPU'; dtype in [DT_BOOL]\n  device='CPU'; dtype in [DT_INT64]\n  device='CPU'; dtype in [DT_INT32]\n  device='CPU'; dtype in [DT_STRING]\n  device='CPU'; dtype in [DT_HALF]\n  device='CPU'; dtype in [DT_DOUBLE]\n  device='CPU'; dtype in [DT_FLOAT]\n\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\n\t [[Node: test_rnn/Forward_MIH5xlXOmdc = Forward_MIH5xlXOmdc[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_4/_5, cluster_31/_2/_3, cluster_28/_8/_9, cluster_26/_12/_13, cluster_29/_6/_7/_69)]]\n\t [[Node: cluster_27/_10/_11/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_cluster_27/_10/_11\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"basic_rnn.py\", line 236, in &lt;module&gt;\n    classifier.train(input_fn, steps=args.num_steps)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\n    saving_listeners)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 583, in run\n    run_metadata=run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1059, in run\n    run_metadata=run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1150, in run\n    raise six.reraise(*original_exc_info)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/six.py\", line 693, in reraise\n    raise value\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1135, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1207, in run\n    run_metadata=run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 987, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 877, in run\n    run_metadata_ptr)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\n    run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\n  device='CPU'; dtype in [DT_BOOL]\n  device='CPU'; dtype in [DT_INT64]\n  device='CPU'; dtype in [DT_INT32]\n  device='CPU'; dtype in [DT_STRING]\n  device='CPU'; dtype in [DT_HALF]\n  device='CPU'; dtype in [DT_DOUBLE]\n  device='CPU'; dtype in [DT_FLOAT]\n\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\n\t [[Node: test_rnn/Forward_MIH5xlXOmdc = Forward_MIH5xlXOmdc[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_4/_5, cluster_31/_2/_3, cluster_28/_8/_9, cluster_26/_12/_13, cluster_29/_6/_7/_69)]]\n\t [[Node: cluster_27/_10/_11/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_cluster_27/_10/_11\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n</code></pre>", "body_text": "This is the input for the code\ninput.txt\nThe code is:\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport argparse\nfrom tensorflow.python.estimator import run_config\nfrom tensorflow.python.ops.rnn import _transpose_batch_time\nfrom tensorflow.python.training import training\n\nBATCH_SIZE = 64\nSEQ_LENGTH = 32\nNUM_BATCHES = 1\n\ndef file_to_input_data(file, seq_length):\n    \"\"\"\n    Reads file, divides into train, validation, test sets and returns the\n    corresponding input source arrays\n    \"\"\"\n    with open(file, 'r') as f:\n        data = f.read()\n\n    char_array = np.array(list(data))\n    char_list, mapped_array = np.unique(char_array, return_inverse=True)\n\n    char_map = {c: i for i, c in enumerate(char_list)}\n    indices_char = {i: c for i, c in enumerate(char_list)}\n\n    num_unique_chars = char_list.shape[0]\n    dataset_size = mapped_array.shape[0]\n\n    # create the partitions\n    val_start = int(0.7 * dataset_size)\n    test_start = int(0.8 * dataset_size)\n    train_data, val_data, test_data = np.array_split(mapped_array,\n                                                     [val_start, test_start])\n\n    # truncate into multiple of seq length\n    def _truncate(x):\n        return x[:(x.shape[0] // seq_length) * seq_length]\n\n    return {\n        \"train\": _truncate(train_data),\n        \"val\": _truncate(val_data),\n        \"test\": _truncate(test_data),\n        \"vocab_size\": num_unique_chars,\n        \"char_map\": char_map,\n        \"indices_char\": indices_char\n    }\n\ndef shifted(x, value=0):\n    '''\n    returns target for a given linear sequence, x\n    '''\n    print(x.shape)\n\n    return np.append(x[1:],0)#np.pad(x[:-1], (1, 0), \"constant\", constant_values=value)\n\n\ndef data_from_file(file, seq_length):\n    \"\"\"Takes params, file, converts to one hot numpy arrays\n    and returns x, y, and vocab_size\"\"\"\n    text = open(file).read()[:10000] # for debugging\n    print(\"Corpus len:\", len(text))\n    chars = sorted(list(set(text)))\n    vocab_size = len(chars)\n    print('total chars:', len(chars))\n    char_indices = dict((c, i) for i, c in enumerate(chars))\n    indices_char = dict((i, c) for i, c in enumerate(chars))\n    sentences = []\n    next_chars = []\n    for i in range(0, len(text)-seq_length, 2):\n        sentences.append(text[i:i+seq_length]) #\"the cat in the ha\"\n        next_chars.append(text[i+seq_length])     #\"t\"\n    print(\"Vectorization...\")\n    x = np.zeros((len(sentences), seq_length, vocab_size), dtype=np.float32)\n    y = np.zeros((len(sentences), vocab_size), dtype=np.float32)\n    for i, sentence in enumerate(sentences):\n        for t, char in enumerate(sentence):\n            x[i, t, char_indices[char]] = 1\n        y[i, char_indices[next_chars[i]]] = 1\n    return {'x':x, 'y':y, 'vocab_size':vocab_size,'indices_char':indices_char,'char_indices':char_indices,'text':text}\n\n\ndef input_fn(params, mode):\n    batch_size = params.get('batch_size', BATCH_SIZE)\n    seq_length = params.get('seq_length', SEQ_LENGTH)\n    char_indices = params.get('char_indices', None)\n    num_classes = params.get('num_classes', None)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        x = params.get('x', None)#[:32000]  #[:batch_size*NUM_BATCHES]\n        #print(\"X SHAPE\", x.shape)\n        y = params.get('y', None) #size: (4984, 57) for 10,000 char sample\n        repeat_count = None\n    elif mode == tf.estimator.ModeKeys.EVAL:\n        data_source = params.get('val_data', None)\n        repeat_count = 1\n    elif mode == tf.estimator.ModeKeys.PREDICT:\n        sentence = params.get('seed_text')\n        char_indices = params.get('char_indices')\n\n\n        x = np.zeros((len(sentence)//seq_length, seq_length, num_classes), dtype=np.float32)\n        for t, char in enumerate(sentence):\n            x[0, t, char_indices[char]] = 1\n\n\n        #print(\"X SHAPE: \", x.shape)\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(1))\n        return ds\n\n    assert x is not None, \"Must supply the data\"\n\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\n    ds = ds.repeat(repeat_count)\n    ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n\n    return ds\n\n\ndef lstm_model_fn(features, labels, mode, params):\n    \"\"\" Basic RNN that uses LSTM Cells\n    features = input_tensors: one-hot tensors encoding the chars\n    mode: instance of tf.estimator.ModeKeys (e.g. ModeKeys.TRAIN)\n    rnn_type = GRU, LSTM, BasicRNN\n    params: dict specifying [learning_rate, seq_length, hidden_units]\"\"\"\n\n    with tf.device(\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"):\n        with tf.variable_scope(\"test_rnn\", use_resource=True):\n            num_classes = params.get(\"num_classes\")\n            batch_size = params.get('batch_size', BATCH_SIZE)\n            state_size = params.get(\"state_size\", 128)\n            seq_length = params.get(\"seq_length\", SEQ_LENGTH)\n\n        #     labels = tf.Print(labels, [labels, tf.shape(labels), \"LABELS SHAPE\"])\n\n            # input tensors need to be [batch_size x sentence_size x vocab_size]\n            #lstm_cell = tf.nn.rnn_cell.LSTMCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)#tf.nn.rnn_cell.BasicLSTMCell(state_size)\n            lstm_cell = tf.nn.rnn_cell.BasicRNNCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)\n            initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n            logits = None\n            predictions = None\n\n            if mode != tf.estimator.ModeKeys.PREDICT:\n                inputs=features\n                outputs,final_state=tf.contrib.recurrent.functional_rnn(cell=lstm_cell,\n                            inputs=inputs,initial_state=initial_state,scope=\"func\",\n                            sequence_length=seq_length,\n                            dtype= tf.float32)\n                #outputs = outputs_ta#.stack()\n\n                #outputs = _transpose_batch_time(outputs)\n        #         outputs = tf.Print(outputs, [outputs, tf.shape(outputs), \"outputs SHAPE\"])\n                with tf.variable_scope(\"rnn_final\",use_resource=True): #to allow prediction to call same function\n                    logits = tf.layers.dense(\n                        outputs, num_classes, name=\"final_layer\") #tf.reshape(outputs, [-1 , state_size])\n\n                logit_loss = logits[:,-1,:] #(64, 57) gets the prediction from the whole sequence\n                logit_loss = tf.reshape(logit_loss, (batch_size, num_classes))\n\n\n                predictions = tf.argmax(logits, axis=1,name=\"predictions\")\n\n            elif mode == tf.estimator.ModeKeys.PREDICT:\n                seed_length = len(params.get('seed_text'))\n                target_length = params.get('target_length')\n                inputs = features\n\n                outputs_ta,final_state=tf.contrib.recurrent.functional_rnn(lstm_cell,inputs,initial_state=initial_state,scope=\"func\")\n                predictions = outputs_ta.stack()\n\n                predictions = tf.Print(predictions, [predictions[90], \"PREDICTIONS\"])\n                return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n            loss = tf.reduce_mean(\n                    tf.nn.softmax_cross_entropy_with_logits(\n                    logits=logit_loss, labels=labels)) #tf.reshape(labels, [-1]))\n\n            optimizer = tf.train.MomentumOptimizer(learning_rate=0.15, momentum=0.97)\n\n            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n\n            if mode == tf.estimator.ModeKeys.TRAIN:\n                return tf.estimator.EstimatorSpec(\n                    mode=mode, loss=loss, train_op=train_op)\n            elif mode == tf.estimator.ModeKeys.EVAL:\n                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=metrics)\n\nif __name__ == \"__main__\":\n    tf.logging.set_verbosity(tf.logging.INFO)\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--train_file',\n        type=str,\n        default=os.path.expanduser(\"./input.txt\"),\n        help='where pre-processed data is stored')\n    parser.add_argument(\n        '--mode',\n        type=str,\n        default='train',\n        help='train, eval, or predict')\n    parser.add_argument(\n        '--num_states', type=int, default=128, help='size of each rnn layer')\n    parser.add_argument(\n        '--seed_text', type=str, default=\"The Volsces have much corn; take\", help='seed for prediction mode')\n    parser.add_argument(\n        '--target_length', type=int, default=100, help='the output length of your given prediction')\n    parser.add_argument(\n        '--seq_length', type=int, default=SEQ_LENGTH, help='number of unrolled time steps')\n    parser.add_argument(\n        '--num_steps', type=int, default=10, help='number of training steps')\n    parser.add_argument(\n        '--batch_size', type=int, default=BATCH_SIZE, help=\"samples per batch\")\n    args = parser.parse_args()\n\n    data = data_from_file(args.train_file, seq_length=args.seq_length)\n\n    classifier = tf.estimator.Estimator(\n        model_fn=lstm_model_fn,\n        params={\n            'num_classes': data[\"vocab_size\"],\n            'state_size': args.num_states,\n            'batch_size': args.batch_size,\n            'seq_length': args.seq_length,\n            'x': data[\"x\"],\n            'y': data['y'],\n            'char_indices': data[\"char_indices\"],\n            'seed_text': args.seed_text,\n            'target_length': args.target_length,\n        },\n        config=run_config.RunConfig(\n            save_summary_steps=10,\n            save_checkpoints_steps=100,\n            model_dir=\"./model\"))\n\n    classifier.train(input_fn, steps=args.num_steps)\n\nthis is the stacktrace of the error:\n2018-09-25 10:54:39.604560: E tensorflow/core/common_runtime/executor.cc:697] Executor failed to create kernel. Not found: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\n  device='CPU'; dtype in [DT_BOOL]\n  device='CPU'; dtype in [DT_INT64]\n  device='CPU'; dtype in [DT_INT32]\n  device='CPU'; dtype in [DT_STRING]\n  device='CPU'; dtype in [DT_HALF]\n  device='CPU'; dtype in [DT_DOUBLE]\n  device='CPU'; dtype in [DT_FLOAT]\n\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\nTraceback (most recent call last):\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\n    return fn(*args)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\n  device='CPU'; dtype in [DT_BOOL]\n  device='CPU'; dtype in [DT_INT64]\n  device='CPU'; dtype in [DT_INT32]\n  device='CPU'; dtype in [DT_STRING]\n  device='CPU'; dtype in [DT_HALF]\n  device='CPU'; dtype in [DT_DOUBLE]\n  device='CPU'; dtype in [DT_FLOAT]\n\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\n\t [[Node: test_rnn/Forward_MIH5xlXOmdc = Forward_MIH5xlXOmdc[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_4/_5, cluster_31/_2/_3, cluster_28/_8/_9, cluster_26/_12/_13, cluster_29/_6/_7/_69)]]\n\t [[Node: cluster_27/_10/_11/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_cluster_27/_10/_11\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"basic_rnn.py\", line 236, in <module>\n    classifier.train(input_fn, steps=args.num_steps)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\n    saving_listeners)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 583, in run\n    run_metadata=run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1059, in run\n    run_metadata=run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1150, in run\n    raise six.reraise(*original_exc_info)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/six.py\", line 693, in reraise\n    raise value\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1135, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1207, in run\n    run_metadata=run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 987, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 877, in run\n    run_metadata_ptr)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\n    run_metadata)\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\n  device='CPU'; dtype in [DT_BOOL]\n  device='CPU'; dtype in [DT_INT64]\n  device='CPU'; dtype in [DT_INT32]\n  device='CPU'; dtype in [DT_STRING]\n  device='CPU'; dtype in [DT_HALF]\n  device='CPU'; dtype in [DT_DOUBLE]\n  device='CPU'; dtype in [DT_FLOAT]\n\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\n\t [[Node: test_rnn/Forward_MIH5xlXOmdc = Forward_MIH5xlXOmdc[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_4/_5, cluster_31/_2/_3, cluster_28/_8/_9, cluster_26/_12/_13, cluster_29/_6/_7/_69)]]\n\t [[Node: cluster_27/_10/_11/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_cluster_27/_10/_11\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]", "body": "This is the input for the code\r\n[input.txt](https://github.com/tensorflow/tensorflow/files/2416432/input.txt)\r\n\r\nThe code is:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\nimport argparse\r\nfrom tensorflow.python.estimator import run_config\r\nfrom tensorflow.python.ops.rnn import _transpose_batch_time\r\nfrom tensorflow.python.training import training\r\n\r\nBATCH_SIZE = 64\r\nSEQ_LENGTH = 32\r\nNUM_BATCHES = 1\r\n\r\ndef file_to_input_data(file, seq_length):\r\n    \"\"\"\r\n    Reads file, divides into train, validation, test sets and returns the\r\n    corresponding input source arrays\r\n    \"\"\"\r\n    with open(file, 'r') as f:\r\n        data = f.read()\r\n\r\n    char_array = np.array(list(data))\r\n    char_list, mapped_array = np.unique(char_array, return_inverse=True)\r\n\r\n    char_map = {c: i for i, c in enumerate(char_list)}\r\n    indices_char = {i: c for i, c in enumerate(char_list)}\r\n\r\n    num_unique_chars = char_list.shape[0]\r\n    dataset_size = mapped_array.shape[0]\r\n\r\n    # create the partitions\r\n    val_start = int(0.7 * dataset_size)\r\n    test_start = int(0.8 * dataset_size)\r\n    train_data, val_data, test_data = np.array_split(mapped_array,\r\n                                                     [val_start, test_start])\r\n\r\n    # truncate into multiple of seq length\r\n    def _truncate(x):\r\n        return x[:(x.shape[0] // seq_length) * seq_length]\r\n\r\n    return {\r\n        \"train\": _truncate(train_data),\r\n        \"val\": _truncate(val_data),\r\n        \"test\": _truncate(test_data),\r\n        \"vocab_size\": num_unique_chars,\r\n        \"char_map\": char_map,\r\n        \"indices_char\": indices_char\r\n    }\r\n\r\ndef shifted(x, value=0):\r\n    '''\r\n    returns target for a given linear sequence, x\r\n    '''\r\n    print(x.shape)\r\n\r\n    return np.append(x[1:],0)#np.pad(x[:-1], (1, 0), \"constant\", constant_values=value)\r\n\r\n\r\ndef data_from_file(file, seq_length):\r\n    \"\"\"Takes params, file, converts to one hot numpy arrays\r\n    and returns x, y, and vocab_size\"\"\"\r\n    text = open(file).read()[:10000] # for debugging\r\n    print(\"Corpus len:\", len(text))\r\n    chars = sorted(list(set(text)))\r\n    vocab_size = len(chars)\r\n    print('total chars:', len(chars))\r\n    char_indices = dict((c, i) for i, c in enumerate(chars))\r\n    indices_char = dict((i, c) for i, c in enumerate(chars))\r\n    sentences = []\r\n    next_chars = []\r\n    for i in range(0, len(text)-seq_length, 2):\r\n        sentences.append(text[i:i+seq_length]) #\"the cat in the ha\"\r\n        next_chars.append(text[i+seq_length])     #\"t\"\r\n    print(\"Vectorization...\")\r\n    x = np.zeros((len(sentences), seq_length, vocab_size), dtype=np.float32)\r\n    y = np.zeros((len(sentences), vocab_size), dtype=np.float32)\r\n    for i, sentence in enumerate(sentences):\r\n        for t, char in enumerate(sentence):\r\n            x[i, t, char_indices[char]] = 1\r\n        y[i, char_indices[next_chars[i]]] = 1\r\n    return {'x':x, 'y':y, 'vocab_size':vocab_size,'indices_char':indices_char,'char_indices':char_indices,'text':text}\r\n\r\n\r\ndef input_fn(params, mode):\r\n    batch_size = params.get('batch_size', BATCH_SIZE)\r\n    seq_length = params.get('seq_length', SEQ_LENGTH)\r\n    char_indices = params.get('char_indices', None)\r\n    num_classes = params.get('num_classes', None)\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        x = params.get('x', None)#[:32000]  #[:batch_size*NUM_BATCHES]\r\n        #print(\"X SHAPE\", x.shape)\r\n        y = params.get('y', None) #size: (4984, 57) for 10,000 char sample\r\n        repeat_count = None\r\n    elif mode == tf.estimator.ModeKeys.EVAL:\r\n        data_source = params.get('val_data', None)\r\n        repeat_count = 1\r\n    elif mode == tf.estimator.ModeKeys.PREDICT:\r\n        sentence = params.get('seed_text')\r\n        char_indices = params.get('char_indices')\r\n\r\n\r\n        x = np.zeros((len(sentence)//seq_length, seq_length, num_classes), dtype=np.float32)\r\n        for t, char in enumerate(sentence):\r\n            x[0, t, char_indices[char]] = 1\r\n\r\n\r\n        #print(\"X SHAPE: \", x.shape)\r\n        ds = tf.data.Dataset.from_tensor_slices(x)\r\n        ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(1))\r\n        return ds\r\n\r\n    assert x is not None, \"Must supply the data\"\r\n\r\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\r\n    ds = ds.repeat(repeat_count)\r\n    ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n\r\n    return ds\r\n\r\n\r\ndef lstm_model_fn(features, labels, mode, params):\r\n    \"\"\" Basic RNN that uses LSTM Cells\r\n    features = input_tensors: one-hot tensors encoding the chars\r\n    mode: instance of tf.estimator.ModeKeys (e.g. ModeKeys.TRAIN)\r\n    rnn_type = GRU, LSTM, BasicRNN\r\n    params: dict specifying [learning_rate, seq_length, hidden_units]\"\"\"\r\n\r\n    with tf.device(\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"):\r\n        with tf.variable_scope(\"test_rnn\", use_resource=True):\r\n            num_classes = params.get(\"num_classes\")\r\n            batch_size = params.get('batch_size', BATCH_SIZE)\r\n            state_size = params.get(\"state_size\", 128)\r\n            seq_length = params.get(\"seq_length\", SEQ_LENGTH)\r\n\r\n        #     labels = tf.Print(labels, [labels, tf.shape(labels), \"LABELS SHAPE\"])\r\n\r\n            # input tensors need to be [batch_size x sentence_size x vocab_size]\r\n            #lstm_cell = tf.nn.rnn_cell.LSTMCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)#tf.nn.rnn_cell.BasicLSTMCell(state_size)\r\n            lstm_cell = tf.nn.rnn_cell.BasicRNNCell(state_size,name=\"lstm_cell\",reuse=tf.AUTO_REUSE)\r\n            initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\r\n            logits = None\r\n            predictions = None\r\n\r\n            if mode != tf.estimator.ModeKeys.PREDICT:\r\n                inputs=features\r\n                outputs,final_state=tf.contrib.recurrent.functional_rnn(cell=lstm_cell,\r\n                            inputs=inputs,initial_state=initial_state,scope=\"func\",\r\n                            sequence_length=seq_length,\r\n                            dtype= tf.float32)\r\n                #outputs = outputs_ta#.stack()\r\n\r\n                #outputs = _transpose_batch_time(outputs)\r\n        #         outputs = tf.Print(outputs, [outputs, tf.shape(outputs), \"outputs SHAPE\"])\r\n                with tf.variable_scope(\"rnn_final\",use_resource=True): #to allow prediction to call same function\r\n                    logits = tf.layers.dense(\r\n                        outputs, num_classes, name=\"final_layer\") #tf.reshape(outputs, [-1 , state_size])\r\n\r\n                logit_loss = logits[:,-1,:] #(64, 57) gets the prediction from the whole sequence\r\n                logit_loss = tf.reshape(logit_loss, (batch_size, num_classes))\r\n\r\n\r\n                predictions = tf.argmax(logits, axis=1,name=\"predictions\")\r\n\r\n            elif mode == tf.estimator.ModeKeys.PREDICT:\r\n                seed_length = len(params.get('seed_text'))\r\n                target_length = params.get('target_length')\r\n                inputs = features\r\n\r\n                outputs_ta,final_state=tf.contrib.recurrent.functional_rnn(lstm_cell,inputs,initial_state=initial_state,scope=\"func\")\r\n                predictions = outputs_ta.stack()\r\n\r\n                predictions = tf.Print(predictions, [predictions[90], \"PREDICTIONS\"])\r\n                return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n            loss = tf.reduce_mean(\r\n                    tf.nn.softmax_cross_entropy_with_logits(\r\n                    logits=logit_loss, labels=labels)) #tf.reshape(labels, [-1]))\r\n\r\n            optimizer = tf.train.MomentumOptimizer(learning_rate=0.15, momentum=0.97)\r\n\r\n            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\r\n\r\n            if mode == tf.estimator.ModeKeys.TRAIN:\r\n                return tf.estimator.EstimatorSpec(\r\n                    mode=mode, loss=loss, train_op=train_op)\r\n            elif mode == tf.estimator.ModeKeys.EVAL:\r\n                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=metrics)\r\n\r\nif __name__ == \"__main__\":\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\r\n        '--train_file',\r\n        type=str,\r\n        default=os.path.expanduser(\"./input.txt\"),\r\n        help='where pre-processed data is stored')\r\n    parser.add_argument(\r\n        '--mode',\r\n        type=str,\r\n        default='train',\r\n        help='train, eval, or predict')\r\n    parser.add_argument(\r\n        '--num_states', type=int, default=128, help='size of each rnn layer')\r\n    parser.add_argument(\r\n        '--seed_text', type=str, default=\"The Volsces have much corn; take\", help='seed for prediction mode')\r\n    parser.add_argument(\r\n        '--target_length', type=int, default=100, help='the output length of your given prediction')\r\n    parser.add_argument(\r\n        '--seq_length', type=int, default=SEQ_LENGTH, help='number of unrolled time steps')\r\n    parser.add_argument(\r\n        '--num_steps', type=int, default=10, help='number of training steps')\r\n    parser.add_argument(\r\n        '--batch_size', type=int, default=BATCH_SIZE, help=\"samples per batch\")\r\n    args = parser.parse_args()\r\n\r\n    data = data_from_file(args.train_file, seq_length=args.seq_length)\r\n\r\n    classifier = tf.estimator.Estimator(\r\n        model_fn=lstm_model_fn,\r\n        params={\r\n            'num_classes': data[\"vocab_size\"],\r\n            'state_size': args.num_states,\r\n            'batch_size': args.batch_size,\r\n            'seq_length': args.seq_length,\r\n            'x': data[\"x\"],\r\n            'y': data['y'],\r\n            'char_indices': data[\"char_indices\"],\r\n            'seed_text': args.seed_text,\r\n            'target_length': args.target_length,\r\n        },\r\n        config=run_config.RunConfig(\r\n            save_summary_steps=10,\r\n            save_checkpoints_steps=100,\r\n            model_dir=\"./model\"))\r\n\r\n    classifier.train(input_fn, steps=args.num_steps)\r\n```\r\n\r\n\r\n\r\nthis is the stacktrace of the error: \r\n```\r\n2018-09-25 10:54:39.604560: E tensorflow/core/common_runtime/executor.cc:697] Executor failed to create kernel. Not found: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\r\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\r\n  device='CPU'; dtype in [DT_BOOL]\r\n  device='CPU'; dtype in [DT_INT64]\r\n  device='CPU'; dtype in [DT_INT32]\r\n  device='CPU'; dtype in [DT_STRING]\r\n  device='CPU'; dtype in [DT_HALF]\r\n  device='CPU'; dtype in [DT_DOUBLE]\r\n  device='CPU'; dtype in [DT_FLOAT]\r\n\r\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\r\nTraceback (most recent call last):\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n    return fn(*args)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\r\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\r\n  device='CPU'; dtype in [DT_BOOL]\r\n  device='CPU'; dtype in [DT_INT64]\r\n  device='CPU'; dtype in [DT_INT32]\r\n  device='CPU'; dtype in [DT_STRING]\r\n  device='CPU'; dtype in [DT_HALF]\r\n  device='CPU'; dtype in [DT_DOUBLE]\r\n  device='CPU'; dtype in [DT_FLOAT]\r\n\r\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\r\n\t [[Node: test_rnn/Forward_MIH5xlXOmdc = Forward_MIH5xlXOmdc[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_4/_5, cluster_31/_2/_3, cluster_28/_8/_9, cluster_26/_12/_13, cluster_29/_6/_7/_69)]]\r\n\t [[Node: cluster_27/_10/_11/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_cluster_27/_10/_11\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"basic_rnn.py\", line 236, in <module>\r\n    classifier.train(input_fn, steps=args.num_steps)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\r\n    saving_listeners)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 583, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1059, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1150, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1135, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 1207, in run\r\n    run_metadata=run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 987, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n    run_metadata_ptr)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n    run_metadata)\r\n  File \"/net/server5/srv/nfs/vishal-data/ws/venv_tf110/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Empty' OpKernel for XLA_CPU devices compatible with node Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)\r\n\t.  Registered:  device='CPU'; dtype in [DT_UINT8]\r\n  device='CPU'; dtype in [DT_BOOL]\r\n  device='CPU'; dtype in [DT_INT64]\r\n  device='CPU'; dtype in [DT_INT32]\r\n  device='CPU'; dtype in [DT_STRING]\r\n  device='CPU'; dtype in [DT_HALF]\r\n  device='CPU'; dtype in [DT_DOUBLE]\r\n  device='CPU'; dtype in [DT_FLOAT]\r\n\r\n\t [[Node: Empty = Empty[dtype=DT_FLOAT, init=true, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](concat)]]\r\n\t [[Node: test_rnn/Forward_MIH5xlXOmdc = Forward_MIH5xlXOmdc[_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](cluster_30/_4/_5, cluster_31/_2/_3, cluster_28/_8/_9, cluster_26/_12/_13, cluster_29/_6/_7/_69)]]\r\n\t [[Node: cluster_27/_10/_11/_74 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_cluster_27/_10/_11\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```"}