{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9962", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9962/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9962/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9962/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9962", "id": 229285953, "node_id": "MDU6SXNzdWUyMjkyODU5NTM=", "number": 9962, "title": "tf.contrib.seq2seq attention_wrapper.py memory_sequence_length can not set None", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-05-17T09:11:36Z", "updated_at": "2017-06-09T15:43:05Z", "closed_at": "2017-06-09T15:43:05Z", "author_association": "NONE", "body_html": "<p>tf version '1.1.0-rc2'<br>\nThe problem is in attention_wrapper.py  77<br>\nmemory_sequence_length = ops.convert_to_tensor(<br>\nmemory_sequence_length, name=\"memory_sequence_length\")</p>\n<p>Don't check if memory_sequence_length is None</p>", "body_text": "tf version '1.1.0-rc2'\nThe problem is in attention_wrapper.py  77\nmemory_sequence_length = ops.convert_to_tensor(\nmemory_sequence_length, name=\"memory_sequence_length\")\nDon't check if memory_sequence_length is None", "body": "tf version '1.1.0-rc2'\r\nThe problem is in attention_wrapper.py  77 \r\n  memory_sequence_length = ops.convert_to_tensor(\r\n      memory_sequence_length, name=\"memory_sequence_length\")\r\n\r\nDon't check if memory_sequence_length is None"}