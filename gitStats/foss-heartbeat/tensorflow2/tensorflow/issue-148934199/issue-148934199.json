{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1997", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1997/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1997/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1997/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1997", "id": 148934199, "node_id": "MDU6SXNzdWUxNDg5MzQxOTk=", "number": 1997, "title": "Training accuracy falling down after some epoches since upgrading to 0.8.0rc0", "user": {"login": "mrphoenix13", "id": 9256665, "node_id": "MDQ6VXNlcjkyNTY2NjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/9256665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrphoenix13", "html_url": "https://github.com/mrphoenix13", "followers_url": "https://api.github.com/users/mrphoenix13/followers", "following_url": "https://api.github.com/users/mrphoenix13/following{/other_user}", "gists_url": "https://api.github.com/users/mrphoenix13/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrphoenix13/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrphoenix13/subscriptions", "organizations_url": "https://api.github.com/users/mrphoenix13/orgs", "repos_url": "https://api.github.com/users/mrphoenix13/repos", "events_url": "https://api.github.com/users/mrphoenix13/events{/privacy}", "received_events_url": "https://api.github.com/users/mrphoenix13/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-04-17T09:19:16Z", "updated_at": "2016-12-09T01:09:42Z", "closed_at": "2016-04-30T06:59:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm trying to use a simple network to classify some 64*64 images. in v0.7 it worked fine and consistent. The training phase was showing a consistent  average growth in accuracy. But since I'm trying to use 0.8, the accuracy fall down occasionally from ~0.9 to ~0!<br>\nI'm using cpu  version for python 2.7</p>\n<p>is it a bug in TF or I'm doing something wrong?</p>\n<h6></h6>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04<br>\nI've installed pip with the following command : sudo apt-get install python-pip python-dev</p>\n<ol>\n<li>The output from python -c \"import tensorflow; print(tensorflow.<strong>version</strong>)\".<br>\n0.8.0rc0<br>\n#############################################\n<h3>my learning code is as below:</h3>\n</li>\n</ol>\n<pre><code>sess = tf.InteractiveSession()\n\nx = tf.placeholder(tf.float32, shape=[None, 64,64])\ny_ = tf.placeholder(tf.float32, shape=[None, 31])\ninput = tf.reshape(x,shape=[-1,64*64])\nw1 = tf.Variable(tf.random_uniform([64*64,128],minval=-0.1,maxval=0.1),dtype=tf.float32)\nb1 = tf.Variable(tf.random_uniform([128],minval=-0.1,maxval=0.1),dtype=tf.float32);\ny1_ = tf.nn.softmax(tf.matmul(input, w1) + b1)\nkeep_prob = tf.placeholder(tf.float32)\ny1 = tf.nn.dropout(y1_, keep_prob)\nw2 = tf.Variable(tf.random_uniform([128,31],minval=-0.1,maxval=0.1),dtype=tf.float32)\nb2 = tf.Variable(tf.random_uniform([31],minval=-0.1,maxval=0.1),dtype=tf.float32);\ny2 = tf.nn.softmax(tf.matmul(y1, w2) + b2)\ncross_entropy = -tf.reduce_sum(y_*tf.log(y2))\nlearn_rate = tf.placeholder(tf.float32)\ntrain_step = tf.train.AdamOptimizer(learn_rate).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y2,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nsess.run(tf.initialize_all_variables())\nd = Dataset()\ndat = d.load()\nfor i in range(9000):\n    if i%200==0:\n        a = accuracy.eval(feed_dict={x: dat.data, y_: dat.label,keep_prob: 1.0,learn_rate:1e-2})\n        print(\"step %d, training accuracy %g\" % (i, a))\n    train_step.run(feed_dict={x: dat.data, y_: dat.label,keep_prob: 0.8 ,learn_rate:1e-2})\n\nfor i in range(5000):\n    if i%100==0:\n        a = accuracy.eval(feed_dict={x: dat.data, y_: dat.label,keep_prob: 1.0,learn_rate:1e-3})\n        print(\"step %d, training accuracy %g\" % (i, a))\n    train_step.run(feed_dict={x: dat.data, y_: dat.label,keep_prob: 0.8,learn_rate:1e-3 })\n</code></pre>\n<h1></h1>\n<p>some line of the output is as below:<br>\nstep 7400, training accuracy 0.870539<br>\nstep 7600, training accuracy 0.875406<br>\nstep 7800, training accuracy 0.877677<br>\nstep 8000, training accuracy 0.882868<br>\nstep 8200, training accuracy 0.884491<br>\nstep 8400, training accuracy 0.887735<br>\nstep 8600, training accuracy 0.888709<br>\nstep 8800, training accuracy 0.893251<br>\nstep 0, training accuracy 0.894549<br>\nstep 100, training accuracy 0.895198<br>\nstep 200, training accuracy 0.894873<br>\nstep 300, training accuracy 0.895198<br>\nstep 400, training accuracy 0.894873<br>\nstep 500, training accuracy 0.895198<br>\nstep 600, training accuracy 0.895198<br>\nstep 700, training accuracy 0.895522<br>\nstep 800, training accuracy 0.895522<br>\nstep 900, training accuracy 0.895847<br>\nstep 1000, training accuracy 0.896171<br>\nstep 1100, training accuracy 0.896171<br>\nstep 1200, training accuracy 0.896496<br>\nstep 1300, training accuracy 0.89682<br>\nstep 1400, training accuracy 0<br>\nstep 1500, training accuracy 0<br>\nstep 1600, training accuracy 0<br>\nstep 1700, training accuracy 0</p>", "body_text": "I'm trying to use a simple network to classify some 64*64 images. in v0.7 it worked fine and consistent. The training phase was showing a consistent  average growth in accuracy. But since I'm trying to use 0.8, the accuracy fall down occasionally from ~0.9 to ~0!\nI'm using cpu  version for python 2.7\nis it a bug in TF or I'm doing something wrong?\n\nEnvironment info\nOperating System: Ubuntu 14.04\nI've installed pip with the following command : sudo apt-get install python-pip python-dev\n\nThe output from python -c \"import tensorflow; print(tensorflow.version)\".\n0.8.0rc0\n#############################################\nmy learning code is as below:\n\n\nsess = tf.InteractiveSession()\n\nx = tf.placeholder(tf.float32, shape=[None, 64,64])\ny_ = tf.placeholder(tf.float32, shape=[None, 31])\ninput = tf.reshape(x,shape=[-1,64*64])\nw1 = tf.Variable(tf.random_uniform([64*64,128],minval=-0.1,maxval=0.1),dtype=tf.float32)\nb1 = tf.Variable(tf.random_uniform([128],minval=-0.1,maxval=0.1),dtype=tf.float32);\ny1_ = tf.nn.softmax(tf.matmul(input, w1) + b1)\nkeep_prob = tf.placeholder(tf.float32)\ny1 = tf.nn.dropout(y1_, keep_prob)\nw2 = tf.Variable(tf.random_uniform([128,31],minval=-0.1,maxval=0.1),dtype=tf.float32)\nb2 = tf.Variable(tf.random_uniform([31],minval=-0.1,maxval=0.1),dtype=tf.float32);\ny2 = tf.nn.softmax(tf.matmul(y1, w2) + b2)\ncross_entropy = -tf.reduce_sum(y_*tf.log(y2))\nlearn_rate = tf.placeholder(tf.float32)\ntrain_step = tf.train.AdamOptimizer(learn_rate).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y2,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nsess.run(tf.initialize_all_variables())\nd = Dataset()\ndat = d.load()\nfor i in range(9000):\n    if i%200==0:\n        a = accuracy.eval(feed_dict={x: dat.data, y_: dat.label,keep_prob: 1.0,learn_rate:1e-2})\n        print(\"step %d, training accuracy %g\" % (i, a))\n    train_step.run(feed_dict={x: dat.data, y_: dat.label,keep_prob: 0.8 ,learn_rate:1e-2})\n\nfor i in range(5000):\n    if i%100==0:\n        a = accuracy.eval(feed_dict={x: dat.data, y_: dat.label,keep_prob: 1.0,learn_rate:1e-3})\n        print(\"step %d, training accuracy %g\" % (i, a))\n    train_step.run(feed_dict={x: dat.data, y_: dat.label,keep_prob: 0.8,learn_rate:1e-3 })\n\n\nsome line of the output is as below:\nstep 7400, training accuracy 0.870539\nstep 7600, training accuracy 0.875406\nstep 7800, training accuracy 0.877677\nstep 8000, training accuracy 0.882868\nstep 8200, training accuracy 0.884491\nstep 8400, training accuracy 0.887735\nstep 8600, training accuracy 0.888709\nstep 8800, training accuracy 0.893251\nstep 0, training accuracy 0.894549\nstep 100, training accuracy 0.895198\nstep 200, training accuracy 0.894873\nstep 300, training accuracy 0.895198\nstep 400, training accuracy 0.894873\nstep 500, training accuracy 0.895198\nstep 600, training accuracy 0.895198\nstep 700, training accuracy 0.895522\nstep 800, training accuracy 0.895522\nstep 900, training accuracy 0.895847\nstep 1000, training accuracy 0.896171\nstep 1100, training accuracy 0.896171\nstep 1200, training accuracy 0.896496\nstep 1300, training accuracy 0.89682\nstep 1400, training accuracy 0\nstep 1500, training accuracy 0\nstep 1600, training accuracy 0\nstep 1700, training accuracy 0", "body": "I'm trying to use a simple network to classify some 64*64 images. in v0.7 it worked fine and consistent. The training phase was showing a consistent  average growth in accuracy. But since I'm trying to use 0.8, the accuracy fall down occasionally from ~0.9 to ~0!\nI'm using cpu  version for python 2.7\n\nis it a bug in TF or I'm doing something wrong?\n###### \n### Environment info\n\nOperating System: Ubuntu 14.04\nI've installed pip with the following command : sudo apt-get install python-pip python-dev\n1. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   0.8.0rc0\n   #############################################\n   ### my learning code is as below:\n\n```\nsess = tf.InteractiveSession()\n\nx = tf.placeholder(tf.float32, shape=[None, 64,64])\ny_ = tf.placeholder(tf.float32, shape=[None, 31])\ninput = tf.reshape(x,shape=[-1,64*64])\nw1 = tf.Variable(tf.random_uniform([64*64,128],minval=-0.1,maxval=0.1),dtype=tf.float32)\nb1 = tf.Variable(tf.random_uniform([128],minval=-0.1,maxval=0.1),dtype=tf.float32);\ny1_ = tf.nn.softmax(tf.matmul(input, w1) + b1)\nkeep_prob = tf.placeholder(tf.float32)\ny1 = tf.nn.dropout(y1_, keep_prob)\nw2 = tf.Variable(tf.random_uniform([128,31],minval=-0.1,maxval=0.1),dtype=tf.float32)\nb2 = tf.Variable(tf.random_uniform([31],minval=-0.1,maxval=0.1),dtype=tf.float32);\ny2 = tf.nn.softmax(tf.matmul(y1, w2) + b2)\ncross_entropy = -tf.reduce_sum(y_*tf.log(y2))\nlearn_rate = tf.placeholder(tf.float32)\ntrain_step = tf.train.AdamOptimizer(learn_rate).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y2,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nsess.run(tf.initialize_all_variables())\nd = Dataset()\ndat = d.load()\nfor i in range(9000):\n    if i%200==0:\n        a = accuracy.eval(feed_dict={x: dat.data, y_: dat.label,keep_prob: 1.0,learn_rate:1e-2})\n        print(\"step %d, training accuracy %g\" % (i, a))\n    train_step.run(feed_dict={x: dat.data, y_: dat.label,keep_prob: 0.8 ,learn_rate:1e-2})\n\nfor i in range(5000):\n    if i%100==0:\n        a = accuracy.eval(feed_dict={x: dat.data, y_: dat.label,keep_prob: 1.0,learn_rate:1e-3})\n        print(\"step %d, training accuracy %g\" % (i, a))\n    train_step.run(feed_dict={x: dat.data, y_: dat.label,keep_prob: 0.8,learn_rate:1e-3 })\n```\n# \n\nsome line of the output is as below:\nstep 7400, training accuracy 0.870539\nstep 7600, training accuracy 0.875406\nstep 7800, training accuracy 0.877677\nstep 8000, training accuracy 0.882868\nstep 8200, training accuracy 0.884491\nstep 8400, training accuracy 0.887735\nstep 8600, training accuracy 0.888709\nstep 8800, training accuracy 0.893251\nstep 0, training accuracy 0.894549\nstep 100, training accuracy 0.895198\nstep 200, training accuracy 0.894873\nstep 300, training accuracy 0.895198\nstep 400, training accuracy 0.894873\nstep 500, training accuracy 0.895198\nstep 600, training accuracy 0.895198\nstep 700, training accuracy 0.895522\nstep 800, training accuracy 0.895522\nstep 900, training accuracy 0.895847\nstep 1000, training accuracy 0.896171\nstep 1100, training accuracy 0.896171\nstep 1200, training accuracy 0.896496\nstep 1300, training accuracy 0.89682\nstep 1400, training accuracy 0\nstep 1500, training accuracy 0\nstep 1600, training accuracy 0\nstep 1700, training accuracy 0\n"}