{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5302", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5302/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5302/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5302/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5302", "id": 186288865, "node_id": "MDU6SXNzdWUxODYyODg4NjU=", "number": 5302, "title": "C++ memory leak after `Session::Close()` /  C++ equivalent to Python `reset_default_graph()` ?", "user": {"login": "beniz", "id": 3530657, "node_id": "MDQ6VXNlcjM1MzA2NTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/3530657?v=4", "gravatar_id": "", "url": "https://api.github.com/users/beniz", "html_url": "https://github.com/beniz", "followers_url": "https://api.github.com/users/beniz/followers", "following_url": "https://api.github.com/users/beniz/following{/other_user}", "gists_url": "https://api.github.com/users/beniz/gists{/gist_id}", "starred_url": "https://api.github.com/users/beniz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/beniz/subscriptions", "organizations_url": "https://api.github.com/users/beniz/orgs", "repos_url": "https://api.github.com/users/beniz/repos", "events_url": "https://api.github.com/users/beniz/events{/privacy}", "received_events_url": "https://api.github.com/users/beniz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-10-31T13:54:18Z", "updated_at": "2018-09-04T13:39:59Z", "closed_at": "2016-10-31T21:46:10Z", "author_association": "NONE", "body_html": "<p>Using C++ API, memory (RAM) does not appear to be fully released after <code>Session::Close()</code> is called.</p>\n<p>See code snippet below. Running it within a loop eventually eats up all RAM and gets killed by system.</p>\n<p>From reading around, I understand that the closing of the session does not release the underlying graph. In Python it seems that <code>reset_default_graph()</code> releases the graph resources.</p>\n<p>Is there any equivalent to <code>reset_default_graph()</code> in C++ ?</p>\n<p>I initially reported this question on the mailing list, <a href=\"https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/NG7n6emda78\" rel=\"nofollow\">https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/NG7n6emda78</a> with no echo, so posted as an issue here. My apologies if this isn't the right procedure.</p>\n<p>Note:<br>\nGPU memory appears to not be released when looking it up with <code>nvidia-smi</code> but I believe it is an <code>nvidia-smi</code> problem as in practice the GPU memory appears to be reusable, so no problem on this side.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p><a href=\"http://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session\" rel=\"nofollow\">http://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"142647609\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1578\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1578/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1578\">#1578</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"143933355\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/keras-team/keras/issues/2102\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/2102/hovercard\" href=\"https://github.com/keras-team/keras/issues/2102\">keras-team/keras#2102</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"125054784\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/700\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/700/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/700\">#700</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"162978874\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3106\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3106/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/3106\">#3106</a></p>\n<h3>Environment info</h3>\n<p>Operating System:</p>\n<p>Ubuntu 16.04 LTS</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<pre><code>-rw-r--r-- 1 root root   560184 Sep  7 18:22 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Sep  7 18:22 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn_static.a\n</code></pre>\n<h3>From source installation</h3>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)</li>\n</ol>\n<pre><code>5c1ca717e8ddd16b0be8410a798dc174380a600d\n</code></pre>\n<ol start=\"2\">\n<li>The output of <code>bazel version</code></li>\n</ol>\n<pre><code>Build label: 0.3.2\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Oct 7 17:25:10 2016 (1475861110)\nBuild timestamp: 1475861110\nBuild timestamp as int: 1475861110\n</code></pre>\n<h3>Short code snippet</h3>\n<p>Put the code below into a loop, and RAM keeps on growing, replace <code>_inputLayer</code> and <code>_outputLayer</code> with proper network layer names, and <code>vtfinputs</code> is a <code>std::vector&lt;tensorflow::Tensor&gt;</code>.</p>\n<div class=\"highlight highlight-source-c++\"><pre>tensorflow::GraphDef graph_def;\ntensorflow::Status graphLoadedStatus = ReadBinaryProto(tensorflow::Env::Default(),graphFile,&amp;graph_def);\ntensorflow::SessionOptions options;\ntensorflow::ConfigProto &amp;config = options.config;\nconfig.mutable_gpu_options()-&gt;<span class=\"pl-en\">set_allow_growth</span>(<span class=\"pl-c1\">true</span>);\nstd::unique_ptr&lt;tensorflow::Session&gt; session = std::unique_ptr&lt;tensorflow::Session&gt;(tensorflow::NewSession(options));\ntensorflow::Status session_create_status = session-&gt;<span class=\"pl-en\">Create</span>(graph_def);                                                        \n...                                                                               \ntensorflow::Status run_status  = session-&gt;<span class=\"pl-en\">Run</span>({{_inputLayer,*(vtfinputs.<span class=\"pl-c1\">begin</span>())}},{_outputLayer},{},&amp;finalOutput)  <span class=\"pl-c\"><span class=\"pl-c\">/*</span> runs file, results are what they should be, and are acquired via finalOutput. <span class=\"pl-c\">*/</span></span>\n...\nsession-&gt;Close();                                                                                                          \nsession.reset();\n\n<span class=\"pl-c\"><span class=\"pl-c\">/*</span> RAM keeps building up if code above put into a loop <span class=\"pl-c\">*/</span></span></pre></div>\n<h3>What other attempted solutions have you tried?</h3>\n<p>using <code>session-&gt;Reset(options,containers)</code> does not appear to compile (Reset does not exist for Session). Looking at <code>session.h</code> and <code>direct_session.h</code> I don't yet understand why this is the case.</p>", "body_text": "Using C++ API, memory (RAM) does not appear to be fully released after Session::Close() is called.\nSee code snippet below. Running it within a loop eventually eats up all RAM and gets killed by system.\nFrom reading around, I understand that the closing of the session does not release the underlying graph. In Python it seems that reset_default_graph() releases the graph resources.\nIs there any equivalent to reset_default_graph() in C++ ?\nI initially reported this question on the mailing list, https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/NG7n6emda78 with no echo, so posted as an issue here. My apologies if this isn't the right procedure.\nNote:\nGPU memory appears to not be released when looking it up with nvidia-smi but I believe it is an nvidia-smi problem as in practice the GPU memory appears to be reusable, so no problem on this side.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nhttp://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session\n#1578\nkeras-team/keras#2102\n#700\n#3106\nEnvironment info\nOperating System:\nUbuntu 16.04 LTS\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n-rw-r--r-- 1 root root   560184 Sep  7 18:22 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Sep  7 18:22 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn_static.a\n\nFrom source installation\n\nThe commit hash (git rev-parse HEAD)\n\n5c1ca717e8ddd16b0be8410a798dc174380a600d\n\n\nThe output of bazel version\n\nBuild label: 0.3.2\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Oct 7 17:25:10 2016 (1475861110)\nBuild timestamp: 1475861110\nBuild timestamp as int: 1475861110\n\nShort code snippet\nPut the code below into a loop, and RAM keeps on growing, replace _inputLayer and _outputLayer with proper network layer names, and vtfinputs is a std::vector<tensorflow::Tensor>.\ntensorflow::GraphDef graph_def;\ntensorflow::Status graphLoadedStatus = ReadBinaryProto(tensorflow::Env::Default(),graphFile,&graph_def);\ntensorflow::SessionOptions options;\ntensorflow::ConfigProto &config = options.config;\nconfig.mutable_gpu_options()->set_allow_growth(true);\nstd::unique_ptr<tensorflow::Session> session = std::unique_ptr<tensorflow::Session>(tensorflow::NewSession(options));\ntensorflow::Status session_create_status = session->Create(graph_def);                                                        \n...                                                                               \ntensorflow::Status run_status  = session->Run({{_inputLayer,*(vtfinputs.begin())}},{_outputLayer},{},&finalOutput)  /* runs file, results are what they should be, and are acquired via finalOutput. */\n...\nsession->Close();                                                                                                          \nsession.reset();\n\n/* RAM keeps building up if code above put into a loop */\nWhat other attempted solutions have you tried?\nusing session->Reset(options,containers) does not appear to compile (Reset does not exist for Session). Looking at session.h and direct_session.h I don't yet understand why this is the case.", "body": "Using C++ API, memory (RAM) does not appear to be fully released after `Session::Close()` is called. \r\n\r\nSee code snippet below. Running it within a loop eventually eats up all RAM and gets killed by system.\r\n\r\nFrom reading around, I understand that the closing of the session does not release the underlying graph. In Python it seems that `reset_default_graph()` releases the graph resources.\r\n\r\nIs there any equivalent to `reset_default_graph()` in C++ ?\r\n\r\nI initially reported this question on the mailing list, https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/NG7n6emda78 with no echo, so posted as an issue here. My apologies if this isn't the right procedure.\r\n\r\nNote:\r\nGPU memory appears to not be released when looking it up with `nvidia-smi` but I believe it is an `nvidia-smi` problem as in practice the GPU memory appears to be reusable, so no problem on this side.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nhttp://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session\r\nhttps://github.com/tensorflow/tensorflow/issues/1578\r\nhttps://github.com/fchollet/keras/issues/2102\r\nhttps://github.com/tensorflow/tensorflow/issues/700\r\nhttps://github.com/tensorflow/tensorflow/issues/3106\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nUbuntu 16.04 LTS\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n```\r\n-rw-r--r-- 1 root root   560184 Sep  7 18:22 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\r\n-rwxr-xr-x 1 root root   394472 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so.8.0.27\r\n-rw-r--r-- 1 root root   737516 Sep  7 18:22 /usr/local/cuda/lib64/libcudart_static.a\r\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so\r\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so.5\r\n-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\n### From source installation\r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n\r\n```\r\n5c1ca717e8ddd16b0be8410a798dc174380a600d\r\n```\r\n\r\n2. The output of `bazel version`\r\n\r\n```\r\nBuild label: 0.3.2\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Oct 7 17:25:10 2016 (1475861110)\r\nBuild timestamp: 1475861110\r\nBuild timestamp as int: 1475861110\r\n```\r\n### Short code snippet\r\n\r\nPut the code below into a loop, and RAM keeps on growing, replace `_inputLayer` and `_outputLayer` with proper network layer names, and `vtfinputs` is a `std::vector<tensorflow::Tensor>`.\r\n\r\n```C++\r\ntensorflow::GraphDef graph_def;\r\ntensorflow::Status graphLoadedStatus = ReadBinaryProto(tensorflow::Env::Default(),graphFile,&graph_def);\r\ntensorflow::SessionOptions options;\r\ntensorflow::ConfigProto &config = options.config;\r\nconfig.mutable_gpu_options()->set_allow_growth(true);\r\nstd::unique_ptr<tensorflow::Session> session = std::unique_ptr<tensorflow::Session>(tensorflow::NewSession(options));\r\ntensorflow::Status session_create_status = session->Create(graph_def);                                                        \r\n...                                                                               \r\ntensorflow::Status run_status  = session->Run({{_inputLayer,*(vtfinputs.begin())}},{_outputLayer},{},&finalOutput)  /* runs file, results are what they should be, and are acquired via finalOutput. */\r\n...\r\nsession->Close();                                                                                                          \r\nsession.reset();\r\n\r\n/* RAM keeps building up if code above put into a loop */\r\n```\r\n### What other attempted solutions have you tried?\r\n\r\nusing ```session->Reset(options,containers)``` does not appear to compile (Reset does not exist for Session). Looking at ```session.h``` and ```direct_session.h``` I don't yet understand why this is the case. \r\n\r\n\r\n"}