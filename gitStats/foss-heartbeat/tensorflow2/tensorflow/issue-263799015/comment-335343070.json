{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335343070", "html_url": "https://github.com/tensorflow/tensorflow/issues/13577#issuecomment-335343070", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13577", "id": 335343070, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTM0MzA3MA==", "user": {"login": "wenruij", "id": 5120224, "node_id": "MDQ6VXNlcjUxMjAyMjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/5120224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wenruij", "html_url": "https://github.com/wenruij", "followers_url": "https://api.github.com/users/wenruij/followers", "following_url": "https://api.github.com/users/wenruij/following{/other_user}", "gists_url": "https://api.github.com/users/wenruij/gists{/gist_id}", "starred_url": "https://api.github.com/users/wenruij/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wenruij/subscriptions", "organizations_url": "https://api.github.com/users/wenruij/orgs", "repos_url": "https://api.github.com/users/wenruij/repos", "events_url": "https://api.github.com/users/wenruij/events{/privacy}", "received_events_url": "https://api.github.com/users/wenruij/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-10T02:41:01Z", "updated_at": "2017-10-10T02:41:01Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6510203\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/reedwm\">@reedwm</a> pls check the full code as below,</p>\n<pre><code>import csv\nimport os\nimport tempfile\n\nfrom six.moves import urllib\nfrom datetime import datetime\n\nimport tensorflow as tf\n\n\nMB_SIZE = 1024.0*1024.0\nCSV_FORMAT = 'adult.data'\n\ncategorical_columns = [\n    \"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\",\n    \"race\", \"gender\", \"native_country\", \"label\"\n]\ncontinuous_columns = [\n    \"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\",\n    \"hours_per_week\"\n]\nall_columns = [\n    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"label\"\n]\n\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n\n\ndef csv2proto(\n        data_source,\n        all_cols,\n        categorical_cols=[],\n        continuous_cols=[],\n        multi_values_cols=[],\n        inner_delimiter=';'\n):\n    if not os.path.isfile(data_source):\n        raise ValueError('data file passed do not exist or not a file')\n\n    csv_size = os.path.getsize(data_source)/MB_SIZE\n    file_name = os.path.splitext(data_source)[0] + '.tfrecords'\n    writer = tf.python_io.TFRecordWriter(file_name)\n    start = datetime.now()\n    with open(data_source) as f:\n        reader = csv.DictReader(f, fieldnames=all_cols)\n        for row in reader:\n            feature = dict()\n            for col in categorical_cols:\n                feature.update({col: _bytes_feature([row[col]])})\n            for col in continuous_cols:\n                feature.update({col: _int64_feature([int(row[col])])})\n            for col in multi_values_cols:\n                feature.update({col: _bytes_feature(row[col].split(inner_delimiter))})\n\n            example = tf.train.Example(features=tf.train.Features(feature=feature))\n            writer.write(example.SerializeToString())\n\n        writer.close()\n        end = datetime.now()\n        proto_size = os.path.getsize(file_name)/MB_SIZE\n\n        convert_logs = \"\\n| Time Elapsed: %d\" % (end-start).seconds + \" s |\"\n        convert_logs += \"\\n| csv size: \" + \"%.2f\" % csv_size + \" MB |\"\n        convert_logs += \"\\n| proto size: \" + \"%.2f\" % proto_size + \" MB |\\n\"\n\n        print convert_logs\n\n\ndef main():\n    urllib.request.urlretrieve(\n        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n        CSV_FORMAT)\n    csv2proto(data_source=CSV_FORMAT,\n              all_cols=all_columns,\n              categorical_cols=categorical_columns,\n              continuous_cols=continuous_columns)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>\n<p>Logs of my side(Mac OS X 10.12.5) is:</p>\n<pre><code>| Time Elapsed: 89 s |\n| csv size: 3.79 MB |\n| proto size: 12.68 MB |\n</code></pre>", "body_text": "@reedwm pls check the full code as below,\nimport csv\nimport os\nimport tempfile\n\nfrom six.moves import urllib\nfrom datetime import datetime\n\nimport tensorflow as tf\n\n\nMB_SIZE = 1024.0*1024.0\nCSV_FORMAT = 'adult.data'\n\ncategorical_columns = [\n    \"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\",\n    \"race\", \"gender\", \"native_country\", \"label\"\n]\ncontinuous_columns = [\n    \"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\",\n    \"hours_per_week\"\n]\nall_columns = [\n    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"label\"\n]\n\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n\n\ndef csv2proto(\n        data_source,\n        all_cols,\n        categorical_cols=[],\n        continuous_cols=[],\n        multi_values_cols=[],\n        inner_delimiter=';'\n):\n    if not os.path.isfile(data_source):\n        raise ValueError('data file passed do not exist or not a file')\n\n    csv_size = os.path.getsize(data_source)/MB_SIZE\n    file_name = os.path.splitext(data_source)[0] + '.tfrecords'\n    writer = tf.python_io.TFRecordWriter(file_name)\n    start = datetime.now()\n    with open(data_source) as f:\n        reader = csv.DictReader(f, fieldnames=all_cols)\n        for row in reader:\n            feature = dict()\n            for col in categorical_cols:\n                feature.update({col: _bytes_feature([row[col]])})\n            for col in continuous_cols:\n                feature.update({col: _int64_feature([int(row[col])])})\n            for col in multi_values_cols:\n                feature.update({col: _bytes_feature(row[col].split(inner_delimiter))})\n\n            example = tf.train.Example(features=tf.train.Features(feature=feature))\n            writer.write(example.SerializeToString())\n\n        writer.close()\n        end = datetime.now()\n        proto_size = os.path.getsize(file_name)/MB_SIZE\n\n        convert_logs = \"\\n| Time Elapsed: %d\" % (end-start).seconds + \" s |\"\n        convert_logs += \"\\n| csv size: \" + \"%.2f\" % csv_size + \" MB |\"\n        convert_logs += \"\\n| proto size: \" + \"%.2f\" % proto_size + \" MB |\\n\"\n\n        print convert_logs\n\n\ndef main():\n    urllib.request.urlretrieve(\n        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n        CSV_FORMAT)\n    csv2proto(data_source=CSV_FORMAT,\n              all_cols=all_columns,\n              categorical_cols=categorical_columns,\n              continuous_cols=continuous_columns)\n\n\nif __name__ == \"__main__\":\n    main()\n\nLogs of my side(Mac OS X 10.12.5) is:\n| Time Elapsed: 89 s |\n| csv size: 3.79 MB |\n| proto size: 12.68 MB |", "body": "@reedwm pls check the full code as below,\r\n\r\n```\r\nimport csv\r\nimport os\r\nimport tempfile\r\n\r\nfrom six.moves import urllib\r\nfrom datetime import datetime\r\n\r\nimport tensorflow as tf\r\n\r\n\r\nMB_SIZE = 1024.0*1024.0\r\nCSV_FORMAT = 'adult.data'\r\n\r\ncategorical_columns = [\r\n    \"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\",\r\n    \"race\", \"gender\", \"native_country\", \"label\"\r\n]\r\ncontinuous_columns = [\r\n    \"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\",\r\n    \"hours_per_week\"\r\n]\r\nall_columns = [\r\n    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\r\n    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\r\n    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"label\"\r\n]\r\n\r\n\r\ndef _int64_feature(value):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\r\n\r\n\r\ndef _bytes_feature(value):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\r\n\r\n\r\ndef csv2proto(\r\n        data_source,\r\n        all_cols,\r\n        categorical_cols=[],\r\n        continuous_cols=[],\r\n        multi_values_cols=[],\r\n        inner_delimiter=';'\r\n):\r\n    if not os.path.isfile(data_source):\r\n        raise ValueError('data file passed do not exist or not a file')\r\n\r\n    csv_size = os.path.getsize(data_source)/MB_SIZE\r\n    file_name = os.path.splitext(data_source)[0] + '.tfrecords'\r\n    writer = tf.python_io.TFRecordWriter(file_name)\r\n    start = datetime.now()\r\n    with open(data_source) as f:\r\n        reader = csv.DictReader(f, fieldnames=all_cols)\r\n        for row in reader:\r\n            feature = dict()\r\n            for col in categorical_cols:\r\n                feature.update({col: _bytes_feature([row[col]])})\r\n            for col in continuous_cols:\r\n                feature.update({col: _int64_feature([int(row[col])])})\r\n            for col in multi_values_cols:\r\n                feature.update({col: _bytes_feature(row[col].split(inner_delimiter))})\r\n\r\n            example = tf.train.Example(features=tf.train.Features(feature=feature))\r\n            writer.write(example.SerializeToString())\r\n\r\n        writer.close()\r\n        end = datetime.now()\r\n        proto_size = os.path.getsize(file_name)/MB_SIZE\r\n\r\n        convert_logs = \"\\n| Time Elapsed: %d\" % (end-start).seconds + \" s |\"\r\n        convert_logs += \"\\n| csv size: \" + \"%.2f\" % csv_size + \" MB |\"\r\n        convert_logs += \"\\n| proto size: \" + \"%.2f\" % proto_size + \" MB |\\n\"\r\n\r\n        print convert_logs\r\n\r\n\r\ndef main():\r\n    urllib.request.urlretrieve(\r\n        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\r\n        CSV_FORMAT)\r\n    csv2proto(data_source=CSV_FORMAT,\r\n              all_cols=all_columns,\r\n              categorical_cols=categorical_columns,\r\n              continuous_cols=continuous_columns)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nLogs of my side(Mac OS X 10.12.5) is:\r\n```\r\n| Time Elapsed: 89 s |\r\n| csv size: 3.79 MB |\r\n| proto size: 12.68 MB |\r\n```\r\n\r\n"}