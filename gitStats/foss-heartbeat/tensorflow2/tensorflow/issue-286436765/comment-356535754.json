{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/356535754", "html_url": "https://github.com/tensorflow/tensorflow/issues/15897#issuecomment-356535754", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15897", "id": 356535754, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjUzNTc1NA==", "user": {"login": "egborbe", "id": 28956112, "node_id": "MDQ6VXNlcjI4OTU2MTEy", "avatar_url": "https://avatars1.githubusercontent.com/u/28956112?v=4", "gravatar_id": "", "url": "https://api.github.com/users/egborbe", "html_url": "https://github.com/egborbe", "followers_url": "https://api.github.com/users/egborbe/followers", "following_url": "https://api.github.com/users/egborbe/following{/other_user}", "gists_url": "https://api.github.com/users/egborbe/gists{/gist_id}", "starred_url": "https://api.github.com/users/egborbe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/egborbe/subscriptions", "organizations_url": "https://api.github.com/users/egborbe/orgs", "repos_url": "https://api.github.com/users/egborbe/repos", "events_url": "https://api.github.com/users/egborbe/events{/privacy}", "received_events_url": "https://api.github.com/users/egborbe/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-10T08:36:59Z", "updated_at": "2018-01-10T08:36:59Z", "author_association": "NONE", "body_html": "<p>Hi ,</p>\n<p>thank you for your attention.<br>\nI now understand the way TF handles Cuda cores<br>\nI did some further measurements and it turned out that NCHW - NHWC conversion is now consuming as much time as the convolution itself on Volta.<br>\nI tried with NCHW and the performance gain against Pascal GPU shot up immediatelly to 250% from 200%. However this is still far from what Nvidia reported with NVCaffe (370% improvement in inference).<br>\nEVen when I use NCHW order for convulotion I realized there were nchw kernel calls as seen from nvprof.<br>\nSo I think there is still room for improvement.<br>\nThanks and regards,<br>\nGabor Bereczki</p>", "body_text": "Hi ,\nthank you for your attention.\nI now understand the way TF handles Cuda cores\nI did some further measurements and it turned out that NCHW - NHWC conversion is now consuming as much time as the convolution itself on Volta.\nI tried with NCHW and the performance gain against Pascal GPU shot up immediatelly to 250% from 200%. However this is still far from what Nvidia reported with NVCaffe (370% improvement in inference).\nEVen when I use NCHW order for convulotion I realized there were nchw kernel calls as seen from nvprof.\nSo I think there is still room for improvement.\nThanks and regards,\nGabor Bereczki", "body": "Hi ,\r\n\r\nthank you for your attention.\r\nI now understand the way TF handles Cuda cores\r\nI did some further measurements and it turned out that NCHW - NHWC conversion is now consuming as much time as the convolution itself on Volta.\r\nI tried with NCHW and the performance gain against Pascal GPU shot up immediatelly to 250% from 200%. However this is still far from what Nvidia reported with NVCaffe (370% improvement in inference).\r\nEVen when I use NCHW order for convulotion I realized there were nchw kernel calls as seen from nvprof.\r\nSo I think there is still room for improvement.\r\nThanks and regards,\r\nGabor Bereczki"}