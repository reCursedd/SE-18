{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/305860820", "html_url": "https://github.com/tensorflow/tensorflow/issues/10216#issuecomment-305860820", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10216", "id": 305860820, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNTg2MDgyMA==", "user": {"login": "Panaetius", "id": 664486, "node_id": "MDQ6VXNlcjY2NDQ4Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/664486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Panaetius", "html_url": "https://github.com/Panaetius", "followers_url": "https://api.github.com/users/Panaetius/followers", "following_url": "https://api.github.com/users/Panaetius/following{/other_user}", "gists_url": "https://api.github.com/users/Panaetius/gists{/gist_id}", "starred_url": "https://api.github.com/users/Panaetius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Panaetius/subscriptions", "organizations_url": "https://api.github.com/users/Panaetius/orgs", "repos_url": "https://api.github.com/users/Panaetius/repos", "events_url": "https://api.github.com/users/Panaetius/events{/privacy}", "received_events_url": "https://api.github.com/users/Panaetius/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-02T17:37:15Z", "updated_at": "2017-06-02T17:37:15Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=70511\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/girving\">@girving</a> I'm currently not really affected, by supplying the width without padding to my unpool op, it's working fine.</p>\n<p>If this isn't changed, then you should update the documentation of tf.nn.max_pool_with_argmax to clearly reflect this behaviour.</p>\n<p>I can understand your reasoning, though I still regard it as a bug. Specifically, if there's [[-1, -2], [0, 0]] at the bottom of a tensor (the 0's being padding), this op would return the index of the -1, instead of one of the 0's, and that's not really what max_pooling should do. The way I see it right now, it's clearly a bug, but one without a lot of consequences (since it only affects the edges of an image), i.e. the example I just mentioned probably doesn't influence network performance, it might even be beneficial (not introducing arbitrary zeros). But it is conceptually a bug.</p>\n<p>That said, if the documentation is changed, it shouldn't make much of a difference. At least I can't think of a use-case where the behaviour can't be easily circumvented (like supplying the original dimensions in the unpool example), so I don't see it as a bug that would prohibit someone from doing what they want.</p>", "body_text": "@girving I'm currently not really affected, by supplying the width without padding to my unpool op, it's working fine.\nIf this isn't changed, then you should update the documentation of tf.nn.max_pool_with_argmax to clearly reflect this behaviour.\nI can understand your reasoning, though I still regard it as a bug. Specifically, if there's [[-1, -2], [0, 0]] at the bottom of a tensor (the 0's being padding), this op would return the index of the -1, instead of one of the 0's, and that's not really what max_pooling should do. The way I see it right now, it's clearly a bug, but one without a lot of consequences (since it only affects the edges of an image), i.e. the example I just mentioned probably doesn't influence network performance, it might even be beneficial (not introducing arbitrary zeros). But it is conceptually a bug.\nThat said, if the documentation is changed, it shouldn't make much of a difference. At least I can't think of a use-case where the behaviour can't be easily circumvented (like supplying the original dimensions in the unpool example), so I don't see it as a bug that would prohibit someone from doing what they want.", "body": "@girving I'm currently not really affected, by supplying the width without padding to my unpool op, it's working fine.\r\n\r\nIf this isn't changed, then you should update the documentation of tf.nn.max_pool_with_argmax to clearly reflect this behaviour.\r\n\r\nI can understand your reasoning, though I still regard it as a bug. Specifically, if there's [[-1, -2], [0, 0]] at the bottom of a tensor (the 0's being padding), this op would return the index of the -1, instead of one of the 0's, and that's not really what max_pooling should do. The way I see it right now, it's clearly a bug, but one without a lot of consequences (since it only affects the edges of an image), i.e. the example I just mentioned probably doesn't influence network performance, it might even be beneficial (not introducing arbitrary zeros). But it is conceptually a bug. \r\n\r\nThat said, if the documentation is changed, it shouldn't make much of a difference. At least I can't think of a use-case where the behaviour can't be easily circumvented (like supplying the original dimensions in the unpool example), so I don't see it as a bug that would prohibit someone from doing what they want."}