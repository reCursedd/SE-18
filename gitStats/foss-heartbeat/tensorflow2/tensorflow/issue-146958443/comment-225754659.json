{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/225754659", "html_url": "https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-225754659", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1824", "id": 225754659, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNTc1NDY1OQ==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-14T01:17:32Z", "updated_at": "2016-06-14T02:17:05Z", "author_association": "MEMBER", "body_html": "<p>I'm unlikely to have much time to write a tutorial in the near future, but the current status of the open source tools are as follows:</p>\n<p>There is now a basic CUPTI GPU tracer integrated in the runtime.  You can run a step with tracing enabled and it records both the ops which are executed and the GPU kernels which are launched.  Here is an example:</p>\n<pre><code>run_metadata = tf.RunMetadata()\n_, l, lr, predictions = sess.run(\n            [optimizer, loss, learning_rate, train_prediction],\n            feed_dict=feed_dict,\n            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n            run_metadata=run_metadata)\n</code></pre>\n<p>After the step completes, the run_metadata should contain a StepStats protobuf with lots of timing information, grouped by tensorflow device.  The CUPTI GPU tracing appears as some additional devices with names like  /gpu:0/stream:56 and /gpu:0/memcpy</p>\n<p>Note: to get GPU tracing you will need to ensure that libcupti.so is on you LD_LIBRARY_PATH.  It is usually found in /usr/local/cuda/extras/lib64.</p>\n<p>The simplest way to use this information is to load the stats into a 'Timeline' as follows:</p>\n<pre><code>from tensorflow.python.client import timeline\ntrace = timeline.Timeline(step_stats=run_metadata.step_stats)\n</code></pre>\n<p>The Timeline class can then be used to emit a JSON trace file in the Chrome Tracing Format, as follows:</p>\n<pre><code>trace_file = open('timeline.ctf.json', 'w')\ntrace_file.write(trace.generate_chrome_trace_format())\n</code></pre>\n<p>To view this trace, navigate to the URL  'chrome://tracing' in a Chrome web browser, click the 'Load' button and locate the timeline file.</p>\n<p>It would be fairly simple to write a small python web server which served up these traces from a running TensorFlow program like <a href=\"https://github.com/catapult-project/catapult/blob/master/tracing/docs/embedding-trace-viewer.md\">this</a></p>", "body_text": "I'm unlikely to have much time to write a tutorial in the near future, but the current status of the open source tools are as follows:\nThere is now a basic CUPTI GPU tracer integrated in the runtime.  You can run a step with tracing enabled and it records both the ops which are executed and the GPU kernels which are launched.  Here is an example:\nrun_metadata = tf.RunMetadata()\n_, l, lr, predictions = sess.run(\n            [optimizer, loss, learning_rate, train_prediction],\n            feed_dict=feed_dict,\n            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n            run_metadata=run_metadata)\n\nAfter the step completes, the run_metadata should contain a StepStats protobuf with lots of timing information, grouped by tensorflow device.  The CUPTI GPU tracing appears as some additional devices with names like  /gpu:0/stream:56 and /gpu:0/memcpy\nNote: to get GPU tracing you will need to ensure that libcupti.so is on you LD_LIBRARY_PATH.  It is usually found in /usr/local/cuda/extras/lib64.\nThe simplest way to use this information is to load the stats into a 'Timeline' as follows:\nfrom tensorflow.python.client import timeline\ntrace = timeline.Timeline(step_stats=run_metadata.step_stats)\n\nThe Timeline class can then be used to emit a JSON trace file in the Chrome Tracing Format, as follows:\ntrace_file = open('timeline.ctf.json', 'w')\ntrace_file.write(trace.generate_chrome_trace_format())\n\nTo view this trace, navigate to the URL  'chrome://tracing' in a Chrome web browser, click the 'Load' button and locate the timeline file.\nIt would be fairly simple to write a small python web server which served up these traces from a running TensorFlow program like this", "body": "I'm unlikely to have much time to write a tutorial in the near future, but the current status of the open source tools are as follows:\n\nThere is now a basic CUPTI GPU tracer integrated in the runtime.  You can run a step with tracing enabled and it records both the ops which are executed and the GPU kernels which are launched.  Here is an example:\n\n```\nrun_metadata = tf.RunMetadata()\n_, l, lr, predictions = sess.run(\n            [optimizer, loss, learning_rate, train_prediction],\n            feed_dict=feed_dict,\n            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n            run_metadata=run_metadata)\n```\n\nAfter the step completes, the run_metadata should contain a StepStats protobuf with lots of timing information, grouped by tensorflow device.  The CUPTI GPU tracing appears as some additional devices with names like  /gpu:0/stream:56 and /gpu:0/memcpy\n\nNote: to get GPU tracing you will need to ensure that libcupti.so is on you LD_LIBRARY_PATH.  It is usually found in /usr/local/cuda/extras/lib64.\n\nThe simplest way to use this information is to load the stats into a 'Timeline' as follows:\n\n```\nfrom tensorflow.python.client import timeline\ntrace = timeline.Timeline(step_stats=run_metadata.step_stats)\n```\n\nThe Timeline class can then be used to emit a JSON trace file in the Chrome Tracing Format, as follows:\n\n```\ntrace_file = open('timeline.ctf.json', 'w')\ntrace_file.write(trace.generate_chrome_trace_format())\n```\n\nTo view this trace, navigate to the URL  'chrome://tracing' in a Chrome web browser, click the 'Load' button and locate the timeline file.\n\nIt would be fairly simple to write a small python web server which served up these traces from a running TensorFlow program like [this](https://github.com/catapult-project/catapult/blob/master/tracing/docs/embedding-trace-viewer.md)\n"}