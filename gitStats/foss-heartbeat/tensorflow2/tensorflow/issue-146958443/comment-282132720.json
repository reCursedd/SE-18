{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/282132720", "html_url": "https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-282132720", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1824", "id": 282132720, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MjEzMjcyMA==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-23T21:50:57Z", "updated_at": "2017-02-23T21:50:57Z", "author_association": "MEMBER", "body_html": "<p>NodeExecStats was intended to collect measurements related to the execution time and memory requirements of a graph node so as to better inform an intelligent placement and/or scheduling algorithm.  None of its fields record the lifespan of any output tensors, since this data is recorded soon after the termination of node execution, and the lifespan may be unknown.</p>\n<p>What you are asking for sounds useful, and may be available some other way that I don't know of, but I'm doubtful.  If we tagged memory allocations with the name of the Op that caused them, it would be possible to annotate the timeline with tensor allocation lifespans.  An Op's output persists until the backward pass whenever its output is also an input to a node in that backward pass, so it should be possible to write a program that analyses that graph and identifies such cases.</p>", "body_text": "NodeExecStats was intended to collect measurements related to the execution time and memory requirements of a graph node so as to better inform an intelligent placement and/or scheduling algorithm.  None of its fields record the lifespan of any output tensors, since this data is recorded soon after the termination of node execution, and the lifespan may be unknown.\nWhat you are asking for sounds useful, and may be available some other way that I don't know of, but I'm doubtful.  If we tagged memory allocations with the name of the Op that caused them, it would be possible to annotate the timeline with tensor allocation lifespans.  An Op's output persists until the backward pass whenever its output is also an input to a node in that backward pass, so it should be possible to write a program that analyses that graph and identifies such cases.", "body": "NodeExecStats was intended to collect measurements related to the execution time and memory requirements of a graph node so as to better inform an intelligent placement and/or scheduling algorithm.  None of its fields record the lifespan of any output tensors, since this data is recorded soon after the termination of node execution, and the lifespan may be unknown.\r\n\r\nWhat you are asking for sounds useful, and may be available some other way that I don't know of, but I'm doubtful.  If we tagged memory allocations with the name of the Op that caused them, it would be possible to annotate the timeline with tensor allocation lifespans.  An Op's output persists until the backward pass whenever its output is also an input to a node in that backward pass, so it should be possible to write a program that analyses that graph and identifies such cases."}