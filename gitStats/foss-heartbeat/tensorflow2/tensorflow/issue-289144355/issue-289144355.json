{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16178", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16178/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16178/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16178/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16178", "id": 289144355, "node_id": "MDU6SXNzdWUyODkxNDQzNTU=", "number": 16178, "title": "Crash in TF lite demo android app when using preprocessing layer", "user": {"login": "martinkersner", "id": 2312761, "node_id": "MDQ6VXNlcjIzMTI3NjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/2312761?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinkersner", "html_url": "https://github.com/martinkersner", "followers_url": "https://api.github.com/users/martinkersner/followers", "following_url": "https://api.github.com/users/martinkersner/following{/other_user}", "gists_url": "https://api.github.com/users/martinkersner/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinkersner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinkersner/subscriptions", "organizations_url": "https://api.github.com/users/martinkersner/orgs", "repos_url": "https://api.github.com/users/martinkersner/repos", "events_url": "https://api.github.com/users/martinkersner/events{/privacy}", "received_events_url": "https://api.github.com/users/martinkersner/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-17T05:09:08Z", "updated_at": "2018-01-17T08:15:46Z", "closed_at": "2018-01-17T08:15:46Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04):</strong> Linux Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.4.0-rc0-21-g1e25994 1.4.0-rc1</li>\n<li><strong>Python version</strong>: Python 3.6.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8/6</li>\n<li><strong>GPU model and memory</strong>: Titan X (Pascal), 12 GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I have a problem adding preprocessing layers to MobileNetV1 model that is quantized afterward. As preprocessing method I would like to use inception preprocessing, but TF lite does not support several operations (sub, div, broadcasting, ...), so I modified following preprocessing</p>\n<div class=\"highlight highlight-source-python\"><pre>images <span class=\"pl-k\">=</span> tf.divide(images, tf.constant(<span class=\"pl-c1\">255.0</span>))\nimages <span class=\"pl-k\">=</span> tf.subtract(images, tf.constant(<span class=\"pl-c1\">0.5</span>))\nimages <span class=\"pl-k\">=</span> tf.multiply(images, tf.constant(<span class=\"pl-c1\">2.0</span>))</pre></div>\n<p>to</p>\n<div class=\"highlight highlight-source-python\"><pre>shape <span class=\"pl-k\">=</span> images.get_shape()\nc1 <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1.0</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">255.0</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>shape)\nc1 <span class=\"pl-k\">=</span> tf.fake_quant_with_min_max_args(c1, <span class=\"pl-v\">min</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">max</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\nc2 <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-k\">-</span><span class=\"pl-c1\">0.5</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>shape)\nc2 <span class=\"pl-k\">=</span> tf.fake_quant_with_min_max_args(c1, <span class=\"pl-v\">min</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">max</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\nc3 <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">2.0</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>shape)\nc3 <span class=\"pl-k\">=</span> tf.fake_quant_with_min_max_args(c1, <span class=\"pl-v\">min</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">max</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\nimages <span class=\"pl-k\">=</span> tf.multiply(images, c1)\nimages <span class=\"pl-k\">=</span> tf.fake_quant_with_min_max_args(images, <span class=\"pl-v\">min</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">max</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\nimages <span class=\"pl-k\">=</span> tf.add(images, c2)\nimages <span class=\"pl-k\">=</span> tf.fake_quant_with_min_max_args(images, <span class=\"pl-v\">min</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0.5</span>, <span class=\"pl-v\">max</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.5</span>)\nimages <span class=\"pl-k\">=</span> tf.multiply(images, c3)\nimages <span class=\"pl-k\">=</span> tf.fake_quant_with_min_max_args(images, <span class=\"pl-v\">min</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">max</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>)</pre></div>\n<p>Quantization is performed with</p>\n<div class=\"highlight highlight-source-python\"><pre>fold_batch_norms.FoldBatchNorms(graph)\nquantize.Quantize(graph, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>is_training)</pre></div>\n<p>and can be trained and evaluated.</p>\n<p>Further, graph is frozen.</p>\n<div class=\"highlight highlight-source-shell\"><pre>bazel-bin/tensorflow/python/tools/freeze_graph \\\n  --input_graph=MobileNetV1-4.pbtxt \\\n  --input_checkpoint=MobileNetV1-4.ckpt \\\n  --output_node_names=output/softmax \\\n  --output_graph=MobileNetV1-4-frozen.pb</pre></div>\n<p>Finally, frozen graph is converted to TF lite model using command.</p>\n<div class=\"highlight highlight-source-shell\"><pre>bazel-bin/tensorflow/contrib/lite/toco/toco \\\n --input_file=MobileNetV1-4-frozen.pb \\\n --input_format=TENSORFLOW_GRAPHDEF \\\n --output_format=TFLITE \\\n --output_file=model.tflite \\\n --inference_type=QUANTIZED_UINT8 \\\n --inference_input_type=QUANTIZED_UINT8 \\\n --input_array=input/image \\\n --output_array=output/softmax \\\n --input_shape=1,224,224,3</pre></div>\n<p>During conversion no error occurs.</p>\n<pre><code>2018-01-17 11:25:52.905034: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 604 operators, 896 arrays (0 quantized)\n2018-01-17 11:25:53.301108: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 66 operators, 127 arrays (1 quantized)\n2018-01-17 11:25:53.302502: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 66 operators, 127 arrays (1 quantized)\n2018-01-17 11:25:53.303020: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 35 operators, 96 arrays (1 quantized)\n2018-01-17 11:25:53.303601: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 35 operators, 96 arrays (1 quantized)\n2018-01-17 11:25:53.326761: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 1: 34 operators, 95 arrays (94 quantized)\n2018-01-17 11:25:53.327269: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 2: 34 operators, 95 arrays (94 quantized)\n2018-01-17 11:25:53.327854: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 1756160 bytes, theoretical optimal value: 1204224 bytes.\n2018-01-17 11:25:53.328080: I tensorflow/contrib/lite/toco/toco_tooling.cc:269] Estimated count of arithmetic ops: 1.14175 billion (note that a multiply-add is counted as 2 ops).\n</code></pre>\n<p>When I upload generated model to TF lite demo application, app crashes logcat prints this error.</p>\n<pre><code>01-17 11:56:52.190 10923-10923/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n01-17 11:56:52.190 10923-10923/? A/DEBUG: Build fingerprint: 'samsung/dreamlteks/dreamlteks:7.0/NRD90M/G950NKSU1AQL3:user/release-keys'\n01-17 11:56:52.191 10923-10923/? A/DEBUG: Revision: '11'\n01-17 11:56:52.191 10923-10923/? A/DEBUG: ABI: 'arm64'\n01-17 11:56:52.191 10923-10923/? A/DEBUG: pid: 10865, tid: 10881, name: CameraBackgroun  &gt;&gt;&gt; android.example.com.tflitecamerademo &lt;&lt;&lt;\n01-17 11:56:52.191 10923-10923/? A/DEBUG: signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x0   0000000000000000  x1   0000000000002a81  x2   0000000000000006  x3   0000000000000008\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x4   0000007e81515040  x5   0000007e815166c0  x6   0000ffffffffffff  x7   ffffffffffffffff\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x8   0000000000000083  x9   ffffffffffffffdf  x10  0000000000000000  x11  ffffffffffffffff\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x12  0000000000000000  x13  ffffffffffff0000  x14  00000000000002e0  x15  000000000000044d\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x16  0000007e9533aed0  x17  0000007e952e29f4  x18  0000000000000001  x19  0000007e817524f8\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x20  0000000000000006  x21  0000007e81752450  x22  000000000000000b  x23  0000007e858340f0\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x24  0000007e817524e8  x25  0000000000000000  x26  0000000000000080  x27  0000007e81516740\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x28  0000000000000001  x29  0000007e81750730  x30  0000007e952dfd14\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     sp   0000007e81750710  pc   0000007e952e29fc  pstate 0000000060000000\n01-17 11:56:52.198 10923-10923/? A/DEBUG: backtrace:\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #00 pc 000000000006f9fc  /system/lib64/libc.so (tgkill+8)\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #01 pc 000000000006cd10  /system/lib64/libc.so (pthread_kill+64)\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #02 pc 0000000000025078  /system/lib64/libc.so (raise+24)\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #03 pc 000000000001cc04  /system/lib64/libc.so (abort+52)\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #04 pc 00000000000881a0  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #05 pc 0000000000071ce4  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #06 pc 00000000000707fc  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #07 pc 000000000007f99c  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #08 pc 0000000000011c5c  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+1628)\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #09 pc 0000000000384abc  /data/app/android.example.com.tflitecamerademo-1/oat/arm64/base.odex (offset 0x329000)\n</code></pre>\n<p>This error doesn't seem to be related to added preprocessing layer, but without adding preprocessing layer, no error occurs and app can run.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04\nTensorFlow installed from (source or binary): pip\nTensorFlow version (use command below): v1.4.0-rc0-21-g1e25994 1.4.0-rc1\nPython version: Python 3.6.2\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 8/6\nGPU model and memory: Titan X (Pascal), 12 GB\nExact command to reproduce:\n\nDescribe the problem\nI have a problem adding preprocessing layers to MobileNetV1 model that is quantized afterward. As preprocessing method I would like to use inception preprocessing, but TF lite does not support several operations (sub, div, broadcasting, ...), so I modified following preprocessing\nimages = tf.divide(images, tf.constant(255.0))\nimages = tf.subtract(images, tf.constant(0.5))\nimages = tf.multiply(images, tf.constant(2.0))\nto\nshape = images.get_shape()\nc1 = tf.constant(1.0/255.0, shape=shape)\nc1 = tf.fake_quant_with_min_max_args(c1, min=-1, max=1)\nc2 = tf.constant(-0.5, shape=shape)\nc2 = tf.fake_quant_with_min_max_args(c1, min=-1, max=1)\nc3 = tf.constant(2.0, shape=shape)\nc3 = tf.fake_quant_with_min_max_args(c1, min=-1, max=1)\n\nimages = tf.multiply(images, c1)\nimages = tf.fake_quant_with_min_max_args(images, min=0, max=1)\nimages = tf.add(images, c2)\nimages = tf.fake_quant_with_min_max_args(images, min=-0.5, max=0.5)\nimages = tf.multiply(images, c3)\nimages = tf.fake_quant_with_min_max_args(images, min=-1.0, max=1.0)\nQuantization is performed with\nfold_batch_norms.FoldBatchNorms(graph)\nquantize.Quantize(graph, is_training=is_training)\nand can be trained and evaluated.\nFurther, graph is frozen.\nbazel-bin/tensorflow/python/tools/freeze_graph \\\n  --input_graph=MobileNetV1-4.pbtxt \\\n  --input_checkpoint=MobileNetV1-4.ckpt \\\n  --output_node_names=output/softmax \\\n  --output_graph=MobileNetV1-4-frozen.pb\nFinally, frozen graph is converted to TF lite model using command.\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\n --input_file=MobileNetV1-4-frozen.pb \\\n --input_format=TENSORFLOW_GRAPHDEF \\\n --output_format=TFLITE \\\n --output_file=model.tflite \\\n --inference_type=QUANTIZED_UINT8 \\\n --inference_input_type=QUANTIZED_UINT8 \\\n --input_array=input/image \\\n --output_array=output/softmax \\\n --input_shape=1,224,224,3\nDuring conversion no error occurs.\n2018-01-17 11:25:52.905034: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 604 operators, 896 arrays (0 quantized)\n2018-01-17 11:25:53.301108: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 66 operators, 127 arrays (1 quantized)\n2018-01-17 11:25:53.302502: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 66 operators, 127 arrays (1 quantized)\n2018-01-17 11:25:53.303020: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 35 operators, 96 arrays (1 quantized)\n2018-01-17 11:25:53.303601: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 35 operators, 96 arrays (1 quantized)\n2018-01-17 11:25:53.326761: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 1: 34 operators, 95 arrays (94 quantized)\n2018-01-17 11:25:53.327269: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 2: 34 operators, 95 arrays (94 quantized)\n2018-01-17 11:25:53.327854: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 1756160 bytes, theoretical optimal value: 1204224 bytes.\n2018-01-17 11:25:53.328080: I tensorflow/contrib/lite/toco/toco_tooling.cc:269] Estimated count of arithmetic ops: 1.14175 billion (note that a multiply-add is counted as 2 ops).\n\nWhen I upload generated model to TF lite demo application, app crashes logcat prints this error.\n01-17 11:56:52.190 10923-10923/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n01-17 11:56:52.190 10923-10923/? A/DEBUG: Build fingerprint: 'samsung/dreamlteks/dreamlteks:7.0/NRD90M/G950NKSU1AQL3:user/release-keys'\n01-17 11:56:52.191 10923-10923/? A/DEBUG: Revision: '11'\n01-17 11:56:52.191 10923-10923/? A/DEBUG: ABI: 'arm64'\n01-17 11:56:52.191 10923-10923/? A/DEBUG: pid: 10865, tid: 10881, name: CameraBackgroun  >>> android.example.com.tflitecamerademo <<<\n01-17 11:56:52.191 10923-10923/? A/DEBUG: signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x0   0000000000000000  x1   0000000000002a81  x2   0000000000000006  x3   0000000000000008\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x4   0000007e81515040  x5   0000007e815166c0  x6   0000ffffffffffff  x7   ffffffffffffffff\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x8   0000000000000083  x9   ffffffffffffffdf  x10  0000000000000000  x11  ffffffffffffffff\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x12  0000000000000000  x13  ffffffffffff0000  x14  00000000000002e0  x15  000000000000044d\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x16  0000007e9533aed0  x17  0000007e952e29f4  x18  0000000000000001  x19  0000007e817524f8\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x20  0000000000000006  x21  0000007e81752450  x22  000000000000000b  x23  0000007e858340f0\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x24  0000007e817524e8  x25  0000000000000000  x26  0000000000000080  x27  0000007e81516740\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x28  0000000000000001  x29  0000007e81750730  x30  0000007e952dfd14\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     sp   0000007e81750710  pc   0000007e952e29fc  pstate 0000000060000000\n01-17 11:56:52.198 10923-10923/? A/DEBUG: backtrace:\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #00 pc 000000000006f9fc  /system/lib64/libc.so (tgkill+8)\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #01 pc 000000000006cd10  /system/lib64/libc.so (pthread_kill+64)\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #02 pc 0000000000025078  /system/lib64/libc.so (raise+24)\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #03 pc 000000000001cc04  /system/lib64/libc.so (abort+52)\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #04 pc 00000000000881a0  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #05 pc 0000000000071ce4  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #06 pc 00000000000707fc  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #07 pc 000000000007f99c  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #08 pc 0000000000011c5c  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+1628)\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #09 pc 0000000000384abc  /data/app/android.example.com.tflitecamerademo-1/oat/arm64/base.odex (offset 0x329000)\n\nThis error doesn't seem to be related to added preprocessing layer, but without adding preprocessing layer, no error occurs and app can run.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Linux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: v1.4.0-rc0-21-g1e25994 1.4.0-rc1\r\n- **Python version**: Python 3.6.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8/6\r\n- **GPU model and memory**: Titan X (Pascal), 12 GB\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI have a problem adding preprocessing layers to MobileNetV1 model that is quantized afterward. As preprocessing method I would like to use inception preprocessing, but TF lite does not support several operations (sub, div, broadcasting, ...), so I modified following preprocessing\r\n\r\n```python\r\nimages = tf.divide(images, tf.constant(255.0))\r\nimages = tf.subtract(images, tf.constant(0.5))\r\nimages = tf.multiply(images, tf.constant(2.0))\r\n```\r\n\r\nto\r\n\r\n```python\r\nshape = images.get_shape()\r\nc1 = tf.constant(1.0/255.0, shape=shape)\r\nc1 = tf.fake_quant_with_min_max_args(c1, min=-1, max=1)\r\nc2 = tf.constant(-0.5, shape=shape)\r\nc2 = tf.fake_quant_with_min_max_args(c1, min=-1, max=1)\r\nc3 = tf.constant(2.0, shape=shape)\r\nc3 = tf.fake_quant_with_min_max_args(c1, min=-1, max=1)\r\n\r\nimages = tf.multiply(images, c1)\r\nimages = tf.fake_quant_with_min_max_args(images, min=0, max=1)\r\nimages = tf.add(images, c2)\r\nimages = tf.fake_quant_with_min_max_args(images, min=-0.5, max=0.5)\r\nimages = tf.multiply(images, c3)\r\nimages = tf.fake_quant_with_min_max_args(images, min=-1.0, max=1.0)\r\n```\r\n\r\nQuantization is performed with\r\n```python\r\nfold_batch_norms.FoldBatchNorms(graph)\r\nquantize.Quantize(graph, is_training=is_training)\r\n```\r\n and can be trained and evaluated.\r\n\r\nFurther, graph is frozen.\r\n```bash\r\nbazel-bin/tensorflow/python/tools/freeze_graph \\\r\n  --input_graph=MobileNetV1-4.pbtxt \\\r\n  --input_checkpoint=MobileNetV1-4.ckpt \\\r\n  --output_node_names=output/softmax \\\r\n  --output_graph=MobileNetV1-4-frozen.pb\r\n```\r\n\r\nFinally, frozen graph is converted to TF lite model using command.\r\n```bash\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n --input_file=MobileNetV1-4-frozen.pb \\\r\n --input_format=TENSORFLOW_GRAPHDEF \\\r\n --output_format=TFLITE \\\r\n --output_file=model.tflite \\\r\n --inference_type=QUANTIZED_UINT8 \\\r\n --inference_input_type=QUANTIZED_UINT8 \\\r\n --input_array=input/image \\\r\n --output_array=output/softmax \\\r\n --input_shape=1,224,224,3\r\n```\r\n\r\nDuring conversion no error occurs.\r\n```\r\n2018-01-17 11:25:52.905034: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 604 operators, 896 arrays (0 quantized)\r\n2018-01-17 11:25:53.301108: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 66 operators, 127 arrays (1 quantized)\r\n2018-01-17 11:25:53.302502: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 66 operators, 127 arrays (1 quantized)\r\n2018-01-17 11:25:53.303020: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 35 operators, 96 arrays (1 quantized)\r\n2018-01-17 11:25:53.303601: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 35 operators, 96 arrays (1 quantized)\r\n2018-01-17 11:25:53.326761: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 1: 34 operators, 95 arrays (94 quantized)\r\n2018-01-17 11:25:53.327269: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 2: 34 operators, 95 arrays (94 quantized)\r\n2018-01-17 11:25:53.327854: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 1756160 bytes, theoretical optimal value: 1204224 bytes.\r\n2018-01-17 11:25:53.328080: I tensorflow/contrib/lite/toco/toco_tooling.cc:269] Estimated count of arithmetic ops: 1.14175 billion (note that a multiply-add is counted as 2 ops).\r\n```\r\n\r\nWhen I upload generated model to TF lite demo application, app crashes logcat prints this error.\r\n```\r\n01-17 11:56:52.190 10923-10923/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\n01-17 11:56:52.190 10923-10923/? A/DEBUG: Build fingerprint: 'samsung/dreamlteks/dreamlteks:7.0/NRD90M/G950NKSU1AQL3:user/release-keys'\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG: Revision: '11'\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG: ABI: 'arm64'\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG: pid: 10865, tid: 10881, name: CameraBackgroun  >>> android.example.com.tflitecamerademo <<<\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG: signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x0   0000000000000000  x1   0000000000002a81  x2   0000000000000006  x3   0000000000000008\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x4   0000007e81515040  x5   0000007e815166c0  x6   0000ffffffffffff  x7   ffffffffffffffff\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x8   0000000000000083  x9   ffffffffffffffdf  x10  0000000000000000  x11  ffffffffffffffff\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x12  0000000000000000  x13  ffffffffffff0000  x14  00000000000002e0  x15  000000000000044d\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x16  0000007e9533aed0  x17  0000007e952e29f4  x18  0000000000000001  x19  0000007e817524f8\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x20  0000000000000006  x21  0000007e81752450  x22  000000000000000b  x23  0000007e858340f0\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x24  0000007e817524e8  x25  0000000000000000  x26  0000000000000080  x27  0000007e81516740\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     x28  0000000000000001  x29  0000007e81750730  x30  0000007e952dfd14\r\n01-17 11:56:52.191 10923-10923/? A/DEBUG:     sp   0000007e81750710  pc   0000007e952e29fc  pstate 0000000060000000\r\n01-17 11:56:52.198 10923-10923/? A/DEBUG: backtrace:\r\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #00 pc 000000000006f9fc  /system/lib64/libc.so (tgkill+8)\r\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #01 pc 000000000006cd10  /system/lib64/libc.so (pthread_kill+64)\r\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #02 pc 0000000000025078  /system/lib64/libc.so (raise+24)\r\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #03 pc 000000000001cc04  /system/lib64/libc.so (abort+52)\r\n01-17 11:56:52.198 10923-10923/? A/DEBUG:     #04 pc 00000000000881a0  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\r\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #05 pc 0000000000071ce4  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\r\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #06 pc 00000000000707fc  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\r\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #07 pc 000000000007f99c  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so\r\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #08 pc 0000000000011c5c  /data/app/android.example.com.tflitecamerademo-1/lib/arm64/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+1628)\r\n01-17 11:56:52.199 10923-10923/? A/DEBUG:     #09 pc 0000000000384abc  /data/app/android.example.com.tflitecamerademo-1/oat/arm64/base.odex (offset 0x329000)\r\n```\r\n\r\nThis error doesn't seem to be related to added preprocessing layer, but without adding preprocessing layer, no error occurs and app can run.\r\n"}