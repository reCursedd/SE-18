{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8934", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8934/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8934/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8934/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8934", "id": 219044278, "node_id": "MDU6SXNzdWUyMTkwNDQyNzg=", "number": 8934, "title": "complex weight for LSTM?", "user": {"login": "DanqingZ", "id": 8596775, "node_id": "MDQ6VXNlcjg1OTY3NzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8596775?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DanqingZ", "html_url": "https://github.com/DanqingZ", "followers_url": "https://api.github.com/users/DanqingZ/followers", "following_url": "https://api.github.com/users/DanqingZ/following{/other_user}", "gists_url": "https://api.github.com/users/DanqingZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/DanqingZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DanqingZ/subscriptions", "organizations_url": "https://api.github.com/users/DanqingZ/orgs", "repos_url": "https://api.github.com/users/DanqingZ/repos", "events_url": "https://api.github.com/users/DanqingZ/events{/privacy}", "received_events_url": "https://api.github.com/users/DanqingZ/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-04-03T19:58:43Z", "updated_at": "2018-08-01T22:40:10Z", "closed_at": "2017-04-04T00:15:20Z", "author_association": "NONE", "body_html": "<p>I am having complex input and output for LSTM, and it looks like I have to initialize LSTM weights as complex tensor. Below is my code:</p>\n<pre><code>rnn_size = 128\ncell = core_rnn_cell.BasicLSTMCell(rnn_size, state_is_tuple=False)\nprint 'initiate LSTM cell: ',cell\nnum_layers = 1\nbatch_size = 1\nseq_length = T.shape[0]\ninitial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\nlearning_rate = 0.003\ninput_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name='input_data')\ntarget_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name = 'target_data')\nlr = tf.Variable(learning_rate, trainable=False, name=\"learning_rate\")\nK = 3\noutput_size = K + K*(K+1)/2 \nembedding_size = 128\nwith tf.variable_scope(\"coordinate_embedding\"):\n#     real_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = \"complex_weight_real\")\n#     imag_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = \"complex_weight_imag\")\n#     matrix = tf.complex(real_w, imag_w)\n    real_embedding_w = tf.get_variable(\"real_embedding_w\", [K, embedding_size])\n    imag_embedding_w = tf.get_variable(\"imag_embedding_w\", [K, embedding_size])\n    embedding_w = tf.complex(real_embedding_w, imag_embedding_w)\n    real_embedding_b = tf.get_variable(\"real_embedding_b\", [embedding_size])\n    imag_embedding_b = tf.get_variable(\"imag_embedding_b\", [embedding_size])\n    embedding_b = tf.complex(real_embedding_b, imag_embedding_b)\n\nwith tf.variable_scope(\"rnnlm\"): \n    real_output_w = tf.get_variable(\"real_output_w\", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)\n    imag_output_w = tf.get_variable(\"imag_output_w\", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)\n    output_w = tf.complex(real_output_w, imag_output_w)\n    real_output_b = tf.get_variable(\"real_output_b\", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)\n    imag_output_b = tf.get_variable(\"imag_output_b\", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)\n    output_b = tf.complex(real_output_b, imag_output_b)\ninputs = tf.split(input_data, seq_length-1, 0)\nstates = []\ninitial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\nstate = initial_state\noutputs = []\npredict_initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\npredict_input =  tf.placeholder(tf.complex64, [1,  2])\npredict_sequence = 100\nindex =0\npredict_outputs = []\noutput, new_state = cell(inputs[i], state)\n</code></pre>\n<p>But I have the below error, but I checked the documentation and didn't find out how to initialize the weights of LSTM cell as complex tensors.</p>\n<pre><code>ValueError: An initializer for variable basic_lstm_cell/weights of &lt;dtype: 'complex64'&gt; is required\n</code></pre>\n<p>Could anyone give me some hint on this? Thanks in advance!</p>", "body_text": "I am having complex input and output for LSTM, and it looks like I have to initialize LSTM weights as complex tensor. Below is my code:\nrnn_size = 128\ncell = core_rnn_cell.BasicLSTMCell(rnn_size, state_is_tuple=False)\nprint 'initiate LSTM cell: ',cell\nnum_layers = 1\nbatch_size = 1\nseq_length = T.shape[0]\ninitial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\nlearning_rate = 0.003\ninput_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name='input_data')\ntarget_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name = 'target_data')\nlr = tf.Variable(learning_rate, trainable=False, name=\"learning_rate\")\nK = 3\noutput_size = K + K*(K+1)/2 \nembedding_size = 128\nwith tf.variable_scope(\"coordinate_embedding\"):\n#     real_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = \"complex_weight_real\")\n#     imag_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = \"complex_weight_imag\")\n#     matrix = tf.complex(real_w, imag_w)\n    real_embedding_w = tf.get_variable(\"real_embedding_w\", [K, embedding_size])\n    imag_embedding_w = tf.get_variable(\"imag_embedding_w\", [K, embedding_size])\n    embedding_w = tf.complex(real_embedding_w, imag_embedding_w)\n    real_embedding_b = tf.get_variable(\"real_embedding_b\", [embedding_size])\n    imag_embedding_b = tf.get_variable(\"imag_embedding_b\", [embedding_size])\n    embedding_b = tf.complex(real_embedding_b, imag_embedding_b)\n\nwith tf.variable_scope(\"rnnlm\"): \n    real_output_w = tf.get_variable(\"real_output_w\", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)\n    imag_output_w = tf.get_variable(\"imag_output_w\", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)\n    output_w = tf.complex(real_output_w, imag_output_w)\n    real_output_b = tf.get_variable(\"real_output_b\", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)\n    imag_output_b = tf.get_variable(\"imag_output_b\", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)\n    output_b = tf.complex(real_output_b, imag_output_b)\ninputs = tf.split(input_data, seq_length-1, 0)\nstates = []\ninitial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\nstate = initial_state\noutputs = []\npredict_initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\npredict_input =  tf.placeholder(tf.complex64, [1,  2])\npredict_sequence = 100\nindex =0\npredict_outputs = []\noutput, new_state = cell(inputs[i], state)\n\nBut I have the below error, but I checked the documentation and didn't find out how to initialize the weights of LSTM cell as complex tensors.\nValueError: An initializer for variable basic_lstm_cell/weights of <dtype: 'complex64'> is required\n\nCould anyone give me some hint on this? Thanks in advance!", "body": "I am having complex input and output for LSTM, and it looks like I have to initialize LSTM weights as complex tensor. Below is my code:\r\n```\r\nrnn_size = 128\r\ncell = core_rnn_cell.BasicLSTMCell(rnn_size, state_is_tuple=False)\r\nprint 'initiate LSTM cell: ',cell\r\nnum_layers = 1\r\nbatch_size = 1\r\nseq_length = T.shape[0]\r\ninitial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\r\nlearning_rate = 0.003\r\ninput_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name='input_data')\r\ntarget_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name = 'target_data')\r\nlr = tf.Variable(learning_rate, trainable=False, name=\"learning_rate\")\r\nK = 3\r\noutput_size = K + K*(K+1)/2 \r\nembedding_size = 128\r\nwith tf.variable_scope(\"coordinate_embedding\"):\r\n#     real_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = \"complex_weight_real\")\r\n#     imag_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = \"complex_weight_imag\")\r\n#     matrix = tf.complex(real_w, imag_w)\r\n    real_embedding_w = tf.get_variable(\"real_embedding_w\", [K, embedding_size])\r\n    imag_embedding_w = tf.get_variable(\"imag_embedding_w\", [K, embedding_size])\r\n    embedding_w = tf.complex(real_embedding_w, imag_embedding_w)\r\n    real_embedding_b = tf.get_variable(\"real_embedding_b\", [embedding_size])\r\n    imag_embedding_b = tf.get_variable(\"imag_embedding_b\", [embedding_size])\r\n    embedding_b = tf.complex(real_embedding_b, imag_embedding_b)\r\n\r\nwith tf.variable_scope(\"rnnlm\"): \r\n    real_output_w = tf.get_variable(\"real_output_w\", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)\r\n    imag_output_w = tf.get_variable(\"imag_output_w\", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)\r\n    output_w = tf.complex(real_output_w, imag_output_w)\r\n    real_output_b = tf.get_variable(\"real_output_b\", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)\r\n    imag_output_b = tf.get_variable(\"imag_output_b\", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)\r\n    output_b = tf.complex(real_output_b, imag_output_b)\r\ninputs = tf.split(input_data, seq_length-1, 0)\r\nstates = []\r\ninitial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\r\nstate = initial_state\r\noutputs = []\r\npredict_initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)\r\npredict_input =  tf.placeholder(tf.complex64, [1,  2])\r\npredict_sequence = 100\r\nindex =0\r\npredict_outputs = []\r\noutput, new_state = cell(inputs[i], state)\r\n```\r\nBut I have the below error, but I checked the documentation and didn't find out how to initialize the weights of LSTM cell as complex tensors.\r\n```\r\nValueError: An initializer for variable basic_lstm_cell/weights of <dtype: 'complex64'> is required\r\n```\r\n\r\nCould anyone give me some hint on this? Thanks in advance!"}