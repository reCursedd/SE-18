{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19324", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19324/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19324/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19324/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19324", "id": 323553208, "node_id": "MDU6SXNzdWUzMjM1NTMyMDg=", "number": 19324, "title": "[feature request] large scale embedding for sparse features", "user": {"login": "candyzone", "id": 7778833, "node_id": "MDQ6VXNlcjc3Nzg4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7778833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/candyzone", "html_url": "https://github.com/candyzone", "followers_url": "https://api.github.com/users/candyzone/followers", "following_url": "https://api.github.com/users/candyzone/following{/other_user}", "gists_url": "https://api.github.com/users/candyzone/gists{/gist_id}", "starred_url": "https://api.github.com/users/candyzone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/candyzone/subscriptions", "organizations_url": "https://api.github.com/users/candyzone/orgs", "repos_url": "https://api.github.com/users/candyzone/repos", "events_url": "https://api.github.com/users/candyzone/events{/privacy}", "received_events_url": "https://api.github.com/users/candyzone/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "yuefengz", "id": 1647833, "node_id": "MDQ6VXNlcjE2NDc4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1647833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuefengz", "html_url": "https://github.com/yuefengz", "followers_url": "https://api.github.com/users/yuefengz/followers", "following_url": "https://api.github.com/users/yuefengz/following{/other_user}", "gists_url": "https://api.github.com/users/yuefengz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuefengz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuefengz/subscriptions", "organizations_url": "https://api.github.com/users/yuefengz/orgs", "repos_url": "https://api.github.com/users/yuefengz/repos", "events_url": "https://api.github.com/users/yuefengz/events{/privacy}", "received_events_url": "https://api.github.com/users/yuefengz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "yuefengz", "id": 1647833, "node_id": "MDQ6VXNlcjE2NDc4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1647833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuefengz", "html_url": "https://github.com/yuefengz", "followers_url": "https://api.github.com/users/yuefengz/followers", "following_url": "https://api.github.com/users/yuefengz/following{/other_user}", "gists_url": "https://api.github.com/users/yuefengz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuefengz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuefengz/subscriptions", "organizations_url": "https://api.github.com/users/yuefengz/orgs", "repos_url": "https://api.github.com/users/yuefengz/repos", "events_url": "https://api.github.com/users/yuefengz/events{/privacy}", "received_events_url": "https://api.github.com/users/yuefengz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2018-05-16T10:04:17Z", "updated_at": "2018-11-22T06:17:06Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux CentOS 7</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4.0 release</li>\n<li><strong>Python version</strong>: python2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.9.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: gcc4.8.5</li>\n<li><strong>CUDA/cuDNN version</strong>: -</li>\n<li><strong>GPU model and memory</strong>: -</li>\n<li><strong>Exact command to reproduce</strong>: -</li>\n</ul>\n<p>In my scene, training data is very large, we have 10e10 unique values(string) for embedding in one sparse column. In short, model structure is \u201cinput-&gt;embedding-&gt;NNs\u201d. I set hash_bucket_size to 15e10 for low hash collision. sample code:</p>\n<pre><code>col0=tf.contrib.layers.sparse_column_with_hash_bucket(\"feature_id\", hash_bucket_size=1.5e11)\ncols=[tf.feature_column.embedding_column(categorical_column=col0, dimension=8)]\n</code></pre>\n<p>in above example, Tensorflow new a Variable with shape [1.5e11, 8]<br>\nSome problems:</p>\n<ol>\n<li>memory waste, more than 0.5e11<em>8</em>4Bytes memory not used.</li>\n<li>hash collision, though enlarging the <code>hash_bucket_size</code>, it might occurs conflict. I don't know how much it influence on model.</li>\n</ol>\n<p>Is there any suggestions in Tensorflow in this case ?<br>\nIn my opinion:<br>\nDefine a new Variable for embedding, need not define the first demension. It will malloc memory for this Variable when the new value is embedding_lookup. It will solve the two problems mentioned above.</p>\n<p>Thanks</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 7\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.4.0 release\nPython version: python2.7\nBazel version (if compiling from source): 0.9.0\nGCC/Compiler version (if compiling from source): gcc4.8.5\nCUDA/cuDNN version: -\nGPU model and memory: -\nExact command to reproduce: -\n\nIn my scene, training data is very large, we have 10e10 unique values(string) for embedding in one sparse column. In short, model structure is \u201cinput->embedding->NNs\u201d. I set hash_bucket_size to 15e10 for low hash collision. sample code:\ncol0=tf.contrib.layers.sparse_column_with_hash_bucket(\"feature_id\", hash_bucket_size=1.5e11)\ncols=[tf.feature_column.embedding_column(categorical_column=col0, dimension=8)]\n\nin above example, Tensorflow new a Variable with shape [1.5e11, 8]\nSome problems:\n\nmemory waste, more than 0.5e1184Bytes memory not used.\nhash collision, though enlarging the hash_bucket_size, it might occurs conflict. I don't know how much it influence on model.\n\nIs there any suggestions in Tensorflow in this case ?\nIn my opinion:\nDefine a new Variable for embedding, need not define the first demension. It will malloc memory for this Variable when the new value is embedding_lookup. It will solve the two problems mentioned above.\nThanks", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.0 release\r\n- **Python version**: python2.7\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc4.8.5\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: -\r\n\r\nIn my scene, training data is very large, we have 10e10 unique values(string) for embedding in one sparse column. In short, model structure is \u201cinput->embedding->NNs\u201d. I set hash_bucket_size to 15e10 for low hash collision. sample code:\r\n```\r\ncol0=tf.contrib.layers.sparse_column_with_hash_bucket(\"feature_id\", hash_bucket_size=1.5e11)\r\ncols=[tf.feature_column.embedding_column(categorical_column=col0, dimension=8)]\r\n```\r\nin above example, Tensorflow new a Variable with shape [1.5e11, 8]\r\nSome problems:\r\n1. memory waste, more than 0.5e11*8*4Bytes memory not used. \r\n2. hash collision, though enlarging the `hash_bucket_size`, it might occurs conflict. I don't know how much it influence on model. \r\n\r\nIs there any suggestions in Tensorflow in this case ?\r\nIn my opinion: \r\nDefine a new Variable for embedding, need not define the first demension. It will malloc memory for this Variable when the new value is embedding_lookup. It will solve the two problems mentioned above.\r\n\r\nThanks"}