{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/436414426", "html_url": "https://github.com/tensorflow/tensorflow/issues/20874#issuecomment-436414426", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20874", "id": 436414426, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjQxNDQyNg==", "user": {"login": "andreasjansson", "id": 713993, "node_id": "MDQ6VXNlcjcxMzk5Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/713993?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andreasjansson", "html_url": "https://github.com/andreasjansson", "followers_url": "https://api.github.com/users/andreasjansson/followers", "following_url": "https://api.github.com/users/andreasjansson/following{/other_user}", "gists_url": "https://api.github.com/users/andreasjansson/gists{/gist_id}", "starred_url": "https://api.github.com/users/andreasjansson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andreasjansson/subscriptions", "organizations_url": "https://api.github.com/users/andreasjansson/orgs", "repos_url": "https://api.github.com/users/andreasjansson/repos", "events_url": "https://api.github.com/users/andreasjansson/events{/privacy}", "received_events_url": "https://api.github.com/users/andreasjansson/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-06T21:26:48Z", "updated_at": "2018-11-06T21:26:48Z", "author_association": "NONE", "body_html": "<p>I'm seeing the same issue in 1.12.0 (from the <code>tensorflow/tensorflow:1.12.0-gpu</code> Docker image):</p>\n<p>Minimal example to reproduce:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>tensorflow version: <span class=\"pl-c1\">%s</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> tf.<span class=\"pl-c1\">__version__</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">input_fn</span>():\n    <span class=\"pl-k\">return</span> (\n        tf.data.Dataset.from_tensor_slices([<span class=\"pl-c1\">0</span>])\n        .map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">_</span>: tf.random_uniform([<span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">0</span>, np.pi <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span>))\n        .map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: (x, tf.sin(x)))\n        .repeat()\n        .batch(<span class=\"pl-c1\">10</span>)\n    )\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>):\n    net <span class=\"pl-k\">=</span> tf.layers.dense(features, <span class=\"pl-v\">units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">20</span>)\n    net <span class=\"pl-k\">=</span> tf.nn.tanh(net)\n    net <span class=\"pl-k\">=</span> tf.contrib.layers.batch_norm(net)\n    net <span class=\"pl-k\">=</span> tf.layers.dense(net, <span class=\"pl-v\">units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">20</span>)\n    net <span class=\"pl-k\">=</span> tf.nn.tanh(net)\n    output <span class=\"pl-k\">=</span> tf.layers.dense(net, <span class=\"pl-v\">units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>:\n        loss <span class=\"pl-k\">=</span> tf.reduce_mean(tf.pow(output <span class=\"pl-k\">-</span> labels, <span class=\"pl-c1\">2</span>))\n        train_op <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">0.1</span>).minimize(loss, <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>tf.train.get_global_step())\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>train_op)\n\ndistribution <span class=\"pl-k\">=</span> tf.contrib.distribute.MirroredStrategy()\nconfig <span class=\"pl-k\">=</span> tf.estimator.RunConfig(<span class=\"pl-v\">train_distribute</span><span class=\"pl-k\">=</span>distribution)\nestimator <span class=\"pl-k\">=</span> tf.estimator.Estimator(<span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>model_fn, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config)\n\nestimator.train(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>input_fn, <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1000</span>)</pre></div>\n<p>Output:</p>\n<pre><code>tensorflow version: 1.12.0\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:Not using Distribute Coordinator.\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpF_Z_3F\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29a0297d90&gt;, '_model_dir': '/tmp/tmpF_Z_3F', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': &lt;tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f2a82dfe110&gt;, '_master': '', '_distribute_coordinator_mode': None}\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\nINFO:tensorflow:Configured nccl all-reduce.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Error reported to Coordinator: \nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"&lt;ipython-input-114-26a55e49533e&gt;\", line 19, in model_fn\n    net = tf.contrib.layers.batch_norm(net)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 596, in batch_norm\n    scope=scope)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 416, in _fused_batch_norm\n    is_training, _delay_updates, moving_vars_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 214, in smart_cond\n    return static_cond(pred_value, fn1, fn2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 192, in static_cond\n    return fn1()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 410, in _delay_updates\n    moving_mean, mean, decay, zero_debias=zero_debias_moving_mean)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/moving_averages.py\", line 84, in assign_moving_average\n    with ops.colocate_with(variable):\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4094, in _colocate_with_for_gradient\n    with self.colocate_with(op, ignore_existing):\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4146, in colocate_with\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1307, in internal_convert_to_tensor_or_indexed_slices\n    value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\n    assert not as_ref\nAssertionError\n</code></pre>", "body_text": "I'm seeing the same issue in 1.12.0 (from the tensorflow/tensorflow:1.12.0-gpu Docker image):\nMinimal example to reproduce:\nimport tensorflow as tf\nimport numpy as np\n\nprint('tensorflow version: %s' % tf.__version__)\n\ndef input_fn():\n    return (\n        tf.data.Dataset.from_tensor_slices([0])\n        .map(lambda _: tf.random_uniform([1], 0, np.pi * 2))\n        .map(lambda x: (x, tf.sin(x)))\n        .repeat()\n        .batch(10)\n    )\n\ndef model_fn(features, labels, mode):\n    net = tf.layers.dense(features, units=20)\n    net = tf.nn.tanh(net)\n    net = tf.contrib.layers.batch_norm(net)\n    net = tf.layers.dense(net, units=20)\n    net = tf.nn.tanh(net)\n    output = tf.layers.dense(net, units=1)\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        loss = tf.reduce_mean(tf.pow(output - labels, 2))\n        train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\n\ndistribution = tf.contrib.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\n\nestimator.train(input_fn=input_fn, steps=1000)\nOutput:\ntensorflow version: 1.12.0\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:Not using Distribute Coordinator.\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpF_Z_3F\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29a0297d90>, '_model_dir': '/tmp/tmpF_Z_3F', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f2a82dfe110>, '_master': '', '_distribute_coordinator_mode': None}\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\nINFO:tensorflow:Configured nccl all-reduce.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Error reported to Coordinator: \nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-114-26a55e49533e>\", line 19, in model_fn\n    net = tf.contrib.layers.batch_norm(net)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 596, in batch_norm\n    scope=scope)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 416, in _fused_batch_norm\n    is_training, _delay_updates, moving_vars_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 214, in smart_cond\n    return static_cond(pred_value, fn1, fn2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 192, in static_cond\n    return fn1()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 410, in _delay_updates\n    moving_mean, mean, decay, zero_debias=zero_debias_moving_mean)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/moving_averages.py\", line 84, in assign_moving_average\n    with ops.colocate_with(variable):\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4094, in _colocate_with_for_gradient\n    with self.colocate_with(op, ignore_existing):\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4146, in colocate_with\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1307, in internal_convert_to_tensor_or_indexed_slices\n    value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\n    assert not as_ref\nAssertionError", "body": "I'm seeing the same issue in 1.12.0 (from the `tensorflow/tensorflow:1.12.0-gpu` Docker image):\r\n\r\nMinimal example to reproduce:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nprint('tensorflow version: %s' % tf.__version__)\r\n\r\ndef input_fn():\r\n    return (\r\n        tf.data.Dataset.from_tensor_slices([0])\r\n        .map(lambda _: tf.random_uniform([1], 0, np.pi * 2))\r\n        .map(lambda x: (x, tf.sin(x)))\r\n        .repeat()\r\n        .batch(10)\r\n    )\r\n\r\ndef model_fn(features, labels, mode):\r\n    net = tf.layers.dense(features, units=20)\r\n    net = tf.nn.tanh(net)\r\n    net = tf.contrib.layers.batch_norm(net)\r\n    net = tf.layers.dense(net, units=20)\r\n    net = tf.nn.tanh(net)\r\n    output = tf.layers.dense(net, units=1)\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        loss = tf.reduce_mean(tf.pow(output - labels, 2))\r\n        train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss, global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\r\n\r\ndistribution = tf.contrib.distribute.MirroredStrategy()\r\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\r\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\r\n\r\nestimator.train(input_fn=input_fn, steps=1000)\r\n```\r\n\r\nOutput:\r\n\r\n```\r\ntensorflow version: 1.12.0\r\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\r\nINFO:tensorflow:Not using Distribute Coordinator.\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpF_Z_3F\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29a0297d90>, '_model_dir': '/tmp/tmpF_Z_3F', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f2a82dfe110>, '_master': '', '_distribute_coordinator_mode': None}\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\r\nINFO:tensorflow:Configured nccl all-reduce.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Error reported to Coordinator: \r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\r\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"<ipython-input-114-26a55e49533e>\", line 19, in model_fn\r\n    net = tf.contrib.layers.batch_norm(net)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 596, in batch_norm\r\n    scope=scope)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 416, in _fused_batch_norm\r\n    is_training, _delay_updates, moving_vars_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 214, in smart_cond\r\n    return static_cond(pred_value, fn1, fn2)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 192, in static_cond\r\n    return fn1()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 410, in _delay_updates\r\n    moving_mean, mean, decay, zero_debias=zero_debias_moving_mean)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/moving_averages.py\", line 84, in assign_moving_average\r\n    with ops.colocate_with(variable):\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4094, in _colocate_with_for_gradient\r\n    with self.colocate_with(op, ignore_existing):\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4146, in colocate_with\r\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1307, in internal_convert_to_tensor_or_indexed_slices\r\n    value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\r\n    assert not as_ref\r\nAssertionError\r\n```"}