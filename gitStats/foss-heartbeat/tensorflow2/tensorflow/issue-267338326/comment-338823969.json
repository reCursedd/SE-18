{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/338823969", "html_url": "https://github.com/tensorflow/tensorflow/issues/13875#issuecomment-338823969", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13875", "id": 338823969, "node_id": "MDEyOklzc3VlQ29tbWVudDMzODgyMzk2OQ==", "user": {"login": "jthestness", "id": 28744304, "node_id": "MDQ6VXNlcjI4NzQ0MzA0", "avatar_url": "https://avatars0.githubusercontent.com/u/28744304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jthestness", "html_url": "https://github.com/jthestness", "followers_url": "https://api.github.com/users/jthestness/followers", "following_url": "https://api.github.com/users/jthestness/following{/other_user}", "gists_url": "https://api.github.com/users/jthestness/gists{/gist_id}", "starred_url": "https://api.github.com/users/jthestness/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jthestness/subscriptions", "organizations_url": "https://api.github.com/users/jthestness/orgs", "repos_url": "https://api.github.com/users/jthestness/repos", "events_url": "https://api.github.com/users/jthestness/events{/privacy}", "received_events_url": "https://api.github.com/users/jthestness/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-23T23:17:08Z", "updated_at": "2017-10-23T23:17:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>We've tested a few more things: we tried <code>--config=monolithic</code>, we built the current TF mainline head <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/ea94bbe9fa9f9b3d01fb057c02ef7873d76bf09c/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/ea94bbe9fa9f9b3d01fb057c02ef7873d76bf09c\"><tt>ea94bbe</tt></a> without the CUDA 9/cuDNN 7 changes from NVIDIA, and built using prior versions of CUDA (8) and cuDNN (6). The error exists after each of these builds. IOW, the NVIDIA patches were not part of the problem.</p>\n<p>We've started looking into Bazel's process for static linking against the MPI library. It seems like we might not be pulling MPI symbols into the TF binary, so during linking, gcc might be stripping out the MPI ops thinking they don't connect to anything (i.e., dead code elimination).</p>\n<p>The reason we don't have any Jenkins tests for tf.contrib.mpi_collectives is that we don't currently have a way to build TF with MPI enabled. It requires an MPI library to run the simple ops, and to test the collectives ops, we would need Bazel to be able to run multiple threads or processes that would communicate.</p>", "body_text": "We've tested a few more things: we tried --config=monolithic, we built the current TF mainline head ea94bbe without the CUDA 9/cuDNN 7 changes from NVIDIA, and built using prior versions of CUDA (8) and cuDNN (6). The error exists after each of these builds. IOW, the NVIDIA patches were not part of the problem.\nWe've started looking into Bazel's process for static linking against the MPI library. It seems like we might not be pulling MPI symbols into the TF binary, so during linking, gcc might be stripping out the MPI ops thinking they don't connect to anything (i.e., dead code elimination).\nThe reason we don't have any Jenkins tests for tf.contrib.mpi_collectives is that we don't currently have a way to build TF with MPI enabled. It requires an MPI library to run the simple ops, and to test the collectives ops, we would need Bazel to be able to run multiple threads or processes that would communicate.", "body": "We've tested a few more things: we tried `--config=monolithic`, we built the current TF mainline head ea94bbe without the CUDA 9/cuDNN 7 changes from NVIDIA, and built using prior versions of CUDA (8) and cuDNN (6). The error exists after each of these builds. IOW, the NVIDIA patches were not part of the problem.\r\n\r\nWe've started looking into Bazel's process for static linking against the MPI library. It seems like we might not be pulling MPI symbols into the TF binary, so during linking, gcc might be stripping out the MPI ops thinking they don't connect to anything (i.e., dead code elimination).\r\n\r\nThe reason we don't have any Jenkins tests for tf.contrib.mpi_collectives is that we don't currently have a way to build TF with MPI enabled. It requires an MPI library to run the simple ops, and to test the collectives ops, we would need Bazel to be able to run multiple threads or processes that would communicate."}