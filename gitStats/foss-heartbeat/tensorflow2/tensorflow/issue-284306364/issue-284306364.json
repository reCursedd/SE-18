{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15601", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15601/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15601/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15601/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/15601", "id": 284306364, "node_id": "MDExOlB1bGxSZXF1ZXN0MTU5OTY4NTAy", "number": 15601, "title": "Optimize FusedBatchNorm (and fix a bug).", "user": {"login": "codrut3", "id": 10788581, "node_id": "MDQ6VXNlcjEwNzg4NTgx", "avatar_url": "https://avatars1.githubusercontent.com/u/10788581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codrut3", "html_url": "https://github.com/codrut3", "followers_url": "https://api.github.com/users/codrut3/followers", "following_url": "https://api.github.com/users/codrut3/following{/other_user}", "gists_url": "https://api.github.com/users/codrut3/gists{/gist_id}", "starred_url": "https://api.github.com/users/codrut3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codrut3/subscriptions", "organizations_url": "https://api.github.com/users/codrut3/orgs", "repos_url": "https://api.github.com/users/codrut3/repos", "events_url": "https://api.github.com/users/codrut3/events{/privacy}", "received_events_url": "https://api.github.com/users/codrut3/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 390482148, "node_id": "MDU6TGFiZWwzOTA0ODIxNDg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20review", "name": "awaiting review", "color": "fef2c0", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-12-23T13:22:22Z", "updated_at": "2018-01-13T23:45:21Z", "closed_at": "2018-01-13T23:45:21Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15601", "html_url": "https://github.com/tensorflow/tensorflow/pull/15601", "diff_url": "https://github.com/tensorflow/tensorflow/pull/15601.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/15601.patch"}, "body_html": "<p>I discovered experimentally that <code>cudnn</code> computations can be performed in place. Therefore there is no need to allocate two temporary tensors in <code>FusedBatchNorm</code> for GPU and data format NHWC. One is enough. This lowers memory consumption, and hence increases the maximum possible batch size.</p>\n<p>This might seem risky (because NVIDIA doesn't mention the property), but in fact the current implementation already uses it: by doing forward_input_or_allocate_output in <code>FusedBatchNormOp</code>.<br>\nIf data format is NCHW, and the input is forwarded, then <code>cudnn</code> would be forced<br>\nto do the computation in place (see line 247). This is how I discovered that the whole approach works:<br>\nI was trying to see if forwarding the input is a bug or not.</p>\n<p>I added several tests to ensure that the change is correct.</p>\n<p>While doing this, I discovered that ops_testutil does not properly synchronize at the end.<br>\nThe reason seems to be the call <code>context_-&gt;eigen_gpu_device().synchronize()</code>. Somehow<br>\nit does nothing. I think the problem is that Eigen is not compiled with the flag <code>EIGEN_CUDACC</code>.<br>\nSo I changed it to <code>GPUUtil::Sync(device_.get())</code>.</p>", "body_text": "I discovered experimentally that cudnn computations can be performed in place. Therefore there is no need to allocate two temporary tensors in FusedBatchNorm for GPU and data format NHWC. One is enough. This lowers memory consumption, and hence increases the maximum possible batch size.\nThis might seem risky (because NVIDIA doesn't mention the property), but in fact the current implementation already uses it: by doing forward_input_or_allocate_output in FusedBatchNormOp.\nIf data format is NCHW, and the input is forwarded, then cudnn would be forced\nto do the computation in place (see line 247). This is how I discovered that the whole approach works:\nI was trying to see if forwarding the input is a bug or not.\nI added several tests to ensure that the change is correct.\nWhile doing this, I discovered that ops_testutil does not properly synchronize at the end.\nThe reason seems to be the call context_->eigen_gpu_device().synchronize(). Somehow\nit does nothing. I think the problem is that Eigen is not compiled with the flag EIGEN_CUDACC.\nSo I changed it to GPUUtil::Sync(device_.get()).", "body": "I discovered experimentally that `cudnn` computations can be performed in place. Therefore there is no need to allocate two temporary tensors in `FusedBatchNorm` for GPU and data format NHWC. One is enough. This lowers memory consumption, and hence increases the maximum possible batch size.\r\n\r\nThis might seem risky (because NVIDIA doesn't mention the property), but in fact the current implementation already uses it: by doing forward_input_or_allocate_output in `FusedBatchNormOp`.\r\nIf data format is NCHW, and the input is forwarded, then `cudnn` would be forced\r\nto do the computation in place (see line 247). This is how I discovered that the whole approach works:\r\nI was trying to see if forwarding the input is a bug or not.\r\n\r\nI added several tests to ensure that the change is correct.\r\n\r\nWhile doing this, I discovered that ops_testutil does not properly synchronize at the end.\r\nThe reason seems to be the call `context_->eigen_gpu_device().synchronize()`. Somehow\r\nit does nothing. I think the problem is that Eigen is not compiled with the flag `EIGEN_CUDACC`.\r\nSo I changed it to `GPUUtil::Sync(device_.get())`."}