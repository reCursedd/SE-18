{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22902", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22902/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22902/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22902/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22902", "id": 369239608, "node_id": "MDU6SXNzdWUzNjkyMzk2MDg=", "number": 22902, "title": "Linker error when compiling from head of master on MacOS", "user": {"login": "georgepaw", "id": 6642663, "node_id": "MDQ6VXNlcjY2NDI2NjM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6642663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgepaw", "html_url": "https://github.com/georgepaw", "followers_url": "https://api.github.com/users/georgepaw/followers", "following_url": "https://api.github.com/users/georgepaw/following{/other_user}", "gists_url": "https://api.github.com/users/georgepaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgepaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgepaw/subscriptions", "organizations_url": "https://api.github.com/users/georgepaw/orgs", "repos_url": "https://api.github.com/users/georgepaw/repos", "events_url": "https://api.github.com/users/georgepaw/events{/privacy}", "received_events_url": "https://api.github.com/users/georgepaw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173351, "node_id": "MDU6TGFiZWw0NzMxNzMzNTE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "meteorcloudy", "id": 4171702, "node_id": "MDQ6VXNlcjQxNzE3MDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/4171702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meteorcloudy", "html_url": "https://github.com/meteorcloudy", "followers_url": "https://api.github.com/users/meteorcloudy/followers", "following_url": "https://api.github.com/users/meteorcloudy/following{/other_user}", "gists_url": "https://api.github.com/users/meteorcloudy/gists{/gist_id}", "starred_url": "https://api.github.com/users/meteorcloudy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meteorcloudy/subscriptions", "organizations_url": "https://api.github.com/users/meteorcloudy/orgs", "repos_url": "https://api.github.com/users/meteorcloudy/repos", "events_url": "https://api.github.com/users/meteorcloudy/events{/privacy}", "received_events_url": "https://api.github.com/users/meteorcloudy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "meteorcloudy", "id": 4171702, "node_id": "MDQ6VXNlcjQxNzE3MDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/4171702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meteorcloudy", "html_url": "https://github.com/meteorcloudy", "followers_url": "https://api.github.com/users/meteorcloudy/followers", "following_url": "https://api.github.com/users/meteorcloudy/following{/other_user}", "gists_url": "https://api.github.com/users/meteorcloudy/gists{/gist_id}", "starred_url": "https://api.github.com/users/meteorcloudy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meteorcloudy/subscriptions", "organizations_url": "https://api.github.com/users/meteorcloudy/orgs", "repos_url": "https://api.github.com/users/meteorcloudy/repos", "events_url": "https://api.github.com/users/meteorcloudy/events{/privacy}", "received_events_url": "https://api.github.com/users/meteorcloudy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-10-11T18:03:01Z", "updated_at": "2018-11-20T12:57:41Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOS Mojave and High Sierra</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: master</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.17..2-homebrew</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n</ul>\n<pre><code>clang -v\nApple LLVM version 10.0.0 (clang-1000.11.45.2)\n</code></pre>\n<ul>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>bazel test --test_output=all --nocache_test_results --config=opt tensorflow/compiler/tests:cpu_tests\n</code></pre>\n<p>(Configured with XLA support enabled)</p>\n<h3>Describe the problem</h3>\n<p>When trying to run the above command I get:</p>\n<pre><code>ld: can't open -exported_symbols_list file: -filelist\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n</code></pre>\n<h3>Source code / logs</h3>\n<p>After applying this diff:</p>\n<div class=\"highlight highlight-source-diff\"><pre>index df15914233..8de9c7cfdd 100644\n<span class=\"pl-md\">--- a/tensorflow/tensorflow.bzl</span>\n<span class=\"pl-mi1\">+++ b/tensorflow/tensorflow.bzl</span>\n<span class=\"pl-mdr\">@@ -1636,8 +1636,7 @@</span> def tf_py_wrap_cc(\n     )\n     extra_linkopts = select({\n         \"@local_config_cuda//cuda:darwin\": [\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>            \"-Wl,-exported_symbols_list\",</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>            \"$(location %s.lds)\" % vscriptname,</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>            \"-Wl,-exported_symbols_list,$(location %s.lds)\" % vscriptname,</span>\n         ],\n         clean_dep(\"//tensorflow:windows\"): [],\n         \"//conditions:default\": [</pre></div>\n<p>and running <code>bazel test --test_output=all --nocache_test_results --config=opt tensorflow/compiler/tests:cpu_tests</code></p>\n<p>I get lots of warnings during linking:</p>\n<pre><code>ld: warning: cannot export hidden symbol std::__1::shared_ptr&lt;tensorflow::AWSSha256HMACOpenSSLImpl&gt;::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/platform/s3/libaws_crypto.lo(aws_crypto.o)\nld: warning: cannot export hidden symbol std::__1::shared_ptr&lt;tensorflow::AWSLogSystem&gt;::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/platform/s3/libaws_logging.lo(aws_logging.o)\nld: warning: cannot export hidden symbol std::__1::shared_ptr&lt;tensorflow::Notification&gt;::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/grappler/libutils.a(utils.o)\n</code></pre>\n<p>And then when the tests are ran I get errors such as:</p>\n<pre><code>2018-10-11 13:02:47.136859: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\n*** Received signal 10 ***\n*** BEGIN MANGLED STACK TRACE ***\n0   libtensorflow_framework.so          0x00000001200870a7 _ZN10tensorflow7testingL17StacktraceHandlerEiP9__siginfoPv + 183\n1   libsystem_platform.dylib            0x00007fff66049b3d _sigtramp + 29\n2   ???                                 0x0000000000000000 0x0 + 0\n3   _pywrap_tensorflow_internal.so      0x00000001143583a9 _ZNSt3__110__function6__funcIZN3xla3cpu13CpuExecutable24ExecuteAsyncOnStreamImplEPKNS2_27ServiceExecutableRunOptionsEN4absl4SpanIKPKNS2_12ShapedBufferEEEPNS2_19HloExecutionProfileEE12AsyncRunTaskNS_9allocatorISH_EEFvvEEclEv + 73\n4   libtensorflow_framework.so          0x000000012032bd09 _ZNSt3__110__function6__funcIZN15stream_executor4host10HostStream11EnqueueTaskENS_8functionIFvvEEEE12NotifiedTaskNS_9allocatorIS8_EES6_EclEv + 25\n5   libtensorflow_framework.so          0x00000001200641da _ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi + 618\n6   libtensorflow_framework.so          0x0000000120063e6f _ZNSt3__110__function6__funcIZN10tensorflow6thread16EigenEnvironment12CreateThreadENS_8functionIFvvEEEEUlvE_NS_9allocatorIS8_EES6_EclEv + 47\n7   libtensorflow_framework.so          0x0000000120088a30 _ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEENS_8functionIFvvEEEEEEEEPvSB_ + 48\n8   libsystem_pthread.dylib             0x00007fff6605233d _pthread_body + 126\n9   libsystem_pthread.dylib             0x00007fff660552a7 _pthread_start + 70\n10  libsystem_pthread.dylib             0x00007fff66051425 thread_start + 13\n*** END MANGLED STACK TRACE ***\n\n*** Begin stack trace ***\n\ttensorflow::CurrentStackTrace()\n\ttensorflow::testing::StacktraceHandler(int, __siginfo*, void*)\n\t_sigtramp\n\n\tstd::__1::__function::__func&lt;xla::cpu::CpuExecutable::ExecuteAsyncOnStreamImpl(xla::ServiceExecutableRunOptions const*, absl::Span&lt;xla::ShapedBuffer const* const&gt;, xla::HloExecutionProfile*)::AsyncRunTask, std::__1::allocator&lt;xla::cpu::CpuExecutable::ExecuteAsyncOnStreamImpl(xla::ServiceExecutableRunOptions const*, absl::Span&lt;xla::ShapedBuffer const* const&gt;, xla::HloExecutionProfile*)::AsyncRunTask&gt;, void ()&gt;::operator()()\n\tstd::__1::__function::__func&lt;stream_executor::host::HostStream::EnqueueTask(std::__1::function&lt;void ()&gt;)::NotifiedTask, std::__1::allocator&lt;stream_executor::host::HostStream::EnqueueTask(std::__1::function&lt;void ()&gt;)::NotifiedTask&gt;, void ()&gt;::operator()()\n\tEigen::NonBlockingThreadPoolTempl&lt;tensorflow::thread::EigenEnvironment&gt;::WorkerLoop(int)\n\tstd::__1::__function::__func&lt;tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function&lt;void ()&gt;)::'lambda'(), std::__1::allocator&lt;tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function&lt;void ()&gt;)::'lambda'()&gt;, void ()&gt;::operator()()\n\tvoid* std::__1::__thread_proxy&lt;std::__1::tuple&lt;std::__1::unique_ptr&lt;std::__1::__thread_struct, std::__1::default_delete&lt;std::__1::__thread_struct&gt; &gt;, std::__1::function&lt;void ()&gt; &gt; &gt;(void*)\n\t_pthread_body\n\t_pthread_start\n\tthread_start\n*** End stack trace ***\n</code></pre>\n<p>Note that <code>cc_wrapper.sh</code> calls <code>gcc</code> however I haven't changed it so it still points at Apple LLVM.</p>\n<p>Note that there is an issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"367084543\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/22759\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/22759/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/22759\">#22759</a> however that one uses custom code, where as this is HEAD of master.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave and High Sierra\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): master\nPython version: 2.7\nBazel version (if compiling from source): 0.17..2-homebrew\nGCC/Compiler version (if compiling from source):\n\nclang -v\nApple LLVM version 10.0.0 (clang-1000.11.45.2)\n\n\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce:\n\nbazel test --test_output=all --nocache_test_results --config=opt tensorflow/compiler/tests:cpu_tests\n\n(Configured with XLA support enabled)\nDescribe the problem\nWhen trying to run the above command I get:\nld: can't open -exported_symbols_list file: -filelist\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n\nSource code / logs\nAfter applying this diff:\nindex df15914233..8de9c7cfdd 100644\n--- a/tensorflow/tensorflow.bzl\n+++ b/tensorflow/tensorflow.bzl\n@@ -1636,8 +1636,7 @@ def tf_py_wrap_cc(\n     )\n     extra_linkopts = select({\n         \"@local_config_cuda//cuda:darwin\": [\n-            \"-Wl,-exported_symbols_list\",\n-            \"$(location %s.lds)\" % vscriptname,\n+            \"-Wl,-exported_symbols_list,$(location %s.lds)\" % vscriptname,\n         ],\n         clean_dep(\"//tensorflow:windows\"): [],\n         \"//conditions:default\": [\nand running bazel test --test_output=all --nocache_test_results --config=opt tensorflow/compiler/tests:cpu_tests\nI get lots of warnings during linking:\nld: warning: cannot export hidden symbol std::__1::shared_ptr<tensorflow::AWSSha256HMACOpenSSLImpl>::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/platform/s3/libaws_crypto.lo(aws_crypto.o)\nld: warning: cannot export hidden symbol std::__1::shared_ptr<tensorflow::AWSLogSystem>::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/platform/s3/libaws_logging.lo(aws_logging.o)\nld: warning: cannot export hidden symbol std::__1::shared_ptr<tensorflow::Notification>::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/grappler/libutils.a(utils.o)\n\nAnd then when the tests are ran I get errors such as:\n2018-10-11 13:02:47.136859: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\n*** Received signal 10 ***\n*** BEGIN MANGLED STACK TRACE ***\n0   libtensorflow_framework.so          0x00000001200870a7 _ZN10tensorflow7testingL17StacktraceHandlerEiP9__siginfoPv + 183\n1   libsystem_platform.dylib            0x00007fff66049b3d _sigtramp + 29\n2   ???                                 0x0000000000000000 0x0 + 0\n3   _pywrap_tensorflow_internal.so      0x00000001143583a9 _ZNSt3__110__function6__funcIZN3xla3cpu13CpuExecutable24ExecuteAsyncOnStreamImplEPKNS2_27ServiceExecutableRunOptionsEN4absl4SpanIKPKNS2_12ShapedBufferEEEPNS2_19HloExecutionProfileEE12AsyncRunTaskNS_9allocatorISH_EEFvvEEclEv + 73\n4   libtensorflow_framework.so          0x000000012032bd09 _ZNSt3__110__function6__funcIZN15stream_executor4host10HostStream11EnqueueTaskENS_8functionIFvvEEEE12NotifiedTaskNS_9allocatorIS8_EES6_EclEv + 25\n5   libtensorflow_framework.so          0x00000001200641da _ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi + 618\n6   libtensorflow_framework.so          0x0000000120063e6f _ZNSt3__110__function6__funcIZN10tensorflow6thread16EigenEnvironment12CreateThreadENS_8functionIFvvEEEEUlvE_NS_9allocatorIS8_EES6_EclEv + 47\n7   libtensorflow_framework.so          0x0000000120088a30 _ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEENS_8functionIFvvEEEEEEEEPvSB_ + 48\n8   libsystem_pthread.dylib             0x00007fff6605233d _pthread_body + 126\n9   libsystem_pthread.dylib             0x00007fff660552a7 _pthread_start + 70\n10  libsystem_pthread.dylib             0x00007fff66051425 thread_start + 13\n*** END MANGLED STACK TRACE ***\n\n*** Begin stack trace ***\n\ttensorflow::CurrentStackTrace()\n\ttensorflow::testing::StacktraceHandler(int, __siginfo*, void*)\n\t_sigtramp\n\n\tstd::__1::__function::__func<xla::cpu::CpuExecutable::ExecuteAsyncOnStreamImpl(xla::ServiceExecutableRunOptions const*, absl::Span<xla::ShapedBuffer const* const>, xla::HloExecutionProfile*)::AsyncRunTask, std::__1::allocator<xla::cpu::CpuExecutable::ExecuteAsyncOnStreamImpl(xla::ServiceExecutableRunOptions const*, absl::Span<xla::ShapedBuffer const* const>, xla::HloExecutionProfile*)::AsyncRunTask>, void ()>::operator()()\n\tstd::__1::__function::__func<stream_executor::host::HostStream::EnqueueTask(std::__1::function<void ()>)::NotifiedTask, std::__1::allocator<stream_executor::host::HostStream::EnqueueTask(std::__1::function<void ()>)::NotifiedTask>, void ()>::operator()()\n\tEigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int)\n\tstd::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()()\n\tvoid* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*)\n\t_pthread_body\n\t_pthread_start\n\tthread_start\n*** End stack trace ***\n\nNote that cc_wrapper.sh calls gcc however I haven't changed it so it still points at Apple LLVM.\nNote that there is an issue #22759 however that one uses custom code, where as this is HEAD of master.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave and High Sierra\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.17..2-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: \r\n```\r\nclang -v\r\nApple LLVM version 10.0.0 (clang-1000.11.45.2)\r\n```\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\n```\r\nbazel test --test_output=all --nocache_test_results --config=opt tensorflow/compiler/tests:cpu_tests\r\n```\r\n(Configured with XLA support enabled)\r\n### Describe the problem\r\nWhen trying to run the above command I get:\r\n```\r\nld: can't open -exported_symbols_list file: -filelist\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n```\r\n\r\n### Source code / logs\r\nAfter applying this diff:\r\n```diff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\r\nindex df15914233..8de9c7cfdd 100644\r\n--- a/tensorflow/tensorflow.bzl\r\n+++ b/tensorflow/tensorflow.bzl\r\n@@ -1636,8 +1636,7 @@ def tf_py_wrap_cc(\r\n     )\r\n     extra_linkopts = select({\r\n         \"@local_config_cuda//cuda:darwin\": [\r\n-            \"-Wl,-exported_symbols_list\",\r\n-            \"$(location %s.lds)\" % vscriptname,\r\n+            \"-Wl,-exported_symbols_list,$(location %s.lds)\" % vscriptname,\r\n         ],\r\n         clean_dep(\"//tensorflow:windows\"): [],\r\n         \"//conditions:default\": [\r\n```\r\n\r\nand running `bazel test --test_output=all --nocache_test_results --config=opt tensorflow/compiler/tests:cpu_tests`\r\n\r\nI get lots of warnings during linking:\r\n```\r\nld: warning: cannot export hidden symbol std::__1::shared_ptr<tensorflow::AWSSha256HMACOpenSSLImpl>::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/platform/s3/libaws_crypto.lo(aws_crypto.o)\r\nld: warning: cannot export hidden symbol std::__1::shared_ptr<tensorflow::AWSLogSystem>::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/platform/s3/libaws_logging.lo(aws_logging.o)\r\nld: warning: cannot export hidden symbol std::__1::shared_ptr<tensorflow::Notification>::__enable_weak_this(...) from bazel-out/darwin-opt/bin/tensorflow/core/grappler/libutils.a(utils.o)\r\n```\r\n\r\nAnd then when the tests are ran I get errors such as:\r\n\r\n```\r\n2018-10-11 13:02:47.136859: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n*** Received signal 10 ***\r\n*** BEGIN MANGLED STACK TRACE ***\r\n0   libtensorflow_framework.so          0x00000001200870a7 _ZN10tensorflow7testingL17StacktraceHandlerEiP9__siginfoPv + 183\r\n1   libsystem_platform.dylib            0x00007fff66049b3d _sigtramp + 29\r\n2   ???                                 0x0000000000000000 0x0 + 0\r\n3   _pywrap_tensorflow_internal.so      0x00000001143583a9 _ZNSt3__110__function6__funcIZN3xla3cpu13CpuExecutable24ExecuteAsyncOnStreamImplEPKNS2_27ServiceExecutableRunOptionsEN4absl4SpanIKPKNS2_12ShapedBufferEEEPNS2_19HloExecutionProfileEE12AsyncRunTaskNS_9allocatorISH_EEFvvEEclEv + 73\r\n4   libtensorflow_framework.so          0x000000012032bd09 _ZNSt3__110__function6__funcIZN15stream_executor4host10HostStream11EnqueueTaskENS_8functionIFvvEEEE12NotifiedTaskNS_9allocatorIS8_EES6_EclEv + 25\r\n5   libtensorflow_framework.so          0x00000001200641da _ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi + 618\r\n6   libtensorflow_framework.so          0x0000000120063e6f _ZNSt3__110__function6__funcIZN10tensorflow6thread16EigenEnvironment12CreateThreadENS_8functionIFvvEEEEUlvE_NS_9allocatorIS8_EES6_EclEv + 47\r\n7   libtensorflow_framework.so          0x0000000120088a30 _ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEENS_8functionIFvvEEEEEEEEPvSB_ + 48\r\n8   libsystem_pthread.dylib             0x00007fff6605233d _pthread_body + 126\r\n9   libsystem_pthread.dylib             0x00007fff660552a7 _pthread_start + 70\r\n10  libsystem_pthread.dylib             0x00007fff66051425 thread_start + 13\r\n*** END MANGLED STACK TRACE ***\r\n\r\n*** Begin stack trace ***\r\n\ttensorflow::CurrentStackTrace()\r\n\ttensorflow::testing::StacktraceHandler(int, __siginfo*, void*)\r\n\t_sigtramp\r\n\r\n\tstd::__1::__function::__func<xla::cpu::CpuExecutable::ExecuteAsyncOnStreamImpl(xla::ServiceExecutableRunOptions const*, absl::Span<xla::ShapedBuffer const* const>, xla::HloExecutionProfile*)::AsyncRunTask, std::__1::allocator<xla::cpu::CpuExecutable::ExecuteAsyncOnStreamImpl(xla::ServiceExecutableRunOptions const*, absl::Span<xla::ShapedBuffer const* const>, xla::HloExecutionProfile*)::AsyncRunTask>, void ()>::operator()()\r\n\tstd::__1::__function::__func<stream_executor::host::HostStream::EnqueueTask(std::__1::function<void ()>)::NotifiedTask, std::__1::allocator<stream_executor::host::HostStream::EnqueueTask(std::__1::function<void ()>)::NotifiedTask>, void ()>::operator()()\r\n\tEigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int)\r\n\tstd::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()()\r\n\tvoid* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*)\r\n\t_pthread_body\r\n\t_pthread_start\r\n\tthread_start\r\n*** End stack trace ***\r\n```\r\n\r\nNote that `cc_wrapper.sh` calls `gcc` however I haven't changed it so it still points at Apple LLVM.\r\n\r\nNote that there is an issue #22759 however that one uses custom code, where as this is HEAD of master."}