{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16803", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16803/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16803/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16803/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16803", "id": 294806466, "node_id": "MDU6SXNzdWUyOTQ4MDY0NjY=", "number": 16803, "title": "transform_graph generates faulty model after optimization (quantisation).", "user": {"login": "kmonachopoulos", "id": 3832904, "node_id": "MDQ6VXNlcjM4MzI5MDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/3832904?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmonachopoulos", "html_url": "https://github.com/kmonachopoulos", "followers_url": "https://api.github.com/users/kmonachopoulos/followers", "following_url": "https://api.github.com/users/kmonachopoulos/following{/other_user}", "gists_url": "https://api.github.com/users/kmonachopoulos/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmonachopoulos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmonachopoulos/subscriptions", "organizations_url": "https://api.github.com/users/kmonachopoulos/orgs", "repos_url": "https://api.github.com/users/kmonachopoulos/repos", "events_url": "https://api.github.com/users/kmonachopoulos/events{/privacy}", "received_events_url": "https://api.github.com/users/kmonachopoulos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2018-02-06T15:43:05Z", "updated_at": "2018-08-09T20:45:38Z", "closed_at": "2018-08-09T20:44:57Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource</li>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n<li><strong>Python version</strong>:<br>\n1.4.1</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.8.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\ngcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.6)</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am using a pre-trained style transfer model that I have converted  to .pb format. When I inference a single image through the fp32 model then I can see the styled image at the output of the network and everything works fine. Later on I optimized the model for inference using <code>transform_graph</code> tool with these parameters :</p>\n<pre><code>--transforms='\n  add_default_attributes\n  strip_unused_nodes(type=float)\n  remove_nodes(op=CheckNumerics)\n  fold_constants(ignore_errors=true)\n  fold_batch_norms\n  fold_old_batch_norms\n  quantize_weights\n  quantize_nodes\n  strip_unused_nodes\n  sort_by_execution_order'\n</code></pre>\n<p>the quantised models (.pb) generated successfully but now I have problem with inference when I execute sess.run().</p>\n<h3>Source code / logs</h3>\n<pre><code>Traceback (most recent call last):\n  File \"Inf_Image_pb.py\", line 89, in &lt;module&gt;\n    Session_out = sess.run(l_output, feed_dict={l_input: image})            \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 889, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1120, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\n    options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [474,712,3] != values[2].shape = []\n\t [[Node: Reshape/shape = Pack[N=3, T=DT_INT32, axis=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_image_0_0, _arg_input_image_0_0, Reshape/shape/2)]]\n\nCaused by op u'Reshape/shape', defined at:\n  File \"Inf_Image_pb.py\", line 74, in &lt;module&gt;\n    producer_op_list=None\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Shapes of all inputs must match: values[0].shape = [474,712,3] != values[2].shape = []\n\t [[Node: Reshape/shape = Pack[N=3, T=DT_INT32, axis=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_image_0_0, _arg_input_image_0_0, Reshape/shape/2)]]\n</code></pre>\n<p>I have tried other tensorflow versions, other bazel versions to rebuild the tool and the legacy quantisation tool 'quantize_graph' with mode --mode=eightbit but still fail to inference. In addition I tried other transform combinations using the <code>transform_graph</code> tool, other batch sizes and other input dimensions but still getting error. What is this error refers to ? I can't find any useful information online ..</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\nTensorFlow installed from (source or binary):\nsource\nTensorFlow version (use command below):\nPython version:\n1.4.1\nBazel version (if compiling from source):\n0.8.1\nGCC/Compiler version (if compiling from source):\ngcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.6)\n\nDescribe the problem\nI am using a pre-trained style transfer model that I have converted  to .pb format. When I inference a single image through the fp32 model then I can see the styled image at the output of the network and everything works fine. Later on I optimized the model for inference using transform_graph tool with these parameters :\n--transforms='\n  add_default_attributes\n  strip_unused_nodes(type=float)\n  remove_nodes(op=CheckNumerics)\n  fold_constants(ignore_errors=true)\n  fold_batch_norms\n  fold_old_batch_norms\n  quantize_weights\n  quantize_nodes\n  strip_unused_nodes\n  sort_by_execution_order'\n\nthe quantised models (.pb) generated successfully but now I have problem with inference when I execute sess.run().\nSource code / logs\nTraceback (most recent call last):\n  File \"Inf_Image_pb.py\", line 89, in <module>\n    Session_out = sess.run(l_output, feed_dict={l_input: image})            \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 889, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1120, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\n    options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [474,712,3] != values[2].shape = []\n\t [[Node: Reshape/shape = Pack[N=3, T=DT_INT32, axis=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_image_0_0, _arg_input_image_0_0, Reshape/shape/2)]]\n\nCaused by op u'Reshape/shape', defined at:\n  File \"Inf_Image_pb.py\", line 74, in <module>\n    producer_op_list=None\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Shapes of all inputs must match: values[0].shape = [474,712,3] != values[2].shape = []\n\t [[Node: Reshape/shape = Pack[N=3, T=DT_INT32, axis=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_image_0_0, _arg_input_image_0_0, Reshape/shape/2)]]\n\nI have tried other tensorflow versions, other bazel versions to rebuild the tool and the legacy quantisation tool 'quantize_graph' with mode --mode=eightbit but still fail to inference. In addition I tried other transform combinations using the transform_graph tool, other batch sizes and other input dimensions but still getting error. What is this error refers to ? I can't find any useful information online ..", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n1.4.1\r\n- **Bazel version (if compiling from source)**:\r\n0.8.1\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.6)\r\n\r\n### Describe the problem\r\nI am using a pre-trained style transfer model that I have converted  to .pb format. When I inference a single image through the fp32 model then I can see the styled image at the output of the network and everything works fine. Later on I optimized the model for inference using `transform_graph` tool with these parameters : \r\n\r\n```\r\n--transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=float)\r\n  remove_nodes(op=CheckNumerics)\r\n  fold_constants(ignore_errors=true)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  quantize_nodes\r\n  strip_unused_nodes\r\n  sort_by_execution_order'\r\n```\r\nthe quantised models (.pb) generated successfully but now I have problem with inference when I execute sess.run().\r\n\r\n### Source code / logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"Inf_Image_pb.py\", line 89, in <module>\r\n    Session_out = sess.run(l_output, feed_dict={l_input: image})            \r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [474,712,3] != values[2].shape = []\r\n\t [[Node: Reshape/shape = Pack[N=3, T=DT_INT32, axis=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_image_0_0, _arg_input_image_0_0, Reshape/shape/2)]]\r\n\r\nCaused by op u'Reshape/shape', defined at:\r\n  File \"Inf_Image_pb.py\", line 74, in <module>\r\n    producer_op_list=None\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Shapes of all inputs must match: values[0].shape = [474,712,3] != values[2].shape = []\r\n\t [[Node: Reshape/shape = Pack[N=3, T=DT_INT32, axis=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_image_0_0, _arg_input_image_0_0, Reshape/shape/2)]]\r\n```\r\nI have tried other tensorflow versions, other bazel versions to rebuild the tool and the legacy quantisation tool 'quantize_graph' with mode --mode=eightbit but still fail to inference. In addition I tried other transform combinations using the `transform_graph` tool, other batch sizes and other input dimensions but still getting error. What is this error refers to ? I can't find any useful information online ..\r\n"}