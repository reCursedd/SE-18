{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22002", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22002/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22002/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22002/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22002", "id": 356177788, "node_id": "MDU6SXNzdWUzNTYxNzc3ODg=", "number": 22002, "title": "Feature Request: [tf.data] Access to the size of prefetch buffer", "user": {"login": "wookayin", "id": 1009873, "node_id": "MDQ6VXNlcjEwMDk4NzM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1009873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wookayin", "html_url": "https://github.com/wookayin", "followers_url": "https://api.github.com/users/wookayin/followers", "following_url": "https://api.github.com/users/wookayin/following{/other_user}", "gists_url": "https://api.github.com/users/wookayin/gists{/gist_id}", "starred_url": "https://api.github.com/users/wookayin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wookayin/subscriptions", "organizations_url": "https://api.github.com/users/wookayin/orgs", "repos_url": "https://api.github.com/users/wookayin/repos", "events_url": "https://api.github.com/users/wookayin/events{/privacy}", "received_events_url": "https://api.github.com/users/wookayin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-09-01T06:41:58Z", "updated_at": "2018-11-20T07:55:36Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p><strong>(TL;DR)</strong> Add a new API that can tell the size of the prefetch buffer, similar to <a href=\"https://www.tensorflow.org/api_docs/python/tf/FIFOQueue#size\" rel=\"nofollow\">FIFOQueue.size()</a>.</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: ALL</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.1 (as of current master, it seems unimplemented yet)</li>\n<li><strong>Python version</strong>: ALL</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p><code>tf.data.Dataset.prefetch()</code> allows to have an efficient input pipeline by making input processing operations runnable in parallel to downstream GPU operations. It has a similar semantic to <a href=\"https://www.tensorflow.org/api_docs/python/tf/FIFOQueue\" rel=\"nofollow\">FIFO Queues</a>.</p>\n<p>Currently, there is no way to access the number of elements in the queue or prefetch buffers. We may want to add some methods or operations for this in the <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/data/ops/dataset_ops.py#L2348\">PrefetchDataset</a> class. Traditional TF queue objects have <a href=\"https://www.tensorflow.org/api_docs/python/tf/FIFOQueue#size\" rel=\"nofollow\"><code>size()</code></a> method that returns a <em>scalar tensor</em> for the number of elements in the queue. It is very helpful to debug whether there is any performance issue on the input pipeline or preprocessing.</p>\n<p>For example:</p>\n<div class=\"highlight highlight-source-python\"><pre>  dataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_generator(<span class=\"pl-c1\">...</span>)\n  dataset <span class=\"pl-k\">=</span> dataset.shuffle(<span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10000</span>).repeat()\n\n  dataset <span class=\"pl-k\">=</span> dataset.prefetch(<span class=\"pl-c1\">1024</span>)             <span class=\"pl-c\"><span class=\"pl-c\">#</span> returns an instance of PrefetchDataset</span>\n  prefetch_size_op <span class=\"pl-k\">=</span> dataset.size()            <span class=\"pl-c\"><span class=\"pl-c\">#</span> [!] Proposal. Needs to be named properly</span>\n  prefetch_capacity_op <span class=\"pl-k\">=</span> dataset._buffer_size         <span class=\"pl-c\"><span class=\"pl-c\">#</span> this is already available, but needs to be exposed public, e.g. dataset.capacity()</span>\n\n  dataset <span class=\"pl-k\">=</span> dataset.batch(<span class=\"pl-c1\">32</span>)\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> ...</span></pre></div>\n<p>Thanks!</p>", "body_text": "(TL;DR) Add a new API that can tell the size of the prefetch buffer, similar to FIFOQueue.size().\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): ALL\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below): 1.10.1 (as of current master, it seems unimplemented yet)\nPython version: ALL\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\ntf.data.Dataset.prefetch() allows to have an efficient input pipeline by making input processing operations runnable in parallel to downstream GPU operations. It has a similar semantic to FIFO Queues.\nCurrently, there is no way to access the number of elements in the queue or prefetch buffers. We may want to add some methods or operations for this in the PrefetchDataset class. Traditional TF queue objects have size() method that returns a scalar tensor for the number of elements in the queue. It is very helpful to debug whether there is any performance issue on the input pipeline or preprocessing.\nFor example:\n  dataset = tf.data.Dataset.from_generator(...)\n  dataset = dataset.shuffle(buffer_size=10000).repeat()\n\n  dataset = dataset.prefetch(1024)             # returns an instance of PrefetchDataset\n  prefetch_size_op = dataset.size()            # [!] Proposal. Needs to be named properly\n  prefetch_capacity_op = dataset._buffer_size         # this is already available, but needs to be exposed public, e.g. dataset.capacity()\n\n  dataset = dataset.batch(32)\n  # ...\nThanks!", "body": "**(TL;DR)** Add a new API that can tell the size of the prefetch buffer, similar to [FIFOQueue.size()](https://www.tensorflow.org/api_docs/python/tf/FIFOQueue#size).\r\n\r\n### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ALL\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: \r\n- **TensorFlow version (use command below)**: 1.10.1 (as of current master, it seems unimplemented yet)\r\n- **Python version**: ALL\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\n`tf.data.Dataset.prefetch()` allows to have an efficient input pipeline by making input processing operations runnable in parallel to downstream GPU operations. It has a similar semantic to [FIFO Queues](https://www.tensorflow.org/api_docs/python/tf/FIFOQueue).\r\n\r\nCurrently, there is no way to access the number of elements in the queue or prefetch buffers. We may want to add some methods or operations for this in the [PrefetchDataset](https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/data/ops/dataset_ops.py#L2348) class. Traditional TF queue objects have [`size()`](https://www.tensorflow.org/api_docs/python/tf/FIFOQueue#size) method that returns a *scalar tensor* for the number of elements in the queue. It is very helpful to debug whether there is any performance issue on the input pipeline or preprocessing.\r\n\r\nFor example:\r\n\r\n```python\r\n  dataset = tf.data.Dataset.from_generator(...)\r\n  dataset = dataset.shuffle(buffer_size=10000).repeat()\r\n\r\n  dataset = dataset.prefetch(1024)             # returns an instance of PrefetchDataset\r\n  prefetch_size_op = dataset.size()            # [!] Proposal. Needs to be named properly\r\n  prefetch_capacity_op = dataset._buffer_size         # this is already available, but needs to be exposed public, e.g. dataset.capacity()\r\n\r\n  dataset = dataset.batch(32)\r\n  # ...\r\n```\r\n\r\nThanks!"}