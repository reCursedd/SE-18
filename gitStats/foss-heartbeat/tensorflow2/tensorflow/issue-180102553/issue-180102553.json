{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4658", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4658/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4658/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4658/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4658", "id": 180102553, "node_id": "MDU6SXNzdWUxODAxMDI1NTM=", "number": 4658, "title": "Change variable name  not take effect in checkpoints", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-09-29T16:44:24Z", "updated_at": "2016-09-30T13:06:10Z", "closed_at": "2016-09-29T23:25:38Z", "author_association": "NONE", "body_html": "<p>I want to load into one session different checkpoints of the same model. Like take step 10 and step 100<br>\nIn order to avoid conflict name, I try to modify the variable name first, like change from<br>\nshow_and_tell/model_init/emb:0 to show_and_tell_1/model_init/emb:0,<br>\nmy input checkpoint with all varaibles starts with show_and_tell, and I want to modify it to show_and_tell_1<br>\nso I can load the two models at once.<br>\nCode like below, but the savec checkpoint.meta shows still show_and_tell/model_init/emb:0, what's wrong?</p>\n<p>def reset_model_top_scope():<br>\nsess = tf.InteractiveSession()<br>\nmeta_filename = \".\".join([input_checkpoint, \"meta\"])<br>\nsaver = tf.train.import_meta_graph(meta_filename)<br>\nsaver.restore(sess, input_checkpoint)<br>\nscope = FLAGS.scope<br>\nout_scope = FLAGS.out_scope if FLAGS.out_scope else '%s_%d'%(scope, FLAGS.out_index)<br>\noutput_checkpoint = FLAGS.output_checkpoint<br>\nwith tf.variable_scope(scope) as topscope:<br>\nsrc_vars =[v for v in tf.all_variables() if v.name.startswith(topscope.name)]<br>\nout_vars = {out_scope + v.name[len(scope):v.name.rfind(':')]:v for v in src_vars}<br>\ntf.train.Saver(var_list=out_vars).save(sess, output_checkpoint)<br>\nsess.close()</p>", "body_text": "I want to load into one session different checkpoints of the same model. Like take step 10 and step 100\nIn order to avoid conflict name, I try to modify the variable name first, like change from\nshow_and_tell/model_init/emb:0 to show_and_tell_1/model_init/emb:0,\nmy input checkpoint with all varaibles starts with show_and_tell, and I want to modify it to show_and_tell_1\nso I can load the two models at once.\nCode like below, but the savec checkpoint.meta shows still show_and_tell/model_init/emb:0, what's wrong?\ndef reset_model_top_scope():\nsess = tf.InteractiveSession()\nmeta_filename = \".\".join([input_checkpoint, \"meta\"])\nsaver = tf.train.import_meta_graph(meta_filename)\nsaver.restore(sess, input_checkpoint)\nscope = FLAGS.scope\nout_scope = FLAGS.out_scope if FLAGS.out_scope else '%s_%d'%(scope, FLAGS.out_index)\noutput_checkpoint = FLAGS.output_checkpoint\nwith tf.variable_scope(scope) as topscope:\nsrc_vars =[v for v in tf.all_variables() if v.name.startswith(topscope.name)]\nout_vars = {out_scope + v.name[len(scope):v.name.rfind(':')]:v for v in src_vars}\ntf.train.Saver(var_list=out_vars).save(sess, output_checkpoint)\nsess.close()", "body": "I want to load into one session different checkpoints of the same model. Like take step 10 and step 100\nIn order to avoid conflict name, I try to modify the variable name first, like change from \nshow_and_tell/model_init/emb:0 to show_and_tell_1/model_init/emb:0,\nmy input checkpoint with all varaibles starts with show_and_tell, and I want to modify it to show_and_tell_1\nso I can load the two models at once.\nCode like below, but the savec checkpoint.meta shows still show_and_tell/model_init/emb:0, what's wrong?\n\ndef reset_model_top_scope():\n    sess = tf.InteractiveSession()\n    meta_filename = \".\".join([input_checkpoint, \"meta\"])\n    saver = tf.train.import_meta_graph(meta_filename)\n    saver.restore(sess, input_checkpoint)\n    scope = FLAGS.scope\n    out_scope = FLAGS.out_scope if FLAGS.out_scope else '%s_%d'%(scope, FLAGS.out_index)\n    output_checkpoint = FLAGS.output_checkpoint \n    with tf.variable_scope(scope) as topscope:\n        src_vars =[v for v in tf.all_variables() if v.name.startswith(topscope.name)]\n    out_vars = {out_scope + v.name[len(scope):v.name.rfind(':')]:v for v in src_vars}\n    tf.train.Saver(var_list=out_vars).save(sess, output_checkpoint)\n    sess.close()\n"}