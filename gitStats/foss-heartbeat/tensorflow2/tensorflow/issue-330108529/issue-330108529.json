{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19826", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19826/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19826/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19826/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19826", "id": 330108529, "node_id": "MDU6SXNzdWUzMzAxMDg1Mjk=", "number": 19826, "title": "averaging pooling fail to execute in tensorflow C API for rectangle size", "user": {"login": "coldgemini", "id": 33364009, "node_id": "MDQ6VXNlcjMzMzY0MDA5", "avatar_url": "https://avatars3.githubusercontent.com/u/33364009?v=4", "gravatar_id": "", "url": "https://api.github.com/users/coldgemini", "html_url": "https://github.com/coldgemini", "followers_url": "https://api.github.com/users/coldgemini/followers", "following_url": "https://api.github.com/users/coldgemini/following{/other_user}", "gists_url": "https://api.github.com/users/coldgemini/gists{/gist_id}", "starred_url": "https://api.github.com/users/coldgemini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/coldgemini/subscriptions", "organizations_url": "https://api.github.com/users/coldgemini/orgs", "repos_url": "https://api.github.com/users/coldgemini/repos", "events_url": "https://api.github.com/users/coldgemini/events{/privacy}", "received_events_url": "https://api.github.com/users/coldgemini/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-06-07T03:59:40Z", "updated_at": "2018-07-23T23:02:24Z", "closed_at": "2018-07-23T22:58:53Z", "author_association": "NONE", "body_html": "<p>while square size like 96X96 is OK the rectangle sized average pooling induces failure on GPU version C API.<br>\nchecked the freeze_graph.py tool and the output dimension is right. the bug should be somewhere in the GPU version implementation.</p>\n<p>2018-06-07 10:38:08.502720: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.<br>\n2018-06-07 10:38:09.262953: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.<br>\n2018-06-07 10:38:10.250411: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.<br>\n2018-06-07 10:38:10.290275: F tensorflow/stream_executor/cuda/cuda_dnn.cc:570] could not convert BatchDescriptor {count: 1 feature_map_count: 256 spatial: 0 2  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM<br>\nAborted (core dumped)</p>", "body_text": "while square size like 96X96 is OK the rectangle sized average pooling induces failure on GPU version C API.\nchecked the freeze_graph.py tool and the output dimension is right. the bug should be somewhere in the GPU version implementation.\n2018-06-07 10:38:08.502720: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2018-06-07 10:38:09.262953: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2018-06-07 10:38:10.250411: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2018-06-07 10:38:10.290275: F tensorflow/stream_executor/cuda/cuda_dnn.cc:570] could not convert BatchDescriptor {count: 1 feature_map_count: 256 spatial: 0 2  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM\nAborted (core dumped)", "body": "while square size like 96X96 is OK the rectangle sized average pooling induces failure on GPU version C API.\r\nchecked the freeze_graph.py tool and the output dimension is right. the bug should be somewhere in the GPU version implementation.\r\n\r\n2018-06-07 10:38:08.502720: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2018-06-07 10:38:09.262953: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2018-06-07 10:38:10.250411: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2018-06-07 10:38:10.290275: F tensorflow/stream_executor/cuda/cuda_dnn.cc:570] could not convert BatchDescriptor {count: 1 feature_map_count: 256 spatial: 0 2  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM\r\nAborted (core dumped)"}